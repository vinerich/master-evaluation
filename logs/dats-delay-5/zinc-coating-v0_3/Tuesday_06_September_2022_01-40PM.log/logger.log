[32m[0906 13-40-32 @logger.py:99][0m Log file set to /app/logs/dats-delay-5/zinc-coating-v0_3/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-32 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00003, current rewards: -8.24474, mean: -0.82447
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -68.31580, mean: -1.13860
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -139.34661, mean: -1.26679
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -210.27297, mean: -1.31421
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -281.54926, mean: -1.34071
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -340.67011, mean: -1.31027
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -403.59767, mean: -1.30193
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -474.44308, mean: -1.31790
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -523.58797, mean: -1.27704
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -580.21315, mean: -1.26133
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -643.54623, mean: -1.26186
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -701.87727, mean: -1.25335
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -769.85307, mean: -1.26205
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -819.98910, mean: -1.24241
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -875.09105, mean: -1.23252
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -943.57115, mean: -1.24154
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -994.73451, mean: -1.22807
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1056.65236, mean: -1.22867
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1096.77348, mean: -1.20525
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1159.70602, mean: -1.20803
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1214.27098, mean: -1.20225
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1273.33161, mean: -1.20126
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1330.28745, mean: -1.19846
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1384.84520, mean: -1.19383
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1443.97636, mean: -1.19337
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1498.83301, mean: -1.18955
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1544.26270, mean: -1.17883
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1598.70452, mean: -1.17552
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1641.83663, mean: -1.16442
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1698.75451, mean: -1.16353
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1751.94404, mean: -1.16023
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1806.08327, mean: -1.15775
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1855.15870, mean: -1.15227
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1903.00591, mean: -1.14639
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1983.15269, mean: -1.15974
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2059.42695, mean: -1.17013
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2137.84958, mean: -1.18113
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2215.73220, mean: -1.19125
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2285.79257, mean: -1.19675
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2363.39613, mean: -1.20581
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2441.60828, mean: -1.21473
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2517.70958, mean: -1.22219
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2595.31151, mean: -1.23001
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2643.28641, mean: -1.22374
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2694.26675, mean: -1.21913
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2745.67215, mean: -1.21490
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2792.74870, mean: -1.20898
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2849.83001, mean: -1.20756
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2898.25718, mean: -1.20260
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2951.42184, mean: -1.19976
[32m[0906 13-40-33 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-40-35 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-35 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11543, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10167, current rewards: -4.20451, mean: -0.07008
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10029, current rewards: 1.71014, mean: 0.01555
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10026, current rewards: 7.62060, mean: 0.04763
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09992, current rewards: 13.53524, mean: 0.06445
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09978, current rewards: 19.44727, mean: 0.07480
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09974, current rewards: 25.36321, mean: 0.08182
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09960, current rewards: 30.16849, mean: 0.08380
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09954, current rewards: 33.29491, mean: 0.08121
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09985, current rewards: 36.43035, mean: 0.07920
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10031, current rewards: 27.37441, mean: 0.05368
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10150, current rewards: -15.62904, mean: -0.02791
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10253, current rewards: -60.75003, mean: -0.09959
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10333, current rewards: -108.13966, mean: -0.16385
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10402, current rewards: -155.50446, mean: -0.21902
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10468, current rewards: -200.81843, mean: -0.26423
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10519, current rewards: -278.44771, mean: -0.34376
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10567, current rewards: -378.44771, mean: -0.44006
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10609, current rewards: -478.44771, mean: -0.52577
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10646, current rewards: -578.44771, mean: -0.60255
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10679, current rewards: -649.30261, mean: -0.64287
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10709, current rewards: -663.75869, mean: -0.62619
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10736, current rewards: -685.74325, mean: -0.61779
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10762, current rewards: -708.61937, mean: -0.61088
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10782, current rewards: -722.32725, mean: -0.59696
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10801, current rewards: -726.50865, mean: -0.57659
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10821, current rewards: -769.63443, mean: -0.58751
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10829, current rewards: -808.05934, mean: -0.59416
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10844, current rewards: -846.43868, mean: -0.60031
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10863, current rewards: -884.73884, mean: -0.60599
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10875, current rewards: -927.85296, mean: -0.61447
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10889, current rewards: -970.98166, mean: -0.62242
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10902, current rewards: -984.23974, mean: -0.61133
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10916, current rewards: -972.48891, mean: -0.58584
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10930, current rewards: -960.39771, mean: -0.56164
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10941, current rewards: -948.30801, mean: -0.53881
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10950, current rewards: -936.22915, mean: -0.51725
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10963, current rewards: -924.13237, mean: -0.49685
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10973, current rewards: -911.77646, mean: -0.47737
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10983, current rewards: -897.09414, mean: -0.45770
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10990, current rewards: -882.97767, mean: -0.43929
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10992, current rewards: -876.86023, mean: -0.42566
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11000, current rewards: -870.66832, mean: -0.41264
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11008, current rewards: -864.47638, mean: -0.40022
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11015, current rewards: -858.28789, mean: -0.38837
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11021, current rewards: -852.09961, mean: -0.37704
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11024, current rewards: -846.28694, mean: -0.36636
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11033, current rewards: -840.77325, mean: -0.35626
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11039, current rewards: -835.29534, mean: -0.34660
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11044, current rewards: -830.19199, mean: -0.33748
[32m[0906 13-45-12 @Agent.py:117][0m Average action selection time: 0.1105
[32m[0906 13-45-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-45-12 @MBExp.py:227][0m Rewards obtained: [-826.2049700204786], Lows: [593], Highs: [15], Total time: 276.922318
[32m[0906 13-45-17 @MBExp.py:144][0m ####################################################################
[32m[0906 13-45-17 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11273, current rewards: -12.00000, mean: -1.20000
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11162, current rewards: -112.00000, mean: -1.86667
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11149, current rewards: -212.00000, mean: -1.92727
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11166, current rewards: -312.00000, mean: -1.95000
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11169, current rewards: -412.00000, mean: -1.96190
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11163, current rewards: -512.00000, mean: -1.96923
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11174, current rewards: -612.00000, mean: -1.97419
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11172, current rewards: -712.00000, mean: -1.97778
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11171, current rewards: -706.29208, mean: -1.72266
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11170, current rewards: -691.79187, mean: -1.50390
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11145, current rewards: -677.29074, mean: -1.32802
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11137, current rewards: -662.73336, mean: -1.18345
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11140, current rewards: -648.22445, mean: -1.06266
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11142, current rewards: -633.75102, mean: -0.96023
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11146, current rewards: -626.71304, mean: -0.88269
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11150, current rewards: -600.43567, mean: -0.79005
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11150, current rewards: -580.31683, mean: -0.71644
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11156, current rewards: -560.71146, mean: -0.65199
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11155, current rewards: -541.16069, mean: -0.59468
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11154, current rewards: -521.45658, mean: -0.54318
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11156, current rewards: -501.94007, mean: -0.49697
[32m[0906 13-47-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11156, current rewards: -482.24912, mean: -0.45495
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11156, current rewards: -462.60900, mean: -0.41676
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11162, current rewards: -454.07692, mean: -0.39145
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11166, current rewards: -441.24917, mean: -0.36467
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11170, current rewards: -423.91930, mean: -0.33644
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11165, current rewards: -407.06740, mean: -0.31074
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11151, current rewards: -390.23028, mean: -0.28693
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11151, current rewards: -373.37983, mean: -0.26481
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11153, current rewards: -356.58625, mean: -0.24424
[32m[0906 13-48-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11152, current rewards: -339.74930, mean: -0.22500
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11152, current rewards: -324.44560, mean: -0.20798
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11153, current rewards: -312.28993, mean: -0.19397
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11153, current rewards: -303.65634, mean: -0.18293
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11155, current rewards: -294.84884, mean: -0.17243
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11156, current rewards: -286.02237, mean: -0.16251
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11156, current rewards: -277.19899, mean: -0.15315
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11157, current rewards: -268.38071, mean: -0.14429
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11159, current rewards: -259.55882, mean: -0.13589
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11159, current rewards: -250.75457, mean: -0.12794
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11159, current rewards: -241.94648, mean: -0.12037
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11153, current rewards: -231.02935, mean: -0.11215
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11155, current rewards: -220.12281, mean: -0.10432
[32m[0906 13-49-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11159, current rewards: -229.06345, mean: -0.10605
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11160, current rewards: -205.79528, mean: -0.09312
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11158, current rewards: -180.42071, mean: -0.07983
[32m[0906 13-49-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11152, current rewards: -158.37586, mean: -0.06856
[32m[0906 13-49-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11154, current rewards: -146.55939, mean: -0.06210
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11154, current rewards: -121.63927, mean: -0.05047
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11155, current rewards: -100.25442, mean: -0.04075
[32m[0906 13-49-57 @Agent.py:117][0m Average action selection time: 0.1116
[32m[0906 13-49-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-49-57 @MBExp.py:227][0m Rewards obtained: [-62.931986818766504], Lows: [412], Highs: [14], Total time: 556.504087
[32m[0906 13-50-04 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-04 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11263, current rewards: -5.39666, mean: -0.53967
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11167, current rewards: -1.34079, mean: -0.02235
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11140, current rewards: 2.55238, mean: 0.02320
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11164, current rewards: 6.44759, mean: 0.04030
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11154, current rewards: 10.34754, mean: 0.04927
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11150, current rewards: 14.24597, mean: 0.05479
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11153, current rewards: 18.13876, mean: 0.05851
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11144, current rewards: 21.97555, mean: 0.06104
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11146, current rewards: 25.76127, mean: 0.06283
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11143, current rewards: 29.54827, mean: 0.06424
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11108, current rewards: 33.34036, mean: 0.06537
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11100, current rewards: 37.13142, mean: 0.06631
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11108, current rewards: 30.75780, mean: 0.05042
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11111, current rewards: 34.86932, mean: 0.05283
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11117, current rewards: 38.97850, mean: 0.05490
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11120, current rewards: 43.19523, mean: 0.05684
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11123, current rewards: 47.43054, mean: 0.05856
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11129, current rewards: 51.66280, mean: 0.06007
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11130, current rewards: 55.89547, mean: 0.06142
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11128, current rewards: 60.12649, mean: 0.06263
[32m[0906 13-51-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11134, current rewards: 64.36083, mean: 0.06372
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11135, current rewards: 68.59430, mean: 0.06471
[32m[0906 13-52-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11134, current rewards: 67.48897, mean: 0.06080
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11138, current rewards: 72.28694, mean: 0.06232
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11138, current rewards: 78.86228, mean: 0.06518
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11138, current rewards: 85.04879, mean: 0.06750
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11136, current rewards: 91.24298, mean: 0.06965
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11124, current rewards: 97.43909, mean: 0.07165
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11119, current rewards: 103.62822, mean: 0.07350
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11121, current rewards: 109.82362, mean: 0.07522
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11122, current rewards: 103.36397, mean: 0.06845
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11125, current rewards: 109.57838, mean: 0.07024
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11128, current rewards: 115.34719, mean: 0.07164
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11130, current rewards: 121.08328, mean: 0.07294
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11132, current rewards: 126.81859, mean: 0.07416
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11132, current rewards: 125.81094, mean: 0.07148
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11133, current rewards: 131.77169, mean: 0.07280
[32m[0906 13-53-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11134, current rewards: 137.73339, mean: 0.07405
[32m[0906 13-53-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11134, current rewards: 143.70132, mean: 0.07524
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11133, current rewards: 149.66182, mean: 0.07636
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11132, current rewards: 154.45908, mean: 0.07685
[32m[0906 13-53-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11125, current rewards: 158.87632, mean: 0.07712
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11122, current rewards: 164.97983, mean: 0.07819
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11123, current rewards: 168.97493, mean: 0.07823
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11124, current rewards: 172.97329, mean: 0.07827
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11122, current rewards: 176.97063, mean: 0.07831
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11117, current rewards: 180.97065, mean: 0.07834
[32m[0906 13-54-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11114, current rewards: 184.96918, mean: 0.07838
[32m[0906 13-54-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11115, current rewards: 189.68459, mean: 0.07871
[32m[0906 13-54-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11118, current rewards: 195.21448, mean: 0.07936
[32m[0906 13-54-43 @Agent.py:117][0m Average action selection time: 0.1112
[32m[0906 13-54-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-54-43 @MBExp.py:227][0m Rewards obtained: [199.6398925760123], Lows: [11], Highs: [17], Total time: 835.167142
[32m[0906 13-54-52 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-52 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11155, current rewards: -5.49676, mean: -0.54968
[32m[0906 13-54-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11152, current rewards: 2.16958, mean: 0.03616
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11132, current rewards: 9.93892, mean: 0.09035
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11154, current rewards: 17.71854, mean: 0.11074
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11136, current rewards: 25.48925, mean: 0.12138
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11147, current rewards: 33.27425, mean: 0.12798
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11148, current rewards: 41.04062, mean: 0.13239
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11154, current rewards: 48.64589, mean: 0.13513
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11158, current rewards: 55.07775, mean: 0.13434
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11135, current rewards: 61.66243, mean: 0.13405
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11101, current rewards: 68.24518, mean: 0.13381
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11100, current rewards: 74.83921, mean: 0.13364
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11107, current rewards: 81.43539, mean: 0.13350
[32m[0906 13-56-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11108, current rewards: 88.02246, mean: 0.13337
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11114, current rewards: 94.61309, mean: 0.13326
[32m[0906 13-56-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11116, current rewards: 99.41272, mean: 0.13081
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11118, current rewards: 104.48126, mean: 0.12899
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11122, current rewards: 109.54181, mean: 0.12737
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11122, current rewards: 114.60553, mean: 0.12594
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11120, current rewards: 119.66821, mean: 0.12465
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11124, current rewards: 114.37579, mean: 0.11324
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11124, current rewards: 121.06454, mean: 0.11421
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11124, current rewards: 127.76167, mean: 0.11510
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11127, current rewards: 134.45027, mean: 0.11591
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11129, current rewards: 141.14224, mean: 0.11665
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11132, current rewards: 147.83192, mean: 0.11733
[32m[0906 13-57-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11129, current rewards: 154.52511, mean: 0.11796
[32m[0906 13-57-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11116, current rewards: 161.22140, mean: 0.11855
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11111, current rewards: 167.91258, mean: 0.11909
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11114, current rewards: 174.60298, mean: 0.11959
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11114, current rewards: 181.29666, mean: 0.12006
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11115, current rewards: 187.18850, mean: 0.11999
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11114, current rewards: 193.44195, mean: 0.12015
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11115, current rewards: 187.63550, mean: 0.11303
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11116, current rewards: 199.37187, mean: 0.11659
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11115, current rewards: 211.10940, mean: 0.11995
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11116, current rewards: 222.85973, mean: 0.12313
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11119, current rewards: 234.58044, mean: 0.12612
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11119, current rewards: 246.29966, mean: 0.12895
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11124, current rewards: 260.53245, mean: 0.13292
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11127, current rewards: 263.72342, mean: 0.13121
[32m[0906 13-58-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11121, current rewards: 269.82357, mean: 0.13098
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11117, current rewards: 275.91584, mean: 0.13077
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11123, current rewards: 282.00747, mean: 0.13056
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11124, current rewards: 288.09990, mean: 0.13036
[32m[0906 13-59-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11125, current rewards: 294.19484, mean: 0.13017
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11120, current rewards: 300.27970, mean: 0.12999
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11113, current rewards: 306.33094, mean: 0.12980
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11117, current rewards: 312.42382, mean: 0.12964
[32m[0906 13-59-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11119, current rewards: 318.51414, mean: 0.12948
[32m[0906 13-59-31 @Agent.py:117][0m Average action selection time: 0.1112
[32m[0906 13-59-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-59-31 @MBExp.py:227][0m Rewards obtained: [323.3849543224615], Lows: [11], Highs: [11], Total time: 1113.8908040000001
[32m[0906 13-59-43 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-43 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11127, current rewards: -6.51187, mean: -0.65119
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11154, current rewards: -2.11078, mean: -0.03518
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11185, current rewards: 2.19166, mean: 0.01992
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11170, current rewards: 6.49172, mean: 0.04057
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11158, current rewards: 10.79434, mean: 0.05140
[32m[0906 14-00-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11162, current rewards: 15.10227, mean: 0.05809
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11147, current rewards: 19.90552, mean: 0.06421
[32m[0906 14-00-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11139, current rewards: 24.11904, mean: 0.06700
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11142, current rewards: 28.33204, mean: 0.06910
[32m[0906 14-00-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11103, current rewards: 22.28030, mean: 0.04844
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11079, current rewards: 26.89507, mean: 0.05274
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11073, current rewards: 31.50985, mean: 0.05627
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11074, current rewards: 36.12462, mean: 0.05922
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11080, current rewards: 40.73939, mean: 0.06173
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11078, current rewards: 44.50209, mean: 0.06268
[32m[0906 14-01-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11082, current rewards: 47.83812, mean: 0.06294
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11088, current rewards: 15.97236, mean: 0.01972
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11090, current rewards: -34.02764, mean: -0.03957
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11092, current rewards: -84.02764, mean: -0.09234
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11095, current rewards: -134.02764, mean: -0.13961
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11095, current rewards: -184.02764, mean: -0.18221
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11096, current rewards: -234.02764, mean: -0.22078
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11097, current rewards: -284.02764, mean: -0.25588
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11097, current rewards: -334.02764, mean: -0.28795
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11096, current rewards: -384.02764, mean: -0.31738
[32m[0906 14-02-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11098, current rewards: -434.02764, mean: -0.34447
[32m[0906 14-02-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11092, current rewards: -484.02764, mean: -0.36949
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11080, current rewards: -534.02764, mean: -0.39267
[32m[0906 14-02-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11072, current rewards: -584.02764, mean: -0.41420
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11069, current rewards: -634.02764, mean: -0.43427
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11073, current rewards: -684.02764, mean: -0.45300
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11077, current rewards: -734.02764, mean: -0.47053
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11080, current rewards: -784.02764, mean: -0.48697
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11085, current rewards: -834.02764, mean: -0.50243
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11087, current rewards: -884.02764, mean: -0.51698
[32m[0906 14-02-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11089, current rewards: -934.02764, mean: -0.53070
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11093, current rewards: -984.02764, mean: -0.54366
[32m[0906 14-03-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11094, current rewards: -1034.02764, mean: -0.55593
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11096, current rewards: -1084.02764, mean: -0.56755
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11099, current rewards: -1134.02764, mean: -0.57859
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11096, current rewards: -1184.02764, mean: -0.58907
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11088, current rewards: -1234.02764, mean: -0.59904
[32m[0906 14-03-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11083, current rewards: -1284.02764, mean: -0.60854
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11082, current rewards: -1334.02764, mean: -0.61761
[32m[0906 14-03-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11083, current rewards: -1384.02764, mean: -0.62626
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11084, current rewards: -1434.02764, mean: -0.63453
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11078, current rewards: -1484.02764, mean: -0.64244
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11072, current rewards: -1534.02764, mean: -0.65001
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11072, current rewards: -1584.02764, mean: -0.65727
[32m[0906 14-04-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11075, current rewards: -1634.02764, mean: -0.66424
[32m[0906 14-04-20 @Agent.py:117][0m Average action selection time: 0.1108
[32m[0906 14-04-20 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-04-20 @MBExp.py:227][0m Rewards obtained: [-1674.0276359911243], Lows: [5], Highs: [1730], Total time: 1391.4819430000002
[32m[0906 14-04-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-34 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-04-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11273, current rewards: -14.00000, mean: -1.40000
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11269, current rewards: -11.08386, mean: -0.18473
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11216, current rewards: -6.29275, mean: -0.05721
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11198, current rewards: -1.49330, mean: -0.00933
[32m[0906 14-04-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11204, current rewards: 3.30049, mean: 0.01572
[32m[0906 14-05-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11197, current rewards: 7.92664, mean: 0.03049
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11198, current rewards: 12.68771, mean: 0.04093
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11202, current rewards: 17.45109, mean: 0.04848
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11182, current rewards: -18.70790, mean: -0.04563
[32m[0906 14-05-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11145, current rewards: -81.81369, mean: -0.17786
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11113, current rewards: -144.89751, mean: -0.28411
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11109, current rewards: -210.15099, mean: -0.37527
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11117, current rewards: -273.24844, mean: -0.44795
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11119, current rewards: -335.01643, mean: -0.50760
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11116, current rewards: -382.87652, mean: -0.53926
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11125, current rewards: -428.16890, mean: -0.56338
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11124, current rewards: -473.46158, mean: -0.58452
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11124, current rewards: -518.75423, mean: -0.60320
[32m[0906 14-06-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11126, current rewards: -564.04318, mean: -0.61983
[32m[0906 14-06-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11126, current rewards: -609.34203, mean: -0.63473
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11124, current rewards: -654.64999, mean: -0.64817
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11126, current rewards: -661.68336, mean: -0.62423
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11126, current rewards: -656.76154, mean: -0.59168
[32m[0906 14-06-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11126, current rewards: -651.85601, mean: -0.56194
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11130, current rewards: -646.95362, mean: -0.53467
[32m[0906 14-06-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11130, current rewards: -642.04667, mean: -0.50956
[32m[0906 14-07-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11127, current rewards: -637.14218, mean: -0.48637
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11117, current rewards: -632.24001, mean: -0.46488
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11105, current rewards: -627.33337, mean: -0.44492
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11100, current rewards: -632.64935, mean: -0.43332
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11102, current rewards: -628.02565, mean: -0.41591
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11105, current rewards: -623.56690, mean: -0.39972
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11109, current rewards: -619.10816, mean: -0.38454
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11111, current rewards: -614.64941, mean: -0.37027
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11111, current rewards: -610.19067, mean: -0.35684
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11112, current rewards: -605.73192, mean: -0.34417
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11112, current rewards: -601.27318, mean: -0.33220
[32m[0906 14-08-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11112, current rewards: -596.81443, mean: -0.32087
[32m[0906 14-08-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11123, current rewards: -622.14203, mean: -0.32573
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11129, current rewards: -672.14203, mean: -0.34293
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11134, current rewards: -722.14203, mean: -0.35927
[32m[0906 14-08-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11131, current rewards: -772.14203, mean: -0.37483
[32m[0906 14-08-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11122, current rewards: -822.14203, mean: -0.38964
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11115, current rewards: -872.14203, mean: -0.40377
[32m[0906 14-08-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11117, current rewards: -922.14203, mean: -0.41726
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11118, current rewards: -972.14203, mean: -0.43015
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11110, current rewards: -1022.14203, mean: -0.44249
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11105, current rewards: -1072.14203, mean: -0.45430
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11097, current rewards: -1122.14203, mean: -0.46562
[32m[0906 14-09-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11099, current rewards: -1172.14203, mean: -0.47648
[32m[0906 14-09-13 @Agent.py:117][0m Average action selection time: 0.1110
[32m[0906 14-09-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-09-13 @MBExp.py:227][0m Rewards obtained: [-1212.1420310400676], Lows: [380], Highs: [625], Total time: 1669.6812790000004
[32m[0906 14-09-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-29 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11098, current rewards: -5.66920, mean: -0.56692
[32m[0906 14-09-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11131, current rewards: 6.34795, mean: 0.10580
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11168, current rewards: 19.99419, mean: 0.18177
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11161, current rewards: 33.62224, mean: 0.21014
[32m[0906 14-09-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11152, current rewards: 47.25701, mean: 0.22503
[32m[0906 14-09-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11167, current rewards: 61.37208, mean: 0.23605
[32m[0906 14-10-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11157, current rewards: 75.07976, mean: 0.24219
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11152, current rewards: 88.77170, mean: 0.24659
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11124, current rewards: 95.15593, mean: 0.23209
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11080, current rewards: 112.58692, mean: 0.24475
[32m[0906 14-10-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11049, current rewards: 130.03857, mean: 0.25498
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11046, current rewards: 147.46802, mean: 0.26334
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11051, current rewards: 164.90224, mean: 0.27033
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11055, current rewards: 179.79242, mean: 0.27241
[32m[0906 14-10-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11061, current rewards: 195.93565, mean: 0.27597
[32m[0906 14-10-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11062, current rewards: 212.05715, mean: 0.27902
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11066, current rewards: 228.18191, mean: 0.28171
[32m[0906 14-11-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11071, current rewards: 244.33941, mean: 0.28412
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11073, current rewards: 260.46251, mean: 0.28622
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11078, current rewards: 276.62405, mean: 0.28815
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11076, current rewards: 292.78627, mean: 0.28989
[32m[0906 14-11-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11076, current rewards: 309.68125, mean: 0.29215
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11080, current rewards: 326.00245, mean: 0.29370
[32m[0906 14-11-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11081, current rewards: 342.35230, mean: 0.29513
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11081, current rewards: 351.42523, mean: 0.29043
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11083, current rewards: 360.10617, mean: 0.28580
[32m[0906 14-11-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11081, current rewards: 368.80291, mean: 0.28153
[32m[0906 14-12-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11069, current rewards: 377.48743, mean: 0.27756
[32m[0906 14-12-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11059, current rewards: 386.16664, mean: 0.27388
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11049, current rewards: 395.99903, mean: 0.27123
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11048, current rewards: 407.34575, mean: 0.26977
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11052, current rewards: 416.43493, mean: 0.26695
[32m[0906 14-12-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11052, current rewards: 419.62159, mean: 0.26063
[32m[0906 14-12-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11054, current rewards: 425.94349, mean: 0.25659
[32m[0906 14-12-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11058, current rewards: 434.75969, mean: 0.25425
[32m[0906 14-12-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11057, current rewards: 443.55204, mean: 0.25202
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11059, current rewards: 452.34737, mean: 0.24992
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11063, current rewards: 461.16039, mean: 0.24794
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11064, current rewards: 458.40608, mean: 0.24000
[32m[0906 14-13-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11067, current rewards: 468.47040, mean: 0.23902
[32m[0906 14-13-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11066, current rewards: 478.48577, mean: 0.23805
[32m[0906 14-13-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11058, current rewards: 488.48787, mean: 0.23713
[32m[0906 14-13-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11053, current rewards: 498.49195, mean: 0.23625
[32m[0906 14-13-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11046, current rewards: 508.51320, mean: 0.23542
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11047, current rewards: 508.35341, mean: 0.23002
[32m[0906 14-13-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11051, current rewards: 521.03970, mean: 0.23055
[32m[0906 14-13-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11045, current rewards: 533.69973, mean: 0.23104
[32m[0906 14-13-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11040, current rewards: 546.37693, mean: 0.23152
[32m[0906 14-13-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11036, current rewards: 559.05424, mean: 0.23197
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11035, current rewards: 571.72978, mean: 0.23241
[32m[0906 14-14-06 @Agent.py:117][0m Average action selection time: 0.1104
[32m[0906 14-14-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-14-06 @MBExp.py:227][0m Rewards obtained: [581.87622675655], Lows: [18], Highs: [11], Total time: 1946.2842800000003
[32m[0906 14-14-24 @MBExp.py:144][0m ####################################################################
[32m[0906 14-14-24 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11239, current rewards: -4.35307, mean: -0.43531
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11191, current rewards: 1.68223, mean: 0.02804
[32m[0906 14-14-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11169, current rewards: 7.67997, mean: 0.06982
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11167, current rewards: 13.68776, mean: 0.08555
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11154, current rewards: 20.32510, mean: 0.09679
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11148, current rewards: 26.47524, mean: 0.10183
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11156, current rewards: 32.62243, mean: 0.10523
[32m[0906 14-15-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11143, current rewards: 27.47116, mean: 0.07631
[32m[0906 14-15-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11095, current rewards: 34.91031, mean: 0.08515
[32m[0906 14-15-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11067, current rewards: 42.35416, mean: 0.09207
[32m[0906 14-15-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11036, current rewards: 49.79908, mean: 0.09765
[32m[0906 14-15-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11036, current rewards: 57.24528, mean: 0.10222
[32m[0906 14-15-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11047, current rewards: 65.61885, mean: 0.10757
[32m[0906 14-15-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11053, current rewards: 73.69314, mean: 0.11166
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11054, current rewards: 81.76743, mean: 0.11517
[32m[0906 14-15-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11061, current rewards: 89.84172, mean: 0.11821
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11062, current rewards: 70.04035, mean: 0.08647
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11062, current rewards: 20.04035, mean: 0.02330
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11066, current rewards: -29.95965, mean: -0.03292
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11066, current rewards: -79.95965, mean: -0.08329
[32m[0906 14-16-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11069, current rewards: -76.61524, mean: -0.07586
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11075, current rewards: -73.63286, mean: -0.06946
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11077, current rewards: -70.64332, mean: -0.06364
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11081, current rewards: -67.65418, mean: -0.05832
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11082, current rewards: -64.66373, mean: -0.05344
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11083, current rewards: -70.20266, mean: -0.05572
[32m[0906 14-16-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11080, current rewards: -62.67213, mean: -0.04784
[32m[0906 14-16-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11069, current rewards: -55.12383, mean: -0.04053
[32m[0906 14-17-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11057, current rewards: -47.57543, mean: -0.03374
[32m[0906 14-17-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11049, current rewards: -41.24111, mean: -0.02825
[32m[0906 14-17-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11044, current rewards: -45.22036, mean: -0.02995
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11047, current rewards: -38.90649, mean: -0.02494
[32m[0906 14-17-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11052, current rewards: -32.59562, mean: -0.02025
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11054, current rewards: -26.28151, mean: -0.01583
[32m[0906 14-17-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11059, current rewards: -19.96580, mean: -0.01168
[32m[0906 14-17-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11064, current rewards: -13.65043, mean: -0.00776
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11064, current rewards: -7.33446, mean: -0.00405
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11066, current rewards: 0.21958, mean: 0.00012
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11070, current rewards: 6.47691, mean: 0.00339
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11071, current rewards: 12.73506, mean: 0.00650
[32m[0906 14-18-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11070, current rewards: 14.06491, mean: 0.00700
[32m[0906 14-18-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11063, current rewards: 20.74746, mean: 0.01007
[32m[0906 14-18-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11056, current rewards: 27.42754, mean: 0.01300
[32m[0906 14-18-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11049, current rewards: 34.10651, mean: 0.01579
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11047, current rewards: 28.60930, mean: 0.01295
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11048, current rewards: 35.49885, mean: 0.01571
[32m[0906 14-18-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11043, current rewards: 42.58532, mean: 0.01844
[32m[0906 14-18-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11038, current rewards: 49.79011, mean: 0.02110
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11032, current rewards: 56.99266, mean: 0.02365
[32m[0906 14-18-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11029, current rewards: 64.19483, mean: 0.02610
[32m[0906 14-19-01 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-19-01 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-19-01 @MBExp.py:227][0m Rewards obtained: [69.95808370418128], Lows: [22], Highs: [184], Total time: 2222.720553
[32m[0906 14-19-22 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-22 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11056, current rewards: 0.85640, mean: 0.08564
[32m[0906 14-19-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11147, current rewards: 8.88323, mean: 0.14805
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11143, current rewards: 17.18335, mean: 0.15621
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11143, current rewards: 25.48347, mean: 0.15927
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11149, current rewards: 31.27074, mean: 0.14891
[32m[0906 14-19-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11144, current rewards: 33.74081, mean: 0.12977
[32m[0906 14-19-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11134, current rewards: 36.21089, mean: 0.11681
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11114, current rewards: 38.68097, mean: 0.10745
[32m[0906 14-20-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11069, current rewards: 41.15104, mean: 0.10037
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11034, current rewards: 43.62112, mean: 0.09483
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11012, current rewards: 46.09119, mean: 0.09037
[32m[0906 14-20-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11011, current rewards: 48.56127, mean: 0.08672
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11020, current rewards: 46.83209, mean: 0.07677
[32m[0906 14-20-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11028, current rewards: -3.16791, mean: -0.00480
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11032, current rewards: -53.16791, mean: -0.07488
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11034, current rewards: -103.16791, mean: -0.13575
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11042, current rewards: -153.16791, mean: -0.18910
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11048, current rewards: -181.56567, mean: -0.21112
[32m[0906 14-21-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11052, current rewards: -177.45421, mean: -0.19500
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11057, current rewards: -173.34401, mean: -0.18057
[32m[0906 14-21-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11059, current rewards: -176.71127, mean: -0.17496
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11063, current rewards: -172.57059, mean: -0.16280
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11064, current rewards: -168.52212, mean: -0.15182
[32m[0906 14-21-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11066, current rewards: -164.47317, mean: -0.14179
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11070, current rewards: -160.42200, mean: -0.13258
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11073, current rewards: -156.37280, mean: -0.12411
[32m[0906 14-21-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11068, current rewards: -152.32382, mean: -0.11628
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11060, current rewards: -148.27169, mean: -0.10902
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11048, current rewards: -144.01196, mean: -0.10214
[32m[0906 14-22-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11039, current rewards: -138.39413, mean: -0.09479
[32m[0906 14-22-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11032, current rewards: -132.92030, mean: -0.08803
[32m[0906 14-22-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11036, current rewards: -127.44666, mean: -0.08170
[32m[0906 14-22-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11038, current rewards: -121.97679, mean: -0.07576
[32m[0906 14-22-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11042, current rewards: -116.50322, mean: -0.07018
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11045, current rewards: -111.03034, mean: -0.06493
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11049, current rewards: -105.55551, mean: -0.05997
[32m[0906 14-22-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11053, current rewards: -100.08326, mean: -0.05529
[32m[0906 14-22-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11057, current rewards: -104.50805, mean: -0.05619
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11059, current rewards: -100.10536, mean: -0.05241
[32m[0906 14-22-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11061, current rewards: -95.74116, mean: -0.04885
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11059, current rewards: -91.37825, mean: -0.04546
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11053, current rewards: -87.01193, mean: -0.04224
[32m[0906 14-23-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11047, current rewards: -82.64583, mean: -0.03917
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11040, current rewards: -83.45812, mean: -0.03864
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11034, current rewards: -79.16241, mean: -0.03582
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11037, current rewards: -74.79210, mean: -0.03309
[32m[0906 14-23-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11032, current rewards: -70.42483, mean: -0.03049
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11028, current rewards: -66.05796, mean: -0.02799
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11023, current rewards: -61.69233, mean: -0.02560
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11018, current rewards: -62.59148, mean: -0.02544
[32m[0906 14-23-58 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-23-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-23-58 @MBExp.py:227][0m Rewards obtained: [-59.05283558429841], Lows: [6], Highs: [250], Total time: 2498.884626
[32m[0906 14-24-22 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-22 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-24-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10973, current rewards: -5.49096, mean: -0.54910
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11170, current rewards: -1.14193, mean: -0.01903
[32m[0906 14-24-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11162, current rewards: 3.44032, mean: 0.03128
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11148, current rewards: 8.02082, mean: 0.05013
[32m[0906 14-24-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11142, current rewards: 12.59562, mean: 0.05998
[32m[0906 14-24-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11148, current rewards: 17.17379, mean: 0.06605
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11150, current rewards: 21.75135, mean: 0.07017
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11108, current rewards: 24.23069, mean: 0.06731
[32m[0906 14-25-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11061, current rewards: 21.50565, mean: 0.05245
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11025, current rewards: 27.25502, mean: 0.05925
[32m[0906 14-25-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11003, current rewards: 32.99944, mean: 0.06470
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11002, current rewards: 38.74325, mean: 0.06918
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11011, current rewards: 45.70136, mean: 0.07492
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11026, current rewards: 51.77295, mean: 0.07844
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11033, current rewards: 47.22032, mean: 0.06651
[32m[0906 14-25-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11034, current rewards: 53.03119, mean: 0.06978
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11041, current rewards: 58.84146, mean: 0.07264
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11044, current rewards: 64.65336, mean: 0.07518
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11047, current rewards: 70.46591, mean: 0.07744
[32m[0906 14-26-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11054, current rewards: 76.27928, mean: 0.07946
[32m[0906 14-26-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11056, current rewards: 81.88664, mean: 0.08108
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11059, current rewards: 80.03477, mean: 0.07550
[32m[0906 14-26-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11063, current rewards: 86.43777, mean: 0.07787
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11064, current rewards: 92.85228, mean: 0.08005
[32m[0906 14-26-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11064, current rewards: 99.25640, mean: 0.08203
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11068, current rewards: 105.66572, mean: 0.08386
[32m[0906 14-26-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11065, current rewards: 112.06950, mean: 0.08555
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11054, current rewards: 118.48555, mean: 0.08712
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11043, current rewards: 125.10559, mean: 0.08873
[32m[0906 14-27-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11031, current rewards: 132.21793, mean: 0.09056
[32m[0906 14-27-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11022, current rewards: 138.76414, mean: 0.09190
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11019, current rewards: 145.31326, mean: 0.09315
[32m[0906 14-27-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11022, current rewards: 142.40261, mean: 0.08845
[32m[0906 14-27-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11027, current rewards: 150.05769, mean: 0.09040
[32m[0906 14-27-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11034, current rewards: 157.71277, mean: 0.09223
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11037, current rewards: 165.36786, mean: 0.09396
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11039, current rewards: 173.02294, mean: 0.09559
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11042, current rewards: 158.19661, mean: 0.08505
[32m[0906 14-27-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11044, current rewards: 108.19661, mean: 0.05665
[32m[0906 14-27-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11046, current rewards: 58.19661, mean: 0.02969
[32m[0906 14-28-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11044, current rewards: 8.19661, mean: 0.00408
[32m[0906 14-28-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11037, current rewards: -41.80339, mean: -0.02029
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11031, current rewards: -91.80339, mean: -0.04351
[32m[0906 14-28-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11023, current rewards: -141.80339, mean: -0.06565
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11016, current rewards: -191.80339, mean: -0.08679
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11015, current rewards: -241.80339, mean: -0.10699
[32m[0906 14-28-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11011, current rewards: -291.80339, mean: -0.12632
[32m[0906 14-28-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11005, current rewards: -341.80339, mean: -0.14483
[32m[0906 14-28-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11002, current rewards: -391.80339, mean: -0.16257
[32m[0906 14-28-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10996, current rewards: -441.80339, mean: -0.17959
[32m[0906 14-28-57 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-28-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-28-57 @MBExp.py:227][0m Rewards obtained: [-481.8033914621675], Lows: [16], Highs: [669], Total time: 2774.385055
[32m[0906 14-29-23 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-23 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-29-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11170, current rewards: 0.75454, mean: 0.07545
[32m[0906 14-29-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11143, current rewards: 6.87814, mean: 0.11464
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11167, current rewards: 13.28983, mean: 0.12082
[32m[0906 14-29-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11159, current rewards: 19.69659, mean: 0.12310
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 26.05900, mean: 0.12409
[32m[0906 14-29-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11150, current rewards: 32.47690, mean: 0.12491
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11124, current rewards: 38.89971, mean: 0.12548
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11068, current rewards: 45.32697, mean: 0.12591
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11034, current rewards: 51.76161, mean: 0.12625
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11003, current rewards: 58.18916, mean: 0.12650
[32m[0906 14-30-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10976, current rewards: 64.61687, mean: 0.12670
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10973, current rewards: 71.03667, mean: 0.12685
[32m[0906 14-30-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10982, current rewards: 77.05218, mean: 0.12632
[32m[0906 14-30-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10996, current rewards: 78.33235, mean: 0.11869
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11007, current rewards: 85.55063, mean: 0.12049
[32m[0906 14-30-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11013, current rewards: 92.76255, mean: 0.12206
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11021, current rewards: 99.96591, mean: 0.12341
[32m[0906 14-30-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11027, current rewards: 107.18213, mean: 0.12463
[32m[0906 14-31-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11029, current rewards: 114.40873, mean: 0.12572
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11034, current rewards: 121.62511, mean: 0.12669
[32m[0906 14-31-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11036, current rewards: 130.45077, mean: 0.12916
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11039, current rewards: 136.57699, mean: 0.12885
[32m[0906 14-31-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11047, current rewards: 142.61031, mean: 0.12848
[32m[0906 14-31-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11050, current rewards: 148.64126, mean: 0.12814
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11051, current rewards: 154.67426, mean: 0.12783
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11055, current rewards: 160.70812, mean: 0.12755
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11052, current rewards: 156.15103, mean: 0.11920
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11041, current rewards: 161.74449, mean: 0.11893
[32m[0906 14-31-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11032, current rewards: 167.34354, mean: 0.11868
[32m[0906 14-32-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11020, current rewards: 172.97018, mean: 0.11847
[32m[0906 14-32-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11011, current rewards: 178.56472, mean: 0.11825
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11007, current rewards: 184.15510, mean: 0.11805
[32m[0906 14-32-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11009, current rewards: 183.40486, mean: 0.11392
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11014, current rewards: 185.55278, mean: 0.11178
[32m[0906 14-32-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11018, current rewards: 191.33370, mean: 0.11189
[32m[0906 14-32-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11020, current rewards: 197.10979, mean: 0.11199
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11024, current rewards: 202.89093, mean: 0.11209
[32m[0906 14-32-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11026, current rewards: 208.30006, mean: 0.11199
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11028, current rewards: 208.47508, mean: 0.10915
[32m[0906 14-33-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11033, current rewards: 214.35945, mean: 0.10937
[32m[0906 14-33-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11032, current rewards: 220.23818, mean: 0.10957
[32m[0906 14-33-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11025, current rewards: 226.12374, mean: 0.10977
[32m[0906 14-33-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11020, current rewards: 232.00441, mean: 0.10995
[32m[0906 14-33-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11015, current rewards: 227.47811, mean: 0.10531
[32m[0906 14-33-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11008, current rewards: 233.16747, mean: 0.10551
[32m[0906 14-33-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11005, current rewards: 239.66299, mean: 0.10605
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11002, current rewards: 245.21748, mean: 0.10615
[32m[0906 14-33-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10996, current rewards: 245.37265, mean: 0.10397
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10993, current rewards: 251.13695, mean: 0.10421
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10989, current rewards: 256.98468, mean: 0.10447
[32m[0906 14-33-58 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-33-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-33-58 @MBExp.py:227][0m Rewards obtained: [261.6755981935254], Lows: [15], Highs: [15], Total time: 3049.741246
[32m[0906 14-34-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-26 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 14-34-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11172, current rewards: -5.59170, mean: -0.55917
[32m[0906 14-34-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11206, current rewards: 1.47087, mean: 0.02451
[32m[0906 14-34-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11204, current rewards: 8.93047, mean: 0.08119
[32m[0906 14-34-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11204, current rewards: 16.19526, mean: 0.10122
[32m[0906 14-34-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11217, current rewards: 23.32225, mean: 0.11106
[32m[0906 14-34-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11209, current rewards: 30.65465, mean: 0.11790
[32m[0906 14-35-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11161, current rewards: 37.99644, mean: 0.12257
[32m[0906 14-35-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11119, current rewards: 45.34254, mean: 0.12595
[32m[0906 14-35-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11079, current rewards: 52.68315, mean: 0.12850
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11051, current rewards: 60.00583, mean: 0.13045
[32m[0906 14-35-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11032, current rewards: 67.34200, mean: 0.13204
[32m[0906 14-35-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11027, current rewards: 74.67219, mean: 0.13334
[32m[0906 14-35-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11036, current rewards: 81.88944, mean: 0.13424
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11049, current rewards: 89.18552, mean: 0.13513
[32m[0906 14-35-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11052, current rewards: 85.74369, mean: 0.12077
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11059, current rewards: 93.03524, mean: 0.12241
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11066, current rewards: 100.32065, mean: 0.12385
[32m[0906 14-36-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11071, current rewards: 107.60338, mean: 0.12512
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11074, current rewards: 114.88354, mean: 0.12625
[32m[0906 14-36-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11079, current rewards: 122.16734, mean: 0.12726
[32m[0906 14-36-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11083, current rewards: 131.22004, mean: 0.12992
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11085, current rewards: 138.17824, mean: 0.13036
[32m[0906 14-36-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11090, current rewards: 145.13414, mean: 0.13075
[32m[0906 14-36-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11093, current rewards: 152.10300, mean: 0.13112
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11099, current rewards: 146.23715, mean: 0.12086
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11101, current rewards: 152.73683, mean: 0.12122
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11098, current rewards: 159.23530, mean: 0.12155
[32m[0906 14-36-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11088, current rewards: 165.73400, mean: 0.12186
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11079, current rewards: 171.77047, mean: 0.12182
[32m[0906 14-37-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11071, current rewards: 178.64670, mean: 0.12236
[32m[0906 14-37-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11064, current rewards: 185.51597, mean: 0.12286
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11055, current rewards: 192.38356, mean: 0.12332
[32m[0906 14-37-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11056, current rewards: 190.01764, mean: 0.11802
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11066, current rewards: 193.77436, mean: 0.11673
[32m[0906 14-37-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11071, current rewards: 197.53414, mean: 0.11552
[32m[0906 14-37-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11074, current rewards: 201.29594, mean: 0.11437
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11078, current rewards: 204.92821, mean: 0.11322
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11081, current rewards: 208.79936, mean: 0.11226
[32m[0906 14-37-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11084, current rewards: 212.69495, mean: 0.11136
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11087, current rewards: 216.59524, mean: 0.11051
[32m[0906 14-38-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11085, current rewards: 220.49834, mean: 0.10970
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11078, current rewards: 224.39669, mean: 0.10893
[32m[0906 14-38-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11074, current rewards: 228.29424, mean: 0.10820
[32m[0906 14-38-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11067, current rewards: 232.19331, mean: 0.10750
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11061, current rewards: 236.10426, mean: 0.10683
[32m[0906 14-38-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11057, current rewards: 240.04503, mean: 0.10621
[32m[0906 14-38-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11051, current rewards: 243.83886, mean: 0.10556
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11046, current rewards: 247.63608, mean: 0.10493
[32m[0906 14-38-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11042, current rewards: 253.67753, mean: 0.10526
[32m[0906 14-38-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11038, current rewards: 260.03867, mean: 0.10571
[32m[0906 14-39-03 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-39-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-39-03 @MBExp.py:227][0m Rewards obtained: [265.1259028677689], Lows: [11], Highs: [12], Total time: 3326.262948
[32m[0906 14-39-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-33 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-39-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11228, current rewards: -5.54720, mean: -0.55472
[32m[0906 14-39-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11264, current rewards: -0.61138, mean: -0.01019
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11225, current rewards: 4.23800, mean: 0.03853
[32m[0906 14-39-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11209, current rewards: 9.23621, mean: 0.05773
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11207, current rewards: 14.02891, mean: 0.06680
[32m[0906 14-40-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11185, current rewards: 18.81929, mean: 0.07238
[32m[0906 14-40-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11133, current rewards: 23.61066, mean: 0.07616
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11084, current rewards: 28.39990, mean: 0.07889
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11053, current rewards: 34.72285, mean: 0.08469
[32m[0906 14-40-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11032, current rewards: 39.63340, mean: 0.08616
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11011, current rewards: 44.54133, mean: 0.08734
[32m[0906 14-40-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11008, current rewards: 49.79915, mean: 0.08893
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11029, current rewards: 54.73544, mean: 0.08973
[32m[0906 14-40-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11039, current rewards: 59.67316, mean: 0.09041
[32m[0906 14-40-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11045, current rewards: 64.60445, mean: 0.09099
[32m[0906 14-40-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11058, current rewards: 69.53969, mean: 0.09150
[32m[0906 14-41-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11065, current rewards: 74.46966, mean: 0.09194
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11070, current rewards: 79.40521, mean: 0.09233
[32m[0906 14-41-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11080, current rewards: 73.84584, mean: 0.08115
[32m[0906 14-41-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11087, current rewards: 78.08730, mean: 0.08134
[32m[0906 14-41-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11094, current rewards: 34.40052, mean: 0.03406
[32m[0906 14-41-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11101, current rewards: -15.59948, mean: -0.01472
[32m[0906 14-41-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11103, current rewards: -54.28532, mean: -0.04891
[32m[0906 14-41-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11105, current rewards: -48.27901, mean: -0.04162
[32m[0906 14-41-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11109, current rewards: -42.27348, mean: -0.03494
[32m[0906 14-41-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11110, current rewards: -36.26760, mean: -0.02878
[32m[0906 14-41-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11111, current rewards: -30.26097, mean: -0.02310
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11099, current rewards: -29.96371, mean: -0.02203
[32m[0906 14-42-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11089, current rewards: -24.13827, mean: -0.01712
[32m[0906 14-42-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11081, current rewards: -19.03756, mean: -0.01304
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11072, current rewards: -13.93092, mean: -0.00923
[32m[0906 14-42-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11065, current rewards: -8.82369, mean: -0.00566
[32m[0906 14-42-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11060, current rewards: -3.71397, mean: -0.00231
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11063, current rewards: 1.38575, mean: 0.00083
[32m[0906 14-42-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11065, current rewards: 6.48735, mean: 0.00379
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11070, current rewards: 11.59049, mean: 0.00659
[32m[0906 14-42-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11073, current rewards: 16.95072, mean: 0.00937
[32m[0906 14-42-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11075, current rewards: 22.05317, mean: 0.01186
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11079, current rewards: 16.73899, mean: 0.00876
[32m[0906 14-43-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11082, current rewards: 21.61212, mean: 0.01103
[32m[0906 14-43-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11080, current rewards: 26.48492, mean: 0.01318
[32m[0906 14-43-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11075, current rewards: 31.35792, mean: 0.01522
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11068, current rewards: 36.23371, mean: 0.01717
[32m[0906 14-43-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11063, current rewards: 35.64194, mean: 0.01650
[32m[0906 14-43-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11058, current rewards: 40.79862, mean: 0.01846
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11053, current rewards: 45.83201, mean: 0.02028
[32m[0906 14-43-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11044, current rewards: 50.86692, mean: 0.02202
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11040, current rewards: 55.90226, mean: 0.02369
[32m[0906 14-44-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11035, current rewards: 60.93332, mean: 0.02528
[32m[0906 14-44-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11030, current rewards: 55.50251, mean: 0.02256
[32m[0906 14-44-09 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-44-09 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-44-09 @MBExp.py:227][0m Rewards obtained: [59.61863574745689], Lows: [16], Highs: [150], Total time: 3602.63937
[32m[0906 14-44-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-42 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-44-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11219, current rewards: -4.48480, mean: -0.44848
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11129, current rewards: 1.00572, mean: 0.01676
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11171, current rewards: 6.48443, mean: 0.05895
[32m[0906 14-45-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11160, current rewards: 11.94517, mean: 0.07466
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 17.43608, mean: 0.08303
[32m[0906 14-45-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11105, current rewards: 22.92020, mean: 0.08815
[32m[0906 14-45-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11048, current rewards: 28.41149, mean: 0.09165
[32m[0906 14-45-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11008, current rewards: 33.90015, mean: 0.09417
[32m[0906 14-45-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10985, current rewards: 39.38948, mean: 0.09607
[32m[0906 14-45-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10959, current rewards: 44.87836, mean: 0.09756
[32m[0906 14-45-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10941, current rewards: 50.36271, mean: 0.09875
[32m[0906 14-45-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10943, current rewards: 56.70713, mean: 0.10126
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10957, current rewards: 61.76724, mean: 0.10126
[32m[0906 14-45-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10968, current rewards: 67.18349, mean: 0.10179
[32m[0906 14-46-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10983, current rewards: 72.59465, mean: 0.10225
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10994, current rewards: 78.00877, mean: 0.10264
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11002, current rewards: 83.42421, mean: 0.10299
[32m[0906 14-46-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11014, current rewards: 88.84086, mean: 0.10330
[32m[0906 14-46-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11021, current rewards: 94.25295, mean: 0.10357
[32m[0906 14-46-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11028, current rewards: 99.51836, mean: 0.10366
[32m[0906 14-46-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11036, current rewards: 104.73343, mean: 0.10370
[32m[0906 14-46-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11040, current rewards: 110.17494, mean: 0.10394
[32m[0906 14-46-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11047, current rewards: 115.61946, mean: 0.10416
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11050, current rewards: 121.05697, mean: 0.10436
[32m[0906 14-46-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11054, current rewards: 114.15597, mean: 0.09434
[32m[0906 14-47-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11061, current rewards: 119.44562, mean: 0.09480
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11059, current rewards: 124.73354, mean: 0.09522
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11049, current rewards: 129.53970, mean: 0.09525
[32m[0906 14-47-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11042, current rewards: 134.97950, mean: 0.09573
[32m[0906 14-47-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11034, current rewards: 140.42095, mean: 0.09618
[32m[0906 14-47-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11029, current rewards: 145.86152, mean: 0.09660
[32m[0906 14-47-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11026, current rewards: 151.30430, mean: 0.09699
[32m[0906 14-47-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11018, current rewards: 156.75093, mean: 0.09736
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11019, current rewards: 156.85797, mean: 0.09449
[32m[0906 14-47-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11024, current rewards: 162.26998, mean: 0.09489
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11029, current rewards: 167.68232, mean: 0.09527
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11032, current rewards: 173.08958, mean: 0.09563
[32m[0906 14-48-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11038, current rewards: 178.49506, mean: 0.09597
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11040, current rewards: 183.90816, mean: 0.09629
[32m[0906 14-48-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11043, current rewards: 189.32306, mean: 0.09659
[32m[0906 14-48-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11044, current rewards: 194.73103, mean: 0.09688
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11039, current rewards: 200.14457, mean: 0.09716
[32m[0906 14-48-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11033, current rewards: 205.55401, mean: 0.09742
[32m[0906 14-48-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11029, current rewards: 211.14307, mean: 0.09775
[32m[0906 14-48-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11025, current rewards: 212.78298, mean: 0.09628
[32m[0906 14-48-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11019, current rewards: 211.73974, mean: 0.09369
[32m[0906 14-48-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11009, current rewards: 218.71603, mean: 0.09468
[32m[0906 14-49-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11004, current rewards: 225.69097, mean: 0.09563
[32m[0906 14-49-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11001, current rewards: 232.66821, mean: 0.09654
[32m[0906 14-49-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10997, current rewards: 239.64393, mean: 0.09742
[32m[0906 14-49-17 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-49-17 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-49-18 @MBExp.py:227][0m Rewards obtained: [245.22376601358337], Lows: [12], Highs: [10], Total time: 3878.191368
[32m[0906 14-49-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-52 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11271, current rewards: -4.25220, mean: -0.42522
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11253, current rewards: 0.59564, mean: 0.00993
[32m[0906 14-50-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11220, current rewards: 5.01433, mean: 0.04558
[32m[0906 14-50-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11196, current rewards: 9.82654, mean: 0.06142
[32m[0906 14-50-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11203, current rewards: 14.64054, mean: 0.06972
[32m[0906 14-50-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11125, current rewards: 19.45593, mean: 0.07483
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11066, current rewards: 24.27188, mean: 0.07830
[32m[0906 14-50-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11043, current rewards: 29.08380, mean: 0.08079
[32m[0906 14-50-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11010, current rewards: 33.89822, mean: 0.08268
[32m[0906 14-50-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10990, current rewards: 38.71110, mean: 0.08415
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10975, current rewards: 43.57519, mean: 0.08544
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10978, current rewards: 48.38722, mean: 0.08641
[32m[0906 14-51-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11005, current rewards: 53.19620, mean: 0.08721
[32m[0906 14-51-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11022, current rewards: 58.01022, mean: 0.08789
[32m[0906 14-51-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11039, current rewards: 52.39184, mean: 0.07379
[32m[0906 14-51-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11060, current rewards: 57.12740, mean: 0.07517
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11073, current rewards: 61.86179, mean: 0.07637
[32m[0906 14-51-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11085, current rewards: 66.59429, mean: 0.07744
[32m[0906 14-51-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11100, current rewards: 71.32922, mean: 0.07838
[32m[0906 14-51-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11109, current rewards: 76.06238, mean: 0.07923
[32m[0906 14-51-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11117, current rewards: 80.79601, mean: 0.08000
[32m[0906 14-51-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11127, current rewards: 85.52987, mean: 0.08069
[32m[0906 14-51-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11132, current rewards: 90.26669, mean: 0.08132
[32m[0906 14-52-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11137, current rewards: 94.99919, mean: 0.08190
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11142, current rewards: 99.73195, mean: 0.08242
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11143, current rewards: 101.18206, mean: 0.08030
[32m[0906 14-52-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11140, current rewards: 104.83356, mean: 0.08003
[32m[0906 14-52-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11127, current rewards: 110.39777, mean: 0.08117
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11115, current rewards: 115.96660, mean: 0.08225
[32m[0906 14-52-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11106, current rewards: 121.53189, mean: 0.08324
[32m[0906 14-52-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11098, current rewards: 127.09591, mean: 0.08417
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11090, current rewards: 132.65975, mean: 0.08504
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11084, current rewards: 138.22864, mean: 0.08586
[32m[0906 14-52-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11079, current rewards: 143.79102, mean: 0.08662
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11083, current rewards: 149.72155, mean: 0.08756
[32m[0906 14-53-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11088, current rewards: 155.74943, mean: 0.08849
[32m[0906 14-53-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11091, current rewards: 161.43360, mean: 0.08919
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11094, current rewards: 167.12205, mean: 0.08985
[32m[0906 14-53-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11098, current rewards: 160.12258, mean: 0.08383
[32m[0906 14-53-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11101, current rewards: 165.25904, mean: 0.08432
[32m[0906 14-53-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11101, current rewards: 170.21625, mean: 0.08468
[32m[0906 14-53-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11096, current rewards: 175.17346, mean: 0.08504
[32m[0906 14-53-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11088, current rewards: 180.13067, mean: 0.08537
[32m[0906 14-53-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11082, current rewards: 184.51427, mean: 0.08542
[32m[0906 14-53-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11078, current rewards: 188.75554, mean: 0.08541
[32m[0906 14-54-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11072, current rewards: 192.99682, mean: 0.08540
[32m[0906 14-54-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11061, current rewards: 152.76025, mean: 0.06613
[32m[0906 14-54-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11052, current rewards: 102.76025, mean: 0.04354
[32m[0906 14-54-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11047, current rewards: 52.76025, mean: 0.02189
[32m[0906 14-54-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11041, current rewards: 2.76025, mean: 0.00112
[32m[0906 14-54-29 @Agent.py:117][0m Average action selection time: 0.1104
[32m[0906 14-54-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-54-29 @MBExp.py:227][0m Rewards obtained: [-37.239752172071064], Lows: [11], Highs: [241], Total time: 4154.8733
[32m[0906 14-55-06 @MBExp.py:144][0m ####################################################################
[32m[0906 14-55-06 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11088, current rewards: -6.56832, mean: -0.65683
[32m[0906 14-55-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11157, current rewards: -0.41684, mean: -0.00695
[32m[0906 14-55-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11217, current rewards: 4.41313, mean: 0.04012
[32m[0906 14-55-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11208, current rewards: 9.81577, mean: 0.06135
[32m[0906 14-55-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11188, current rewards: 15.20933, mean: 0.07243
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11117, current rewards: 20.60666, mean: 0.07926
[32m[0906 14-55-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11066, current rewards: 26.00221, mean: 0.08388
[32m[0906 14-55-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11046, current rewards: 31.40650, mean: 0.08724
[32m[0906 14-55-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11027, current rewards: 36.80350, mean: 0.08976
[32m[0906 14-55-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11006, current rewards: 42.20069, mean: 0.09174
[32m[0906 14-56-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10992, current rewards: 47.70906, mean: 0.09355
[32m[0906 14-56-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10992, current rewards: 53.10461, mean: 0.09483
[32m[0906 14-56-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11008, current rewards: 58.50171, mean: 0.09590
[32m[0906 14-56-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11027, current rewards: 63.89104, mean: 0.09680
[32m[0906 14-56-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11038, current rewards: 69.28570, mean: 0.09759
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11045, current rewards: 64.31146, mean: 0.08462
[32m[0906 14-56-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11058, current rewards: 69.82435, mean: 0.08620
[32m[0906 14-56-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11065, current rewards: 75.33615, mean: 0.08760
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11072, current rewards: 81.47739, mean: 0.08954
[32m[0906 14-56-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11085, current rewards: 86.90750, mean: 0.09053
[32m[0906 14-56-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11088, current rewards: 92.33372, mean: 0.09142
[32m[0906 14-57-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11091, current rewards: 97.76147, mean: 0.09223
[32m[0906 14-57-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11097, current rewards: 103.18865, mean: 0.09296
[32m[0906 14-57-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11100, current rewards: 108.61938, mean: 0.09364
[32m[0906 14-57-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11105, current rewards: 114.04549, mean: 0.09425
[32m[0906 14-57-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11108, current rewards: 119.47252, mean: 0.09482
[32m[0906 14-57-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11109, current rewards: 124.64280, mean: 0.09515
[32m[0906 14-57-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11102, current rewards: 125.20705, mean: 0.09206
[32m[0906 14-57-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11090, current rewards: 130.61933, mean: 0.09264
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11080, current rewards: 136.03160, mean: 0.09317
[32m[0906 14-57-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11073, current rewards: 141.44683, mean: 0.09367
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11065, current rewards: 146.86359, mean: 0.09414
[32m[0906 14-58-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11056, current rewards: 152.27451, mean: 0.09458
[32m[0906 14-58-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11049, current rewards: 157.69068, mean: 0.09499
[32m[0906 14-58-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11054, current rewards: 163.10112, mean: 0.09538
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11058, current rewards: 168.30366, mean: 0.09563
[32m[0906 14-58-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11065, current rewards: 173.70624, mean: 0.09597
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11068, current rewards: 179.11451, mean: 0.09630
[32m[0906 14-58-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11071, current rewards: 184.51718, mean: 0.09661
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11076, current rewards: 189.91730, mean: 0.09690
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11074, current rewards: 195.31912, mean: 0.09717
[32m[0906 14-58-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11069, current rewards: 200.72050, mean: 0.09744
[32m[0906 14-59-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11064, current rewards: 206.12018, mean: 0.09769
[32m[0906 14-59-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11059, current rewards: 202.36778, mean: 0.09369
[32m[0906 14-59-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11053, current rewards: 207.80848, mean: 0.09403
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11049, current rewards: 213.24935, mean: 0.09436
[32m[0906 14-59-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11039, current rewards: 218.69043, mean: 0.09467
[32m[0906 14-59-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11028, current rewards: 224.13166, mean: 0.09497
[32m[0906 14-59-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11025, current rewards: 221.14160, mean: 0.09176
[32m[0906 14-59-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11023, current rewards: 224.58389, mean: 0.09129
[32m[0906 14-59-42 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-59-42 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-59-43 @MBExp.py:227][0m Rewards obtained: [228.94649108861393], Lows: [16], Highs: [10], Total time: 4431.096466
[32m[0906 15-00-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-00-22 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-00-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11091, current rewards: -4.50149, mean: -0.45015
[32m[0906 15-00-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11199, current rewards: 1.43954, mean: 0.02399
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11220, current rewards: 7.77059, mean: 0.07064
[32m[0906 15-00-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11203, current rewards: 14.07134, mean: 0.08795
[32m[0906 15-00-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11111, current rewards: 20.37043, mean: 0.09700
[32m[0906 15-00-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11066, current rewards: 26.66024, mean: 0.10254
[32m[0906 15-00-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11028, current rewards: 32.96390, mean: 0.10634
[32m[0906 15-01-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10999, current rewards: 39.26443, mean: 0.10907
[32m[0906 15-01-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10995, current rewards: 45.55721, mean: 0.11112
[32m[0906 15-01-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10975, current rewards: 51.85372, mean: 0.11273
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10966, current rewards: 58.17449, mean: 0.11407
[32m[0906 15-01-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10977, current rewards: 64.45849, mean: 0.11510
[32m[0906 15-01-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11003, current rewards: 70.74559, mean: 0.11598
[32m[0906 15-01-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11019, current rewards: 77.03571, mean: 0.11672
[32m[0906 15-01-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11031, current rewards: 72.41008, mean: 0.10199
[32m[0906 15-01-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11041, current rewards: 78.01167, mean: 0.10265
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11051, current rewards: 83.61779, mean: 0.10323
[32m[0906 15-01-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11056, current rewards: 89.22316, mean: 0.10375
[32m[0906 15-02-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11059, current rewards: 95.47986, mean: 0.10492
[32m[0906 15-02-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11066, current rewards: 100.93931, mean: 0.10515
[32m[0906 15-02-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11068, current rewards: 96.45439, mean: 0.09550
[32m[0906 15-02-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11072, current rewards: 102.27547, mean: 0.09649
[32m[0906 15-02-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11079, current rewards: 107.94580, mean: 0.09725
[32m[0906 15-02-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11081, current rewards: 113.61471, mean: 0.09794
[32m[0906 15-02-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11084, current rewards: 119.28690, mean: 0.09858
[32m[0906 15-02-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11089, current rewards: 120.50509, mean: 0.09564
[32m[0906 15-02-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11084, current rewards: 124.22053, mean: 0.09482
[32m[0906 15-02-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11072, current rewards: 129.37766, mean: 0.09513
[32m[0906 15-02-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11062, current rewards: 134.67218, mean: 0.09551
[32m[0906 15-03-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11051, current rewards: 139.96963, mean: 0.09587
[32m[0906 15-03-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11043, current rewards: 145.26936, mean: 0.09620
[32m[0906 15-03-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11036, current rewards: 150.56269, mean: 0.09651
[32m[0906 15-03-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11027, current rewards: 150.40458, mean: 0.09342
[32m[0906 15-03-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11018, current rewards: 156.13974, mean: 0.09406
[32m[0906 15-03-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11021, current rewards: 161.86858, mean: 0.09466
[32m[0906 15-03-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11025, current rewards: 167.98373, mean: 0.09545
[32m[0906 15-03-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11027, current rewards: 173.69152, mean: 0.09596
[32m[0906 15-03-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11030, current rewards: 179.39541, mean: 0.09645
[32m[0906 15-03-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11033, current rewards: 184.47836, mean: 0.09659
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11039, current rewards: 189.80895, mean: 0.09684
[32m[0906 15-04-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11037, current rewards: 195.13980, mean: 0.09708
[32m[0906 15-04-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11031, current rewards: 200.46917, mean: 0.09732
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11026, current rewards: 205.80005, mean: 0.09754
[32m[0906 15-04-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11020, current rewards: 211.15896, mean: 0.09776
[32m[0906 15-04-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11014, current rewards: 216.49191, mean: 0.09796
[32m[0906 15-04-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11011, current rewards: 221.82466, mean: 0.09815
[32m[0906 15-04-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11001, current rewards: 227.14823, mean: 0.09833
[32m[0906 15-04-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10989, current rewards: 232.46964, mean: 0.09850
[32m[0906 15-04-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10985, current rewards: 237.80128, mean: 0.09867
[32m[0906 15-04-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10981, current rewards: 243.13022, mean: 0.09883
[32m[0906 15-04-57 @Agent.py:117][0m Average action selection time: 0.1098
[32m[0906 15-04-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-04-57 @MBExp.py:227][0m Rewards obtained: [247.3997656917086], Lows: [10], Highs: [15], Total time: 4706.2422129999995
[32m[0906 15-05-39 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-39 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-05-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11150, current rewards: -4.59780, mean: -0.45978
[32m[0906 15-05-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11138, current rewards: 0.91134, mean: 0.01519
[32m[0906 15-05-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11169, current rewards: 7.08637, mean: 0.06442
[32m[0906 15-05-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11115, current rewards: 13.25830, mean: 0.08286
[32m[0906 15-06-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11037, current rewards: 19.42767, mean: 0.09251
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11002, current rewards: 25.60057, mean: 0.09846
[32m[0906 15-06-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10955, current rewards: 31.77189, mean: 0.10249
[32m[0906 15-06-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10933, current rewards: 37.94757, mean: 0.10541
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10923, current rewards: 44.11756, mean: 0.10760
[32m[0906 15-06-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10911, current rewards: 51.06907, mean: 0.11102
[32m[0906 15-06-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10897, current rewards: 57.83948, mean: 0.11341
[32m[0906 15-06-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10907, current rewards: 63.94723, mean: 0.11419
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10931, current rewards: 70.05445, mean: 0.11484
[32m[0906 15-06-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10954, current rewards: 76.17101, mean: 0.11541
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10976, current rewards: 81.71545, mean: 0.11509
[32m[0906 15-07-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10989, current rewards: 87.64223, mean: 0.11532
[32m[0906 15-07-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11003, current rewards: 93.56583, mean: 0.11551
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11021, current rewards: 99.49238, mean: 0.11569
[32m[0906 15-07-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11033, current rewards: 104.93437, mean: 0.11531
[32m[0906 15-07-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11046, current rewards: 111.04582, mean: 0.11567
[32m[0906 15-07-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11058, current rewards: 117.16419, mean: 0.11600
[32m[0906 15-07-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11066, current rewards: 123.28203, mean: 0.11630
[32m[0906 15-07-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11071, current rewards: 129.39229, mean: 0.11657
[32m[0906 15-07-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11076, current rewards: 135.50394, mean: 0.11681
[32m[0906 15-07-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11080, current rewards: 141.28721, mean: 0.11677
[32m[0906 15-07-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11084, current rewards: 147.32439, mean: 0.11692
[32m[0906 15-08-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11078, current rewards: 153.97680, mean: 0.11754
[32m[0906 15-08-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11068, current rewards: 159.92369, mean: 0.11759
[32m[0906 15-08-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11060, current rewards: 165.87917, mean: 0.11764
[32m[0906 15-08-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11051, current rewards: 171.83491, mean: 0.11770
[32m[0906 15-08-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11043, current rewards: 177.78883, mean: 0.11774
[32m[0906 15-08-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11036, current rewards: 183.74795, mean: 0.11779
[32m[0906 15-08-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11029, current rewards: 189.70456, mean: 0.11783
[32m[0906 15-08-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11022, current rewards: 195.66960, mean: 0.11787
[32m[0906 15-08-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11019, current rewards: 192.31718, mean: 0.11247
[32m[0906 15-08-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11023, current rewards: 198.12422, mean: 0.11257
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11026, current rewards: 204.47428, mean: 0.11297
[32m[0906 15-09-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11031, current rewards: 210.81918, mean: 0.11334
[32m[0906 15-09-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11034, current rewards: 217.16481, mean: 0.11370
[32m[0906 15-09-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11038, current rewards: 223.51565, mean: 0.11404
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11037, current rewards: 229.86337, mean: 0.11436
[32m[0906 15-09-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11031, current rewards: 229.62430, mean: 0.11147
[32m[0906 15-09-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11027, current rewards: 235.61915, mean: 0.11167
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11023, current rewards: 241.92213, mean: 0.11200
[32m[0906 15-09-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11018, current rewards: 247.90509, mean: 0.11217
[32m[0906 15-09-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11014, current rewards: 253.89755, mean: 0.11234
[32m[0906 15-09-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11005, current rewards: 259.87515, mean: 0.11250
[32m[0906 15-09-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10993, current rewards: 265.86768, mean: 0.11266
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10985, current rewards: 261.25667, mean: 0.10841
[32m[0906 15-10-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10982, current rewards: 267.12943, mean: 0.10859
[32m[0906 15-10-14 @Agent.py:117][0m Average action selection time: 0.1098
[32m[0906 15-10-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-10-14 @MBExp.py:227][0m Rewards obtained: [271.827438028642], Lows: [10], Highs: [12], Total time: 4981.454656999999
[32m[0906 15-10-58 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-58 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 15-10-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11127, current rewards: -6.88811, mean: -0.68881
[32m[0906 15-11-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11191, current rewards: -0.50922, mean: -0.00849
[32m[0906 15-11-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11205, current rewards: 4.85695, mean: 0.04415
[32m[0906 15-11-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11111, current rewards: 10.16661, mean: 0.06354
[32m[0906 15-11-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11036, current rewards: 15.47469, mean: 0.07369
[32m[0906 15-11-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11006, current rewards: 20.78023, mean: 0.07992
[32m[0906 15-11-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10961, current rewards: 26.09125, mean: 0.08417
[32m[0906 15-11-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10938, current rewards: 31.39707, mean: 0.08721
[32m[0906 15-11-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10928, current rewards: 36.70262, mean: 0.08952
[32m[0906 15-11-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10914, current rewards: 42.00931, mean: 0.09132
[32m[0906 15-11-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10906, current rewards: 47.08749, mean: 0.09233
[32m[0906 15-12-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10921, current rewards: 50.31340, mean: 0.08985
[32m[0906 15-12-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10946, current rewards: 45.34373, mean: 0.07433
[32m[0906 15-12-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10966, current rewards: 50.85948, mean: 0.07706
[32m[0906 15-12-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10986, current rewards: 56.37562, mean: 0.07940
[32m[0906 15-12-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11000, current rewards: 61.88752, mean: 0.08143
[32m[0906 15-12-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11016, current rewards: 67.40271, mean: 0.08321
[32m[0906 15-12-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11024, current rewards: 72.91954, mean: 0.08479
[32m[0906 15-12-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11034, current rewards: 77.97804, mean: 0.08569
[32m[0906 15-12-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11043, current rewards: 83.19491, mean: 0.08666
[32m[0906 15-12-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11048, current rewards: 88.40765, mean: 0.08753
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11052, current rewards: 93.62029, mean: 0.08832
[32m[0906 15-13-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11060, current rewards: 98.83367, mean: 0.08904
[32m[0906 15-13-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11063, current rewards: 104.04514, mean: 0.08969
[32m[0906 15-13-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11066, current rewards: 104.83924, mean: 0.08664
[32m[0906 15-13-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11074, current rewards: 109.74129, mean: 0.08710
[32m[0906 15-13-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11069, current rewards: 115.94890, mean: 0.08851
[32m[0906 15-13-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11059, current rewards: 122.03958, mean: 0.08973
[32m[0906 15-13-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11050, current rewards: 128.12609, mean: 0.09087
[32m[0906 15-13-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11041, current rewards: 134.20713, mean: 0.09192
[32m[0906 15-13-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11032, current rewards: 140.29145, mean: 0.09291
[32m[0906 15-13-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11026, current rewards: 146.37937, mean: 0.09383
[32m[0906 15-13-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11018, current rewards: 142.65775, mean: 0.08861
[32m[0906 15-14-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11011, current rewards: 149.60163, mean: 0.09012
[32m[0906 15-14-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11006, current rewards: 156.51014, mean: 0.09153
[32m[0906 15-14-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11009, current rewards: 163.55991, mean: 0.09293
[32m[0906 15-14-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11013, current rewards: 170.60775, mean: 0.09426
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11018, current rewards: 177.65223, mean: 0.09551
[32m[0906 15-14-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11022, current rewards: 184.69722, mean: 0.09670
[32m[0906 15-14-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11027, current rewards: 191.74314, mean: 0.09783
[32m[0906 15-14-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11025, current rewards: 198.79032, mean: 0.09890
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11019, current rewards: 205.83886, mean: 0.09992
[32m[0906 15-14-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11016, current rewards: 213.02769, mean: 0.10096
[32m[0906 15-14-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11011, current rewards: 213.28032, mean: 0.09874
[32m[0906 15-15-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11006, current rewards: 218.95734, mean: 0.09908
[32m[0906 15-15-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11002, current rewards: 224.62888, mean: 0.09939
[32m[0906 15-15-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10993, current rewards: 230.29914, mean: 0.09970
[32m[0906 15-15-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10981, current rewards: 235.97329, mean: 0.09999
[32m[0906 15-15-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10971, current rewards: 241.65014, mean: 0.10027
[32m[0906 15-15-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10967, current rewards: 236.70687, mean: 0.09622
[32m[0906 15-15-33 @Agent.py:117][0m Average action selection time: 0.1096
[32m[0906 15-15-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-15-33 @MBExp.py:227][0m Rewards obtained: [241.1248656198153], Lows: [17], Highs: [16], Total time: 5256.278138999999
[32m[0906 15-16-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-16-19 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 15-16-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11075, current rewards: -11.45228, mean: -1.14523
[32m[0906 15-16-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11195, current rewards: -4.78227, mean: -0.07970
[32m[0906 15-16-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11176, current rewards: 0.60981, mean: 0.00554
[32m[0906 15-16-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11062, current rewards: 6.00265, mean: 0.03752
[32m[0906 15-16-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11020, current rewards: 11.39371, mean: 0.05426
[32m[0906 15-16-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10978, current rewards: 16.78653, mean: 0.06456
[32m[0906 15-16-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10948, current rewards: 22.17989, mean: 0.07155
[32m[0906 15-16-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10940, current rewards: 27.57225, mean: 0.07659
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10920, current rewards: 32.96292, mean: 0.08040
[32m[0906 15-17-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10906, current rewards: 21.30489, mean: 0.04631
[32m[0906 15-17-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10904, current rewards: 29.60056, mean: 0.05804
[32m[0906 15-17-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10908, current rewards: 37.89331, mean: 0.06767
[32m[0906 15-17-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10931, current rewards: 46.19017, mean: 0.07572
[32m[0906 15-17-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10965, current rewards: 54.48955, mean: 0.08256
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10981, current rewards: 62.78123, mean: 0.08842
[32m[0906 15-17-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10991, current rewards: 71.07685, mean: 0.09352
[32m[0906 15-17-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11002, current rewards: 79.37662, mean: 0.09800
[32m[0906 15-17-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11014, current rewards: 80.49036, mean: 0.09359
[32m[0906 15-18-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11025, current rewards: 86.63109, mean: 0.09520
[32m[0906 15-18-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11032, current rewards: 92.76801, mean: 0.09663
[32m[0906 15-18-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11037, current rewards: 98.90629, mean: 0.09793
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11040, current rewards: 105.04628, mean: 0.09910
[32m[0906 15-18-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11046, current rewards: 111.18220, mean: 0.10016
[32m[0906 15-18-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11048, current rewards: 117.32007, mean: 0.10114
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11052, current rewards: 120.08186, mean: 0.09924
[32m[0906 15-18-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11055, current rewards: 123.38142, mean: 0.09792
[32m[0906 15-18-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11047, current rewards: 128.43660, mean: 0.09804
[32m[0906 15-18-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11039, current rewards: 133.87107, mean: 0.09843
[32m[0906 15-18-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11029, current rewards: 139.30452, mean: 0.09880
[32m[0906 15-19-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11020, current rewards: 144.73857, mean: 0.09914
[32m[0906 15-19-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11013, current rewards: 150.17118, mean: 0.09945
[32m[0906 15-19-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11005, current rewards: 145.12166, mean: 0.09303
[32m[0906 15-19-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10998, current rewards: 150.80487, mean: 0.09367
[32m[0906 15-19-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10992, current rewards: 156.48915, mean: 0.09427
[32m[0906 15-19-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10987, current rewards: 162.75045, mean: 0.09518
[32m[0906 15-19-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10987, current rewards: 168.57632, mean: 0.09578
[32m[0906 15-19-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10994, current rewards: 174.40703, mean: 0.09636
[32m[0906 15-19-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10998, current rewards: 180.23832, mean: 0.09690
[32m[0906 15-19-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11002, current rewards: 186.06847, mean: 0.09742
[32m[0906 15-19-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11007, current rewards: 186.02166, mean: 0.09491
[32m[0906 15-20-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11005, current rewards: 191.40491, mean: 0.09523
[32m[0906 15-20-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11000, current rewards: 196.78400, mean: 0.09553
[32m[0906 15-20-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10996, current rewards: 201.69684, mean: 0.09559
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10991, current rewards: 206.76859, mean: 0.09573
[32m[0906 15-20-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10986, current rewards: 212.22180, mean: 0.09603
[32m[0906 15-20-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10983, current rewards: 217.66771, mean: 0.09631
[32m[0906 15-20-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10975, current rewards: 223.12757, mean: 0.09659
[32m[0906 15-20-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10964, current rewards: 228.57404, mean: 0.09685
[32m[0906 15-20-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10954, current rewards: 234.02590, mean: 0.09711
[32m[0906 15-20-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10948, current rewards: 239.47376, mean: 0.09735
[32m[0906 15-20-54 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-20-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-20-54 @MBExp.py:227][0m Rewards obtained: [243.83433093309566], Lows: [17], Highs: [21], Total time: 5530.6220109999995
[32m[0906 15-21-42 @MBExp.py:144][0m ####################################################################
[32m[0906 15-21-42 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 15-21-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11251, current rewards: -4.03994, mean: -0.40399
[32m[0906 15-21-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11228, current rewards: 0.77884, mean: 0.01298
[32m[0906 15-21-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11085, current rewards: 5.87276, mean: 0.05339
[32m[0906 15-22-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11001, current rewards: 10.95577, mean: 0.06847
[32m[0906 15-22-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10939, current rewards: 16.04087, mean: 0.07639
[32m[0906 15-22-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10902, current rewards: 21.12489, mean: 0.08125
[32m[0906 15-22-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10888, current rewards: 26.20727, mean: 0.08454
[32m[0906 15-22-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10869, current rewards: 31.29354, mean: 0.08693
[32m[0906 15-22-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10857, current rewards: 36.37983, mean: 0.08873
[32m[0906 15-22-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10855, current rewards: 41.54313, mean: 0.09031
[32m[0906 15-22-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10848, current rewards: 46.67453, mean: 0.09152
[32m[0906 15-22-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10851, current rewards: 51.79848, mean: 0.09250
[32m[0906 15-22-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10885, current rewards: 56.92253, mean: 0.09332
[32m[0906 15-22-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10902, current rewards: 62.04628, mean: 0.09401
[32m[0906 15-23-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10921, current rewards: 63.68553, mean: 0.08970
[32m[0906 15-23-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10939, current rewards: 68.71236, mean: 0.09041
[32m[0906 15-23-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10950, current rewards: 73.73989, mean: 0.09104
[32m[0906 15-23-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10961, current rewards: 79.05447, mean: 0.09192
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10973, current rewards: 84.10205, mean: 0.09242
[32m[0906 15-23-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10981, current rewards: 89.12294, mean: 0.09284
[32m[0906 15-23-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10988, current rewards: 94.14973, mean: 0.09322
[32m[0906 15-23-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10999, current rewards: 99.17104, mean: 0.09356
[32m[0906 15-23-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11003, current rewards: 98.80094, mean: 0.08901
[32m[0906 15-23-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11008, current rewards: 103.71245, mean: 0.08941
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11015, current rewards: 108.62735, mean: 0.08977
[32m[0906 15-24-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11017, current rewards: 103.10840, mean: 0.08183
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11010, current rewards: 107.70873, mean: 0.08222
[32m[0906 15-24-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10999, current rewards: 112.75138, mean: 0.08291
[32m[0906 15-24-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10991, current rewards: 117.79226, mean: 0.08354
[32m[0906 15-24-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10985, current rewards: 122.83194, mean: 0.08413
[32m[0906 15-24-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10978, current rewards: 127.87183, mean: 0.08468
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10972, current rewards: 132.91148, mean: 0.08520
[32m[0906 15-24-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10967, current rewards: 137.95420, mean: 0.08569
[32m[0906 15-24-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10962, current rewards: 142.99194, mean: 0.08614
[32m[0906 15-24-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10956, current rewards: 148.41300, mean: 0.08679
[32m[0906 15-24-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10956, current rewards: 153.40466, mean: 0.08716
[32m[0906 15-25-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10961, current rewards: 152.57943, mean: 0.08430
[32m[0906 15-25-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10967, current rewards: 157.16858, mean: 0.08450
[32m[0906 15-25-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10973, current rewards: 161.75823, mean: 0.08469
[32m[0906 15-25-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10977, current rewards: 166.34858, mean: 0.08487
[32m[0906 15-25-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10975, current rewards: 170.93793, mean: 0.08504
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10972, current rewards: 175.52408, mean: 0.08521
[32m[0906 15-25-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10969, current rewards: 180.20429, mean: 0.08540
[32m[0906 15-25-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10965, current rewards: 184.85374, mean: 0.08558
[32m[0906 15-25-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10963, current rewards: 189.49909, mean: 0.08575
[32m[0906 15-25-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10960, current rewards: 194.14450, mean: 0.08590
[32m[0906 15-25-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10953, current rewards: 198.79276, mean: 0.08606
[32m[0906 15-26-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10945, current rewards: 203.43969, mean: 0.08620
[32m[0906 15-26-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10935, current rewards: 197.71712, mean: 0.08204
[32m[0906 15-26-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10928, current rewards: 202.63695, mean: 0.08237
[32m[0906 15-26-16 @Agent.py:117][0m Average action selection time: 0.1093
[32m[0906 15-26-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-26-16 @MBExp.py:227][0m Rewards obtained: [206.5778716445706], Lows: [10], Highs: [18], Total time: 5804.506665
[32m[0906 15-27-07 @MBExp.py:144][0m ####################################################################
[32m[0906 15-27-07 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 15-27-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10981, current rewards: -0.88330, mean: -0.08833
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11082, current rewards: 4.66957, mean: 0.07783
[32m[0906 15-27-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10964, current rewards: 10.17979, mean: 0.09254
[32m[0906 15-27-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10902, current rewards: 15.69151, mean: 0.09807
[32m[0906 15-27-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10885, current rewards: 21.20153, mean: 0.10096
[32m[0906 15-27-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10889, current rewards: 26.71406, mean: 0.10275
[32m[0906 15-27-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10871, current rewards: 32.22540, mean: 0.10395
[32m[0906 15-27-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10856, current rewards: 37.73693, mean: 0.10482
[32m[0906 15-27-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10848, current rewards: 37.58870, mean: 0.09168
[32m[0906 15-27-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10839, current rewards: 42.54462, mean: 0.09249
[32m[0906 15-28-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10828, current rewards: 48.09435, mean: 0.09430
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10839, current rewards: 53.64922, mean: 0.09580
[32m[0906 15-28-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10863, current rewards: 59.20092, mean: 0.09705
[32m[0906 15-28-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10885, current rewards: 64.75446, mean: 0.09811
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10906, current rewards: 70.30531, mean: 0.09902
[32m[0906 15-28-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10922, current rewards: 75.85413, mean: 0.09981
[32m[0906 15-28-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10937, current rewards: 81.40607, mean: 0.10050
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10954, current rewards: 87.75816, mean: 0.10204
[32m[0906 15-28-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10965, current rewards: 93.31415, mean: 0.10254
[32m[0906 15-28-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10976, current rewards: 98.86374, mean: 0.10298
[32m[0906 15-28-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10990, current rewards: 99.11904, mean: 0.09814
[32m[0906 15-29-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10999, current rewards: 104.59339, mean: 0.09867
[32m[0906 15-29-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11013, current rewards: 110.05483, mean: 0.09915
[32m[0906 15-29-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11022, current rewards: 115.51910, mean: 0.09959
[32m[0906 15-29-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11031, current rewards: 120.97434, mean: 0.09998
[32m[0906 15-29-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11039, current rewards: 126.71407, mean: 0.10057
[32m[0906 15-29-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11033, current rewards: 132.21049, mean: 0.10092
[32m[0906 15-29-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11026, current rewards: 141.28917, mean: 0.10389
[32m[0906 15-29-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11021, current rewards: 147.38551, mean: 0.10453
[32m[0906 15-29-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11012, current rewards: 153.47528, mean: 0.10512
[32m[0906 15-29-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11005, current rewards: 159.56645, mean: 0.10567
[32m[0906 15-29-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11000, current rewards: 165.65005, mean: 0.10619
[32m[0906 15-30-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10992, current rewards: 171.73233, mean: 0.10667
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10985, current rewards: 177.81497, mean: 0.10712
[32m[0906 15-30-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10979, current rewards: 180.74495, mean: 0.10570
[32m[0906 15-30-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10973, current rewards: 186.38433, mean: 0.10590
[32m[0906 15-30-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10977, current rewards: 192.03379, mean: 0.10610
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10983, current rewards: 197.68340, mean: 0.10628
[32m[0906 15-30-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10986, current rewards: 203.32672, mean: 0.10645
[32m[0906 15-30-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10989, current rewards: 208.98127, mean: 0.10662
[32m[0906 15-30-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10987, current rewards: 204.07043, mean: 0.10153
[32m[0906 15-30-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10981, current rewards: 209.68882, mean: 0.10179
[32m[0906 15-30-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10975, current rewards: 215.07665, mean: 0.10193
[32m[0906 15-31-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10971, current rewards: 220.76682, mean: 0.10221
[32m[0906 15-31-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10966, current rewards: 226.46375, mean: 0.10247
[32m[0906 15-31-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10962, current rewards: 232.15393, mean: 0.10272
[32m[0906 15-31-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10955, current rewards: 237.84423, mean: 0.10296
[32m[0906 15-31-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10945, current rewards: 237.18846, mean: 0.10050
[32m[0906 15-31-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10935, current rewards: 238.98629, mean: 0.09916
[32m[0906 15-31-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10926, current rewards: 244.49530, mean: 0.09939
[32m[0906 15-31-40 @Agent.py:117][0m Average action selection time: 0.1092
[32m[0906 15-31-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-31-40 @MBExp.py:227][0m Rewards obtained: [249.37893542600816], Lows: [13], Highs: [10], Total time: 6078.256300999999
[32m[0906 15-32-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-33 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11174, current rewards: -3.65139, mean: -0.36514
[32m[0906 15-32-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11089, current rewards: 5.20989, mean: 0.08683
[32m[0906 15-32-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10947, current rewards: 13.16484, mean: 0.11968
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10898, current rewards: 21.11084, mean: 0.13194
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10878, current rewards: 29.07526, mean: 0.13845
[32m[0906 15-33-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10856, current rewards: 37.03568, mean: 0.14244
[32m[0906 15-33-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10846, current rewards: 45.00040, mean: 0.14516
[32m[0906 15-33-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10841, current rewards: 45.51063, mean: 0.12642
[32m[0906 15-33-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10838, current rewards: 51.13586, mean: 0.12472
[32m[0906 15-33-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10840, current rewards: 57.04910, mean: 0.12402
[32m[0906 15-33-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10837, current rewards: 62.60884, mean: 0.12276
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10846, current rewards: 68.16551, mean: 0.12172
[32m[0906 15-33-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10876, current rewards: 73.72135, mean: 0.12085
[32m[0906 15-33-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10895, current rewards: 68.88089, mean: 0.10436
[32m[0906 15-33-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10915, current rewards: 74.34010, mean: 0.10470
[32m[0906 15-33-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10933, current rewards: 79.79396, mean: 0.10499
[32m[0906 15-34-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10948, current rewards: 85.24959, mean: 0.10525
[32m[0906 15-34-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10959, current rewards: 90.67762, mean: 0.10544
[32m[0906 15-34-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10973, current rewards: 96.13010, mean: 0.10564
[32m[0906 15-34-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10984, current rewards: 101.58181, mean: 0.10581
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10990, current rewards: 96.79948, mean: 0.09584
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11000, current rewards: 102.46624, mean: 0.09667
[32m[0906 15-34-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11008, current rewards: 108.14329, mean: 0.09743
[32m[0906 15-34-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11013, current rewards: 113.81296, mean: 0.09811
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11021, current rewards: 119.48590, mean: 0.09875
[32m[0906 15-34-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11026, current rewards: 124.50572, mean: 0.09881
[32m[0906 15-34-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11018, current rewards: 130.01608, mean: 0.09925
[32m[0906 15-35-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11012, current rewards: 135.53438, mean: 0.09966
[32m[0906 15-35-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11007, current rewards: 141.05144, mean: 0.10004
[32m[0906 15-35-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11000, current rewards: 146.56208, mean: 0.10038
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10993, current rewards: 152.08039, mean: 0.10072
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10985, current rewards: 157.59793, mean: 0.10102
[32m[0906 15-35-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10981, current rewards: 163.11357, mean: 0.10131
[32m[0906 15-35-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10976, current rewards: 169.03884, mean: 0.10183
[32m[0906 15-35-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10971, current rewards: 175.34764, mean: 0.10254
[32m[0906 15-35-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10966, current rewards: 170.69029, mean: 0.09698
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10967, current rewards: 176.86797, mean: 0.09772
[32m[0906 15-35-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10971, current rewards: 183.04566, mean: 0.09841
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10977, current rewards: 189.22334, mean: 0.09907
[32m[0906 15-36-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10982, current rewards: 195.40102, mean: 0.09969
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10978, current rewards: 181.35473, mean: 0.09023
[32m[0906 15-36-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10975, current rewards: 131.35473, mean: 0.06376
[32m[0906 15-36-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10972, current rewards: 81.35473, mean: 0.03856
[32m[0906 15-36-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10968, current rewards: 31.35473, mean: 0.01452
[32m[0906 15-36-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10965, current rewards: -18.64527, mean: -0.00844
[32m[0906 15-36-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10961, current rewards: -68.64527, mean: -0.03037
[32m[0906 15-36-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10955, current rewards: -118.64527, mean: -0.05136
[32m[0906 15-36-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10946, current rewards: -168.64527, mean: -0.07146
[32m[0906 15-36-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10935, current rewards: -218.64527, mean: -0.09072
[32m[0906 15-37-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10925, current rewards: -226.94596, mean: -0.09225
[32m[0906 15-37-07 @Agent.py:117][0m Average action selection time: 0.1092
[32m[0906 15-37-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-37-07 @MBExp.py:227][0m Rewards obtained: [-222.8472469964857], Lows: [16], Highs: [440], Total time: 6351.97571
[32m[0906 15-38-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-02 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 15-38-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11028, current rewards: -4.31571, mean: -0.43157
[32m[0906 15-38-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10839, current rewards: 1.08743, mean: 0.01812
[32m[0906 15-38-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10826, current rewards: 6.30935, mean: 0.05736
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10801, current rewards: 11.53401, mean: 0.07209
[32m[0906 15-38-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10799, current rewards: 16.75531, mean: 0.07979
[32m[0906 15-38-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10793, current rewards: 21.97944, mean: 0.08454
[32m[0906 15-38-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10784, current rewards: 17.02436, mean: 0.05492
[32m[0906 15-38-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10787, current rewards: 22.66630, mean: 0.06296
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10782, current rewards: 27.90310, mean: 0.06806
[32m[0906 15-38-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10786, current rewards: 33.76993, mean: 0.07341
[32m[0906 15-38-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10787, current rewards: 39.63420, mean: 0.07771
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10797, current rewards: 45.49095, mean: 0.08123
[32m[0906 15-39-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10824, current rewards: 51.35212, mean: 0.08418
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10850, current rewards: 57.21235, mean: 0.08669
[32m[0906 15-39-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10866, current rewards: 63.06809, mean: 0.08883
[32m[0906 15-39-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10883, current rewards: 68.92675, mean: 0.09069
[32m[0906 15-39-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10906, current rewards: 75.12319, mean: 0.09274
[32m[0906 15-39-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10916, current rewards: 76.35292, mean: 0.08878
[32m[0906 15-39-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10927, current rewards: 81.75175, mean: 0.08984
[32m[0906 15-39-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10940, current rewards: 87.08488, mean: 0.09071
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10948, current rewards: 92.42009, mean: 0.09151
[32m[0906 15-39-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10957, current rewards: 97.75591, mean: 0.09222
[32m[0906 15-40-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10966, current rewards: 103.08917, mean: 0.09287
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10974, current rewards: 108.42242, mean: 0.09347
[32m[0906 15-40-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10980, current rewards: 113.75750, mean: 0.09401
[32m[0906 15-40-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10987, current rewards: 108.22434, mean: 0.08589
[32m[0906 15-40-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10976, current rewards: 113.58735, mean: 0.08671
[32m[0906 15-40-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10968, current rewards: 118.95581, mean: 0.08747
[32m[0906 15-40-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10962, current rewards: 124.32102, mean: 0.08817
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10951, current rewards: 129.68839, mean: 0.08883
[32m[0906 15-40-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10942, current rewards: 135.05361, mean: 0.08944
[32m[0906 15-40-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10937, current rewards: 140.42051, mean: 0.09001
[32m[0906 15-40-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10930, current rewards: 137.11809, mean: 0.08517
[32m[0906 15-41-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10925, current rewards: 142.21091, mean: 0.08567
[32m[0906 15-41-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10921, current rewards: 146.90181, mean: 0.08591
[32m[0906 15-41-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10914, current rewards: 151.36056, mean: 0.08600
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10913, current rewards: 155.81930, mean: 0.08609
[32m[0906 15-41-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10917, current rewards: 160.27805, mean: 0.08617
[32m[0906 15-41-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10923, current rewards: 144.04247, mean: 0.07541
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10929, current rewards: 94.04247, mean: 0.04798
[32m[0906 15-41-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10924, current rewards: 44.04247, mean: 0.02191
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10920, current rewards: -5.95753, mean: -0.00289
[32m[0906 15-41-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10916, current rewards: -54.90924, mean: -0.02602
[32m[0906 15-41-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10912, current rewards: -104.90924, mean: -0.04857
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10907, current rewards: -154.90924, mean: -0.07009
[32m[0906 15-42-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10904, current rewards: -204.90924, mean: -0.09067
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10899, current rewards: -254.90924, mean: -0.11035
[32m[0906 15-42-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10889, current rewards: -304.90924, mean: -0.12920
[32m[0906 15-42-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10880, current rewards: -354.90924, mean: -0.14727
[32m[0906 15-42-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10870, current rewards: -404.90924, mean: -0.16460
[32m[0906 15-42-35 @Agent.py:117][0m Average action selection time: 0.1086
[32m[0906 15-42-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-42-35 @MBExp.py:227][0m Rewards obtained: [-437.53230896513213], Lows: [15], Highs: [611], Total time: 6624.239477
[32m[0906 15-43-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-43-32 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 15-43-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10632, current rewards: -3.04085, mean: -0.30408
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10756, current rewards: 3.58777, mean: 0.05980
[32m[0906 15-43-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10806, current rewards: 9.85011, mean: 0.08955
[32m[0906 15-43-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10803, current rewards: 16.10414, mean: 0.10065
[32m[0906 15-43-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10785, current rewards: 22.35946, mean: 0.10647
[32m[0906 15-44-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10790, current rewards: 28.61265, mean: 0.11005
[32m[0906 15-44-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10782, current rewards: 34.86392, mean: 0.11246
[32m[0906 15-44-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10773, current rewards: 41.12066, mean: 0.11422
[32m[0906 15-44-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10781, current rewards: 47.33347, mean: 0.11545
[32m[0906 15-44-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10779, current rewards: 49.35385, mean: 0.10729
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10774, current rewards: 48.99222, mean: 0.09606
[32m[0906 15-44-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10791, current rewards: 55.11091, mean: 0.09841
[32m[0906 15-44-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10820, current rewards: 61.23428, mean: 0.10038
[32m[0906 15-44-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10845, current rewards: 67.35062, mean: 0.10205
[32m[0906 15-44-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10872, current rewards: 73.47259, mean: 0.10348
[32m[0906 15-44-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10888, current rewards: 79.59458, mean: 0.10473
[32m[0906 15-45-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10904, current rewards: 85.65406, mean: 0.10575
[32m[0906 15-45-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10922, current rewards: 91.78525, mean: 0.10673
[32m[0906 15-45-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10931, current rewards: 97.91573, mean: 0.10760
[32m[0906 15-45-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10940, current rewards: 104.03827, mean: 0.10837
[32m[0906 15-45-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10953, current rewards: 110.16108, mean: 0.10907
[32m[0906 15-45-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10961, current rewards: 116.28735, mean: 0.10971
[32m[0906 15-45-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10967, current rewards: 122.41877, mean: 0.11029
[32m[0906 15-45-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10973, current rewards: 128.54179, mean: 0.11081
[32m[0906 15-45-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10978, current rewards: 134.33713, mean: 0.11102
[32m[0906 15-45-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10986, current rewards: 141.07502, mean: 0.11196
[32m[0906 15-45-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10977, current rewards: 146.90481, mean: 0.11214
[32m[0906 15-46-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10969, current rewards: 152.73641, mean: 0.11231
[32m[0906 15-46-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10964, current rewards: 158.56760, mean: 0.11246
[32m[0906 15-46-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10957, current rewards: 164.39609, mean: 0.11260
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10952, current rewards: 170.22920, mean: 0.11273
[32m[0906 15-46-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10949, current rewards: 176.05778, mean: 0.11286
[32m[0906 15-46-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10944, current rewards: 181.89127, mean: 0.11298
[32m[0906 15-46-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10939, current rewards: 187.32694, mean: 0.11285
[32m[0906 15-46-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10936, current rewards: 193.13110, mean: 0.11294
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10931, current rewards: 188.54785, mean: 0.10713
[32m[0906 15-46-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10927, current rewards: 194.38519, mean: 0.10740
[32m[0906 15-46-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10933, current rewards: 200.22003, mean: 0.10765
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10939, current rewards: 206.05110, mean: 0.10788
[32m[0906 15-47-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10945, current rewards: 211.88380, mean: 0.10810
[32m[0906 15-47-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10942, current rewards: 217.71350, mean: 0.10832
[32m[0906 15-47-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10939, current rewards: 223.86809, mean: 0.10867
[32m[0906 15-47-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10934, current rewards: 229.76958, mean: 0.10890
[32m[0906 15-47-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10934, current rewards: 235.66600, mean: 0.10910
[32m[0906 15-47-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10933, current rewards: 241.55788, mean: 0.10930
[32m[0906 15-47-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10930, current rewards: 247.45464, mean: 0.10949
[32m[0906 15-47-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10927, current rewards: 253.34873, mean: 0.10967
[32m[0906 15-47-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10918, current rewards: 253.60234, mean: 0.10746
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10908, current rewards: 259.60583, mean: 0.10772
[32m[0906 15-48-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10900, current rewards: 265.61047, mean: 0.10797
[32m[0906 15-48-05 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 15-48-05 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-48-05 @MBExp.py:227][0m Rewards obtained: [270.4112043373194], Lows: [10], Highs: [10], Total time: 6897.262674
[32m[0906 15-49-05 @MBExp.py:144][0m ####################################################################
[32m[0906 15-49-05 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 15-49-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10826, current rewards: -5.59977, mean: -0.55998
[32m[0906 15-49-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10772, current rewards: -0.48542, mean: -0.00809
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10796, current rewards: 4.63293, mean: 0.04212
[32m[0906 15-49-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10806, current rewards: 9.74969, mean: 0.06094
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10801, current rewards: 14.86609, mean: 0.07079
[32m[0906 15-49-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10811, current rewards: 19.98198, mean: 0.07685
[32m[0906 15-49-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10800, current rewards: 25.09906, mean: 0.08096
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10793, current rewards: 30.21422, mean: 0.08393
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10798, current rewards: 35.80391, mean: 0.08733
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10794, current rewards: 35.52405, mean: 0.07723
[32m[0906 15-50-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10794, current rewards: 40.80987, mean: 0.08002
[32m[0906 15-50-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10817, current rewards: 46.10181, mean: 0.08232
[32m[0906 15-50-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10841, current rewards: 51.39087, mean: 0.08425
[32m[0906 15-50-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10867, current rewards: 56.68418, mean: 0.08589
[32m[0906 15-50-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10891, current rewards: 61.97275, mean: 0.08729
[32m[0906 15-50-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10907, current rewards: 67.26316, mean: 0.08850
[32m[0906 15-50-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10924, current rewards: 72.47160, mean: 0.08947
[32m[0906 15-50-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10940, current rewards: 77.80521, mean: 0.09047
[32m[0906 15-50-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10952, current rewards: 77.98289, mean: 0.08570
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10964, current rewards: 83.10224, mean: 0.08656
[32m[0906 15-50-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10978, current rewards: 88.21935, mean: 0.08735
[32m[0906 15-51-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10989, current rewards: 93.34172, mean: 0.08806
[32m[0906 15-51-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10998, current rewards: 98.45859, mean: 0.08870
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11010, current rewards: 103.57908, mean: 0.08929
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11017, current rewards: 108.42629, mean: 0.08961
[32m[0906 15-51-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11020, current rewards: 103.79556, mean: 0.08238
[32m[0906 15-51-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11012, current rewards: 109.14288, mean: 0.08332
[32m[0906 15-51-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11006, current rewards: 114.49677, mean: 0.08419
[32m[0906 15-51-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11000, current rewards: 119.85433, mean: 0.08500
[32m[0906 15-51-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10992, current rewards: 125.20963, mean: 0.08576
[32m[0906 15-51-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10987, current rewards: 130.56527, mean: 0.08647
[32m[0906 15-51-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10982, current rewards: 135.91881, mean: 0.08713
[32m[0906 15-52-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10974, current rewards: 141.98465, mean: 0.08819
[32m[0906 15-52-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10967, current rewards: 147.75495, mean: 0.08901
[32m[0906 15-52-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10963, current rewards: 153.18361, mean: 0.08958
[32m[0906 15-52-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10958, current rewards: 158.61291, mean: 0.09012
[32m[0906 15-52-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10953, current rewards: 164.04438, mean: 0.09063
[32m[0906 15-52-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10957, current rewards: 162.70465, mean: 0.08748
[32m[0906 15-52-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10962, current rewards: 168.02015, mean: 0.08797
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10967, current rewards: 173.34417, mean: 0.08844
[32m[0906 15-52-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10964, current rewards: 178.66411, mean: 0.08889
[32m[0906 15-52-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10959, current rewards: 184.41024, mean: 0.08952
[32m[0906 15-52-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10955, current rewards: 189.75266, mean: 0.08993
[32m[0906 15-53-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10952, current rewards: 195.08997, mean: 0.09032
[32m[0906 15-53-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10949, current rewards: 200.43596, mean: 0.09070
[32m[0906 15-53-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10945, current rewards: 205.78181, mean: 0.09105
[32m[0906 15-53-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10943, current rewards: 200.67742, mean: 0.08687
[32m[0906 15-53-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10932, current rewards: 206.12399, mean: 0.08734
[32m[0906 15-53-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10921, current rewards: 211.57047, mean: 0.08779
[32m[0906 15-53-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10913, current rewards: 216.74606, mean: 0.08811
[32m[0906 15-53-38 @Agent.py:117][0m Average action selection time: 0.1091
[32m[0906 15-53-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-53-38 @MBExp.py:227][0m Rewards obtained: [221.07645529654084], Lows: [10], Highs: [22], Total time: 7170.62451
[32m[0906 15-54-40 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-40 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 15-54-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10776, current rewards: -5.59369, mean: -0.55937
[32m[0906 15-54-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10781, current rewards: -0.14037, mean: -0.00234
[32m[0906 15-54-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10830, current rewards: 5.33194, mean: 0.04847
[32m[0906 15-54-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10826, current rewards: 10.80506, mean: 0.06753
[32m[0906 15-55-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10821, current rewards: 16.27670, mean: 0.07751
[32m[0906 15-55-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10828, current rewards: 21.74814, mean: 0.08365
[32m[0906 15-55-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10817, current rewards: 27.22897, mean: 0.08784
[32m[0906 15-55-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10811, current rewards: 33.39753, mean: 0.09277
[32m[0906 15-55-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10815, current rewards: 38.73576, mean: 0.09448
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10813, current rewards: 44.08946, mean: 0.09585
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10812, current rewards: 49.43865, mean: 0.09694
[32m[0906 15-55-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10832, current rewards: 54.79352, mean: 0.09785
[32m[0906 15-55-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10862, current rewards: 60.14376, mean: 0.09860
[32m[0906 15-55-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10885, current rewards: 65.49493, mean: 0.09923
[32m[0906 15-55-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10909, current rewards: 65.99424, mean: 0.09295
[32m[0906 15-56-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10927, current rewards: 72.24761, mean: 0.09506
[32m[0906 15-56-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10943, current rewards: 78.34561, mean: 0.09672
[32m[0906 15-56-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10960, current rewards: 84.41301, mean: 0.09815
[32m[0906 15-56-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10971, current rewards: 90.50544, mean: 0.09946
[32m[0906 15-56-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10982, current rewards: 96.60267, mean: 0.10063
[32m[0906 15-56-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10993, current rewards: 102.70091, mean: 0.10168
[32m[0906 15-56-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11000, current rewards: 108.76015, mean: 0.10260
[32m[0906 15-56-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11010, current rewards: 104.04179, mean: 0.09373
[32m[0906 15-56-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11016, current rewards: 109.32462, mean: 0.09425
[32m[0906 15-56-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11025, current rewards: 114.60960, mean: 0.09472
[32m[0906 15-56-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11025, current rewards: 119.89193, mean: 0.09515
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11015, current rewards: 125.17528, mean: 0.09555
[32m[0906 15-57-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11007, current rewards: 130.45632, mean: 0.09592
[32m[0906 15-57-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11001, current rewards: 135.73853, mean: 0.09627
[32m[0906 15-57-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10994, current rewards: 141.01867, mean: 0.09659
[32m[0906 15-57-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10987, current rewards: 146.30215, mean: 0.09689
[32m[0906 15-57-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10989, current rewards: 151.50664, mean: 0.09712
[32m[0906 15-57-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10985, current rewards: 156.26990, mean: 0.09706
[32m[0906 15-57-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10977, current rewards: 161.34993, mean: 0.09720
[32m[0906 15-57-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10972, current rewards: 161.24188, mean: 0.09429
[32m[0906 15-57-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10965, current rewards: 166.72590, mean: 0.09473
[32m[0906 15-57-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10960, current rewards: 172.19850, mean: 0.09514
[32m[0906 15-58-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10959, current rewards: 177.67486, mean: 0.09552
[32m[0906 15-58-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10963, current rewards: 183.14917, mean: 0.09589
[32m[0906 15-58-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10966, current rewards: 188.62378, mean: 0.09624
[32m[0906 15-58-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10962, current rewards: 195.28723, mean: 0.09716
[32m[0906 15-58-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10956, current rewards: 200.96807, mean: 0.09756
[32m[0906 15-58-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10950, current rewards: 195.25038, mean: 0.09254
[32m[0906 15-58-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10947, current rewards: 200.59044, mean: 0.09287
[32m[0906 15-58-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10942, current rewards: 208.05063, mean: 0.09414
[32m[0906 15-58-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10937, current rewards: 215.51082, mean: 0.09536
[32m[0906 15-58-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10934, current rewards: 222.97101, mean: 0.09652
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10923, current rewards: 214.34235, mean: 0.09082
[32m[0906 15-59-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10911, current rewards: 164.34235, mean: 0.06819
[32m[0906 15-59-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10902, current rewards: 114.34235, mean: 0.04648
[32m[0906 15-59-13 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 15-59-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-59-13 @MBExp.py:227][0m Rewards obtained: [74.34234837627727], Lows: [12], Highs: [170], Total time: 7443.686465
[32m[0906 16-00-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-00-17 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 16-00-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10721, current rewards: -4.67594, mean: -0.46759
[32m[0906 16-00-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10764, current rewards: 0.46310, mean: 0.00772
[32m[0906 16-00-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10780, current rewards: 5.91035, mean: 0.05373
[32m[0906 16-00-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10764, current rewards: 11.35482, mean: 0.07097
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10752, current rewards: 16.80146, mean: 0.08001
[32m[0906 16-00-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10747, current rewards: 22.24889, mean: 0.08557
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10743, current rewards: 17.24095, mean: 0.05562
[32m[0906 16-00-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10745, current rewards: 22.71390, mean: 0.06309
[32m[0906 16-01-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10752, current rewards: 28.40598, mean: 0.06928
[32m[0906 16-01-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10747, current rewards: 34.10139, mean: 0.07413
[32m[0906 16-01-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10745, current rewards: 39.79441, mean: 0.07803
[32m[0906 16-01-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10769, current rewards: 45.48618, mean: 0.08123
[32m[0906 16-01-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10796, current rewards: 51.18573, mean: 0.08391
[32m[0906 16-01-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10827, current rewards: 56.88220, mean: 0.08619
[32m[0906 16-01-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10846, current rewards: 62.58265, mean: 0.08814
[32m[0906 16-01-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10863, current rewards: 59.00884, mean: 0.07764
[32m[0906 16-01-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10880, current rewards: 65.93381, mean: 0.08140
[32m[0906 16-01-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10891, current rewards: 71.88091, mean: 0.08358
[32m[0906 16-01-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10902, current rewards: 77.82714, mean: 0.08552
[32m[0906 16-02-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10917, current rewards: 83.77240, mean: 0.08726
[32m[0906 16-02-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10928, current rewards: 89.72007, mean: 0.08883
[32m[0906 16-02-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10937, current rewards: 95.66606, mean: 0.09025
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10947, current rewards: 101.61192, mean: 0.09154
[32m[0906 16-02-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10953, current rewards: 107.55637, mean: 0.09272
[32m[0906 16-02-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10960, current rewards: 113.22124, mean: 0.09357
[32m[0906 16-02-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10958, current rewards: 119.39825, mean: 0.09476
[32m[0906 16-02-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10948, current rewards: 125.58000, mean: 0.09586
[32m[0906 16-02-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10940, current rewards: 125.72897, mean: 0.09245
[32m[0906 16-02-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10933, current rewards: 131.10607, mean: 0.09298
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10926, current rewards: 136.48090, mean: 0.09348
[32m[0906 16-03-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10919, current rewards: 141.85329, mean: 0.09394
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10914, current rewards: 147.21493, mean: 0.09437
[32m[0906 16-03-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10910, current rewards: 153.58482, mean: 0.09539
[32m[0906 16-03-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10906, current rewards: 159.12246, mean: 0.09586
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10903, current rewards: 164.65381, mean: 0.09629
[32m[0906 16-03-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10900, current rewards: 159.82107, mean: 0.09081
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10897, current rewards: 165.41774, mean: 0.09139
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10896, current rewards: 171.01788, mean: 0.09195
[32m[0906 16-03-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10904, current rewards: 176.61410, mean: 0.09247
[32m[0906 16-03-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10910, current rewards: 182.21790, mean: 0.09297
[32m[0906 16-03-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10905, current rewards: 177.26833, mean: 0.08819
[32m[0906 16-04-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10903, current rewards: 182.43371, mean: 0.08856
[32m[0906 16-04-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10901, current rewards: 187.78362, mean: 0.08900
[32m[0906 16-04-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10897, current rewards: 193.13288, mean: 0.08941
[32m[0906 16-04-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10893, current rewards: 198.47455, mean: 0.08981
[32m[0906 16-04-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10891, current rewards: 203.82138, mean: 0.09019
[32m[0906 16-04-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10887, current rewards: 209.17016, mean: 0.09055
[32m[0906 16-04-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10878, current rewards: 214.51826, mean: 0.09090
[32m[0906 16-04-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10869, current rewards: 219.86345, mean: 0.09123
[32m[0906 16-04-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10860, current rewards: 225.21195, mean: 0.09155
[32m[0906 16-04-49 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 16-04-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-04-49 @MBExp.py:227][0m Rewards obtained: [223.94558131292314], Lows: [20], Highs: [15], Total time: 7715.754656
[32m[0906 16-05-55 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-55 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 16-05-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10733, current rewards: -5.43292, mean: -0.54329
[32m[0906 16-06-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10794, current rewards: -0.16209, mean: -0.00270
[32m[0906 16-06-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10786, current rewards: 5.09678, mean: 0.04633
[32m[0906 16-06-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10769, current rewards: 10.35746, mean: 0.06473
[32m[0906 16-06-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10772, current rewards: 15.61623, mean: 0.07436
[32m[0906 16-06-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10769, current rewards: 20.87688, mean: 0.08030
[32m[0906 16-06-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10770, current rewards: 26.13453, mean: 0.08430
[32m[0906 16-06-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10772, current rewards: 31.54297, mean: 0.08762
[32m[0906 16-06-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10767, current rewards: 36.91181, mean: 0.09003
[32m[0906 16-06-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10763, current rewards: 42.28363, mean: 0.09192
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10769, current rewards: 47.64775, mean: 0.09343
[32m[0906 16-06-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10795, current rewards: 53.01628, mean: 0.09467
[32m[0906 16-07-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10823, current rewards: 58.38064, mean: 0.09571
[32m[0906 16-07-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10845, current rewards: 54.37960, mean: 0.08239
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10860, current rewards: 60.26503, mean: 0.08488
[32m[0906 16-07-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10878, current rewards: 66.14946, mean: 0.08704
[32m[0906 16-07-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10892, current rewards: 72.03466, mean: 0.08893
[32m[0906 16-07-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10906, current rewards: 77.91878, mean: 0.09060
[32m[0906 16-07-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10927, current rewards: 83.80202, mean: 0.09209
[32m[0906 16-07-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10937, current rewards: 83.53402, mean: 0.08701
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10944, current rewards: 89.70363, mean: 0.08882
[32m[0906 16-07-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10955, current rewards: 95.26786, mean: 0.08988
[32m[0906 16-07-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10961, current rewards: 100.83616, mean: 0.09084
[32m[0906 16-08-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10965, current rewards: 106.78124, mean: 0.09205
[32m[0906 16-08-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10972, current rewards: 112.40820, mean: 0.09290
[32m[0906 16-08-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10964, current rewards: 118.04569, mean: 0.09369
[32m[0906 16-08-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10955, current rewards: 123.68509, mean: 0.09442
[32m[0906 16-08-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10950, current rewards: 129.31558, mean: 0.09508
[32m[0906 16-08-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10943, current rewards: 134.95094, mean: 0.09571
[32m[0906 16-08-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10934, current rewards: 129.99042, mean: 0.08903
[32m[0906 16-08-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10930, current rewards: 135.62379, mean: 0.08982
[32m[0906 16-08-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10922, current rewards: 141.82651, mean: 0.09091
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10916, current rewards: 147.31910, mean: 0.09150
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10912, current rewards: 152.80354, mean: 0.09205
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10905, current rewards: 158.29112, mean: 0.09257
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10901, current rewards: 163.77955, mean: 0.09306
[32m[0906 16-09-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10898, current rewards: 169.26669, mean: 0.09352
[32m[0906 16-09-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10893, current rewards: 169.37568, mean: 0.09106
[32m[0906 16-09-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10898, current rewards: 175.24728, mean: 0.09175
[32m[0906 16-09-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10901, current rewards: 181.30993, mean: 0.09251
[32m[0906 16-09-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10897, current rewards: 187.24323, mean: 0.09316
[32m[0906 16-09-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10894, current rewards: 193.18536, mean: 0.09378
[32m[0906 16-09-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10891, current rewards: 199.13017, mean: 0.09437
[32m[0906 16-09-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10887, current rewards: 205.07379, mean: 0.09494
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10885, current rewards: 211.02206, mean: 0.09549
[32m[0906 16-10-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10882, current rewards: 216.96487, mean: 0.09600
[32m[0906 16-10-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10879, current rewards: 212.51388, mean: 0.09200
[32m[0906 16-10-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10870, current rewards: 217.96139, mean: 0.09236
[32m[0906 16-10-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10861, current rewards: 223.28549, mean: 0.09265
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10852, current rewards: 228.76552, mean: 0.09299
[32m[0906 16-10-27 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-10-27 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-10-27 @MBExp.py:227][0m Rewards obtained: [233.15053853902447], Lows: [15], Highs: [17], Total time: 7987.551315
[32m[0906 16-11-35 @MBExp.py:144][0m ####################################################################
[32m[0906 16-11-35 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 16-11-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10692, current rewards: -0.33603, mean: -0.03360
[32m[0906 16-11-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10727, current rewards: 5.36684, mean: 0.08945
[32m[0906 16-11-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10751, current rewards: 11.20331, mean: 0.10185
[32m[0906 16-11-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10765, current rewards: 17.05018, mean: 0.10656
[32m[0906 16-11-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10762, current rewards: 22.88999, mean: 0.10900
[32m[0906 16-12-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10771, current rewards: 28.73029, mean: 0.11050
[32m[0906 16-12-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10760, current rewards: 34.57046, mean: 0.11152
[32m[0906 16-12-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10756, current rewards: 40.41153, mean: 0.11225
[32m[0906 16-12-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10760, current rewards: 46.25371, mean: 0.11281
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10756, current rewards: 52.09655, mean: 0.11325
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10749, current rewards: 57.93754, mean: 0.11360
[32m[0906 16-12-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10782, current rewards: 63.78625, mean: 0.11390
[32m[0906 16-12-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10811, current rewards: 69.62822, mean: 0.11414
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10833, current rewards: 75.47036, mean: 0.11435
[32m[0906 16-12-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10859, current rewards: 81.96949, mean: 0.11545
[32m[0906 16-12-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10874, current rewards: 87.79613, mean: 0.11552
[32m[0906 16-13-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10888, current rewards: 93.62294, mean: 0.11558
[32m[0906 16-13-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10903, current rewards: 93.56615, mean: 0.10880
[32m[0906 16-13-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10915, current rewards: 99.15381, mean: 0.10896
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10924, current rewards: 104.74755, mean: 0.10911
[32m[0906 16-13-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10939, current rewards: 110.34838, mean: 0.10926
[32m[0906 16-13-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10948, current rewards: 115.94467, mean: 0.10938
[32m[0906 16-13-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10957, current rewards: 121.53800, mean: 0.10949
[32m[0906 16-13-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10965, current rewards: 127.13724, mean: 0.10960
[32m[0906 16-13-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10972, current rewards: 132.71921, mean: 0.10969
[32m[0906 16-13-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10964, current rewards: 138.31037, mean: 0.10977
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10958, current rewards: 143.90560, mean: 0.10985
[32m[0906 16-14-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10949, current rewards: 144.17508, mean: 0.10601
[32m[0906 16-14-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10942, current rewards: 151.77629, mean: 0.10764
[32m[0906 16-14-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10934, current rewards: 159.35164, mean: 0.10914
[32m[0906 16-14-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10927, current rewards: 166.93098, mean: 0.11055
[32m[0906 16-14-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10922, current rewards: 174.51259, mean: 0.11187
[32m[0906 16-14-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10916, current rewards: 182.09095, mean: 0.11310
[32m[0906 16-14-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10911, current rewards: 189.65288, mean: 0.11425
[32m[0906 16-14-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10907, current rewards: 197.23739, mean: 0.11534
[32m[0906 16-14-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10902, current rewards: 204.82455, mean: 0.11638
[32m[0906 16-14-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10897, current rewards: 200.82732, mean: 0.11095
[32m[0906 16-14-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10895, current rewards: 206.35806, mean: 0.11095
[32m[0906 16-15-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10899, current rewards: 211.89522, mean: 0.11094
[32m[0906 16-15-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10901, current rewards: 217.43090, mean: 0.11093
[32m[0906 16-15-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10898, current rewards: 222.97010, mean: 0.11093
[32m[0906 16-15-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10894, current rewards: 228.51261, mean: 0.11093
[32m[0906 16-15-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10890, current rewards: 234.05226, mean: 0.11093
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10888, current rewards: 229.15789, mean: 0.10609
[32m[0906 16-15-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10885, current rewards: 234.99025, mean: 0.10633
[32m[0906 16-15-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10880, current rewards: 240.82192, mean: 0.10656
[32m[0906 16-15-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10879, current rewards: 246.23289, mean: 0.10659
[32m[0906 16-15-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10871, current rewards: 252.02683, mean: 0.10679
[32m[0906 16-15-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10862, current rewards: 257.79727, mean: 0.10697
[32m[0906 16-16-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10854, current rewards: 263.56334, mean: 0.10714
[32m[0906 16-16-07 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 16-16-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-16-07 @MBExp.py:227][0m Rewards obtained: [268.17703596913213], Lows: [10], Highs: [11], Total time: 8259.453803999999
[32m[0906 16-17-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-17-18 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 16-17-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10642, current rewards: -5.73849, mean: -0.57385
[32m[0906 16-17-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10815, current rewards: -0.42092, mean: -0.00702
[32m[0906 16-17-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10829, current rewards: 4.96145, mean: 0.04510
[32m[0906 16-17-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10863, current rewards: 10.34451, mean: 0.06465
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10872, current rewards: 15.78947, mean: 0.07519
[32m[0906 16-17-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10850, current rewards: 21.85706, mean: 0.08407
[32m[0906 16-17-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10829, current rewards: 27.24979, mean: 0.08790
[32m[0906 16-17-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10827, current rewards: 32.64056, mean: 0.09067
[32m[0906 16-18-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10820, current rewards: 27.64522, mean: 0.06743
[32m[0906 16-18-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10810, current rewards: 32.88804, mean: 0.07150
[32m[0906 16-18-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10809, current rewards: 38.13227, mean: 0.07477
[32m[0906 16-18-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10836, current rewards: 43.37538, mean: 0.07746
[32m[0906 16-18-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10862, current rewards: 48.62140, mean: 0.07971
[32m[0906 16-18-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10883, current rewards: 53.86275, mean: 0.08161
[32m[0906 16-18-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10902, current rewards: 59.10498, mean: 0.08325
[32m[0906 16-18-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10921, current rewards: 64.34846, mean: 0.08467
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10934, current rewards: 59.59693, mean: 0.07358
[32m[0906 16-18-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10943, current rewards: 67.89705, mean: 0.07895
[32m[0906 16-18-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10955, current rewards: 76.19717, mean: 0.08373
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10961, current rewards: 84.49729, mean: 0.08802
[32m[0906 16-19-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10966, current rewards: 74.14137, mean: 0.07341
[32m[0906 16-19-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10976, current rewards: 24.14137, mean: 0.02277
[32m[0906 16-19-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10980, current rewards: -25.85863, mean: -0.02330
[32m[0906 16-19-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10984, current rewards: -75.85863, mean: -0.06540
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10988, current rewards: -125.85863, mean: -0.10402
[32m[0906 16-19-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10980, current rewards: -175.85863, mean: -0.13957
[32m[0906 16-19-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10972, current rewards: -225.85863, mean: -0.17241
[32m[0906 16-19-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10966, current rewards: -275.85863, mean: -0.20284
[32m[0906 16-19-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10958, current rewards: -325.85863, mean: -0.23111
[32m[0906 16-19-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10951, current rewards: -375.85863, mean: -0.25744
[32m[0906 16-20-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10946, current rewards: -425.85863, mean: -0.28203
[32m[0906 16-20-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10938, current rewards: -475.85863, mean: -0.30504
[32m[0906 16-20-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10932, current rewards: -525.85863, mean: -0.32662
[32m[0906 16-20-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10927, current rewards: -575.85863, mean: -0.34690
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10923, current rewards: -625.85863, mean: -0.36600
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10917, current rewards: -675.85863, mean: -0.38401
[32m[0906 16-20-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10914, current rewards: -725.85863, mean: -0.40103
[32m[0906 16-20-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10909, current rewards: -772.53586, mean: -0.41534
[32m[0906 16-20-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10910, current rewards: -767.12132, mean: -0.40163
[32m[0906 16-20-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10913, current rewards: -761.90992, mean: -0.38873
[32m[0906 16-20-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10909, current rewards: -756.69714, mean: -0.37647
[32m[0906 16-21-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10906, current rewards: -751.48497, mean: -0.36480
[32m[0906 16-21-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10901, current rewards: -751.88438, mean: -0.35634
[32m[0906 16-21-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10897, current rewards: -746.70417, mean: -0.34570
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10895, current rewards: -741.52865, mean: -0.33553
[32m[0906 16-21-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10891, current rewards: -736.35575, mean: -0.32582
[32m[0906 16-21-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10888, current rewards: -731.42631, mean: -0.31663
[32m[0906 16-21-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10881, current rewards: -726.29956, mean: -0.30775
[32m[0906 16-21-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10871, current rewards: -731.88131, mean: -0.30369
[32m[0906 16-21-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10862, current rewards: -726.72570, mean: -0.29542
[32m[0906 16-21-50 @Agent.py:117][0m Average action selection time: 0.1086
[32m[0906 16-21-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-21-50 @MBExp.py:227][0m Rewards obtained: [-722.6017388372214], Lows: [15], Highs: [874], Total time: 8531.567680999999
[32m[0906 16-23-02 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-02 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 16-23-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10631, current rewards: -5.16685, mean: -0.51669
[32m[0906 16-23-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10717, current rewards: 0.16168, mean: 0.00269
[32m[0906 16-23-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10767, current rewards: 5.66141, mean: 0.05147
[32m[0906 16-23-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10744, current rewards: 11.16984, mean: 0.06981
[32m[0906 16-23-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10747, current rewards: 16.67471, mean: 0.07940
[32m[0906 16-23-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10760, current rewards: 16.69328, mean: 0.06420
[32m[0906 16-23-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10749, current rewards: 22.28387, mean: 0.07188
[32m[0906 16-23-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10746, current rewards: 27.87175, mean: 0.07742
[32m[0906 16-23-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10743, current rewards: 33.46358, mean: 0.08162
[32m[0906 16-23-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10741, current rewards: 39.05591, mean: 0.08490
[32m[0906 16-23-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10758, current rewards: 44.64442, mean: 0.08754
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10786, current rewards: 50.23643, mean: 0.08971
[32m[0906 16-24-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10812, current rewards: 55.82820, mean: 0.09152
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10839, current rewards: 61.42528, mean: 0.09307
[32m[0906 16-24-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10858, current rewards: 67.01837, mean: 0.09439
[32m[0906 16-24-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10873, current rewards: 72.61416, mean: 0.09554
[32m[0906 16-24-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10891, current rewards: 78.20770, mean: 0.09655
[32m[0906 16-24-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10906, current rewards: 50.80215, mean: 0.05907
[32m[0906 16-24-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10919, current rewards: 40.47225, mean: 0.04447
[32m[0906 16-24-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10933, current rewards: 46.89666, mean: 0.04885
[32m[0906 16-24-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10942, current rewards: 53.23014, mean: 0.05270
[32m[0906 16-24-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10950, current rewards: 59.64704, mean: 0.05627
[32m[0906 16-25-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10959, current rewards: 66.06276, mean: 0.05952
[32m[0906 16-25-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10965, current rewards: 61.27389, mean: 0.05282
[32m[0906 16-25-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10962, current rewards: 66.72838, mean: 0.05515
[32m[0906 16-25-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10957, current rewards: 72.19081, mean: 0.05729
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10948, current rewards: 77.64726, mean: 0.05927
[32m[0906 16-25-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10941, current rewards: 83.10695, mean: 0.06111
[32m[0906 16-25-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10936, current rewards: 88.82750, mean: 0.06300
[32m[0906 16-25-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10930, current rewards: 94.37649, mean: 0.06464
[32m[0906 16-25-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10924, current rewards: 99.91984, mean: 0.06617
[32m[0906 16-25-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10919, current rewards: 95.04879, mean: 0.06093
[32m[0906 16-25-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10914, current rewards: 100.65630, mean: 0.06252
[32m[0906 16-26-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10908, current rewards: 106.29195, mean: 0.06403
[32m[0906 16-26-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10905, current rewards: 111.92430, mean: 0.06545
[32m[0906 16-26-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10901, current rewards: 117.55921, mean: 0.06680
[32m[0906 16-26-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10898, current rewards: 122.99519, mean: 0.06795
[32m[0906 16-26-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10894, current rewards: 128.45674, mean: 0.06906
[32m[0906 16-26-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10895, current rewards: 134.13134, mean: 0.07023
[32m[0906 16-26-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10895, current rewards: 139.79883, mean: 0.07133
[32m[0906 16-26-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10891, current rewards: 145.47286, mean: 0.07237
[32m[0906 16-26-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10888, current rewards: 151.14362, mean: 0.07337
[32m[0906 16-26-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10885, current rewards: 156.82439, mean: 0.07432
[32m[0906 16-26-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10881, current rewards: 162.48974, mean: 0.07523
[32m[0906 16-27-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10878, current rewards: 157.88446, mean: 0.07144
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10876, current rewards: 165.54363, mean: 0.07325
[32m[0906 16-27-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10874, current rewards: 171.54020, mean: 0.07426
[32m[0906 16-27-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10866, current rewards: 177.53876, mean: 0.07523
[32m[0906 16-27-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10858, current rewards: 180.17201, mean: 0.07476
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10851, current rewards: 182.35643, mean: 0.07413
[32m[0906 16-27-34 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-27-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-27-34 @MBExp.py:227][0m Rewards obtained: [186.84147452266063], Lows: [37], Highs: [22], Total time: 8803.433880999999
[32m[0906 16-28-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-28-49 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 16-28-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10691, current rewards: -5.59386, mean: -0.55939
[32m[0906 16-28-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10748, current rewards: -0.37233, mean: -0.00621
[32m[0906 16-29-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10787, current rewards: 4.91965, mean: 0.04472
[32m[0906 16-29-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10778, current rewards: 10.55619, mean: 0.06598
[32m[0906 16-29-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10762, current rewards: 16.09203, mean: 0.07663
[32m[0906 16-29-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10768, current rewards: 21.43782, mean: 0.08245
[32m[0906 16-29-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10768, current rewards: 26.78509, mean: 0.08640
[32m[0906 16-29-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10766, current rewards: 32.13528, mean: 0.08926
[32m[0906 16-29-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10769, current rewards: 37.48238, mean: 0.09142
[32m[0906 16-29-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10767, current rewards: 32.43605, mean: 0.07051
[32m[0906 16-29-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10775, current rewards: 37.87887, mean: 0.07427
[32m[0906 16-29-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10813, current rewards: 43.31705, mean: 0.07735
[32m[0906 16-29-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10835, current rewards: 48.41080, mean: 0.07936
[32m[0906 16-30-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10854, current rewards: 53.84484, mean: 0.08158
[32m[0906 16-30-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10876, current rewards: 59.27852, mean: 0.08349
[32m[0906 16-30-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10888, current rewards: 64.70999, mean: 0.08514
[32m[0906 16-30-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10900, current rewards: 70.14115, mean: 0.08659
[32m[0906 16-30-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10914, current rewards: 75.57245, mean: 0.08787
[32m[0906 16-30-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10924, current rewards: 81.00272, mean: 0.08901
[32m[0906 16-30-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10934, current rewards: 86.43627, mean: 0.09004
[32m[0906 16-30-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10945, current rewards: 92.56475, mean: 0.09165
[32m[0906 16-30-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10950, current rewards: 98.00233, mean: 0.09246
[32m[0906 16-30-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10959, current rewards: 103.44460, mean: 0.09319
[32m[0906 16-30-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10962, current rewards: 103.73420, mean: 0.08943
[32m[0906 16-31-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10952, current rewards: 109.10094, mean: 0.09017
[32m[0906 16-31-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10945, current rewards: 114.46408, mean: 0.09084
[32m[0906 16-31-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10936, current rewards: 119.82762, mean: 0.09147
[32m[0906 16-31-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10929, current rewards: 125.18763, mean: 0.09205
[32m[0906 16-31-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10924, current rewards: 130.49332, mean: 0.09255
[32m[0906 16-31-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10917, current rewards: 135.85440, mean: 0.09305
[32m[0906 16-31-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10912, current rewards: 139.11001, mean: 0.09213
[32m[0906 16-31-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10908, current rewards: 136.31583, mean: 0.08738
[32m[0906 16-31-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10902, current rewards: 141.96131, mean: 0.08817
[32m[0906 16-31-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10899, current rewards: 147.60787, mean: 0.08892
[32m[0906 16-31-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10895, current rewards: 153.25633, mean: 0.08962
[32m[0906 16-32-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10890, current rewards: 158.90248, mean: 0.09029
[32m[0906 16-32-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10886, current rewards: 164.99517, mean: 0.09116
[32m[0906 16-32-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10883, current rewards: 170.90575, mean: 0.09188
[32m[0906 16-32-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10881, current rewards: 176.45511, mean: 0.09238
[32m[0906 16-32-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10880, current rewards: 158.07538, mean: 0.08065
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10879, current rewards: 166.06007, mean: 0.08262
[32m[0906 16-32-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10875, current rewards: 173.91961, mean: 0.08443
[32m[0906 16-32-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10871, current rewards: 181.77915, mean: 0.08615
[32m[0906 16-32-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10869, current rewards: 189.63868, mean: 0.08780
[32m[0906 16-32-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10867, current rewards: 160.46812, mean: 0.07261
[32m[0906 16-32-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10863, current rewards: 110.46812, mean: 0.04888
[32m[0906 16-33-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10863, current rewards: 60.46812, mean: 0.02618
[32m[0906 16-33-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10855, current rewards: 10.46812, mean: 0.00444
[32m[0906 16-33-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10846, current rewards: -39.53188, mean: -0.01640
[32m[0906 16-33-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10839, current rewards: -89.53188, mean: -0.03640
[32m[0906 16-33-21 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 16-33-21 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-33-21 @MBExp.py:227][0m Rewards obtained: [-109.74728699923851], Lows: [22], Highs: [315], Total time: 9074.969744999999
[32m[0906 16-34-38 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-38 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 16-34-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10839, current rewards: -6.51800, mean: -0.65180
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10787, current rewards: -0.96531, mean: -0.01609
[32m[0906 16-34-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10810, current rewards: 4.48329, mean: 0.04076
[32m[0906 16-34-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10784, current rewards: 10.02350, mean: 0.06265
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10777, current rewards: 15.46321, mean: 0.07363
[32m[0906 16-35-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10771, current rewards: 20.90294, mean: 0.08040
[32m[0906 16-35-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10759, current rewards: 26.34137, mean: 0.08497
[32m[0906 16-35-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10757, current rewards: 31.77784, mean: 0.08827
[32m[0906 16-35-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10763, current rewards: 37.22123, mean: 0.09078
[32m[0906 16-35-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10757, current rewards: 34.22593, mean: 0.07440
[32m[0906 16-35-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10776, current rewards: 38.19982, mean: 0.07490
[32m[0906 16-35-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10812, current rewards: 43.45152, mean: 0.07759
[32m[0906 16-35-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10840, current rewards: 49.01571, mean: 0.08035
[32m[0906 16-35-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10859, current rewards: 54.58608, mean: 0.08271
[32m[0906 16-35-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10880, current rewards: 60.15485, mean: 0.08473
[32m[0906 16-36-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10894, current rewards: 59.91210, mean: 0.07883
[32m[0906 16-36-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10909, current rewards: 64.94590, mean: 0.08018
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10923, current rewards: 69.98413, mean: 0.08138
[32m[0906 16-36-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10935, current rewards: 75.01594, mean: 0.08244
[32m[0906 16-36-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10946, current rewards: 79.86500, mean: 0.08319
[32m[0906 16-36-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10955, current rewards: 84.71267, mean: 0.08387
[32m[0906 16-36-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10962, current rewards: 89.60429, mean: 0.08453
[32m[0906 16-36-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10974, current rewards: 94.49957, mean: 0.08513
[32m[0906 16-36-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10977, current rewards: 99.39150, mean: 0.08568
[32m[0906 16-36-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10969, current rewards: 104.28317, mean: 0.08618
[32m[0906 16-36-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10963, current rewards: 109.17737, mean: 0.08665
[32m[0906 16-37-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10956, current rewards: 114.06728, mean: 0.08707
[32m[0906 16-37-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10949, current rewards: 118.95860, mean: 0.08747
[32m[0906 16-37-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10946, current rewards: 124.05029, mean: 0.08798
[32m[0906 16-37-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10940, current rewards: 122.70581, mean: 0.08405
[32m[0906 16-37-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10934, current rewards: 121.66792, mean: 0.08057
[32m[0906 16-37-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10932, current rewards: 126.98897, mean: 0.08140
[32m[0906 16-37-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10931, current rewards: 132.30820, mean: 0.08218
[32m[0906 16-37-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10926, current rewards: 137.63099, mean: 0.08291
[32m[0906 16-37-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10920, current rewards: 142.95267, mean: 0.08360
[32m[0906 16-37-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10915, current rewards: 148.27224, mean: 0.08425
[32m[0906 16-37-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10910, current rewards: 147.64064, mean: 0.08157
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10905, current rewards: 153.05768, mean: 0.08229
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10901, current rewards: 158.47431, mean: 0.08297
[32m[0906 16-38-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10897, current rewards: 163.89254, mean: 0.08362
[32m[0906 16-38-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10894, current rewards: 169.30926, mean: 0.08423
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10890, current rewards: 174.72248, mean: 0.08482
[32m[0906 16-38-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10890, current rewards: 180.13761, mean: 0.08537
[32m[0906 16-38-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10892, current rewards: 185.54979, mean: 0.08590
[32m[0906 16-38-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10891, current rewards: 190.53949, mean: 0.08622
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10889, current rewards: 195.97051, mean: 0.08671
[32m[0906 16-38-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10890, current rewards: 201.42094, mean: 0.08720
[32m[0906 16-38-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10885, current rewards: 206.67817, mean: 0.08758
[32m[0906 16-39-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10876, current rewards: 212.29120, mean: 0.08809
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10867, current rewards: 217.90585, mean: 0.08858
[32m[0906 16-39-10 @Agent.py:117][0m Average action selection time: 0.1086
[32m[0906 16-39-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-39-10 @MBExp.py:227][0m Rewards obtained: [222.39006455948527], Lows: [12], Highs: [16], Total time: 9347.190916999998
[32m[0906 16-40-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-40-30 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 16-40-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10706, current rewards: -12.93374, mean: -1.29337
[32m[0906 16-40-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10710, current rewards: -10.31783, mean: -0.17196
[32m[0906 16-40-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10733, current rewards: -4.37604, mean: -0.03978
[32m[0906 16-40-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10726, current rewards: 1.56636, mean: 0.00979
[32m[0906 16-40-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10734, current rewards: 7.51481, mean: 0.03578
[32m[0906 16-40-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10747, current rewards: 13.45310, mean: 0.05174
[32m[0906 16-41-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10737, current rewards: 19.40133, mean: 0.06258
[32m[0906 16-41-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10736, current rewards: 15.04601, mean: 0.04179
[32m[0906 16-41-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10740, current rewards: 20.73721, mean: 0.05058
[32m[0906 16-41-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10740, current rewards: 26.32627, mean: 0.05723
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10773, current rewards: 31.90849, mean: 0.06257
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10805, current rewards: 37.67533, mean: 0.06728
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10829, current rewards: 43.26816, mean: 0.07093
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10856, current rewards: 41.44583, mean: 0.06280
[32m[0906 16-41-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10877, current rewards: 47.66280, mean: 0.06713
[32m[0906 16-41-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10894, current rewards: 53.87013, mean: 0.07088
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10911, current rewards: 60.06910, mean: 0.07416
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10923, current rewards: 56.12362, mean: 0.06526
[32m[0906 16-42-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10935, current rewards: 61.83801, mean: 0.06795
[32m[0906 16-42-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10949, current rewards: 67.71873, mean: 0.07054
[32m[0906 16-42-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10960, current rewards: 73.42344, mean: 0.07270
[32m[0906 16-42-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10968, current rewards: 79.13025, mean: 0.07465
[32m[0906 16-42-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10977, current rewards: 84.83215, mean: 0.07643
[32m[0906 16-42-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10975, current rewards: 90.53499, mean: 0.07805
[32m[0906 16-42-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10967, current rewards: 96.23899, mean: 0.07954
[32m[0906 16-42-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10962, current rewards: 101.94025, mean: 0.08090
[32m[0906 16-42-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10953, current rewards: 107.64718, mean: 0.08217
[32m[0906 16-42-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10946, current rewards: 107.66472, mean: 0.07917
[32m[0906 16-43-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10941, current rewards: 113.52992, mean: 0.08052
[32m[0906 16-43-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10935, current rewards: 119.35990, mean: 0.08175
[32m[0906 16-43-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10927, current rewards: 125.19094, mean: 0.08291
[32m[0906 16-43-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10923, current rewards: 131.02751, mean: 0.08399
[32m[0906 16-43-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10917, current rewards: 126.27879, mean: 0.07843
[32m[0906 16-43-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10913, current rewards: 132.16886, mean: 0.07962
[32m[0906 16-43-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10908, current rewards: 138.06365, mean: 0.08074
[32m[0906 16-43-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10905, current rewards: 143.98459, mean: 0.08181
[32m[0906 16-43-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10899, current rewards: 150.80640, mean: 0.08332
[32m[0906 16-43-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10897, current rewards: 156.68395, mean: 0.08424
[32m[0906 16-43-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10892, current rewards: 162.56086, mean: 0.08511
[32m[0906 16-44-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10889, current rewards: 168.43741, mean: 0.08594
[32m[0906 16-44-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10886, current rewards: 174.31466, mean: 0.08672
[32m[0906 16-44-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10882, current rewards: 180.19003, mean: 0.08747
[32m[0906 16-44-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10879, current rewards: 186.06879, mean: 0.08818
[32m[0906 16-44-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10875, current rewards: 185.30285, mean: 0.08579
[32m[0906 16-44-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10873, current rewards: 190.59546, mean: 0.08624
[32m[0906 16-44-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10871, current rewards: 196.18316, mean: 0.08681
[32m[0906 16-44-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10868, current rewards: 201.76990, mean: 0.08735
[32m[0906 16-44-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10862, current rewards: 207.36312, mean: 0.08787
[32m[0906 16-44-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10854, current rewards: 212.95117, mean: 0.08836
[32m[0906 16-44-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10844, current rewards: 218.54129, mean: 0.08884
[32m[0906 16-45-02 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-45-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-45-02 @MBExp.py:227][0m Rewards obtained: [223.01487415284979], Lows: [23], Highs: [21], Total time: 9618.848201999997
[32m[0906 16-46-23 @MBExp.py:144][0m ####################################################################
[32m[0906 16-46-23 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 16-46-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10783, current rewards: -5.58902, mean: -0.55890
[32m[0906 16-46-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10821, current rewards: -0.11933, mean: -0.00199
[32m[0906 16-46-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10786, current rewards: 5.65730, mean: 0.05143
[32m[0906 16-46-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10772, current rewards: 12.20130, mean: 0.07626
[32m[0906 16-46-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10781, current rewards: 18.09241, mean: 0.08615
[32m[0906 16-46-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10786, current rewards: 23.98747, mean: 0.09226
[32m[0906 16-46-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10774, current rewards: 29.88077, mean: 0.09639
[32m[0906 16-47-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10779, current rewards: 35.76230, mean: 0.09934
[32m[0906 16-47-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10775, current rewards: 41.65200, mean: 0.10159
[32m[0906 16-47-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10767, current rewards: 47.54315, mean: 0.10335
[32m[0906 16-47-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10809, current rewards: 53.43270, mean: 0.10477
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10838, current rewards: 58.66355, mean: 0.10476
[32m[0906 16-47-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10867, current rewards: 64.50654, mean: 0.10575
[32m[0906 16-47-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10898, current rewards: 70.23102, mean: 0.10641
[32m[0906 16-47-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10917, current rewards: 75.95494, mean: 0.10698
[32m[0906 16-47-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10932, current rewards: 81.67621, mean: 0.10747
[32m[0906 16-47-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10943, current rewards: 87.40671, mean: 0.10791
[32m[0906 16-47-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10956, current rewards: 93.13393, mean: 0.10830
[32m[0906 16-48-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10968, current rewards: 98.86029, mean: 0.10864
[32m[0906 16-48-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10974, current rewards: 104.84358, mean: 0.10921
[32m[0906 16-48-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10980, current rewards: 110.72768, mean: 0.10963
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10988, current rewards: 116.51124, mean: 0.10992
[32m[0906 16-48-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10993, current rewards: 122.29763, mean: 0.11018
[32m[0906 16-48-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10983, current rewards: 128.07899, mean: 0.11041
[32m[0906 16-48-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10977, current rewards: 133.86194, mean: 0.11063
[32m[0906 16-48-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10968, current rewards: 139.64138, mean: 0.11083
[32m[0906 16-48-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10957, current rewards: 134.93098, mean: 0.10300
[32m[0906 16-48-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10951, current rewards: 140.47552, mean: 0.10329
[32m[0906 16-48-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10943, current rewards: 146.22291, mean: 0.10370
[32m[0906 16-49-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10936, current rewards: 151.74856, mean: 0.10394
[32m[0906 16-49-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10930, current rewards: 157.27409, mean: 0.10416
[32m[0906 16-49-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10923, current rewards: 162.79957, mean: 0.10436
[32m[0906 16-49-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10916, current rewards: 168.32492, mean: 0.10455
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10913, current rewards: 173.84351, mean: 0.10473
[32m[0906 16-49-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10907, current rewards: 179.36728, mean: 0.10489
[32m[0906 16-49-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10903, current rewards: 184.89540, mean: 0.10505
[32m[0906 16-49-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10899, current rewards: 190.14452, mean: 0.10505
[32m[0906 16-49-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10895, current rewards: 195.72769, mean: 0.10523
[32m[0906 16-49-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10888, current rewards: 190.74001, mean: 0.09986
[32m[0906 16-49-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10886, current rewards: 195.95567, mean: 0.09998
[32m[0906 16-50-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10883, current rewards: 201.23840, mean: 0.10012
[32m[0906 16-50-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10880, current rewards: 206.51623, mean: 0.10025
[32m[0906 16-50-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10879, current rewards: 211.79439, mean: 0.10038
[32m[0906 16-50-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10876, current rewards: 217.06819, mean: 0.10049
[32m[0906 16-50-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10874, current rewards: 222.34876, mean: 0.10061
[32m[0906 16-50-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10871, current rewards: 217.79737, mean: 0.09637
[32m[0906 16-50-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10869, current rewards: 223.49151, mean: 0.09675
[32m[0906 16-50-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10862, current rewards: 229.19229, mean: 0.09712
[32m[0906 16-50-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10854, current rewards: 234.89305, mean: 0.09747
[32m[0906 16-50-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10845, current rewards: 240.58843, mean: 0.09780
[32m[0906 16-50-55 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-50-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-50-55 @MBExp.py:227][0m Rewards obtained: [245.14562020373344], Lows: [15], Highs: [6], Total time: 9890.497858999997
[32m[0906 16-52-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-52-19 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 16-52-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10582, current rewards: -5.65908, mean: -0.56591
[32m[0906 16-52-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10715, current rewards: -0.20006, mean: -0.00333
[32m[0906 16-52-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10736, current rewards: 5.27331, mean: 0.04794
[32m[0906 16-52-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10747, current rewards: 10.74753, mean: 0.06717
[32m[0906 16-52-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10745, current rewards: 16.22416, mean: 0.07726
[32m[0906 16-52-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10743, current rewards: 21.69669, mean: 0.08345
[32m[0906 16-52-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10751, current rewards: 27.16937, mean: 0.08764
[32m[0906 16-52-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10751, current rewards: 32.64202, mean: 0.09067
[32m[0906 16-53-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10752, current rewards: 37.87934, mean: 0.09239
[32m[0906 16-53-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10759, current rewards: 43.53755, mean: 0.09465
[32m[0906 16-53-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10791, current rewards: 48.61164, mean: 0.09532
[32m[0906 16-53-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10827, current rewards: 54.16969, mean: 0.09673
[32m[0906 16-53-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10857, current rewards: 59.70664, mean: 0.09788
[32m[0906 16-53-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10882, current rewards: 65.24854, mean: 0.09886
[32m[0906 16-53-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10904, current rewards: 70.79495, mean: 0.09971
[32m[0906 16-53-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10918, current rewards: 67.90317, mean: 0.08935
[32m[0906 16-53-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10930, current rewards: 70.77539, mean: 0.08738
[32m[0906 16-53-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10943, current rewards: 75.81779, mean: 0.08816
[32m[0906 16-53-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10952, current rewards: 80.90248, mean: 0.08890
[32m[0906 16-54-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10959, current rewards: 86.58396, mean: 0.09019
[32m[0906 16-54-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10972, current rewards: 91.38679, mean: 0.09048
[32m[0906 16-54-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10979, current rewards: 96.18964, mean: 0.09074
[32m[0906 16-54-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10980, current rewards: 100.99249, mean: 0.09098
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10972, current rewards: 105.79545, mean: 0.09120
[32m[0906 16-54-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10964, current rewards: 110.59819, mean: 0.09140
[32m[0906 16-54-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10955, current rewards: 115.40093, mean: 0.09159
[32m[0906 16-54-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10949, current rewards: 112.44525, mean: 0.08584
[32m[0906 16-54-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10943, current rewards: 117.56812, mean: 0.08645
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10938, current rewards: 122.48911, mean: 0.08687
[32m[0906 16-54-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10936, current rewards: 127.41441, mean: 0.08727
[32m[0906 16-55-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10930, current rewards: 132.34283, mean: 0.08764
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10925, current rewards: 137.26068, mean: 0.08799
[32m[0906 16-55-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10920, current rewards: 142.18370, mean: 0.08831
[32m[0906 16-55-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10916, current rewards: 147.09775, mean: 0.08861
[32m[0906 16-55-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10913, current rewards: 152.01471, mean: 0.08890
[32m[0906 16-55-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10911, current rewards: 156.91592, mean: 0.08916
[32m[0906 16-55-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10906, current rewards: 162.37407, mean: 0.08971
[32m[0906 16-55-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10902, current rewards: 167.82897, mean: 0.09023
[32m[0906 16-55-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10893, current rewards: 173.29315, mean: 0.09073
[32m[0906 16-55-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10890, current rewards: 178.74288, mean: 0.09120
[32m[0906 16-55-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10886, current rewards: 184.19781, mean: 0.09164
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10884, current rewards: 179.40377, mean: 0.08709
[32m[0906 16-56-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10881, current rewards: 184.95772, mean: 0.08766
[32m[0906 16-56-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10878, current rewards: 190.19428, mean: 0.08805
[32m[0906 16-56-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10876, current rewards: 195.74151, mean: 0.08857
[32m[0906 16-56-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10873, current rewards: 201.27053, mean: 0.08906
[32m[0906 16-56-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10872, current rewards: 206.79961, mean: 0.08952
[32m[0906 16-56-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10866, current rewards: 212.32796, mean: 0.08997
[32m[0906 16-56-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10856, current rewards: 217.86379, mean: 0.09040
[32m[0906 16-56-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10848, current rewards: 223.39503, mean: 0.09081
[32m[0906 16-56-51 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-56-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-56-51 @MBExp.py:227][0m Rewards obtained: [227.81911453874037], Lows: [10], Highs: [13], Total time: 10162.257706999997
[32m[0906 16-58-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-58-17 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 16-58-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10728, current rewards: -4.71416, mean: -0.47142
[32m[0906 16-58-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10784, current rewards: 0.27176, mean: 0.00453
[32m[0906 16-58-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10778, current rewards: 5.87178, mean: 0.05338
[32m[0906 16-58-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10755, current rewards: 10.99954, mean: 0.06875
[32m[0906 16-58-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10755, current rewards: 16.12819, mean: 0.07680
[32m[0906 16-58-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10761, current rewards: 21.25038, mean: 0.08173
[32m[0906 16-58-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10751, current rewards: 26.37669, mean: 0.08509
[32m[0906 16-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10749, current rewards: 31.49958, mean: 0.08750
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10745, current rewards: 36.62896, mean: 0.08934
[32m[0906 16-59-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10750, current rewards: 41.75508, mean: 0.09077
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10789, current rewards: 47.10892, mean: 0.09237
[32m[0906 16-59-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10814, current rewards: 52.24182, mean: 0.09329
[32m[0906 16-59-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10838, current rewards: 47.03608, mean: 0.07711
[32m[0906 16-59-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10861, current rewards: 52.61414, mean: 0.07972
[32m[0906 16-59-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10878, current rewards: 58.04516, mean: 0.08175
[32m[0906 16-59-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10893, current rewards: 63.47677, mean: 0.08352
[32m[0906 16-59-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10911, current rewards: 68.90840, mean: 0.08507
[32m[0906 16-59-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10922, current rewards: 74.34128, mean: 0.08644
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10930, current rewards: 79.35089, mean: 0.08720
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10938, current rewards: 84.51415, mean: 0.08804
[32m[0906 17-00-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10945, current rewards: 86.54743, mean: 0.08569
[32m[0906 17-00-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10952, current rewards: 88.61520, mean: 0.08360
[32m[0906 17-00-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10946, current rewards: 93.76285, mean: 0.08447
[32m[0906 17-00-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10935, current rewards: 98.91575, mean: 0.08527
[32m[0906 17-00-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10928, current rewards: 104.06273, mean: 0.08600
[32m[0906 17-00-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10920, current rewards: 109.21507, mean: 0.08668
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10912, current rewards: 114.35926, mean: 0.08730
[32m[0906 17-00-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10907, current rewards: 119.69389, mean: 0.08801
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10898, current rewards: 124.84647, mean: 0.08854
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10892, current rewards: 129.99430, mean: 0.08904
[32m[0906 17-01-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10888, current rewards: 135.15096, mean: 0.08950
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10883, current rewards: 140.30623, mean: 0.08994
[32m[0906 17-01-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10877, current rewards: 145.45805, mean: 0.09035
[32m[0906 17-01-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10873, current rewards: 150.61578, mean: 0.09073
[32m[0906 17-01-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10869, current rewards: 155.76149, mean: 0.09109
[32m[0906 17-01-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10864, current rewards: 150.29481, mean: 0.08539
[32m[0906 17-01-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10863, current rewards: 155.44633, mean: 0.08588
[32m[0906 17-01-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10858, current rewards: 160.76353, mean: 0.08643
[32m[0906 17-01-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10846, current rewards: 166.08373, mean: 0.08695
[32m[0906 17-01-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10843, current rewards: 171.40281, mean: 0.08745
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10840, current rewards: 176.72183, mean: 0.08792
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10838, current rewards: 182.03725, mean: 0.08837
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10835, current rewards: 187.35264, mean: 0.08879
[32m[0906 17-02-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10832, current rewards: 192.66942, mean: 0.08920
[32m[0906 17-02-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10830, current rewards: 197.98509, mean: 0.08959
[32m[0906 17-02-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10828, current rewards: 203.30487, mean: 0.08996
[32m[0906 17-02-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10825, current rewards: 208.61988, mean: 0.09031
[32m[0906 17-02-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10821, current rewards: 213.93689, mean: 0.09065
[32m[0906 17-02-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10814, current rewards: 219.25421, mean: 0.09098
[32m[0906 17-02-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10805, current rewards: 218.95662, mean: 0.08901
[32m[0906 17-02-48 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 17-02-48 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-02-48 @MBExp.py:227][0m Rewards obtained: [223.13491334717125], Lows: [10], Highs: [16], Total time: 10432.936850999997
[32m[0906 17-04-16 @MBExp.py:144][0m ####################################################################
[32m[0906 17-04-16 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10610, current rewards: -5.49728, mean: -0.54973
[32m[0906 17-04-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10709, current rewards: 1.50969, mean: 0.02516
[32m[0906 17-04-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10745, current rewards: 7.28119, mean: 0.06619
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10748, current rewards: 13.04607, mean: 0.08154
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10743, current rewards: 18.80753, mean: 0.08956
[32m[0906 17-04-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10763, current rewards: 24.57063, mean: 0.09450
[32m[0906 17-04-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10762, current rewards: 24.76592, mean: 0.07989
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10760, current rewards: 30.26213, mean: 0.08406
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10772, current rewards: 35.75775, mean: 0.08721
[32m[0906 17-05-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10782, current rewards: 41.18921, mean: 0.08954
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10815, current rewards: 45.97533, mean: 0.09015
[32m[0906 17-05-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10858, current rewards: 51.29431, mean: 0.09160
[32m[0906 17-05-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10883, current rewards: 56.60692, mean: 0.09280
[32m[0906 17-05-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10906, current rewards: 61.92744, mean: 0.09383
[32m[0906 17-05-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10927, current rewards: 67.24592, mean: 0.09471
[32m[0906 17-05-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10939, current rewards: 72.56306, mean: 0.09548
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10948, current rewards: 77.88335, mean: 0.09615
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10963, current rewards: 83.20424, mean: 0.09675
[32m[0906 17-05-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10972, current rewards: 89.01827, mean: 0.09782
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10981, current rewards: 84.19992, mean: 0.08771
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10988, current rewards: 89.97675, mean: 0.08909
[32m[0906 17-06-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10988, current rewards: 95.74512, mean: 0.09033
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10981, current rewards: 101.51373, mean: 0.09145
[32m[0906 17-06-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10973, current rewards: 107.27903, mean: 0.09248
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10964, current rewards: 113.04578, mean: 0.09343
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10957, current rewards: 111.13943, mean: 0.08821
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10948, current rewards: 117.32884, mean: 0.08956
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10940, current rewards: 123.33571, mean: 0.09069
[32m[0906 17-06-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10934, current rewards: 129.34311, mean: 0.09173
[32m[0906 17-06-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10926, current rewards: 135.36170, mean: 0.09271
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10920, current rewards: 141.37896, mean: 0.09363
[32m[0906 17-07-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10916, current rewards: 147.38638, mean: 0.09448
[32m[0906 17-07-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10909, current rewards: 153.39410, mean: 0.09528
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10903, current rewards: 149.19426, mean: 0.08988
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10900, current rewards: 155.48415, mean: 0.09093
[32m[0906 17-07-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10896, current rewards: 161.13320, mean: 0.09155
[32m[0906 17-07-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10893, current rewards: 167.78575, mean: 0.09270
[32m[0906 17-07-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10889, current rewards: 174.43137, mean: 0.09378
[32m[0906 17-07-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10876, current rewards: 181.06816, mean: 0.09480
[32m[0906 17-07-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10872, current rewards: 187.72159, mean: 0.09578
[32m[0906 17-07-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10870, current rewards: 194.36416, mean: 0.09670
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10867, current rewards: 201.00572, mean: 0.09758
[32m[0906 17-08-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10863, current rewards: 207.65282, mean: 0.09841
[32m[0906 17-08-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10862, current rewards: 215.24498, mean: 0.09965
[32m[0906 17-08-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10858, current rewards: 221.71504, mean: 0.10032
[32m[0906 17-08-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10855, current rewards: 228.20271, mean: 0.10097
[32m[0906 17-08-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10854, current rewards: 234.70108, mean: 0.10160
[32m[0906 17-08-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10849, current rewards: 230.83773, mean: 0.09781
[32m[0906 17-08-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10840, current rewards: 236.36670, mean: 0.09808
[32m[0906 17-08-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10832, current rewards: 241.77892, mean: 0.09828
[32m[0906 17-08-47 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 17-08-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-08-47 @MBExp.py:227][0m Rewards obtained: [246.10437136584306], Lows: [16], Highs: [17], Total time: 10704.299070999998
[32m[0906 17-10-18 @MBExp.py:144][0m ####################################################################
[32m[0906 17-10-18 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 17-10-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10551, current rewards: 0.42332, mean: 0.04233
[32m[0906 17-10-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10702, current rewards: 7.72070, mean: 0.12868
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10756, current rewards: 10.91114, mean: 0.09919
[32m[0906 17-10-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10777, current rewards: 13.29879, mean: 0.08312
[32m[0906 17-10-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10772, current rewards: 15.68645, mean: 0.07470
[32m[0906 17-10-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10766, current rewards: 18.07411, mean: 0.06952
[32m[0906 17-10-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10777, current rewards: -0.49330, mean: -0.00159
[32m[0906 17-10-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10773, current rewards: -50.49330, mean: -0.14026
[32m[0906 17-11-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10769, current rewards: -100.49330, mean: -0.24511
[32m[0906 17-11-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10794, current rewards: -150.49330, mean: -0.32716
[32m[0906 17-11-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10826, current rewards: -200.49330, mean: -0.39312
[32m[0906 17-11-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10856, current rewards: -250.49330, mean: -0.44731
[32m[0906 17-11-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10880, current rewards: -300.49330, mean: -0.49261
[32m[0906 17-11-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10896, current rewards: -350.49330, mean: -0.53105
[32m[0906 17-11-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10918, current rewards: -400.49330, mean: -0.56408
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10930, current rewards: -450.49330, mean: -0.59275
[32m[0906 17-11-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10942, current rewards: -500.49330, mean: -0.61789
[32m[0906 17-11-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10956, current rewards: -550.49330, mean: -0.64011
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10965, current rewards: -600.49330, mean: -0.65988
[32m[0906 17-12-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10973, current rewards: -648.22517, mean: -0.67523
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10982, current rewards: -648.01370, mean: -0.64160
[32m[0906 17-12-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10976, current rewards: -641.96750, mean: -0.60563
[32m[0906 17-12-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10966, current rewards: -635.91727, mean: -0.57290
[32m[0906 17-12-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10960, current rewards: -629.87616, mean: -0.54300
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10952, current rewards: -623.83330, mean: -0.51556
[32m[0906 17-12-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10942, current rewards: -617.79005, mean: -0.49031
[32m[0906 17-12-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10937, current rewards: -611.17997, mean: -0.46655
[32m[0906 17-12-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10930, current rewards: -605.07389, mean: -0.44491
[32m[0906 17-12-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10921, current rewards: -599.45303, mean: -0.42514
[32m[0906 17-12-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10917, current rewards: -593.59919, mean: -0.40657
[32m[0906 17-13-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10910, current rewards: -587.73947, mean: -0.38923
[32m[0906 17-13-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10906, current rewards: -581.89109, mean: -0.37301
[32m[0906 17-13-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10903, current rewards: -576.03978, mean: -0.35779
[32m[0906 17-13-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10898, current rewards: -570.17636, mean: -0.34348
[32m[0906 17-13-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10893, current rewards: -564.32487, mean: -0.33001
[32m[0906 17-13-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10890, current rewards: -569.94377, mean: -0.32383
[32m[0906 17-13-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10887, current rewards: -564.55668, mean: -0.31191
[32m[0906 17-13-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10877, current rewards: -559.16738, mean: -0.30063
[32m[0906 17-13-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10866, current rewards: -553.78110, mean: -0.28994
[32m[0906 17-13-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10865, current rewards: -548.39693, mean: -0.27979
[32m[0906 17-13-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10863, current rewards: -543.00829, mean: -0.27015
[32m[0906 17-14-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10862, current rewards: -537.61956, mean: -0.26098
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10860, current rewards: -532.23111, mean: -0.25224
[32m[0906 17-14-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10857, current rewards: -526.84194, mean: -0.24391
[32m[0906 17-14-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10856, current rewards: -521.45311, mean: -0.23595
[32m[0906 17-14-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10855, current rewards: -516.06739, mean: -0.22835
[32m[0906 17-14-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10852, current rewards: -510.67798, mean: -0.22107
[32m[0906 17-14-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10849, current rewards: -505.29247, mean: -0.21411
[32m[0906 17-14-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10840, current rewards: -505.34227, mean: -0.20969
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10831, current rewards: -499.58449, mean: -0.20308
[32m[0906 17-14-49 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 17-14-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-14-50 @MBExp.py:227][0m Rewards obtained: [-495.1093721118959], Lows: [6], Highs: [678], Total time: 10975.681759999998
[32m[0906 17-16-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-16-23 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 17-16-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10606, current rewards: 1.51876, mean: 0.15188
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10725, current rewards: 6.58095, mean: 0.10968
[32m[0906 17-16-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10741, current rewards: 12.63950, mean: 0.11490
[32m[0906 17-16-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10764, current rewards: 18.29173, mean: 0.11432
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10777, current rewards: 23.94703, mean: 0.11403
[32m[0906 17-16-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10766, current rewards: 29.60195, mean: 0.11385
[32m[0906 17-16-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10779, current rewards: 35.25700, mean: 0.11373
[32m[0906 17-17-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10774, current rewards: 40.91049, mean: 0.11364
[32m[0906 17-17-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10769, current rewards: 46.56423, mean: 0.11357
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10797, current rewards: 47.20490, mean: 0.10262
[32m[0906 17-17-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10831, current rewards: 52.78301, mean: 0.10350
[32m[0906 17-17-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10859, current rewards: 58.65187, mean: 0.10474
[32m[0906 17-17-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10895, current rewards: 64.52750, mean: 0.10578
[32m[0906 17-17-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10919, current rewards: 70.40102, mean: 0.10667
[32m[0906 17-17-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10943, current rewards: 63.62775, mean: 0.08962
[32m[0906 17-17-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10956, current rewards: 70.44118, mean: 0.09269
[32m[0906 17-17-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10963, current rewards: 77.24633, mean: 0.09537
[32m[0906 17-17-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10972, current rewards: 84.05079, mean: 0.09773
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10979, current rewards: 90.97201, mean: 0.09997
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10984, current rewards: 97.77071, mean: 0.10184
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10989, current rewards: 104.57534, mean: 0.10354
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10976, current rewards: 111.36286, mean: 0.10506
[32m[0906 17-18-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10965, current rewards: 118.15932, mean: 0.10645
[32m[0906 17-18-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10958, current rewards: 124.95640, mean: 0.10772
[32m[0906 17-18-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10947, current rewards: 131.75031, mean: 0.10888
[32m[0906 17-18-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10937, current rewards: 138.54698, mean: 0.10996
[32m[0906 17-18-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10932, current rewards: 145.35030, mean: 0.11095
[32m[0906 17-18-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10924, current rewards: 152.14838, mean: 0.11187
[32m[0906 17-18-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10919, current rewards: 148.95949, mean: 0.10565
[32m[0906 17-19-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10913, current rewards: 154.78521, mean: 0.10602
[32m[0906 17-19-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10906, current rewards: 160.60902, mean: 0.10636
[32m[0906 17-19-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10901, current rewards: 166.43085, mean: 0.10669
[32m[0906 17-19-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10896, current rewards: 172.25607, mean: 0.10699
[32m[0906 17-19-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10892, current rewards: 178.08349, mean: 0.10728
[32m[0906 17-19-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10886, current rewards: 184.11917, mean: 0.10767
[32m[0906 17-19-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10882, current rewards: 189.96348, mean: 0.10793
[32m[0906 17-19-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10878, current rewards: 195.80137, mean: 0.10818
[32m[0906 17-19-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10865, current rewards: 201.63918, mean: 0.10841
[32m[0906 17-19-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10856, current rewards: 207.47967, mean: 0.10863
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10853, current rewards: 213.32003, mean: 0.10884
[32m[0906 17-20-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10850, current rewards: 219.16159, mean: 0.10904
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10848, current rewards: 224.99879, mean: 0.10922
[32m[0906 17-20-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10846, current rewards: 230.00406, mean: 0.10901
[32m[0906 17-20-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10843, current rewards: 235.08438, mean: 0.10884
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10842, current rewards: 240.15981, mean: 0.10867
[32m[0906 17-20-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10841, current rewards: 245.23453, mean: 0.10851
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10839, current rewards: 250.31420, mean: 0.10836
[32m[0906 17-20-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10836, current rewards: 245.05242, mean: 0.10384
[32m[0906 17-20-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10827, current rewards: 250.76164, mean: 0.10405
[32m[0906 17-20-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10817, current rewards: 256.20519, mean: 0.10415
[32m[0906 17-20-54 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 17-20-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-20-54 @MBExp.py:227][0m Rewards obtained: [260.72713238361433], Lows: [14], Highs: [10], Total time: 11246.692966999997
[32m[0906 17-22-29 @MBExp.py:144][0m ####################################################################
[32m[0906 17-22-29 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 17-22-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10649, current rewards: -4.39903, mean: -0.43990
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10735, current rewards: 0.88596, mean: 0.01477
[32m[0906 17-22-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10742, current rewards: 6.55723, mean: 0.05961
[32m[0906 17-22-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10758, current rewards: 12.22746, mean: 0.07642
[32m[0906 17-22-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10759, current rewards: 17.89254, mean: 0.08520
[32m[0906 17-22-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10764, current rewards: 23.55995, mean: 0.09062
[32m[0906 17-23-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10775, current rewards: 29.23133, mean: 0.09429
[32m[0906 17-23-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10765, current rewards: 34.90568, mean: 0.09696
[32m[0906 17-23-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10766, current rewards: 40.57365, mean: 0.09896
[32m[0906 17-23-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10806, current rewards: 47.59535, mean: 0.10347
[32m[0906 17-23-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10840, current rewards: 53.28187, mean: 0.10447
[32m[0906 17-23-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10871, current rewards: 53.30123, mean: 0.09518
[32m[0906 17-23-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10892, current rewards: 58.92654, mean: 0.09660
[32m[0906 17-23-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10910, current rewards: 64.55203, mean: 0.09781
[32m[0906 17-23-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10929, current rewards: 70.17502, mean: 0.09884
[32m[0906 17-23-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10940, current rewards: 75.79931, mean: 0.09974
[32m[0906 17-23-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10951, current rewards: 81.42846, mean: 0.10053
[32m[0906 17-24-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10966, current rewards: 87.03248, mean: 0.10120
[32m[0906 17-24-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10975, current rewards: 92.60070, mean: 0.10176
[32m[0906 17-24-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10981, current rewards: 97.97465, mean: 0.10206
[32m[0906 17-24-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10979, current rewards: 103.72740, mean: 0.10270
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10968, current rewards: 109.47414, mean: 0.10328
[32m[0906 17-24-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10958, current rewards: 115.22371, mean: 0.10381
[32m[0906 17-24-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10952, current rewards: 120.97071, mean: 0.10429
[32m[0906 17-24-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10943, current rewards: 117.57693, mean: 0.09717
[32m[0906 17-24-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10935, current rewards: 123.62220, mean: 0.09811
[32m[0906 17-24-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10931, current rewards: 130.99509, mean: 0.10000
[32m[0906 17-24-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10925, current rewards: 138.45528, mean: 0.10181
[32m[0906 17-25-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10917, current rewards: 97.64891, mean: 0.06925
[32m[0906 17-25-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10913, current rewards: 47.64891, mean: 0.03264
[32m[0906 17-25-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10907, current rewards: -2.35109, mean: -0.00156
[32m[0906 17-25-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10901, current rewards: -52.35109, mean: -0.03356
[32m[0906 17-25-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10897, current rewards: -102.35109, mean: -0.06357
[32m[0906 17-25-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10892, current rewards: -152.35109, mean: -0.09178
[32m[0906 17-25-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10886, current rewards: -202.35109, mean: -0.11833
[32m[0906 17-25-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10885, current rewards: -252.35109, mean: -0.14338
[32m[0906 17-25-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10877, current rewards: -302.35109, mean: -0.16704
[32m[0906 17-25-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10865, current rewards: -352.35109, mean: -0.18944
[32m[0906 17-25-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10856, current rewards: -402.35109, mean: -0.21066
[32m[0906 17-26-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10854, current rewards: -452.35109, mean: -0.23079
[32m[0906 17-26-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10853, current rewards: -502.35109, mean: -0.24993
[32m[0906 17-26-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10851, current rewards: -552.35109, mean: -0.26813
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10848, current rewards: -602.35109, mean: -0.28547
[32m[0906 17-26-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10844, current rewards: -652.35109, mean: -0.30201
[32m[0906 17-26-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10843, current rewards: -702.35109, mean: -0.31781
[32m[0906 17-26-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10839, current rewards: -752.35109, mean: -0.33290
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10838, current rewards: -802.35109, mean: -0.34734
[32m[0906 17-26-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10834, current rewards: -852.35109, mean: -0.36117
[32m[0906 17-26-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10826, current rewards: -902.35109, mean: -0.37442
[32m[0906 17-26-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10818, current rewards: -952.35109, mean: -0.38713
[32m[0906 17-27-00 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 17-27-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-27-00 @MBExp.py:227][0m Rewards obtained: [-992.3510872861813], Lows: [5], Highs: [1142], Total time: 11517.771086999997
[32m[0906 17-28-38 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-38 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 17-28-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10614, current rewards: 0.99855, mean: 0.09986
[32m[0906 17-28-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.12202, current rewards: 6.29832, mean: 0.10497
[32m[0906 17-28-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.13308, current rewards: 11.97516, mean: 0.10887
[32m[0906 17-29-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.13664, current rewards: 17.65278, mean: 0.11033
[32m[0906 17-29-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.13772, current rewards: 23.32831, mean: 0.11109
[32m[0906 17-29-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.13881, current rewards: 29.00001, mean: 0.11154
[32m[0906 17-29-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.13899, current rewards: 34.68182, mean: 0.11188
[32m[0906 17-29-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.13962, current rewards: 40.37279, mean: 0.11215
[32m[0906 17-29-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.14091, current rewards: 46.05521, mean: 0.11233
[32m[0906 17-29-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.14199, current rewards: 51.73036, mean: 0.11246
[32m[0906 17-29-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.14305, current rewards: 57.42632, mean: 0.11260
[32m[0906 17-29-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.14385, current rewards: 63.10819, mean: 0.11269
[32m[0906 17-30-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.14440, current rewards: 68.78468, mean: 0.11276
[32m[0906 17-30-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.14486, current rewards: 74.46755, mean: 0.11283
[32m[0906 17-30-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.14504, current rewards: 80.14791, mean: 0.11288
[32m[0906 17-30-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.14509, current rewards: 85.83467, mean: 0.11294
[32m[0906 17-30-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.14417, current rewards: 88.07499, mean: 0.10873
[32m[0906 17-30-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.14206, current rewards: 93.57892, mean: 0.10881
[32m[0906 17-30-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.14018, current rewards: 99.14328, mean: 0.10895
[32m[0906 17-30-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.13848, current rewards: 104.70152, mean: 0.10906
[32m[0906 17-30-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.13699, current rewards: 110.26351, mean: 0.10917
[32m[0906 17-31-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.13560, current rewards: 115.81928, mean: 0.10926
[32m[0906 17-31-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.13434, current rewards: 121.38056, mean: 0.10935
[32m[0906 17-31-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.13320, current rewards: 126.94117, mean: 0.10943
[32m[0906 17-31-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.13214, current rewards: 132.50378, mean: 0.10951
[32m[0906 17-31-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.13116, current rewards: 138.79731, mean: 0.11016
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.13029, current rewards: 144.50513, mean: 0.11031
[32m[0906 17-31-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.12946, current rewards: 150.05965, mean: 0.11034
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.12869, current rewards: 150.01868, mean: 0.10640
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.12798, current rewards: 155.59225, mean: 0.10657
[32m[0906 17-31-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.12732, current rewards: 161.16685, mean: 0.10673
[32m[0906 17-31-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.12657, current rewards: 166.74171, mean: 0.10689
[32m[0906 17-32-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.12589, current rewards: 172.31945, mean: 0.10703
[32m[0906 17-32-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.12527, current rewards: 177.89284, mean: 0.10716
[32m[0906 17-32-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.12476, current rewards: 178.41142, mean: 0.10433
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.12428, current rewards: 183.82674, mean: 0.10445
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.12382, current rewards: 189.24759, mean: 0.10456
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.12339, current rewards: 194.66672, mean: 0.10466
[32m[0906 17-32-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.12298, current rewards: 200.08840, mean: 0.10476
[32m[0906 17-32-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.12259, current rewards: 205.50648, mean: 0.10485
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.12221, current rewards: 210.92475, mean: 0.10494
[32m[0906 17-32-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.12188, current rewards: 216.34825, mean: 0.10502
[32m[0906 17-32-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.12152, current rewards: 221.69784, mean: 0.10507
[32m[0906 17-33-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.12111, current rewards: 227.11176, mean: 0.10514
[32m[0906 17-33-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.12073, current rewards: 232.52289, mean: 0.10521
[32m[0906 17-33-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.12036, current rewards: 240.95352, mean: 0.10662
[32m[0906 17-33-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.12000, current rewards: 246.37171, mean: 0.10665
[32m[0906 17-33-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11969, current rewards: 251.78245, mean: 0.10669
[32m[0906 17-33-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11937, current rewards: 257.19047, mean: 0.10672
[32m[0906 17-33-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11906, current rewards: 262.60455, mean: 0.10675
[32m[0906 17-33-36 @Agent.py:117][0m Average action selection time: 0.1189
[32m[0906 17-33-36 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-33-36 @MBExp.py:227][0m Rewards obtained: [266.58260629535], Lows: [0], Highs: [13], Total time: 11815.703019999997
[32m[0906 17-35-16 @MBExp.py:144][0m ####################################################################
[32m[0906 17-35-16 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 17-35-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11037, current rewards: -5.03454, mean: -0.50345
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10817, current rewards: 1.00849, mean: 0.01681
[32m[0906 17-35-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10806, current rewards: 6.68974, mean: 0.06082
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10795, current rewards: 12.37006, mean: 0.07731
[32m[0906 17-35-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10886, current rewards: 18.04360, mean: 0.08592
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10940, current rewards: 23.72393, mean: 0.09125
[32m[0906 17-35-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10979, current rewards: 29.40250, mean: 0.09485
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11003, current rewards: 35.08190, mean: 0.09745
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11029, current rewards: 33.65555, mean: 0.08209
[32m[0906 17-36-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11044, current rewards: 40.36321, mean: 0.08775
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11060, current rewards: 47.06353, mean: 0.09228
[32m[0906 17-36-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11067, current rewards: 53.76556, mean: 0.09601
[32m[0906 17-36-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11070, current rewards: 60.47299, mean: 0.09914
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11083, current rewards: 67.17808, mean: 0.10178
[32m[0906 17-36-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11065, current rewards: 73.88644, mean: 0.10407
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11048, current rewards: 80.58595, mean: 0.10603
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11034, current rewards: 86.99801, mean: 0.10740
[32m[0906 17-36-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11019, current rewards: 93.15124, mean: 0.10832
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11006, current rewards: 85.36461, mean: 0.09381
[32m[0906 17-37-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11001, current rewards: 91.00881, mean: 0.09480
[32m[0906 17-37-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10991, current rewards: 96.70468, mean: 0.09575
[32m[0906 17-37-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10981, current rewards: 102.40065, mean: 0.09660
[32m[0906 17-37-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10974, current rewards: 108.10191, mean: 0.09739
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10966, current rewards: 113.80627, mean: 0.09811
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10959, current rewards: 119.50468, mean: 0.09876
[32m[0906 17-37-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10959, current rewards: 125.20220, mean: 0.09937
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10955, current rewards: 130.90299, mean: 0.09993
[32m[0906 17-37-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10946, current rewards: 136.60868, mean: 0.10045
[32m[0906 17-37-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10941, current rewards: 142.30889, mean: 0.10093
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10934, current rewards: 148.00947, mean: 0.10138
[32m[0906 17-38-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10927, current rewards: 153.71268, mean: 0.10180
[32m[0906 17-38-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10911, current rewards: 159.42130, mean: 0.10219
[32m[0906 17-38-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10894, current rewards: 165.12282, mean: 0.10256
[32m[0906 17-38-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10883, current rewards: 162.28207, mean: 0.09776
[32m[0906 17-38-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10881, current rewards: 168.13229, mean: 0.09832
[32m[0906 17-38-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10877, current rewards: 174.02126, mean: 0.09888
[32m[0906 17-38-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10873, current rewards: 179.90543, mean: 0.09940
[32m[0906 17-38-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10872, current rewards: 185.78868, mean: 0.09989
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10869, current rewards: 191.67549, mean: 0.10035
[32m[0906 17-38-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10865, current rewards: 197.56270, mean: 0.10080
[32m[0906 17-38-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10862, current rewards: 203.44909, mean: 0.10122
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10859, current rewards: 208.85814, mean: 0.10139
[32m[0906 17-39-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10854, current rewards: 214.55424, mean: 0.10168
[32m[0906 17-39-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10845, current rewards: 220.37638, mean: 0.10203
[32m[0906 17-39-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10834, current rewards: 226.44192, mean: 0.10246
[32m[0906 17-39-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10825, current rewards: 232.50195, mean: 0.10288
[32m[0906 17-39-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10817, current rewards: 238.56401, mean: 0.10327
[32m[0906 17-39-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10808, current rewards: 244.62370, mean: 0.10365
[32m[0906 17-39-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10799, current rewards: 250.36805, mean: 0.10389
[32m[0906 17-39-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10791, current rewards: 256.50899, mean: 0.10427
[32m[0906 17-39-46 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 17-39-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-39-46 @MBExp.py:227][0m Rewards obtained: [262.00137738200056], Lows: [14], Highs: [12], Total time: 12086.181641999998
[32m[0906 17-41-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-41-28 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 17-41-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10666, current rewards: -6.63121, mean: -0.66312
[32m[0906 17-41-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10790, current rewards: -0.17126, mean: -0.00285
[32m[0906 17-41-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10775, current rewards: 5.43125, mean: 0.04937
[32m[0906 17-41-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10778, current rewards: 11.03726, mean: 0.06898
[32m[0906 17-41-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10877, current rewards: 16.63827, mean: 0.07923
[32m[0906 17-41-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10924, current rewards: 22.24044, mean: 0.08554
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10972, current rewards: 27.84345, mean: 0.08982
[32m[0906 17-42-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10989, current rewards: 33.44332, mean: 0.09290
[32m[0906 17-42-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11008, current rewards: 39.14775, mean: 0.09548
[32m[0906 17-42-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11030, current rewards: 44.80537, mean: 0.09740
[32m[0906 17-42-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11040, current rewards: 50.46270, mean: 0.09895
[32m[0906 17-42-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11045, current rewards: 56.12086, mean: 0.10022
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11059, current rewards: 56.84411, mean: 0.09319
[32m[0906 17-42-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11056, current rewards: 62.55938, mean: 0.09479
[32m[0906 17-42-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11034, current rewards: 68.28069, mean: 0.09617
[32m[0906 17-42-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11019, current rewards: 73.99657, mean: 0.09736
[32m[0906 17-42-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11001, current rewards: 80.44082, mean: 0.09931
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10987, current rewards: 86.72945, mean: 0.10085
[32m[0906 17-43-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10980, current rewards: 94.20311, mean: 0.10352
[32m[0906 17-43-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10969, current rewards: 101.66341, mean: 0.10590
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10956, current rewards: 109.12481, mean: 0.10804
[32m[0906 17-43-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10949, current rewards: 116.58093, mean: 0.10998
[32m[0906 17-43-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10940, current rewards: 113.31866, mean: 0.10209
[32m[0906 17-43-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10933, current rewards: 119.65221, mean: 0.10315
[32m[0906 17-43-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10927, current rewards: 125.78766, mean: 0.10396
[32m[0906 17-43-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10921, current rewards: 132.02478, mean: 0.10478
[32m[0906 17-43-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10914, current rewards: 138.22309, mean: 0.10551
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10909, current rewards: 144.42666, mean: 0.10620
[32m[0906 17-44-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10903, current rewards: 150.62485, mean: 0.10683
[32m[0906 17-44-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10898, current rewards: 151.20030, mean: 0.10356
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10888, current rewards: 142.83073, mean: 0.09459
[32m[0906 17-44-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10872, current rewards: 134.00372, mean: 0.08590
[32m[0906 17-44-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10857, current rewards: 122.96820, mean: 0.07638
[32m[0906 17-44-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10849, current rewards: 113.48972, mean: 0.06837
[32m[0906 17-44-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10846, current rewards: 101.34419, mean: 0.05927
[32m[0906 17-44-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10844, current rewards: 107.61169, mean: 0.06114
[32m[0906 17-44-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10844, current rewards: 113.87654, mean: 0.06292
[32m[0906 17-44-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10842, current rewards: 120.14238, mean: 0.06459
[32m[0906 17-44-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10841, current rewards: 126.40724, mean: 0.06618
[32m[0906 17-45-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10841, current rewards: 132.66999, mean: 0.06769
[32m[0906 17-45-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10838, current rewards: 138.93885, mean: 0.06912
[32m[0906 17-45-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10837, current rewards: 143.75194, mean: 0.06978
[32m[0906 17-45-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10835, current rewards: 148.19394, mean: 0.07023
[32m[0906 17-45-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10825, current rewards: 154.44380, mean: 0.07150
[32m[0906 17-45-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10817, current rewards: 160.69104, mean: 0.07271
[32m[0906 17-45-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10809, current rewards: 166.93938, mean: 0.07387
[32m[0906 17-45-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10800, current rewards: 173.19091, mean: 0.07497
[32m[0906 17-45-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10794, current rewards: 179.44129, mean: 0.07603
[32m[0906 17-45-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10788, current rewards: 185.69165, mean: 0.07705
[32m[0906 17-45-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10781, current rewards: 191.49744, mean: 0.07784
[32m[0906 17-45-58 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 17-45-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-45-58 @MBExp.py:227][0m Rewards obtained: [196.20399196104805], Lows: [48], Highs: [21], Total time: 12356.485410999998
[32m[0906 17-47-43 @MBExp.py:144][0m ####################################################################
[32m[0906 17-47-43 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 17-47-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10694, current rewards: -3.12965, mean: -0.31297
[32m[0906 17-47-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10791, current rewards: 3.19953, mean: 0.05333
[32m[0906 17-47-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10792, current rewards: 8.93145, mean: 0.08119
[32m[0906 17-48-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10785, current rewards: 14.66359, mean: 0.09165
[32m[0906 17-48-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10870, current rewards: 20.39927, mean: 0.09714
[32m[0906 17-48-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10937, current rewards: 26.13286, mean: 0.10051
[32m[0906 17-48-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10967, current rewards: 31.87453, mean: 0.10282
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10996, current rewards: 37.55688, mean: 0.10432
[32m[0906 17-48-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11015, current rewards: 43.18172, mean: 0.10532
[32m[0906 17-48-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11032, current rewards: 48.93239, mean: 0.10637
[32m[0906 17-48-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11046, current rewards: 54.68308, mean: 0.10722
[32m[0906 17-48-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11056, current rewards: 60.43344, mean: 0.10792
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11062, current rewards: 55.85759, mean: 0.09157
[32m[0906 17-48-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11061, current rewards: 61.56775, mean: 0.09328
[32m[0906 17-49-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11043, current rewards: 67.27379, mean: 0.09475
[32m[0906 17-49-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11026, current rewards: 72.98143, mean: 0.09603
[32m[0906 17-49-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11014, current rewards: 79.00602, mean: 0.09754
[32m[0906 17-49-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10999, current rewards: 84.70265, mean: 0.09849
[32m[0906 17-49-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10986, current rewards: 90.39479, mean: 0.09933
[32m[0906 17-49-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10979, current rewards: 85.86256, mean: 0.08944
[32m[0906 17-49-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10969, current rewards: 91.72692, mean: 0.09082
[32m[0906 17-49-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10960, current rewards: 97.62500, mean: 0.09210
[32m[0906 17-49-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10953, current rewards: 103.52381, mean: 0.09326
[32m[0906 17-49-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10946, current rewards: 109.42140, mean: 0.09433
[32m[0906 17-49-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10938, current rewards: 115.42043, mean: 0.09539
[32m[0906 17-50-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10933, current rewards: 121.33518, mean: 0.09630
[32m[0906 17-50-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10927, current rewards: 127.24990, mean: 0.09714
[32m[0906 17-50-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10921, current rewards: 133.16491, mean: 0.09792
[32m[0906 17-50-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10917, current rewards: 139.07986, mean: 0.09864
[32m[0906 17-50-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10912, current rewards: 144.99326, mean: 0.09931
[32m[0906 17-50-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10894, current rewards: 144.13298, mean: 0.09545
[32m[0906 17-50-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10880, current rewards: 150.05345, mean: 0.09619
[32m[0906 17-50-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10865, current rewards: 155.65930, mean: 0.09668
[32m[0906 17-50-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10851, current rewards: 161.56493, mean: 0.09733
[32m[0906 17-50-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10852, current rewards: 167.47470, mean: 0.09794
[32m[0906 17-50-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10849, current rewards: 173.37989, mean: 0.09851
[32m[0906 17-51-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10847, current rewards: 179.28288, mean: 0.09905
[32m[0906 17-51-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10847, current rewards: 185.18253, mean: 0.09956
[32m[0906 17-51-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10844, current rewards: 191.08858, mean: 0.10005
[32m[0906 17-51-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10843, current rewards: 197.00307, mean: 0.10051
[32m[0906 17-51-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10842, current rewards: 203.66980, mean: 0.10133
[32m[0906 17-51-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10840, current rewards: 209.57095, mean: 0.10173
[32m[0906 17-51-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10836, current rewards: 205.16709, mean: 0.09724
[32m[0906 17-51-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10829, current rewards: 211.03719, mean: 0.09770
[32m[0906 17-51-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10820, current rewards: 216.90347, mean: 0.09815
[32m[0906 17-51-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10811, current rewards: 222.77310, mean: 0.09857
[32m[0906 17-51-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10804, current rewards: 228.64224, mean: 0.09898
[32m[0906 17-51-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10796, current rewards: 224.83706, mean: 0.09527
[32m[0906 17-52-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10788, current rewards: 230.77091, mean: 0.09576
[32m[0906 17-52-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10782, current rewards: 236.45664, mean: 0.09612
[32m[0906 17-52-13 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 17-52-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-52-14 @MBExp.py:227][0m Rewards obtained: [241.31691904719588], Lows: [20], Highs: [12], Total time: 12626.755993999997
[32m[0906 17-54-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-54-01 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10663, current rewards: -5.73892, mean: -0.57389
[32m[0906 17-54-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10743, current rewards: -0.55999, mean: -0.00933
[32m[0906 17-54-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10793, current rewards: 4.89762, mean: 0.04452
[32m[0906 17-54-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10784, current rewards: 10.35188, mean: 0.06470
[32m[0906 17-54-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10872, current rewards: 15.80662, mean: 0.07527
[32m[0906 17-54-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10944, current rewards: 21.25366, mean: 0.08174
[32m[0906 17-54-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10979, current rewards: 26.71015, mean: 0.08616
[32m[0906 17-54-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11006, current rewards: 32.16842, mean: 0.08936
[32m[0906 17-54-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11038, current rewards: 37.62116, mean: 0.09176
[32m[0906 17-54-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11050, current rewards: 43.06966, mean: 0.09363
[32m[0906 17-54-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11061, current rewards: 48.52194, mean: 0.09514
[32m[0906 17-55-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11073, current rewards: 53.97423, mean: 0.09638
[32m[0906 17-55-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11081, current rewards: 48.90290, mean: 0.08017
[32m[0906 17-55-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11063, current rewards: 54.74624, mean: 0.08295
[32m[0906 17-55-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11048, current rewards: 60.73043, mean: 0.08554
[32m[0906 17-55-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11029, current rewards: 66.75202, mean: 0.08783
[32m[0906 17-55-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11012, current rewards: 72.74712, mean: 0.08981
[32m[0906 17-55-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11002, current rewards: 78.73947, mean: 0.09156
[32m[0906 17-55-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10988, current rewards: 84.72998, mean: 0.09311
[32m[0906 17-55-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10975, current rewards: 90.72200, mean: 0.09450
[32m[0906 17-55-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10966, current rewards: 96.71899, mean: 0.09576
[32m[0906 17-55-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10955, current rewards: 86.44261, mean: 0.08155
[32m[0906 17-56-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10947, current rewards: 91.80590, mean: 0.08271
[32m[0906 17-56-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10943, current rewards: 97.69570, mean: 0.08422
[32m[0906 17-56-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10934, current rewards: 103.38416, mean: 0.08544
[32m[0906 17-56-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10928, current rewards: 108.88026, mean: 0.08641
[32m[0906 17-56-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10927, current rewards: 114.38240, mean: 0.08731
[32m[0906 17-56-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10921, current rewards: 119.87270, mean: 0.08814
[32m[0906 17-56-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10916, current rewards: 125.36891, mean: 0.08891
[32m[0906 17-56-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10907, current rewards: 130.86435, mean: 0.08963
[32m[0906 17-56-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10891, current rewards: 136.36304, mean: 0.09031
[32m[0906 17-56-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10874, current rewards: 141.86337, mean: 0.09094
[32m[0906 17-56-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10862, current rewards: 147.55353, mean: 0.09165
[32m[0906 17-57-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10848, current rewards: 143.06236, mean: 0.08618
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10846, current rewards: 148.76664, mean: 0.08700
[32m[0906 17-57-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10847, current rewards: 154.47526, mean: 0.08777
[32m[0906 17-57-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10845, current rewards: 160.18424, mean: 0.08850
[32m[0906 17-57-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10844, current rewards: 165.88883, mean: 0.08919
[32m[0906 17-57-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10844, current rewards: 171.59436, mean: 0.08984
[32m[0906 17-57-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10846, current rewards: 177.30184, mean: 0.09046
[32m[0906 17-57-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10847, current rewards: 182.81002, mean: 0.09095
[32m[0906 17-57-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10845, current rewards: 186.34737, mean: 0.09046
[32m[0906 17-57-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10840, current rewards: 188.42084, mean: 0.08930
[32m[0906 17-57-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10830, current rewards: 193.95563, mean: 0.08979
[32m[0906 17-58-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10821, current rewards: 199.50125, mean: 0.09027
[32m[0906 17-58-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10812, current rewards: 205.03876, mean: 0.09073
[32m[0906 17-58-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10803, current rewards: 210.58047, mean: 0.09116
[32m[0906 17-58-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10794, current rewards: 216.12092, mean: 0.09158
[32m[0906 17-58-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10785, current rewards: 222.03553, mean: 0.09213
[32m[0906 17-58-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10778, current rewards: 217.09093, mean: 0.08825
[32m[0906 17-58-31 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 17-58-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-58-31 @MBExp.py:227][0m Rewards obtained: [221.55269995496073], Lows: [20], Highs: [16], Total time: 12896.950789999997
[32m[0906 18-00-20 @MBExp.py:144][0m ####################################################################
[32m[0906 18-00-20 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 18-00-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10653, current rewards: -4.50837, mean: -0.45084
[32m[0906 18-00-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10705, current rewards: 1.54917, mean: 0.02582
[32m[0906 18-00-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10712, current rewards: 7.63893, mean: 0.06944
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10738, current rewards: 13.71883, mean: 0.08574
[32m[0906 18-00-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10800, current rewards: 19.80605, mean: 0.09431
[32m[0906 18-00-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10859, current rewards: 25.89603, mean: 0.09960
[32m[0906 18-00-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10917, current rewards: 32.24453, mean: 0.10401
[32m[0906 18-00-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10947, current rewards: 28.33505, mean: 0.07871
[32m[0906 18-01-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10966, current rewards: 34.45916, mean: 0.08405
[32m[0906 18-01-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10988, current rewards: 40.10132, mean: 0.08718
[32m[0906 18-01-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10998, current rewards: 45.74320, mean: 0.08969
[32m[0906 18-01-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11014, current rewards: 51.37906, mean: 0.09175
[32m[0906 18-01-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11015, current rewards: 57.01704, mean: 0.09347
[32m[0906 18-01-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10995, current rewards: 62.65314, mean: 0.09493
[32m[0906 18-01-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10983, current rewards: 68.29573, mean: 0.09619
[32m[0906 18-01-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10968, current rewards: 73.42218, mean: 0.09661
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10954, current rewards: 73.62581, mean: 0.09090
[32m[0906 18-01-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10947, current rewards: 79.25694, mean: 0.09216
[32m[0906 18-01-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10937, current rewards: 84.86693, mean: 0.09326
[32m[0906 18-02-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10930, current rewards: 90.48520, mean: 0.09426
[32m[0906 18-02-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10923, current rewards: 96.09935, mean: 0.09515
[32m[0906 18-02-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10917, current rewards: 101.70929, mean: 0.09595
[32m[0906 18-02-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10909, current rewards: 107.32515, mean: 0.09669
[32m[0906 18-02-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10904, current rewards: 112.87701, mean: 0.09731
[32m[0906 18-02-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10897, current rewards: 118.48053, mean: 0.09792
[32m[0906 18-02-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10892, current rewards: 124.08718, mean: 0.09848
[32m[0906 18-02-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10891, current rewards: 129.97241, mean: 0.09922
[32m[0906 18-02-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10885, current rewards: 136.89735, mean: 0.10066
[32m[0906 18-02-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10882, current rewards: 143.81467, mean: 0.10200
[32m[0906 18-02-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10868, current rewards: 150.73772, mean: 0.10325
[32m[0906 18-03-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10854, current rewards: 157.66539, mean: 0.10441
[32m[0906 18-03-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10841, current rewards: 164.46050, mean: 0.10542
[32m[0906 18-03-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10830, current rewards: 171.44779, mean: 0.10649
[32m[0906 18-03-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10818, current rewards: 178.42623, mean: 0.10749
[32m[0906 18-03-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10817, current rewards: 185.39175, mean: 0.10842
[32m[0906 18-03-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10818, current rewards: 180.57554, mean: 0.10260
[32m[0906 18-03-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10818, current rewards: 186.32891, mean: 0.10294
[32m[0906 18-03-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10817, current rewards: 192.08358, mean: 0.10327
[32m[0906 18-03-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10817, current rewards: 197.83665, mean: 0.10358
[32m[0906 18-03-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10815, current rewards: 204.19469, mean: 0.10418
[32m[0906 18-03-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10814, current rewards: 210.15364, mean: 0.10455
[32m[0906 18-04-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10815, current rewards: 215.87912, mean: 0.10480
[32m[0906 18-04-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10813, current rewards: 221.60582, mean: 0.10503
[32m[0906 18-04-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10803, current rewards: 227.33123, mean: 0.10525
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10797, current rewards: 233.05780, mean: 0.10546
[32m[0906 18-04-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10788, current rewards: 228.96982, mean: 0.10131
[32m[0906 18-04-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10781, current rewards: 234.76933, mean: 0.10163
[32m[0906 18-04-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10776, current rewards: 240.57132, mean: 0.10194
[32m[0906 18-04-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10770, current rewards: 246.47037, mean: 0.10227
[32m[0906 18-04-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10763, current rewards: 252.27591, mean: 0.10255
[32m[0906 18-04-49 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-04-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-04-50 @MBExp.py:227][0m Rewards obtained: [250.0921405405563], Lows: [15], Highs: [16], Total time: 13166.793306999996
[32m[0906 18-06-41 @MBExp.py:144][0m ####################################################################
[32m[0906 18-06-41 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 18-06-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10882, current rewards: -5.92993, mean: -0.59299
[32m[0906 18-06-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10799, current rewards: 0.96235, mean: 0.01604
[32m[0906 18-06-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10777, current rewards: 7.33802, mean: 0.06671
[32m[0906 18-06-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10805, current rewards: 13.70672, mean: 0.08567
[32m[0906 18-07-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10867, current rewards: 20.07722, mean: 0.09561
[32m[0906 18-07-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10923, current rewards: 26.44303, mean: 0.10170
[32m[0906 18-07-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10973, current rewards: 18.07226, mean: 0.05830
[32m[0906 18-07-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10997, current rewards: 24.13334, mean: 0.06704
[32m[0906 18-07-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11011, current rewards: 30.19583, mean: 0.07365
[32m[0906 18-07-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11041, current rewards: 36.25562, mean: 0.07882
[32m[0906 18-07-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11059, current rewards: 42.31783, mean: 0.08298
[32m[0906 18-07-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11074, current rewards: 48.38131, mean: 0.08640
[32m[0906 18-07-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11053, current rewards: 54.44276, mean: 0.08925
[32m[0906 18-07-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11037, current rewards: 60.50306, mean: 0.09167
[32m[0906 18-07-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11026, current rewards: 67.01823, mean: 0.09439
[32m[0906 18-08-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11011, current rewards: 67.41527, mean: 0.08870
[32m[0906 18-08-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10995, current rewards: 72.67376, mean: 0.08972
[32m[0906 18-08-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10987, current rewards: 77.91964, mean: 0.09060
[32m[0906 18-08-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10977, current rewards: 83.16759, mean: 0.09139
[32m[0906 18-08-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10966, current rewards: 88.41334, mean: 0.09210
[32m[0906 18-08-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10958, current rewards: 93.65863, mean: 0.09273
[32m[0906 18-08-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10947, current rewards: 98.90564, mean: 0.09331
[32m[0906 18-08-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10939, current rewards: 103.05079, mean: 0.09284
[32m[0906 18-08-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10933, current rewards: 105.76688, mean: 0.09118
[32m[0906 18-08-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10927, current rewards: 112.00268, mean: 0.09256
[32m[0906 18-08-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10921, current rewards: 118.26311, mean: 0.09386
[32m[0906 18-09-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10918, current rewards: 108.70569, mean: 0.08298
[32m[0906 18-09-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10911, current rewards: 114.27992, mean: 0.08403
[32m[0906 18-09-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10901, current rewards: 119.85548, mean: 0.08500
[32m[0906 18-09-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10888, current rewards: 125.42947, mean: 0.08591
[32m[0906 18-09-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10872, current rewards: 130.88654, mean: 0.08668
[32m[0906 18-09-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10860, current rewards: 126.43633, mean: 0.08105
[32m[0906 18-09-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10848, current rewards: 133.22949, mean: 0.08275
[32m[0906 18-09-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10838, current rewards: 140.10638, mean: 0.08440
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10836, current rewards: 146.95185, mean: 0.08594
[32m[0906 18-09-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10836, current rewards: 153.76103, mean: 0.08736
[32m[0906 18-09-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10837, current rewards: 160.55004, mean: 0.08870
[32m[0906 18-10-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10836, current rewards: 167.33768, mean: 0.08997
[32m[0906 18-10-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10836, current rewards: 174.12842, mean: 0.09117
[32m[0906 18-10-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10835, current rewards: 172.75273, mean: 0.08814
[32m[0906 18-10-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10834, current rewards: 178.36235, mean: 0.08874
[32m[0906 18-10-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10835, current rewards: 183.96961, mean: 0.08931
[32m[0906 18-10-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10834, current rewards: 189.57841, mean: 0.08985
[32m[0906 18-10-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10824, current rewards: 195.18916, mean: 0.09037
[32m[0906 18-10-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10816, current rewards: 190.65949, mean: 0.08627
[32m[0906 18-10-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10808, current rewards: 197.46071, mean: 0.08737
[32m[0906 18-10-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10801, current rewards: 204.01487, mean: 0.08832
[32m[0906 18-10-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10794, current rewards: 209.79778, mean: 0.08890
[32m[0906 18-11-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10787, current rewards: 216.18201, mean: 0.08970
[32m[0906 18-11-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10780, current rewards: 222.57553, mean: 0.09048
[32m[0906 18-11-11 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-11-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-11-11 @MBExp.py:227][0m Rewards obtained: [227.6855772672941], Lows: [27], Highs: [22], Total time: 13437.078608999997
[32m[0906 18-13-05 @MBExp.py:144][0m ####################################################################
[32m[0906 18-13-05 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10669, current rewards: -3.53590, mean: -0.35359
[32m[0906 18-13-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10756, current rewards: 2.45465, mean: 0.04091
[32m[0906 18-13-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10803, current rewards: 8.48522, mean: 0.07714
[32m[0906 18-13-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10800, current rewards: 14.51404, mean: 0.09071
[32m[0906 18-13-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10875, current rewards: 20.54218, mean: 0.09782
[32m[0906 18-13-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10942, current rewards: 25.90881, mean: 0.09965
[32m[0906 18-13-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10987, current rewards: 31.68619, mean: 0.10221
[32m[0906 18-13-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11020, current rewards: 37.45613, mean: 0.10404
[32m[0906 18-13-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11049, current rewards: 43.22050, mean: 0.10542
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11065, current rewards: 32.93486, mean: 0.07160
[32m[0906 18-14-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11073, current rewards: 38.44257, mean: 0.07538
[32m[0906 18-14-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11077, current rewards: 43.89563, mean: 0.07839
[32m[0906 18-14-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11055, current rewards: 49.34953, mean: 0.08090
[32m[0906 18-14-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11036, current rewards: 54.81909, mean: 0.08306
[32m[0906 18-14-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11023, current rewards: 60.29255, mean: 0.08492
[32m[0906 18-14-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11010, current rewards: 65.73664, mean: 0.08650
[32m[0906 18-14-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10997, current rewards: 71.18528, mean: 0.08788
[32m[0906 18-14-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10990, current rewards: 76.64233, mean: 0.08912
[32m[0906 18-14-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10980, current rewards: 82.09413, mean: 0.09021
[32m[0906 18-14-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10970, current rewards: 83.33419, mean: 0.08681
[32m[0906 18-14-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10966, current rewards: 82.58384, mean: 0.08177
[32m[0906 18-15-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10958, current rewards: 88.23845, mean: 0.08324
[32m[0906 18-15-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10952, current rewards: 94.38234, mean: 0.08503
[32m[0906 18-15-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10947, current rewards: 100.03178, mean: 0.08623
[32m[0906 18-15-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10941, current rewards: 105.68869, mean: 0.08735
[32m[0906 18-15-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10935, current rewards: 111.34049, mean: 0.08837
[32m[0906 18-15-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10933, current rewards: 116.56581, mean: 0.08898
[32m[0906 18-15-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10929, current rewards: 121.90728, mean: 0.08964
[32m[0906 18-15-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10914, current rewards: 127.25189, mean: 0.09025
[32m[0906 18-15-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10900, current rewards: 132.58701, mean: 0.09081
[32m[0906 18-15-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10887, current rewards: 138.39393, mean: 0.09165
[32m[0906 18-15-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10876, current rewards: 143.76685, mean: 0.09216
[32m[0906 18-16-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10865, current rewards: 149.14398, mean: 0.09264
[32m[0906 18-16-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10855, current rewards: 154.52249, mean: 0.09309
[32m[0906 18-16-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10856, current rewards: 159.90053, mean: 0.09351
[32m[0906 18-16-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10854, current rewards: 165.27610, mean: 0.09391
[32m[0906 18-16-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10854, current rewards: 160.71249, mean: 0.08879
[32m[0906 18-16-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10855, current rewards: 166.57418, mean: 0.08956
[32m[0906 18-16-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10854, current rewards: 173.03029, mean: 0.09059
[32m[0906 18-16-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10852, current rewards: 179.79432, mean: 0.09173
[32m[0906 18-16-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10854, current rewards: 186.55836, mean: 0.09282
[32m[0906 18-16-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10854, current rewards: 193.32240, mean: 0.09385
[32m[0906 18-16-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10852, current rewards: 200.08644, mean: 0.09483
[32m[0906 18-17-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10844, current rewards: 206.85048, mean: 0.09576
[32m[0906 18-17-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10835, current rewards: 213.61452, mean: 0.09666
[32m[0906 18-17-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10827, current rewards: 215.83743, mean: 0.09550
[32m[0906 18-17-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10820, current rewards: 165.83743, mean: 0.07179
[32m[0906 18-17-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10812, current rewards: 115.83743, mean: 0.04908
[32m[0906 18-17-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10805, current rewards: 65.83743, mean: 0.02732
[32m[0906 18-17-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10801, current rewards: 15.83743, mean: 0.00644
[32m[0906 18-17-36 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 18-17-36 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-17-36 @MBExp.py:227][0m Rewards obtained: [-24.162569979544713], Lows: [15], Highs: [254], Total time: 13707.864768999996
[32m[0906 18-19-32 @MBExp.py:144][0m ####################################################################
[32m[0906 18-19-32 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 18-19-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10678, current rewards: -3.35679, mean: -0.33568
[32m[0906 18-19-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10809, current rewards: 4.36257, mean: 0.07271
[32m[0906 18-19-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10768, current rewards: 11.71223, mean: 0.10647
[32m[0906 18-19-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10748, current rewards: 19.05861, mean: 0.11912
[32m[0906 18-19-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10848, current rewards: 26.41191, mean: 0.12577
[32m[0906 18-20-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10900, current rewards: 33.76223, mean: 0.12985
[32m[0906 18-20-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10943, current rewards: 41.11247, mean: 0.13262
[32m[0906 18-20-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10977, current rewards: 48.46559, mean: 0.13463
[32m[0906 18-20-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11000, current rewards: 55.82541, mean: 0.13616
[32m[0906 18-20-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11020, current rewards: 57.05578, mean: 0.12403
[32m[0906 18-20-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11043, current rewards: 62.75000, mean: 0.12304
[32m[0906 18-20-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11026, current rewards: 68.44748, mean: 0.12223
[32m[0906 18-20-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11005, current rewards: 74.13980, mean: 0.12154
[32m[0906 18-20-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10995, current rewards: 79.83099, mean: 0.12096
[32m[0906 18-20-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10982, current rewards: 85.52691, mean: 0.12046
[32m[0906 18-20-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10975, current rewards: 91.22278, mean: 0.12003
[32m[0906 18-21-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10977, current rewards: 96.91813, mean: 0.11965
[32m[0906 18-21-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10969, current rewards: 102.60844, mean: 0.11931
[32m[0906 18-21-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10962, current rewards: 102.76615, mean: 0.11293
[32m[0906 18-21-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10959, current rewards: 108.36345, mean: 0.11288
[32m[0906 18-21-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10952, current rewards: 113.88963, mean: 0.11276
[32m[0906 18-21-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10948, current rewards: 119.47760, mean: 0.11271
[32m[0906 18-21-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10945, current rewards: 125.06691, mean: 0.11267
[32m[0906 18-21-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10938, current rewards: 130.64599, mean: 0.11263
[32m[0906 18-21-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10935, current rewards: 136.23027, mean: 0.11259
[32m[0906 18-21-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10931, current rewards: 141.81547, mean: 0.11255
[32m[0906 18-21-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10925, current rewards: 147.40244, mean: 0.11252
[32m[0906 18-22-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10915, current rewards: 152.98810, mean: 0.11249
[32m[0906 18-22-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10899, current rewards: 162.76946, mean: 0.11544
[32m[0906 18-22-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10883, current rewards: 168.49736, mean: 0.11541
[32m[0906 18-22-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10869, current rewards: 174.75106, mean: 0.11573
[32m[0906 18-22-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10858, current rewards: 181.00017, mean: 0.11603
[32m[0906 18-22-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10846, current rewards: 187.25398, mean: 0.11631
[32m[0906 18-22-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10838, current rewards: 193.51234, mean: 0.11657
[32m[0906 18-22-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10838, current rewards: 189.18710, mean: 0.11064
[32m[0906 18-22-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10837, current rewards: 194.85326, mean: 0.11071
[32m[0906 18-22-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10835, current rewards: 200.51474, mean: 0.11078
[32m[0906 18-22-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10834, current rewards: 207.38888, mean: 0.11150
[32m[0906 18-22-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10834, current rewards: 213.10506, mean: 0.11157
[32m[0906 18-23-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10834, current rewards: 218.82523, mean: 0.11165
[32m[0906 18-23-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10833, current rewards: 224.53928, mean: 0.11171
[32m[0906 18-23-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10832, current rewards: 230.25526, mean: 0.11177
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10832, current rewards: 235.97205, mean: 0.11184
[32m[0906 18-23-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10823, current rewards: 231.82461, mean: 0.10733
[32m[0906 18-23-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10815, current rewards: 240.36253, mean: 0.10876
[32m[0906 18-23-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10810, current rewards: 248.86161, mean: 0.11012
[32m[0906 18-23-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10802, current rewards: 223.69896, mean: 0.09684
[32m[0906 18-23-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10795, current rewards: 173.69896, mean: 0.07360
[32m[0906 18-23-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10789, current rewards: 123.69896, mean: 0.05133
[32m[0906 18-23-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10782, current rewards: 73.69896, mean: 0.02996
[32m[0906 18-24-02 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-24-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-24-02 @MBExp.py:227][0m Rewards obtained: [33.69896312773079], Lows: [11], Highs: [232], Total time: 13978.242186999996
[32m[0906 18-26-01 @MBExp.py:144][0m ####################################################################
[32m[0906 18-26-01 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 18-26-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10644, current rewards: -2.84260, mean: -0.28426
[32m[0906 18-26-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10750, current rewards: 5.10969, mean: 0.08516
[32m[0906 18-26-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10771, current rewards: 11.42511, mean: 0.10386
[32m[0906 18-26-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10799, current rewards: 17.74054, mean: 0.11088
[32m[0906 18-26-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10876, current rewards: 24.05596, mean: 0.11455
[32m[0906 18-26-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10936, current rewards: 27.54078, mean: 0.10593
[32m[0906 18-26-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10985, current rewards: 30.42686, mean: 0.09815
[32m[0906 18-26-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11004, current rewards: 33.31295, mean: 0.09254
[32m[0906 18-26-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11024, current rewards: 36.19903, mean: 0.08829
[32m[0906 18-26-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11046, current rewards: 39.08511, mean: 0.08497
[32m[0906 18-26-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11042, current rewards: 41.97120, mean: 0.08230
[32m[0906 18-27-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11024, current rewards: 44.85728, mean: 0.08010
[32m[0906 18-27-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11007, current rewards: 14.95399, mean: 0.02451
[32m[0906 18-27-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10988, current rewards: -35.04601, mean: -0.05310
[32m[0906 18-27-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10981, current rewards: -85.04601, mean: -0.11978
[32m[0906 18-27-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10972, current rewards: -135.04601, mean: -0.17769
[32m[0906 18-27-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10969, current rewards: -185.04601, mean: -0.22845
[32m[0906 18-27-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10971, current rewards: -235.04601, mean: -0.27331
[32m[0906 18-27-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10962, current rewards: -285.04601, mean: -0.31324
[32m[0906 18-27-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10955, current rewards: -335.04601, mean: -0.34901
[32m[0906 18-27-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10951, current rewards: -385.04601, mean: -0.38123
[32m[0906 18-27-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10943, current rewards: -435.04601, mean: -0.41042
[32m[0906 18-28-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10936, current rewards: -485.04601, mean: -0.43698
[32m[0906 18-28-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10933, current rewards: -535.04601, mean: -0.46125
[32m[0906 18-28-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10925, current rewards: -585.04601, mean: -0.48351
[32m[0906 18-28-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10921, current rewards: -635.04601, mean: -0.50400
[32m[0906 18-28-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10918, current rewards: -685.04601, mean: -0.52294
[32m[0906 18-28-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10901, current rewards: -735.04601, mean: -0.54048
[32m[0906 18-28-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10884, current rewards: -785.04601, mean: -0.55677
[32m[0906 18-28-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10871, current rewards: -835.04601, mean: -0.57195
[32m[0906 18-28-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10857, current rewards: -885.04601, mean: -0.58612
[32m[0906 18-28-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10844, current rewards: -935.04601, mean: -0.59939
[32m[0906 18-28-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10834, current rewards: -985.04601, mean: -0.61183
[32m[0906 18-29-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10827, current rewards: -1035.04601, mean: -0.62352
[32m[0906 18-29-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10828, current rewards: -1085.04601, mean: -0.63453
[32m[0906 18-29-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10829, current rewards: -1135.04601, mean: -0.64491
[32m[0906 18-29-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10829, current rewards: -1185.04601, mean: -0.65472
[32m[0906 18-29-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10829, current rewards: -1235.04601, mean: -0.66400
[32m[0906 18-29-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10830, current rewards: -1285.04601, mean: -0.67280
[32m[0906 18-29-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10830, current rewards: -1335.04601, mean: -0.68115
[32m[0906 18-29-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10829, current rewards: -1385.04601, mean: -0.68908
[32m[0906 18-29-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10830, current rewards: -1435.04601, mean: -0.69662
[32m[0906 18-29-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10830, current rewards: -1485.04601, mean: -0.70381
[32m[0906 18-29-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10822, current rewards: -1535.04601, mean: -0.71067
[32m[0906 18-30-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10816, current rewards: -1585.04601, mean: -0.71722
[32m[0906 18-30-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10809, current rewards: -1635.04601, mean: -0.72347
[32m[0906 18-30-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10801, current rewards: -1685.04601, mean: -0.72946
[32m[0906 18-30-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10796, current rewards: -1735.04601, mean: -0.73519
[32m[0906 18-30-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10789, current rewards: -1785.04601, mean: -0.74068
[32m[0906 18-30-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10784, current rewards: -1835.04601, mean: -0.74595
[32m[0906 18-30-31 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 18-30-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-30-31 @MBExp.py:227][0m Rewards obtained: [-1875.0460061691806], Lows: [0], Highs: [1926], Total time: 14248.671068999996
[32m[0906 18-32-32 @MBExp.py:144][0m ####################################################################
[32m[0906 18-32-32 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 18-32-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10857, current rewards: -4.38743, mean: -0.43874
[32m[0906 18-32-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10871, current rewards: 2.06144, mean: 0.03436
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10845, current rewards: 8.04246, mean: 0.07311
[32m[0906 18-32-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10845, current rewards: 14.01356, mean: 0.08758
[32m[0906 18-32-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10918, current rewards: 19.98747, mean: 0.09518
[32m[0906 18-33-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10971, current rewards: 26.05031, mean: 0.10019
[32m[0906 18-33-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11013, current rewards: 32.05313, mean: 0.10340
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11052, current rewards: 38.06262, mean: 0.10573
[32m[0906 18-33-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11073, current rewards: 44.07432, mean: 0.10750
[32m[0906 18-33-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11090, current rewards: 50.08372, mean: 0.10888
[32m[0906 18-33-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11067, current rewards: 56.09064, mean: 0.10998
[32m[0906 18-33-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11045, current rewards: 51.55384, mean: 0.09206
[32m[0906 18-33-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11028, current rewards: 57.13496, mean: 0.09366
[32m[0906 18-33-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11015, current rewards: 62.39169, mean: 0.09453
[32m[0906 18-33-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11005, current rewards: 67.97631, mean: 0.09574
[32m[0906 18-33-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10993, current rewards: 73.56875, mean: 0.09680
[32m[0906 18-34-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10986, current rewards: 79.16446, mean: 0.09773
[32m[0906 18-34-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10977, current rewards: 84.75685, mean: 0.09855
[32m[0906 18-34-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10970, current rewards: 90.34764, mean: 0.09928
[32m[0906 18-34-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10964, current rewards: 95.92914, mean: 0.09993
[32m[0906 18-34-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10960, current rewards: 101.51571, mean: 0.10051
[32m[0906 18-34-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10957, current rewards: 107.79342, mean: 0.10169
[32m[0906 18-34-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10950, current rewards: 113.37647, mean: 0.10214
[32m[0906 18-34-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10944, current rewards: 109.62907, mean: 0.09451
[32m[0906 18-34-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10941, current rewards: 115.12246, mean: 0.09514
[32m[0906 18-34-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10939, current rewards: 120.62016, mean: 0.09573
[32m[0906 18-34-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10925, current rewards: 126.11704, mean: 0.09627
[32m[0906 18-35-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10911, current rewards: 131.60884, mean: 0.09677
[32m[0906 18-35-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10896, current rewards: 137.10569, mean: 0.09724
[32m[0906 18-35-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10882, current rewards: 142.43779, mean: 0.09756
[32m[0906 18-35-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10871, current rewards: 137.59754, mean: 0.09112
[32m[0906 18-35-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10859, current rewards: 144.01376, mean: 0.09232
[32m[0906 18-35-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10847, current rewards: 150.41984, mean: 0.09343
[32m[0906 18-35-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10845, current rewards: 156.82200, mean: 0.09447
[32m[0906 18-35-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10843, current rewards: 163.22038, mean: 0.09545
[32m[0906 18-35-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10842, current rewards: 169.62727, mean: 0.09638
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10841, current rewards: 176.02386, mean: 0.09725
[32m[0906 18-35-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10841, current rewards: 182.43339, mean: 0.09808
[32m[0906 18-36-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10839, current rewards: 178.42697, mean: 0.09342
[32m[0906 18-36-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10841, current rewards: 183.79081, mean: 0.09377
[32m[0906 18-36-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10841, current rewards: 188.76261, mean: 0.09391
[32m[0906 18-36-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10841, current rewards: 193.73417, mean: 0.09405
[32m[0906 18-36-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10841, current rewards: 198.70539, mean: 0.09417
[32m[0906 18-36-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10833, current rewards: 203.67678, mean: 0.09429
[32m[0906 18-36-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10825, current rewards: 208.64813, mean: 0.09441
[32m[0906 18-36-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10819, current rewards: 213.52212, mean: 0.09448
[32m[0906 18-36-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10812, current rewards: 218.21953, mean: 0.09447
[32m[0906 18-36-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10805, current rewards: 223.28667, mean: 0.09461
[32m[0906 18-36-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10799, current rewards: 228.35258, mean: 0.09475
[32m[0906 18-36-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10794, current rewards: 233.42076, mean: 0.09489
[32m[0906 18-37-03 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 18-37-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-37-03 @MBExp.py:227][0m Rewards obtained: [237.47415284351013], Lows: [20], Highs: [5], Total time: 14519.302563999996
[32m[0906 18-39-06 @MBExp.py:144][0m ####################################################################
[32m[0906 18-39-06 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 18-39-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10805, current rewards: -4.71817, mean: -0.47182
[32m[0906 18-39-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10846, current rewards: -0.00360, mean: -0.00006
[32m[0906 18-39-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10856, current rewards: 4.85856, mean: 0.04417
[32m[0906 18-39-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10860, current rewards: 9.83880, mean: 0.06149
[32m[0906 18-39-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10920, current rewards: 15.86045, mean: 0.07553
[32m[0906 18-39-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10985, current rewards: 22.57688, mean: 0.08683
[32m[0906 18-39-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11021, current rewards: 29.27844, mean: 0.09445
[32m[0906 18-39-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11051, current rewards: 35.99376, mean: 0.09998
[32m[0906 18-39-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11076, current rewards: 42.68416, mean: 0.10411
[32m[0906 18-39-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11067, current rewards: 49.38430, mean: 0.10736
[32m[0906 18-40-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11048, current rewards: 44.69233, mean: 0.08763
[32m[0906 18-40-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11029, current rewards: 49.96505, mean: 0.08922
[32m[0906 18-40-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11009, current rewards: 55.20483, mean: 0.09050
[32m[0906 18-40-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11000, current rewards: 60.47550, mean: 0.09163
[32m[0906 18-40-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10986, current rewards: 65.74122, mean: 0.09259
[32m[0906 18-40-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10972, current rewards: 71.01010, mean: 0.09343
[32m[0906 18-40-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10967, current rewards: 76.28187, mean: 0.09418
[32m[0906 18-40-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10958, current rewards: 81.55012, mean: 0.09483
[32m[0906 18-40-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10948, current rewards: 86.82087, mean: 0.09541
[32m[0906 18-40-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10944, current rewards: 81.98367, mean: 0.08540
[32m[0906 18-40-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10937, current rewards: 87.55936, mean: 0.08669
[32m[0906 18-41-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10931, current rewards: 93.13707, mean: 0.08787
[32m[0906 18-41-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10928, current rewards: 98.71191, mean: 0.08893
[32m[0906 18-41-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10923, current rewards: 104.28448, mean: 0.08990
[32m[0906 18-41-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10917, current rewards: 109.85902, mean: 0.09079
[32m[0906 18-41-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10914, current rewards: 109.99105, mean: 0.08729
[32m[0906 18-41-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10898, current rewards: 115.46609, mean: 0.08814
[32m[0906 18-41-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10882, current rewards: 120.96539, mean: 0.08895
[32m[0906 18-41-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10870, current rewards: 126.81295, mean: 0.08994
[32m[0906 18-41-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10856, current rewards: 132.68606, mean: 0.09088
[32m[0906 18-41-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10842, current rewards: 138.13672, mean: 0.09148
[32m[0906 18-41-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10831, current rewards: 143.58491, mean: 0.09204
[32m[0906 18-42-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10822, current rewards: 149.03444, mean: 0.09257
[32m[0906 18-42-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10820, current rewards: 154.11751, mean: 0.09284
[32m[0906 18-42-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10823, current rewards: 159.50265, mean: 0.09328
[32m[0906 18-42-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10823, current rewards: 164.88540, mean: 0.09368
[32m[0906 18-42-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10823, current rewards: 170.27124, mean: 0.09407
[32m[0906 18-42-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10826, current rewards: 175.68619, mean: 0.09445
[32m[0906 18-42-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10825, current rewards: 181.07329, mean: 0.09480
[32m[0906 18-42-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10827, current rewards: 186.46218, mean: 0.09513
[32m[0906 18-42-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10827, current rewards: 191.85078, mean: 0.09545
[32m[0906 18-42-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10828, current rewards: 197.23597, mean: 0.09575
[32m[0906 18-42-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10827, current rewards: 197.68747, mean: 0.09369
[32m[0906 18-43-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10820, current rewards: 204.63445, mean: 0.09474
[32m[0906 18-43-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10813, current rewards: 211.58777, mean: 0.09574
[32m[0906 18-43-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10805, current rewards: 218.09557, mean: 0.09650
[32m[0906 18-43-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10799, current rewards: 224.93848, mean: 0.09738
[32m[0906 18-43-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10792, current rewards: 231.78321, mean: 0.09821
[32m[0906 18-43-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10786, current rewards: 238.61705, mean: 0.09901
[32m[0906 18-43-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10783, current rewards: 245.45270, mean: 0.09978
[32m[0906 18-43-36 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-43-36 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-43-36 @MBExp.py:227][0m Rewards obtained: [250.93528172937127], Lows: [10], Highs: [15], Total time: 14789.677622999996
[32m[0906 18-45-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-45-42 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 18-45-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10676, current rewards: -8.09355, mean: -0.80936
[32m[0906 18-45-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10853, current rewards: -2.50659, mean: -0.04178
[32m[0906 18-45-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10911, current rewards: 3.37670, mean: 0.03070
[32m[0906 18-45-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10908, current rewards: 9.22915, mean: 0.05768
[32m[0906 18-46-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10962, current rewards: 14.85848, mean: 0.07075
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11044, current rewards: 20.75430, mean: 0.07982
[32m[0906 18-46-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11094, current rewards: 26.64996, mean: 0.08597
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11128, current rewards: 19.32475, mean: 0.05368
[32m[0906 18-46-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11160, current rewards: 24.78160, mean: 0.06044
[32m[0906 18-46-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11135, current rewards: 30.23589, mean: 0.06573
[32m[0906 18-46-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11117, current rewards: 35.69063, mean: 0.06998
[32m[0906 18-46-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11099, current rewards: 41.14939, mean: 0.07348
[32m[0906 18-46-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11083, current rewards: 48.26923, mean: 0.07913
[32m[0906 18-46-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11067, current rewards: 56.56935, mean: 0.08571
[32m[0906 18-47-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11059, current rewards: 64.86947, mean: 0.09137
[32m[0906 18-47-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11045, current rewards: 73.16959, mean: 0.09628
[32m[0906 18-47-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11035, current rewards: 55.81766, mean: 0.06891
[32m[0906 18-47-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11027, current rewards: 5.81766, mean: 0.00676
[32m[0906 18-47-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11020, current rewards: -44.18234, mean: -0.04855
[32m[0906 18-47-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11015, current rewards: -94.18234, mean: -0.09811
[32m[0906 18-47-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11015, current rewards: -144.18234, mean: -0.14275
[32m[0906 18-47-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11014, current rewards: -194.18234, mean: -0.18319
[32m[0906 18-47-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11012, current rewards: -244.18234, mean: -0.21998
[32m[0906 18-47-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11008, current rewards: -294.18234, mean: -0.25361
[32m[0906 18-47-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11005, current rewards: -344.18234, mean: -0.28445
[32m[0906 18-48-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10994, current rewards: -394.18234, mean: -0.31284
[32m[0906 18-48-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10977, current rewards: -405.13685, mean: -0.30926
[32m[0906 18-48-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10962, current rewards: -398.13968, mean: -0.29275
[32m[0906 18-48-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10948, current rewards: -391.14510, mean: -0.27741
[32m[0906 18-48-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10935, current rewards: -384.27237, mean: -0.26320
[32m[0906 18-48-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10922, current rewards: -377.26446, mean: -0.24984
[32m[0906 18-48-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10911, current rewards: -370.25768, mean: -0.23734
[32m[0906 18-48-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10899, current rewards: -363.25432, mean: -0.22562
[32m[0906 18-48-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10897, current rewards: -367.72269, mean: -0.22152
[32m[0906 18-48-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10897, current rewards: -361.70365, mean: -0.21152
[32m[0906 18-48-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10897, current rewards: -355.68707, mean: -0.20209
[32m[0906 18-49-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10896, current rewards: -349.66865, mean: -0.19319
[32m[0906 18-49-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10895, current rewards: -343.72858, mean: -0.18480
[32m[0906 18-49-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10894, current rewards: -337.62016, mean: -0.17676
[32m[0906 18-49-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10891, current rewards: -331.50898, mean: -0.16914
[32m[0906 18-49-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10892, current rewards: -325.39423, mean: -0.16189
[32m[0906 18-49-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10891, current rewards: -319.28407, mean: -0.15499
[32m[0906 18-49-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10889, current rewards: -319.53634, mean: -0.15144
[32m[0906 18-49-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10883, current rewards: -317.70071, mean: -0.14708
[32m[0906 18-49-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10875, current rewards: -312.33113, mean: -0.14133
[32m[0906 18-49-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10866, current rewards: -306.16119, mean: -0.13547
[32m[0906 18-49-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10860, current rewards: -300.36596, mean: -0.13003
[32m[0906 18-49-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10852, current rewards: -294.57073, mean: -0.12482
[32m[0906 18-50-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10845, current rewards: -288.77550, mean: -0.11982
[32m[0906 18-50-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10842, current rewards: -282.98027, mean: -0.11503
[32m[0906 18-50-14 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 18-50-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-50-14 @MBExp.py:227][0m Rewards obtained: [-278.3440888910206], Lows: [18], Highs: [493], Total time: 15061.517063999996
[32m[0906 18-52-22 @MBExp.py:144][0m ####################################################################
[32m[0906 18-52-22 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 18-52-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10932, current rewards: -4.59970, mean: -0.45997
[32m[0906 18-52-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10899, current rewards: 1.05343, mean: 0.01756
[32m[0906 18-52-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10914, current rewards: 6.66958, mean: 0.06063
[32m[0906 18-52-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10905, current rewards: 12.03058, mean: 0.07519
[32m[0906 18-52-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10946, current rewards: 17.65653, mean: 0.08408
[32m[0906 18-52-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11022, current rewards: 23.28379, mean: 0.08955
[32m[0906 18-52-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11064, current rewards: 28.91479, mean: 0.09327
[32m[0906 18-53-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11108, current rewards: 34.54891, mean: 0.09597
[32m[0906 18-53-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11098, current rewards: 40.17701, mean: 0.09799
[32m[0906 18-53-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11080, current rewards: 39.73370, mean: 0.08638
[32m[0906 18-53-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11063, current rewards: 42.81635, mean: 0.08395
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11044, current rewards: 45.90211, mean: 0.08197
[32m[0906 18-53-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11030, current rewards: 48.98263, mean: 0.08030
[32m[0906 18-53-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11024, current rewards: 52.06187, mean: 0.07888
[32m[0906 18-53-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11013, current rewards: 55.14403, mean: 0.07767
[32m[0906 18-53-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11003, current rewards: 58.22532, mean: 0.07661
[32m[0906 18-53-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10998, current rewards: 61.30823, mean: 0.07569
[32m[0906 18-53-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10992, current rewards: 64.38757, mean: 0.07487
[32m[0906 18-54-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10984, current rewards: 67.47074, mean: 0.07414
[32m[0906 18-54-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10980, current rewards: 70.53554, mean: 0.07347
[32m[0906 18-54-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10976, current rewards: 73.60513, mean: 0.07288
[32m[0906 18-54-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10969, current rewards: 76.70562, mean: 0.07236
[32m[0906 18-54-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10966, current rewards: 79.80406, mean: 0.07190
[32m[0906 18-54-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10960, current rewards: 82.90760, mean: 0.07147
[32m[0906 18-54-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10950, current rewards: 86.00931, mean: 0.07108
[32m[0906 18-54-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10935, current rewards: 89.10888, mean: 0.07072
[32m[0906 18-54-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10919, current rewards: 92.89790, mean: 0.07091
[32m[0906 18-54-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10905, current rewards: 97.80587, mean: 0.07192
[32m[0906 18-54-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10893, current rewards: 103.21101, mean: 0.07320
[32m[0906 18-55-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10880, current rewards: 107.93305, mean: 0.07393
[32m[0906 18-55-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10866, current rewards: 112.65573, mean: 0.07461
[32m[0906 18-55-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10857, current rewards: 117.37510, mean: 0.07524
[32m[0906 18-55-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10846, current rewards: 117.90918, mean: 0.07324
[32m[0906 18-55-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10845, current rewards: 118.59836, mean: 0.07144
[32m[0906 18-55-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10847, current rewards: 124.33778, mean: 0.07271
[32m[0906 18-55-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10847, current rewards: 130.07827, mean: 0.07391
[32m[0906 18-55-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10848, current rewards: 135.59324, mean: 0.07491
[32m[0906 18-55-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10850, current rewards: 141.19466, mean: 0.07591
[32m[0906 18-55-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10849, current rewards: 141.79481, mean: 0.07424
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10849, current rewards: 147.08926, mean: 0.07505
[32m[0906 18-56-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10851, current rewards: 152.38871, mean: 0.07582
[32m[0906 18-56-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10849, current rewards: 157.68635, mean: 0.07655
[32m[0906 18-56-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10849, current rewards: 162.98621, mean: 0.07724
[32m[0906 18-56-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10843, current rewards: 168.28281, mean: 0.07791
[32m[0906 18-56-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10835, current rewards: 173.26061, mean: 0.07840
[32m[0906 18-56-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10827, current rewards: 178.19848, mean: 0.07885
[32m[0906 18-56-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10822, current rewards: 183.33807, mean: 0.07937
[32m[0906 18-56-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10815, current rewards: 188.47473, mean: 0.07986
[32m[0906 18-56-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10809, current rewards: 193.61390, mean: 0.08034
[32m[0906 18-56-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10808, current rewards: 193.03925, mean: 0.07847
[32m[0906 18-56-53 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 18-56-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-56-53 @MBExp.py:227][0m Rewards obtained: [196.66978753962147], Lows: [5], Highs: [20], Total time: 15332.529975999996
[32m[0906 18-59-03 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-03 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 18-59-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10738, current rewards: -5.63993, mean: -0.56399
[32m[0906 18-59-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10857, current rewards: 0.91391, mean: 0.01523
[32m[0906 18-59-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10859, current rewards: 7.91466, mean: 0.07195
[32m[0906 18-59-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10855, current rewards: 14.82257, mean: 0.09264
[32m[0906 18-59-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10916, current rewards: 21.85223, mean: 0.10406
[32m[0906 18-59-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10987, current rewards: 28.88142, mean: 0.11108
[32m[0906 18-59-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11029, current rewards: 35.93446, mean: 0.11592
[32m[0906 18-59-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11044, current rewards: 42.96863, mean: 0.11936
[32m[0906 18-59-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11021, current rewards: 50.02365, mean: 0.12201
[32m[0906 18-59-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11004, current rewards: 57.05628, mean: 0.12404
[32m[0906 19-00-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10995, current rewards: 64.10172, mean: 0.12569
[32m[0906 19-00-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10986, current rewards: 71.34568, mean: 0.12740
[32m[0906 19-00-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10974, current rewards: 72.58456, mean: 0.11899
[32m[0906 19-00-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10969, current rewards: 80.11481, mean: 0.12139
[32m[0906 19-00-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10962, current rewards: 85.64748, mean: 0.12063
[32m[0906 19-00-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10955, current rewards: 91.17744, mean: 0.11997
[32m[0906 19-00-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10953, current rewards: 96.70705, mean: 0.11939
[32m[0906 19-00-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10946, current rewards: 90.09378, mean: 0.10476
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10943, current rewards: 95.80514, mean: 0.10528
[32m[0906 19-00-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10942, current rewards: 101.51097, mean: 0.10574
[32m[0906 19-00-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10937, current rewards: 107.21647, mean: 0.10615
[32m[0906 19-01-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10936, current rewards: 112.92243, mean: 0.10653
[32m[0906 19-01-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10933, current rewards: 112.92058, mean: 0.10173
[32m[0906 19-01-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10930, current rewards: 118.42672, mean: 0.10209
[32m[0906 19-01-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10930, current rewards: 123.92952, mean: 0.10242
[32m[0906 19-01-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10923, current rewards: 129.43400, mean: 0.10273
[32m[0906 19-01-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10908, current rewards: 134.93609, mean: 0.10300
[32m[0906 19-01-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10895, current rewards: 134.69517, mean: 0.09904
[32m[0906 19-01-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10881, current rewards: 140.32094, mean: 0.09952
[32m[0906 19-01-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10868, current rewards: 146.10441, mean: 0.10007
[32m[0906 19-01-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10856, current rewards: 151.88070, mean: 0.10058
[32m[0906 19-01-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10844, current rewards: 157.66528, mean: 0.10107
[32m[0906 19-01-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10833, current rewards: 163.44419, mean: 0.10152
[32m[0906 19-02-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10836, current rewards: 169.22654, mean: 0.10194
[32m[0906 19-02-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10837, current rewards: 175.01016, mean: 0.10235
[32m[0906 19-02-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10837, current rewards: 180.78611, mean: 0.10272
[32m[0906 19-02-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10839, current rewards: 187.09596, mean: 0.10337
[32m[0906 19-02-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10839, current rewards: 192.84612, mean: 0.10368
[32m[0906 19-02-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10839, current rewards: 190.13796, mean: 0.09955
[32m[0906 19-02-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10841, current rewards: 194.17394, mean: 0.09907
[32m[0906 19-02-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10841, current rewards: 199.72618, mean: 0.09937
[32m[0906 19-02-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10841, current rewards: 205.27786, mean: 0.09965
[32m[0906 19-02-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10844, current rewards: 210.83196, mean: 0.09992
[32m[0906 19-02-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10838, current rewards: 216.37930, mean: 0.10018
[32m[0906 19-03-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10831, current rewards: 221.63492, mean: 0.10029
[32m[0906 19-03-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10824, current rewards: 216.61621, mean: 0.09585
[32m[0906 19-03-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10817, current rewards: 222.71295, mean: 0.09641
[32m[0906 19-03-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10811, current rewards: 228.80604, mean: 0.09695
[32m[0906 19-03-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10806, current rewards: 234.89639, mean: 0.09747
[32m[0906 19-03-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10800, current rewards: 240.99054, mean: 0.09796
[32m[0906 19-03-34 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 19-03-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-03-34 @MBExp.py:227][0m Rewards obtained: [245.86591758995925], Lows: [16], Highs: [21], Total time: 15603.202286999996
[32m[0906 19-05-47 @MBExp.py:144][0m ####################################################################
[32m[0906 19-05-47 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 19-05-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10791, current rewards: -5.75962, mean: -0.57596
[32m[0906 19-05-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10885, current rewards: 3.67822, mean: 0.06130
[32m[0906 19-05-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10910, current rewards: 13.35476, mean: 0.12141
[32m[0906 19-06-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10920, current rewards: -11.60673, mean: -0.07254
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10930, current rewards: -33.81736, mean: -0.16104
[32m[0906 19-06-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11001, current rewards: -50.17976, mean: -0.19300
[32m[0906 19-06-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11062, current rewards: -96.36259, mean: -0.31085
[32m[0906 19-06-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11043, current rewards: -140.61875, mean: -0.39061
[32m[0906 19-06-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11029, current rewards: -184.84826, mean: -0.45085
[32m[0906 19-06-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11018, current rewards: -231.21471, mean: -0.50264
[32m[0906 19-06-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11007, current rewards: -279.73714, mean: -0.54850
[32m[0906 19-06-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10998, current rewards: -328.37361, mean: -0.58638
[32m[0906 19-06-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10994, current rewards: -374.98800, mean: -0.61473
[32m[0906 19-07-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10986, current rewards: -419.47316, mean: -0.63557
[32m[0906 19-07-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10985, current rewards: -463.94195, mean: -0.65344
[32m[0906 19-07-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10976, current rewards: -522.39972, mean: -0.68737
[32m[0906 19-07-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10971, current rewards: -583.89908, mean: -0.72086
[32m[0906 19-07-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10971, current rewards: -645.27238, mean: -0.75032
[32m[0906 19-07-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10966, current rewards: -700.61324, mean: -0.76990
[32m[0906 19-07-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10968, current rewards: -694.72549, mean: -0.72367
[32m[0906 19-07-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10970, current rewards: -689.31962, mean: -0.68249
[32m[0906 19-07-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10966, current rewards: -683.73385, mean: -0.64503
[32m[0906 19-07-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10962, current rewards: -678.14518, mean: -0.61094
[32m[0906 19-07-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10961, current rewards: -672.55869, mean: -0.57979
[32m[0906 19-08-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10960, current rewards: -666.96928, mean: -0.55121
[32m[0906 19-08-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10945, current rewards: -661.38403, mean: -0.52491
[32m[0906 19-08-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10931, current rewards: -655.79935, mean: -0.50061
[32m[0906 19-08-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10917, current rewards: -650.21193, mean: -0.47810
[32m[0906 19-08-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10902, current rewards: -643.95585, mean: -0.45671
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10893, current rewards: -638.34727, mean: -0.43722
[32m[0906 19-08-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10880, current rewards: -632.73650, mean: -0.41903
[32m[0906 19-08-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10870, current rewards: -637.02863, mean: -0.40835
[32m[0906 19-08-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10866, current rewards: -631.27055, mean: -0.39209
[32m[0906 19-08-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10869, current rewards: -625.50976, mean: -0.37681
[32m[0906 19-08-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10871, current rewards: -619.74398, mean: -0.36242
[32m[0906 19-08-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10874, current rewards: -613.98161, mean: -0.34885
[32m[0906 19-09-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10874, current rewards: -608.33817, mean: -0.33610
[32m[0906 19-09-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10876, current rewards: -602.60212, mean: -0.32398
[32m[0906 19-09-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10879, current rewards: -596.86388, mean: -0.31249
[32m[0906 19-09-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10880, current rewards: -591.12853, mean: -0.30160
[32m[0906 19-09-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10881, current rewards: -596.35482, mean: -0.29669
[32m[0906 19-09-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10883, current rewards: -591.30494, mean: -0.28704
[32m[0906 19-09-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10884, current rewards: -586.25506, mean: -0.27785
[32m[0906 19-09-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10879, current rewards: -581.20519, mean: -0.26908
[32m[0906 19-09-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10873, current rewards: -576.73625, mean: -0.26097
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10866, current rewards: -573.30581, mean: -0.25368
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10859, current rewards: -569.87538, mean: -0.24670
[32m[0906 19-10-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10854, current rewards: -566.44495, mean: -0.24002
[32m[0906 19-10-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10847, current rewards: -608.96469, mean: -0.25268
[32m[0906 19-10-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10840, current rewards: -658.96469, mean: -0.26787
[32m[0906 19-10-19 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 19-10-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-10-19 @MBExp.py:227][0m Rewards obtained: [-698.9646894863835], Lows: [430], Highs: [144], Total time: 15874.941400999996
[32m[0906 19-12-34 @MBExp.py:144][0m ####################################################################
[32m[0906 19-12-34 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 19-12-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10669, current rewards: -4.42040, mean: -0.44204
[32m[0906 19-12-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10887, current rewards: 0.96763, mean: 0.01613
[32m[0906 19-12-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10858, current rewards: 6.33087, mean: 0.05755
[32m[0906 19-12-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10851, current rewards: 11.69482, mean: 0.07309
[32m[0906 19-12-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10889, current rewards: 17.05690, mean: 0.08122
[32m[0906 19-13-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10957, current rewards: 22.41734, mean: 0.08622
[32m[0906 19-13-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10968, current rewards: 27.77953, mean: 0.08961
[32m[0906 19-13-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10966, current rewards: 27.74918, mean: 0.07708
[32m[0906 19-13-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10950, current rewards: 33.30648, mean: 0.08124
[32m[0906 19-13-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10948, current rewards: 38.86258, mean: 0.08448
[32m[0906 19-13-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10947, current rewards: 44.45814, mean: 0.08717
[32m[0906 19-13-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10937, current rewards: 50.01258, mean: 0.08931
[32m[0906 19-13-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10932, current rewards: 55.56019, mean: 0.09108
[32m[0906 19-13-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10932, current rewards: 61.11099, mean: 0.09259
[32m[0906 19-13-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10927, current rewards: 66.66152, mean: 0.09389
[32m[0906 19-13-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10923, current rewards: 72.21653, mean: 0.09502
[32m[0906 19-14-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10924, current rewards: 77.64562, mean: 0.09586
[32m[0906 19-14-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10918, current rewards: 83.02207, mean: 0.09654
[32m[0906 19-14-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10914, current rewards: 88.68808, mean: 0.09746
[32m[0906 19-14-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10913, current rewards: 94.20379, mean: 0.09813
[32m[0906 19-14-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10910, current rewards: 99.60018, mean: 0.09861
[32m[0906 19-14-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10905, current rewards: 105.00364, mean: 0.09906
[32m[0906 19-14-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10903, current rewards: 110.41258, mean: 0.09947
[32m[0906 19-14-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10898, current rewards: 115.81548, mean: 0.09984
[32m[0906 19-14-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10885, current rewards: 121.21561, mean: 0.10018
[32m[0906 19-14-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10870, current rewards: 126.33410, mean: 0.10027
[32m[0906 19-14-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10855, current rewards: 132.16459, mean: 0.10089
[32m[0906 19-15-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10840, current rewards: 137.38531, mean: 0.10102
[32m[0906 19-15-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10829, current rewards: 143.33136, mean: 0.10165
[32m[0906 19-15-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10816, current rewards: 149.27485, mean: 0.10224
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10803, current rewards: 155.20659, mean: 0.10279
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10795, current rewards: 161.15154, mean: 0.10330
[32m[0906 19-15-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10791, current rewards: 167.09762, mean: 0.10379
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10792, current rewards: 173.03890, mean: 0.10424
[32m[0906 19-15-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10794, current rewards: 178.97518, mean: 0.10466
[32m[0906 19-15-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10794, current rewards: 184.76382, mean: 0.10498
[32m[0906 19-15-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10795, current rewards: 191.03082, mean: 0.10554
[32m[0906 19-15-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10798, current rewards: 197.34753, mean: 0.10610
[32m[0906 19-16-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10800, current rewards: 204.10722, mean: 0.10686
[32m[0906 19-16-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10802, current rewards: 210.99230, mean: 0.10765
[32m[0906 19-16-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10804, current rewards: 217.54231, mean: 0.10823
[32m[0906 19-16-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10805, current rewards: 224.32218, mean: 0.10889
[32m[0906 19-16-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10807, current rewards: 230.96185, mean: 0.10946
[32m[0906 19-16-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10806, current rewards: 237.76873, mean: 0.11008
[32m[0906 19-16-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10798, current rewards: 244.41348, mean: 0.11059
[32m[0906 19-16-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10792, current rewards: 251.29323, mean: 0.11119
[32m[0906 19-16-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10785, current rewards: 257.94765, mean: 0.11167
[32m[0906 19-16-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10779, current rewards: 264.74358, mean: 0.11218
[32m[0906 19-16-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10773, current rewards: 271.38520, mean: 0.11261
[32m[0906 19-16-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10766, current rewards: 267.59551, mean: 0.10878
[32m[0906 19-17-03 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 19-17-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-17-04 @MBExp.py:227][0m Rewards obtained: [271.87927909175727], Lows: [5], Highs: [10], Total time: 16144.856481999996
[32m[0906 19-19-21 @MBExp.py:144][0m ####################################################################
[32m[0906 19-19-21 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 19-19-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10786, current rewards: -4.24574, mean: -0.42457
[32m[0906 19-19-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10852, current rewards: 2.17849, mean: 0.03631
[32m[0906 19-19-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10851, current rewards: 6.99017, mean: 0.06355
[32m[0906 19-19-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10885, current rewards: 12.51751, mean: 0.07823
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10900, current rewards: 18.03764, mean: 0.08589
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10973, current rewards: 23.57375, mean: 0.09067
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10962, current rewards: 29.11265, mean: 0.09391
[32m[0906 19-20-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10954, current rewards: 34.63660, mean: 0.09621
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10954, current rewards: 40.17359, mean: 0.09798
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10948, current rewards: 39.97440, mean: 0.08690
[32m[0906 19-20-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10942, current rewards: 47.27093, mean: 0.09269
[32m[0906 19-20-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10938, current rewards: 53.28218, mean: 0.09515
[32m[0906 19-20-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10938, current rewards: 59.29857, mean: 0.09721
[32m[0906 19-20-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10930, current rewards: 65.32304, mean: 0.09897
[32m[0906 19-20-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10932, current rewards: 71.33599, mean: 0.10047
[32m[0906 19-20-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10930, current rewards: 77.35547, mean: 0.10178
[32m[0906 19-20-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10926, current rewards: 83.36230, mean: 0.10292
[32m[0906 19-20-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10927, current rewards: 76.66146, mean: 0.08914
[32m[0906 19-21-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10926, current rewards: 81.93411, mean: 0.09004
[32m[0906 19-21-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10925, current rewards: 86.76510, mean: 0.09038
[32m[0906 19-21-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10927, current rewards: 93.12485, mean: 0.09220
[32m[0906 19-21-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10926, current rewards: 99.47402, mean: 0.09384
[32m[0906 19-21-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10929, current rewards: 105.76983, mean: 0.09529
[32m[0906 19-21-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10928, current rewards: 75.62205, mean: 0.06519
[32m[0906 19-21-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10913, current rewards: 39.13562, mean: 0.03234
[32m[0906 19-21-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10898, current rewards: -7.86301, mean: -0.00624
[32m[0906 19-21-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10887, current rewards: -60.00061, mean: -0.04580
[32m[0906 19-21-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10876, current rewards: -116.83053, mean: -0.08590
[32m[0906 19-21-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10866, current rewards: -158.69966, mean: -0.11255
[32m[0906 19-21-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10856, current rewards: -188.41545, mean: -0.12905
[32m[0906 19-22-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10845, current rewards: -222.12217, mean: -0.14710
[32m[0906 19-22-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10834, current rewards: -267.37714, mean: -0.17140
[32m[0906 19-22-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10834, current rewards: -292.77382, mean: -0.18185
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10836, current rewards: -287.88003, mean: -0.17342
[32m[0906 19-22-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10837, current rewards: -282.98649, mean: -0.16549
[32m[0906 19-22-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10842, current rewards: -278.08966, mean: -0.15801
[32m[0906 19-22-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10842, current rewards: -273.19480, mean: -0.15094
[32m[0906 19-22-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10844, current rewards: -268.30685, mean: -0.14425
[32m[0906 19-22-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10846, current rewards: -270.20284, mean: -0.14147
[32m[0906 19-22-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10846, current rewards: -264.62952, mean: -0.13502
[32m[0906 19-22-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10847, current rewards: -259.06324, mean: -0.12889
[32m[0906 19-23-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10849, current rewards: -253.49649, mean: -0.12306
[32m[0906 19-23-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10848, current rewards: -247.93194, mean: -0.11750
[32m[0906 19-23-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10845, current rewards: -242.55950, mean: -0.11230
[32m[0906 19-23-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10838, current rewards: -236.87350, mean: -0.10718
[32m[0906 19-23-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10830, current rewards: -231.17818, mean: -0.10229
[32m[0906 19-23-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10823, current rewards: -225.49027, mean: -0.09761
[32m[0906 19-23-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10817, current rewards: -219.79282, mean: -0.09313
[32m[0906 19-23-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10810, current rewards: -214.09739, mean: -0.08884
[32m[0906 19-23-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10804, current rewards: -208.40462, mean: -0.08472
[32m[0906 19-23-51 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 19-23-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-23-51 @MBExp.py:227][0m Rewards obtained: [-203.8548792268957], Lows: [233], Highs: [21], Total time: 16415.748394999995
[32m[0906 19-26-11 @MBExp.py:144][0m ####################################################################
[32m[0906 19-26-11 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 19-26-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11037, current rewards: -5.39323, mean: -0.53932
[32m[0906 19-26-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10946, current rewards: -0.29399, mean: -0.00490
[32m[0906 19-26-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10932, current rewards: 5.48747, mean: 0.04989
[32m[0906 19-26-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10953, current rewards: 11.27325, mean: 0.07046
[32m[0906 19-26-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10943, current rewards: 17.05973, mean: 0.08124
[32m[0906 19-26-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10956, current rewards: 22.84756, mean: 0.08788
[32m[0906 19-26-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10958, current rewards: 28.63410, mean: 0.09237
[32m[0906 19-26-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10955, current rewards: 34.42154, mean: 0.09562
[32m[0906 19-26-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10950, current rewards: 40.20925, mean: 0.09807
[32m[0906 19-27-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10955, current rewards: 45.99609, mean: 0.09999
[32m[0906 19-27-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10953, current rewards: 51.78034, mean: 0.10153
[32m[0906 19-27-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10950, current rewards: 50.98827, mean: 0.09105
[32m[0906 19-27-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10953, current rewards: 56.60942, mean: 0.09280
[32m[0906 19-27-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10948, current rewards: 62.23294, mean: 0.09429
[32m[0906 19-27-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10945, current rewards: 67.85582, mean: 0.09557
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10956, current rewards: 73.47558, mean: 0.09668
[32m[0906 19-27-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10958, current rewards: 79.09323, mean: 0.09765
[32m[0906 19-27-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10954, current rewards: 84.40069, mean: 0.09814
[32m[0906 19-27-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10953, current rewards: 89.86074, mean: 0.09875
[32m[0906 19-27-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10949, current rewards: 95.36195, mean: 0.09934
[32m[0906 19-28-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10950, current rewards: 100.86710, mean: 0.09987
[32m[0906 19-28-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10950, current rewards: 106.37264, mean: 0.10035
[32m[0906 19-28-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10944, current rewards: 111.87375, mean: 0.10079
[32m[0906 19-28-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10926, current rewards: 117.37524, mean: 0.10119
[32m[0906 19-28-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10913, current rewards: 122.88087, mean: 0.10155
[32m[0906 19-28-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10898, current rewards: 114.37545, mean: 0.09077
[32m[0906 19-28-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10883, current rewards: 120.98130, mean: 0.09235
[32m[0906 19-28-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10871, current rewards: 128.92655, mean: 0.09480
[32m[0906 19-28-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10859, current rewards: 136.88192, mean: 0.09708
[32m[0906 19-28-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10850, current rewards: 144.82378, mean: 0.09919
[32m[0906 19-28-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10841, current rewards: 152.76115, mean: 0.10117
[32m[0906 19-29-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10830, current rewards: 160.70387, mean: 0.10302
[32m[0906 19-29-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10831, current rewards: 168.64047, mean: 0.10475
[32m[0906 19-29-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10833, current rewards: 176.60989, mean: 0.10639
[32m[0906 19-29-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10834, current rewards: 173.56939, mean: 0.10150
[32m[0906 19-29-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10837, current rewards: 179.15909, mean: 0.10179
[32m[0906 19-29-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10840, current rewards: 184.74876, mean: 0.10207
[32m[0906 19-29-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10841, current rewards: 190.34053, mean: 0.10233
[32m[0906 19-29-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10843, current rewards: 195.93380, mean: 0.10258
[32m[0906 19-29-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10844, current rewards: 201.52287, mean: 0.10282
[32m[0906 19-29-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10846, current rewards: 207.11587, mean: 0.10304
[32m[0906 19-29-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10848, current rewards: 212.70702, mean: 0.10326
[32m[0906 19-30-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10849, current rewards: 212.54211, mean: 0.10073
[32m[0906 19-30-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10847, current rewards: 218.22133, mean: 0.10103
[32m[0906 19-30-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10840, current rewards: 223.91755, mean: 0.10132
[32m[0906 19-30-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10833, current rewards: 229.61216, mean: 0.10160
[32m[0906 19-30-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10827, current rewards: 235.31768, mean: 0.10187
[32m[0906 19-30-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10821, current rewards: 241.01747, mean: 0.10213
[32m[0906 19-30-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10815, current rewards: 246.72124, mean: 0.10237
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10809, current rewards: 252.42264, mean: 0.10261
[32m[0906 19-30-42 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 19-30-42 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-30-42 @MBExp.py:227][0m Rewards obtained: [256.9860835716495], Lows: [14], Highs: [16], Total time: 16686.824903999994
[32m[0906 19-33-04 @MBExp.py:144][0m ####################################################################
[32m[0906 19-33-04 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 19-33-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11145, current rewards: -5.76674, mean: -0.57667
[32m[0906 19-33-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10929, current rewards: -0.70132, mean: -0.01169
[32m[0906 19-33-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10927, current rewards: 4.83864, mean: 0.04399
[32m[0906 19-33-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10945, current rewards: 10.37700, mean: 0.06486
[32m[0906 19-33-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10886, current rewards: 15.91230, mean: 0.07577
[32m[0906 19-33-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10906, current rewards: 21.45362, mean: 0.08251
[32m[0906 19-33-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10918, current rewards: 26.99412, mean: 0.08708
[32m[0906 19-33-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10926, current rewards: 32.53501, mean: 0.09038
[32m[0906 19-33-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10928, current rewards: 38.07725, mean: 0.09287
[32m[0906 19-33-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10936, current rewards: 34.78439, mean: 0.07562
[32m[0906 19-34-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10936, current rewards: 40.44302, mean: 0.07930
[32m[0906 19-34-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10932, current rewards: 46.10384, mean: 0.08233
[32m[0906 19-34-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10933, current rewards: 51.76420, mean: 0.08486
[32m[0906 19-34-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10932, current rewards: 57.42126, mean: 0.08700
[32m[0906 19-34-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10929, current rewards: 63.08400, mean: 0.08885
[32m[0906 19-34-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10931, current rewards: 68.74463, mean: 0.09045
[32m[0906 19-34-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10925, current rewards: 74.40471, mean: 0.09186
[32m[0906 19-34-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10920, current rewards: 80.50549, mean: 0.09361
[32m[0906 19-34-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10918, current rewards: 86.18892, mean: 0.09471
[32m[0906 19-34-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10911, current rewards: 91.87186, mean: 0.09570
[32m[0906 19-34-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10907, current rewards: 97.55449, mean: 0.09659
[32m[0906 19-35-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10908, current rewards: 96.63087, mean: 0.09116
[32m[0906 19-35-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10897, current rewards: 102.51769, mean: 0.09236
[32m[0906 19-35-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10879, current rewards: 108.40152, mean: 0.09345
[32m[0906 19-35-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10869, current rewards: 114.28666, mean: 0.09445
[32m[0906 19-35-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10857, current rewards: 120.11443, mean: 0.09533
[32m[0906 19-35-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10844, current rewards: 103.17538, mean: 0.07876
[32m[0906 19-35-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10835, current rewards: 93.10657, mean: 0.06846
[32m[0906 19-35-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10824, current rewards: 80.90868, mean: 0.05738
[32m[0906 19-35-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10813, current rewards: 70.83231, mean: 0.04852
[32m[0906 19-35-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10807, current rewards: 60.75585, mean: 0.04024
[32m[0906 19-35-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10799, current rewards: 48.57808, mean: 0.03114
[32m[0906 19-35-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10801, current rewards: 38.51042, mean: 0.02392
[32m[0906 19-36-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10807, current rewards: 28.43026, mean: 0.01713
[32m[0906 19-36-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10810, current rewards: 30.59072, mean: 0.01789
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10812, current rewards: 36.45242, mean: 0.02071
[32m[0906 19-36-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10815, current rewards: 42.30673, mean: 0.02337
[32m[0906 19-36-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10816, current rewards: 37.41113, mean: 0.02011
[32m[0906 19-36-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10816, current rewards: 43.01330, mean: 0.02252
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10818, current rewards: 48.61019, mean: 0.02480
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10819, current rewards: 54.20917, mean: 0.02697
[32m[0906 19-36-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10819, current rewards: 59.80846, mean: 0.02903
[32m[0906 19-36-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10822, current rewards: 66.31475, mean: 0.03143
[32m[0906 19-36-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10819, current rewards: 71.89741, mean: 0.03329
[32m[0906 19-37-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10812, current rewards: 77.48105, mean: 0.03506
[32m[0906 19-37-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10806, current rewards: 83.06198, mean: 0.03675
[32m[0906 19-37-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10798, current rewards: 88.64815, mean: 0.03838
[32m[0906 19-37-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10792, current rewards: 88.94935, mean: 0.03769
[32m[0906 19-37-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10785, current rewards: 94.61204, mean: 0.03926
[32m[0906 19-37-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10782, current rewards: 100.26575, mean: 0.04076
[32m[0906 19-37-35 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 19-37-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-37-35 @MBExp.py:227][0m Rewards obtained: [104.78993579088274], Lows: [80], Highs: [21], Total time: 16957.240282999992
[32m[0906 19-39-59 @MBExp.py:144][0m ####################################################################
[32m[0906 19-39-59 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 19-40-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10955, current rewards: -14.00000, mean: -1.40000
[32m[0906 19-40-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10926, current rewards: -12.73271, mean: -0.21221
[32m[0906 19-40-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10916, current rewards: -7.25018, mean: -0.06591
[32m[0906 19-40-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10889, current rewards: -1.76077, mean: -0.01100
[32m[0906 19-40-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10802, current rewards: 3.72730, mean: 0.01775
[32m[0906 19-40-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10822, current rewards: 9.21320, mean: 0.03544
[32m[0906 19-40-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10843, current rewards: 14.69699, mean: 0.04741
[32m[0906 19-40-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10864, current rewards: 7.23473, mean: 0.02010
[32m[0906 19-40-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10867, current rewards: 12.17613, mean: 0.02970
[32m[0906 19-40-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10877, current rewards: 17.08626, mean: 0.03714
[32m[0906 19-40-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10877, current rewards: 21.97229, mean: 0.04308
[32m[0906 19-41-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10881, current rewards: 26.85925, mean: 0.04796
[32m[0906 19-41-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10885, current rewards: 31.74818, mean: 0.05205
[32m[0906 19-41-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10885, current rewards: 36.63859, mean: 0.05551
[32m[0906 19-41-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10884, current rewards: 41.52507, mean: 0.05849
[32m[0906 19-41-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10890, current rewards: 46.40751, mean: 0.06106
[32m[0906 19-41-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10892, current rewards: 51.31432, mean: 0.06335
[32m[0906 19-41-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10893, current rewards: 46.43453, mean: 0.05399
[32m[0906 19-41-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10898, current rewards: 52.01544, mean: 0.05716
[32m[0906 19-41-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10899, current rewards: 57.59214, mean: 0.05999
[32m[0906 19-41-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10899, current rewards: 63.16977, mean: 0.06254
[32m[0906 19-41-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10897, current rewards: 68.74735, mean: 0.06486
[32m[0906 19-42-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10882, current rewards: 74.32608, mean: 0.06696
[32m[0906 19-42-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10869, current rewards: 70.00802, mean: 0.06035
[32m[0906 19-42-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10859, current rewards: 75.55730, mean: 0.06244
[32m[0906 19-42-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10846, current rewards: 81.04162, mean: 0.06432
[32m[0906 19-42-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10833, current rewards: 86.58186, mean: 0.06609
[32m[0906 19-42-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10823, current rewards: 92.12199, mean: 0.06774
[32m[0906 19-42-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10814, current rewards: 97.66711, mean: 0.06927
[32m[0906 19-42-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10805, current rewards: 102.09799, mean: 0.06993
[32m[0906 19-42-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10799, current rewards: 103.36495, mean: 0.06845
[32m[0906 19-42-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10798, current rewards: 108.98859, mean: 0.06986
[32m[0906 19-42-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10802, current rewards: 114.61410, mean: 0.07119
[32m[0906 19-42-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10807, current rewards: 120.23889, mean: 0.07243
[32m[0906 19-43-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10810, current rewards: 125.86181, mean: 0.07360
[32m[0906 19-43-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10814, current rewards: 131.48099, mean: 0.07471
[32m[0906 19-43-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10816, current rewards: 137.09975, mean: 0.07575
[32m[0906 19-43-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10820, current rewards: 142.71715, mean: 0.07673
[32m[0906 19-43-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10824, current rewards: 148.33800, mean: 0.07766
[32m[0906 19-43-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10826, current rewards: 143.65964, mean: 0.07330
[32m[0906 19-43-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10829, current rewards: 149.25635, mean: 0.07426
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10832, current rewards: 154.25454, mean: 0.07488
[32m[0906 19-43-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10834, current rewards: 159.85818, mean: 0.07576
[32m[0906 19-43-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10832, current rewards: 165.29317, mean: 0.07652
[32m[0906 19-43-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10828, current rewards: 170.85138, mean: 0.07731
[32m[0906 19-44-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10822, current rewards: 176.41346, mean: 0.07806
[32m[0906 19-44-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10817, current rewards: 181.97304, mean: 0.07878
[32m[0906 19-44-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10813, current rewards: 187.53426, mean: 0.07946
[32m[0906 19-44-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10807, current rewards: 193.09645, mean: 0.08012
[32m[0906 19-44-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10807, current rewards: 198.59444, mean: 0.08073
[32m[0906 19-44-30 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 19-44-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-44-30 @MBExp.py:227][0m Rewards obtained: [203.05499607205465], Lows: [22], Highs: [21], Total time: 17228.30195499999
[32m[0906 19-46-58 @MBExp.py:144][0m ####################################################################
[32m[0906 19-46-58 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 19-46-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10959, current rewards: -3.75913, mean: -0.37591
[32m[0906 19-47-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10943, current rewards: -42.75208, mean: -0.71253
[32m[0906 19-47-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10971, current rewards: -88.54446, mean: -0.80495
[32m[0906 19-47-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10890, current rewards: -132.25306, mean: -0.82658
[32m[0906 19-47-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10822, current rewards: -178.14715, mean: -0.84832
[32m[0906 19-47-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10857, current rewards: -223.87952, mean: -0.86108
[32m[0906 19-47-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10894, current rewards: -269.35276, mean: -0.86888
[32m[0906 19-47-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10929, current rewards: -327.69233, mean: -0.91026
[32m[0906 19-47-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10938, current rewards: -386.33970, mean: -0.94229
[32m[0906 19-47-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10938, current rewards: -427.84500, mean: -0.93010
[32m[0906 19-47-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10937, current rewards: -471.93486, mean: -0.92536
[32m[0906 19-47-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10940, current rewards: -517.95685, mean: -0.92492
[32m[0906 19-48-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10937, current rewards: -516.09574, mean: -0.84606
[32m[0906 19-48-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10933, current rewards: -509.97600, mean: -0.77269
[32m[0906 19-48-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10938, current rewards: -503.85646, mean: -0.70966
[32m[0906 19-48-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10937, current rewards: -497.73605, mean: -0.65492
[32m[0906 19-48-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10938, current rewards: -491.67543, mean: -0.60701
[32m[0906 19-48-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10943, current rewards: -485.52240, mean: -0.56456
[32m[0906 19-48-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10942, current rewards: -479.37398, mean: -0.52678
[32m[0906 19-48-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10944, current rewards: -473.22751, mean: -0.49295
[32m[0906 19-48-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10947, current rewards: -467.07724, mean: -0.46245
[32m[0906 19-48-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10929, current rewards: -461.28333, mean: -0.43517
[32m[0906 19-48-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10914, current rewards: -455.32494, mean: -0.41020
[32m[0906 19-49-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10901, current rewards: -449.35395, mean: -0.38737
[32m[0906 19-49-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10889, current rewards: -442.88234, mean: -0.36602
[32m[0906 19-49-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10876, current rewards: -436.97358, mean: -0.34680
[32m[0906 19-49-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10869, current rewards: -431.06525, mean: -0.32906
[32m[0906 19-49-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10859, current rewards: -436.51932, mean: -0.32097
[32m[0906 19-49-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10849, current rewards: -430.80508, mean: -0.30554
[32m[0906 19-49-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10842, current rewards: -425.09311, mean: -0.29116
[32m[0906 19-49-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10832, current rewards: -419.37723, mean: -0.27773
[32m[0906 19-49-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10829, current rewards: -413.66244, mean: -0.26517
[32m[0906 19-49-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10836, current rewards: -407.73542, mean: -0.25325
[32m[0906 19-49-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10839, current rewards: -401.90204, mean: -0.24211
[32m[0906 19-50-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10842, current rewards: -396.14577, mean: -0.23166
[32m[0906 19-50-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10845, current rewards: -390.38786, mean: -0.22181
[32m[0906 19-50-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10847, current rewards: -384.62733, mean: -0.21250
[32m[0906 19-50-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10852, current rewards: -388.33027, mean: -0.20878
[32m[0906 19-50-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10856, current rewards: -382.01477, mean: -0.20001
[32m[0906 19-50-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10859, current rewards: -375.69927, mean: -0.19168
[32m[0906 19-50-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10863, current rewards: -369.40681, mean: -0.18378
[32m[0906 19-50-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10865, current rewards: -363.26008, mean: -0.17634
[32m[0906 19-50-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10868, current rewards: -408.07663, mean: -0.19340
[32m[0906 19-50-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10869, current rewards: -455.79226, mean: -0.21101
[32m[0906 19-50-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10864, current rewards: -505.67069, mean: -0.22881
[32m[0906 19-51-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10858, current rewards: -553.05763, mean: -0.24472
[32m[0906 19-51-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10854, current rewards: -602.96516, mean: -0.26102
[32m[0906 19-51-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10847, current rewards: -643.60430, mean: -0.27271
[32m[0906 19-51-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10842, current rewards: -673.46782, mean: -0.27945
[32m[0906 19-51-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10845, current rewards: -702.34709, mean: -0.28551
[32m[0906 19-51-30 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 19-51-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-51-30 @MBExp.py:227][0m Rewards obtained: [-737.3598243041099], Lows: [525], Highs: [11], Total time: 17500.29530099999
[32m[0906 19-53-59 @MBExp.py:144][0m ####################################################################
[32m[0906 19-53-59 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 19-54-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11413, current rewards: -14.00000, mean: -1.40000
[32m[0906 19-54-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11053, current rewards: -26.41179, mean: -0.44020
[32m[0906 19-54-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10980, current rewards: -15.85562, mean: -0.14414
[32m[0906 19-54-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10887, current rewards: -5.33794, mean: -0.03336
[32m[0906 19-54-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10830, current rewards: 5.16559, mean: 0.02460
[32m[0906 19-54-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10846, current rewards: 15.60570, mean: 0.06002
[32m[0906 19-54-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10865, current rewards: 26.07390, mean: 0.08411
[32m[0906 19-54-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10883, current rewards: 18.25037, mean: 0.05070
[32m[0906 19-54-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10889, current rewards: 15.43211, mean: 0.03764
[32m[0906 19-54-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10898, current rewards: 24.98964, mean: 0.05433
[32m[0906 19-54-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10908, current rewards: 34.63927, mean: 0.06792
[32m[0906 19-55-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10914, current rewards: 44.28296, mean: 0.07908
[32m[0906 19-55-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10916, current rewards: 53.92803, mean: 0.08841
[32m[0906 19-55-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10920, current rewards: 63.57849, mean: 0.09633
[32m[0906 19-55-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10918, current rewards: 64.34918, mean: 0.09063
[32m[0906 19-55-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10923, current rewards: 69.98647, mean: 0.09209
[32m[0906 19-55-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10929, current rewards: 75.47149, mean: 0.09317
[32m[0906 19-55-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10929, current rewards: 81.20591, mean: 0.09443
[32m[0906 19-55-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10928, current rewards: 86.93362, mean: 0.09553
[32m[0906 19-55-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10932, current rewards: 92.66554, mean: 0.09653
[32m[0906 19-55-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10915, current rewards: 98.39530, mean: 0.09742
[32m[0906 19-55-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10898, current rewards: 104.12178, mean: 0.09823
[32m[0906 19-56-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10886, current rewards: 109.84700, mean: 0.09896
[32m[0906 19-56-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10872, current rewards: 104.84894, mean: 0.09039
[32m[0906 19-56-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10859, current rewards: 109.91275, mean: 0.09084
[32m[0906 19-56-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10850, current rewards: 115.46299, mean: 0.09164
[32m[0906 19-56-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10839, current rewards: 121.01008, mean: 0.09237
[32m[0906 19-56-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10830, current rewards: 126.56208, mean: 0.09306
[32m[0906 19-56-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10822, current rewards: 132.11041, mean: 0.09370
[32m[0906 19-56-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10813, current rewards: 137.65820, mean: 0.09429
[32m[0906 19-56-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10806, current rewards: 137.19888, mean: 0.09086
[32m[0906 19-56-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10800, current rewards: 143.26357, mean: 0.09184
[32m[0906 19-56-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10803, current rewards: 149.37885, mean: 0.09278
[32m[0906 19-56-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10809, current rewards: 155.44285, mean: 0.09364
[32m[0906 19-57-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10814, current rewards: 161.50833, mean: 0.09445
[32m[0906 19-57-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10817, current rewards: 167.56906, mean: 0.09521
[32m[0906 19-57-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10822, current rewards: 173.62847, mean: 0.09593
[32m[0906 19-57-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10826, current rewards: 179.69668, mean: 0.09661
[32m[0906 19-57-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10828, current rewards: 185.76692, mean: 0.09726
[32m[0906 19-57-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10834, current rewards: 191.82363, mean: 0.09787
[32m[0906 19-57-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10839, current rewards: 199.21311, mean: 0.09911
[32m[0906 19-57-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10841, current rewards: 206.03772, mean: 0.10002
[32m[0906 19-57-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10845, current rewards: 214.00218, mean: 0.10142
[32m[0906 19-57-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10844, current rewards: 221.96470, mean: 0.10276
[32m[0906 19-57-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10839, current rewards: 229.93415, mean: 0.10404
[32m[0906 19-58-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10835, current rewards: 237.89198, mean: 0.10526
[32m[0906 19-58-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10829, current rewards: 245.84440, mean: 0.10643
[32m[0906 19-58-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10823, current rewards: 253.79751, mean: 0.10754
[32m[0906 19-58-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10821, current rewards: 261.77051, mean: 0.10862
[32m[0906 19-58-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10824, current rewards: 268.36216, mean: 0.10909
[32m[0906 19-58-30 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 19-58-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-58-30 @MBExp.py:227][0m Rewards obtained: [277.02368150284553], Lows: [36], Highs: [18], Total time: 17771.75593299999
[32m[0906 20-01-02 @MBExp.py:144][0m ####################################################################
[32m[0906 20-01-02 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 20-01-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12030, current rewards: -11.94092, mean: -1.19409
[32m[0906 20-01-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11158, current rewards: -6.42048, mean: -0.10701
[32m[0906 20-01-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11021, current rewards: -1.04216, mean: -0.00947
[32m[0906 20-01-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10884, current rewards: 4.33521, mean: 0.02710
[32m[0906 20-01-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10806, current rewards: 9.71556, mean: 0.04626
[32m[0906 20-01-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10827, current rewards: 15.09411, mean: 0.05805
[32m[0906 20-01-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10839, current rewards: 20.47327, mean: 0.06604
[32m[0906 20-01-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10854, current rewards: 25.85159, mean: 0.07181
[32m[0906 20-01-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10869, current rewards: 20.75734, mean: 0.05063
[32m[0906 20-01-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10875, current rewards: 26.74310, mean: 0.05814
[32m[0906 20-01-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10882, current rewards: 32.72456, mean: 0.06417
[32m[0906 20-02-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10891, current rewards: 38.70902, mean: 0.06912
[32m[0906 20-02-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10893, current rewards: 44.68829, mean: 0.07326
[32m[0906 20-02-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10893, current rewards: 50.67502, mean: 0.07678
[32m[0906 20-02-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10897, current rewards: 56.65600, mean: 0.07980
[32m[0906 20-02-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10899, current rewards: 62.42386, mean: 0.08214
[32m[0906 20-02-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10898, current rewards: 68.34301, mean: 0.08437
[32m[0906 20-02-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10901, current rewards: 74.30823, mean: 0.08640
[32m[0906 20-02-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10907, current rewards: 60.37338, mean: 0.06634
[32m[0906 20-02-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10906, current rewards: 64.96817, mean: 0.06768
[32m[0906 20-02-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10906, current rewards: 69.56221, mean: 0.06887
[32m[0906 20-02-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10888, current rewards: 74.15024, mean: 0.06995
[32m[0906 20-03-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10873, current rewards: 78.74150, mean: 0.07094
[32m[0906 20-03-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10862, current rewards: 83.33102, mean: 0.07184
[32m[0906 20-03-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10849, current rewards: 88.33320, mean: 0.07300
[32m[0906 20-03-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10836, current rewards: 92.70382, mean: 0.07357
[32m[0906 20-03-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10828, current rewards: 97.07255, mean: 0.07410
[32m[0906 20-03-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10818, current rewards: 101.43597, mean: 0.07459
[32m[0906 20-03-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10809, current rewards: 107.33758, mean: 0.07613
[32m[0906 20-03-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10803, current rewards: 112.73178, mean: 0.07721
[32m[0906 20-03-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10796, current rewards: 118.13043, mean: 0.07823
[32m[0906 20-03-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10789, current rewards: 123.52991, mean: 0.07919
[32m[0906 20-03-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10797, current rewards: 128.92417, mean: 0.08008
[32m[0906 20-04-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10802, current rewards: 134.32253, mean: 0.08092
[32m[0906 20-04-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10804, current rewards: 139.71952, mean: 0.08171
[32m[0906 20-04-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10808, current rewards: 145.11101, mean: 0.08245
[32m[0906 20-04-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10819, current rewards: 139.96276, mean: 0.07733
[32m[0906 20-04-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10822, current rewards: 145.44090, mean: 0.07819
[32m[0906 20-04-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10827, current rewards: 150.91828, mean: 0.07901
[32m[0906 20-04-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10830, current rewards: 156.39866, mean: 0.07980
[32m[0906 20-04-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10832, current rewards: 161.98562, mean: 0.08059
[32m[0906 20-04-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10836, current rewards: 167.46921, mean: 0.08130
[32m[0906 20-04-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10838, current rewards: 162.49090, mean: 0.07701
[32m[0906 20-04-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10839, current rewards: 168.19494, mean: 0.07787
[32m[0906 20-05-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10834, current rewards: 173.90211, mean: 0.07869
[32m[0906 20-05-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10827, current rewards: 179.61237, mean: 0.07947
[32m[0906 20-05-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10822, current rewards: 185.31606, mean: 0.08022
[32m[0906 20-05-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10818, current rewards: 191.02509, mean: 0.08094
[32m[0906 20-05-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10813, current rewards: 196.37983, mean: 0.08149
[32m[0906 20-05-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10809, current rewards: 202.10620, mean: 0.08216
[32m[0906 20-05-33 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 20-05-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-05-33 @MBExp.py:227][0m Rewards obtained: [206.68536633187395], Lows: [24], Highs: [12], Total time: 18042.87633699999
[32m[0906 20-08-07 @MBExp.py:144][0m ####################################################################
[32m[0906 20-08-07 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 20-08-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10787, current rewards: -2.61674, mean: -0.26167
[32m[0906 20-08-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10909, current rewards: 4.57461, mean: 0.07624
[32m[0906 20-08-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10802, current rewards: 12.87473, mean: 0.11704
[32m[0906 20-08-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10717, current rewards: 21.17485, mean: 0.13234
[32m[0906 20-08-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10680, current rewards: 29.47497, mean: 0.14036
[32m[0906 20-08-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10690, current rewards: 37.77509, mean: 0.14529
[32m[0906 20-08-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10732, current rewards: 46.07521, mean: 0.14863
[32m[0906 20-08-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10764, current rewards: 36.03939, mean: 0.10011
[32m[0906 20-08-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10784, current rewards: -13.96061, mean: -0.03405
[32m[0906 20-08-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10805, current rewards: -63.96061, mean: -0.13904
[32m[0906 20-09-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10814, current rewards: -113.96061, mean: -0.22345
[32m[0906 20-09-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10819, current rewards: -163.96061, mean: -0.29279
[32m[0906 20-09-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10836, current rewards: -213.96061, mean: -0.35076
[32m[0906 20-09-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10844, current rewards: -263.96061, mean: -0.39994
[32m[0906 20-09-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10846, current rewards: -313.96061, mean: -0.44220
[32m[0906 20-09-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10850, current rewards: -363.96061, mean: -0.47890
[32m[0906 20-09-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10852, current rewards: -413.96061, mean: -0.51106
[32m[0906 20-09-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10856, current rewards: -463.96061, mean: -0.53949
[32m[0906 20-09-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10859, current rewards: -513.96061, mean: -0.56479
[32m[0906 20-09-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10859, current rewards: -563.96061, mean: -0.58746
[32m[0906 20-09-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10845, current rewards: -613.96061, mean: -0.60788
[32m[0906 20-10-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10832, current rewards: -663.96061, mean: -0.62638
[32m[0906 20-10-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10817, current rewards: -713.96061, mean: -0.64321
[32m[0906 20-10-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10803, current rewards: -763.96061, mean: -0.65859
[32m[0906 20-10-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10791, current rewards: -813.96061, mean: -0.67269
[32m[0906 20-10-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10778, current rewards: -863.96061, mean: -0.68568
[32m[0906 20-10-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10766, current rewards: -913.96061, mean: -0.69768
[32m[0906 20-10-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10757, current rewards: -963.96061, mean: -0.70879
[32m[0906 20-10-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10748, current rewards: -1013.96061, mean: -0.71912
[32m[0906 20-10-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10740, current rewards: -1063.96061, mean: -0.72874
[32m[0906 20-10-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10734, current rewards: -1113.96061, mean: -0.73772
[32m[0906 20-10-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10726, current rewards: -1163.96061, mean: -0.74613
[32m[0906 20-11-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10729, current rewards: -1213.96061, mean: -0.75401
[32m[0906 20-11-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10734, current rewards: -1263.96061, mean: -0.76142
[32m[0906 20-11-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10737, current rewards: -1313.96061, mean: -0.76840
[32m[0906 20-11-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10740, current rewards: -1363.96061, mean: -0.77498
[32m[0906 20-11-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10745, current rewards: -1413.96061, mean: -0.78119
[32m[0906 20-11-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10748, current rewards: -1463.96061, mean: -0.78708
[32m[0906 20-11-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10751, current rewards: -1513.96061, mean: -0.79265
[32m[0906 20-11-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10755, current rewards: -1563.96061, mean: -0.79794
[32m[0906 20-11-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10757, current rewards: -1613.96061, mean: -0.80297
[32m[0906 20-11-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10759, current rewards: -1663.96061, mean: -0.80775
[32m[0906 20-11-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10764, current rewards: -1713.96061, mean: -0.81230
[32m[0906 20-12-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10766, current rewards: -1763.96061, mean: -0.81665
[32m[0906 20-12-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10760, current rewards: -1813.96061, mean: -0.82080
[32m[0906 20-12-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10755, current rewards: -1863.96061, mean: -0.82476
[32m[0906 20-12-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10749, current rewards: -1913.96061, mean: -0.82855
[32m[0906 20-12-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10744, current rewards: -1963.96061, mean: -0.83219
[32m[0906 20-12-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10740, current rewards: -2013.96061, mean: -0.83567
[32m[0906 20-12-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10738, current rewards: -2063.96061, mean: -0.83901
[32m[0906 20-12-36 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 20-12-36 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-12-36 @MBExp.py:227][0m Rewards obtained: [-2103.960614070991], Lows: [0], Highs: [2158], Total time: 18312.20107299999
[32m[0906 20-15-11 @MBExp.py:144][0m ####################################################################
[32m[0906 20-15-11 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 20-15-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10760, current rewards: -6.25145, mean: -0.62514
[32m[0906 20-15-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10786, current rewards: -0.45750, mean: -0.00763
[32m[0906 20-15-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10652, current rewards: 5.28586, mean: 0.04805
[32m[0906 20-15-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10598, current rewards: 11.02830, mean: 0.06893
[32m[0906 20-15-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10575, current rewards: 16.77046, mean: 0.07986
[32m[0906 20-15-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10604, current rewards: 22.51456, mean: 0.08659
[32m[0906 20-15-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10647, current rewards: 28.25368, mean: 0.09114
[32m[0906 20-15-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10686, current rewards: 33.95103, mean: 0.09431
[32m[0906 20-15-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10706, current rewards: 39.69704, mean: 0.09682
[32m[0906 20-16-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10723, current rewards: 45.43768, mean: 0.09878
[32m[0906 20-16-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10738, current rewards: 51.18915, mean: 0.10037
[32m[0906 20-16-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10747, current rewards: 43.99754, mean: 0.07857
[32m[0906 20-16-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10752, current rewards: 49.76187, mean: 0.08158
[32m[0906 20-16-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10759, current rewards: 55.50654, mean: 0.08410
[32m[0906 20-16-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10760, current rewards: 61.24349, mean: 0.08626
[32m[0906 20-16-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10763, current rewards: 67.15123, mean: 0.08836
[32m[0906 20-16-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10770, current rewards: 72.88992, mean: 0.08999
[32m[0906 20-16-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10772, current rewards: 78.62699, mean: 0.09143
[32m[0906 20-16-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10773, current rewards: 84.36384, mean: 0.09271
[32m[0906 20-16-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10767, current rewards: 90.09535, mean: 0.09385
[32m[0906 20-17-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10752, current rewards: 91.92640, mean: 0.09102
[32m[0906 20-17-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10738, current rewards: 96.58146, mean: 0.09111
[32m[0906 20-17-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10728, current rewards: 101.24126, mean: 0.09121
[32m[0906 20-17-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10715, current rewards: 105.74859, mean: 0.09116
[32m[0906 20-17-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10705, current rewards: 110.36824, mean: 0.09121
[32m[0906 20-17-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10696, current rewards: 114.98134, mean: 0.09126
[32m[0906 20-17-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10689, current rewards: 119.59696, mean: 0.09130
[32m[0906 20-17-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10685, current rewards: 124.21293, mean: 0.09133
[32m[0906 20-17-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10681, current rewards: 128.82823, mean: 0.09137
[32m[0906 20-17-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10676, current rewards: 133.44089, mean: 0.09140
[32m[0906 20-17-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10668, current rewards: 138.05948, mean: 0.09143
[32m[0906 20-17-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10667, current rewards: 128.46200, mean: 0.08235
[32m[0906 20-18-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10673, current rewards: 134.23542, mean: 0.08338
[32m[0906 20-18-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10677, current rewards: 140.02520, mean: 0.08435
[32m[0906 20-18-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10684, current rewards: 145.81409, mean: 0.08527
[32m[0906 20-18-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10687, current rewards: 151.60462, mean: 0.08614
[32m[0906 20-18-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10692, current rewards: 157.39331, mean: 0.08696
[32m[0906 20-18-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10699, current rewards: 163.18382, mean: 0.08773
[32m[0906 20-18-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10702, current rewards: 168.97536, mean: 0.08847
[32m[0906 20-18-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10705, current rewards: 175.32043, mean: 0.08945
[32m[0906 20-18-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10710, current rewards: 181.10110, mean: 0.09010
[32m[0906 20-18-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10712, current rewards: 181.13884, mean: 0.08793
[32m[0906 20-18-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10716, current rewards: 186.95960, mean: 0.08861
[32m[0906 20-19-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10720, current rewards: 192.77892, mean: 0.08925
[32m[0906 20-19-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10716, current rewards: 198.60842, mean: 0.08987
[32m[0906 20-19-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10711, current rewards: 204.42979, mean: 0.09046
[32m[0906 20-19-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10708, current rewards: 210.25676, mean: 0.09102
[32m[0906 20-19-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10703, current rewards: 215.97486, mean: 0.09151
[32m[0906 20-19-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10699, current rewards: 221.18736, mean: 0.09178
[32m[0906 20-19-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10705, current rewards: 210.94898, mean: 0.08575
[32m[0906 20-19-40 @Agent.py:117][0m Average action selection time: 0.1071
[32m[0906 20-19-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-19-40 @MBExp.py:227][0m Rewards obtained: [214.53017579659658], Lows: [20], Highs: [17], Total time: 18580.69899899999
[32m[0906 20-22-17 @MBExp.py:144][0m ####################################################################
[32m[0906 20-22-17 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 20-22-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11434, current rewards: -4.58661, mean: -0.45866
[32m[0906 20-22-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10665, current rewards: 1.67389, mean: 0.02790
[32m[0906 20-22-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10617, current rewards: 7.82729, mean: 0.07116
[32m[0906 20-22-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10579, current rewards: 13.96714, mean: 0.08729
[32m[0906 20-22-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10549, current rewards: 20.11095, mean: 0.09577
[32m[0906 20-22-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10576, current rewards: 26.26002, mean: 0.10100
[32m[0906 20-22-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10619, current rewards: 22.34742, mean: 0.07209
[32m[0906 20-22-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10655, current rewards: 27.87412, mean: 0.07743
[32m[0906 20-23-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10688, current rewards: 33.39727, mean: 0.08146
[32m[0906 20-23-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10704, current rewards: 38.92290, mean: 0.08462
[32m[0906 20-23-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10719, current rewards: 44.44446, mean: 0.08715
[32m[0906 20-23-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10740, current rewards: 49.96880, mean: 0.08923
[32m[0906 20-23-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10753, current rewards: 55.49271, mean: 0.09097
[32m[0906 20-23-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10760, current rewards: 61.01372, mean: 0.09245
[32m[0906 20-23-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10771, current rewards: 66.30535, mean: 0.09339
[32m[0906 20-23-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10776, current rewards: 48.67825, mean: 0.06405
[32m[0906 20-23-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10785, current rewards: -3.03928, mean: -0.00375
[32m[0906 20-23-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10794, current rewards: -84.52233, mean: -0.09828
[32m[0906 20-23-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10801, current rewards: -159.32580, mean: -0.17508
[32m[0906 20-24-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10786, current rewards: -232.22704, mean: -0.24190
[32m[0906 20-24-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10779, current rewards: -289.76759, mean: -0.28690
[32m[0906 20-24-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10767, current rewards: -355.42301, mean: -0.33530
[32m[0906 20-24-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10757, current rewards: -436.96088, mean: -0.39366
[32m[0906 20-24-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10749, current rewards: -480.80066, mean: -0.41448
[32m[0906 20-24-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10740, current rewards: -569.34424, mean: -0.47053
[32m[0906 20-24-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10732, current rewards: -630.56407, mean: -0.50045
[32m[0906 20-24-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10729, current rewards: -675.66396, mean: -0.51577
[32m[0906 20-24-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10719, current rewards: -722.30628, mean: -0.53111
[32m[0906 20-24-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10711, current rewards: -766.46654, mean: -0.54359
[32m[0906 20-24-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10705, current rewards: -771.51557, mean: -0.52844
[32m[0906 20-24-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10700, current rewards: -765.81752, mean: -0.50716
[32m[0906 20-25-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10701, current rewards: -759.26688, mean: -0.48671
[32m[0906 20-25-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10708, current rewards: -753.44604, mean: -0.46798
[32m[0906 20-25-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10715, current rewards: -747.62870, mean: -0.45038
[32m[0906 20-25-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10719, current rewards: -747.41602, mean: -0.43709
[32m[0906 20-25-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10724, current rewards: -741.14557, mean: -0.42111
[32m[0906 20-25-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10727, current rewards: -735.26255, mean: -0.40622
[32m[0906 20-25-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10731, current rewards: -729.37264, mean: -0.39214
[32m[0906 20-25-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10735, current rewards: -723.47715, mean: -0.37878
[32m[0906 20-25-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10737, current rewards: -717.26507, mean: -0.36595
[32m[0906 20-25-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10740, current rewards: -711.42484, mean: -0.35394
[32m[0906 20-25-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10745, current rewards: -705.57597, mean: -0.34251
[32m[0906 20-26-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10746, current rewards: -710.61481, mean: -0.33678
[32m[0906 20-26-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10749, current rewards: -700.19999, mean: -0.32417
[32m[0906 20-26-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10744, current rewards: -689.78213, mean: -0.31212
[32m[0906 20-26-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10738, current rewards: -679.36268, mean: -0.30060
[32m[0906 20-26-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10732, current rewards: -668.94318, mean: -0.28959
[32m[0906 20-26-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10727, current rewards: -659.62771, mean: -0.27950
[32m[0906 20-26-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10721, current rewards: -650.68362, mean: -0.26999
[32m[0906 20-26-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10722, current rewards: -641.71704, mean: -0.26086
[32m[0906 20-26-46 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 20-26-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-26-46 @MBExp.py:227][0m Rewards obtained: [-634.5412773169013], Lows: [460], Highs: [15], Total time: 18849.59928999999
[32m[0906 20-29-26 @MBExp.py:144][0m ####################################################################
[32m[0906 20-29-26 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 20-29-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10381, current rewards: -12.93991, mean: -1.29399
[32m[0906 20-29-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10451, current rewards: -7.38908, mean: -0.12315
[32m[0906 20-29-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10490, current rewards: -1.77711, mean: -0.01616
[32m[0906 20-29-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10486, current rewards: 3.83187, mean: 0.02395
[32m[0906 20-29-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10480, current rewards: 9.45149, mean: 0.04501
[32m[0906 20-29-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10540, current rewards: 5.59037, mean: 0.02150
[32m[0906 20-29-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10579, current rewards: 13.51652, mean: 0.04360
[32m[0906 20-30-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10607, current rewards: 20.61307, mean: 0.05726
[32m[0906 20-30-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10645, current rewards: 27.70962, mean: 0.06758
[32m[0906 20-30-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10673, current rewards: 9.68369, mean: 0.02105
[32m[0906 20-30-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10685, current rewards: -40.31631, mean: -0.07905
[32m[0906 20-30-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10700, current rewards: -90.31631, mean: -0.16128
[32m[0906 20-30-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10708, current rewards: -140.31631, mean: -0.23003
[32m[0906 20-30-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10714, current rewards: -190.31631, mean: -0.28836
[32m[0906 20-30-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10722, current rewards: -240.31631, mean: -0.33847
[32m[0906 20-30-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10728, current rewards: -290.31631, mean: -0.38200
[32m[0906 20-30-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10732, current rewards: -340.31631, mean: -0.42014
[32m[0906 20-30-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10742, current rewards: -390.31631, mean: -0.45386
[32m[0906 20-31-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10730, current rewards: -440.31631, mean: -0.48386
[32m[0906 20-31-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10716, current rewards: -490.31631, mean: -0.51075
[32m[0906 20-31-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10707, current rewards: -540.31631, mean: -0.53497
[32m[0906 20-31-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10694, current rewards: -590.31631, mean: -0.55690
[32m[0906 20-31-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10683, current rewards: -640.31631, mean: -0.57686
[32m[0906 20-31-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10677, current rewards: -690.31631, mean: -0.59510
[32m[0906 20-31-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10668, current rewards: -740.31631, mean: -0.61183
[32m[0906 20-31-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10661, current rewards: -790.31631, mean: -0.62724
[32m[0906 20-31-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10658, current rewards: -840.31631, mean: -0.64146
[32m[0906 20-31-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10651, current rewards: -890.31631, mean: -0.65464
[32m[0906 20-31-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10645, current rewards: -940.31631, mean: -0.66689
[32m[0906 20-32-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10641, current rewards: -990.31631, mean: -0.67830
[32m[0906 20-32-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10634, current rewards: -1040.31631, mean: -0.68895
[32m[0906 20-32-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10635, current rewards: -1090.31631, mean: -0.69892
[32m[0906 20-32-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10644, current rewards: -1140.31631, mean: -0.70827
[32m[0906 20-32-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10649, current rewards: -1190.31631, mean: -0.71706
[32m[0906 20-32-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10655, current rewards: -1240.31631, mean: -0.72533
[32m[0906 20-32-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10662, current rewards: -1290.31631, mean: -0.73313
[32m[0906 20-32-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10668, current rewards: -1340.31631, mean: -0.74051
[32m[0906 20-32-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10672, current rewards: -1390.31631, mean: -0.74748
[32m[0906 20-32-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10679, current rewards: -1440.31631, mean: -0.75409
[32m[0906 20-32-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10682, current rewards: -1490.31631, mean: -0.76037
[32m[0906 20-33-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10686, current rewards: -1540.31631, mean: -0.76633
[32m[0906 20-33-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10690, current rewards: -1590.31631, mean: -0.77200
[32m[0906 20-33-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10693, current rewards: -1640.31631, mean: -0.77740
[32m[0906 20-33-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10696, current rewards: -1690.31631, mean: -0.78255
[32m[0906 20-33-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10694, current rewards: -1740.31631, mean: -0.78747
[32m[0906 20-33-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10688, current rewards: -1790.31631, mean: -0.79218
[32m[0906 20-33-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10685, current rewards: -1825.47121, mean: -0.79025
[32m[0906 20-33-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10682, current rewards: -1818.70671, mean: -0.77064
[32m[0906 20-33-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10677, current rewards: -1812.09848, mean: -0.75191
[32m[0906 20-33-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10682, current rewards: -1805.49025, mean: -0.73394
[32m[0906 20-33-54 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 20-33-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-33-54 @MBExp.py:227][0m Rewards obtained: [-1800.2036622757391], Lows: [11], Highs: [1864], Total time: 19117.54947999999
[32m[0906 20-36-36 @MBExp.py:144][0m ####################################################################
[32m[0906 20-36-36 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 20-36-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10395, current rewards: -4.58970, mean: -0.45897
[32m[0906 20-36-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10493, current rewards: 1.83386, mean: 0.03056
[32m[0906 20-36-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10529, current rewards: 7.63135, mean: 0.06938
[32m[0906 20-36-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10516, current rewards: 13.42364, mean: 0.08390
[32m[0906 20-36-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10513, current rewards: 19.22243, mean: 0.09154
[32m[0906 20-37-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10534, current rewards: 25.26692, mean: 0.09718
[32m[0906 20-37-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10584, current rewards: 31.10053, mean: 0.10032
[32m[0906 20-37-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10618, current rewards: 30.88571, mean: 0.08579
[32m[0906 20-37-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10652, current rewards: 36.35600, mean: 0.08867
[32m[0906 20-37-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10676, current rewards: 41.82547, mean: 0.09092
[32m[0906 20-37-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10695, current rewards: 47.29511, mean: 0.09274
[32m[0906 20-37-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10723, current rewards: 52.76835, mean: 0.09423
[32m[0906 20-37-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10735, current rewards: 58.23434, mean: 0.09547
[32m[0906 20-37-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10743, current rewards: 63.57671, mean: 0.09633
[32m[0906 20-37-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10750, current rewards: 64.17454, mean: 0.09039
[32m[0906 20-37-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10762, current rewards: 61.10540, mean: 0.08040
[32m[0906 20-38-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10764, current rewards: 66.39790, mean: 0.08197
[32m[0906 20-38-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10760, current rewards: 71.68863, mean: 0.08336
[32m[0906 20-38-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10745, current rewards: 76.97440, mean: 0.08459
[32m[0906 20-38-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10730, current rewards: 82.26533, mean: 0.08569
[32m[0906 20-38-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10719, current rewards: 87.55359, mean: 0.08669
[32m[0906 20-38-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10708, current rewards: 92.84208, mean: 0.08759
[32m[0906 20-38-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10696, current rewards: 98.48930, mean: 0.08873
[32m[0906 20-38-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10688, current rewards: 103.81072, mean: 0.08949
[32m[0906 20-38-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10676, current rewards: 109.14126, mean: 0.09020
[32m[0906 20-38-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10668, current rewards: 114.47199, mean: 0.09085
[32m[0906 20-38-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10663, current rewards: 119.79905, mean: 0.09145
[32m[0906 20-39-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10657, current rewards: 125.12759, mean: 0.09201
[32m[0906 20-39-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10650, current rewards: 130.45443, mean: 0.09252
[32m[0906 20-39-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10647, current rewards: 135.78062, mean: 0.09300
[32m[0906 20-39-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10641, current rewards: 141.10636, mean: 0.09345
[32m[0906 20-39-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10644, current rewards: 146.43387, mean: 0.09387
[32m[0906 20-39-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10651, current rewards: 146.39336, mean: 0.09093
[32m[0906 20-39-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10658, current rewards: 152.31300, mean: 0.09175
[32m[0906 20-39-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10664, current rewards: 158.21459, mean: 0.09252
[32m[0906 20-39-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10672, current rewards: 164.12640, mean: 0.09325
[32m[0906 20-39-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10676, current rewards: 170.03716, mean: 0.09394
[32m[0906 20-39-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10682, current rewards: 175.95843, mean: 0.09460
[32m[0906 20-40-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10688, current rewards: 181.87512, mean: 0.09522
[32m[0906 20-40-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10693, current rewards: 187.77991, mean: 0.09581
[32m[0906 20-40-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10697, current rewards: 193.69220, mean: 0.09636
[32m[0906 20-40-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10702, current rewards: 199.60300, mean: 0.09689
[32m[0906 20-40-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10706, current rewards: 205.52552, mean: 0.09741
[32m[0906 20-40-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10709, current rewards: 210.81913, mean: 0.09760
[32m[0906 20-40-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10707, current rewards: 216.78961, mean: 0.09809
[32m[0906 20-40-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10704, current rewards: 222.75653, mean: 0.09856
[32m[0906 20-40-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10700, current rewards: 228.75425, mean: 0.09903
[32m[0906 20-40-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10697, current rewards: 234.68286, mean: 0.09944
[32m[0906 20-40-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10695, current rewards: 240.62152, mean: 0.09984
[32m[0906 20-40-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10700, current rewards: 246.55087, mean: 0.10022
[32m[0906 20-41-04 @Agent.py:117][0m Average action selection time: 0.1070
[32m[0906 20-41-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-41-04 @MBExp.py:227][0m Rewards obtained: [251.30369934722455], Lows: [7], Highs: [15], Total time: 19385.98560299999
[32m[0906 20-43-48 @MBExp.py:144][0m ####################################################################
[32m[0906 20-43-48 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 20-43-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12913, current rewards: -6.72693, mean: -0.67269
[32m[0906 20-43-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11047, current rewards: -0.92234, mean: -0.01537
[32m[0906 20-44-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10801, current rewards: 4.94106, mean: 0.04492
[32m[0906 20-44-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10702, current rewards: 10.80565, mean: 0.06754
[32m[0906 20-44-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10636, current rewards: 16.59647, mean: 0.07903
[32m[0906 20-44-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10623, current rewards: 22.18398, mean: 0.08532
[32m[0906 20-44-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10653, current rewards: 28.05799, mean: 0.09051
[32m[0906 20-44-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10669, current rewards: 33.92860, mean: 0.09425
[32m[0906 20-44-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10686, current rewards: 39.80256, mean: 0.09708
[32m[0906 20-44-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10693, current rewards: 45.67667, mean: 0.09930
[32m[0906 20-44-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10704, current rewards: 51.54702, mean: 0.10107
[32m[0906 20-44-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10720, current rewards: 57.41809, mean: 0.10253
[32m[0906 20-44-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10722, current rewards: 63.28955, mean: 0.10375
[32m[0906 20-44-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10731, current rewards: 69.11044, mean: 0.10471
[32m[0906 20-45-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10742, current rewards: 74.97548, mean: 0.10560
[32m[0906 20-45-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10745, current rewards: 64.50152, mean: 0.08487
[32m[0906 20-45-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10744, current rewards: 69.93883, mean: 0.08634
[32m[0906 20-45-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10726, current rewards: 75.38655, mean: 0.08766
[32m[0906 20-45-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10709, current rewards: 80.83337, mean: 0.08883
[32m[0906 20-45-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10699, current rewards: 86.27638, mean: 0.08987
[32m[0906 20-45-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10686, current rewards: 91.72555, mean: 0.09082
[32m[0906 20-45-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10675, current rewards: 97.15059, mean: 0.09165
[32m[0906 20-45-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10668, current rewards: 102.59968, mean: 0.09243
[32m[0906 20-45-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10660, current rewards: 97.64613, mean: 0.08418
[32m[0906 20-45-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10652, current rewards: 103.18782, mean: 0.08528
[32m[0906 20-46-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10646, current rewards: 108.72603, mean: 0.08629
[32m[0906 20-46-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10639, current rewards: 114.26566, mean: 0.08723
[32m[0906 20-46-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10632, current rewards: 119.80007, mean: 0.08809
[32m[0906 20-46-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10625, current rewards: 125.33749, mean: 0.08889
[32m[0906 20-46-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10619, current rewards: 132.16672, mean: 0.09053
[32m[0906 20-46-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10613, current rewards: 137.68502, mean: 0.09118
[32m[0906 20-46-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10608, current rewards: 138.72056, mean: 0.08892
[32m[0906 20-46-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10606, current rewards: 144.22622, mean: 0.08958
[32m[0906 20-46-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10611, current rewards: 149.73273, mean: 0.09020
[32m[0906 20-46-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10616, current rewards: 155.23837, mean: 0.09078
[32m[0906 20-46-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10628, current rewards: 148.53858, mean: 0.08440
[32m[0906 20-47-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10634, current rewards: 154.59551, mean: 0.08541
[32m[0906 20-47-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10639, current rewards: 160.32272, mean: 0.08620
[32m[0906 20-47-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10644, current rewards: 166.66416, mean: 0.08726
[32m[0906 20-47-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10647, current rewards: 173.03725, mean: 0.08828
[32m[0906 20-47-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10653, current rewards: 179.41482, mean: 0.08926
[32m[0906 20-47-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10657, current rewards: 185.79011, mean: 0.09019
[32m[0906 20-47-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10662, current rewards: 192.17021, mean: 0.09108
[32m[0906 20-47-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10669, current rewards: 198.54533, mean: 0.09192
[32m[0906 20-47-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10666, current rewards: 204.92025, mean: 0.09272
[32m[0906 20-47-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10661, current rewards: 195.98350, mean: 0.08672
[32m[0906 20-47-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10657, current rewards: 201.33139, mean: 0.08716
[32m[0906 20-48-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10652, current rewards: 206.69820, mean: 0.08758
[32m[0906 20-48-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10651, current rewards: 212.06461, mean: 0.08799
[32m[0906 20-48-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10656, current rewards: 217.43357, mean: 0.08839
[32m[0906 20-48-15 @Agent.py:117][0m Average action selection time: 0.1066
[32m[0906 20-48-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-48-15 @MBExp.py:227][0m Rewards obtained: [221.72669528318113], Lows: [22], Highs: [20], Total time: 19653.24944399999
[32m[0906 20-51-01 @MBExp.py:144][0m ####################################################################
[32m[0906 20-51-01 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 20-51-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10646, current rewards: 0.98752, mean: 0.09875
[32m[0906 20-51-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10815, current rewards: 5.97647, mean: 0.09961
[32m[0906 20-51-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10640, current rewards: 11.72936, mean: 0.10663
[32m[0906 20-51-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10586, current rewards: 17.48330, mean: 0.10927
[32m[0906 20-51-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10573, current rewards: 24.66133, mean: 0.11743
[32m[0906 20-51-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10550, current rewards: 30.83439, mean: 0.11859
[32m[0906 20-51-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10594, current rewards: 36.93283, mean: 0.11914
[32m[0906 20-51-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10630, current rewards: 43.03341, mean: 0.11954
[32m[0906 20-51-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10653, current rewards: 49.13190, mean: 0.11983
[32m[0906 20-51-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10669, current rewards: 55.22850, mean: 0.12006
[32m[0906 20-51-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10690, current rewards: 61.33398, mean: 0.12026
[32m[0906 20-52-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10703, current rewards: 67.43322, mean: 0.12042
[32m[0906 20-52-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10713, current rewards: 66.94974, mean: 0.10975
[32m[0906 20-52-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10726, current rewards: 71.07919, mean: 0.10770
[32m[0906 20-52-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10731, current rewards: 75.22531, mean: 0.10595
[32m[0906 20-52-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10737, current rewards: 79.37002, mean: 0.10443
[32m[0906 20-52-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10727, current rewards: 83.51379, mean: 0.10310
[32m[0906 20-52-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10712, current rewards: 87.65685, mean: 0.10193
[32m[0906 20-52-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10700, current rewards: 91.79995, mean: 0.10088
[32m[0906 20-52-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10701, current rewards: 81.87273, mean: 0.08528
[32m[0906 20-52-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10691, current rewards: 86.95969, mean: 0.08610
[32m[0906 20-52-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10679, current rewards: 92.04747, mean: 0.08684
[32m[0906 20-53-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10671, current rewards: 97.13341, mean: 0.08751
[32m[0906 20-53-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10663, current rewards: 102.22042, mean: 0.08812
[32m[0906 20-53-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10655, current rewards: 107.30431, mean: 0.08868
[32m[0906 20-53-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10653, current rewards: 112.39133, mean: 0.08920
[32m[0906 20-53-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10645, current rewards: 102.25326, mean: 0.07806
[32m[0906 20-53-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10639, current rewards: 104.75877, mean: 0.07703
[32m[0906 20-53-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10636, current rewards: 109.41870, mean: 0.07760
[32m[0906 20-53-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10631, current rewards: 114.75107, mean: 0.07860
[32m[0906 20-53-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10626, current rewards: 119.64600, mean: 0.07924
[32m[0906 20-53-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10623, current rewards: 124.53235, mean: 0.07983
[32m[0906 20-53-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10618, current rewards: 129.42604, mean: 0.08039
[32m[0906 20-53-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10616, current rewards: 134.31786, mean: 0.08091
[32m[0906 20-54-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10622, current rewards: 140.34357, mean: 0.08207
[32m[0906 20-54-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10627, current rewards: 143.88045, mean: 0.08175
[32m[0906 20-54-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10633, current rewards: 147.41760, mean: 0.08145
[32m[0906 20-54-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10640, current rewards: 150.95482, mean: 0.08116
[32m[0906 20-54-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10646, current rewards: 154.49127, mean: 0.08089
[32m[0906 20-54-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10651, current rewards: 158.02925, mean: 0.08063
[32m[0906 20-54-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10658, current rewards: 161.56551, mean: 0.08038
[32m[0906 20-54-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10661, current rewards: 165.10013, mean: 0.08015
[32m[0906 20-54-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10665, current rewards: 158.64261, mean: 0.07519
[32m[0906 20-54-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10669, current rewards: 163.90160, mean: 0.07588
[32m[0906 20-54-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10667, current rewards: 168.98811, mean: 0.07647
[32m[0906 20-55-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10662, current rewards: 174.06010, mean: 0.07702
[32m[0906 20-55-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10659, current rewards: 179.25087, mean: 0.07760
[32m[0906 20-55-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10653, current rewards: 184.42642, mean: 0.07815
[32m[0906 20-55-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10656, current rewards: 183.82717, mean: 0.07628
[32m[0906 20-55-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10661, current rewards: 187.34650, mean: 0.07616
[32m[0906 20-55-28 @Agent.py:117][0m Average action selection time: 0.1066
[32m[0906 20-55-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-55-28 @MBExp.py:227][0m Rewards obtained: [190.1618312497157], Lows: [19], Highs: [17], Total time: 19920.65062499999
[32m[0906 20-58-17 @MBExp.py:144][0m ####################################################################
[32m[0906 20-58-17 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 20-58-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10625, current rewards: -15.00000, mean: -1.50000
[32m[0906 20-58-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10747, current rewards: -15.97422, mean: -0.26624
[32m[0906 20-58-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10762, current rewards: -10.34008, mean: -0.09400
[32m[0906 20-58-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10763, current rewards: -3.79411, mean: -0.02371
[32m[0906 20-58-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10676, current rewards: 1.85942, mean: 0.00885
[32m[0906 20-58-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10624, current rewards: 7.51559, mean: 0.02891
[32m[0906 20-58-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10651, current rewards: 13.17191, mean: 0.04249
[32m[0906 20-58-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10673, current rewards: 18.82769, mean: 0.05230
[32m[0906 20-59-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10688, current rewards: 19.11323, mean: 0.04662
[32m[0906 20-59-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10707, current rewards: 25.19675, mean: 0.05478
[32m[0906 20-59-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10715, current rewards: 31.28216, mean: 0.06134
[32m[0906 20-59-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10728, current rewards: 37.28333, mean: 0.06658
[32m[0906 20-59-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10738, current rewards: 43.39101, mean: 0.07113
[32m[0906 20-59-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10743, current rewards: 49.48736, mean: 0.07498
[32m[0906 20-59-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10753, current rewards: 55.59515, mean: 0.07830
[32m[0906 20-59-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10759, current rewards: 61.70091, mean: 0.08119
[32m[0906 20-59-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10765, current rewards: 67.80522, mean: 0.08371
[32m[0906 20-59-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10767, current rewards: 73.90318, mean: 0.08593
[32m[0906 20-59-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10752, current rewards: 77.76052, mean: 0.08545
[32m[0906 21-00-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10738, current rewards: 81.44523, mean: 0.08484
[32m[0906 21-00-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10727, current rewards: 87.35826, mean: 0.08649
[32m[0906 21-00-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10714, current rewards: 93.25942, mean: 0.08798
[32m[0906 21-00-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10701, current rewards: 99.16655, mean: 0.08934
[32m[0906 21-00-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10693, current rewards: 105.06823, mean: 0.09058
[32m[0906 21-00-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10681, current rewards: 110.96734, mean: 0.09171
[32m[0906 21-00-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10677, current rewards: 98.83694, mean: 0.07844
[32m[0906 21-00-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10669, current rewards: 104.41842, mean: 0.07971
[32m[0906 21-00-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10660, current rewards: 109.87391, mean: 0.08079
[32m[0906 21-00-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10652, current rewards: 115.39145, mean: 0.08184
[32m[0906 21-00-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10644, current rewards: 121.00684, mean: 0.08288
[32m[0906 21-00-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10637, current rewards: 116.83316, mean: 0.07737
[32m[0906 21-01-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10631, current rewards: 122.42860, mean: 0.07848
[32m[0906 21-01-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10625, current rewards: 128.02926, mean: 0.07952
[32m[0906 21-01-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10619, current rewards: 133.63411, mean: 0.08050
[32m[0906 21-01-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10613, current rewards: 139.24253, mean: 0.08143
[32m[0906 21-01-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10609, current rewards: 144.85237, mean: 0.08230
[32m[0906 21-01-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10611, current rewards: 150.65146, mean: 0.08323
[32m[0906 21-01-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10612, current rewards: 149.43438, mean: 0.08034
[32m[0906 21-01-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10615, current rewards: 154.27066, mean: 0.08077
[32m[0906 21-01-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10619, current rewards: 159.12330, mean: 0.08119
[32m[0906 21-01-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10622, current rewards: 163.97429, mean: 0.08158
[32m[0906 21-01-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10627, current rewards: 168.81711, mean: 0.08195
[32m[0906 21-02-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10630, current rewards: 157.32258, mean: 0.07456
[32m[0906 21-02-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10633, current rewards: 162.92453, mean: 0.07543
[32m[0906 21-02-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10633, current rewards: 168.68307, mean: 0.07633
[32m[0906 21-02-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10628, current rewards: 174.28393, mean: 0.07712
[32m[0906 21-02-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10623, current rewards: 179.88523, mean: 0.07787
[32m[0906 21-02-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10620, current rewards: 185.48780, mean: 0.07860
[32m[0906 21-02-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10616, current rewards: 191.09689, mean: 0.07929
[32m[0906 21-02-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10612, current rewards: 196.69978, mean: 0.07996
[32m[0906 21-02-43 @Agent.py:117][0m Average action selection time: 0.1061
[32m[0906 21-02-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-02-43 @MBExp.py:227][0m Rewards obtained: [201.18585009604982], Lows: [28], Highs: [24], Total time: 20186.77896899999
[32m[0906 21-05-32 @MBExp.py:144][0m ####################################################################
[32m[0906 21-05-32 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 21-05-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10529, current rewards: 1.35898, mean: 0.13590
[32m[0906 21-05-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10717, current rewards: 6.43475, mean: 0.10725
[32m[0906 21-05-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10698, current rewards: 12.70329, mean: 0.11548
[32m[0906 21-05-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10598, current rewards: 19.15014, mean: 0.11969
[32m[0906 21-05-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10550, current rewards: 24.98487, mean: 0.11898
[32m[0906 21-05-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10510, current rewards: 30.82028, mean: 0.11854
[32m[0906 21-06-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10524, current rewards: 36.65585, mean: 0.11824
[32m[0906 21-06-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10555, current rewards: 42.49010, mean: 0.11803
[32m[0906 21-06-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10569, current rewards: 48.32584, mean: 0.11787
[32m[0906 21-06-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10581, current rewards: 54.16150, mean: 0.11774
[32m[0906 21-06-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10598, current rewards: 59.99578, mean: 0.11764
[32m[0906 21-06-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10605, current rewards: 65.38036, mean: 0.11675
[32m[0906 21-06-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10614, current rewards: 64.60614, mean: 0.10591
[32m[0906 21-06-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10625, current rewards: 69.47667, mean: 0.10527
[32m[0906 21-06-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10632, current rewards: 74.34155, mean: 0.10471
[32m[0906 21-06-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10635, current rewards: 79.20709, mean: 0.10422
[32m[0906 21-06-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10641, current rewards: 84.07273, mean: 0.10379
[32m[0906 21-07-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10631, current rewards: 90.75101, mean: 0.10552
[32m[0906 21-07-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10615, current rewards: 96.66561, mean: 0.10623
[32m[0906 21-07-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10602, current rewards: 103.39528, mean: 0.10770
[32m[0906 21-07-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10591, current rewards: 109.24958, mean: 0.10817
[32m[0906 21-07-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10580, current rewards: 115.10498, mean: 0.10859
[32m[0906 21-07-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10573, current rewards: 120.96005, mean: 0.10897
[32m[0906 21-07-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10573, current rewards: 116.74164, mean: 0.10064
[32m[0906 21-07-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10564, current rewards: 122.21766, mean: 0.10101
[32m[0906 21-07-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10559, current rewards: 127.69275, mean: 0.10134
[32m[0906 21-07-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10552, current rewards: 133.16740, mean: 0.10165
[32m[0906 21-07-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10548, current rewards: 138.59547, mean: 0.10191
[32m[0906 21-08-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10545, current rewards: 144.06898, mean: 0.10218
[32m[0906 21-08-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10538, current rewards: 149.54356, mean: 0.10243
[32m[0906 21-08-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10532, current rewards: 155.02170, mean: 0.10266
[32m[0906 21-08-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10528, current rewards: 160.49784, mean: 0.10288
[32m[0906 21-08-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10522, current rewards: 158.27542, mean: 0.09831
[32m[0906 21-08-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10516, current rewards: 163.76436, mean: 0.09865
[32m[0906 21-08-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10513, current rewards: 169.29720, mean: 0.09900
[32m[0906 21-08-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10509, current rewards: 174.65956, mean: 0.09924
[32m[0906 21-08-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10513, current rewards: 180.19538, mean: 0.09956
[32m[0906 21-08-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10518, current rewards: 185.73732, mean: 0.09986
[32m[0906 21-08-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10522, current rewards: 180.76047, mean: 0.09464
[32m[0906 21-08-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10526, current rewards: 186.54514, mean: 0.09518
[32m[0906 21-09-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10530, current rewards: 192.30299, mean: 0.09567
[32m[0906 21-09-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10533, current rewards: 198.06485, mean: 0.09615
[32m[0906 21-09-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10537, current rewards: 203.82666, mean: 0.09660
[32m[0906 21-09-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10541, current rewards: 196.43695, mean: 0.09094
[32m[0906 21-09-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10540, current rewards: 201.39780, mean: 0.09113
[32m[0906 21-09-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10535, current rewards: 207.16289, mean: 0.09166
[32m[0906 21-09-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10531, current rewards: 212.92550, mean: 0.09218
[32m[0906 21-09-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10527, current rewards: 218.69085, mean: 0.09267
[32m[0906 21-09-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10523, current rewards: 224.45234, mean: 0.09313
[32m[0906 21-09-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10520, current rewards: 230.21436, mean: 0.09358
[32m[0906 21-09-56 @Agent.py:117][0m Average action selection time: 0.1052
[32m[0906 21-09-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-09-56 @MBExp.py:227][0m Rewards obtained: [234.82625732603765], Lows: [17], Highs: [11], Total time: 20450.599872999992
[32m[0906 21-12-47 @MBExp.py:144][0m ####################################################################
[32m[0906 21-12-47 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 21-12-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10515, current rewards: -0.82253, mean: -0.08225
[32m[0906 21-12-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10591, current rewards: 7.66366, mean: 0.12773
[32m[0906 21-12-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10529, current rewards: 15.67502, mean: 0.14250
[32m[0906 21-13-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10477, current rewards: -18.36598, mean: -0.11479
[32m[0906 21-13-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10438, current rewards: -68.36598, mean: -0.32555
[32m[0906 21-13-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10414, current rewards: -118.36598, mean: -0.45525
[32m[0906 21-13-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10436, current rewards: -168.36598, mean: -0.54312
[32m[0906 21-13-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10464, current rewards: -218.36598, mean: -0.60657
[32m[0906 21-13-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10487, current rewards: -268.36598, mean: -0.65455
[32m[0906 21-13-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10507, current rewards: -318.36598, mean: -0.69210
[32m[0906 21-13-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10523, current rewards: -368.36598, mean: -0.72229
[32m[0906 21-13-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10533, current rewards: -418.36598, mean: -0.74708
[32m[0906 21-13-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10546, current rewards: -468.36598, mean: -0.76781
[32m[0906 21-13-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10554, current rewards: -518.36598, mean: -0.78540
[32m[0906 21-14-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10562, current rewards: -568.36598, mean: -0.80052
[32m[0906 21-14-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10569, current rewards: -618.36598, mean: -0.81364
[32m[0906 21-14-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10566, current rewards: -668.36598, mean: -0.82514
[32m[0906 21-14-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10552, current rewards: -718.36598, mean: -0.83531
[32m[0906 21-14-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10543, current rewards: -768.36598, mean: -0.84436
[32m[0906 21-14-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10531, current rewards: -818.36598, mean: -0.85246
[32m[0906 21-14-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10522, current rewards: -868.36598, mean: -0.85977
[32m[0906 21-14-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10514, current rewards: -918.36598, mean: -0.86638
[32m[0906 21-14-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10504, current rewards: -968.36598, mean: -0.87240
[32m[0906 21-14-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10495, current rewards: -1018.36598, mean: -0.87790
[32m[0906 21-14-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10490, current rewards: -1068.36598, mean: -0.88295
[32m[0906 21-15-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10486, current rewards: -1118.36598, mean: -0.88759
[32m[0906 21-15-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10480, current rewards: -1168.36598, mean: -0.89188
[32m[0906 21-15-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10474, current rewards: -1218.36598, mean: -0.89586
[32m[0906 21-15-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10469, current rewards: -1268.36598, mean: -0.89955
[32m[0906 21-15-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10464, current rewards: -1318.36598, mean: -0.90299
[32m[0906 21-15-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10462, current rewards: -1368.36598, mean: -0.90620
[32m[0906 21-15-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10456, current rewards: -1418.36598, mean: -0.90921
[32m[0906 21-15-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10453, current rewards: -1468.36598, mean: -0.91203
[32m[0906 21-15-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10452, current rewards: -1518.36598, mean: -0.91468
[32m[0906 21-15-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10448, current rewards: -1568.36598, mean: -0.91717
[32m[0906 21-15-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10445, current rewards: -1618.36598, mean: -0.91953
[32m[0906 21-15-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10455, current rewards: -1668.36598, mean: -0.92175
[32m[0906 21-16-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10461, current rewards: -1718.36598, mean: -0.92385
[32m[0906 21-16-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10467, current rewards: -1768.36598, mean: -0.92585
[32m[0906 21-16-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10473, current rewards: -1818.36598, mean: -0.92774
[32m[0906 21-16-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10478, current rewards: -1868.36598, mean: -0.92954
[32m[0906 21-16-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10482, current rewards: -1918.36598, mean: -0.93125
[32m[0906 21-16-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10488, current rewards: -1968.36598, mean: -0.93287
[32m[0906 21-16-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10491, current rewards: -2018.36598, mean: -0.93443
[32m[0906 21-16-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10494, current rewards: -2068.36598, mean: -0.93591
[32m[0906 21-16-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10491, current rewards: -2118.36598, mean: -0.93733
[32m[0906 21-16-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10488, current rewards: -2168.36598, mean: -0.93869
[32m[0906 21-16-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10485, current rewards: -2218.36598, mean: -0.93999
[32m[0906 21-17-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10482, current rewards: -2268.36598, mean: -0.94123
[32m[0906 21-17-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10478, current rewards: -2318.36598, mean: -0.94243
[32m[0906 21-17-10 @Agent.py:117][0m Average action selection time: 0.1048
[32m[0906 21-17-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-17-10 @MBExp.py:227][0m Rewards obtained: [-2358.365975713045], Lows: [1], Highs: [2375], Total time: 20713.41908699999
[32m[0906 21-20-03 @MBExp.py:144][0m ####################################################################
[32m[0906 21-20-03 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 21-20-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10899, current rewards: -4.54421, mean: -0.45442
[32m[0906 21-20-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11474, current rewards: -25.40022, mean: -0.42334
[32m[0906 21-20-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11253, current rewards: -53.02369, mean: -0.48203
[32m[0906 21-20-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10967, current rewards: -54.00890, mean: -0.33756
[32m[0906 21-20-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10810, current rewards: -48.49942, mean: -0.23095
[32m[0906 21-20-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10740, current rewards: -40.94974, mean: -0.15750
[32m[0906 21-20-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10698, current rewards: -35.84291, mean: -0.11562
[32m[0906 21-20-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10696, current rewards: -27.13688, mean: -0.07538
[32m[0906 21-20-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10746, current rewards: -32.88866, mean: -0.08022
[32m[0906 21-20-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10733, current rewards: -23.21483, mean: -0.05047
[32m[0906 21-20-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10730, current rewards: -15.77460, mean: -0.03093
[32m[0906 21-21-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10719, current rewards: -24.74034, mean: -0.04418
[32m[0906 21-21-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10710, current rewards: -74.74034, mean: -0.12253
[32m[0906 21-21-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10705, current rewards: -124.74034, mean: -0.18900
[32m[0906 21-21-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10699, current rewards: -174.74034, mean: -0.24611
[32m[0906 21-21-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10695, current rewards: -224.74034, mean: -0.29571
[32m[0906 21-21-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10684, current rewards: -274.74034, mean: -0.33919
[32m[0906 21-21-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10663, current rewards: -324.74034, mean: -0.37761
[32m[0906 21-21-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10644, current rewards: -374.74034, mean: -0.41180
[32m[0906 21-21-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10627, current rewards: -424.74034, mean: -0.44244
[32m[0906 21-21-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10610, current rewards: -474.74034, mean: -0.47004
[32m[0906 21-21-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10593, current rewards: -524.74034, mean: -0.49504
[32m[0906 21-22-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10582, current rewards: -574.74034, mean: -0.51778
[32m[0906 21-22-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10570, current rewards: -624.74034, mean: -0.53857
[32m[0906 21-22-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10561, current rewards: -674.74034, mean: -0.55764
[32m[0906 21-22-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10552, current rewards: -724.74034, mean: -0.57519
[32m[0906 21-22-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10544, current rewards: -774.74034, mean: -0.59140
[32m[0906 21-22-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10534, current rewards: -824.74034, mean: -0.60643
[32m[0906 21-22-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10527, current rewards: -874.74034, mean: -0.62038
[32m[0906 21-22-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10520, current rewards: -924.74034, mean: -0.63338
[32m[0906 21-22-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10512, current rewards: -974.74034, mean: -0.64552
[32m[0906 21-22-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10507, current rewards: -1024.74034, mean: -0.65688
[32m[0906 21-22-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10501, current rewards: -1074.74034, mean: -0.66754
[32m[0906 21-22-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10496, current rewards: -1124.74034, mean: -0.67755
[32m[0906 21-23-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10492, current rewards: -1174.74034, mean: -0.68698
[32m[0906 21-23-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10490, current rewards: -1224.74034, mean: -0.69588
[32m[0906 21-23-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10493, current rewards: -1274.74034, mean: -0.70428
[32m[0906 21-23-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10498, current rewards: -1324.74034, mean: -0.71223
[32m[0906 21-23-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10501, current rewards: -1374.74034, mean: -0.71976
[32m[0906 21-23-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10504, current rewards: -1424.74034, mean: -0.72691
[32m[0906 21-23-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10508, current rewards: -1474.74034, mean: -0.73370
[32m[0906 21-23-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10510, current rewards: -1524.74034, mean: -0.74017
[32m[0906 21-23-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10513, current rewards: -1574.74034, mean: -0.74632
[32m[0906 21-23-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10518, current rewards: -1624.74034, mean: -0.75219
[32m[0906 21-23-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10518, current rewards: -1674.74034, mean: -0.75780
[32m[0906 21-24-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10514, current rewards: -1724.74034, mean: -0.76316
[32m[0906 21-24-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10510, current rewards: -1774.74034, mean: -0.76829
[32m[0906 21-24-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10506, current rewards: -1824.74034, mean: -0.77320
[32m[0906 21-24-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10502, current rewards: -1874.74034, mean: -0.77790
[32m[0906 21-24-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10498, current rewards: -1924.74034, mean: -0.78241
[32m[0906 21-24-27 @Agent.py:117][0m Average action selection time: 0.1050
[32m[0906 21-24-27 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-24-27 @MBExp.py:227][0m Rewards obtained: [-1964.7403403862024], Lows: [48], Highs: [1963], Total time: 20976.66265199999
[32m[0906 21-27-22 @MBExp.py:144][0m ####################################################################
[32m[0906 21-27-22 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 21-27-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11875, current rewards: -11.90851, mean: -1.19085
[32m[0906 21-27-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10787, current rewards: -16.54224, mean: -0.27570
[32m[0906 21-27-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10705, current rewards: -16.79563, mean: -0.15269
[32m[0906 21-27-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10592, current rewards: -8.98717, mean: -0.05617
[32m[0906 21-27-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10520, current rewards: -1.16971, mean: -0.00557
[32m[0906 21-27-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10490, current rewards: 6.65069, mean: 0.02558
[32m[0906 21-27-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10482, current rewards: 14.46512, mean: 0.04666
[32m[0906 21-28-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10501, current rewards: 22.28839, mean: 0.06191
[32m[0906 21-28-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10519, current rewards: 20.77612, mean: 0.05067
[32m[0906 21-28-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10519, current rewards: 26.59855, mean: 0.05782
[32m[0906 21-28-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10526, current rewards: 32.16402, mean: 0.06307
[32m[0906 21-28-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10533, current rewards: 37.91650, mean: 0.06771
[32m[0906 21-28-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10535, current rewards: 43.64840, mean: 0.07155
[32m[0906 21-28-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10534, current rewards: 49.38695, mean: 0.07483
[32m[0906 21-28-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10540, current rewards: 55.12371, mean: 0.07764
[32m[0906 21-28-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10535, current rewards: 60.85598, mean: 0.08007
[32m[0906 21-28-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10516, current rewards: 66.59057, mean: 0.08221
[32m[0906 21-28-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10505, current rewards: 72.32254, mean: 0.08410
[32m[0906 21-28-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10493, current rewards: 77.57275, mean: 0.08524
[32m[0906 21-29-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10483, current rewards: 82.93485, mean: 0.08639
[32m[0906 21-29-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10476, current rewards: 88.29169, mean: 0.08742
[32m[0906 21-29-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10468, current rewards: 93.65245, mean: 0.08835
[32m[0906 21-29-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10462, current rewards: 99.01561, mean: 0.08920
[32m[0906 21-29-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10454, current rewards: 104.37917, mean: 0.08998
[32m[0906 21-29-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10449, current rewards: 109.74490, mean: 0.09070
[32m[0906 21-29-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10442, current rewards: 115.10322, mean: 0.09135
[32m[0906 21-29-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10438, current rewards: 120.68840, mean: 0.09213
[32m[0906 21-29-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10434, current rewards: 126.06624, mean: 0.09270
[32m[0906 21-29-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10427, current rewards: 131.45551, mean: 0.09323
[32m[0906 21-29-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10422, current rewards: 136.85219, mean: 0.09373
[32m[0906 21-30-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10418, current rewards: 139.87603, mean: 0.09263
[32m[0906 21-30-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10414, current rewards: 152.08677, mean: 0.09749
[32m[0906 21-30-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10409, current rewards: 164.28134, mean: 0.10204
[32m[0906 21-30-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10405, current rewards: 176.49967, mean: 0.10633
[32m[0906 21-30-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10402, current rewards: 189.24011, mean: 0.11067
[32m[0906 21-30-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10410, current rewards: 174.16945, mean: 0.09896
[32m[0906 21-30-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10406, current rewards: 180.37412, mean: 0.09965
[32m[0906 21-30-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10408, current rewards: 186.57687, mean: 0.10031
[32m[0906 21-30-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10412, current rewards: 192.78248, mean: 0.10093
[32m[0906 21-30-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10416, current rewards: 198.98760, mean: 0.10152
[32m[0906 21-30-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10419, current rewards: 188.88510, mean: 0.09397
[32m[0906 21-30-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10422, current rewards: 198.21855, mean: 0.09622
[32m[0906 21-31-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10426, current rewards: 207.55199, mean: 0.09837
[32m[0906 21-31-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10429, current rewards: 212.35846, mean: 0.09831
[32m[0906 21-31-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10430, current rewards: 207.93707, mean: 0.09409
[32m[0906 21-31-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10426, current rewards: 157.93707, mean: 0.06988
[32m[0906 21-31-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10423, current rewards: 107.93707, mean: 0.04673
[32m[0906 21-31-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10420, current rewards: 57.93707, mean: 0.02455
[32m[0906 21-31-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10418, current rewards: 7.93707, mean: 0.00329
[32m[0906 21-31-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10415, current rewards: -42.06293, mean: -0.01710
[32m[0906 21-31-43 @Agent.py:117][0m Average action selection time: 0.1042
[32m[0906 21-31-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-31-43 @MBExp.py:227][0m Rewards obtained: [-82.06292865150075], Lows: [42], Highs: [308], Total time: 21237.891000999993
[32m[0906 21-34-40 @MBExp.py:144][0m ####################################################################
[32m[0906 21-34-40 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 21-34-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10384, current rewards: -5.62720, mean: -0.56272
[32m[0906 21-34-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10482, current rewards: -0.66842, mean: -0.01114
[32m[0906 21-34-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10379, current rewards: 4.26158, mean: 0.03874
[32m[0906 21-34-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10359, current rewards: 9.19624, mean: 0.05748
[32m[0906 21-35-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10345, current rewards: 14.12941, mean: 0.06728
[32m[0906 21-35-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10327, current rewards: 19.05870, mean: 0.07330
[32m[0906 21-35-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10328, current rewards: 23.99165, mean: 0.07739
[32m[0906 21-35-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10353, current rewards: 28.92513, mean: 0.08035
[32m[0906 21-35-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10376, current rewards: 33.85686, mean: 0.08258
[32m[0906 21-35-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10394, current rewards: 28.38195, mean: 0.06170
[32m[0906 21-35-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10409, current rewards: 32.83811, mean: 0.06439
[32m[0906 21-35-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10420, current rewards: 37.22840, mean: 0.06648
[32m[0906 21-35-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10434, current rewards: 41.62026, mean: 0.06823
[32m[0906 21-35-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10441, current rewards: 46.01046, mean: 0.06971
[32m[0906 21-35-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10444, current rewards: 44.92861, mean: 0.06328
[32m[0906 21-36-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10432, current rewards: 50.76976, mean: 0.06680
[32m[0906 21-36-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10419, current rewards: 56.66293, mean: 0.06995
[32m[0906 21-36-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10409, current rewards: 62.63679, mean: 0.07283
[32m[0906 21-36-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10402, current rewards: 69.06020, mean: 0.07589
[32m[0906 21-36-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10395, current rewards: 62.79470, mean: 0.06541
[32m[0906 21-36-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10389, current rewards: 69.55874, mean: 0.06887
[32m[0906 21-36-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10383, current rewards: 76.32278, mean: 0.07200
[32m[0906 21-36-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10374, current rewards: 83.08683, mean: 0.07485
[32m[0906 21-36-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10369, current rewards: 84.17447, mean: 0.07256
[32m[0906 21-36-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10364, current rewards: 34.17447, mean: 0.02824
[32m[0906 21-36-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10360, current rewards: -15.82553, mean: -0.01256
[32m[0906 21-36-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10356, current rewards: -24.75984, mean: -0.01890
[32m[0906 21-37-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10353, current rewards: -18.78449, mean: -0.01381
[32m[0906 21-37-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10351, current rewards: -12.80212, mean: -0.00908
[32m[0906 21-37-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10347, current rewards: -6.81383, mean: -0.00467
[32m[0906 21-37-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10347, current rewards: -0.82496, mean: -0.00055
[32m[0906 21-37-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10344, current rewards: 5.16016, mean: 0.00331
[32m[0906 21-37-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10342, current rewards: 11.15556, mean: 0.00693
[32m[0906 21-37-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10341, current rewards: 17.13190, mean: 0.01032
[32m[0906 21-37-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10341, current rewards: 22.19309, mean: 0.01298
[32m[0906 21-37-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10338, current rewards: 25.68156, mean: 0.01459
[32m[0906 21-37-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10336, current rewards: 29.17442, mean: 0.01612
[32m[0906 21-37-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10343, current rewards: 32.66892, mean: 0.01756
[32m[0906 21-37-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10348, current rewards: 36.15614, mean: 0.01893
[32m[0906 21-38-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10352, current rewards: 39.65047, mean: 0.02023
[32m[0906 21-38-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10357, current rewards: 43.14529, mean: 0.02147
[32m[0906 21-38-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10361, current rewards: 46.63874, mean: 0.02264
[32m[0906 21-38-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10364, current rewards: 50.32790, mean: 0.02385
[32m[0906 21-38-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10370, current rewards: 53.93380, mean: 0.02497
[32m[0906 21-38-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10373, current rewards: 47.72271, mean: 0.02159
[32m[0906 21-38-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10371, current rewards: 53.48186, mean: 0.02366
[32m[0906 21-38-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10370, current rewards: 59.27026, mean: 0.02566
[32m[0906 21-38-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10368, current rewards: 65.05481, mean: 0.02757
[32m[0906 21-38-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10366, current rewards: 70.84430, mean: 0.02940
[32m[0906 21-38-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10366, current rewards: 76.63434, mean: 0.03115
[32m[0906 21-39-00 @Agent.py:117][0m Average action selection time: 0.1037
[32m[0906 21-39-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-39-01 @MBExp.py:227][0m Rewards obtained: [81.15404732431203], Lows: [16], Highs: [129], Total time: 21497.944723999994
[32m[0906 21-41-42 @MBExp.py:144][0m ####################################################################
[32m[0906 21-41-42 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 21-41-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09969, current rewards: -9.12047, mean: -0.91205
[32m[0906 21-41-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10010, current rewards: -9.24669, mean: -0.15411
[32m[0906 21-41-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10015, current rewards: -4.39505, mean: -0.03996
[32m[0906 21-41-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09934, current rewards: 0.45307, mean: 0.00283
[32m[0906 21-42-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09882, current rewards: 5.29744, mean: 0.02523
[32m[0906 21-42-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09847, current rewards: 10.14176, mean: 0.03901
[32m[0906 21-42-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09825, current rewards: 14.98909, mean: 0.04835
[32m[0906 21-42-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09852, current rewards: 19.82291, mean: 0.05506
[32m[0906 21-42-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09871, current rewards: 24.67572, mean: 0.06018
[32m[0906 21-42-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09884, current rewards: 29.55331, mean: 0.06425
[32m[0906 21-42-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09898, current rewards: 35.02991, mean: 0.06869
[32m[0906 21-42-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09905, current rewards: 39.79888, mean: 0.07107
[32m[0906 21-42-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09913, current rewards: 45.58172, mean: 0.07472
[32m[0906 21-42-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09918, current rewards: 51.37772, mean: 0.07785
[32m[0906 21-42-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09924, current rewards: 57.16701, mean: 0.08052
[32m[0906 21-42-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09933, current rewards: 50.50012, mean: 0.06645
[32m[0906 21-43-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09917, current rewards: 55.89594, mean: 0.06901
[32m[0906 21-43-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09904, current rewards: 61.09400, mean: 0.07104
[32m[0906 21-43-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09894, current rewards: 66.87354, mean: 0.07349
[32m[0906 21-43-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09885, current rewards: 72.65768, mean: 0.07569
[32m[0906 21-43-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09877, current rewards: 78.44037, mean: 0.07766
[32m[0906 21-43-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09870, current rewards: 84.21883, mean: 0.07945
[32m[0906 21-43-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09861, current rewards: 89.99990, mean: 0.08108
[32m[0906 21-43-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09854, current rewards: 95.77657, mean: 0.08257
[32m[0906 21-43-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09847, current rewards: 101.56136, mean: 0.08394
[32m[0906 21-43-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09842, current rewards: 109.42010, mean: 0.08684
[32m[0906 21-43-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09838, current rewards: 115.08621, mean: 0.08785
[32m[0906 21-43-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09832, current rewards: 114.49962, mean: 0.08419
[32m[0906 21-44-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09828, current rewards: 120.07429, mean: 0.08516
[32m[0906 21-44-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09824, current rewards: 125.63886, mean: 0.08605
[32m[0906 21-44-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09820, current rewards: 131.20488, mean: 0.08689
[32m[0906 21-44-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09817, current rewards: 136.77142, mean: 0.08767
[32m[0906 21-44-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09785, current rewards: 142.33261, mean: 0.08841
[32m[0906 21-44-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09759, current rewards: 147.58276, mean: 0.08891
[32m[0906 21-44-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09728, current rewards: 153.16412, mean: 0.08957
[32m[0906 21-44-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09699, current rewards: 158.82028, mean: 0.09024
[32m[0906 21-44-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09672, current rewards: 164.48168, mean: 0.09087
[32m[0906 21-44-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09652, current rewards: 170.14016, mean: 0.09147
[32m[0906 21-44-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09634, current rewards: 175.79045, mean: 0.09204
[32m[0906 21-44-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09616, current rewards: 170.79041, mean: 0.08714
[32m[0906 21-44-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09600, current rewards: 176.40038, mean: 0.08776
[32m[0906 21-45-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09584, current rewards: 182.01414, mean: 0.08836
[32m[0906 21-45-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09569, current rewards: 187.39922, mean: 0.08881
[32m[0906 21-45-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09555, current rewards: 193.02675, mean: 0.08936
[32m[0906 21-45-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09542, current rewards: 198.65713, mean: 0.08989
[32m[0906 21-45-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09524, current rewards: 204.27996, mean: 0.09039
[32m[0906 21-45-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09507, current rewards: 204.36568, mean: 0.08847
[32m[0906 21-45-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09490, current rewards: 210.01005, mean: 0.08899
[32m[0906 21-45-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09473, current rewards: 215.65105, mean: 0.08948
[32m[0906 21-45-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09459, current rewards: 221.29423, mean: 0.08996
[32m[0906 21-45-39 @Agent.py:117][0m Average action selection time: 0.0945
[32m[0906 21-45-39 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-45-39 @MBExp.py:227][0m Rewards obtained: [225.96460981361955], Lows: [17], Highs: [17], Total time: 21734.945392999995
[32m[0906 21-48-06 @MBExp.py:144][0m ####################################################################
[32m[0906 21-48-06 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 21-48-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09529, current rewards: -5.55677, mean: -0.55568
[32m[0906 21-48-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09061, current rewards: 0.50750, mean: 0.00846
[32m[0906 21-48-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08963, current rewards: 6.56834, mean: 0.05971
[32m[0906 21-48-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08888, current rewards: 12.63473, mean: 0.07897
[32m[0906 21-48-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08846, current rewards: 15.33215, mean: 0.07301
[32m[0906 21-48-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08820, current rewards: -3.01907, mean: -0.01161
[32m[0906 21-48-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08802, current rewards: 3.48839, mean: 0.01125
[32m[0906 21-48-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08819, current rewards: 9.98225, mean: 0.02773
[32m[0906 21-48-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08837, current rewards: 16.00301, mean: 0.03903
[32m[0906 21-48-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08849, current rewards: 22.34728, mean: 0.04858
[32m[0906 21-48-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08861, current rewards: 28.70850, mean: 0.05629
[32m[0906 21-48-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08873, current rewards: 35.06882, mean: 0.06262
[32m[0906 21-49-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08882, current rewards: 41.41538, mean: 0.06789
[32m[0906 21-49-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08889, current rewards: 47.76051, mean: 0.07236
[32m[0906 21-49-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08894, current rewards: 54.12378, mean: 0.07623
[32m[0906 21-49-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08886, current rewards: 60.47986, mean: 0.07958
[32m[0906 21-49-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08875, current rewards: 52.94278, mean: 0.06536
[32m[0906 21-49-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08866, current rewards: 57.39777, mean: 0.06674
[32m[0906 21-49-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08859, current rewards: 61.85536, mean: 0.06797
[32m[0906 21-49-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08851, current rewards: 66.31159, mean: 0.06907
[32m[0906 21-49-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08843, current rewards: 70.77137, mean: 0.07007
[32m[0906 21-49-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08837, current rewards: 75.22949, mean: 0.07097
[32m[0906 21-49-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08831, current rewards: 79.68622, mean: 0.07179
[32m[0906 21-49-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08825, current rewards: 84.14335, mean: 0.07254
[32m[0906 21-49-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08821, current rewards: 88.74088, mean: 0.07334
[32m[0906 21-49-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08817, current rewards: 94.41188, mean: 0.07493
[32m[0906 21-50-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08812, current rewards: 99.55753, mean: 0.07600
[32m[0906 21-50-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08808, current rewards: 104.70318, mean: 0.07699
[32m[0906 21-50-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08805, current rewards: 109.84883, mean: 0.07791
[32m[0906 21-50-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08802, current rewards: 109.47991, mean: 0.07499
[32m[0906 21-50-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08799, current rewards: 59.47991, mean: 0.03939
[32m[0906 21-50-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08797, current rewards: 9.47991, mean: 0.00608
[32m[0906 21-50-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08794, current rewards: -40.52009, mean: -0.02517
[32m[0906 21-50-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08791, current rewards: -90.52009, mean: -0.05453
[32m[0906 21-50-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08789, current rewards: -140.52009, mean: -0.08218
[32m[0906 21-50-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08787, current rewards: -190.52009, mean: -0.10825
[32m[0906 21-50-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08784, current rewards: -240.52009, mean: -0.13288
[32m[0906 21-50-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08789, current rewards: -290.52009, mean: -0.15619
[32m[0906 21-50-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08794, current rewards: -340.52009, mean: -0.17828
[32m[0906 21-50-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08799, current rewards: -390.52009, mean: -0.19924
[32m[0906 21-51-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08803, current rewards: -440.52009, mean: -0.21916
[32m[0906 21-51-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08807, current rewards: -490.52009, mean: -0.23812
[32m[0906 21-51-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08810, current rewards: -540.52009, mean: -0.25617
[32m[0906 21-51-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08813, current rewards: -590.52009, mean: -0.27339
[32m[0906 21-51-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08816, current rewards: -640.52009, mean: -0.28983
[32m[0906 21-51-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08817, current rewards: -690.52009, mean: -0.30554
[32m[0906 21-51-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08815, current rewards: -740.52009, mean: -0.32057
[32m[0906 21-51-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08813, current rewards: -790.52009, mean: -0.33497
[32m[0906 21-51-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08811, current rewards: -840.52009, mean: -0.34876
[32m[0906 21-51-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08811, current rewards: -890.52009, mean: -0.36200
[32m[0906 21-51-47 @Agent.py:117][0m Average action selection time: 0.0881
[32m[0906 21-51-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-51-47 @MBExp.py:227][0m Rewards obtained: [-930.5200887758622], Lows: [18], Highs: [1055], Total time: 21956.009841999996
[32m[0906 21-54-17 @MBExp.py:144][0m ####################################################################
[32m[0906 21-54-17 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 21-54-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08908, current rewards: -15.00000, mean: -1.50000
[32m[0906 21-54-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08953, current rewards: -115.00000, mean: -1.91667
[32m[0906 21-54-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08919, current rewards: -215.00000, mean: -1.95455
[32m[0906 21-54-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08860, current rewards: -315.00000, mean: -1.96875
[32m[0906 21-54-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08828, current rewards: -415.00000, mean: -1.97619
[32m[0906 21-54-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08807, current rewards: -515.00000, mean: -1.98077
[32m[0906 21-54-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08793, current rewards: -615.00000, mean: -1.98387
[32m[0906 21-54-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08812, current rewards: -715.00000, mean: -1.98611
[32m[0906 21-54-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08829, current rewards: -815.00000, mean: -1.98780
[32m[0906 21-54-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08844, current rewards: -915.00000, mean: -1.98913
[32m[0906 21-55-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08856, current rewards: -1015.00000, mean: -1.99020
[32m[0906 21-55-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08865, current rewards: -1115.00000, mean: -1.99107
[32m[0906 21-55-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08872, current rewards: -1215.00000, mean: -1.99180
[32m[0906 21-55-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08880, current rewards: -1315.00000, mean: -1.99242
[32m[0906 21-55-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08883, current rewards: -1415.00000, mean: -1.99296
[32m[0906 21-55-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08872, current rewards: -1515.00000, mean: -1.99342
[32m[0906 21-55-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08861, current rewards: -1615.00000, mean: -1.99383
[32m[0906 21-55-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08852, current rewards: -1715.00000, mean: -1.99419
[32m[0906 21-55-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08843, current rewards: -1815.00000, mean: -1.99451
[32m[0906 21-55-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08835, current rewards: -1915.00000, mean: -1.99479
[32m[0906 21-55-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08828, current rewards: -2015.00000, mean: -1.99505
[32m[0906 21-55-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08822, current rewards: -2115.00000, mean: -1.99528
[32m[0906 21-55-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08815, current rewards: -2215.00000, mean: -1.99550
[32m[0906 21-55-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08810, current rewards: -2315.00000, mean: -1.99569
[32m[0906 21-56-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08806, current rewards: -2415.00000, mean: -1.99587
[32m[0906 21-56-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08801, current rewards: -2515.00000, mean: -1.99603
[32m[0906 21-56-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08797, current rewards: -2615.00000, mean: -1.99618
[32m[0906 21-56-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08794, current rewards: -2715.00000, mean: -1.99632
[32m[0906 21-56-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08790, current rewards: -2815.00000, mean: -1.99645
[32m[0906 21-56-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08788, current rewards: -2915.00000, mean: -1.99658
[32m[0906 21-56-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08785, current rewards: -3015.00000, mean: -1.99669
[32m[0906 21-56-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08783, current rewards: -3115.00000, mean: -1.99679
[32m[0906 21-56-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08781, current rewards: -3215.00000, mean: -1.99689
[32m[0906 21-56-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08779, current rewards: -3315.00000, mean: -1.99699
[32m[0906 21-56-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08777, current rewards: -3415.00000, mean: -1.99708
[32m[0906 21-56-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08774, current rewards: -3515.00000, mean: -1.99716
[32m[0906 21-56-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08773, current rewards: -3615.00000, mean: -1.99724
[32m[0906 21-57-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08774, current rewards: -3715.00000, mean: -1.99731
[32m[0906 21-57-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08779, current rewards: -3815.00000, mean: -1.99738
[32m[0906 21-57-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08783, current rewards: -3915.00000, mean: -1.99745
[32m[0906 21-57-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08788, current rewards: -4015.00000, mean: -1.99751
[32m[0906 21-57-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08791, current rewards: -4115.00000, mean: -1.99757
[32m[0906 21-57-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08795, current rewards: -4215.00000, mean: -1.99763
[32m[0906 21-57-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08799, current rewards: -4315.00000, mean: -1.99769
[32m[0906 21-57-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08803, current rewards: -4415.00000, mean: -1.99774
[32m[0906 21-57-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08803, current rewards: -4515.00000, mean: -1.99779
[32m[0906 21-57-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08801, current rewards: -4615.00000, mean: -1.99784
[32m[0906 21-57-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08800, current rewards: -4715.00000, mean: -1.99788
[32m[0906 21-57-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08798, current rewards: -4815.00000, mean: -1.99793
[32m[0906 21-57-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08798, current rewards: -4915.00000, mean: -1.99797
[32m[0906 21-57-57 @Agent.py:117][0m Average action selection time: 0.0880
[32m[0906 21-57-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-57-57 @MBExp.py:227][0m Rewards obtained: [-4995], Lows: [2495], Highs: [5], Total time: 22176.746768999998
[32m[0906 22-00-28 @MBExp.py:144][0m ####################################################################
[32m[0906 22-00-28 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 22-00-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09421, current rewards: -14.00000, mean: -1.40000
[32m[0906 22-00-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09061, current rewards: -24.09417, mean: -0.40157
[32m[0906 22-00-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09016, current rewards: -18.59864, mean: -0.16908
[32m[0906 22-00-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08996, current rewards: -13.10612, mean: -0.08191
[32m[0906 22-00-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08941, current rewards: -7.61360, mean: -0.03626
[32m[0906 22-00-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08901, current rewards: -2.12446, mean: -0.00817
[32m[0906 22-00-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08869, current rewards: 3.36711, mean: 0.01086
[32m[0906 22-01-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08874, current rewards: 8.86542, mean: 0.02463
[32m[0906 22-01-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08887, current rewards: 15.66826, mean: 0.03822
[32m[0906 22-01-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08894, current rewards: 21.17992, mean: 0.04604
[32m[0906 22-01-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08904, current rewards: 26.69208, mean: 0.05234
[32m[0906 22-01-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08912, current rewards: 32.20125, mean: 0.05750
[32m[0906 22-01-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08920, current rewards: 17.64178, mean: 0.02892
[32m[0906 22-01-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08923, current rewards: -82.35822, mean: -0.12479
[32m[0906 22-01-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08920, current rewards: -182.35822, mean: -0.25684
[32m[0906 22-01-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08904, current rewards: -282.35822, mean: -0.37152
[32m[0906 22-01-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08891, current rewards: -344.85073, mean: -0.42574
[32m[0906 22-01-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08879, current rewards: -439.41258, mean: -0.51094
[32m[0906 22-01-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08869, current rewards: -539.41258, mean: -0.59276
[32m[0906 22-01-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08859, current rewards: -563.08026, mean: -0.58654
[32m[0906 22-01-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08852, current rewards: -557.47640, mean: -0.55196
[32m[0906 22-02-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08845, current rewards: -551.87447, mean: -0.52064
[32m[0906 22-02-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08839, current rewards: -546.26944, mean: -0.49213
[32m[0906 22-02-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08832, current rewards: -549.11021, mean: -0.47337
[32m[0906 22-02-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08828, current rewards: -544.93596, mean: -0.45036
[32m[0906 22-02-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08825, current rewards: -539.11959, mean: -0.42787
[32m[0906 22-02-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08821, current rewards: -533.06198, mean: -0.40692
[32m[0906 22-02-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08818, current rewards: -527.05902, mean: -0.38754
[32m[0906 22-02-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08815, current rewards: -521.00039, mean: -0.36950
[32m[0906 22-02-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08810, current rewards: -514.97816, mean: -0.35272
[32m[0906 22-02-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08807, current rewards: -508.94819, mean: -0.33705
[32m[0906 22-02-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08805, current rewards: -502.91966, mean: -0.32238
[32m[0906 22-02-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08807, current rewards: -509.59366, mean: -0.31652
[32m[0906 22-02-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08808, current rewards: -503.44919, mean: -0.30328
[32m[0906 22-02-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08806, current rewards: -497.17966, mean: -0.29075
[32m[0906 22-03-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08804, current rewards: -490.90961, mean: -0.27893
[32m[0906 22-03-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08800, current rewards: -484.63671, mean: -0.26776
[32m[0906 22-03-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08797, current rewards: -478.36813, mean: -0.25719
[32m[0906 22-03-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08795, current rewards: -472.10069, mean: -0.24717
[32m[0906 22-03-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08797, current rewards: -465.83118, mean: -0.23767
[32m[0906 22-03-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08802, current rewards: -459.56391, mean: -0.22864
[32m[0906 22-03-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08806, current rewards: -453.24891, mean: -0.22002
[32m[0906 22-03-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08810, current rewards: -446.98518, mean: -0.21184
[32m[0906 22-03-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08813, current rewards: -440.72103, mean: -0.20404
[32m[0906 22-03-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08816, current rewards: -434.45456, mean: -0.19659
[32m[0906 22-03-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08816, current rewards: -428.18609, mean: -0.18946
[32m[0906 22-03-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08814, current rewards: -421.92023, mean: -0.18265
[32m[0906 22-03-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08812, current rewards: -415.65260, mean: -0.17612
[32m[0906 22-04-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08810, current rewards: -417.15333, mean: -0.17309
[32m[0906 22-04-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08808, current rewards: -423.66032, mean: -0.17222
[32m[0906 22-04-09 @Agent.py:117][0m Average action selection time: 0.0881
[32m[0906 22-04-09 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-04-09 @MBExp.py:227][0m Rewards obtained: [-419.38951385230274], Lows: [335], Highs: [16], Total time: 22397.717474999998
[32m[0906 22-06-42 @MBExp.py:144][0m ####################################################################
[32m[0906 22-06-42 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 22-06-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08834, current rewards: 0.74251, mean: 0.07425
[32m[0906 22-06-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08969, current rewards: 5.09801, mean: 0.08497
[32m[0906 22-06-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08952, current rewards: 10.18798, mean: 0.09262
[32m[0906 22-06-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08928, current rewards: 15.28115, mean: 0.09551
[32m[0906 22-07-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08876, current rewards: 20.37012, mean: 0.09700
[32m[0906 22-07-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08842, current rewards: 25.46265, mean: 0.09793
[32m[0906 22-07-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08820, current rewards: 30.55485, mean: 0.09856
[32m[0906 22-07-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08826, current rewards: 35.64854, mean: 0.09902
[32m[0906 22-07-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08843, current rewards: 40.88303, mean: 0.09971
[32m[0906 22-07-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08858, current rewards: 45.83099, mean: 0.09963
[32m[0906 22-07-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08868, current rewards: 50.78235, mean: 0.09957
[32m[0906 22-07-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08875, current rewards: 55.73224, mean: 0.09952
[32m[0906 22-07-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08882, current rewards: 60.68396, mean: 0.09948
[32m[0906 22-07-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08885, current rewards: 65.63561, mean: 0.09945
[32m[0906 22-07-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08893, current rewards: 70.58692, mean: 0.09942
[32m[0906 22-07-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08887, current rewards: 75.53722, mean: 0.09939
[32m[0906 22-07-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08875, current rewards: 74.52665, mean: 0.09201
[32m[0906 22-07-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08866, current rewards: 79.64914, mean: 0.09262
[32m[0906 22-08-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08857, current rewards: 84.55087, mean: 0.09291
[32m[0906 22-08-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08848, current rewards: 89.45423, mean: 0.09318
[32m[0906 22-08-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08838, current rewards: 94.36113, mean: 0.09343
[32m[0906 22-08-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08833, current rewards: 101.74629, mean: 0.09599
[32m[0906 22-08-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08825, current rewards: 107.30761, mean: 0.09667
[32m[0906 22-08-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08820, current rewards: 112.10141, mean: 0.09664
[32m[0906 22-08-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08815, current rewards: 116.79810, mean: 0.09653
[32m[0906 22-08-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08810, current rewards: 121.64197, mean: 0.09654
[32m[0906 22-08-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08807, current rewards: 126.48790, mean: 0.09656
[32m[0906 22-08-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08802, current rewards: 131.33486, mean: 0.09657
[32m[0906 22-08-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08798, current rewards: 136.18475, mean: 0.09658
[32m[0906 22-08-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08795, current rewards: 141.03704, mean: 0.09660
[32m[0906 22-08-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08792, current rewards: 141.01180, mean: 0.09339
[32m[0906 22-08-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08788, current rewards: 145.84548, mean: 0.09349
[32m[0906 22-09-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08785, current rewards: 150.65121, mean: 0.09357
[32m[0906 22-09-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08783, current rewards: 155.38522, mean: 0.09361
[32m[0906 22-09-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08780, current rewards: 160.50746, mean: 0.09386
[32m[0906 22-09-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08778, current rewards: 165.62215, mean: 0.09410
[32m[0906 22-09-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08776, current rewards: 170.74800, mean: 0.09434
[32m[0906 22-09-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08774, current rewards: 165.20028, mean: 0.08882
[32m[0906 22-09-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08772, current rewards: 170.70595, mean: 0.08937
[32m[0906 22-09-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08775, current rewards: 176.21326, mean: 0.08990
[32m[0906 22-09-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08779, current rewards: 181.72226, mean: 0.09041
[32m[0906 22-09-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08783, current rewards: 187.12188, mean: 0.09084
[32m[0906 22-09-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08787, current rewards: 192.57943, mean: 0.09127
[32m[0906 22-09-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08791, current rewards: 198.03811, mean: 0.09168
[32m[0906 22-09-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08794, current rewards: 203.50067, mean: 0.09208
[32m[0906 22-10-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08795, current rewards: 208.96421, mean: 0.09246
[32m[0906 22-10-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08793, current rewards: 214.41840, mean: 0.09282
[32m[0906 22-10-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08791, current rewards: 219.87296, mean: 0.09317
[32m[0906 22-10-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08789, current rewards: 225.33397, mean: 0.09350
[32m[0906 22-10-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08788, current rewards: 230.79187, mean: 0.09382
[32m[0906 22-10-22 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0906 22-10-22 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-10-22 @MBExp.py:227][0m Rewards obtained: [235.15987930203866], Lows: [6], Highs: [12], Total time: 22618.113468999996
[32m[0906 22-12-56 @MBExp.py:144][0m ####################################################################
[32m[0906 22-12-56 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 22-12-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08925, current rewards: -5.73618, mean: -0.57362
[32m[0906 22-13-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08934, current rewards: -0.26379, mean: -0.00440
[32m[0906 22-13-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08960, current rewards: 5.21450, mean: 0.04740
[32m[0906 22-13-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08889, current rewards: 10.69110, mean: 0.06682
[32m[0906 22-13-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08842, current rewards: 16.16573, mean: 0.07698
[32m[0906 22-13-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08813, current rewards: 21.63982, mean: 0.08323
[32m[0906 22-13-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08800, current rewards: 27.11672, mean: 0.08747
[32m[0906 22-13-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08803, current rewards: 32.38029, mean: 0.08995
[32m[0906 22-13-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08823, current rewards: 37.85685, mean: 0.09233
[32m[0906 22-13-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08838, current rewards: 43.32583, mean: 0.09419
[32m[0906 22-13-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08851, current rewards: 38.24853, mean: 0.07500
[32m[0906 22-13-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08859, current rewards: 43.94722, mean: 0.07848
[32m[0906 22-13-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08867, current rewards: 49.37266, mean: 0.08094
[32m[0906 22-13-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08877, current rewards: 54.79681, mean: 0.08303
[32m[0906 22-14-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08881, current rewards: 60.21821, mean: 0.08481
[32m[0906 22-14-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08869, current rewards: 65.72538, mean: 0.08648
[32m[0906 22-14-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08857, current rewards: 71.14764, mean: 0.08784
[32m[0906 22-14-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08847, current rewards: 76.56996, mean: 0.08903
[32m[0906 22-14-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08840, current rewards: 81.99028, mean: 0.09010
[32m[0906 22-14-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08834, current rewards: 67.37246, mean: 0.07018
[32m[0906 22-14-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08826, current rewards: 73.01753, mean: 0.07229
[32m[0906 22-14-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08821, current rewards: 78.06014, mean: 0.07364
[32m[0906 22-14-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08816, current rewards: 83.10272, mean: 0.07487
[32m[0906 22-14-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08811, current rewards: 88.19555, mean: 0.07603
[32m[0906 22-14-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08806, current rewards: 93.24021, mean: 0.07706
[32m[0906 22-14-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08802, current rewards: 98.28634, mean: 0.07801
[32m[0906 22-14-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08799, current rewards: 103.33441, mean: 0.07888
[32m[0906 22-14-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08795, current rewards: 108.38466, mean: 0.07969
[32m[0906 22-15-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08793, current rewards: 113.42785, mean: 0.08045
[32m[0906 22-15-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08790, current rewards: 118.47212, mean: 0.08115
[32m[0906 22-15-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08787, current rewards: 113.28537, mean: 0.07502
[32m[0906 22-15-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08785, current rewards: 118.74384, mean: 0.07612
[32m[0906 22-15-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08782, current rewards: 124.20172, mean: 0.07714
[32m[0906 22-15-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08779, current rewards: 129.66270, mean: 0.07811
[32m[0906 22-15-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08777, current rewards: 135.12140, mean: 0.07902
[32m[0906 22-15-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08776, current rewards: 140.58220, mean: 0.07988
[32m[0906 22-15-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08773, current rewards: 134.85260, mean: 0.07450
[32m[0906 22-15-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08771, current rewards: 138.92388, mean: 0.07469
[32m[0906 22-15-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08769, current rewards: 142.99346, mean: 0.07487
[32m[0906 22-15-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08772, current rewards: 147.06221, mean: 0.07503
[32m[0906 22-15-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08776, current rewards: 151.13362, mean: 0.07519
[32m[0906 22-15-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08781, current rewards: 155.20350, mean: 0.07534
[32m[0906 22-16-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08784, current rewards: 159.27519, mean: 0.07549
[32m[0906 22-16-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08788, current rewards: 163.34696, mean: 0.07562
[32m[0906 22-16-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08791, current rewards: 167.41762, mean: 0.07575
[32m[0906 22-16-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08794, current rewards: 171.48679, mean: 0.07588
[32m[0906 22-16-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08793, current rewards: 168.78366, mean: 0.07307
[32m[0906 22-16-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08791, current rewards: 172.74024, mean: 0.07320
[32m[0906 22-16-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08789, current rewards: 178.35522, mean: 0.07401
[32m[0906 22-16-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08787, current rewards: 183.96800, mean: 0.07478
[32m[0906 22-16-37 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0906 22-16-37 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-16-37 @MBExp.py:227][0m Rewards obtained: [178.33674060523413], Lows: [29], Highs: [17], Total time: 22838.471605999996
[32m[0906 22-19-13 @MBExp.py:144][0m ####################################################################
[32m[0906 22-19-13 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 22-19-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08846, current rewards: -4.64748, mean: -0.46475
[32m[0906 22-19-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08975, current rewards: 0.48299, mean: 0.00805
[32m[0906 22-19-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08971, current rewards: 5.66191, mean: 0.05147
[32m[0906 22-19-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08897, current rewards: 10.83762, mean: 0.06774
[32m[0906 22-19-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08853, current rewards: 16.01486, mean: 0.07626
[32m[0906 22-19-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08823, current rewards: 21.21893, mean: 0.08161
[32m[0906 22-19-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08806, current rewards: 13.92512, mean: 0.04492
[32m[0906 22-19-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08807, current rewards: 19.18360, mean: 0.05329
[32m[0906 22-19-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08833, current rewards: 24.43980, mean: 0.05961
[32m[0906 22-19-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08847, current rewards: 29.69571, mean: 0.06456
[32m[0906 22-19-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08859, current rewards: 34.95141, mean: 0.06853
[32m[0906 22-20-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08870, current rewards: 40.20777, mean: 0.07180
[32m[0906 22-20-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08880, current rewards: 40.49398, mean: 0.06638
[32m[0906 22-20-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08888, current rewards: 45.94647, mean: 0.06962
[32m[0906 22-20-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08890, current rewards: 51.39335, mean: 0.07239
[32m[0906 22-20-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08879, current rewards: 56.90070, mean: 0.07487
[32m[0906 22-20-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08869, current rewards: 62.40445, mean: 0.07704
[32m[0906 22-20-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08858, current rewards: 67.90697, mean: 0.07896
[32m[0906 22-20-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08851, current rewards: 73.41491, mean: 0.08068
[32m[0906 22-20-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08846, current rewards: 78.91607, mean: 0.08220
[32m[0906 22-20-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08839, current rewards: 84.41825, mean: 0.08358
[32m[0906 22-20-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08834, current rewards: 89.92631, mean: 0.08484
[32m[0906 22-20-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08829, current rewards: 96.02865, mean: 0.08651
[32m[0906 22-20-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08825, current rewards: 101.53908, mean: 0.08753
[32m[0906 22-21-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08821, current rewards: 93.88614, mean: 0.07759
[32m[0906 22-21-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08817, current rewards: 89.55404, mean: 0.07107
[32m[0906 22-21-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08813, current rewards: 86.44067, mean: 0.06599
[32m[0906 22-21-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08809, current rewards: 91.69049, mean: 0.06742
[32m[0906 22-21-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08805, current rewards: 96.92896, mean: 0.06874
[32m[0906 22-21-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08803, current rewards: 104.09821, mean: 0.07130
[32m[0906 22-21-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08799, current rewards: 109.12930, mean: 0.07227
[32m[0906 22-21-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08796, current rewards: 114.36513, mean: 0.07331
[32m[0906 22-21-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08795, current rewards: 119.60307, mean: 0.07429
[32m[0906 22-21-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08793, current rewards: 124.83647, mean: 0.07520
[32m[0906 22-21-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08791, current rewards: 130.07591, mean: 0.07607
[32m[0906 22-21-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08788, current rewards: 135.31047, mean: 0.07688
[32m[0906 22-21-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08786, current rewards: 140.54688, mean: 0.07765
[32m[0906 22-21-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08784, current rewards: 145.78076, mean: 0.07838
[32m[0906 22-22-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08781, current rewards: 151.26538, mean: 0.07920
[32m[0906 22-22-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08782, current rewards: 156.59033, mean: 0.07989
[32m[0906 22-22-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08786, current rewards: 152.33552, mean: 0.07579
[32m[0906 22-22-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08791, current rewards: 157.94467, mean: 0.07667
[32m[0906 22-22-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08795, current rewards: 163.55615, mean: 0.07751
[32m[0906 22-22-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08799, current rewards: 169.16982, mean: 0.07832
[32m[0906 22-22-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08803, current rewards: 174.77887, mean: 0.07909
[32m[0906 22-22-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08807, current rewards: 180.38567, mean: 0.07982
[32m[0906 22-22-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08807, current rewards: 179.07357, mean: 0.07752
[32m[0906 22-22-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08805, current rewards: 184.52707, mean: 0.07819
[32m[0906 22-22-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08802, current rewards: 190.01960, mean: 0.07885
[32m[0906 22-22-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08800, current rewards: 195.50934, mean: 0.07948
[32m[0906 22-22-54 @Agent.py:117][0m Average action selection time: 0.0880
[32m[0906 22-22-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-22-54 @MBExp.py:227][0m Rewards obtained: [199.90533762697086], Lows: [34], Highs: [21], Total time: 23059.149783999994
[32m[0906 22-25-32 @MBExp.py:144][0m ####################################################################
[32m[0906 22-25-32 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 22-25-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08789, current rewards: -5.56058, mean: -0.55606
[32m[0906 22-25-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08928, current rewards: -0.97244, mean: -0.01621
[32m[0906 22-25-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08876, current rewards: 3.60963, mean: 0.03281
[32m[0906 22-25-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08819, current rewards: 8.19224, mean: 0.05120
[32m[0906 22-25-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08786, current rewards: 12.77540, mean: 0.06084
[32m[0906 22-25-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08767, current rewards: 17.14945, mean: 0.06596
[32m[0906 22-25-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08756, current rewards: 21.70029, mean: 0.07000
[32m[0906 22-26-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08755, current rewards: 26.25154, mean: 0.07292
[32m[0906 22-26-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08778, current rewards: 30.80142, mean: 0.07513
[32m[0906 22-26-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08800, current rewards: 30.04858, mean: 0.06532
[32m[0906 22-26-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08818, current rewards: 34.35821, mean: 0.06737
[32m[0906 22-26-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08834, current rewards: 38.66453, mean: 0.06904
[32m[0906 22-26-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08844, current rewards: 42.96796, mean: 0.07044
[32m[0906 22-26-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08854, current rewards: 47.01738, mean: 0.07124
[32m[0906 22-26-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08850, current rewards: 51.22420, mean: 0.07215
[32m[0906 22-26-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08842, current rewards: 55.42929, mean: 0.07293
[32m[0906 22-26-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08834, current rewards: 49.39997, mean: 0.06099
[32m[0906 22-26-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08828, current rewards: 54.16514, mean: 0.06298
[32m[0906 22-26-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08822, current rewards: 58.93103, mean: 0.06476
[32m[0906 22-26-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08816, current rewards: 63.69210, mean: 0.06635
[32m[0906 22-27-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08810, current rewards: 68.45391, mean: 0.06778
[32m[0906 22-27-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08821, current rewards: 73.36878, mean: 0.06922
[32m[0906 22-27-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08861, current rewards: 78.84562, mean: 0.07103
[32m[0906 22-27-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08898, current rewards: 83.81089, mean: 0.07225
[32m[0906 22-27-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08930, current rewards: 83.21697, mean: 0.06877
[32m[0906 22-27-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08961, current rewards: 88.10934, mean: 0.06993
[32m[0906 22-27-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08989, current rewards: 93.00200, mean: 0.07099
[32m[0906 22-27-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09015, current rewards: 97.89095, mean: 0.07198
[32m[0906 22-27-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09041, current rewards: 102.78094, mean: 0.07289
[32m[0906 22-27-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09064, current rewards: 107.66654, mean: 0.07374
[32m[0906 22-27-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09085, current rewards: 112.35268, mean: 0.07441
[32m[0906 22-27-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09105, current rewards: 117.25208, mean: 0.07516
[32m[0906 22-27-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09124, current rewards: 122.15729, mean: 0.07587
[32m[0906 22-28-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09141, current rewards: 127.05834, mean: 0.07654
[32m[0906 22-28-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09157, current rewards: 131.95650, mean: 0.07717
[32m[0906 22-28-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09174, current rewards: 136.85954, mean: 0.07776
[32m[0906 22-28-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09189, current rewards: 141.76331, mean: 0.07832
[32m[0906 22-28-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09204, current rewards: 146.98570, mean: 0.07902
[32m[0906 22-28-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09217, current rewards: 151.45831, mean: 0.07930
[32m[0906 22-28-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09234, current rewards: 156.01317, mean: 0.07960
[32m[0906 22-28-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09253, current rewards: 160.56328, mean: 0.07988
[32m[0906 22-28-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09271, current rewards: 165.10521, mean: 0.08015
[32m[0906 22-28-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09288, current rewards: 169.64629, mean: 0.08040
[32m[0906 22-28-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09304, current rewards: 174.19509, mean: 0.08065
[32m[0906 22-28-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09321, current rewards: 178.73895, mean: 0.08088
[32m[0906 22-29-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09336, current rewards: 173.03844, mean: 0.07657
[32m[0906 22-29-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09345, current rewards: 179.96010, mean: 0.07790
[32m[0906 22-29-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09352, current rewards: 186.49263, mean: 0.07902
[32m[0906 22-29-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09359, current rewards: 193.02525, mean: 0.08009
[32m[0906 22-29-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09366, current rewards: 199.55967, mean: 0.08112
[32m[0906 22-29-26 @Agent.py:117][0m Average action selection time: 0.0937
[32m[0906 22-29-26 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-29-27 @MBExp.py:227][0m Rewards obtained: [204.78926980095375], Lows: [10], Highs: [16], Total time: 23294.183735999995
[32m[0906 22-32-23 @MBExp.py:144][0m ####################################################################
[32m[0906 22-32-23 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 22-32-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10006, current rewards: 1.24861, mean: 0.12486
[32m[0906 22-32-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10002, current rewards: 7.42629, mean: 0.12377
[32m[0906 22-32-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09877, current rewards: 13.60398, mean: 0.12367
[32m[0906 22-32-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09826, current rewards: 19.78166, mean: 0.12364
[32m[0906 22-32-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09798, current rewards: 25.69158, mean: 0.12234
[32m[0906 22-32-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09774, current rewards: 28.91074, mean: 0.11120
[32m[0906 22-32-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09769, current rewards: 32.11307, mean: 0.10359
[32m[0906 22-32-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09756, current rewards: 35.31540, mean: 0.09810
[32m[0906 22-33-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09789, current rewards: 38.51772, mean: 0.09395
[32m[0906 22-33-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09810, current rewards: 41.72005, mean: 0.09070
[32m[0906 22-33-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09836, current rewards: 44.92238, mean: 0.08808
[32m[0906 22-33-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09849, current rewards: 48.12471, mean: 0.08594
[32m[0906 22-33-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09861, current rewards: 10.89326, mean: 0.01786
[32m[0906 22-33-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09804, current rewards: -39.10674, mean: -0.05925
[32m[0906 22-33-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09725, current rewards: -89.10674, mean: -0.12550
[32m[0906 22-33-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09659, current rewards: -139.10674, mean: -0.18304
[32m[0906 22-33-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09598, current rewards: -189.10674, mean: -0.23347
[32m[0906 22-33-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09548, current rewards: -239.10674, mean: -0.27803
[32m[0906 22-33-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09502, current rewards: -289.10674, mean: -0.31770
[32m[0906 22-33-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09462, current rewards: -339.10674, mean: -0.35324
[32m[0906 22-33-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09426, current rewards: -389.10674, mean: -0.38525
[32m[0906 22-34-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09391, current rewards: -439.10674, mean: -0.41425
[32m[0906 22-34-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09361, current rewards: -489.10674, mean: -0.44064
[32m[0906 22-34-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09333, current rewards: -539.10674, mean: -0.46475
[32m[0906 22-34-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09306, current rewards: -589.10674, mean: -0.48687
[32m[0906 22-34-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09282, current rewards: -639.10674, mean: -0.50723
[32m[0906 22-34-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09261, current rewards: -689.10674, mean: -0.52604
[32m[0906 22-34-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09241, current rewards: -739.10674, mean: -0.54346
[32m[0906 22-34-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09222, current rewards: -789.10674, mean: -0.55965
[32m[0906 22-34-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09204, current rewards: -839.10674, mean: -0.57473
[32m[0906 22-34-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09187, current rewards: -889.10674, mean: -0.58881
[32m[0906 22-34-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09171, current rewards: -939.10674, mean: -0.60199
[32m[0906 22-34-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09158, current rewards: -989.10674, mean: -0.61435
[32m[0906 22-34-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09144, current rewards: -1039.10674, mean: -0.62597
[32m[0906 22-35-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09131, current rewards: -1089.10674, mean: -0.63690
[32m[0906 22-35-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09120, current rewards: -1139.10674, mean: -0.64722
[32m[0906 22-35-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09108, current rewards: -1189.10674, mean: -0.65697
[32m[0906 22-35-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09098, current rewards: -1239.10674, mean: -0.66619
[32m[0906 22-35-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09088, current rewards: -1289.10674, mean: -0.67492
[32m[0906 22-35-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09082, current rewards: -1339.10674, mean: -0.68322
[32m[0906 22-35-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09079, current rewards: -1389.10674, mean: -0.69110
[32m[0906 22-35-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09076, current rewards: -1439.10674, mean: -0.69860
[32m[0906 22-35-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09073, current rewards: -1489.10674, mean: -0.70574
[32m[0906 22-35-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09071, current rewards: -1539.10674, mean: -0.71255
[32m[0906 22-35-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09069, current rewards: -1589.10674, mean: -0.71905
[32m[0906 22-35-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09067, current rewards: -1639.10674, mean: -0.72527
[32m[0906 22-35-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09063, current rewards: -1689.10674, mean: -0.73122
[32m[0906 22-35-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09055, current rewards: -1739.10674, mean: -0.73691
[32m[0906 22-36-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09048, current rewards: -1789.10674, mean: -0.74237
[32m[0906 22-36-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09041, current rewards: -1839.10674, mean: -0.74760
[32m[0906 22-36-10 @Agent.py:117][0m Average action selection time: 0.0904
[32m[0906 22-36-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-36-10 @MBExp.py:227][0m Rewards obtained: [-1879.1067354943218], Lows: [0], Highs: [1928], Total time: 23520.797468999994
[32m[0906 22-38-52 @MBExp.py:144][0m ####################################################################
[32m[0906 22-38-52 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 22-38-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08966, current rewards: -4.52285, mean: -0.45228
[32m[0906 22-38-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09575, current rewards: -55.37295, mean: -0.92288
[32m[0906 22-39-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09825, current rewards: -100.82346, mean: -0.91658
[32m[0906 22-39-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09778, current rewards: -155.08989, mean: -0.96931
[32m[0906 22-39-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09714, current rewards: -193.57632, mean: -0.92179
[32m[0906 22-39-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09808, current rewards: -231.07721, mean: -0.88876
[32m[0906 22-39-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09790, current rewards: -277.50131, mean: -0.89517
[32m[0906 22-39-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09741, current rewards: -324.98422, mean: -0.90273
[32m[0906 22-39-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09674, current rewards: -352.82124, mean: -0.86054
[32m[0906 22-39-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09660, current rewards: -385.22452, mean: -0.83744
[32m[0906 22-39-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09634, current rewards: -420.01901, mean: -0.82357
[32m[0906 22-39-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09629, current rewards: -432.45176, mean: -0.77224
[32m[0906 22-39-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09561, current rewards: -460.76883, mean: -0.75536
[32m[0906 22-39-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09495, current rewards: -499.98997, mean: -0.75756
[32m[0906 22-39-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09438, current rewards: -487.98904, mean: -0.68731
[32m[0906 22-40-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09398, current rewards: -483.94290, mean: -0.63677
[32m[0906 22-40-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09353, current rewards: -498.94667, mean: -0.61598
[32m[0906 22-40-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09327, current rewards: -543.69080, mean: -0.63220
[32m[0906 22-40-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09293, current rewards: -537.85775, mean: -0.59105
[32m[0906 22-40-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09274, current rewards: -538.72331, mean: -0.56117
[32m[0906 22-40-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09246, current rewards: -541.69961, mean: -0.53634
[32m[0906 22-40-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09219, current rewards: -535.22315, mean: -0.50493
[32m[0906 22-40-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09197, current rewards: -528.81211, mean: -0.47641
[32m[0906 22-40-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09176, current rewards: -522.39115, mean: -0.45034
[32m[0906 22-40-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09156, current rewards: -515.95844, mean: -0.42641
[32m[0906 22-40-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09139, current rewards: -509.53946, mean: -0.40440
[32m[0906 22-40-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09122, current rewards: -503.11772, mean: -0.38406
[32m[0906 22-40-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09106, current rewards: -500.07387, mean: -0.36770
[32m[0906 22-41-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09103, current rewards: -497.54546, mean: -0.35287
[32m[0906 22-41-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09133, current rewards: -528.25750, mean: -0.36182
[32m[0906 22-41-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09154, current rewards: -568.34693, mean: -0.37639
[32m[0906 22-41-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09176, current rewards: -575.58990, mean: -0.36897
[32m[0906 22-41-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09207, current rewards: -622.32782, mean: -0.38654
[32m[0906 22-41-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09276, current rewards: -686.85533, mean: -0.41377
[32m[0906 22-41-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09284, current rewards: -699.57025, mean: -0.40911
[32m[0906 22-41-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09277, current rewards: -714.07672, mean: -0.40573
[32m[0906 22-41-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09281, current rewards: -714.18629, mean: -0.39458
[32m[0906 22-41-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09276, current rewards: -728.63168, mean: -0.39174
[32m[0906 22-41-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09267, current rewards: -723.72312, mean: -0.37891
[32m[0906 22-41-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09259, current rewards: -718.82215, mean: -0.36675
[32m[0906 22-41-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09251, current rewards: -713.91456, mean: -0.35518
[32m[0906 22-42-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09245, current rewards: -709.01114, mean: -0.34418
[32m[0906 22-42-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09239, current rewards: -704.10691, mean: -0.33370
[32m[0906 22-42-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09234, current rewards: -699.20286, mean: -0.32371
[32m[0906 22-42-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09223, current rewards: -694.30190, mean: -0.31416
[32m[0906 22-42-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09211, current rewards: -689.19091, mean: -0.30495
[32m[0906 22-42-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09200, current rewards: -684.32062, mean: -0.29624
[32m[0906 22-42-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09189, current rewards: -679.45672, mean: -0.28791
[32m[0906 22-42-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09182, current rewards: -674.59306, mean: -0.27991
[32m[0906 22-42-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09181, current rewards: -680.98143, mean: -0.27682
[32m[0906 22-42-42 @Agent.py:117][0m Average action selection time: 0.0919
[32m[0906 22-42-42 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-42-42 @MBExp.py:227][0m Rewards obtained: [-675.1135345151658], Lows: [473], Highs: [41], Total time: 23751.177144999994
[32m[0906 22-45-25 @MBExp.py:144][0m ####################################################################
[32m[0906 22-45-25 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 22-45-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09309, current rewards: -4.48707, mean: -0.44871
[32m[0906 22-45-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08823, current rewards: 1.49910, mean: 0.02499
[32m[0906 22-45-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08782, current rewards: 7.50992, mean: 0.06827
[32m[0906 22-45-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08758, current rewards: 13.51678, mean: 0.08448
[32m[0906 22-45-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08750, current rewards: 19.52686, mean: 0.09299
[32m[0906 22-45-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08744, current rewards: 25.53739, mean: 0.09822
[32m[0906 22-45-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08787, current rewards: 31.54954, mean: 0.10177
[32m[0906 22-45-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08811, current rewards: 37.55490, mean: 0.10432
[32m[0906 22-46-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08828, current rewards: 43.56078, mean: 0.10625
[32m[0906 22-46-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08844, current rewards: 49.57425, mean: 0.10777
[32m[0906 22-46-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08859, current rewards: 55.58620, mean: 0.10899
[32m[0906 22-46-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08849, current rewards: 61.70239, mean: 0.11018
[32m[0906 22-46-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08836, current rewards: 68.12461, mean: 0.11168
[32m[0906 22-46-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08825, current rewards: 74.15853, mean: 0.11236
[32m[0906 22-46-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08816, current rewards: 80.20127, mean: 0.11296
[32m[0906 22-46-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08809, current rewards: 86.23953, mean: 0.11347
[32m[0906 22-46-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08803, current rewards: 85.69046, mean: 0.10579
[32m[0906 22-46-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08798, current rewards: 90.32196, mean: 0.10503
[32m[0906 22-46-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08793, current rewards: 94.95328, mean: 0.10434
[32m[0906 22-46-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08788, current rewards: 99.58365, mean: 0.10373
[32m[0906 22-46-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08786, current rewards: 104.58608, mean: 0.10355
[32m[0906 22-46-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08783, current rewards: 109.37832, mean: 0.10319
[32m[0906 22-47-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08780, current rewards: 114.16434, mean: 0.10285
[32m[0906 22-47-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08778, current rewards: 118.95858, mean: 0.10255
[32m[0906 22-47-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08777, current rewards: 123.74740, mean: 0.10227
[32m[0906 22-47-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08776, current rewards: 128.53790, mean: 0.10201
[32m[0906 22-47-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08772, current rewards: 133.32567, mean: 0.10178
[32m[0906 22-47-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08771, current rewards: 138.11600, mean: 0.10156
[32m[0906 22-47-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08769, current rewards: 131.56970, mean: 0.09331
[32m[0906 22-47-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08767, current rewards: 137.13241, mean: 0.09393
[32m[0906 22-47-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08766, current rewards: 142.70576, mean: 0.09451
[32m[0906 22-47-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08765, current rewards: 148.28912, mean: 0.09506
[32m[0906 22-47-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08762, current rewards: 153.86046, mean: 0.09557
[32m[0906 22-47-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08761, current rewards: 159.43962, mean: 0.09605
[32m[0906 22-47-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08759, current rewards: 165.01806, mean: 0.09650
[32m[0906 22-48-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08758, current rewards: 170.59695, mean: 0.09693
[32m[0906 22-48-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08758, current rewards: 177.23085, mean: 0.09792
[32m[0906 22-48-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08764, current rewards: 182.87832, mean: 0.09832
[32m[0906 22-48-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08770, current rewards: 182.98344, mean: 0.09580
[32m[0906 22-48-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08776, current rewards: 188.26945, mean: 0.09606
[32m[0906 22-48-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08781, current rewards: 193.55690, mean: 0.09630
[32m[0906 22-48-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08786, current rewards: 198.84258, mean: 0.09653
[32m[0906 22-48-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08790, current rewards: 204.12437, mean: 0.09674
[32m[0906 22-48-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08795, current rewards: 209.40792, mean: 0.09695
[32m[0906 22-48-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08794, current rewards: 214.52486, mean: 0.09707
[32m[0906 22-48-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08793, current rewards: 219.49646, mean: 0.09712
[32m[0906 22-48-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08791, current rewards: 224.68323, mean: 0.09727
[32m[0906 22-48-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08789, current rewards: 229.87831, mean: 0.09741
[32m[0906 22-48-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08787, current rewards: 235.06753, mean: 0.09754
[32m[0906 22-49-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08790, current rewards: 222.24427, mean: 0.09034
[32m[0906 22-49-06 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0906 22-49-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-49-06 @MBExp.py:227][0m Rewards obtained: [226.28303618375685], Lows: [15], Highs: [15], Total time: 23971.731578999996
[32m[0906 22-51-51 @MBExp.py:144][0m ####################################################################
[32m[0906 22-51-51 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 22-51-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09214, current rewards: -7.26006, mean: -0.72601
[32m[0906 22-51-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08792, current rewards: -17.67905, mean: -0.29465
[32m[0906 22-52-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08755, current rewards: -11.44104, mean: -0.10401
[32m[0906 22-52-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08746, current rewards: -10.92471, mean: -0.06828
[32m[0906 22-52-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08737, current rewards: -45.97446, mean: -0.21893
[32m[0906 22-52-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08729, current rewards: -93.87224, mean: -0.36105
[32m[0906 22-52-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08756, current rewards: -141.76780, mean: -0.45732
[32m[0906 22-52-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08789, current rewards: -189.65578, mean: -0.52682
[32m[0906 22-52-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08809, current rewards: -216.79593, mean: -0.52877
[32m[0906 22-52-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08828, current rewards: -211.18269, mean: -0.45909
[32m[0906 22-52-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08842, current rewards: -205.57049, mean: -0.40308
[32m[0906 22-52-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08830, current rewards: -200.33389, mean: -0.35774
[32m[0906 22-52-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08820, current rewards: -194.93978, mean: -0.31957
[32m[0906 22-52-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08810, current rewards: -190.30143, mean: -0.28834
[32m[0906 22-52-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08802, current rewards: -186.71013, mean: -0.26297
[32m[0906 22-52-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08794, current rewards: -183.12221, mean: -0.24095
[32m[0906 22-53-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08788, current rewards: -179.52987, mean: -0.22164
[32m[0906 22-53-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08783, current rewards: -175.93760, mean: -0.20458
[32m[0906 22-53-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08780, current rewards: -172.34653, mean: -0.18939
[32m[0906 22-53-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08775, current rewards: -168.75281, mean: -0.17578
[32m[0906 22-53-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08771, current rewards: -165.21147, mean: -0.16358
[32m[0906 22-53-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08767, current rewards: -161.64068, mean: -0.15249
[32m[0906 22-53-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08765, current rewards: -158.07012, mean: -0.14241
[32m[0906 22-53-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08762, current rewards: -154.49694, mean: -0.13319
[32m[0906 22-53-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08761, current rewards: -150.92030, mean: -0.12473
[32m[0906 22-53-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08759, current rewards: -147.34628, mean: -0.11694
[32m[0906 22-53-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08757, current rewards: -143.77072, mean: -0.10975
[32m[0906 22-53-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08755, current rewards: -140.19667, mean: -0.10309
[32m[0906 22-53-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08766, current rewards: -186.94084, mean: -0.13258
[32m[0906 22-53-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08763, current rewards: -236.94084, mean: -0.16229
[32m[0906 22-54-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08761, current rewards: -286.94084, mean: -0.19003
[32m[0906 22-54-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08761, current rewards: -336.94084, mean: -0.21599
[32m[0906 22-54-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08760, current rewards: -386.94084, mean: -0.24034
[32m[0906 22-54-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08761, current rewards: -436.94084, mean: -0.26322
[32m[0906 22-54-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08760, current rewards: -459.78889, mean: -0.26888
[32m[0906 22-54-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08759, current rewards: -454.73901, mean: -0.25837
[32m[0906 22-54-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08758, current rewards: -449.83852, mean: -0.24853
[32m[0906 22-54-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08759, current rewards: -445.30293, mean: -0.23941
[32m[0906 22-54-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08763, current rewards: -440.76734, mean: -0.23077
[32m[0906 22-54-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08768, current rewards: -436.23175, mean: -0.22257
[32m[0906 22-54-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08774, current rewards: -469.87108, mean: -0.23377
[32m[0906 22-54-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08779, current rewards: -519.87108, mean: -0.25236
[32m[0906 22-54-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08784, current rewards: -569.87108, mean: -0.27008
[32m[0906 22-55-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08788, current rewards: -619.87108, mean: -0.28698
[32m[0906 22-55-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08788, current rewards: -669.87108, mean: -0.30311
[32m[0906 22-55-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08786, current rewards: -719.87108, mean: -0.31853
[32m[0906 22-55-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08784, current rewards: -769.87108, mean: -0.33328
[32m[0906 22-55-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08783, current rewards: -819.87108, mean: -0.34740
[32m[0906 22-55-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08782, current rewards: -869.87108, mean: -0.36094
[32m[0906 22-55-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08782, current rewards: -919.87108, mean: -0.37393
[32m[0906 22-55-31 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0906 22-55-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-55-31 @MBExp.py:227][0m Rewards obtained: [-959.8710771585904], Lows: [8], Highs: [1070], Total time: 24192.085187999997
[32m[0906 22-58-18 @MBExp.py:144][0m ####################################################################
[32m[0906 22-58-18 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 22-58-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08890, current rewards: -8.91339, mean: -0.89134
[32m[0906 22-58-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08951, current rewards: -9.03857, mean: -0.15064
[32m[0906 22-58-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08963, current rewards: -3.24599, mean: -0.02951
[32m[0906 22-58-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08961, current rewards: 4.50617, mean: 0.02816
[32m[0906 22-58-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08907, current rewards: 10.31541, mean: 0.04912
[32m[0906 22-58-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08862, current rewards: 16.12051, mean: 0.06200
[32m[0906 22-58-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08867, current rewards: 21.93835, mean: 0.07077
[32m[0906 22-58-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08881, current rewards: 27.75375, mean: 0.07709
[32m[0906 22-58-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08888, current rewards: 33.56662, mean: 0.08187
[32m[0906 22-58-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08899, current rewards: 33.79360, mean: 0.07346
[32m[0906 22-59-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08895, current rewards: 36.66376, mean: 0.07189
[32m[0906 22-59-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08880, current rewards: 41.91049, mean: 0.07484
[32m[0906 22-59-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08863, current rewards: 47.21167, mean: 0.07740
[32m[0906 22-59-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08852, current rewards: 52.83297, mean: 0.08005
[32m[0906 22-59-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08840, current rewards: 58.45645, mean: 0.08233
[32m[0906 22-59-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08835, current rewards: 64.08555, mean: 0.08432
[32m[0906 22-59-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08825, current rewards: 69.71266, mean: 0.08607
[32m[0906 22-59-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08818, current rewards: 75.33357, mean: 0.08760
[32m[0906 22-59-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08810, current rewards: 80.96484, mean: 0.08897
[32m[0906 22-59-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08802, current rewards: 86.59521, mean: 0.09020
[32m[0906 22-59-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08799, current rewards: 92.56801, mean: 0.09165
[32m[0906 22-59-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08795, current rewards: 92.60680, mean: 0.08736
[32m[0906 22-59-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08790, current rewards: 97.53441, mean: 0.08787
[32m[0906 23-00-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08786, current rewards: 102.45940, mean: 0.08833
[32m[0906 23-00-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08783, current rewards: 107.38262, mean: 0.08875
[32m[0906 23-00-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08779, current rewards: 99.66671, mean: 0.07910
[32m[0906 23-00-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08776, current rewards: 106.23449, mean: 0.08110
[32m[0906 23-00-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08772, current rewards: 112.91163, mean: 0.08302
[32m[0906 23-00-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08768, current rewards: 119.28762, mean: 0.08460
[32m[0906 23-00-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08767, current rewards: 126.00414, mean: 0.08630
[32m[0906 23-00-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08764, current rewards: 132.72233, mean: 0.08790
[32m[0906 23-00-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08761, current rewards: 139.44122, mean: 0.08939
[32m[0906 23-00-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08760, current rewards: 146.15556, mean: 0.09078
[32m[0906 23-00-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08759, current rewards: 152.87550, mean: 0.09209
[32m[0906 23-00-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08758, current rewards: 159.59442, mean: 0.09333
[32m[0906 23-00-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08756, current rewards: 166.31259, mean: 0.09450
[32m[0906 23-00-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08755, current rewards: 173.71498, mean: 0.09598
[32m[0906 23-01-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08753, current rewards: 180.39863, mean: 0.09699
[32m[0906 23-01-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08752, current rewards: 187.07658, mean: 0.09795
[32m[0906 23-01-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08750, current rewards: 193.76095, mean: 0.09886
[32m[0906 23-01-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08748, current rewards: 191.93152, mean: 0.09549
[32m[0906 23-01-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08747, current rewards: 197.31629, mean: 0.09578
[32m[0906 23-01-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08746, current rewards: 202.63904, mean: 0.09604
[32m[0906 23-01-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08750, current rewards: 207.95645, mean: 0.09628
[32m[0906 23-01-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08751, current rewards: 213.67514, mean: 0.09669
[32m[0906 23-01-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08750, current rewards: 219.19399, mean: 0.09699
[32m[0906 23-01-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08748, current rewards: 224.56405, mean: 0.09721
[32m[0906 23-01-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08747, current rewards: 229.93584, mean: 0.09743
[32m[0906 23-01-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08746, current rewards: 235.29684, mean: 0.09763
[32m[0906 23-01-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08746, current rewards: 240.66580, mean: 0.09783
[32m[0906 23-01-57 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0906 23-01-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-01-57 @MBExp.py:227][0m Rewards obtained: [244.9614701381943], Lows: [7], Highs: [32], Total time: 24411.571616999998
[32m[0906 23-04-46 @MBExp.py:144][0m ####################################################################
[32m[0906 23-04-46 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 23-04-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08880, current rewards: -11.93404, mean: -1.19340
[32m[0906 23-04-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08962, current rewards: -10.49696, mean: -0.17495
[32m[0906 23-04-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08955, current rewards: -4.89028, mean: -0.04446
[32m[0906 23-05-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08936, current rewards: 0.67799, mean: 0.00424
[32m[0906 23-05-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08884, current rewards: 6.29983, mean: 0.03000
[32m[0906 23-05-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08852, current rewards: 11.91651, mean: 0.04583
[32m[0906 23-05-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08848, current rewards: 17.53327, mean: 0.05656
[32m[0906 23-05-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08863, current rewards: 23.15127, mean: 0.06431
[32m[0906 23-05-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08873, current rewards: 28.76832, mean: 0.07017
[32m[0906 23-05-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08880, current rewards: 34.38312, mean: 0.07475
[32m[0906 23-05-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08870, current rewards: 39.99638, mean: 0.07842
[32m[0906 23-05-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08856, current rewards: 46.38023, mean: 0.08282
[32m[0906 23-05-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08844, current rewards: 41.53882, mean: 0.06810
[32m[0906 23-05-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08834, current rewards: 46.13028, mean: 0.06989
[32m[0906 23-05-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08826, current rewards: 50.72139, mean: 0.07144
[32m[0906 23-05-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08817, current rewards: 55.31229, mean: 0.07278
[32m[0906 23-05-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08812, current rewards: 59.90314, mean: 0.07395
[32m[0906 23-06-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08806, current rewards: 64.49405, mean: 0.07499
[32m[0906 23-06-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08800, current rewards: 69.08614, mean: 0.07592
[32m[0906 23-06-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08794, current rewards: 73.33499, mean: 0.07639
[32m[0906 23-06-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08793, current rewards: 67.60060, mean: 0.06693
[32m[0906 23-06-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08789, current rewards: 70.88300, mean: 0.06687
[32m[0906 23-06-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08785, current rewards: 74.16991, mean: 0.06682
[32m[0906 23-06-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08782, current rewards: 77.23717, mean: 0.06658
[32m[0906 23-06-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08779, current rewards: 80.16521, mean: 0.06625
[32m[0906 23-06-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08776, current rewards: 83.08527, mean: 0.06594
[32m[0906 23-06-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08774, current rewards: 86.01328, mean: 0.06566
[32m[0906 23-06-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08772, current rewards: 88.94584, mean: 0.06540
[32m[0906 23-06-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08771, current rewards: 92.75271, mean: 0.06578
[32m[0906 23-06-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08769, current rewards: 96.61016, mean: 0.06617
[32m[0906 23-06-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08767, current rewards: 100.46760, mean: 0.06653
[32m[0906 23-07-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08765, current rewards: 104.32505, mean: 0.06688
[32m[0906 23-07-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08764, current rewards: 75.86803, mean: 0.04712
[32m[0906 23-07-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08763, current rewards: 25.86803, mean: 0.01558
[32m[0906 23-07-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08761, current rewards: -24.13197, mean: -0.01411
[32m[0906 23-07-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08758, current rewards: -74.13197, mean: -0.04212
[32m[0906 23-07-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08756, current rewards: -124.13197, mean: -0.06858
[32m[0906 23-07-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08755, current rewards: -174.13197, mean: -0.09362
[32m[0906 23-07-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08754, current rewards: -224.13197, mean: -0.11735
[32m[0906 23-07-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08752, current rewards: -274.13197, mean: -0.13986
[32m[0906 23-07-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08750, current rewards: -324.13197, mean: -0.16126
[32m[0906 23-07-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08749, current rewards: -374.13197, mean: -0.18162
[32m[0906 23-07-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08747, current rewards: -424.13197, mean: -0.20101
[32m[0906 23-07-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08750, current rewards: -474.13197, mean: -0.21951
[32m[0906 23-08-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08755, current rewards: -524.13197, mean: -0.23716
[32m[0906 23-08-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08753, current rewards: -574.13197, mean: -0.25404
[32m[0906 23-08-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08753, current rewards: -624.13197, mean: -0.27019
[32m[0906 23-08-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08752, current rewards: -674.13197, mean: -0.28565
[32m[0906 23-08-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08751, current rewards: -724.13197, mean: -0.30047
[32m[0906 23-08-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08751, current rewards: -774.13197, mean: -0.31469
[32m[0906 23-08-25 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0906 23-08-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-08-25 @MBExp.py:227][0m Rewards obtained: [-814.1319693603945], Lows: [15], Highs: [926], Total time: 24631.177753999997
[32m[0906 23-11-16 @MBExp.py:144][0m ####################################################################
[32m[0906 23-11-16 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 23-11-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08785, current rewards: -9.81023, mean: -0.98102
[32m[0906 23-11-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09477, current rewards: -39.98057, mean: -0.66634
[32m[0906 23-11-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09432, current rewards: -80.92214, mean: -0.73566
[32m[0906 23-11-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09438, current rewards: -120.26788, mean: -0.75167
[32m[0906 23-11-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09390, current rewards: -161.70050, mean: -0.77000
[32m[0906 23-11-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09373, current rewards: -199.90409, mean: -0.76886
[32m[0906 23-11-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09324, current rewards: -231.76337, mean: -0.74762
[32m[0906 23-11-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09319, current rewards: -285.26327, mean: -0.79240
[32m[0906 23-11-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09381, current rewards: -320.79678, mean: -0.78243
[32m[0906 23-11-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09374, current rewards: -347.96665, mean: -0.75645
[32m[0906 23-12-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09387, current rewards: -385.54186, mean: -0.75596
[32m[0906 23-12-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09365, current rewards: -424.00036, mean: -0.75714
[32m[0906 23-12-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09385, current rewards: -481.05515, mean: -0.78862
[32m[0906 23-12-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09452, current rewards: -551.26072, mean: -0.83524
[32m[0906 23-12-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09548, current rewards: -604.72065, mean: -0.85172
[32m[0906 23-12-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09638, current rewards: -659.34100, mean: -0.86755
[32m[0906 23-12-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09714, current rewards: -707.73857, mean: -0.87375
[32m[0906 23-12-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09736, current rewards: -764.59597, mean: -0.88907
[32m[0906 23-12-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09790, current rewards: -819.55939, mean: -0.90061
[32m[0906 23-12-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09849, current rewards: -857.55753, mean: -0.89329
[32m[0906 23-12-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09895, current rewards: -899.83614, mean: -0.89093
[32m[0906 23-13-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09898, current rewards: -937.82943, mean: -0.88474
[32m[0906 23-13-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09865, current rewards: -996.13559, mean: -0.89742
[32m[0906 23-13-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09836, current rewards: -1048.70023, mean: -0.90405
[32m[0906 23-13-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09830, current rewards: -1083.95484, mean: -0.89583
[32m[0906 23-13-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09816, current rewards: -1151.94573, mean: -0.91424
[32m[0906 23-13-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09830, current rewards: -1185.77598, mean: -0.90517
[32m[0906 23-13-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09815, current rewards: -1232.28220, mean: -0.90609
[32m[0906 23-13-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09820, current rewards: -1275.48828, mean: -0.90460
[32m[0906 23-13-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09802, current rewards: -1322.34857, mean: -0.90572
[32m[0906 23-13-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09781, current rewards: -1365.95901, mean: -0.90461
[32m[0906 23-13-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09760, current rewards: -1419.26902, mean: -0.90979
[32m[0906 23-13-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09763, current rewards: -1459.85374, mean: -0.90674
[32m[0906 23-13-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09759, current rewards: -1509.81348, mean: -0.90953
[32m[0906 23-14-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09728, current rewards: -1504.96122, mean: -0.88009
[32m[0906 23-14-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09698, current rewards: -1500.20053, mean: -0.85239
[32m[0906 23-14-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09671, current rewards: -1495.13203, mean: -0.82604
[32m[0906 23-14-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09645, current rewards: -1490.05081, mean: -0.80110
[32m[0906 23-14-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09620, current rewards: -1484.97177, mean: -0.77747
[32m[0906 23-14-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09600, current rewards: -1479.89588, mean: -0.75505
[32m[0906 23-14-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09584, current rewards: -1474.81434, mean: -0.73374
[32m[0906 23-14-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09592, current rewards: -1501.86287, mean: -0.72906
[32m[0906 23-14-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09588, current rewards: -1541.92626, mean: -0.73077
[32m[0906 23-14-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09574, current rewards: -1586.51977, mean: -0.73450
[32m[0906 23-14-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09557, current rewards: -1631.11243, mean: -0.73806
[32m[0906 23-14-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09542, current rewards: -1681.11243, mean: -0.74386
[32m[0906 23-14-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09530, current rewards: -1731.11243, mean: -0.74940
[32m[0906 23-15-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09518, current rewards: -1781.11243, mean: -0.75471
[32m[0906 23-15-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09506, current rewards: -1831.11243, mean: -0.75980
[32m[0906 23-15-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09494, current rewards: -1881.11243, mean: -0.76468
[32m[0906 23-15-15 @Agent.py:117][0m Average action selection time: 0.0955
[32m[0906 23-15-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-15-15 @MBExp.py:227][0m Rewards obtained: [-1920.8300262046855], Lows: [472], Highs: [1088], Total time: 24870.777486999996
[32m[0906 23-18-07 @MBExp.py:144][0m ####################################################################
[32m[0906 23-18-07 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 23-18-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08854, current rewards: -11.90419, mean: -1.19042
[32m[0906 23-18-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08818, current rewards: -100.53389, mean: -1.67556
[32m[0906 23-18-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08870, current rewards: -171.22937, mean: -1.55663
[32m[0906 23-18-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08917, current rewards: -251.21697, mean: -1.57011
[32m[0906 23-18-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08888, current rewards: -328.65837, mean: -1.56504
[32m[0906 23-18-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08898, current rewards: -399.23357, mean: -1.53551
[32m[0906 23-18-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08866, current rewards: -477.80321, mean: -1.54130
[32m[0906 23-18-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08844, current rewards: -538.88860, mean: -1.49691
[32m[0906 23-18-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08844, current rewards: -613.69999, mean: -1.49683
[32m[0906 23-18-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08858, current rewards: -687.85462, mean: -1.49534
[32m[0906 23-18-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08842, current rewards: -767.24086, mean: -1.50439
[32m[0906 23-18-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08830, current rewards: -810.73830, mean: -1.44775
[32m[0906 23-19-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08819, current rewards: -803.66041, mean: -1.31748
[32m[0906 23-19-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08816, current rewards: -809.59218, mean: -1.22665
[32m[0906 23-19-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08815, current rewards: -848.16910, mean: -1.19460
[32m[0906 23-19-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08808, current rewards: -890.47543, mean: -1.17168
[32m[0906 23-19-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08803, current rewards: -952.90409, mean: -1.17642
[32m[0906 23-19-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08797, current rewards: -993.46134, mean: -1.15519
[32m[0906 23-19-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08804, current rewards: -1054.01278, mean: -1.15826
[32m[0906 23-19-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08808, current rewards: -1094.61797, mean: -1.14023
[32m[0906 23-19-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08808, current rewards: -1127.15620, mean: -1.11600
[32m[0906 23-19-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08803, current rewards: -1175.43221, mean: -1.10890
[32m[0906 23-19-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08799, current rewards: -1227.30762, mean: -1.10568
[32m[0906 23-19-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08798, current rewards: -1280.29268, mean: -1.10370
[32m[0906 23-19-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08800, current rewards: -1331.40434, mean: -1.10033
[32m[0906 23-19-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08800, current rewards: -1390.34764, mean: -1.10345
[32m[0906 23-20-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08799, current rewards: -1416.26658, mean: -1.08112
[32m[0906 23-20-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08794, current rewards: -1421.42258, mean: -1.04516
[32m[0906 23-20-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08796, current rewards: -1441.99562, mean: -1.02269
[32m[0906 23-20-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08794, current rewards: -1436.48412, mean: -0.98389
[32m[0906 23-20-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08792, current rewards: -1430.97212, mean: -0.94766
[32m[0906 23-20-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08789, current rewards: -1425.45726, mean: -0.91375
[32m[0906 23-20-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08786, current rewards: -1419.94557, mean: -0.88195
[32m[0906 23-20-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08783, current rewards: -1414.43341, mean: -0.85207
[32m[0906 23-20-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08781, current rewards: -1408.91868, mean: -0.82393
[32m[0906 23-20-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08779, current rewards: -1403.40559, mean: -0.79739
[32m[0906 23-20-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08777, current rewards: -1397.88933, mean: -0.77231
[32m[0906 23-20-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08775, current rewards: -1392.37600, mean: -0.74859
[32m[0906 23-20-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08773, current rewards: -1386.86136, mean: -0.72611
[32m[0906 23-21-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08776, current rewards: -1416.84724, mean: -0.72288
[32m[0906 23-21-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08777, current rewards: -1415.63138, mean: -0.70429
[32m[0906 23-21-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08775, current rewards: -1412.47753, mean: -0.68567
[32m[0906 23-21-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08775, current rewards: -1409.00614, mean: -0.66778
[32m[0906 23-21-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08773, current rewards: -1414.33814, mean: -0.65479
[32m[0906 23-21-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08779, current rewards: -1442.28379, mean: -0.65262
[32m[0906 23-21-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08786, current rewards: -1453.04514, mean: -0.64294
[32m[0906 23-21-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08794, current rewards: -1485.92224, mean: -0.64326
[32m[0906 23-21-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08804, current rewards: -1514.33316, mean: -0.64167
[32m[0906 23-21-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08812, current rewards: -1536.80108, mean: -0.63768
[32m[0906 23-21-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08819, current rewards: -1560.22394, mean: -0.63424
[32m[0906 23-21-49 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0906 23-21-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-21-49 @MBExp.py:227][0m Rewards obtained: [-1608.9600311287793], Lows: [910], Highs: [20], Total time: 25092.197971999994
[32m[0906 23-24-43 @MBExp.py:144][0m ####################################################################
[32m[0906 23-24-43 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 23-24-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08612, current rewards: -7.73039, mean: -0.77304
[32m[0906 23-24-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08722, current rewards: -102.68746, mean: -1.71146
[32m[0906 23-24-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08755, current rewards: -202.68746, mean: -1.84261
[32m[0906 23-24-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08769, current rewards: -302.68746, mean: -1.89180
[32m[0906 23-25-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08751, current rewards: -402.68746, mean: -1.91756
[32m[0906 23-25-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08744, current rewards: -502.68746, mean: -1.93341
[32m[0906 23-25-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08734, current rewards: -602.68746, mean: -1.94415
[32m[0906 23-25-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08731, current rewards: -702.68746, mean: -1.95191
[32m[0906 23-25-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08791, current rewards: -789.02636, mean: -1.92445
[32m[0906 23-25-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09031, current rewards: -847.80899, mean: -1.84306
[32m[0906 23-25-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09172, current rewards: -912.67021, mean: -1.78955
[32m[0906 23-25-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09175, current rewards: -1001.49630, mean: -1.78839
[32m[0906 23-25-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09190, current rewards: -1068.54437, mean: -1.75171
[32m[0906 23-25-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09221, current rewards: -1144.93858, mean: -1.73476
[32m[0906 23-25-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09225, current rewards: -1225.90502, mean: -1.72663
[32m[0906 23-25-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09321, current rewards: -1278.05315, mean: -1.68165
[32m[0906 23-25-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09342, current rewards: -1346.63078, mean: -1.66251
[32m[0906 23-26-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09404, current rewards: -1400.87973, mean: -1.62893
[32m[0906 23-26-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09433, current rewards: -1471.85614, mean: -1.61742
[32m[0906 23-26-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09479, current rewards: -1520.93474, mean: -1.58431
[32m[0906 23-26-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09455, current rewards: -1596.29547, mean: -1.58049
[32m[0906 23-26-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09435, current rewards: -1680.00826, mean: -1.58491
[32m[0906 23-26-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09408, current rewards: -1767.80531, mean: -1.59262
[32m[0906 23-26-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09376, current rewards: -1858.54921, mean: -1.60220
[32m[0906 23-26-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09394, current rewards: -1909.60034, mean: -1.57818
[32m[0906 23-26-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09399, current rewards: -1974.51175, mean: -1.56707
[32m[0906 23-26-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09372, current rewards: -2063.72927, mean: -1.57537
[32m[0906 23-26-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09347, current rewards: -2163.72927, mean: -1.59098
[32m[0906 23-26-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09323, current rewards: -2263.72927, mean: -1.60548
[32m[0906 23-26-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09302, current rewards: -2363.72927, mean: -1.61899
[32m[0906 23-27-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09281, current rewards: -2463.72927, mean: -1.63161
[32m[0906 23-27-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09263, current rewards: -2563.72927, mean: -1.64342
[32m[0906 23-27-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09245, current rewards: -2663.72927, mean: -1.65449
[32m[0906 23-27-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09229, current rewards: -2763.72927, mean: -1.66490
[32m[0906 23-27-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09213, current rewards: -2863.72927, mean: -1.67470
[32m[0906 23-27-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09198, current rewards: -2963.72927, mean: -1.68394
[32m[0906 23-27-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09184, current rewards: -3063.72927, mean: -1.69267
[32m[0906 23-27-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09177, current rewards: -3163.72927, mean: -1.70093
[32m[0906 23-27-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09166, current rewards: -3263.72927, mean: -1.70876
[32m[0906 23-27-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09154, current rewards: -3363.72927, mean: -1.71619
[32m[0906 23-27-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09144, current rewards: -3463.72927, mean: -1.72325
[32m[0906 23-27-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09133, current rewards: -3563.72927, mean: -1.72997
[32m[0906 23-27-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09128, current rewards: -3663.72927, mean: -1.73636
[32m[0906 23-28-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09125, current rewards: -3763.72927, mean: -1.74247
[32m[0906 23-28-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09121, current rewards: -3863.72927, mean: -1.74829
[32m[0906 23-28-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09118, current rewards: -3963.72927, mean: -1.75386
[32m[0906 23-28-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09115, current rewards: -4063.72927, mean: -1.75919
[32m[0906 23-28-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09113, current rewards: -4163.72927, mean: -1.76429
[32m[0906 23-28-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09110, current rewards: -4263.72927, mean: -1.76918
[32m[0906 23-28-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09106, current rewards: -4363.72927, mean: -1.77387
[32m[0906 23-28-31 @Agent.py:117][0m Average action selection time: 0.0910
[32m[0906 23-28-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-28-31 @MBExp.py:227][0m Rewards obtained: [-4443.729271488395], Lows: [2190], Highs: [103], Total time: 25320.552565999995
[32m[0906 23-31-27 @MBExp.py:144][0m ####################################################################
[32m[0906 23-31-27 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 23-31-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09522, current rewards: -10.85000, mean: -1.08500
[32m[0906 23-31-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08752, current rewards: -110.85000, mean: -1.84750
[32m[0906 23-31-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08778, current rewards: -210.85000, mean: -1.91682
[32m[0906 23-31-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08769, current rewards: -310.85000, mean: -1.94281
[32m[0906 23-31-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08777, current rewards: -410.85000, mean: -1.95643
[32m[0906 23-31-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08797, current rewards: -505.76372, mean: -1.94525
[32m[0906 23-31-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08830, current rewards: -541.09017, mean: -1.74545
[32m[0906 23-31-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08910, current rewards: -568.74555, mean: -1.57985
[32m[0906 23-32-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08934, current rewards: -602.76473, mean: -1.47016
[32m[0906 23-32-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08986, current rewards: -652.77642, mean: -1.41908
[32m[0906 23-32-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09054, current rewards: -700.45572, mean: -1.37344
[32m[0906 23-32-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09100, current rewards: -746.60644, mean: -1.33323
[32m[0906 23-32-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09114, current rewards: -764.84963, mean: -1.25385
[32m[0906 23-32-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09085, current rewards: -757.02575, mean: -1.14701
[32m[0906 23-32-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09058, current rewards: -749.22729, mean: -1.05525
[32m[0906 23-32-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09035, current rewards: -740.92117, mean: -0.97490
[32m[0906 23-32-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09026, current rewards: -809.63716, mean: -0.99955
[32m[0906 23-32-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09009, current rewards: -909.63716, mean: -1.05772
[32m[0906 23-32-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08994, current rewards: -1009.63716, mean: -1.10949
[32m[0906 23-32-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08990, current rewards: -1097.46063, mean: -1.14319
[32m[0906 23-32-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08975, current rewards: -1138.95660, mean: -1.12768
[32m[0906 23-33-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08976, current rewards: -1201.70094, mean: -1.13368
[32m[0906 23-33-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08981, current rewards: -1223.60438, mean: -1.10235
[32m[0906 23-33-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08968, current rewards: -1219.80513, mean: -1.05156
[32m[0906 23-33-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08956, current rewards: -1216.00588, mean: -1.00496
[32m[0906 23-33-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08945, current rewards: -1212.20663, mean: -0.96207
[32m[0906 23-33-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08936, current rewards: -1236.70075, mean: -0.94405
[32m[0906 23-33-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08929, current rewards: -1286.70075, mean: -0.94610
[32m[0906 23-33-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08921, current rewards: -1336.70075, mean: -0.94801
[32m[0906 23-33-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08913, current rewards: -1386.70075, mean: -0.94980
[32m[0906 23-33-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08906, current rewards: -1436.70075, mean: -0.95146
[32m[0906 23-33-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08901, current rewards: -1486.70075, mean: -0.95301
[32m[0906 23-33-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08895, current rewards: -1536.70075, mean: -0.95447
[32m[0906 23-33-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08888, current rewards: -1586.70075, mean: -0.95584
[32m[0906 23-33-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08883, current rewards: -1636.70075, mean: -0.95713
[32m[0906 23-34-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08878, current rewards: -1686.70075, mean: -0.95835
[32m[0906 23-34-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08879, current rewards: -1736.70075, mean: -0.95950
[32m[0906 23-34-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08878, current rewards: -1786.70075, mean: -0.96059
[32m[0906 23-34-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08873, current rewards: -1836.70075, mean: -0.96162
[32m[0906 23-34-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08869, current rewards: -1886.70075, mean: -0.96260
[32m[0906 23-34-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08866, current rewards: -1936.70075, mean: -0.96353
[32m[0906 23-34-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08864, current rewards: -1986.70075, mean: -0.96442
[32m[0906 23-34-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08867, current rewards: -2036.70075, mean: -0.96526
[32m[0906 23-34-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08869, current rewards: -2086.70075, mean: -0.96607
[32m[0906 23-34-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08871, current rewards: -2136.70075, mean: -0.96683
[32m[0906 23-34-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08873, current rewards: -2186.70075, mean: -0.96757
[32m[0906 23-34-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08875, current rewards: -2236.70075, mean: -0.96827
[32m[0906 23-34-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08876, current rewards: -2286.70075, mean: -0.96894
[32m[0906 23-35-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08878, current rewards: -2336.70075, mean: -0.96959
[32m[0906 23-35-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08880, current rewards: -2386.70075, mean: -0.97020
[32m[0906 23-35-10 @Agent.py:117][0m Average action selection time: 0.0888
[32m[0906 23-35-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-35-10 @MBExp.py:227][0m Rewards obtained: [-2426.7007473059475], Lows: [503], Highs: [1480], Total time: 25543.332043999995
[32m[0906 23-38-08 @MBExp.py:144][0m ####################################################################
[32m[0906 23-38-08 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 23-38-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09658, current rewards: -4.18786, mean: -0.41879
[32m[0906 23-38-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09498, current rewards: -86.13342, mean: -1.43556
[32m[0906 23-38-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09652, current rewards: -139.93697, mean: -1.27215
[32m[0906 23-38-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09656, current rewards: -214.15919, mean: -1.33849
[32m[0906 23-38-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09757, current rewards: -278.46023, mean: -1.32600
[32m[0906 23-38-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09740, current rewards: -334.76434, mean: -1.28756
[32m[0906 23-38-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09674, current rewards: -367.19882, mean: -1.18451
[32m[0906 23-38-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09721, current rewards: -425.99699, mean: -1.18332
[32m[0906 23-38-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09752, current rewards: -482.70200, mean: -1.17732
[32m[0906 23-38-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09671, current rewards: -534.25906, mean: -1.16143
[32m[0906 23-38-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09716, current rewards: -565.36521, mean: -1.10856
[32m[0906 23-39-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09730, current rewards: -606.92322, mean: -1.08379
[32m[0906 23-39-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09697, current rewards: -673.64641, mean: -1.10434
[32m[0906 23-39-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09676, current rewards: -743.24457, mean: -1.12613
[32m[0906 23-39-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09671, current rewards: -798.62206, mean: -1.12482
[32m[0906 23-39-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09612, current rewards: -842.55266, mean: -1.10862
[32m[0906 23-39-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09569, current rewards: -855.83799, mean: -1.05659
[32m[0906 23-39-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09523, current rewards: -870.31141, mean: -1.01199
[32m[0906 23-39-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09480, current rewards: -920.31141, mean: -1.01133
[32m[0906 23-39-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09439, current rewards: -970.31141, mean: -1.01074
[32m[0906 23-39-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09403, current rewards: -1020.31141, mean: -1.01021
[32m[0906 23-39-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09370, current rewards: -1070.31141, mean: -1.00973
[32m[0906 23-39-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09341, current rewards: -1120.31141, mean: -1.00929
[32m[0906 23-39-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09315, current rewards: -1170.31141, mean: -1.00889
[32m[0906 23-40-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09289, current rewards: -1220.31141, mean: -1.00852
[32m[0906 23-40-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09266, current rewards: -1270.31141, mean: -1.00818
[32m[0906 23-40-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09244, current rewards: -1320.31141, mean: -1.00787
[32m[0906 23-40-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09223, current rewards: -1370.31141, mean: -1.00758
[32m[0906 23-40-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09205, current rewards: -1420.31141, mean: -1.00731
[32m[0906 23-40-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09189, current rewards: -1470.31141, mean: -1.00706
[32m[0906 23-40-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09172, current rewards: -1520.31141, mean: -1.00683
[32m[0906 23-40-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09157, current rewards: -1570.31141, mean: -1.00661
[32m[0906 23-40-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09142, current rewards: -1620.31141, mean: -1.00640
[32m[0906 23-40-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09130, current rewards: -1670.31141, mean: -1.00621
[32m[0906 23-40-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09117, current rewards: -1720.31141, mean: -1.00603
[32m[0906 23-40-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09106, current rewards: -1770.31141, mean: -1.00586
[32m[0906 23-40-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09095, current rewards: -1820.31141, mean: -1.00570
[32m[0906 23-40-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09085, current rewards: -1870.31141, mean: -1.00554
[32m[0906 23-41-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09075, current rewards: -1920.31141, mean: -1.00540
[32m[0906 23-41-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09067, current rewards: -1970.31141, mean: -1.00526
[32m[0906 23-41-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09065, current rewards: -2020.31141, mean: -1.00513
[32m[0906 23-41-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09063, current rewards: -2070.31141, mean: -1.00501
[32m[0906 23-41-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09060, current rewards: -2120.31141, mean: -1.00489
[32m[0906 23-41-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09057, current rewards: -2170.31141, mean: -1.00477
[32m[0906 23-41-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09054, current rewards: -2220.31141, mean: -1.00467
[32m[0906 23-41-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09052, current rewards: -2270.31141, mean: -1.00456
[32m[0906 23-41-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09051, current rewards: -2320.31141, mean: -1.00446
[32m[0906 23-41-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09048, current rewards: -2370.31141, mean: -1.00437
[32m[0906 23-41-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09047, current rewards: -2420.31141, mean: -1.00428
[32m[0906 23-41-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09043, current rewards: -2470.31141, mean: -1.00419
[32m[0906 23-41-54 @Agent.py:117][0m Average action selection time: 0.0904
[32m[0906 23-41-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-41-54 @MBExp.py:227][0m Rewards obtained: [-2510.3114081713343], Lows: [362], Highs: [1841], Total time: 25769.986276999996
[32m[0906 23-44-54 @MBExp.py:144][0m ####################################################################
[32m[0906 23-44-54 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 23-44-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08597, current rewards: -6.75577, mean: -0.67558
[32m[0906 23-44-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08710, current rewards: -1.39264, mean: -0.02321
[32m[0906 23-45-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08708, current rewards: 4.17467, mean: 0.03795
[32m[0906 23-45-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08706, current rewards: 9.74411, mean: 0.06090
[32m[0906 23-45-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08714, current rewards: 15.31346, mean: 0.07292
[32m[0906 23-45-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08711, current rewards: 20.88554, mean: 0.08033
[32m[0906 23-45-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08708, current rewards: 26.45431, mean: 0.08534
[32m[0906 23-45-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08704, current rewards: 32.02664, mean: 0.08896
[32m[0906 23-45-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08706, current rewards: 27.21750, mean: 0.06638
[32m[0906 23-45-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08705, current rewards: 23.86382, mean: 0.05188
[32m[0906 23-45-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08700, current rewards: 29.37574, mean: 0.05760
[32m[0906 23-45-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08700, current rewards: 34.88628, mean: 0.06230
[32m[0906 23-45-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08696, current rewards: 40.39901, mean: 0.06623
[32m[0906 23-45-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08698, current rewards: 45.91026, mean: 0.06956
[32m[0906 23-45-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08698, current rewards: 51.42236, mean: 0.07243
[32m[0906 23-46-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08695, current rewards: 46.53523, mean: 0.06123
[32m[0906 23-46-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08695, current rewards: 52.37865, mean: 0.06467
[32m[0906 23-46-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08695, current rewards: 59.05487, mean: 0.06867
[32m[0906 23-46-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08696, current rewards: 65.38921, mean: 0.07186
[32m[0906 23-46-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08695, current rewards: 71.72467, mean: 0.07471
[32m[0906 23-46-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08696, current rewards: 78.06151, mean: 0.07729
[32m[0906 23-46-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08697, current rewards: 71.82821, mean: 0.06776
[32m[0906 23-46-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08697, current rewards: 69.16030, mean: 0.06231
[32m[0906 23-46-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08697, current rewards: 73.83163, mean: 0.06365
[32m[0906 23-46-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08697, current rewards: 78.50560, mean: 0.06488
[32m[0906 23-46-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08697, current rewards: 83.18037, mean: 0.06602
[32m[0906 23-46-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08699, current rewards: 87.85390, mean: 0.06706
[32m[0906 23-46-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08698, current rewards: 92.52246, mean: 0.06803
[32m[0906 23-46-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08696, current rewards: 97.19552, mean: 0.06893
[32m[0906 23-47-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08696, current rewards: 91.39201, mean: 0.06260
[32m[0906 23-47-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08695, current rewards: 96.29702, mean: 0.06377
[32m[0906 23-47-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08696, current rewards: 101.20152, mean: 0.06487
[32m[0906 23-47-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08695, current rewards: 106.10096, mean: 0.06590
[32m[0906 23-47-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08695, current rewards: 111.23812, mean: 0.06701
[32m[0906 23-47-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08696, current rewards: 115.37702, mean: 0.06747
[32m[0906 23-47-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08697, current rewards: 118.57786, mean: 0.06737
[32m[0906 23-47-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08696, current rewards: 121.78012, mean: 0.06728
[32m[0906 23-47-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08696, current rewards: 124.98156, mean: 0.06719
[32m[0906 23-47-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08696, current rewards: 128.18277, mean: 0.06711
[32m[0906 23-47-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08697, current rewards: 118.26043, mean: 0.06034
[32m[0906 23-47-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08698, current rewards: 125.04168, mean: 0.06221
[32m[0906 23-47-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08704, current rewards: 131.13231, mean: 0.06366
[32m[0906 23-47-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08709, current rewards: 136.39208, mean: 0.06464
[32m[0906 23-48-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08715, current rewards: 141.95849, mean: 0.06572
[32m[0906 23-48-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08721, current rewards: 147.52342, mean: 0.06675
[32m[0906 23-48-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08726, current rewards: 153.08592, mean: 0.06774
[32m[0906 23-48-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08732, current rewards: 158.64892, mean: 0.06868
[32m[0906 23-48-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08737, current rewards: 164.21292, mean: 0.06958
[32m[0906 23-48-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08741, current rewards: 169.77619, mean: 0.07045
[32m[0906 23-48-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08746, current rewards: 175.33992, mean: 0.07128
[32m[0906 23-48-33 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0906 23-48-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-48-33 @MBExp.py:227][0m Rewards obtained: [179.7906868697711], Lows: [24], Highs: [29], Total time: 25989.373087999997
[32m[0906 23-51-34 @MBExp.py:144][0m ####################################################################
[32m[0906 23-51-34 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 23-51-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08620, current rewards: -5.31095, mean: -0.53110
[32m[0906 23-51-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08720, current rewards: 1.25199, mean: 0.02087
[32m[0906 23-51-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08711, current rewards: 7.57534, mean: 0.06887
[32m[0906 23-51-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08708, current rewards: 13.90074, mean: 0.08688
[32m[0906 23-51-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08705, current rewards: 20.22919, mean: 0.09633
[32m[0906 23-51-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08706, current rewards: 26.54454, mean: 0.10209
[32m[0906 23-52-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08707, current rewards: 32.87084, mean: 0.10603
[32m[0906 23-52-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08707, current rewards: 39.19940, mean: 0.10889
[32m[0906 23-52-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08706, current rewards: 44.93243, mean: 0.10959
[32m[0906 23-52-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08704, current rewards: 51.32649, mean: 0.11158
[32m[0906 23-52-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08704, current rewards: 57.71527, mean: 0.11317
[32m[0906 23-52-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08703, current rewards: 53.49394, mean: 0.09552
[32m[0906 23-52-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08703, current rewards: 60.12556, mean: 0.09857
[32m[0906 23-52-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08707, current rewards: 66.74651, mean: 0.10113
[32m[0906 23-52-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08707, current rewards: 73.37628, mean: 0.10335
[32m[0906 23-52-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08706, current rewards: 80.00941, mean: 0.10528
[32m[0906 23-52-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08707, current rewards: 87.19731, mean: 0.10765
[32m[0906 23-52-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08707, current rewards: 93.67944, mean: 0.10893
[32m[0906 23-52-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08707, current rewards: 100.11024, mean: 0.11001
[32m[0906 23-52-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08705, current rewards: 106.53013, mean: 0.11097
[32m[0906 23-53-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08705, current rewards: 112.96622, mean: 0.11185
[32m[0906 23-53-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08706, current rewards: 119.39567, mean: 0.11264
[32m[0906 23-53-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08705, current rewards: 115.10542, mean: 0.10370
[32m[0906 23-53-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08704, current rewards: 120.62224, mean: 0.10398
[32m[0906 23-53-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08704, current rewards: 126.15316, mean: 0.10426
[32m[0906 23-53-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08704, current rewards: 132.01929, mean: 0.10478
[32m[0906 23-53-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08704, current rewards: 137.52628, mean: 0.10498
[32m[0906 23-53-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08704, current rewards: 143.03552, mean: 0.10517
[32m[0906 23-53-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08705, current rewards: 148.54735, mean: 0.10535
[32m[0906 23-53-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08705, current rewards: 154.05562, mean: 0.10552
[32m[0906 23-53-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08704, current rewards: 159.56226, mean: 0.10567
[32m[0906 23-53-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08704, current rewards: 152.42040, mean: 0.09771
[32m[0906 23-53-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08703, current rewards: 158.03567, mean: 0.09816
[32m[0906 23-53-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08701, current rewards: 163.57012, mean: 0.09854
[32m[0906 23-54-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08700, current rewards: 169.10528, mean: 0.09889
[32m[0906 23-54-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08701, current rewards: 164.46532, mean: 0.09345
[32m[0906 23-54-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08693, current rewards: 170.14959, mean: 0.09401
[32m[0906 23-54-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08693, current rewards: 175.83766, mean: 0.09454
[32m[0906 23-54-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08693, current rewards: 181.52391, mean: 0.09504
[32m[0906 23-54-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08693, current rewards: 187.21059, mean: 0.09552
[32m[0906 23-54-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08693, current rewards: 192.89870, mean: 0.09597
[32m[0906 23-54-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08693, current rewards: 197.87067, mean: 0.09605
[32m[0906 23-54-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08699, current rewards: 203.50512, mean: 0.09645
[32m[0906 23-54-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08705, current rewards: 209.13895, mean: 0.09682
[32m[0906 23-54-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08711, current rewards: 214.77496, mean: 0.09718
[32m[0906 23-54-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08717, current rewards: 220.40769, mean: 0.09753
[32m[0906 23-54-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08722, current rewards: 226.04044, mean: 0.09785
[32m[0906 23-55-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08727, current rewards: 231.67869, mean: 0.09817
[32m[0906 23-55-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08732, current rewards: 237.31691, mean: 0.09847
[32m[0906 23-55-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08737, current rewards: 238.06381, mean: 0.09677
[32m[0906 23-55-13 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0906 23-55-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-55-13 @MBExp.py:227][0m Rewards obtained: [242.26889833842404], Lows: [21], Highs: [11], Total time: 26208.551638999998
[32m[0906 23-58-17 @MBExp.py:144][0m ####################################################################
[32m[0906 23-58-17 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 23-58-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08597, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-58-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08893, current rewards: -91.42560, mean: -1.52376
[32m[0906 23-58-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09278, current rewards: -165.32674, mean: -1.50297
[32m[0906 23-58-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09151, current rewards: -258.53705, mean: -1.61586
[32m[0906 23-58-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09153, current rewards: -343.11051, mean: -1.63386
[32m[0906 23-58-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09276, current rewards: -425.10285, mean: -1.63501
[32m[0906 23-58-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09226, current rewards: -503.07753, mean: -1.62283
[32m[0906 23-58-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09151, current rewards: -603.07753, mean: -1.67522
[32m[0906 23-58-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09096, current rewards: -703.07753, mean: -1.71482
[32m[0906 23-58-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09056, current rewards: -803.07753, mean: -1.74582
[32m[0906 23-59-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09025, current rewards: -903.07753, mean: -1.77074
[32m[0906 23-59-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08995, current rewards: -1003.07753, mean: -1.79121
[32m[0906 23-59-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08971, current rewards: -1103.07753, mean: -1.80832
[32m[0906 23-59-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08952, current rewards: -1203.07753, mean: -1.82284
[32m[0906 23-59-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08939, current rewards: -1303.07753, mean: -1.83532
[32m[0906 23-59-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08922, current rewards: -1403.07753, mean: -1.84615
[32m[0906 23-59-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08908, current rewards: -1503.07753, mean: -1.85565
[32m[0906 23-59-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08896, current rewards: -1603.07753, mean: -1.86404
[32m[0906 23-59-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08884, current rewards: -1703.07753, mean: -1.87151
[32m[0906 23-59-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08884, current rewards: -1748.06686, mean: -1.82090
[32m[0906 23-59-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08879, current rewards: -1760.84663, mean: -1.74341
[32m[0906 23-59-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08884, current rewards: -1771.91009, mean: -1.67161
[32m[0906 23-59-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08882, current rewards: -1786.96636, mean: -1.60988
[32m[0907 00-00-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08888, current rewards: -1801.57069, mean: -1.55308
[32m[0907 00-00-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08891, current rewards: -1838.28713, mean: -1.51925
[32m[0907 00-00-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08884, current rewards: -1938.28713, mean: -1.53832
[32m[0907 00-00-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08876, current rewards: -2038.28713, mean: -1.55594
[32m[0907 00-00-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08869, current rewards: -2135.45305, mean: -1.57019
[32m[0907 00-00-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08864, current rewards: -2235.45305, mean: -1.58543
[32m[0907 00-00-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08857, current rewards: -2335.45305, mean: -1.59963
[32m[0907 00-00-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08857, current rewards: -2433.30882, mean: -1.61146
[32m[0907 00-00-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08852, current rewards: -2533.30882, mean: -1.62392
[32m[0907 00-00-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08847, current rewards: -2633.30882, mean: -1.63560
[32m[0907 00-00-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08843, current rewards: -2733.30882, mean: -1.64657
[32m[0907 00-00-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08839, current rewards: -2833.30882, mean: -1.65691
[32m[0907 00-00-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08835, current rewards: -2933.30882, mean: -1.66665
[32m[0907 00-00-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08826, current rewards: -3030.66246, mean: -1.67440
[32m[0907 00-01-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08822, current rewards: -3130.66246, mean: -1.68315
[32m[0907 00-01-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08818, current rewards: -3230.66246, mean: -1.69145
[32m[0907 00-01-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08815, current rewards: -3330.66246, mean: -1.69932
[32m[0907 00-01-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08812, current rewards: -3430.66246, mean: -1.70680
[32m[0907 00-01-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08813, current rewards: -3530.66246, mean: -1.71391
[32m[0907 00-01-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08817, current rewards: -3630.66246, mean: -1.72069
[32m[0907 00-01-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08820, current rewards: -3730.66246, mean: -1.72716
[32m[0907 00-01-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08822, current rewards: -3830.66246, mean: -1.73333
[32m[0907 00-01-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08826, current rewards: -3930.66246, mean: -1.73923
[32m[0907 00-01-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08828, current rewards: -4030.66246, mean: -1.74488
[32m[0907 00-01-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08832, current rewards: -4130.66246, mean: -1.75028
[32m[0907 00-01-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08834, current rewards: -4230.66246, mean: -1.75546
[32m[0907 00-01-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08836, current rewards: -4328.14475, mean: -1.75941
[32m[0907 00-01-58 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0907 00-01-58 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-01-58 @MBExp.py:227][0m Rewards obtained: [-4408.144749617508], Lows: [2211], Highs: [31], Total time: 26430.141143999997
[32m[0907 00-05-03 @MBExp.py:144][0m ####################################################################
[32m[0907 00-05-03 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 00-05-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08564, current rewards: -14.00000, mean: -1.40000
[32m[0907 00-05-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08697, current rewards: -8.01270, mean: -0.13354
[32m[0907 00-05-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08698, current rewards: -2.03907, mean: -0.01854
[32m[0907 00-05-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08695, current rewards: 3.93976, mean: 0.02462
[32m[0907 00-05-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08698, current rewards: 9.92068, mean: 0.04724
[32m[0907 00-05-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08693, current rewards: 15.89854, mean: 0.06115
[32m[0907 00-05-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08693, current rewards: 21.86245, mean: 0.07052
[32m[0907 00-05-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08694, current rewards: 15.42517, mean: 0.04285
[32m[0907 00-05-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08691, current rewards: 21.34737, mean: 0.05207
[32m[0907 00-05-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08696, current rewards: 27.26247, mean: 0.05927
[32m[0907 00-05-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08702, current rewards: 33.17812, mean: 0.06506
[32m[0907 00-05-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08704, current rewards: 39.10093, mean: 0.06982
[32m[0907 00-05-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08705, current rewards: 45.02213, mean: 0.07381
[32m[0907 00-06-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08706, current rewards: 50.94472, mean: 0.07719
[32m[0907 00-06-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08707, current rewards: 56.86299, mean: 0.08009
[32m[0907 00-06-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08707, current rewards: 62.71849, mean: 0.08252
[32m[0907 00-06-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08705, current rewards: 68.70263, mean: 0.08482
[32m[0907 00-06-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08705, current rewards: 74.68734, mean: 0.08685
[32m[0907 00-06-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08704, current rewards: 80.67233, mean: 0.08865
[32m[0907 00-06-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08702, current rewards: 86.65652, mean: 0.09027
[32m[0907 00-06-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08703, current rewards: 92.65027, mean: 0.09173
[32m[0907 00-06-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08703, current rewards: 92.41972, mean: 0.08719
[32m[0907 00-06-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08702, current rewards: 97.60585, mean: 0.08793
[32m[0907 00-06-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08701, current rewards: 102.88868, mean: 0.08870
[32m[0907 00-06-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08701, current rewards: 108.09057, mean: 0.08933
[32m[0907 00-06-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08700, current rewards: 113.29815, mean: 0.08992
[32m[0907 00-06-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08701, current rewards: 113.60455, mean: 0.08672
[32m[0907 00-07-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08701, current rewards: 119.56563, mean: 0.08792
[32m[0907 00-07-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08702, current rewards: 125.52430, mean: 0.08902
[32m[0907 00-07-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08702, current rewards: 131.47932, mean: 0.09005
[32m[0907 00-07-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08702, current rewards: 137.44676, mean: 0.09102
[32m[0907 00-07-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08703, current rewards: 143.01522, mean: 0.09168
[32m[0907 00-07-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08703, current rewards: 148.82684, mean: 0.09244
[32m[0907 00-07-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08703, current rewards: 154.63096, mean: 0.09315
[32m[0907 00-07-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08704, current rewards: 160.44120, mean: 0.09383
[32m[0907 00-07-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08709, current rewards: 155.64908, mean: 0.08844
[32m[0907 00-07-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08702, current rewards: 161.00145, mean: 0.08895
[32m[0907 00-07-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08702, current rewards: 166.35480, mean: 0.08944
[32m[0907 00-07-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08702, current rewards: 171.71035, mean: 0.08990
[32m[0907 00-07-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08702, current rewards: 177.65996, mean: 0.09064
[32m[0907 00-07-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08702, current rewards: 183.02575, mean: 0.09106
[32m[0907 00-08-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08703, current rewards: 188.38826, mean: 0.09145
[32m[0907 00-08-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08702, current rewards: 193.75020, mean: 0.09182
[32m[0907 00-08-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08704, current rewards: 199.11081, mean: 0.09218
[32m[0907 00-08-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08709, current rewards: 204.47537, mean: 0.09252
[32m[0907 00-08-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08714, current rewards: 209.83756, mean: 0.09285
[32m[0907 00-08-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08719, current rewards: 215.20486, mean: 0.09316
[32m[0907 00-08-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08725, current rewards: 220.95345, mean: 0.09362
[32m[0907 00-08-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08730, current rewards: 220.90371, mean: 0.09166
[32m[0907 00-08-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08735, current rewards: 226.06500, mean: 0.09190
[32m[0907 00-08-42 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0907 00-08-42 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-08-43 @MBExp.py:227][0m Rewards obtained: [230.18871848492861], Lows: [15], Highs: [21], Total time: 26649.363076999998
[32m[0907 00-11-49 @MBExp.py:144][0m ####################################################################
[32m[0907 00-11-49 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 00-11-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08729, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-11-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08659, current rewards: -50.35244, mean: -0.83921
[32m[0907 00-11-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08674, current rewards: -67.42357, mean: -0.61294
[32m[0907 00-12-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08693, current rewards: -86.75640, mean: -0.54223
[32m[0907 00-12-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08706, current rewards: -77.82072, mean: -0.37057
[32m[0907 00-12-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08711, current rewards: -118.15534, mean: -0.45444
[32m[0907 00-12-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08706, current rewards: -162.69315, mean: -0.52482
[32m[0907 00-12-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08703, current rewards: -203.44979, mean: -0.56514
[32m[0907 00-12-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08704, current rewards: -212.05391, mean: -0.51720
[32m[0907 00-12-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08702, current rewards: -206.56304, mean: -0.44905
[32m[0907 00-12-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08701, current rewards: -201.07488, mean: -0.39426
[32m[0907 00-12-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08700, current rewards: -195.58629, mean: -0.34926
[32m[0907 00-12-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08698, current rewards: -190.10003, mean: -0.31164
[32m[0907 00-12-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08698, current rewards: -184.60905, mean: -0.27971
[32m[0907 00-12-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08698, current rewards: -179.15207, mean: -0.25233
[32m[0907 00-12-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08698, current rewards: -173.66541, mean: -0.22851
[32m[0907 00-13-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08700, current rewards: -168.17464, mean: -0.20762
[32m[0907 00-13-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08701, current rewards: -162.68700, mean: -0.18917
[32m[0907 00-13-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08700, current rewards: -157.19437, mean: -0.17274
[32m[0907 00-13-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08700, current rewards: -151.70554, mean: -0.15803
[32m[0907 00-13-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08699, current rewards: -146.21352, mean: -0.14477
[32m[0907 00-13-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08699, current rewards: -140.72440, mean: -0.13276
[32m[0907 00-13-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08699, current rewards: -151.16747, mean: -0.13619
[32m[0907 00-13-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08700, current rewards: -144.95329, mean: -0.12496
[32m[0907 00-13-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08699, current rewards: -138.67669, mean: -0.11461
[32m[0907 00-13-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08699, current rewards: -132.39669, mean: -0.10508
[32m[0907 00-13-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08698, current rewards: -126.12248, mean: -0.09628
[32m[0907 00-13-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08698, current rewards: -119.84382, mean: -0.08812
[32m[0907 00-13-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08697, current rewards: -113.56851, mean: -0.08055
[32m[0907 00-13-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08696, current rewards: -107.28957, mean: -0.07349
[32m[0907 00-14-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08696, current rewards: -99.09436, mean: -0.06563
[32m[0907 00-14-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08697, current rewards: -92.32567, mean: -0.05918
[32m[0907 00-14-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08698, current rewards: -98.03284, mean: -0.06089
[32m[0907 00-14-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08698, current rewards: -91.90738, mean: -0.05537
[32m[0907 00-14-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08698, current rewards: -86.01257, mean: -0.05030
[32m[0907 00-14-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08698, current rewards: -80.11886, mean: -0.04552
[32m[0907 00-14-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08697, current rewards: -74.22745, mean: -0.04101
[32m[0907 00-14-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08692, current rewards: -68.33536, mean: -0.03674
[32m[0907 00-14-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08692, current rewards: -62.40020, mean: -0.03267
[32m[0907 00-14-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08692, current rewards: -63.11763, mean: -0.03220
[32m[0907 00-14-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08692, current rewards: -57.00673, mean: -0.02836
[32m[0907 00-14-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08692, current rewards: -50.89957, mean: -0.02471
[32m[0907 00-14-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08691, current rewards: -44.79015, mean: -0.02123
[32m[0907 00-14-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08691, current rewards: -38.67761, mean: -0.01791
[32m[0907 00-15-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08694, current rewards: -32.56414, mean: -0.01473
[32m[0907 00-15-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08699, current rewards: -26.45274, mean: -0.01170
[32m[0907 00-15-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08705, current rewards: -20.63822, mean: -0.00893
[32m[0907 00-15-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08710, current rewards: -14.49626, mean: -0.00614
[32m[0907 00-15-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08716, current rewards: -7.76892, mean: -0.00322
[32m[0907 00-15-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08721, current rewards: -1.74273, mean: -0.00071
[32m[0907 00-15-28 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0907 00-15-28 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-15-28 @MBExp.py:227][0m Rewards obtained: [3.077645264292576], Lows: [137], Highs: [26], Total time: 26868.220948
[32m[0907 00-18-37 @MBExp.py:144][0m ####################################################################
[32m[0907 00-18-37 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 00-18-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11725, current rewards: -4.35115, mean: -0.43512
[32m[0907 00-18-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10757, current rewards: -34.11856, mean: -0.56864
[32m[0907 00-18-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10572, current rewards: -83.85361, mean: -0.76231
[32m[0907 00-18-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10667, current rewards: -120.78914, mean: -0.75493
[32m[0907 00-18-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10525, current rewards: -164.20884, mean: -0.78195
[32m[0907 00-19-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10481, current rewards: -215.51815, mean: -0.82892
[32m[0907 00-19-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10360, current rewards: -265.52792, mean: -0.85654
[32m[0907 00-19-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10133, current rewards: -331.05566, mean: -0.91960
[32m[0907 00-19-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10015, current rewards: -385.63509, mean: -0.94057
[32m[0907 00-19-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09882, current rewards: -450.86783, mean: -0.98015
[32m[0907 00-19-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09870, current rewards: -497.23897, mean: -0.97498
[32m[0907 00-19-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09858, current rewards: -551.20220, mean: -0.98429
[32m[0907 00-19-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09785, current rewards: -616.17160, mean: -1.01012
[32m[0907 00-19-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09804, current rewards: -655.06712, mean: -0.99253
[32m[0907 00-19-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09808, current rewards: -714.98500, mean: -1.00702
[32m[0907 00-19-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09820, current rewards: -770.77773, mean: -1.01418
[32m[0907 00-19-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09772, current rewards: -820.77773, mean: -1.01331
[32m[0907 00-20-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09761, current rewards: -870.77773, mean: -1.01253
[32m[0907 00-20-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09774, current rewards: -920.01099, mean: -1.01100
[32m[0907 00-20-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09851, current rewards: -958.77577, mean: -0.99872
[32m[0907 00-20-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09939, current rewards: -986.87533, mean: -0.97710
[32m[0907 00-20-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09945, current rewards: -1036.87533, mean: -0.97818
[32m[0907 00-20-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09969, current rewards: -1068.11504, mean: -0.96227
[32m[0907 00-20-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10026, current rewards: -1125.57688, mean: -0.97032
[32m[0907 00-20-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10002, current rewards: -1161.26520, mean: -0.95972
[32m[0907 00-20-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09950, current rewards: -1211.26520, mean: -0.96132
[32m[0907 00-20-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09902, current rewards: -1261.26520, mean: -0.96280
[32m[0907 00-20-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09858, current rewards: -1311.26520, mean: -0.96417
[32m[0907 00-20-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09815, current rewards: -1361.26520, mean: -0.96544
[32m[0907 00-21-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09777, current rewards: -1411.26520, mean: -0.96662
[32m[0907 00-21-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09742, current rewards: -1449.61294, mean: -0.96001
[32m[0907 00-21-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09709, current rewards: -1499.61294, mean: -0.96129
[32m[0907 00-21-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09677, current rewards: -1549.61294, mean: -0.96249
[32m[0907 00-21-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09642, current rewards: -1599.61294, mean: -0.96362
[32m[0907 00-21-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09607, current rewards: -1649.61294, mean: -0.96469
[32m[0907 00-21-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09581, current rewards: -1699.61294, mean: -0.96569
[32m[0907 00-21-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09556, current rewards: -1749.61294, mean: -0.96664
[32m[0907 00-21-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09533, current rewards: -1799.61294, mean: -0.96753
[32m[0907 00-21-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09511, current rewards: -1849.61294, mean: -0.96838
[32m[0907 00-21-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09490, current rewards: -1899.61294, mean: -0.96919
[32m[0907 00-21-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09474, current rewards: -1949.61294, mean: -0.96996
[32m[0907 00-21-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09462, current rewards: -1999.61294, mean: -0.97069
[32m[0907 00-21-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09449, current rewards: -2049.61294, mean: -0.97138
[32m[0907 00-22-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09438, current rewards: -2099.61294, mean: -0.97204
[32m[0907 00-22-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09427, current rewards: -2149.61294, mean: -0.97268
[32m[0907 00-22-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09415, current rewards: -2199.61294, mean: -0.97328
[32m[0907 00-22-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09405, current rewards: -2249.61294, mean: -0.97386
[32m[0907 00-22-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09395, current rewards: -2299.61294, mean: -0.97441
[32m[0907 00-22-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09382, current rewards: -2349.61294, mean: -0.97494
[32m[0907 00-22-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09367, current rewards: -2399.61294, mean: -0.97545
[32m[0907 00-22-31 @Agent.py:117][0m Average action selection time: 0.0936
[32m[0907 00-22-31 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-22-31 @MBExp.py:227][0m Rewards obtained: [-2439.6129396581846], Lows: [303], Highs: [1886], Total time: 27102.894966
[32m[0907 00-25-42 @MBExp.py:144][0m ####################################################################
[32m[0907 00-25-42 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 00-25-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09082, current rewards: -1.21628, mean: -0.12163
[32m[0907 00-25-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08753, current rewards: -35.92108, mean: -0.59868
[32m[0907 00-25-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09038, current rewards: -79.80613, mean: -0.72551
[32m[0907 00-25-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09083, current rewards: -173.08028, mean: -1.08175
[32m[0907 00-26-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09068, current rewards: -224.52373, mean: -1.06916
[32m[0907 00-26-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08997, current rewards: -324.52373, mean: -1.24817
[32m[0907 00-26-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08945, current rewards: -424.52373, mean: -1.36943
[32m[0907 00-26-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08909, current rewards: -524.52373, mean: -1.45701
[32m[0907 00-26-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08884, current rewards: -624.52373, mean: -1.52323
[32m[0907 00-26-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08862, current rewards: -724.52373, mean: -1.57505
[32m[0907 00-26-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08843, current rewards: -824.52373, mean: -1.61671
[32m[0907 00-26-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08830, current rewards: -924.52373, mean: -1.65094
[32m[0907 00-26-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08819, current rewards: -1024.52373, mean: -1.67955
[32m[0907 00-26-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08810, current rewards: -1124.52373, mean: -1.70382
[32m[0907 00-26-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08801, current rewards: -1224.52373, mean: -1.72468
[32m[0907 00-26-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08793, current rewards: -1324.52373, mean: -1.74279
[32m[0907 00-26-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08786, current rewards: -1424.52373, mean: -1.75867
[32m[0907 00-26-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08780, current rewards: -1524.52373, mean: -1.77270
[32m[0907 00-27-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08775, current rewards: -1624.52373, mean: -1.78519
[32m[0907 00-27-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08771, current rewards: -1724.52373, mean: -1.79638
[32m[0907 00-27-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08768, current rewards: -1824.52373, mean: -1.80646
[32m[0907 00-27-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08764, current rewards: -1924.52373, mean: -1.81559
[32m[0907 00-27-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08761, current rewards: -2024.52373, mean: -1.82390
[32m[0907 00-27-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08757, current rewards: -2124.52373, mean: -1.83149
[32m[0907 00-27-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08755, current rewards: -2224.52373, mean: -1.83845
[32m[0907 00-27-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08753, current rewards: -2324.52373, mean: -1.84486
[32m[0907 00-27-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08751, current rewards: -2424.52373, mean: -1.85078
[32m[0907 00-27-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08747, current rewards: -2524.52373, mean: -1.85627
[32m[0907 00-27-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08745, current rewards: -2624.52373, mean: -1.86136
[32m[0907 00-27-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08743, current rewards: -2724.52373, mean: -1.86611
[32m[0907 00-27-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08742, current rewards: -2824.52373, mean: -1.87055
[32m[0907 00-27-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08741, current rewards: -2924.52373, mean: -1.87469
[32m[0907 00-28-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08739, current rewards: -3024.52373, mean: -1.87859
[32m[0907 00-28-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08736, current rewards: -3124.52373, mean: -1.88224
[32m[0907 00-28-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08730, current rewards: -3224.52373, mean: -1.88569
[32m[0907 00-28-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08722, current rewards: -3324.52373, mean: -1.88893
[32m[0907 00-28-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08720, current rewards: -3424.52373, mean: -1.89200
[32m[0907 00-28-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08719, current rewards: -3524.52373, mean: -1.89491
[32m[0907 00-28-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08719, current rewards: -3624.52373, mean: -1.89766
[32m[0907 00-28-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08718, current rewards: -3724.52373, mean: -1.90027
[32m[0907 00-28-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08718, current rewards: -3824.52373, mean: -1.90275
[32m[0907 00-28-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08721, current rewards: -3924.52373, mean: -1.90511
[32m[0907 00-28-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08726, current rewards: -4024.52373, mean: -1.90736
[32m[0907 00-28-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08731, current rewards: -4124.52373, mean: -1.90950
[32m[0907 00-28-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08736, current rewards: -4224.52373, mean: -1.91155
[32m[0907 00-29-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08740, current rewards: -4324.52373, mean: -1.91351
[32m[0907 00-29-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08745, current rewards: -4424.52373, mean: -1.91538
[32m[0907 00-29-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08749, current rewards: -4524.52373, mean: -1.91717
[32m[0907 00-29-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08750, current rewards: -4624.52373, mean: -1.91889
[32m[0907 00-29-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08749, current rewards: -4724.52373, mean: -1.92054
[32m[0907 00-29-21 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0907 00-29-21 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-29-21 @MBExp.py:227][0m Rewards obtained: [-4804.523730998343], Lows: [2379], Highs: [55], Total time: 27322.33199
[32m[0907 00-32-34 @MBExp.py:144][0m ####################################################################
[32m[0907 00-32-34 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 00-32-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08592, current rewards: -5.71776, mean: -0.57178
[32m[0907 00-32-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08676, current rewards: -0.30016, mean: -0.00500
[32m[0907 00-32-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08695, current rewards: 5.09973, mean: 0.04636
[32m[0907 00-32-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08695, current rewards: 10.50155, mean: 0.06563
[32m[0907 00-32-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08691, current rewards: 15.90543, mean: 0.07574
[32m[0907 00-32-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08689, current rewards: 21.44937, mean: 0.08250
[32m[0907 00-33-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08691, current rewards: 26.84835, mean: 0.08661
[32m[0907 00-33-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08693, current rewards: 32.25146, mean: 0.08959
[32m[0907 00-33-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08699, current rewards: 37.65332, mean: 0.09184
[32m[0907 00-33-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08713, current rewards: 30.42061, mean: 0.06613
[32m[0907 00-33-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08715, current rewards: 34.96791, mean: 0.06856
[32m[0907 00-33-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08713, current rewards: 39.51575, mean: 0.07056
[32m[0907 00-33-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08711, current rewards: 44.06548, mean: 0.07224
[32m[0907 00-33-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08707, current rewards: 48.30162, mean: 0.07318
[32m[0907 00-33-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08705, current rewards: 52.61993, mean: 0.07411
[32m[0907 00-33-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08706, current rewards: 56.93685, mean: 0.07492
[32m[0907 00-33-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08706, current rewards: 61.25413, mean: 0.07562
[32m[0907 00-33-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08708, current rewards: 65.56948, mean: 0.07624
[32m[0907 00-33-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08707, current rewards: 64.65135, mean: 0.07105
[32m[0907 00-33-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08707, current rewards: 70.14647, mean: 0.07307
[32m[0907 00-34-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08707, current rewards: 75.64130, mean: 0.07489
[32m[0907 00-34-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08707, current rewards: 80.92195, mean: 0.07634
[32m[0907 00-34-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08708, current rewards: 86.14404, mean: 0.07761
[32m[0907 00-34-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08706, current rewards: 91.60898, mean: 0.07897
[32m[0907 00-34-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08706, current rewards: 97.07103, mean: 0.08022
[32m[0907 00-34-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08707, current rewards: 102.53535, mean: 0.08138
[32m[0907 00-34-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08706, current rewards: 108.00484, mean: 0.08245
[32m[0907 00-34-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08707, current rewards: 113.46682, mean: 0.08343
[32m[0907 00-34-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08706, current rewards: 118.92702, mean: 0.08435
[32m[0907 00-34-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08706, current rewards: 124.39271, mean: 0.08520
[32m[0907 00-34-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08706, current rewards: 116.24187, mean: 0.07698
[32m[0907 00-34-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08705, current rewards: 121.74158, mean: 0.07804
[32m[0907 00-34-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08703, current rewards: 127.20913, mean: 0.07901
[32m[0907 00-34-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08703, current rewards: 132.68175, mean: 0.07993
[32m[0907 00-35-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08697, current rewards: 138.14860, mean: 0.08079
[32m[0907 00-35-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08691, current rewards: 143.61583, mean: 0.08160
[32m[0907 00-35-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08686, current rewards: 149.07999, mean: 0.08236
[32m[0907 00-35-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08681, current rewards: 154.54344, mean: 0.08309
[32m[0907 00-35-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08676, current rewards: 161.31291, mean: 0.08446
[32m[0907 00-35-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08671, current rewards: 166.75552, mean: 0.08508
[32m[0907 00-35-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08668, current rewards: 172.19023, mean: 0.08567
[32m[0907 00-35-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08671, current rewards: 177.62045, mean: 0.08622
[32m[0907 00-35-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08679, current rewards: 183.05014, mean: 0.08675
[32m[0907 00-35-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08686, current rewards: 188.48158, mean: 0.08726
[32m[0907 00-35-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08693, current rewards: 183.36201, mean: 0.08297
[32m[0907 00-35-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08700, current rewards: 188.82019, mean: 0.08355
[32m[0907 00-35-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08705, current rewards: 194.23075, mean: 0.08408
[32m[0907 00-36-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08710, current rewards: 199.11662, mean: 0.08437
[32m[0907 00-36-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08715, current rewards: 204.51952, mean: 0.08486
[32m[0907 00-36-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08718, current rewards: 209.92729, mean: 0.08534
[32m[0907 00-36-12 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0907 00-36-12 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-36-13 @MBExp.py:227][0m Rewards obtained: [214.2517028541372], Lows: [15], Highs: [16], Total time: 27541.019811
[32m[0907 00-39-27 @MBExp.py:144][0m ####################################################################
[32m[0907 00-39-27 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 00-39-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09205, current rewards: -7.80981, mean: -0.78098
[32m[0907 00-39-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08798, current rewards: -3.60003, mean: -0.06000
[32m[0907 00-39-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08750, current rewards: 2.41571, mean: 0.02196
[32m[0907 00-39-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08743, current rewards: 8.43018, mean: 0.05269
[32m[0907 00-39-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08732, current rewards: 14.44420, mean: 0.06878
[32m[0907 00-39-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08722, current rewards: 20.32799, mean: 0.07818
[32m[0907 00-39-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08719, current rewards: 19.58419, mean: 0.06317
[32m[0907 00-39-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08719, current rewards: 25.02400, mean: 0.06951
[32m[0907 00-40-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08715, current rewards: 30.44801, mean: 0.07426
[32m[0907 00-40-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08712, current rewards: 35.87974, mean: 0.07800
[32m[0907 00-40-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08712, current rewards: 41.30967, mean: 0.08100
[32m[0907 00-40-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08708, current rewards: 46.73976, mean: 0.08346
[32m[0907 00-40-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08708, current rewards: 52.16446, mean: 0.08552
[32m[0907 00-40-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08711, current rewards: 43.53318, mean: 0.06596
[32m[0907 00-40-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08709, current rewards: 48.30102, mean: 0.06803
[32m[0907 00-40-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08708, current rewards: 53.07080, mean: 0.06983
[32m[0907 00-40-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08709, current rewards: 57.83723, mean: 0.07140
[32m[0907 00-40-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08709, current rewards: 62.60476, mean: 0.07280
[32m[0907 00-40-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08708, current rewards: 67.36468, mean: 0.07403
[32m[0907 00-40-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08709, current rewards: 72.14159, mean: 0.07515
[32m[0907 00-40-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08708, current rewards: 76.90632, mean: 0.07614
[32m[0907 00-40-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08707, current rewards: 81.66537, mean: 0.07704
[32m[0907 00-41-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08705, current rewards: 87.45687, mean: 0.07879
[32m[0907 00-41-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08703, current rewards: 92.91544, mean: 0.08010
[32m[0907 00-41-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08702, current rewards: 88.21709, mean: 0.07291
[32m[0907 00-41-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08701, current rewards: 94.13347, mean: 0.07471
[32m[0907 00-41-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08701, current rewards: 100.05041, mean: 0.07637
[32m[0907 00-41-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08700, current rewards: 105.96809, mean: 0.07792
[32m[0907 00-41-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08700, current rewards: 111.88272, mean: 0.07935
[32m[0907 00-41-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08699, current rewards: 117.79957, mean: 0.08068
[32m[0907 00-41-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08699, current rewards: 123.70828, mean: 0.08193
[32m[0907 00-41-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08697, current rewards: 128.34600, mean: 0.08227
[32m[0907 00-41-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08696, current rewards: 133.99257, mean: 0.08323
[32m[0907 00-41-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08696, current rewards: 139.64194, mean: 0.08412
[32m[0907 00-41-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08691, current rewards: 145.29435, mean: 0.08497
[32m[0907 00-42-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08684, current rewards: 150.93910, mean: 0.08576
[32m[0907 00-42-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08676, current rewards: 156.59926, mean: 0.08652
[32m[0907 00-42-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08669, current rewards: 162.25519, mean: 0.08723
[32m[0907 00-42-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08664, current rewards: 167.91002, mean: 0.08791
[32m[0907 00-42-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08658, current rewards: 174.45406, mean: 0.08901
[32m[0907 00-42-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08655, current rewards: 181.14563, mean: 0.09012
[32m[0907 00-42-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08659, current rewards: 187.04452, mean: 0.09080
[32m[0907 00-42-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08666, current rewards: 186.20126, mean: 0.08825
[32m[0907 00-42-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08673, current rewards: 185.45461, mean: 0.08586
[32m[0907 00-42-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08679, current rewards: 183.88649, mean: 0.08321
[32m[0907 00-42-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08687, current rewards: 179.47083, mean: 0.07941
[32m[0907 00-42-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08692, current rewards: 183.05987, mean: 0.07925
[32m[0907 00-42-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08698, current rewards: 186.69765, mean: 0.07911
[32m[0907 00-42-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08704, current rewards: 190.11819, mean: 0.07889
[32m[0907 00-43-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08709, current rewards: 193.62908, mean: 0.07871
[32m[0907 00-43-05 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 00-43-05 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-43-05 @MBExp.py:227][0m Rewards obtained: [196.4396996441812], Lows: [13], Highs: [37], Total time: 27759.473862
[32m[0907 00-46-21 @MBExp.py:144][0m ####################################################################
[32m[0907 00-46-21 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 00-46-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09291, current rewards: -6.76630, mean: -0.67663
[32m[0907 00-46-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08784, current rewards: -0.31525, mean: -0.00525
[32m[0907 00-46-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08749, current rewards: 7.33983, mean: 0.06673
[32m[0907 00-46-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08737, current rewards: 14.99491, mean: 0.09372
[32m[0907 00-46-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08726, current rewards: 22.64999, mean: 0.10786
[32m[0907 00-46-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08723, current rewards: 30.30507, mean: 0.11656
[32m[0907 00-46-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08716, current rewards: 18.35743, mean: 0.05922
[32m[0907 00-46-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08715, current rewards: -31.64257, mean: -0.08790
[32m[0907 00-46-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08715, current rewards: -81.64257, mean: -0.19913
[32m[0907 00-47-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08720, current rewards: -131.64257, mean: -0.28618
[32m[0907 00-47-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08716, current rewards: -181.64257, mean: -0.35616
[32m[0907 00-47-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08716, current rewards: -231.64257, mean: -0.41365
[32m[0907 00-47-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08716, current rewards: -281.64257, mean: -0.46171
[32m[0907 00-47-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08712, current rewards: -331.64257, mean: -0.50249
[32m[0907 00-47-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08711, current rewards: -381.64257, mean: -0.53752
[32m[0907 00-47-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08709, current rewards: -431.64257, mean: -0.56795
[32m[0907 00-47-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08708, current rewards: -481.64257, mean: -0.59462
[32m[0907 00-47-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08708, current rewards: -531.64257, mean: -0.61819
[32m[0907 00-47-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08707, current rewards: -581.64257, mean: -0.63917
[32m[0907 00-47-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08707, current rewards: -631.64257, mean: -0.65796
[32m[0907 00-47-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08707, current rewards: -681.64257, mean: -0.67489
[32m[0907 00-47-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08705, current rewards: -731.64257, mean: -0.69023
[32m[0907 00-47-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08703, current rewards: -781.64257, mean: -0.70418
[32m[0907 00-48-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08701, current rewards: -831.64257, mean: -0.71693
[32m[0907 00-48-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08700, current rewards: -881.64257, mean: -0.72863
[32m[0907 00-48-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08700, current rewards: -931.64257, mean: -0.73940
[32m[0907 00-48-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08699, current rewards: -981.64257, mean: -0.74935
[32m[0907 00-48-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08698, current rewards: -1031.64257, mean: -0.75856
[32m[0907 00-48-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08697, current rewards: -1081.64257, mean: -0.76712
[32m[0907 00-48-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08696, current rewards: -1131.64257, mean: -0.77510
[32m[0907 00-48-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08696, current rewards: -1181.64257, mean: -0.78254
[32m[0907 00-48-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08695, current rewards: -1231.64257, mean: -0.78951
[32m[0907 00-48-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08695, current rewards: -1281.64257, mean: -0.79605
[32m[0907 00-48-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08694, current rewards: -1331.64257, mean: -0.80219
[32m[0907 00-48-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08691, current rewards: -1381.64257, mean: -0.80798
[32m[0907 00-48-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08685, current rewards: -1431.64257, mean: -0.81343
[32m[0907 00-48-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08679, current rewards: -1481.64257, mean: -0.81859
[32m[0907 00-49-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08673, current rewards: -1531.64257, mean: -0.82346
[32m[0907 00-49-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08668, current rewards: -1581.64257, mean: -0.82809
[32m[0907 00-49-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08663, current rewards: -1631.64257, mean: -0.83247
[32m[0907 00-49-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08660, current rewards: -1681.64257, mean: -0.83664
[32m[0907 00-49-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08664, current rewards: -1731.64257, mean: -0.84060
[32m[0907 00-49-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08671, current rewards: -1781.64257, mean: -0.84438
[32m[0907 00-49-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08677, current rewards: -1831.64257, mean: -0.84798
[32m[0907 00-49-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08683, current rewards: -1881.64257, mean: -0.85142
[32m[0907 00-49-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08689, current rewards: -1931.64257, mean: -0.85471
[32m[0907 00-49-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08695, current rewards: -1981.64257, mean: -0.85785
[32m[0907 00-49-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08701, current rewards: -2031.64257, mean: -0.86087
[32m[0907 00-49-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08706, current rewards: -2081.64257, mean: -0.86375
[32m[0907 00-49-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08712, current rewards: -2131.64257, mean: -0.86652
[32m[0907 00-49-59 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 00-49-59 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-49-59 @MBExp.py:227][0m Rewards obtained: [-2171.642573978399], Lows: [1], Highs: [2212], Total time: 27978.019857
[32m[0907 00-53-17 @MBExp.py:144][0m ####################################################################
[32m[0907 00-53-17 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 00-53-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08939, current rewards: -15.00000, mean: -1.50000
[32m[0907 00-53-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08819, current rewards: -115.00000, mean: -1.91667
[32m[0907 00-53-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08922, current rewards: -215.00000, mean: -1.95455
[32m[0907 00-53-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09036, current rewards: -315.00000, mean: -1.96875
[32m[0907 00-53-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08997, current rewards: -415.00000, mean: -1.97619
[32m[0907 00-53-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09022, current rewards: -512.59793, mean: -1.97153
[32m[0907 00-53-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09014, current rewards: -612.59793, mean: -1.97612
[32m[0907 00-53-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08997, current rewards: -712.59793, mean: -1.97944
[32m[0907 00-53-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09015, current rewards: -812.59793, mean: -1.98195
[32m[0907 00-53-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09034, current rewards: -910.05632, mean: -1.97838
[32m[0907 00-54-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09035, current rewards: -1007.73873, mean: -1.97596
[32m[0907 00-54-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09179, current rewards: -1098.71348, mean: -1.96199
[32m[0907 00-54-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09208, current rewards: -1196.18623, mean: -1.96096
[32m[0907 00-54-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09276, current rewards: -1289.93075, mean: -1.95444
[32m[0907 00-54-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09259, current rewards: -1387.37570, mean: -1.95405
[32m[0907 00-54-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09341, current rewards: -1471.24150, mean: -1.93584
[32m[0907 00-54-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09302, current rewards: -1569.13726, mean: -1.93721
[32m[0907 00-54-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09269, current rewards: -1669.13726, mean: -1.94086
[32m[0907 00-54-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09239, current rewards: -1769.13726, mean: -1.94411
[32m[0907 00-54-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09212, current rewards: -1869.13726, mean: -1.94702
[32m[0907 00-54-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09186, current rewards: -1969.13726, mean: -1.94964
[32m[0907 00-54-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09163, current rewards: -2069.13726, mean: -1.95202
[32m[0907 00-54-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09142, current rewards: -2169.13726, mean: -1.95418
[32m[0907 00-55-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09129, current rewards: -2256.81031, mean: -1.94553
[32m[0907 00-55-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09116, current rewards: -2356.81031, mean: -1.94778
[32m[0907 00-55-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09111, current rewards: -2449.46912, mean: -1.94402
[32m[0907 00-55-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09101, current rewards: -2545.07820, mean: -1.94281
[32m[0907 00-55-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09091, current rewards: -2635.76834, mean: -1.93806
[32m[0907 00-55-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09077, current rewards: -2730.53310, mean: -1.93655
[32m[0907 00-55-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09070, current rewards: -2830.53310, mean: -1.93872
[32m[0907 00-55-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09064, current rewards: -2920.40658, mean: -1.93404
[32m[0907 00-55-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09063, current rewards: -3020.40658, mean: -1.93616
[32m[0907 00-55-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09098, current rewards: -3118.26623, mean: -1.93681
[32m[0907 00-55-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09117, current rewards: -3218.26623, mean: -1.93871
[32m[0907 00-55-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09140, current rewards: -3315.80007, mean: -1.93906
[32m[0907 00-55-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09157, current rewards: -3415.80007, mean: -1.94080
[32m[0907 00-56-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09165, current rewards: -3513.55928, mean: -1.94119
[32m[0907 00-56-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09196, current rewards: -3613.55928, mean: -1.94277
[32m[0907 00-56-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09198, current rewards: -3647.36517, mean: -1.90962
[32m[0907 00-56-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09192, current rewards: -3641.88985, mean: -1.85811
[32m[0907 00-56-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09186, current rewards: -3637.19344, mean: -1.80955
[32m[0907 00-56-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09180, current rewards: -3632.49703, mean: -1.76335
[32m[0907 00-56-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09175, current rewards: -3627.80062, mean: -1.71934
[32m[0907 00-56-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09169, current rewards: -3623.10421, mean: -1.67736
[32m[0907 00-56-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09165, current rewards: -3618.40780, mean: -1.63729
[32m[0907 00-56-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09161, current rewards: -3613.71139, mean: -1.59899
[32m[0907 00-56-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09155, current rewards: -3609.01498, mean: -1.56234
[32m[0907 00-56-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09150, current rewards: -3604.34552, mean: -1.52727
[32m[0907 00-56-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09141, current rewards: -3640.55218, mean: -1.51060
[32m[0907 00-57-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09132, current rewards: -3690.55218, mean: -1.50022
[32m[0907 00-57-05 @Agent.py:117][0m Average action selection time: 0.0912
[32m[0907 00-57-05 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-57-06 @MBExp.py:227][0m Rewards obtained: [-3730.5521796845783], Lows: [1830], Highs: [132], Total time: 28206.889382999998
[32m[0907 01-00-25 @MBExp.py:144][0m ####################################################################
[32m[0907 01-00-25 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 01-00-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.13163, current rewards: -14.00000, mean: -1.40000
[32m[0907 01-00-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.12112, current rewards: -61.72929, mean: -1.02882
[32m[0907 01-00-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.12293, current rewards: -113.16716, mean: -1.02879
[32m[0907 01-00-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.12305, current rewards: -178.44207, mean: -1.11526
[32m[0907 01-00-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11984, current rewards: -248.93578, mean: -1.18541
[32m[0907 01-00-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11853, current rewards: -288.17344, mean: -1.10836
[32m[0907 01-01-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11608, current rewards: -353.91633, mean: -1.14167
[32m[0907 01-01-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11459, current rewards: -429.40280, mean: -1.19279
[32m[0907 01-01-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11681, current rewards: -493.51839, mean: -1.20370
[32m[0907 01-01-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11446, current rewards: -584.44826, mean: -1.27054
[32m[0907 01-01-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11332, current rewards: -683.44826, mean: -1.34009
[32m[0907 01-01-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11158, current rewards: -747.76157, mean: -1.33529
[32m[0907 01-01-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11191, current rewards: -798.88035, mean: -1.30964
[32m[0907 01-01-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11207, current rewards: -856.32393, mean: -1.29746
[32m[0907 01-01-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11195, current rewards: -892.63250, mean: -1.25723
[32m[0907 01-01-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11154, current rewards: -952.08507, mean: -1.25274
[32m[0907 01-01-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11096, current rewards: -1015.08507, mean: -1.25319
[32m[0907 01-02-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11140, current rewards: -1061.33580, mean: -1.23411
[32m[0907 01-02-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11124, current rewards: -1111.58137, mean: -1.22152
[32m[0907 01-02-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11039, current rewards: -1199.00358, mean: -1.24896
[32m[0907 01-02-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10921, current rewards: -1299.00358, mean: -1.28614
[32m[0907 01-02-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10816, current rewards: -1399.00358, mean: -1.31981
[32m[0907 01-02-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10720, current rewards: -1499.00358, mean: -1.35045
[32m[0907 01-02-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10633, current rewards: -1599.00358, mean: -1.37845
[32m[0907 01-02-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10550, current rewards: -1699.00358, mean: -1.40414
[32m[0907 01-02-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10476, current rewards: -1799.00358, mean: -1.42778
[32m[0907 01-02-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10408, current rewards: -1899.00358, mean: -1.44962
[32m[0907 01-02-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10346, current rewards: -1999.00358, mean: -1.46986
[32m[0907 01-02-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10283, current rewards: -2099.00358, mean: -1.48866
[32m[0907 01-02-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10221, current rewards: -2199.00358, mean: -1.50617
[32m[0907 01-02-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10163, current rewards: -2299.00358, mean: -1.52252
[32m[0907 01-03-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10109, current rewards: -2399.00358, mean: -1.53782
[32m[0907 01-03-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10059, current rewards: -2499.00358, mean: -1.55218
[32m[0907 01-03-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10012, current rewards: -2599.00358, mean: -1.56566
[32m[0907 01-03-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09979, current rewards: -2699.00358, mean: -1.57836
[32m[0907 01-03-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09951, current rewards: -2799.00358, mean: -1.59034
[32m[0907 01-03-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09925, current rewards: -2899.00358, mean: -1.60166
[32m[0907 01-03-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09899, current rewards: -2999.00358, mean: -1.61237
[32m[0907 01-03-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09874, current rewards: -3099.00358, mean: -1.62251
[32m[0907 01-03-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09852, current rewards: -3199.00358, mean: -1.63214
[32m[0907 01-03-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09829, current rewards: -3299.00358, mean: -1.64130
[32m[0907 01-03-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09809, current rewards: -3399.00358, mean: -1.65000
[32m[0907 01-03-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09789, current rewards: -3499.00358, mean: -1.65830
[32m[0907 01-03-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09765, current rewards: -3599.00358, mean: -1.66621
[32m[0907 01-04-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09740, current rewards: -3699.00358, mean: -1.67376
[32m[0907 01-04-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09716, current rewards: -3799.00358, mean: -1.68098
[32m[0907 01-04-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09695, current rewards: -3899.00358, mean: -1.68788
[32m[0907 01-04-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09673, current rewards: -3999.00358, mean: -1.69449
[32m[0907 01-04-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09653, current rewards: -4099.00358, mean: -1.70083
[32m[0907 01-04-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09634, current rewards: -4199.00358, mean: -1.70691
[32m[0907 01-04-26 @Agent.py:117][0m Average action selection time: 0.0962
[32m[0907 01-04-26 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-04-26 @MBExp.py:227][0m Rewards obtained: [-4279.003579109688], Lows: [1921], Highs: [456], Total time: 28448.139328999998
[32m[0907 01-07-47 @MBExp.py:144][0m ####################################################################
[32m[0907 01-07-47 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 01-07-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.14350, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-07-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.12637, current rewards: -59.27416, mean: -0.98790
[32m[0907 01-07-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10843, current rewards: -159.27416, mean: -1.44795
[32m[0907 01-08-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10172, current rewards: -259.27416, mean: -1.62046
[32m[0907 01-08-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09822, current rewards: -359.27416, mean: -1.71083
[32m[0907 01-08-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09590, current rewards: -459.27416, mean: -1.76644
[32m[0907 01-08-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09443, current rewards: -559.27416, mean: -1.80411
[32m[0907 01-08-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09538, current rewards: -627.53986, mean: -1.74317
[32m[0907 01-08-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09550, current rewards: -716.01585, mean: -1.74638
[32m[0907 01-08-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09472, current rewards: -813.42706, mean: -1.76832
[32m[0907 01-08-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09615, current rewards: -891.18192, mean: -1.74742
[32m[0907 01-08-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09919, current rewards: -968.67874, mean: -1.72978
[32m[0907 01-08-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10008, current rewards: -1021.22254, mean: -1.67414
[32m[0907 01-08-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10129, current rewards: -1098.16487, mean: -1.66389
[32m[0907 01-08-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10184, current rewards: -1179.64266, mean: -1.66147
[32m[0907 01-09-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10086, current rewards: -1229.64266, mean: -1.61795
[32m[0907 01-09-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10000, current rewards: -1279.64266, mean: -1.57981
[32m[0907 01-09-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09923, current rewards: -1329.64266, mean: -1.54610
[32m[0907 01-09-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09856, current rewards: -1379.64266, mean: -1.51609
[32m[0907 01-09-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09797, current rewards: -1429.64266, mean: -1.48921
[32m[0907 01-09-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09743, current rewards: -1479.64266, mean: -1.46499
[32m[0907 01-09-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09692, current rewards: -1526.49860, mean: -1.44009
[32m[0907 01-09-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09645, current rewards: -1524.09790, mean: -1.37306
[32m[0907 01-09-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09605, current rewards: -1566.76181, mean: -1.35066
[32m[0907 01-09-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09567, current rewards: -1616.76181, mean: -1.33617
[32m[0907 01-09-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09532, current rewards: -1666.76181, mean: -1.32283
[32m[0907 01-09-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09498, current rewards: -1716.76181, mean: -1.31051
[32m[0907 01-09-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09458, current rewards: -1766.76181, mean: -1.29909
[32m[0907 01-10-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09422, current rewards: -1816.76181, mean: -1.28848
[32m[0907 01-10-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09390, current rewards: -1866.76181, mean: -1.27860
[32m[0907 01-10-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09360, current rewards: -1916.76181, mean: -1.26938
[32m[0907 01-10-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09332, current rewards: -1966.76181, mean: -1.26074
[32m[0907 01-10-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09319, current rewards: -2016.76181, mean: -1.25265
[32m[0907 01-10-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09308, current rewards: -2066.76181, mean: -1.24504
[32m[0907 01-10-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09298, current rewards: -2116.76181, mean: -1.23787
[32m[0907 01-10-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09289, current rewards: -2166.76181, mean: -1.23111
[32m[0907 01-10-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09279, current rewards: -2216.76181, mean: -1.22473
[32m[0907 01-10-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09271, current rewards: -2266.76181, mean: -1.21869
[32m[0907 01-10-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09263, current rewards: -2316.76181, mean: -1.21296
[32m[0907 01-10-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09255, current rewards: -2366.76181, mean: -1.20753
[32m[0907 01-10-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09248, current rewards: -2416.76181, mean: -1.20237
[32m[0907 01-10-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09241, current rewards: -2466.76181, mean: -1.19746
[32m[0907 01-11-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09235, current rewards: -2516.76181, mean: -1.19278
[32m[0907 01-11-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09229, current rewards: -2566.76181, mean: -1.18832
[32m[0907 01-11-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09222, current rewards: -2616.76181, mean: -1.18406
[32m[0907 01-11-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09210, current rewards: -2666.76181, mean: -1.17998
[32m[0907 01-11-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09200, current rewards: -2693.48536, mean: -1.16601
[32m[0907 01-11-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09189, current rewards: -2743.48536, mean: -1.16249
[32m[0907 01-11-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09179, current rewards: -2793.48536, mean: -1.15912
[32m[0907 01-11-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09169, current rewards: -2843.48536, mean: -1.15589
[32m[0907 01-11-36 @Agent.py:117][0m Average action selection time: 0.0916
[32m[0907 01-11-36 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-11-37 @MBExp.py:227][0m Rewards obtained: [-2883.485362010736], Lows: [560], Highs: [1782], Total time: 28677.917037
[32m[0907 01-15-00 @MBExp.py:144][0m ####################################################################
[32m[0907 01-15-00 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 01-15-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09719, current rewards: -9.73557, mean: -0.97356
[32m[0907 01-15-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08858, current rewards: -59.56795, mean: -0.99280
[32m[0907 01-15-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08799, current rewards: -109.56795, mean: -0.99607
[32m[0907 01-15-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08750, current rewards: -159.56795, mean: -0.99730
[32m[0907 01-15-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08737, current rewards: -209.56795, mean: -0.99794
[32m[0907 01-15-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08727, current rewards: -259.56795, mean: -0.99834
[32m[0907 01-15-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08722, current rewards: -309.56795, mean: -0.99861
[32m[0907 01-15-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08716, current rewards: -359.56795, mean: -0.99880
[32m[0907 01-15-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08714, current rewards: -409.56795, mean: -0.99895
[32m[0907 01-15-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08714, current rewards: -459.56795, mean: -0.99906
[32m[0907 01-15-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08718, current rewards: -509.56795, mean: -0.99915
[32m[0907 01-15-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08715, current rewards: -559.56795, mean: -0.99923
[32m[0907 01-15-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08711, current rewards: -609.56795, mean: -0.99929
[32m[0907 01-15-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08706, current rewards: -659.56795, mean: -0.99935
[32m[0907 01-16-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08704, current rewards: -709.56795, mean: -0.99939
[32m[0907 01-16-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08703, current rewards: -759.56795, mean: -0.99943
[32m[0907 01-16-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08702, current rewards: -809.56795, mean: -0.99947
[32m[0907 01-16-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08702, current rewards: -859.56795, mean: -0.99950
[32m[0907 01-16-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08702, current rewards: -909.56795, mean: -0.99953
[32m[0907 01-16-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08702, current rewards: -959.56795, mean: -0.99955
[32m[0907 01-16-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08702, current rewards: -1009.56795, mean: -0.99957
[32m[0907 01-16-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08701, current rewards: -1059.56795, mean: -0.99959
[32m[0907 01-16-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08699, current rewards: -1109.56795, mean: -0.99961
[32m[0907 01-16-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08699, current rewards: -1159.56795, mean: -0.99963
[32m[0907 01-16-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08699, current rewards: -1209.56795, mean: -0.99964
[32m[0907 01-16-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08699, current rewards: -1259.56795, mean: -0.99966
[32m[0907 01-16-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08697, current rewards: -1309.56795, mean: -0.99967
[32m[0907 01-16-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08697, current rewards: -1359.56795, mean: -0.99968
[32m[0907 01-17-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08689, current rewards: -1409.56795, mean: -0.99969
[32m[0907 01-17-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08681, current rewards: -1459.56795, mean: -0.99970
[32m[0907 01-17-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08674, current rewards: -1509.56795, mean: -0.99971
[32m[0907 01-17-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08668, current rewards: -1559.56795, mean: -0.99972
[32m[0907 01-17-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08676, current rewards: -1609.56795, mean: -0.99973
[32m[0907 01-17-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08685, current rewards: -1659.56795, mean: -0.99974
[32m[0907 01-17-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08692, current rewards: -1709.56795, mean: -0.99975
[32m[0907 01-17-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08699, current rewards: -1759.56795, mean: -0.99975
[32m[0907 01-17-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08708, current rewards: -1809.56795, mean: -0.99976
[32m[0907 01-17-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08713, current rewards: -1834.75547, mean: -0.98643
[32m[0907 01-17-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08719, current rewards: -1828.83760, mean: -0.95751
[32m[0907 01-17-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08726, current rewards: -1878.83760, mean: -0.95859
[32m[0907 01-17-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08731, current rewards: -1928.83760, mean: -0.95962
[32m[0907 01-18-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08737, current rewards: -1978.83760, mean: -0.96060
[32m[0907 01-18-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08742, current rewards: -2028.83760, mean: -0.96153
[32m[0907 01-18-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08748, current rewards: -2078.83760, mean: -0.96242
[32m[0907 01-18-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08753, current rewards: -2128.83760, mean: -0.96327
[32m[0907 01-18-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08754, current rewards: -2178.83760, mean: -0.96409
[32m[0907 01-18-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08753, current rewards: -2228.83760, mean: -0.96486
[32m[0907 01-18-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08751, current rewards: -2278.83760, mean: -0.96561
[32m[0907 01-18-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08750, current rewards: -2328.83760, mean: -0.96632
[32m[0907 01-18-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08749, current rewards: -2378.83760, mean: -0.96701
[32m[0907 01-18-39 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0907 01-18-39 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-18-39 @MBExp.py:227][0m Rewards obtained: [-2418.8375957587705], Lows: [3], Highs: [2421], Total time: 28897.381823
[32m[0907 01-22-04 @MBExp.py:144][0m ####################################################################
[32m[0907 01-22-04 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 01-22-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09719, current rewards: -10.78230, mean: -1.07823
[32m[0907 01-22-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08852, current rewards: -110.78230, mean: -1.84637
[32m[0907 01-22-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08783, current rewards: -210.78230, mean: -1.91620
[32m[0907 01-22-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08754, current rewards: -310.78230, mean: -1.94239
[32m[0907 01-22-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08738, current rewards: -410.78230, mean: -1.95611
[32m[0907 01-22-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08735, current rewards: -510.78230, mean: -1.96455
[32m[0907 01-22-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08728, current rewards: -610.78230, mean: -1.97027
[32m[0907 01-22-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08720, current rewards: -710.78230, mean: -1.97440
[32m[0907 01-22-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08722, current rewards: -810.78230, mean: -1.97752
[32m[0907 01-22-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08720, current rewards: -910.78230, mean: -1.97996
[32m[0907 01-22-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08723, current rewards: -1010.78230, mean: -1.98193
[32m[0907 01-22-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08725, current rewards: -1110.78230, mean: -1.98354
[32m[0907 01-22-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08721, current rewards: -1210.78230, mean: -1.98489
[32m[0907 01-23-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08718, current rewards: -1310.78230, mean: -1.98603
[32m[0907 01-23-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08718, current rewards: -1410.78230, mean: -1.98702
[32m[0907 01-23-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08718, current rewards: -1510.78230, mean: -1.98787
[32m[0907 01-23-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08717, current rewards: -1610.78230, mean: -1.98862
[32m[0907 01-23-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08715, current rewards: -1710.78230, mean: -1.98928
[32m[0907 01-23-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08717, current rewards: -1810.78230, mean: -1.98987
[32m[0907 01-23-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08718, current rewards: -1910.78230, mean: -1.99040
[32m[0907 01-23-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08720, current rewards: -2010.78230, mean: -1.99087
[32m[0907 01-23-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08719, current rewards: -2110.78230, mean: -1.99130
[32m[0907 01-23-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08717, current rewards: -2210.78230, mean: -1.99170
[32m[0907 01-23-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08716, current rewards: -2310.78230, mean: -1.99205
[32m[0907 01-23-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08714, current rewards: -2410.78230, mean: -1.99238
[32m[0907 01-23-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08713, current rewards: -2510.78230, mean: -1.99268
[32m[0907 01-23-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08711, current rewards: -2610.78230, mean: -1.99296
[32m[0907 01-24-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08707, current rewards: -2710.78230, mean: -1.99322
[32m[0907 01-24-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08700, current rewards: -2810.78230, mean: -1.99346
[32m[0907 01-24-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08692, current rewards: -2910.78230, mean: -1.99369
[32m[0907 01-24-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08685, current rewards: -3010.78230, mean: -1.99390
[32m[0907 01-24-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08680, current rewards: -3110.78230, mean: -1.99409
[32m[0907 01-24-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08686, current rewards: -3210.78230, mean: -1.99427
[32m[0907 01-24-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08696, current rewards: -3310.78230, mean: -1.99445
[32m[0907 01-24-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08704, current rewards: -3410.78230, mean: -1.99461
[32m[0907 01-24-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08711, current rewards: -3510.78230, mean: -1.99476
[32m[0907 01-24-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08719, current rewards: -3610.78230, mean: -1.99491
[32m[0907 01-24-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08724, current rewards: -3710.78230, mean: -1.99504
[32m[0907 01-24-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08730, current rewards: -3810.78230, mean: -1.99517
[32m[0907 01-24-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08736, current rewards: -3910.78230, mean: -1.99530
[32m[0907 01-25-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08742, current rewards: -4010.78230, mean: -1.99541
[32m[0907 01-25-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08747, current rewards: -4110.78230, mean: -1.99553
[32m[0907 01-25-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08752, current rewards: -4210.78230, mean: -1.99563
[32m[0907 01-25-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08757, current rewards: -4310.78230, mean: -1.99573
[32m[0907 01-25-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08762, current rewards: -4410.78230, mean: -1.99583
[32m[0907 01-25-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08764, current rewards: -4510.78230, mean: -1.99592
[32m[0907 01-25-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08762, current rewards: -4610.78230, mean: -1.99601
[32m[0907 01-25-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08760, current rewards: -4710.78230, mean: -1.99609
[32m[0907 01-25-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08758, current rewards: -4810.78230, mean: -1.99618
[32m[0907 01-25-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08757, current rewards: -4910.78230, mean: -1.99625
[32m[0907 01-25-43 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0907 01-25-43 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-25-44 @MBExp.py:227][0m Rewards obtained: [-4990.782297932882], Lows: [2493], Highs: [5], Total time: 29117.032294
[32m[0907 01-29-10 @MBExp.py:144][0m ####################################################################
[32m[0907 01-29-10 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 01-29-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11508, current rewards: -9.50950, mean: -0.95095
[32m[0907 01-29-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09186, current rewards: -7.79819, mean: -0.12997
[32m[0907 01-29-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08973, current rewards: -2.58425, mean: -0.02349
[32m[0907 01-29-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08887, current rewards: 2.31916, mean: 0.01449
[32m[0907 01-29-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08851, current rewards: 9.17678, mean: 0.04370
[32m[0907 01-29-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08827, current rewards: 16.02695, mean: 0.06164
[32m[0907 01-29-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08807, current rewards: 22.87679, mean: 0.07380
[32m[0907 01-29-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08789, current rewards: 29.72758, mean: 0.08258
[32m[0907 01-29-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08779, current rewards: 36.57169, mean: 0.08920
[32m[0907 01-29-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08773, current rewards: 41.15156, mean: 0.08946
[32m[0907 01-29-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08764, current rewards: 42.61105, mean: 0.08355
[32m[0907 01-29-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08756, current rewards: 48.20121, mean: 0.08607
[32m[0907 01-30-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08748, current rewards: 53.71779, mean: 0.08806
[32m[0907 01-30-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08746, current rewards: 59.23016, mean: 0.08974
[32m[0907 01-30-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08742, current rewards: 64.74637, mean: 0.09119
[32m[0907 01-30-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08741, current rewards: 70.26534, mean: 0.09245
[32m[0907 01-30-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08739, current rewards: 75.78162, mean: 0.09356
[32m[0907 01-30-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08738, current rewards: 81.29277, mean: 0.09453
[32m[0907 01-30-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08737, current rewards: 86.80995, mean: 0.09540
[32m[0907 01-30-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08735, current rewards: 92.83351, mean: 0.09670
[32m[0907 01-30-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08734, current rewards: 99.09284, mean: 0.09811
[32m[0907 01-30-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08731, current rewards: 104.58844, mean: 0.09867
[32m[0907 01-30-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08730, current rewards: 110.08241, mean: 0.09917
[32m[0907 01-30-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08727, current rewards: 115.57853, mean: 0.09964
[32m[0907 01-30-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08726, current rewards: 110.30146, mean: 0.09116
[32m[0907 01-31-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08725, current rewards: 108.22590, mean: 0.08589
[32m[0907 01-31-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08723, current rewards: 108.43734, mean: 0.08278
[32m[0907 01-31-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08715, current rewards: 107.60798, mean: 0.07912
[32m[0907 01-31-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08707, current rewards: 101.66779, mean: 0.07210
[32m[0907 01-31-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08697, current rewards: 105.55618, mean: 0.07230
[32m[0907 01-31-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08690, current rewards: 111.39362, mean: 0.07377
[32m[0907 01-31-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08695, current rewards: 97.59215, mean: 0.06256
[32m[0907 01-31-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08702, current rewards: 102.96304, mean: 0.06395
[32m[0907 01-31-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08710, current rewards: 108.37356, mean: 0.06529
[32m[0907 01-31-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08718, current rewards: 113.78290, mean: 0.06654
[32m[0907 01-31-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08725, current rewards: 119.18936, mean: 0.06772
[32m[0907 01-31-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08732, current rewards: 125.01370, mean: 0.06907
[32m[0907 01-31-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08738, current rewards: 130.11068, mean: 0.06995
[32m[0907 01-31-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08744, current rewards: 135.57060, mean: 0.07098
[32m[0907 01-32-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08749, current rewards: 141.03248, mean: 0.07196
[32m[0907 01-32-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08755, current rewards: 146.50575, mean: 0.07289
[32m[0907 01-32-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08761, current rewards: 151.97035, mean: 0.07377
[32m[0907 01-32-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08767, current rewards: 157.42876, mean: 0.07461
[32m[0907 01-32-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08772, current rewards: 162.88550, mean: 0.07541
[32m[0907 01-32-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08775, current rewards: 164.07844, mean: 0.07424
[32m[0907 01-32-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08780, current rewards: 169.79142, mean: 0.07513
[32m[0907 01-32-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08783, current rewards: 175.29740, mean: 0.07589
[32m[0907 01-32-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08787, current rewards: 180.79868, mean: 0.07661
[32m[0907 01-32-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08785, current rewards: 186.30857, mean: 0.07731
[32m[0907 01-32-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08783, current rewards: 191.81565, mean: 0.07797
[32m[0907 01-32-50 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0907 01-32-50 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-32-50 @MBExp.py:227][0m Rewards obtained: [196.22379173392997], Lows: [15], Highs: [45], Total time: 29337.338254000002
[32m[0907 01-36-19 @MBExp.py:144][0m ####################################################################
[32m[0907 01-36-19 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 01-36-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08679, current rewards: -7.88882, mean: -0.78888
[32m[0907 01-36-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08802, current rewards: -22.06096, mean: -0.36768
[32m[0907 01-36-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08752, current rewards: -16.39701, mean: -0.14906
[32m[0907 01-36-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08710, current rewards: -10.72761, mean: -0.06705
[32m[0907 01-36-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08705, current rewards: -5.03359, mean: -0.02397
[32m[0907 01-36-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08712, current rewards: 0.66341, mean: 0.00255
[32m[0907 01-36-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08711, current rewards: 6.36415, mean: 0.02053
[32m[0907 01-36-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08712, current rewards: 12.05738, mean: 0.03349
[32m[0907 01-36-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08710, current rewards: 17.75511, mean: 0.04331
[32m[0907 01-36-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08709, current rewards: 23.45413, mean: 0.05099
[32m[0907 01-37-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08708, current rewards: 23.62106, mean: 0.04632
[32m[0907 01-37-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08708, current rewards: 29.94833, mean: 0.05348
[32m[0907 01-37-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08706, current rewards: 36.52145, mean: 0.05987
[32m[0907 01-37-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08705, current rewards: 43.10452, mean: 0.06531
[32m[0907 01-37-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08704, current rewards: 49.69433, mean: 0.06999
[32m[0907 01-37-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08703, current rewards: 56.28058, mean: 0.07405
[32m[0907 01-37-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08704, current rewards: 52.83947, mean: 0.06523
[32m[0907 01-37-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08704, current rewards: 58.45671, mean: 0.06797
[32m[0907 01-37-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08704, current rewards: 64.07497, mean: 0.07041
[32m[0907 01-37-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08704, current rewards: 69.34387, mean: 0.07223
[32m[0907 01-37-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08703, current rewards: 74.97056, mean: 0.07423
[32m[0907 01-37-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08703, current rewards: 80.59202, mean: 0.07603
[32m[0907 01-37-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08702, current rewards: 86.21389, mean: 0.07767
[32m[0907 01-38-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08701, current rewards: 91.83491, mean: 0.07917
[32m[0907 01-38-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08701, current rewards: 97.46073, mean: 0.08055
[32m[0907 01-38-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08699, current rewards: 103.08601, mean: 0.08181
[32m[0907 01-38-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08698, current rewards: 108.70858, mean: 0.08298
[32m[0907 01-38-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08687, current rewards: 115.28590, mean: 0.08477
[32m[0907 01-38-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08678, current rewards: 120.88403, mean: 0.08573
[32m[0907 01-38-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08670, current rewards: 126.48115, mean: 0.08663
[32m[0907 01-38-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08663, current rewards: 132.08135, mean: 0.08747
[32m[0907 01-38-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08660, current rewards: 131.88738, mean: 0.08454
[32m[0907 01-38-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08665, current rewards: 137.36871, mean: 0.08532
[32m[0907 01-38-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08673, current rewards: 142.85074, mean: 0.08605
[32m[0907 01-38-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08681, current rewards: 148.33248, mean: 0.08674
[32m[0907 01-38-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08690, current rewards: 153.81529, mean: 0.08740
[32m[0907 01-38-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08697, current rewards: 159.29832, mean: 0.08801
[32m[0907 01-39-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08704, current rewards: 164.78145, mean: 0.08859
[32m[0907 01-39-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08710, current rewards: 170.26276, mean: 0.08914
[32m[0907 01-39-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08716, current rewards: 175.74138, mean: 0.08966
[32m[0907 01-39-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08720, current rewards: 181.22045, mean: 0.09016
[32m[0907 01-39-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08725, current rewards: 180.97288, mean: 0.08785
[32m[0907 01-39-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08731, current rewards: 186.76191, mean: 0.08851
[32m[0907 01-39-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08735, current rewards: 192.18172, mean: 0.08897
[32m[0907 01-39-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08740, current rewards: 198.00611, mean: 0.08960
[32m[0907 01-39-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08744, current rewards: 203.84227, mean: 0.09020
[32m[0907 01-39-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08748, current rewards: 209.67975, mean: 0.09077
[32m[0907 01-39-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08752, current rewards: 215.51686, mean: 0.09132
[32m[0907 01-39-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08752, current rewards: 221.34735, mean: 0.09185
[32m[0907 01-39-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08750, current rewards: 227.18310, mean: 0.09235
[32m[0907 01-39-58 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0907 01-39-58 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-39-58 @MBExp.py:227][0m Rewards obtained: [231.85012791357838], Lows: [5], Highs: [40], Total time: 29556.847843000003
[32m[0907 01-43-28 @MBExp.py:144][0m ####################################################################
[32m[0907 01-43-28 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 01-43-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10050, current rewards: -6.54961, mean: -0.65496
[32m[0907 01-43-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09554, current rewards: -58.87207, mean: -0.98120
[32m[0907 01-43-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09291, current rewards: -111.88087, mean: -1.01710
[32m[0907 01-43-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09346, current rewards: -172.46274, mean: -1.07789
[32m[0907 01-43-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09257, current rewards: -210.88623, mean: -1.00422
[32m[0907 01-43-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09232, current rewards: -265.08267, mean: -1.01955
[32m[0907 01-43-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09267, current rewards: -311.47632, mean: -1.00476
[32m[0907 01-44-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09279, current rewards: -367.62428, mean: -1.02118
[32m[0907 01-44-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09317, current rewards: -430.06200, mean: -1.04893
[32m[0907 01-44-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09334, current rewards: -480.49652, mean: -1.04456
[32m[0907 01-44-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09319, current rewards: -528.31747, mean: -1.03592
[32m[0907 01-44-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09280, current rewards: -562.99771, mean: -1.00535
[32m[0907 01-44-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09264, current rewards: -628.99751, mean: -1.03114
[32m[0907 01-44-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09222, current rewards: -633.48804, mean: -0.95983
[32m[0907 01-44-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09184, current rewards: -627.77753, mean: -0.88419
[32m[0907 01-44-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09167, current rewards: -655.40476, mean: -0.86237
[32m[0907 01-44-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09139, current rewards: -755.40476, mean: -0.93260
[32m[0907 01-44-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09114, current rewards: -855.40476, mean: -0.99466
[32m[0907 01-44-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09091, current rewards: -955.40476, mean: -1.04990
[32m[0907 01-44-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09070, current rewards: -1055.40476, mean: -1.09938
[32m[0907 01-45-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09051, current rewards: -1155.40476, mean: -1.14397
[32m[0907 01-45-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09033, current rewards: -1255.40476, mean: -1.18434
[32m[0907 01-45-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09017, current rewards: -1355.40476, mean: -1.22109
[32m[0907 01-45-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09004, current rewards: -1455.40476, mean: -1.25466
[32m[0907 01-45-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08990, current rewards: -1555.40476, mean: -1.28546
[32m[0907 01-45-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08978, current rewards: -1655.40476, mean: -1.31381
[32m[0907 01-45-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08967, current rewards: -1755.40476, mean: -1.34000
[32m[0907 01-45-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08957, current rewards: -1855.40476, mean: -1.36427
[32m[0907 01-45-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08949, current rewards: -1955.40476, mean: -1.38681
[32m[0907 01-45-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08942, current rewards: -2055.40476, mean: -1.40781
[32m[0907 01-45-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08934, current rewards: -2155.40476, mean: -1.42742
[32m[0907 01-45-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08929, current rewards: -2255.40476, mean: -1.44577
[32m[0907 01-45-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08938, current rewards: -2355.40476, mean: -1.46298
[32m[0907 01-45-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08942, current rewards: -2455.40476, mean: -1.47916
[32m[0907 01-46-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08942, current rewards: -2555.40476, mean: -1.49439
[32m[0907 01-46-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08942, current rewards: -2655.40476, mean: -1.50875
[32m[0907 01-46-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08942, current rewards: -2755.40476, mean: -1.52232
[32m[0907 01-46-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08942, current rewards: -2855.40476, mean: -1.53516
[32m[0907 01-46-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08942, current rewards: -2955.40476, mean: -1.54733
[32m[0907 01-46-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08943, current rewards: -3055.40476, mean: -1.55888
[32m[0907 01-46-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08943, current rewards: -3155.40476, mean: -1.56985
[32m[0907 01-46-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08943, current rewards: -3255.40476, mean: -1.58029
[32m[0907 01-46-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08943, current rewards: -3355.40476, mean: -1.59024
[32m[0907 01-46-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08942, current rewards: -3455.40476, mean: -1.59972
[32m[0907 01-46-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08942, current rewards: -3555.40476, mean: -1.60878
[32m[0907 01-46-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08942, current rewards: -3655.40476, mean: -1.61744
[32m[0907 01-46-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08942, current rewards: -3755.40476, mean: -1.62572
[32m[0907 01-47-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08941, current rewards: -3855.40476, mean: -1.63365
[32m[0907 01-47-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08935, current rewards: -3955.40476, mean: -1.64125
[32m[0907 01-47-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08930, current rewards: -4055.40476, mean: -1.64854
[32m[0907 01-47-12 @Agent.py:117][0m Average action selection time: 0.0893
[32m[0907 01-47-12 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-47-12 @MBExp.py:227][0m Rewards obtained: [-4135.404763847165], Lows: [2082], Highs: [36], Total time: 29780.778972000004
[32m[0907 01-50-44 @MBExp.py:144][0m ####################################################################
[32m[0907 01-50-44 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 01-50-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09206, current rewards: -2.91949, mean: -0.29195
[32m[0907 01-50-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08781, current rewards: 3.06678, mean: 0.05111
[32m[0907 01-50-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08725, current rewards: -35.29077, mean: -0.32083
[32m[0907 01-50-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08727, current rewards: -85.29077, mean: -0.53307
[32m[0907 01-51-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08720, current rewards: -135.29077, mean: -0.64424
[32m[0907 01-51-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08717, current rewards: -185.29077, mean: -0.71266
[32m[0907 01-51-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08717, current rewards: -235.29077, mean: -0.75900
[32m[0907 01-51-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08714, current rewards: -285.29077, mean: -0.79247
[32m[0907 01-51-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08712, current rewards: -335.29077, mean: -0.81778
[32m[0907 01-51-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08710, current rewards: -385.29077, mean: -0.83759
[32m[0907 01-51-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08709, current rewards: -399.09522, mean: -0.78254
[32m[0907 01-51-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08708, current rewards: -395.71255, mean: -0.70663
[32m[0907 01-51-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08708, current rewards: -392.32987, mean: -0.64316
[32m[0907 01-51-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08707, current rewards: -434.85630, mean: -0.65887
[32m[0907 01-51-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08705, current rewards: -484.85630, mean: -0.68290
[32m[0907 01-51-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08705, current rewards: -534.85630, mean: -0.70376
[32m[0907 01-51-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08704, current rewards: -584.85630, mean: -0.72204
[32m[0907 01-51-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08704, current rewards: -634.85630, mean: -0.73820
[32m[0907 01-52-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08704, current rewards: -684.85630, mean: -0.75259
[32m[0907 01-52-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08704, current rewards: -734.85630, mean: -0.76548
[32m[0907 01-52-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08703, current rewards: -784.85630, mean: -0.77709
[32m[0907 01-52-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08701, current rewards: -834.85630, mean: -0.78760
[32m[0907 01-52-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08700, current rewards: -884.85630, mean: -0.79717
[32m[0907 01-52-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08699, current rewards: -934.85630, mean: -0.80591
[32m[0907 01-52-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08699, current rewards: -984.85630, mean: -0.81393
[32m[0907 01-52-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08698, current rewards: -1034.85630, mean: -0.82131
[32m[0907 01-52-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08697, current rewards: -1084.85630, mean: -0.82813
[32m[0907 01-52-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08696, current rewards: -1134.85630, mean: -0.83445
[32m[0907 01-52-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08696, current rewards: -1184.85630, mean: -0.84032
[32m[0907 01-52-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08695, current rewards: -1234.85630, mean: -0.84579
[32m[0907 01-52-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08696, current rewards: -1284.85630, mean: -0.85090
[32m[0907 01-53-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08699, current rewards: -1334.85630, mean: -0.85568
[32m[0907 01-53-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08714, current rewards: -1384.85630, mean: -0.86016
[32m[0907 01-53-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08721, current rewards: -1434.85630, mean: -0.86437
[32m[0907 01-53-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08727, current rewards: -1484.85630, mean: -0.86834
[32m[0907 01-53-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08733, current rewards: -1534.85630, mean: -0.87208
[32m[0907 01-53-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08739, current rewards: -1584.85630, mean: -0.87561
[32m[0907 01-53-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08744, current rewards: -1634.85630, mean: -0.87895
[32m[0907 01-53-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08750, current rewards: -1684.85630, mean: -0.88212
[32m[0907 01-53-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08754, current rewards: -1734.85630, mean: -0.88513
[32m[0907 01-53-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08758, current rewards: -1784.85630, mean: -0.88799
[32m[0907 01-53-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08762, current rewards: -1834.85630, mean: -0.89071
[32m[0907 01-53-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08766, current rewards: -1884.85630, mean: -0.89330
[32m[0907 01-53-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08769, current rewards: -1934.85630, mean: -0.89577
[32m[0907 01-53-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08774, current rewards: -1984.85630, mean: -0.89813
[32m[0907 01-54-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08777, current rewards: -2034.85630, mean: -0.90038
[32m[0907 01-54-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08781, current rewards: -2084.85630, mean: -0.90254
[32m[0907 01-54-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08785, current rewards: -2134.85630, mean: -0.90460
[32m[0907 01-54-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08787, current rewards: -2184.85630, mean: -0.90658
[32m[0907 01-54-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08786, current rewards: -2234.85630, mean: -0.90848
[32m[0907 01-54-24 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0907 01-54-24 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-54-24 @MBExp.py:227][0m Rewards obtained: [-2274.8562977496613], Lows: [2], Highs: [2288], Total time: 30001.138072000005
[32m[0907 01-57-58 @MBExp.py:144][0m ####################################################################
[32m[0907 01-57-58 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 01-57-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08602, current rewards: -6.78253, mean: -0.67825
[32m[0907 01-58-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08655, current rewards: -50.38031, mean: -0.83967
[32m[0907 01-58-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08674, current rewards: -100.38031, mean: -0.91255
[32m[0907 01-58-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08677, current rewards: -150.38031, mean: -0.93988
[32m[0907 01-58-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08687, current rewards: -200.38031, mean: -0.95419
[32m[0907 01-58-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08688, current rewards: -250.38031, mean: -0.96300
[32m[0907 01-58-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08689, current rewards: -300.38031, mean: -0.96897
[32m[0907 01-58-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08685, current rewards: -350.38031, mean: -0.97328
[32m[0907 01-58-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08685, current rewards: -400.38031, mean: -0.97654
[32m[0907 01-58-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08684, current rewards: -450.38031, mean: -0.97909
[32m[0907 01-58-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08686, current rewards: -500.38031, mean: -0.98114
[32m[0907 01-58-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08685, current rewards: -550.38031, mean: -0.98282
[32m[0907 01-58-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08685, current rewards: -600.38031, mean: -0.98423
[32m[0907 01-58-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08685, current rewards: -650.38031, mean: -0.98542
[32m[0907 01-58-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08685, current rewards: -700.38031, mean: -0.98645
[32m[0907 01-59-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08684, current rewards: -750.38031, mean: -0.98734
[32m[0907 01-59-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08687, current rewards: -800.38031, mean: -0.98812
[32m[0907 01-59-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08687, current rewards: -850.38031, mean: -0.98881
[32m[0907 01-59-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08687, current rewards: -900.38031, mean: -0.98943
[32m[0907 01-59-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08686, current rewards: -950.38031, mean: -0.98998
[32m[0907 01-59-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08686, current rewards: -1000.38031, mean: -0.99048
[32m[0907 01-59-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08684, current rewards: -1050.38031, mean: -0.99092
[32m[0907 01-59-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08682, current rewards: -1100.38031, mean: -0.99133
[32m[0907 01-59-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08682, current rewards: -1150.38031, mean: -0.99171
[32m[0907 01-59-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08682, current rewards: -1200.38031, mean: -0.99205
[32m[0907 01-59-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08681, current rewards: -1250.38031, mean: -0.99237
[32m[0907 01-59-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08681, current rewards: -1300.38031, mean: -0.99266
[32m[0907 01-59-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08681, current rewards: -1350.38031, mean: -0.99293
[32m[0907 02-00-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08682, current rewards: -1400.38031, mean: -0.99318
[32m[0907 02-00-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08683, current rewards: -1450.38031, mean: -0.99341
[32m[0907 02-00-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08682, current rewards: -1500.38031, mean: -0.99363
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08686, current rewards: -1550.38031, mean: -0.99383
[32m[0907 02-00-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08693, current rewards: -1583.08702, mean: -0.98328
[32m[0907 02-00-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08702, current rewards: -1579.15545, mean: -0.95130
[32m[0907 02-00-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08717, current rewards: -1575.46820, mean: -0.92133
[32m[0907 02-00-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08727, current rewards: -1571.78096, mean: -0.89306
[32m[0907 02-00-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08732, current rewards: -1568.09371, mean: -0.86635
[32m[0907 02-00-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08738, current rewards: -1564.40647, mean: -0.84108
[32m[0907 02-00-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08744, current rewards: -1585.41536, mean: -0.83006
[32m[0907 02-00-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08749, current rewards: -1635.41536, mean: -0.83440
[32m[0907 02-00-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08753, current rewards: -1685.41536, mean: -0.83852
[32m[0907 02-00-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08758, current rewards: -1735.41536, mean: -0.84243
[32m[0907 02-01-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08762, current rewards: -1785.41536, mean: -0.84617
[32m[0907 02-01-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08767, current rewards: -1835.41536, mean: -0.84973
[32m[0907 02-01-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08772, current rewards: -1885.41536, mean: -0.85313
[32m[0907 02-01-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08776, current rewards: -1935.41536, mean: -0.85638
[32m[0907 02-01-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08779, current rewards: -1985.41536, mean: -0.85949
[32m[0907 02-01-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08782, current rewards: -2035.41536, mean: -0.86246
[32m[0907 02-01-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08785, current rewards: -2085.41536, mean: -0.86532
[32m[0907 02-01-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08786, current rewards: -2135.41536, mean: -0.86806
[32m[0907 02-01-38 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0907 02-01-38 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-01-38 @MBExp.py:227][0m Rewards obtained: [-2175.415355178473], Lows: [1], Highs: [2196], Total time: 30221.513365000006
[32m[0907 02-05-13 @MBExp.py:144][0m ####################################################################
[32m[0907 02-05-13 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 02-05-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10366, current rewards: -8.01367, mean: -0.80137
[32m[0907 02-05-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11948, current rewards: -59.20520, mean: -0.98675
[32m[0907 02-05-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.12419, current rewards: -115.21550, mean: -1.04741
[32m[0907 02-05-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.12185, current rewards: -138.88178, mean: -0.86801
[32m[0907 02-05-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11796, current rewards: -198.23994, mean: -0.94400
[32m[0907 02-05-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11542, current rewards: -252.06707, mean: -0.96949
[32m[0907 02-05-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11484, current rewards: -293.58801, mean: -0.94706
[32m[0907 02-05-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11390, current rewards: -318.25848, mean: -0.88405
[32m[0907 02-05-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11432, current rewards: -347.70268, mean: -0.84806
[32m[0907 02-06-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11291, current rewards: -390.03506, mean: -0.84790
[32m[0907 02-06-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11243, current rewards: -443.76357, mean: -0.87012
[32m[0907 02-06-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11092, current rewards: -499.85644, mean: -0.89260
[32m[0907 02-06-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11025, current rewards: -537.33709, mean: -0.88088
[32m[0907 02-06-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10849, current rewards: -531.05948, mean: -0.80464
[32m[0907 02-06-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10698, current rewards: -524.77658, mean: -0.73912
[32m[0907 02-06-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10569, current rewards: -518.49177, mean: -0.68223
[32m[0907 02-06-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10453, current rewards: -512.20175, mean: -0.63235
[32m[0907 02-06-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10352, current rewards: -505.68539, mean: -0.58801
[32m[0907 02-06-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10270, current rewards: -529.40716, mean: -0.58177
[32m[0907 02-06-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10188, current rewards: -528.89632, mean: -0.55093
[32m[0907 02-06-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10114, current rewards: -523.07057, mean: -0.51789
[32m[0907 02-06-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10048, current rewards: -517.24258, mean: -0.48796
[32m[0907 02-07-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09989, current rewards: -511.41262, mean: -0.46073
[32m[0907 02-07-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09933, current rewards: -505.59005, mean: -0.43585
[32m[0907 02-07-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09887, current rewards: -505.34554, mean: -0.41764
[32m[0907 02-07-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09861, current rewards: -552.00458, mean: -0.43810
[32m[0907 02-07-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09818, current rewards: -541.42092, mean: -0.41330
[32m[0907 02-07-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09778, current rewards: -528.43664, mean: -0.38856
[32m[0907 02-07-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09789, current rewards: -567.24561, mean: -0.40230
[32m[0907 02-07-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09777, current rewards: -626.23211, mean: -0.42893
[32m[0907 02-07-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09758, current rewards: -681.90244, mean: -0.45159
[32m[0907 02-07-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09763, current rewards: -748.36705, mean: -0.47972
[32m[0907 02-07-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09758, current rewards: -800.10142, mean: -0.49696
[32m[0907 02-07-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09746, current rewards: -806.63065, mean: -0.48592
[32m[0907 02-07-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09724, current rewards: -797.96966, mean: -0.46665
[32m[0907 02-08-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09703, current rewards: -789.31912, mean: -0.44848
[32m[0907 02-08-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09682, current rewards: -780.64469, mean: -0.43130
[32m[0907 02-08-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09663, current rewards: -771.96718, mean: -0.41504
[32m[0907 02-08-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09644, current rewards: -763.29810, mean: -0.39963
[32m[0907 02-08-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09626, current rewards: -774.84449, mean: -0.39533
[32m[0907 02-08-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09638, current rewards: -808.84630, mean: -0.40241
[32m[0907 02-08-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09627, current rewards: -849.91457, mean: -0.41258
[32m[0907 02-08-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09654, current rewards: -908.76498, mean: -0.43069
[32m[0907 02-08-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09670, current rewards: -975.66922, mean: -0.45170
[32m[0907 02-08-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09670, current rewards: -1029.22206, mean: -0.46571
[32m[0907 02-08-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09687, current rewards: -1051.66507, mean: -0.46534
[32m[0907 02-08-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09701, current rewards: -1073.66748, mean: -0.46479
[32m[0907 02-09-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09699, current rewards: -1097.39556, mean: -0.46500
[32m[0907 02-09-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09684, current rewards: -1128.45647, mean: -0.46824
[32m[0907 02-09-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09688, current rewards: -1175.86765, mean: -0.47799
[32m[0907 02-09-15 @Agent.py:117][0m Average action selection time: 0.0969
[32m[0907 02-09-15 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-09-16 @MBExp.py:227][0m Rewards obtained: [-1235.4765242286742], Lows: [588], Highs: [324], Total time: 30464.562141000006
[32m[0907 02-12-32 @MBExp.py:144][0m ####################################################################
[32m[0907 02-12-32 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 02-12-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.07076, current rewards: -5.92547, mean: -0.59255
[32m[0907 02-12-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.07182, current rewards: -7.07415, mean: -0.11790
[32m[0907 02-12-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.07192, current rewards: 0.85654, mean: 0.00779
[32m[0907 02-12-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.07198, current rewards: 8.54553, mean: 0.05341
[32m[0907 02-12-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.07194, current rewards: 16.29845, mean: 0.07761
[32m[0907 02-12-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.07194, current rewards: 24.65159, mean: 0.09481
[32m[0907 02-12-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.07227, current rewards: 14.92668, mean: 0.04815
[32m[0907 02-12-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.07223, current rewards: 18.50742, mean: 0.05141
[32m[0907 02-13-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.07222, current rewards: -12.34053, mean: -0.03010
[32m[0907 02-13-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.07221, current rewards: -62.34053, mean: -0.13552
[32m[0907 02-13-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.07219, current rewards: -112.34053, mean: -0.22028
[32m[0907 02-13-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.07217, current rewards: -162.34053, mean: -0.28989
[32m[0907 02-13-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.07213, current rewards: -212.34053, mean: -0.34810
[32m[0907 02-13-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.07210, current rewards: -262.34053, mean: -0.39749
[32m[0907 02-13-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.07208, current rewards: -312.34053, mean: -0.43992
[32m[0907 02-13-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.07206, current rewards: -362.34053, mean: -0.47676
[32m[0907 02-13-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.07206, current rewards: -394.24067, mean: -0.48672
[32m[0907 02-13-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.07205, current rewards: -390.49814, mean: -0.45407
[32m[0907 02-13-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.07202, current rewards: -386.75560, mean: -0.42501
[32m[0907 02-13-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.07202, current rewards: -433.53105, mean: -0.45159
[32m[0907 02-13-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.07200, current rewards: -483.53105, mean: -0.47874
[32m[0907 02-13-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.07200, current rewards: -533.53105, mean: -0.50333
[32m[0907 02-13-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.07201, current rewards: -583.53105, mean: -0.52570
[32m[0907 02-13-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.07200, current rewards: -633.53105, mean: -0.54615
[32m[0907 02-13-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.07200, current rewards: -683.53105, mean: -0.56490
[32m[0907 02-14-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.07201, current rewards: -733.53105, mean: -0.58217
[32m[0907 02-14-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.07200, current rewards: -783.53105, mean: -0.59812
[32m[0907 02-14-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.07200, current rewards: -833.53105, mean: -0.61289
[32m[0907 02-14-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.07200, current rewards: -883.53105, mean: -0.62662
[32m[0907 02-14-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.07199, current rewards: -933.53105, mean: -0.63940
[32m[0907 02-14-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.07180, current rewards: -983.53105, mean: -0.65135
[32m[0907 02-14-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.07147, current rewards: -1033.53105, mean: -0.66252
[32m[0907 02-14-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.07116, current rewards: -1083.53105, mean: -0.67300
[32m[0907 02-14-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.07088, current rewards: -1133.53105, mean: -0.68285
[32m[0907 02-14-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.07061, current rewards: -1183.53105, mean: -0.69212
[32m[0907 02-14-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.07036, current rewards: -1233.53105, mean: -0.70087
[32m[0907 02-14-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.07013, current rewards: -1283.53105, mean: -0.70913
[32m[0907 02-14-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.06991, current rewards: -1333.53105, mean: -0.71695
[32m[0907 02-14-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.06969, current rewards: -1383.53105, mean: -0.72436
[32m[0907 02-14-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.06948, current rewards: -1433.53105, mean: -0.73139
[32m[0907 02-14-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.06929, current rewards: -1483.53105, mean: -0.73808
[32m[0907 02-14-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.06910, current rewards: -1533.53105, mean: -0.74443
[32m[0907 02-14-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.06892, current rewards: -1583.53105, mean: -0.75049
[32m[0907 02-15-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.06874, current rewards: -1633.53105, mean: -0.75626
[32m[0907 02-15-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.06853, current rewards: -1683.53105, mean: -0.76178
[32m[0907 02-15-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.06814, current rewards: -1733.53105, mean: -0.76705
[32m[0907 02-15-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.06775, current rewards: -1783.53105, mean: -0.77209
[32m[0907 02-15-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.06737, current rewards: -1833.53105, mean: -0.77692
[32m[0907 02-15-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.06702, current rewards: -1883.53105, mean: -0.78155
[32m[0907 02-15-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.06667, current rewards: -1933.53105, mean: -0.78599
[32m[0907 02-15-18 @Agent.py:117][0m Average action selection time: 0.0664
[32m[0907 02-15-18 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-15-18 @MBExp.py:227][0m Rewards obtained: [-1973.5310512634974], Lows: [12], Highs: [2007], Total time: 30631.172792000005
