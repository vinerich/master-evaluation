[32m[0906 13-39-53 @logger.py:99][0m Log file set to /app/logs/dats-delay-5/zinc-coating-v0_1/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-53 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -12.91939, mean: -1.29194
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -72.33200, mean: -1.20553
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -123.93262, mean: -1.12666
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -180.87901, mean: -1.13049
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -229.84519, mean: -1.09450
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -292.52211, mean: -1.12509
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -357.28990, mean: -1.15255
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -407.49066, mean: -1.13192
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -466.67048, mean: -1.13822
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -522.27718, mean: -1.13539
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -585.13605, mean: -1.14733
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -632.42785, mean: -1.12934
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -690.29682, mean: -1.13163
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -751.50736, mean: -1.13865
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -799.92441, mean: -1.12665
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -848.64956, mean: -1.11664
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -895.49609, mean: -1.10555
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -948.25225, mean: -1.10262
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1003.08964, mean: -1.10230
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1056.67150, mean: -1.10070
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1105.65567, mean: -1.09471
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1160.05650, mean: -1.09439
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1235.85559, mean: -1.11338
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1327.37436, mean: -1.14429
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1413.44122, mean: -1.16813
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1491.09711, mean: -1.18341
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1560.79883, mean: -1.19145
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1625.69865, mean: -1.19537
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1679.51641, mean: -1.19115
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1739.45067, mean: -1.19140
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1799.17346, mean: -1.19151
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1858.98422, mean: -1.19166
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1924.56390, mean: -1.19538
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1976.87973, mean: -1.19089
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2023.83372, mean: -1.18353
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2080.01885, mean: -1.18183
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2127.29568, mean: -1.17530
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2174.27404, mean: -1.16896
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2225.60103, mean: -1.16524
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2271.77000, mean: -1.15907
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2314.88857, mean: -1.15169
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2368.82559, mean: -1.14992
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2424.11154, mean: -1.14887
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2477.90982, mean: -1.14718
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2526.41620, mean: -1.14317
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2581.36667, mean: -1.14220
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2625.09757, mean: -1.13641
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2683.51647, mean: -1.13708
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2739.60730, mean: -1.13677
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2800.10146, mean: -1.13825
[32m[0906 13-39-53 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-39-55 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-55 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08667, current rewards: -5.66225, mean: -0.56622
[32m[0906 13-40-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.07636, current rewards: -0.60817, mean: -0.01014
[32m[0906 13-40-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.07521, current rewards: 4.40830, mean: 0.04008
[32m[0906 13-40-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.07517, current rewards: 9.42565, mean: 0.05891
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.07500, current rewards: 14.44230, mean: 0.06877
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.07659, current rewards: 19.46081, mean: 0.07485
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.07808, current rewards: 24.47809, mean: 0.07896
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.07912, current rewards: 29.49495, mean: 0.08193
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08006, current rewards: 34.51301, mean: 0.08418
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08076, current rewards: 40.17139, mean: 0.08733
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08221, current rewards: 45.85635, mean: 0.08991
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08369, current rewards: 46.93197, mean: 0.08381
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08497, current rewards: 53.93979, mean: 0.08843
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08599, current rewards: 60.95795, mean: 0.09236
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08686, current rewards: 67.97653, mean: 0.09574
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08766, current rewards: 74.99466, mean: 0.09868
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08835, current rewards: 82.01253, mean: 0.10125
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08895, current rewards: 80.97722, mean: 0.09416
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08947, current rewards: 85.89383, mean: 0.09439
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09010, current rewards: 90.81112, mean: 0.09459
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09086, current rewards: 95.72088, mean: 0.09477
[32m[0906 13-41-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09191, current rewards: 100.63753, mean: 0.09494
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09292, current rewards: 105.54349, mean: 0.09508
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09381, current rewards: 110.46158, mean: 0.09523
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09461, current rewards: 115.37241, mean: 0.09535
[32m[0906 13-41-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09536, current rewards: 123.10216, mean: 0.09770
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09603, current rewards: 133.63417, mean: 0.10201
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09666, current rewards: 144.16434, mean: 0.10600
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09723, current rewards: 154.71151, mean: 0.10972
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09776, current rewards: 149.29788, mean: 0.10226
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09830, current rewards: 154.25622, mean: 0.10216
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09876, current rewards: 159.20781, mean: 0.10206
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09918, current rewards: 164.16224, mean: 0.10196
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09961, current rewards: 162.82320, mean: 0.09809
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10001, current rewards: 180.32242, mean: 0.10545
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10036, current rewards: 197.86675, mean: 0.11242
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10070, current rewards: 215.43792, mean: 0.11903
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10093, current rewards: 232.98556, mean: 0.12526
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10123, current rewards: 250.53424, mean: 0.13117
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10154, current rewards: 268.12081, mean: 0.13680
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10180, current rewards: 285.69538, mean: 0.14214
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10206, current rewards: 292.17873, mean: 0.14183
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10231, current rewards: 295.94708, mean: 0.14026
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10256, current rewards: 299.63712, mean: 0.13872
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10280, current rewards: 303.32925, mean: 0.13725
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10301, current rewards: 307.02515, mean: 0.13585
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10322, current rewards: 310.71580, mean: 0.13451
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10344, current rewards: 310.15880, mean: 0.13142
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10362, current rewards: 315.60667, mean: 0.13096
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10382, current rewards: 321.05671, mean: 0.13051
[32m[0906 13-44-16 @Agent.py:117][0m Average action selection time: 0.1040
[32m[0906 13-44-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-44-16 @MBExp.py:227][0m Rewards obtained: [324.89524193629177], Lows: [12], Highs: [28], Total time: 260.644179
[32m[0906 13-44-21 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-21 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11188, current rewards: -6.68299, mean: -0.66830
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11180, current rewards: -1.81521, mean: -0.03025
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11199, current rewards: 3.05002, mean: 0.02773
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11179, current rewards: 7.91659, mean: 0.04948
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11153, current rewards: 12.78807, mean: 0.06090
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11121, current rewards: 17.65745, mean: 0.06791
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11122, current rewards: 22.52122, mean: 0.07265
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11132, current rewards: 15.04329, mean: 0.04179
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11139, current rewards: 19.57390, mean: 0.04774
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11132, current rewards: 23.74674, mean: 0.05162
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11112, current rewards: 27.91957, mean: 0.05474
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11116, current rewards: 32.09241, mean: 0.05731
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11116, current rewards: 36.26524, mean: 0.05945
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11122, current rewards: 40.43808, mean: 0.06127
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11123, current rewards: 44.61091, mean: 0.06283
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11124, current rewards: 48.78375, mean: 0.06419
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11128, current rewards: 52.83825, mean: 0.06523
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11129, current rewards: 11.25192, mean: 0.01308
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11130, current rewards: -38.74808, mean: -0.04258
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11134, current rewards: -88.74808, mean: -0.09245
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11124, current rewards: -138.74808, mean: -0.13737
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11121, current rewards: -188.74808, mean: -0.17806
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11128, current rewards: -238.74808, mean: -0.21509
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11129, current rewards: -288.74808, mean: -0.24892
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11130, current rewards: -338.74808, mean: -0.27996
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11134, current rewards: -388.74808, mean: -0.30853
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11136, current rewards: -438.74808, mean: -0.33492
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11140, current rewards: -488.74808, mean: -0.35937
[32m[0906 13-46-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11140, current rewards: -538.74808, mean: -0.38209
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11140, current rewards: -588.74808, mean: -0.40325
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11142, current rewards: -638.74808, mean: -0.42301
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11142, current rewards: -688.74808, mean: -0.44151
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11142, current rewards: -738.74808, mean: -0.45885
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11145, current rewards: -788.74808, mean: -0.47515
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11149, current rewards: -838.74808, mean: -0.49050
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11152, current rewards: -888.74808, mean: -0.50497
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11150, current rewards: -938.74808, mean: -0.51865
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11142, current rewards: -988.74808, mean: -0.53158
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11140, current rewards: -1038.74808, mean: -0.54385
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11141, current rewards: -1088.74808, mean: -0.55548
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11140, current rewards: -1138.74808, mean: -0.56654
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11140, current rewards: -1188.74808, mean: -0.57706
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11141, current rewards: -1238.74808, mean: -0.58708
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11141, current rewards: -1288.74808, mean: -0.59664
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11143, current rewards: -1338.74808, mean: -0.60577
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11144, current rewards: -1388.74808, mean: -0.61449
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11146, current rewards: -1438.74808, mean: -0.62283
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11147, current rewards: -1488.74808, mean: -0.63083
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11148, current rewards: -1538.74808, mean: -0.63848
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11149, current rewards: -1588.74808, mean: -0.64583
[32m[0906 13-49-00 @Agent.py:117][0m Average action selection time: 0.1115
[32m[0906 13-49-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-49-00 @MBExp.py:227][0m Rewards obtained: [-1628.748076486611], Lows: [6], Highs: [1689], Total time: 540.120727
[32m[0906 13-49-08 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-08 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11324, current rewards: -5.25023, mean: -0.52502
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11264, current rewards: 4.69542, mean: 0.07826
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11260, current rewards: 14.68914, mean: 0.13354
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11240, current rewards: 24.68201, mean: 0.15426
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11183, current rewards: 34.66993, mean: 0.16509
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11133, current rewards: 44.64658, mean: 0.17172
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11136, current rewards: 54.65458, mean: 0.17631
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11148, current rewards: 64.64824, mean: 0.17958
[32m[0906 13-49-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11149, current rewards: 74.64052, mean: 0.18205
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11128, current rewards: 84.63468, mean: 0.18399
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11104, current rewards: 84.37263, mean: 0.16544
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11109, current rewards: 94.19307, mean: 0.16820
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11112, current rewards: 104.01653, mean: 0.17052
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11122, current rewards: 113.86057, mean: 0.17252
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11125, current rewards: 123.69317, mean: 0.17422
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11126, current rewards: 133.53138, mean: 0.17570
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11132, current rewards: 140.68320, mean: 0.17368
[32m[0906 13-50-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11129, current rewards: 146.52069, mean: 0.17037
[32m[0906 13-50-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11130, current rewards: 142.48827, mean: 0.15658
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11132, current rewards: 141.65625, mean: 0.14756
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11113, current rewards: 147.21564, mean: 0.14576
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11108, current rewards: 152.77797, mean: 0.14413
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11113, current rewards: 158.34589, mean: 0.14265
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11115, current rewards: 163.90129, mean: 0.14129
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11119, current rewards: 169.80554, mean: 0.14034
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11121, current rewards: 177.70025, mean: 0.14103
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11123, current rewards: 185.10067, mean: 0.14130
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11127, current rewards: 192.51975, mean: 0.14156
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11129, current rewards: 199.94000, mean: 0.14180
[32m[0906 13-51-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11129, current rewards: 207.35281, mean: 0.14202
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11133, current rewards: 220.59655, mean: 0.14609
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11133, current rewards: 244.24692, mean: 0.15657
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11133, current rewards: 268.04786, mean: 0.16649
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11135, current rewards: 286.99367, mean: 0.17289
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11135, current rewards: 305.66149, mean: 0.17875
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11136, current rewards: 324.37581, mean: 0.18430
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11136, current rewards: 343.13569, mean: 0.18958
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11126, current rewards: 361.75950, mean: 0.19449
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11122, current rewards: 380.52581, mean: 0.19923
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11126, current rewards: 386.96074, mean: 0.19743
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11127, current rewards: 396.33516, mean: 0.19718
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11127, current rewards: 407.24185, mean: 0.19769
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11129, current rewards: 417.89724, mean: 0.19806
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11130, current rewards: 428.57133, mean: 0.19841
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11133, current rewards: 439.25308, mean: 0.19876
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11133, current rewards: 449.94240, mean: 0.19909
[32m[0906 13-53-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11134, current rewards: 460.60865, mean: 0.19940
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11136, current rewards: 471.26193, mean: 0.19969
[32m[0906 13-53-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11135, current rewards: 481.92410, mean: 0.19997
[32m[0906 13-53-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11135, current rewards: 492.12245, mean: 0.20005
[32m[0906 13-53-47 @Agent.py:117][0m Average action selection time: 0.1114
[32m[0906 13-53-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-53-47 @MBExp.py:227][0m Rewards obtained: [500.1835109169427], Lows: [15], Highs: [16], Total time: 819.218934
[32m[0906 13-53-56 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-56 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11170, current rewards: -7.88602, mean: -0.78860
[32m[0906 13-54-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11186, current rewards: -4.71148, mean: -0.07852
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11163, current rewards: -1.38885, mean: -0.01263
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11148, current rewards: 1.93523, mean: 0.01210
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11081, current rewards: 5.25677, mean: 0.02503
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11031, current rewards: 8.58005, mean: 0.03300
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11052, current rewards: 11.90376, mean: 0.03840
[32m[0906 13-54-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11074, current rewards: 15.23330, mean: 0.04231
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11088, current rewards: 20.61024, mean: 0.05027
[32m[0906 13-54-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11057, current rewards: 25.70255, mean: 0.05588
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11043, current rewards: 30.80012, mean: 0.06039
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11052, current rewards: 35.89080, mean: 0.06409
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11058, current rewards: 40.98743, mean: 0.06719
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11073, current rewards: 46.08121, mean: 0.06982
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11077, current rewards: 51.17007, mean: 0.07207
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11079, current rewards: 56.26451, mean: 0.07403
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11085, current rewards: 61.57026, mean: 0.07601
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11090, current rewards: 66.78525, mean: 0.07766
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11097, current rewards: 61.34487, mean: 0.06741
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11089, current rewards: 65.85207, mean: 0.06860
[32m[0906 13-55-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11071, current rewards: 70.35443, mean: 0.06966
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11072, current rewards: 74.86291, mean: 0.07063
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11077, current rewards: 79.37092, mean: 0.07151
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11080, current rewards: 83.87406, mean: 0.07231
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11084, current rewards: 87.73120, mean: 0.07251
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11085, current rewards: 91.30524, mean: 0.07246
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11089, current rewards: 94.87634, mean: 0.07242
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11092, current rewards: 98.44731, mean: 0.07239
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11094, current rewards: 102.01328, mean: 0.07235
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11095, current rewards: 105.58399, mean: 0.07232
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11098, current rewards: 109.15570, mean: 0.07229
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11099, current rewards: 112.72827, mean: 0.07226
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11100, current rewards: 111.51497, mean: 0.06926
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11104, current rewards: 116.76941, mean: 0.07034
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11107, current rewards: 121.73776, mean: 0.07119
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11108, current rewards: 126.70192, mean: 0.07199
[32m[0906 13-57-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11106, current rewards: 131.66474, mean: 0.07274
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11098, current rewards: 136.63356, mean: 0.07346
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11095, current rewards: 141.59477, mean: 0.07413
[32m[0906 13-57-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11101, current rewards: 146.56171, mean: 0.07478
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11102, current rewards: 141.11362, mean: 0.07021
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11105, current rewards: 145.15556, mean: 0.07046
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11105, current rewards: 149.26908, mean: 0.07074
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11107, current rewards: 153.38258, mean: 0.07101
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11109, current rewards: 157.49887, mean: 0.07127
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11109, current rewards: 161.61511, mean: 0.07151
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11109, current rewards: 155.29750, mean: 0.06723
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11111, current rewards: 159.72815, mean: 0.06768
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11112, current rewards: 164.15372, mean: 0.06811
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11115, current rewards: 168.57838, mean: 0.06853
[32m[0906 13-58-35 @Agent.py:117][0m Average action selection time: 0.1112
[32m[0906 13-58-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-58-35 @MBExp.py:227][0m Rewards obtained: [172.11987613487446], Lows: [15], Highs: [13], Total time: 1097.881562
[32m[0906 13-58-47 @MBExp.py:144][0m ####################################################################
[32m[0906 13-58-47 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-58-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11549, current rewards: -5.32462, mean: -0.53246
[32m[0906 13-58-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11362, current rewards: -0.97909, mean: -0.01632
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11273, current rewards: 3.40035, mean: 0.03091
[32m[0906 13-59-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11251, current rewards: 7.78050, mean: 0.04863
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11169, current rewards: 12.15837, mean: 0.05790
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11112, current rewards: 16.53819, mean: 0.06361
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11135, current rewards: 20.91722, mean: 0.06747
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11141, current rewards: 25.29972, mean: 0.07028
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11127, current rewards: 29.67872, mean: 0.07239
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11096, current rewards: 34.06173, mean: 0.07405
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11073, current rewards: 38.44311, mean: 0.07538
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11082, current rewards: 42.82423, mean: 0.07647
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11091, current rewards: 31.08775, mean: 0.05096
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11094, current rewards: 36.70906, mean: 0.05562
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11095, current rewards: 42.33102, mean: 0.05962
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11098, current rewards: 47.95676, mean: 0.06310
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11098, current rewards: 53.87180, mean: 0.06651
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11102, current rewards: 59.56819, mean: 0.06927
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11105, current rewards: 65.25027, mean: 0.07170
[32m[0906 14-00-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11089, current rewards: 70.93431, mean: 0.07389
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11072, current rewards: 76.63037, mean: 0.07587
[32m[0906 14-00-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11069, current rewards: 82.31495, mean: 0.07766
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11071, current rewards: 87.99698, mean: 0.07928
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11076, current rewards: 93.68674, mean: 0.08076
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11079, current rewards: 86.74095, mean: 0.07169
[32m[0906 14-01-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11079, current rewards: 92.68244, mean: 0.07356
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11083, current rewards: 98.62908, mean: 0.07529
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11084, current rewards: 104.57659, mean: 0.07689
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11085, current rewards: 110.52127, mean: 0.07838
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11088, current rewards: 116.46781, mean: 0.07977
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11088, current rewards: 122.41678, mean: 0.08107
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11088, current rewards: 128.36413, mean: 0.08228
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11090, current rewards: 135.31550, mean: 0.08405
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11090, current rewards: 143.08649, mean: 0.08620
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11091, current rewards: 150.94603, mean: 0.08827
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11092, current rewards: 137.62673, mean: 0.07820
[32m[0906 14-02-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11088, current rewards: 140.99719, mean: 0.07790
[32m[0906 14-02-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11079, current rewards: 144.36801, mean: 0.07762
[32m[0906 14-02-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11073, current rewards: 147.73945, mean: 0.07735
[32m[0906 14-02-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11070, current rewards: 151.10980, mean: 0.07710
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11073, current rewards: 154.48156, mean: 0.07686
[32m[0906 14-02-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11078, current rewards: 153.16602, mean: 0.07435
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11081, current rewards: 159.25467, mean: 0.07548
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11084, current rewards: 165.32668, mean: 0.07654
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11085, current rewards: 171.39365, mean: 0.07755
[32m[0906 14-02-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11087, current rewards: 177.46001, mean: 0.07852
[32m[0906 14-03-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11090, current rewards: 183.52956, mean: 0.07945
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11092, current rewards: 183.73636, mean: 0.07785
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11095, current rewards: 188.85586, mean: 0.07836
[32m[0906 14-03-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11097, current rewards: 193.18166, mean: 0.07853
[32m[0906 14-03-25 @Agent.py:117][0m Average action selection time: 0.1110
[32m[0906 14-03-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-03-25 @MBExp.py:227][0m Rewards obtained: [196.79974869494714], Lows: [12], Highs: [37], Total time: 1376.016845
[32m[0906 14-03-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-39 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11196, current rewards: -11.81308, mean: -1.18131
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11184, current rewards: -6.75286, mean: -0.11255
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11163, current rewards: -2.63987, mean: -0.02400
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11073, current rewards: 1.47153, mean: 0.00920
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10997, current rewards: 5.58419, mean: 0.02659
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10969, current rewards: 9.70026, mean: 0.03731
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11005, current rewards: 13.81279, mean: 0.04456
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11033, current rewards: 13.83830, mean: 0.03844
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11021, current rewards: 14.06617, mean: 0.03431
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10997, current rewards: 19.61205, mean: 0.04263
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10985, current rewards: 25.15953, mean: 0.04933
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11010, current rewards: 30.70570, mean: 0.05483
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11027, current rewards: 26.14905, mean: 0.04287
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11035, current rewards: 32.16133, mean: 0.04873
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11049, current rewards: 38.17382, mean: 0.05377
[32m[0906 14-05-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11060, current rewards: 44.18608, mean: 0.05814
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11068, current rewards: 50.19852, mean: 0.06197
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11079, current rewards: 56.21101, mean: 0.06536
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11079, current rewards: 62.22341, mean: 0.06838
[32m[0906 14-05-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11068, current rewards: 68.23580, mean: 0.07108
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11055, current rewards: 66.37118, mean: 0.06571
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11053, current rewards: 72.75311, mean: 0.06864
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11061, current rewards: 79.14033, mean: 0.07130
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11067, current rewards: 85.53116, mean: 0.07373
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11071, current rewards: 91.86708, mean: 0.07592
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11079, current rewards: 98.24435, mean: 0.07797
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11079, current rewards: 104.61650, mean: 0.07986
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11080, current rewards: 110.99339, mean: 0.08161
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11083, current rewards: 117.36717, mean: 0.08324
[32m[0906 14-06-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11085, current rewards: 123.74552, mean: 0.08476
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11085, current rewards: 129.61207, mean: 0.08584
[32m[0906 14-06-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11089, current rewards: 135.67930, mean: 0.08697
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11090, current rewards: 141.58508, mean: 0.08794
[32m[0906 14-06-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11091, current rewards: 147.62105, mean: 0.08893
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11094, current rewards: 153.66091, mean: 0.08986
[32m[0906 14-06-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11095, current rewards: 159.69280, mean: 0.09073
[32m[0906 14-07-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11094, current rewards: 165.73120, mean: 0.09156
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11088, current rewards: 171.77001, mean: 0.09235
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11079, current rewards: 177.80287, mean: 0.09309
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11074, current rewards: 182.76860, mean: 0.09325
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11077, current rewards: 185.58910, mean: 0.09233
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11081, current rewards: 188.43429, mean: 0.09147
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11087, current rewards: 191.27952, mean: 0.09065
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11088, current rewards: 194.12478, mean: 0.08987
[32m[0906 14-07-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11088, current rewards: 196.97060, mean: 0.08913
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11091, current rewards: 199.81594, mean: 0.08841
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11091, current rewards: 202.66121, mean: 0.08773
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11092, current rewards: 205.50738, mean: 0.08708
[32m[0906 14-08-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11100, current rewards: 208.50496, mean: 0.08652
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11108, current rewards: 213.39074, mean: 0.08674
[32m[0906 14-08-17 @Agent.py:117][0m Average action selection time: 0.1111
[32m[0906 14-08-17 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-08-17 @MBExp.py:227][0m Rewards obtained: [218.22858663438953], Lows: [13], Highs: [13], Total time: 1654.516886
[32m[0906 14-08-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-34 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11096, current rewards: -5.53727, mean: -0.55373
[32m[0906 14-08-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11216, current rewards: -0.28015, mean: -0.00467
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11211, current rewards: 4.83088, mean: 0.04392
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11074, current rewards: 9.94482, mean: 0.06216
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11023, current rewards: 15.06624, mean: 0.07174
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10973, current rewards: 20.18328, mean: 0.07763
[32m[0906 14-09-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11005, current rewards: 25.56749, mean: 0.08248
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11007, current rewards: 30.78755, mean: 0.08552
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10972, current rewards: 36.00312, mean: 0.08781
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10951, current rewards: 41.22111, mean: 0.08961
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10940, current rewards: 41.00118, mean: 0.08039
[32m[0906 14-09-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10957, current rewards: 47.09415, mean: 0.08410
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10978, current rewards: 52.84938, mean: 0.08664
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10988, current rewards: 58.60962, mean: 0.08880
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10998, current rewards: 64.25359, mean: 0.09050
[32m[0906 14-09-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11011, current rewards: 69.63306, mean: 0.09162
[32m[0906 14-10-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11015, current rewards: 75.32449, mean: 0.09299
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11021, current rewards: 81.01851, mean: 0.09421
[32m[0906 14-10-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11017, current rewards: 78.16564, mean: 0.08590
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11001, current rewards: 82.16584, mean: 0.08559
[32m[0906 14-10-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10989, current rewards: 86.16297, mean: 0.08531
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10989, current rewards: 90.16285, mean: 0.08506
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10994, current rewards: 94.16808, mean: 0.08484
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10997, current rewards: 99.10162, mean: 0.08543
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11005, current rewards: 104.00142, mean: 0.08595
[32m[0906 14-10-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11008, current rewards: 108.90304, mean: 0.08643
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11013, current rewards: 113.80265, mean: 0.08687
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11019, current rewards: 118.70075, mean: 0.08728
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11022, current rewards: 113.81816, mean: 0.08072
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11026, current rewards: 119.32538, mean: 0.08173
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11031, current rewards: 124.82938, mean: 0.08267
[32m[0906 14-11-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11032, current rewards: 130.08157, mean: 0.08339
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11036, current rewards: 135.16771, mean: 0.08396
[32m[0906 14-11-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11038, current rewards: 140.78574, mean: 0.08481
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11040, current rewards: 146.39763, mean: 0.08561
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11044, current rewards: 152.01116, mean: 0.08637
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11042, current rewards: 149.57323, mean: 0.08264
[32m[0906 14-12-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11036, current rewards: 154.55407, mean: 0.08309
[32m[0906 14-12-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11028, current rewards: 159.53285, mean: 0.08353
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11020, current rewards: 164.51408, mean: 0.08394
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11020, current rewards: 169.49014, mean: 0.08432
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11024, current rewards: 174.46776, mean: 0.08469
[32m[0906 14-12-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11025, current rewards: 179.44979, mean: 0.08505
[32m[0906 14-12-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11028, current rewards: 184.42781, mean: 0.08538
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11032, current rewards: 189.40616, mean: 0.08570
[32m[0906 14-12-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11033, current rewards: 194.38851, mean: 0.08601
[32m[0906 14-12-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11035, current rewards: 199.36721, mean: 0.08631
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11037, current rewards: 204.34628, mean: 0.08659
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11039, current rewards: 209.94179, mean: 0.08711
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11041, current rewards: 215.25498, mean: 0.08750
[32m[0906 14-13-11 @Agent.py:117][0m Average action selection time: 0.1104
[32m[0906 14-13-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-13-11 @MBExp.py:227][0m Rewards obtained: [207.25142230058552], Lows: [13], Highs: [21], Total time: 1931.291236
[32m[0906 14-13-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-29 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11042, current rewards: -6.74663, mean: -0.67466
[32m[0906 14-13-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11100, current rewards: -1.08004, mean: -0.01800
[32m[0906 14-13-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11093, current rewards: 4.68939, mean: 0.04263
[32m[0906 14-13-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10988, current rewards: 10.45514, mean: 0.06534
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10941, current rewards: 16.21870, mean: 0.07723
[32m[0906 14-13-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10919, current rewards: 21.98301, mean: 0.08455
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10951, current rewards: 27.71059, mean: 0.08939
[32m[0906 14-14-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10947, current rewards: 33.05610, mean: 0.09182
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10933, current rewards: 28.05143, mean: 0.06842
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10913, current rewards: 35.41093, mean: 0.07698
[32m[0906 14-14-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10900, current rewards: 43.35960, mean: 0.08502
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10927, current rewards: 51.31005, mean: 0.09163
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10944, current rewards: 59.26219, mean: 0.09715
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10964, current rewards: 67.21290, mean: 0.10184
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10974, current rewards: 75.16148, mean: 0.10586
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10982, current rewards: 87.20504, mean: 0.11474
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10994, current rewards: 95.03933, mean: 0.11733
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11001, current rewards: 102.87919, mean: 0.11963
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10988, current rewards: 110.70881, mean: 0.12166
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10978, current rewards: 118.53961, mean: 0.12348
[32m[0906 14-15-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10968, current rewards: 126.37503, mean: 0.12512
[32m[0906 14-15-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10967, current rewards: 134.20414, mean: 0.12661
[32m[0906 14-15-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10977, current rewards: 135.25186, mean: 0.12185
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10984, current rewards: 140.41956, mean: 0.12105
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10989, current rewards: 145.94365, mean: 0.12061
[32m[0906 14-15-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10995, current rewards: 151.46935, mean: 0.12021
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10999, current rewards: 156.98134, mean: 0.11983
[32m[0906 14-15-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11003, current rewards: 162.50628, mean: 0.11949
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11008, current rewards: 168.02678, mean: 0.11917
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11012, current rewards: 173.54452, mean: 0.11887
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11017, current rewards: 179.05698, mean: 0.11858
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11023, current rewards: 184.45979, mean: 0.11824
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11025, current rewards: 189.67019, mean: 0.11781
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11030, current rewards: 195.05480, mean: 0.11750
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11034, current rewards: 200.43537, mean: 0.11721
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11036, current rewards: 205.81174, mean: 0.11694
[32m[0906 14-16-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11036, current rewards: 211.19108, mean: 0.11668
[32m[0906 14-16-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11029, current rewards: 219.36263, mean: 0.11794
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11023, current rewards: 225.87292, mean: 0.11826
[32m[0906 14-17-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11018, current rewards: 232.35761, mean: 0.11855
[32m[0906 14-17-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11014, current rewards: 238.92334, mean: 0.11887
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11018, current rewards: 245.39480, mean: 0.11912
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11022, current rewards: 251.86461, mean: 0.11937
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11026, current rewards: 258.33882, mean: 0.11960
[32m[0906 14-17-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11032, current rewards: 264.81380, mean: 0.11983
[32m[0906 14-17-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11036, current rewards: 271.27967, mean: 0.12004
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11038, current rewards: 277.75421, mean: 0.12024
[32m[0906 14-17-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11040, current rewards: 284.22250, mean: 0.12043
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11043, current rewards: 292.26944, mean: 0.12127
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11045, current rewards: 298.39258, mean: 0.12130
[32m[0906 14-18-06 @Agent.py:117][0m Average action selection time: 0.1105
[32m[0906 14-18-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-18-06 @MBExp.py:227][0m Rewards obtained: [303.2937664835501], Lows: [5], Highs: [13], Total time: 2208.138636
[32m[0906 14-18-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-27 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11130, current rewards: -5.74616, mean: -0.57462
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11106, current rewards: -1.27818, mean: -0.02130
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10958, current rewards: 3.05548, mean: 0.02778
[32m[0906 14-18-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10901, current rewards: 7.38801, mean: 0.04618
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10859, current rewards: 11.72278, mean: 0.05582
[32m[0906 14-18-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10838, current rewards: 16.05334, mean: 0.06174
[32m[0906 14-19-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10879, current rewards: 20.41269, mean: 0.06585
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10858, current rewards: 25.04773, mean: 0.06958
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10846, current rewards: 29.35629, mean: 0.07160
[32m[0906 14-19-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10834, current rewards: 33.66477, mean: 0.07318
[32m[0906 14-19-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10832, current rewards: 37.97565, mean: 0.07446
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10864, current rewards: 37.93902, mean: 0.06775
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10885, current rewards: 41.74479, mean: 0.06843
[32m[0906 14-19-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10905, current rewards: 46.50316, mean: 0.07046
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10927, current rewards: 51.25940, mean: 0.07220
[32m[0906 14-19-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10938, current rewards: 56.13203, mean: 0.07386
[32m[0906 14-19-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10946, current rewards: 48.53007, mean: 0.05991
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10950, current rewards: 53.56366, mean: 0.06228
[32m[0906 14-20-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10939, current rewards: 58.59854, mean: 0.06439
[32m[0906 14-20-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10930, current rewards: 63.63338, mean: 0.06628
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10924, current rewards: 68.66861, mean: 0.06799
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10924, current rewards: 73.70397, mean: 0.06953
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10933, current rewards: 78.73914, mean: 0.07094
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10945, current rewards: 83.60482, mean: 0.07207
[32m[0906 14-20-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10953, current rewards: 83.07832, mean: 0.06866
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10958, current rewards: 87.90827, mean: 0.06977
[32m[0906 14-20-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10966, current rewards: 92.67901, mean: 0.07075
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10975, current rewards: 97.44710, mean: 0.07165
[32m[0906 14-21-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10981, current rewards: 102.21850, mean: 0.07250
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10987, current rewards: 106.99055, mean: 0.07328
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10991, current rewards: 111.76213, mean: 0.07401
[32m[0906 14-21-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10996, current rewards: 116.34261, mean: 0.07458
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10999, current rewards: 121.09590, mean: 0.07521
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11003, current rewards: 125.85672, mean: 0.07582
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11009, current rewards: 130.61237, mean: 0.07638
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11012, current rewards: 131.21410, mean: 0.07455
[32m[0906 14-21-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11012, current rewards: 136.12900, mean: 0.07521
[32m[0906 14-21-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11006, current rewards: 141.04318, mean: 0.07583
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11001, current rewards: 145.96340, mean: 0.07642
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10995, current rewards: 151.06242, mean: 0.07707
[32m[0906 14-22-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10991, current rewards: 155.65533, mean: 0.07744
[32m[0906 14-22-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10994, current rewards: 160.24015, mean: 0.07779
[32m[0906 14-22-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10998, current rewards: 164.82564, mean: 0.07812
[32m[0906 14-22-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11003, current rewards: 169.40505, mean: 0.07843
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11007, current rewards: 173.99476, mean: 0.07873
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11010, current rewards: 178.58043, mean: 0.07902
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11015, current rewards: 183.16794, mean: 0.07929
[32m[0906 14-22-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11019, current rewards: 177.14413, mean: 0.07506
[32m[0906 14-22-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11021, current rewards: 182.24742, mean: 0.07562
[32m[0906 14-22-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11026, current rewards: 187.48103, mean: 0.07621
[32m[0906 14-23-03 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-23-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-23-03 @MBExp.py:227][0m Rewards obtained: [191.6644707321093], Lows: [11], Highs: [21], Total time: 2484.513311
[32m[0906 14-23-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-27 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11191, current rewards: -5.57646, mean: -0.55765
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11077, current rewards: -0.70391, mean: -0.01173
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10926, current rewards: 4.52799, mean: 0.04116
[32m[0906 14-23-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10913, current rewards: 9.75545, mean: 0.06097
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10884, current rewards: 14.98425, mean: 0.07135
[32m[0906 14-23-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10871, current rewards: 20.21264, mean: 0.07774
[32m[0906 14-24-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10884, current rewards: 26.29354, mean: 0.08482
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10869, current rewards: 32.22886, mean: 0.08952
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10856, current rewards: 37.73460, mean: 0.09204
[32m[0906 14-24-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10858, current rewards: 43.24221, mean: 0.09400
[32m[0906 14-24-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10852, current rewards: 48.75124, mean: 0.09559
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10886, current rewards: 47.53988, mean: 0.08489
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10910, current rewards: 52.74393, mean: 0.08647
[32m[0906 14-24-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10926, current rewards: 57.95158, mean: 0.08781
[32m[0906 14-24-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10941, current rewards: 63.15832, mean: 0.08896
[32m[0906 14-24-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10957, current rewards: 69.56723, mean: 0.09154
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10969, current rewards: 74.24583, mean: 0.09166
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10962, current rewards: 78.93926, mean: 0.09179
[32m[0906 14-25-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10950, current rewards: 83.63705, mean: 0.09191
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10939, current rewards: 88.33068, mean: 0.09201
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10931, current rewards: 93.03084, mean: 0.09211
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10931, current rewards: 97.72730, mean: 0.09220
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10942, current rewards: 102.42568, mean: 0.09228
[32m[0906 14-25-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10950, current rewards: 107.50526, mean: 0.09268
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10956, current rewards: 112.33886, mean: 0.09284
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10960, current rewards: 117.02921, mean: 0.09288
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10969, current rewards: 121.71816, mean: 0.09291
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10972, current rewards: 126.40598, mean: 0.09295
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10977, current rewards: 133.74318, mean: 0.09485
[32m[0906 14-26-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10985, current rewards: 138.96991, mean: 0.09518
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10989, current rewards: 144.19367, mean: 0.09549
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10993, current rewards: 149.41704, mean: 0.09578
[32m[0906 14-26-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11000, current rewards: 154.24256, mean: 0.09580
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11004, current rewards: 159.32803, mean: 0.09598
[32m[0906 14-26-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11007, current rewards: 164.41514, mean: 0.09615
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11012, current rewards: 169.50089, mean: 0.09631
[32m[0906 14-26-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11011, current rewards: 164.11663, mean: 0.09067
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11004, current rewards: 169.21069, mean: 0.09097
[32m[0906 14-26-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10998, current rewards: 174.30792, mean: 0.09126
[32m[0906 14-27-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10990, current rewards: 179.40562, mean: 0.09153
[32m[0906 14-27-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10984, current rewards: 184.62235, mean: 0.09185
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10983, current rewards: 189.73450, mean: 0.09210
[32m[0906 14-27-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10985, current rewards: 194.84492, mean: 0.09234
[32m[0906 14-27-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10989, current rewards: 199.95677, mean: 0.09257
[32m[0906 14-27-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10995, current rewards: 205.06783, mean: 0.09279
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11000, current rewards: 210.17896, mean: 0.09300
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11003, current rewards: 215.29145, mean: 0.09320
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11005, current rewards: 220.40246, mean: 0.09339
[32m[0906 14-27-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11007, current rewards: 219.57758, mean: 0.09111
[32m[0906 14-27-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11011, current rewards: 224.69086, mean: 0.09134
[32m[0906 14-28-03 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-28-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-28-03 @MBExp.py:227][0m Rewards obtained: [228.78852783086685], Lows: [5], Highs: [18], Total time: 2760.497101
[32m[0906 14-28-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-28-28 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10980, current rewards: -12.90718, mean: -1.29072
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10918, current rewards: -6.53230, mean: -0.10887
[32m[0906 14-28-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10837, current rewards: -0.89204, mean: -0.00811
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10840, current rewards: 4.74457, mean: 0.02965
[32m[0906 14-28-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10829, current rewards: 8.15958, mean: 0.03886
[32m[0906 14-28-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10811, current rewards: 13.33035, mean: 0.05127
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10805, current rewards: 20.99303, mean: 0.06772
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10808, current rewards: 27.46033, mean: 0.07628
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10802, current rewards: 34.07485, mean: 0.08311
[32m[0906 14-29-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10803, current rewards: 40.68954, mean: 0.08846
[32m[0906 14-29-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10800, current rewards: 47.30384, mean: 0.09275
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10832, current rewards: 53.91391, mean: 0.09627
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10861, current rewards: 60.52014, mean: 0.09921
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10882, current rewards: 67.13042, mean: 0.10171
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10898, current rewards: 73.73983, mean: 0.10386
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10915, current rewards: 79.56000, mean: 0.10468
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10922, current rewards: 85.50958, mean: 0.10557
[32m[0906 14-30-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10914, current rewards: 78.50666, mean: 0.09129
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10908, current rewards: 84.33869, mean: 0.09268
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10898, current rewards: 90.16945, mean: 0.09393
[32m[0906 14-30-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10890, current rewards: 95.99786, mean: 0.09505
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10895, current rewards: 101.82702, mean: 0.09606
[32m[0906 14-30-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10906, current rewards: 107.65723, mean: 0.09699
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10918, current rewards: 115.02770, mean: 0.09916
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10925, current rewards: 121.34312, mean: 0.10028
[32m[0906 14-30-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10932, current rewards: 127.65855, mean: 0.10132
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10944, current rewards: 133.97397, mean: 0.10227
[32m[0906 14-30-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10950, current rewards: 140.28940, mean: 0.10315
[32m[0906 14-31-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10954, current rewards: 115.06819, mean: 0.08161
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10962, current rewards: 65.06819, mean: 0.04457
[32m[0906 14-31-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10965, current rewards: 15.06819, mean: 0.00998
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10970, current rewards: -34.93181, mean: -0.02239
[32m[0906 14-31-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10977, current rewards: -84.93181, mean: -0.05275
[32m[0906 14-31-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10981, current rewards: -134.93181, mean: -0.08128
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10986, current rewards: -184.93181, mean: -0.10815
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10990, current rewards: -234.93181, mean: -0.13348
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10991, current rewards: -284.93181, mean: -0.15742
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10984, current rewards: -334.93181, mean: -0.18007
[32m[0906 14-31-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10980, current rewards: -384.93181, mean: -0.20153
[32m[0906 14-32-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10974, current rewards: -434.93181, mean: -0.22190
[32m[0906 14-32-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10967, current rewards: -484.93181, mean: -0.24126
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10965, current rewards: -534.93181, mean: -0.25968
[32m[0906 14-32-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10967, current rewards: -584.93181, mean: -0.27722
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10971, current rewards: -634.93181, mean: -0.29395
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10975, current rewards: -684.93181, mean: -0.30992
[32m[0906 14-32-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10978, current rewards: -734.93181, mean: -0.32519
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10984, current rewards: -784.93181, mean: -0.33980
[32m[0906 14-32-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10987, current rewards: -834.93181, mean: -0.35378
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10990, current rewards: -884.93181, mean: -0.36719
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10993, current rewards: -934.93181, mean: -0.38005
[32m[0906 14-33-04 @Agent.py:117][0m Average action selection time: 0.1100
[32m[0906 14-33-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-33-04 @MBExp.py:227][0m Rewards obtained: [-974.931814306441], Lows: [10], Highs: [1128], Total time: 3036.098853
[32m[0906 14-33-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-33-32 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 14-33-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11076, current rewards: -2.36406, mean: -0.23641
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10829, current rewards: 3.45670, mean: 0.05761
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10797, current rewards: 9.31340, mean: 0.08467
[32m[0906 14-33-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10795, current rewards: 15.17408, mean: 0.09484
[32m[0906 14-33-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10780, current rewards: 21.03712, mean: 0.10018
[32m[0906 14-34-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10758, current rewards: 26.89946, mean: 0.10346
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10749, current rewards: 33.62905, mean: 0.10848
[32m[0906 14-34-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10752, current rewards: 25.85186, mean: 0.07181
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10756, current rewards: 31.28961, mean: 0.07632
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10762, current rewards: 36.72062, mean: 0.07983
[32m[0906 14-34-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10768, current rewards: 42.15865, mean: 0.08266
[32m[0906 14-34-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10801, current rewards: 47.59629, mean: 0.08499
[32m[0906 14-34-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10832, current rewards: 53.03142, mean: 0.08694
[32m[0906 14-34-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10857, current rewards: 58.46187, mean: 0.08858
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10887, current rewards: 63.89518, mean: 0.08999
[32m[0906 14-34-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10904, current rewards: 65.13848, mean: 0.08571
[32m[0906 14-35-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10905, current rewards: 72.51769, mean: 0.08953
[32m[0906 14-35-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10901, current rewards: 79.89925, mean: 0.09291
[32m[0906 14-35-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10894, current rewards: 87.28548, mean: 0.09592
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10888, current rewards: 94.66382, mean: 0.09861
[32m[0906 14-35-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10887, current rewards: 102.03116, mean: 0.10102
[32m[0906 14-35-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10889, current rewards: 109.43045, mean: 0.10324
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10902, current rewards: 116.81700, mean: 0.10524
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10917, current rewards: 124.92106, mean: 0.10769
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10926, current rewards: 132.53736, mean: 0.10954
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10935, current rewards: 129.39588, mean: 0.10270
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10946, current rewards: 136.13447, mean: 0.10392
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10953, current rewards: 142.87683, mean: 0.10506
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10960, current rewards: 149.61258, mean: 0.10611
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10968, current rewards: 156.35519, mean: 0.10709
[32m[0906 14-36-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10976, current rewards: 163.09491, mean: 0.10801
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10982, current rewards: 168.77730, mean: 0.10819
[32m[0906 14-36-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10989, current rewards: 174.22486, mean: 0.10821
[32m[0906 14-36-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10995, current rewards: 179.67068, mean: 0.10824
[32m[0906 14-36-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11000, current rewards: 185.12135, mean: 0.10826
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11005, current rewards: 190.56984, mean: 0.10828
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11005, current rewards: 196.02204, mean: 0.10830
[32m[0906 14-36-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11000, current rewards: 201.47551, mean: 0.10832
[32m[0906 14-37-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10995, current rewards: 206.91963, mean: 0.10833
[32m[0906 14-37-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10992, current rewards: 212.31857, mean: 0.10833
[32m[0906 14-37-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10989, current rewards: 218.12922, mean: 0.10852
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10984, current rewards: 218.14251, mean: 0.10589
[32m[0906 14-37-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10985, current rewards: 223.04203, mean: 0.10571
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10994, current rewards: 227.94200, mean: 0.10553
[32m[0906 14-37-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11000, current rewards: 232.84563, mean: 0.10536
[32m[0906 14-37-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11004, current rewards: 237.74960, mean: 0.10520
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11010, current rewards: 242.65109, mean: 0.10504
[32m[0906 14-37-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11013, current rewards: 247.71278, mean: 0.10496
[32m[0906 14-37-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11017, current rewards: 252.70887, mean: 0.10486
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11022, current rewards: 257.70561, mean: 0.10476
[32m[0906 14-38-08 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-38-08 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-38-08 @MBExp.py:227][0m Rewards obtained: [261.6968266504395], Lows: [5], Highs: [25], Total time: 3312.411325
[32m[0906 14-38-38 @MBExp.py:144][0m ####################################################################
[32m[0906 14-38-38 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10630, current rewards: -2.79726, mean: -0.27973
[32m[0906 14-38-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10749, current rewards: 2.78949, mean: 0.04649
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10799, current rewards: 8.36191, mean: 0.07602
[32m[0906 14-38-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10779, current rewards: 13.93422, mean: 0.08709
[32m[0906 14-39-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10782, current rewards: 19.50617, mean: 0.09289
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10734, current rewards: 24.91084, mean: 0.09581
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10725, current rewards: 25.01476, mean: 0.08069
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10731, current rewards: 30.08543, mean: 0.08357
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10747, current rewards: 35.15809, mean: 0.08575
[32m[0906 14-39-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10754, current rewards: 40.23134, mean: 0.08746
[32m[0906 14-39-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10767, current rewards: 45.29777, mean: 0.08882
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10810, current rewards: 50.37085, mean: 0.08995
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10839, current rewards: 55.44001, mean: 0.09089
[32m[0906 14-39-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10867, current rewards: 60.50771, mean: 0.09168
[32m[0906 14-39-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10893, current rewards: 61.69165, mean: 0.08689
[32m[0906 14-40-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10909, current rewards: 66.57751, mean: 0.08760
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10901, current rewards: 71.46303, mean: 0.08823
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10898, current rewards: 76.34726, mean: 0.08878
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10891, current rewards: 81.23431, mean: 0.08927
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10887, current rewards: 86.12041, mean: 0.08971
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10883, current rewards: 91.00750, mean: 0.09011
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10887, current rewards: 95.89393, mean: 0.09047
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10905, current rewards: 100.32436, mean: 0.09038
[32m[0906 14-40-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10916, current rewards: 105.02925, mean: 0.09054
[32m[0906 14-40-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10928, current rewards: 109.72906, mean: 0.09069
[32m[0906 14-40-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10940, current rewards: 104.55702, mean: 0.08298
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10948, current rewards: 109.45926, mean: 0.08356
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10958, current rewards: 114.36432, mean: 0.08409
[32m[0906 14-41-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10967, current rewards: 119.26669, mean: 0.08459
[32m[0906 14-41-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10976, current rewards: 124.17188, mean: 0.08505
[32m[0906 14-41-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10985, current rewards: 129.30204, mean: 0.08563
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10994, current rewards: 134.24023, mean: 0.08605
[32m[0906 14-41-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10999, current rewards: 139.17648, mean: 0.08645
[32m[0906 14-41-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11004, current rewards: 144.11344, mean: 0.08682
[32m[0906 14-41-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11009, current rewards: 149.05411, mean: 0.08717
[32m[0906 14-41-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11015, current rewards: 153.99373, mean: 0.08750
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11017, current rewards: 158.92978, mean: 0.08781
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11012, current rewards: 163.86826, mean: 0.08810
[32m[0906 14-42-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11007, current rewards: 158.83552, mean: 0.08316
[32m[0906 14-42-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11003, current rewards: 163.89227, mean: 0.08362
[32m[0906 14-42-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10998, current rewards: 168.95940, mean: 0.08406
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10994, current rewards: 174.02383, mean: 0.08448
[32m[0906 14-42-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10991, current rewards: 179.08967, mean: 0.08488
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10996, current rewards: 184.15806, mean: 0.08526
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10999, current rewards: 189.22296, mean: 0.08562
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11004, current rewards: 194.29090, mean: 0.08597
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11009, current rewards: 199.35698, mean: 0.08630
[32m[0906 14-42-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11013, current rewards: 204.42466, mean: 0.08662
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11018, current rewards: 209.49012, mean: 0.08693
[32m[0906 14-43-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11022, current rewards: 214.55714, mean: 0.08722
[32m[0906 14-43-15 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-43-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-43-15 @MBExp.py:227][0m Rewards obtained: [208.8553513264838], Lows: [17], Highs: [10], Total time: 3588.749499
[32m[0906 14-43-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-43-47 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-43-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10762, current rewards: -4.37291, mean: -0.43729
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10815, current rewards: 2.02904, mean: 0.03382
[32m[0906 14-43-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10792, current rewards: 8.27868, mean: 0.07526
[32m[0906 14-44-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10785, current rewards: 14.53189, mean: 0.09082
[32m[0906 14-44-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10773, current rewards: 20.77785, mean: 0.09894
[32m[0906 14-44-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10705, current rewards: 27.26900, mean: 0.10488
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10696, current rewards: 33.42724, mean: 0.10783
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10719, current rewards: 39.58203, mean: 0.10995
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10727, current rewards: 45.74346, mean: 0.11157
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10736, current rewards: 51.90282, mean: 0.11283
[32m[0906 14-44-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10748, current rewards: 45.27408, mean: 0.08877
[32m[0906 14-44-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10784, current rewards: 50.57876, mean: 0.09032
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10819, current rewards: 55.88387, mean: 0.09161
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10846, current rewards: 61.69548, mean: 0.09348
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10865, current rewards: 67.49071, mean: 0.09506
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10875, current rewards: 59.89508, mean: 0.07881
[32m[0906 14-45-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10870, current rewards: 37.47330, mean: 0.04626
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10866, current rewards: 42.71709, mean: 0.04967
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10863, current rewards: 47.95714, mean: 0.05270
[32m[0906 14-45-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10857, current rewards: 53.18079, mean: 0.05540
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10852, current rewards: 58.72864, mean: 0.05815
[32m[0906 14-45-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10857, current rewards: 64.31185, mean: 0.06067
[32m[0906 14-45-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10868, current rewards: 69.86185, mean: 0.06294
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10879, current rewards: 75.41424, mean: 0.06501
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10891, current rewards: 80.96519, mean: 0.06691
[32m[0906 14-46-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10903, current rewards: 86.51972, mean: 0.06867
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10911, current rewards: 92.07207, mean: 0.07028
[32m[0906 14-46-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10921, current rewards: 97.62564, mean: 0.07178
[32m[0906 14-46-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10930, current rewards: 94.16583, mean: 0.06678
[32m[0906 14-46-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10938, current rewards: 98.96536, mean: 0.06778
[32m[0906 14-46-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10948, current rewards: 104.82171, mean: 0.06942
[32m[0906 14-46-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10956, current rewards: 110.77284, mean: 0.07101
[32m[0906 14-46-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10964, current rewards: 116.72810, mean: 0.07250
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10971, current rewards: 122.68633, mean: 0.07391
[32m[0906 14-46-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10976, current rewards: 128.64192, mean: 0.07523
[32m[0906 14-47-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10982, current rewards: 134.59577, mean: 0.07647
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10983, current rewards: 140.54803, mean: 0.07765
[32m[0906 14-47-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10977, current rewards: 146.50432, mean: 0.07877
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10974, current rewards: 143.03412, mean: 0.07489
[32m[0906 14-47-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10969, current rewards: 149.62451, mean: 0.07634
[32m[0906 14-47-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10968, current rewards: 156.21440, mean: 0.07772
[32m[0906 14-47-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10969, current rewards: 162.80430, mean: 0.07903
[32m[0906 14-47-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10964, current rewards: 169.39426, mean: 0.08028
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10966, current rewards: 175.98919, mean: 0.08148
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10972, current rewards: 182.57491, mean: 0.08261
[32m[0906 14-47-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10977, current rewards: 183.47312, mean: 0.08118
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10981, current rewards: 188.80193, mean: 0.08173
[32m[0906 14-48-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10986, current rewards: 194.32740, mean: 0.08234
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10989, current rewards: 199.85316, mean: 0.08293
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10992, current rewards: 205.38075, mean: 0.08349
[32m[0906 14-48-23 @Agent.py:117][0m Average action selection time: 0.1100
[32m[0906 14-48-23 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-48-23 @MBExp.py:227][0m Rewards obtained: [209.80550936397853], Lows: [16], Highs: [47], Total time: 3864.353437
[32m[0906 14-48-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-48-58 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10816, current rewards: -4.47562, mean: -0.44756
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10791, current rewards: 0.83748, mean: 0.01396
[32m[0906 14-49-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10796, current rewards: 6.11232, mean: 0.05557
[32m[0906 14-49-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10801, current rewards: 11.38606, mean: 0.07116
[32m[0906 14-49-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10741, current rewards: 17.04414, mean: 0.08116
[32m[0906 14-49-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10696, current rewards: 22.15554, mean: 0.08521
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10685, current rewards: 27.26503, mean: 0.08795
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10701, current rewards: 32.36832, mean: 0.08991
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10726, current rewards: 37.48352, mean: 0.09142
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10731, current rewards: 42.59474, mean: 0.09260
[32m[0906 14-49-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10740, current rewards: 42.61560, mean: 0.08356
[32m[0906 14-49-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10784, current rewards: 48.33616, mean: 0.08631
[32m[0906 14-50-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10817, current rewards: 53.37185, mean: 0.08749
[32m[0906 14-50-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10845, current rewards: 58.50401, mean: 0.08864
[32m[0906 14-50-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10869, current rewards: 52.23341, mean: 0.07357
[32m[0906 14-50-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10869, current rewards: 57.33183, mean: 0.07544
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10868, current rewards: 62.43018, mean: 0.07707
[32m[0906 14-50-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10869, current rewards: 67.52854, mean: 0.07852
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10865, current rewards: 72.62694, mean: 0.07981
[32m[0906 14-50-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10862, current rewards: 77.72530, mean: 0.08096
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10862, current rewards: 82.67412, mean: 0.08186
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10867, current rewards: 87.74564, mean: 0.08278
[32m[0906 14-50-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10885, current rewards: 87.63188, mean: 0.07895
[32m[0906 14-51-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10903, current rewards: 93.52761, mean: 0.08063
[32m[0906 14-51-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10917, current rewards: 99.42445, mean: 0.08217
[32m[0906 14-51-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10935, current rewards: 105.32768, mean: 0.08359
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10950, current rewards: 111.22447, mean: 0.08490
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10962, current rewards: 117.12088, mean: 0.08612
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10976, current rewards: 123.02808, mean: 0.08725
[32m[0906 14-51-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10987, current rewards: 128.02329, mean: 0.08769
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10998, current rewards: 132.76601, mean: 0.08792
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11008, current rewards: 137.50971, mean: 0.08815
[32m[0906 14-51-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11016, current rewards: 142.25245, mean: 0.08836
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11023, current rewards: 146.99351, mean: 0.08855
[32m[0906 14-52-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11031, current rewards: 151.73795, mean: 0.08874
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11036, current rewards: 156.47994, mean: 0.08891
[32m[0906 14-52-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11038, current rewards: 161.22722, mean: 0.08908
[32m[0906 14-52-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11033, current rewards: 165.53077, mean: 0.08900
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11027, current rewards: 170.43349, mean: 0.08923
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11022, current rewards: 170.12038, mean: 0.08680
[32m[0906 14-52-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11019, current rewards: 175.19719, mean: 0.08716
[32m[0906 14-52-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11013, current rewards: 180.27285, mean: 0.08751
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11011, current rewards: 185.34635, mean: 0.08784
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11011, current rewards: 190.42038, mean: 0.08816
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11015, current rewards: 195.49485, mean: 0.08846
[32m[0906 14-53-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11022, current rewards: 200.47123, mean: 0.08870
[32m[0906 14-53-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11026, current rewards: 205.50113, mean: 0.08896
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11029, current rewards: 210.53158, mean: 0.08921
[32m[0906 14-53-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11035, current rewards: 215.56159, mean: 0.08944
[32m[0906 14-53-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11039, current rewards: 220.59174, mean: 0.08967
[32m[0906 14-53-35 @Agent.py:117][0m Average action selection time: 0.1104
[32m[0906 14-53-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-53-35 @MBExp.py:227][0m Rewards obtained: [224.61379189329355], Lows: [6], Highs: [20], Total time: 4141.116333
[32m[0906 14-54-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-12 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10760, current rewards: 0.80995, mean: 0.08099
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10755, current rewards: 6.14829, mean: 0.10247
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10774, current rewards: 11.75058, mean: 0.10682
[32m[0906 14-54-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10791, current rewards: 17.35550, mean: 0.10847
[32m[0906 14-54-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10707, current rewards: 22.95996, mean: 0.10933
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10662, current rewards: 28.56040, mean: 0.10985
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10664, current rewards: 34.16513, mean: 0.11021
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10678, current rewards: 39.76904, mean: 0.11047
[32m[0906 14-54-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10693, current rewards: 45.37384, mean: 0.11067
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10713, current rewards: 45.52281, mean: 0.09896
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10726, current rewards: 50.87484, mean: 0.09975
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10771, current rewards: 56.22324, mean: 0.10040
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10808, current rewards: 62.27567, mean: 0.10209
[32m[0906 14-55-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10835, current rewards: 67.76391, mean: 0.10267
[32m[0906 14-55-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10858, current rewards: 73.24812, mean: 0.10317
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10860, current rewards: 78.73368, mean: 0.10360
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10859, current rewards: 84.21726, mean: 0.10397
[32m[0906 14-55-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10856, current rewards: 79.34643, mean: 0.09226
[32m[0906 14-55-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10855, current rewards: 85.00759, mean: 0.09341
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10853, current rewards: 90.67492, mean: 0.09445
[32m[0906 14-56-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10855, current rewards: 96.33913, mean: 0.09539
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10859, current rewards: 96.43546, mean: 0.09098
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10873, current rewards: 102.37330, mean: 0.09223
[32m[0906 14-56-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10889, current rewards: 108.09629, mean: 0.09319
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10903, current rewards: 113.81630, mean: 0.09406
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10917, current rewards: 116.19550, mean: 0.09222
[32m[0906 14-56-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10929, current rewards: 118.62625, mean: 0.09055
[32m[0906 14-56-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10937, current rewards: 122.71835, mean: 0.09023
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10947, current rewards: 126.48489, mean: 0.08971
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10956, current rewards: 130.67764, mean: 0.08951
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10963, current rewards: 134.87227, mean: 0.08932
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10970, current rewards: 139.06854, mean: 0.08915
[32m[0906 14-57-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10978, current rewards: 143.26513, mean: 0.08898
[32m[0906 14-57-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10983, current rewards: 147.45810, mean: 0.08883
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10988, current rewards: 151.65243, mean: 0.08869
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10996, current rewards: 155.84440, mean: 0.08855
[32m[0906 14-57-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11002, current rewards: 160.04323, mean: 0.08842
[32m[0906 14-57-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10998, current rewards: 164.56638, mean: 0.08848
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10994, current rewards: 169.74754, mean: 0.08887
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10989, current rewards: 175.10473, mean: 0.08934
[32m[0906 14-57-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10986, current rewards: 180.45691, mean: 0.08978
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10982, current rewards: 185.81366, mean: 0.09020
[32m[0906 14-58-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10978, current rewards: 191.16899, mean: 0.09060
[32m[0906 14-58-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10975, current rewards: 196.52134, mean: 0.09098
[32m[0906 14-58-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10979, current rewards: 201.87717, mean: 0.09135
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10985, current rewards: 206.81294, mean: 0.09151
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10991, current rewards: 212.00486, mean: 0.09178
[32m[0906 14-58-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10996, current rewards: 217.18755, mean: 0.09203
[32m[0906 14-58-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10999, current rewards: 222.37673, mean: 0.09227
[32m[0906 14-58-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11003, current rewards: 227.55999, mean: 0.09250
[32m[0906 14-58-48 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-58-48 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-58-48 @MBExp.py:227][0m Rewards obtained: [221.05360175670225], Lows: [10], Highs: [15], Total time: 4416.985387
[32m[0906 14-59-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-27 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11017, current rewards: -4.04029, mean: -0.40403
[32m[0906 14-59-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10860, current rewards: 15.82021, mean: 0.26367
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10868, current rewards: 38.79826, mean: 0.35271
[32m[0906 14-59-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10830, current rewards: 60.56789, mean: 0.37855
[32m[0906 14-59-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10727, current rewards: 67.88487, mean: 0.32326
[32m[0906 14-59-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10676, current rewards: 75.57856, mean: 0.29069
[32m[0906 15-00-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10673, current rewards: 83.27194, mean: 0.26862
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10691, current rewards: 90.97107, mean: 0.25270
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10705, current rewards: 98.66990, mean: 0.24066
[32m[0906 15-00-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10723, current rewards: 106.36767, mean: 0.23123
[32m[0906 15-00-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10733, current rewards: 114.05471, mean: 0.22364
[32m[0906 15-00-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10778, current rewards: 121.75212, mean: 0.21741
[32m[0906 15-00-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10820, current rewards: 129.19644, mean: 0.21180
[32m[0906 15-00-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10848, current rewards: 135.77044, mean: 0.20571
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10856, current rewards: 142.83080, mean: 0.20117
[32m[0906 15-00-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10857, current rewards: 149.89255, mean: 0.19723
[32m[0906 15-00-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10854, current rewards: 156.95584, mean: 0.19377
[32m[0906 15-01-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10852, current rewards: 164.01992, mean: 0.19072
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10857, current rewards: 171.07935, mean: 0.18800
[32m[0906 15-01-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10854, current rewards: 131.57096, mean: 0.13705
[32m[0906 15-01-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10855, current rewards: 80.58404, mean: 0.07979
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10861, current rewards: 37.30137, mean: 0.03519
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10878, current rewards: -17.35811, mean: -0.01564
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10893, current rewards: -44.63704, mean: -0.03848
[32m[0906 15-01-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10905, current rewards: -40.31713, mean: -0.03332
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10914, current rewards: -35.99792, mean: -0.02857
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10923, current rewards: -31.67952, mean: -0.02418
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10933, current rewards: -27.35793, mean: -0.02012
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10939, current rewards: -28.50954, mean: -0.02022
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10947, current rewards: -57.34858, mean: -0.03928
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10953, current rewards: -85.23701, mean: -0.05645
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10959, current rewards: -112.64244, mean: -0.07221
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10966, current rewards: -145.14628, mean: -0.09015
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10971, current rewards: -177.55592, mean: -0.10696
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10976, current rewards: -210.18633, mean: -0.12292
[32m[0906 15-02-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10982, current rewards: -238.40917, mean: -0.13546
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10984, current rewards: -266.61689, mean: -0.14730
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10977, current rewards: -284.73778, mean: -0.15308
[32m[0906 15-02-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10974, current rewards: -278.42236, mean: -0.14577
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10968, current rewards: -272.10693, mean: -0.13883
[32m[0906 15-03-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10963, current rewards: -265.79151, mean: -0.13223
[32m[0906 15-03-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10960, current rewards: -259.47608, mean: -0.12596
[32m[0906 15-03-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10955, current rewards: -253.16066, mean: -0.11998
[32m[0906 15-03-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10950, current rewards: -246.84523, mean: -0.11428
[32m[0906 15-03-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10951, current rewards: -266.43490, mean: -0.12056
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10955, current rewards: -316.43490, mean: -0.14002
[32m[0906 15-03-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10959, current rewards: -366.43490, mean: -0.15863
[32m[0906 15-03-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10965, current rewards: -416.43490, mean: -0.17646
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10969, current rewards: -466.43490, mean: -0.19354
[32m[0906 15-03-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10973, current rewards: -516.43490, mean: -0.20993
[32m[0906 15-04-02 @Agent.py:117][0m Average action selection time: 0.1098
[32m[0906 15-04-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-04-02 @MBExp.py:227][0m Rewards obtained: [-556.4349045781422], Lows: [280], Highs: [328], Total time: 4692.129354
[32m[0906 15-04-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-04-44 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10741, current rewards: -4.55307, mean: -0.45531
[32m[0906 15-04-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10851, current rewards: 1.00993, mean: 0.01683
[32m[0906 15-04-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10813, current rewards: 6.57633, mean: 0.05978
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10707, current rewards: 12.07930, mean: 0.07550
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10654, current rewards: 17.62756, mean: 0.08394
[32m[0906 15-05-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10609, current rewards: 23.18457, mean: 0.08917
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10603, current rewards: 28.73740, mean: 0.09270
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10635, current rewards: 34.28990, mean: 0.09525
[32m[0906 15-05-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10652, current rewards: 39.84429, mean: 0.09718
[32m[0906 15-05-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10661, current rewards: 45.39906, mean: 0.09869
[32m[0906 15-05-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10677, current rewards: 50.95509, mean: 0.09991
[32m[0906 15-05-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10717, current rewards: 56.32890, mean: 0.10059
[32m[0906 15-05-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10757, current rewards: 56.21468, mean: 0.09216
[32m[0906 15-05-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10789, current rewards: 60.99038, mean: 0.09241
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10788, current rewards: 65.77657, mean: 0.09264
[32m[0906 15-06-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10789, current rewards: 70.55760, mean: 0.09284
[32m[0906 15-06-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10787, current rewards: 75.33071, mean: 0.09300
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10789, current rewards: 80.10539, mean: 0.09315
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10793, current rewards: 84.88002, mean: 0.09327
[32m[0906 15-06-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10793, current rewards: 90.42413, mean: 0.09419
[32m[0906 15-06-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10794, current rewards: 94.90422, mean: 0.09396
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10801, current rewards: 99.38044, mean: 0.09376
[32m[0906 15-06-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10818, current rewards: 103.65825, mean: 0.09339
[32m[0906 15-06-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10835, current rewards: 108.72887, mean: 0.09373
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10853, current rewards: 113.79843, mean: 0.09405
[32m[0906 15-07-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10870, current rewards: 118.86766, mean: 0.09434
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10883, current rewards: 123.93519, mean: 0.09461
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10899, current rewards: 128.96557, mean: 0.09483
[32m[0906 15-07-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10911, current rewards: 133.68398, mean: 0.09481
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10922, current rewards: 138.75479, mean: 0.09504
[32m[0906 15-07-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10935, current rewards: 143.82365, mean: 0.09525
[32m[0906 15-07-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10946, current rewards: 148.89796, mean: 0.09545
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10954, current rewards: 153.97145, mean: 0.09563
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10961, current rewards: 159.03940, mean: 0.09581
[32m[0906 15-07-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10967, current rewards: 153.72128, mean: 0.08990
[32m[0906 15-07-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10974, current rewards: 159.22120, mean: 0.09047
[32m[0906 15-08-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10976, current rewards: 165.45012, mean: 0.09141
[32m[0906 15-08-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10970, current rewards: 171.06668, mean: 0.09197
[32m[0906 15-08-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10967, current rewards: 176.68268, mean: 0.09250
[32m[0906 15-08-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10963, current rewards: 182.29996, mean: 0.09301
[32m[0906 15-08-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10959, current rewards: 187.92233, mean: 0.09349
[32m[0906 15-08-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10956, current rewards: 193.54290, mean: 0.09395
[32m[0906 15-08-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10953, current rewards: 199.16287, mean: 0.09439
[32m[0906 15-08-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10949, current rewards: 194.36501, mean: 0.08998
[32m[0906 15-08-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10947, current rewards: 200.10281, mean: 0.09054
[32m[0906 15-08-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10952, current rewards: 205.86784, mean: 0.09109
[32m[0906 15-08-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10956, current rewards: 211.63164, mean: 0.09162
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10962, current rewards: 217.39453, mean: 0.09212
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10966, current rewards: 223.15968, mean: 0.09260
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10970, current rewards: 228.92369, mean: 0.09306
[32m[0906 15-09-19 @Agent.py:117][0m Average action selection time: 0.1097
[32m[0906 15-09-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-09-19 @MBExp.py:227][0m Rewards obtained: [233.53477050286614], Lows: [10], Highs: [10], Total time: 4967.198904999999
[32m[0906 15-10-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-03 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10857, current rewards: -4.28765, mean: -0.42877
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10842, current rewards: 1.80257, mean: 0.03004
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10786, current rewards: 7.44362, mean: 0.06767
[32m[0906 15-10-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10686, current rewards: 12.01062, mean: 0.07507
[32m[0906 15-10-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10625, current rewards: 16.63195, mean: 0.07920
[32m[0906 15-10-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10586, current rewards: 21.25095, mean: 0.08173
[32m[0906 15-10-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10583, current rewards: 25.87082, mean: 0.08345
[32m[0906 15-10-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10611, current rewards: 30.48935, mean: 0.08469
[32m[0906 15-10-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10633, current rewards: 35.10795, mean: 0.08563
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10658, current rewards: 39.72832, mean: 0.08637
[32m[0906 15-10-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10663, current rewards: 44.35063, mean: 0.08696
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10710, current rewards: 40.28336, mean: 0.07193
[32m[0906 15-11-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10752, current rewards: 46.94789, mean: 0.07696
[32m[0906 15-11-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10769, current rewards: 53.59878, mean: 0.08121
[32m[0906 15-11-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10771, current rewards: 60.25047, mean: 0.08486
[32m[0906 15-11-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10779, current rewards: 66.90289, mean: 0.08803
[32m[0906 15-11-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10780, current rewards: 73.55308, mean: 0.09081
[32m[0906 15-11-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10782, current rewards: 80.20259, mean: 0.09326
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10786, current rewards: 86.85769, mean: 0.09545
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10786, current rewards: 93.61860, mean: 0.09752
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10787, current rewards: 100.31097, mean: 0.09932
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10793, current rewards: 107.00204, mean: 0.10095
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10811, current rewards: 113.69645, mean: 0.10243
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10828, current rewards: 120.39018, mean: 0.10378
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10847, current rewards: 127.08364, mean: 0.10503
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10861, current rewards: 133.78027, mean: 0.10617
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10873, current rewards: 134.25599, mean: 0.10249
[32m[0906 15-12-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10888, current rewards: 140.54001, mean: 0.10334
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10899, current rewards: 146.50564, mean: 0.10390
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10907, current rewards: 152.47034, mean: 0.10443
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10918, current rewards: 158.43037, mean: 0.10492
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10926, current rewards: 164.39251, mean: 0.10538
[32m[0906 15-12-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10936, current rewards: 170.35703, mean: 0.10581
[32m[0906 15-13-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10941, current rewards: 176.32424, mean: 0.10622
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10946, current rewards: 182.29074, mean: 0.10660
[32m[0906 15-13-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10953, current rewards: 188.07386, mean: 0.10686
[32m[0906 15-13-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10955, current rewards: 193.72084, mean: 0.10703
[32m[0906 15-13-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10950, current rewards: 199.53951, mean: 0.10728
[32m[0906 15-13-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10948, current rewards: 205.35914, mean: 0.10752
[32m[0906 15-13-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10944, current rewards: 211.17794, mean: 0.10774
[32m[0906 15-13-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10940, current rewards: 206.48605, mean: 0.10273
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10937, current rewards: 212.51446, mean: 0.10316
[32m[0906 15-13-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10934, current rewards: 218.54719, mean: 0.10358
[32m[0906 15-14-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10930, current rewards: 224.57841, mean: 0.10397
[32m[0906 15-14-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10927, current rewards: 230.73627, mean: 0.10441
[32m[0906 15-14-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10930, current rewards: 236.77561, mean: 0.10477
[32m[0906 15-14-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10934, current rewards: 242.81876, mean: 0.10512
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10940, current rewards: 248.85686, mean: 0.10545
[32m[0906 15-14-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10944, current rewards: 254.89015, mean: 0.10576
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10948, current rewards: 260.92663, mean: 0.10607
[32m[0906 15-14-37 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-14-37 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-14-37 @MBExp.py:227][0m Rewards obtained: [265.7554555465379], Lows: [10], Highs: [10], Total time: 5241.737735
[32m[0906 15-15-24 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-24 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 15-15-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10782, current rewards: -9.18820, mean: -0.91882
[32m[0906 15-15-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10789, current rewards: -21.33622, mean: -0.35560
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10693, current rewards: -14.21991, mean: -0.12927
[32m[0906 15-15-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10637, current rewards: -8.15742, mean: -0.05098
[32m[0906 15-15-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10581, current rewards: -2.09763, mean: -0.00999
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10554, current rewards: 3.96746, mean: 0.01526
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10552, current rewards: 10.03273, mean: 0.03236
[32m[0906 15-16-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10581, current rewards: 4.65507, mean: 0.01293
[32m[0906 15-16-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10601, current rewards: 9.87266, mean: 0.02408
[32m[0906 15-16-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10624, current rewards: 15.08364, mean: 0.03279
[32m[0906 15-16-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10638, current rewards: 20.44363, mean: 0.04009
[32m[0906 15-16-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10677, current rewards: 25.95173, mean: 0.04634
[32m[0906 15-16-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10723, current rewards: 31.05027, mean: 0.05090
[32m[0906 15-16-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10737, current rewards: 36.15364, mean: 0.05478
[32m[0906 15-16-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10741, current rewards: 41.25649, mean: 0.05811
[32m[0906 15-16-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10747, current rewards: 46.35394, mean: 0.06099
[32m[0906 15-16-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10748, current rewards: 51.08756, mean: 0.06307
[32m[0906 15-16-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10750, current rewards: 55.94390, mean: 0.06505
[32m[0906 15-17-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10759, current rewards: 60.79667, mean: 0.06681
[32m[0906 15-17-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10761, current rewards: 65.12028, mean: 0.06783
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10761, current rewards: 69.77319, mean: 0.06908
[32m[0906 15-17-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10768, current rewards: 74.41964, mean: 0.07021
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10785, current rewards: 79.06944, mean: 0.07123
[32m[0906 15-17-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10805, current rewards: 83.71927, mean: 0.07217
[32m[0906 15-17-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10825, current rewards: 88.37304, mean: 0.07304
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10839, current rewards: 93.02734, mean: 0.07383
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10853, current rewards: 97.68184, mean: 0.07457
[32m[0906 15-17-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10863, current rewards: 102.56312, mean: 0.07541
[32m[0906 15-17-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10875, current rewards: 107.27539, mean: 0.07608
[32m[0906 15-18-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10885, current rewards: 111.98893, mean: 0.07670
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10894, current rewards: 106.61819, mean: 0.07061
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10901, current rewards: 111.85492, mean: 0.07170
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10910, current rewards: 117.08872, mean: 0.07273
[32m[0906 15-18-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10915, current rewards: 122.32480, mean: 0.07369
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10921, current rewards: 127.55747, mean: 0.07460
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10930, current rewards: 133.17685, mean: 0.07567
[32m[0906 15-18-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10933, current rewards: 138.72585, mean: 0.07664
[32m[0906 15-18-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10929, current rewards: 143.83731, mean: 0.07733
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10926, current rewards: 148.94877, mean: 0.07798
[32m[0906 15-18-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10923, current rewards: 154.06021, mean: 0.07860
[32m[0906 15-19-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10920, current rewards: 151.88921, mean: 0.07557
[32m[0906 15-19-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10919, current rewards: 157.07499, mean: 0.07625
[32m[0906 15-19-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10914, current rewards: 162.26327, mean: 0.07690
[32m[0906 15-19-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10911, current rewards: 167.44886, mean: 0.07752
[32m[0906 15-19-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10909, current rewards: 172.46414, mean: 0.07804
[32m[0906 15-19-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10906, current rewards: 178.34575, mean: 0.07891
[32m[0906 15-19-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10913, current rewards: 184.22641, mean: 0.07975
[32m[0906 15-19-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10919, current rewards: 190.10149, mean: 0.08055
[32m[0906 15-19-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10923, current rewards: 190.64495, mean: 0.07911
[32m[0906 15-19-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10930, current rewards: 196.74497, mean: 0.07998
[32m[0906 15-19-58 @Agent.py:117][0m Average action selection time: 0.1093
[32m[0906 15-19-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-19-58 @MBExp.py:227][0m Rewards obtained: [201.62930480607017], Lows: [22], Highs: [18], Total time: 5515.789371999999
[32m[0906 15-20-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-20-46 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 15-20-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10691, current rewards: -5.55027, mean: -0.55503
[32m[0906 15-20-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10761, current rewards: 0.02613, mean: 0.00044
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10669, current rewards: 5.99437, mean: 0.05449
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10586, current rewards: 12.57314, mean: 0.07858
[32m[0906 15-21-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10535, current rewards: 18.49029, mean: 0.08805
[32m[0906 15-21-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10522, current rewards: 24.40073, mean: 0.09385
[32m[0906 15-21-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10508, current rewards: 30.31649, mean: 0.09780
[32m[0906 15-21-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10538, current rewards: 36.23175, mean: 0.10064
[32m[0906 15-21-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10577, current rewards: 42.14429, mean: 0.10279
[32m[0906 15-21-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10597, current rewards: 48.05778, mean: 0.10447
[32m[0906 15-21-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10617, current rewards: 53.97144, mean: 0.10583
[32m[0906 15-21-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10663, current rewards: 53.95721, mean: 0.09635
[32m[0906 15-21-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10706, current rewards: 58.67687, mean: 0.09619
[32m[0906 15-21-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10706, current rewards: 63.39052, mean: 0.09605
[32m[0906 15-22-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10717, current rewards: 68.09934, mean: 0.09591
[32m[0906 15-22-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10721, current rewards: 72.80944, mean: 0.09580
[32m[0906 15-22-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10725, current rewards: 77.51651, mean: 0.09570
[32m[0906 15-22-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10730, current rewards: 82.23080, mean: 0.09562
[32m[0906 15-22-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10732, current rewards: 86.94043, mean: 0.09554
[32m[0906 15-22-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10734, current rewards: 91.87884, mean: 0.09571
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10738, current rewards: 96.70665, mean: 0.09575
[32m[0906 15-22-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10740, current rewards: 101.17940, mean: 0.09545
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10758, current rewards: 105.64959, mean: 0.09518
[32m[0906 15-22-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10778, current rewards: 100.87754, mean: 0.08696
[32m[0906 15-22-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10792, current rewards: 106.53566, mean: 0.08805
[32m[0906 15-23-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10806, current rewards: 112.19065, mean: 0.08904
[32m[0906 15-23-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10822, current rewards: 117.84570, mean: 0.08996
[32m[0906 15-23-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10834, current rewards: 123.50155, mean: 0.09081
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10848, current rewards: 129.15654, mean: 0.09160
[32m[0906 15-23-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10858, current rewards: 134.81400, mean: 0.09234
[32m[0906 15-23-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10867, current rewards: 140.47161, mean: 0.09303
[32m[0906 15-23-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10877, current rewards: 146.12581, mean: 0.09367
[32m[0906 15-23-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10885, current rewards: 151.78336, mean: 0.09428
[32m[0906 15-23-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10891, current rewards: 157.44195, mean: 0.09484
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10900, current rewards: 157.65696, mean: 0.09220
[32m[0906 15-23-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10906, current rewards: 163.35650, mean: 0.09282
[32m[0906 15-24-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10909, current rewards: 169.05052, mean: 0.09340
[32m[0906 15-24-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10906, current rewards: 174.74912, mean: 0.09395
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10902, current rewards: 180.43836, mean: 0.09447
[32m[0906 15-24-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10897, current rewards: 186.12473, mean: 0.09496
[32m[0906 15-24-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10894, current rewards: 181.67785, mean: 0.09039
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10891, current rewards: 187.30358, mean: 0.09092
[32m[0906 15-24-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10889, current rewards: 192.92893, mean: 0.09144
[32m[0906 15-24-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10888, current rewards: 198.55381, mean: 0.09192
[32m[0906 15-24-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10886, current rewards: 204.40564, mean: 0.09249
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10884, current rewards: 210.00086, mean: 0.09292
[32m[0906 15-24-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10889, current rewards: 206.36642, mean: 0.08934
[32m[0906 15-25-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10893, current rewards: 211.78153, mean: 0.08974
[32m[0906 15-25-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10899, current rewards: 217.19349, mean: 0.09012
[32m[0906 15-25-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10906, current rewards: 222.59606, mean: 0.09049
[32m[0906 15-25-20 @Agent.py:117][0m Average action selection time: 0.1091
[32m[0906 15-25-20 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-25-20 @MBExp.py:227][0m Rewards obtained: [226.92486393441882], Lows: [10], Highs: [25], Total time: 5789.270608999999
[32m[0906 15-26-10 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-10 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 15-26-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10736, current rewards: -7.80663, mean: -0.78066
[32m[0906 15-26-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10757, current rewards: -1.70971, mean: -0.02850
[32m[0906 15-26-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10598, current rewards: 3.56437, mean: 0.03240
[32m[0906 15-26-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10535, current rewards: 9.21782, mean: 0.05761
[32m[0906 15-26-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10517, current rewards: 14.86447, mean: 0.07078
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10495, current rewards: 20.51584, mean: 0.07891
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10485, current rewards: 26.16815, mean: 0.08441
[32m[0906 15-26-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10522, current rewards: 27.47448, mean: 0.07632
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10547, current rewards: 33.67678, mean: 0.08214
[32m[0906 15-26-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10570, current rewards: 39.87837, mean: 0.08669
[32m[0906 15-27-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10590, current rewards: 45.59667, mean: 0.08941
[32m[0906 15-27-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10629, current rewards: 52.04169, mean: 0.09293
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10657, current rewards: 58.57433, mean: 0.09602
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10671, current rewards: 65.11089, mean: 0.09865
[32m[0906 15-27-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10679, current rewards: 71.64896, mean: 0.10091
[32m[0906 15-27-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10694, current rewards: 78.17590, mean: 0.10286
[32m[0906 15-27-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10702, current rewards: 67.87103, mean: 0.08379
[32m[0906 15-27-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10707, current rewards: 54.61262, mean: 0.06350
[32m[0906 15-27-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10709, current rewards: 43.46435, mean: 0.04776
[32m[0906 15-27-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10714, current rewards: 40.00419, mean: 0.04167
[32m[0906 15-27-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10718, current rewards: 45.63060, mean: 0.04518
[32m[0906 15-28-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10722, current rewards: 51.26206, mean: 0.04836
[32m[0906 15-28-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10740, current rewards: 56.88900, mean: 0.05125
[32m[0906 15-28-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10758, current rewards: 62.51642, mean: 0.05389
[32m[0906 15-28-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10776, current rewards: 63.91859, mean: 0.05283
[32m[0906 15-28-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10793, current rewards: 64.53575, mean: 0.05122
[32m[0906 15-28-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10809, current rewards: 70.10781, mean: 0.05352
[32m[0906 15-28-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10825, current rewards: 74.99385, mean: 0.05514
[32m[0906 15-28-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10838, current rewards: 80.02103, mean: 0.05675
[32m[0906 15-28-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10850, current rewards: 65.83520, mean: 0.04509
[32m[0906 15-28-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10864, current rewards: 56.18180, mean: 0.03721
[32m[0906 15-29-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10876, current rewards: 46.43578, mean: 0.02977
[32m[0906 15-29-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10886, current rewards: 34.51744, mean: 0.02144
[32m[0906 15-29-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10898, current rewards: 24.72134, mean: 0.01489
[32m[0906 15-29-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10908, current rewards: 14.96792, mean: 0.00875
[32m[0906 15-29-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10915, current rewards: 3.26755, mean: 0.00186
[32m[0906 15-29-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10921, current rewards: -3.42237, mean: -0.00189
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10919, current rewards: 2.19848, mean: 0.00118
[32m[0906 15-29-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10917, current rewards: 7.81423, mean: 0.00409
[32m[0906 15-29-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10916, current rewards: 13.43363, mean: 0.00685
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10911, current rewards: 19.04789, mean: 0.00948
[32m[0906 15-29-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10907, current rewards: 24.66622, mean: 0.01197
[32m[0906 15-30-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10907, current rewards: 30.28731, mean: 0.01435
[32m[0906 15-30-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10903, current rewards: 35.90737, mean: 0.01662
[32m[0906 15-30-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10900, current rewards: 41.65815, mean: 0.01885
[32m[0906 15-30-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10898, current rewards: 47.29236, mean: 0.02093
[32m[0906 15-30-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10898, current rewards: 52.92159, mean: 0.02291
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10905, current rewards: 58.55714, mean: 0.02481
[32m[0906 15-30-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10910, current rewards: 64.18588, mean: 0.02663
[32m[0906 15-30-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10915, current rewards: 69.82061, mean: 0.02838
[32m[0906 15-30-44 @Agent.py:117][0m Average action selection time: 0.1092
[32m[0906 15-30-44 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-30-44 @MBExp.py:227][0m Rewards obtained: [74.32556458706598], Lows: [99], Highs: [16], Total time: 6062.955832
[32m[0906 15-31-37 @MBExp.py:144][0m ####################################################################
[32m[0906 15-31-37 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 15-31-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10739, current rewards: -5.61114, mean: -0.56111
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10552, current rewards: -0.06056, mean: -0.00101
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10509, current rewards: 5.23590, mean: 0.04760
[32m[0906 15-31-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10486, current rewards: 10.76777, mean: 0.06730
[32m[0906 15-31-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10475, current rewards: 16.29797, mean: 0.07761
[32m[0906 15-32-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10464, current rewards: 21.82796, mean: 0.08395
[32m[0906 15-32-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10459, current rewards: 27.35241, mean: 0.08823
[32m[0906 15-32-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10493, current rewards: 32.88870, mean: 0.09136
[32m[0906 15-32-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10544, current rewards: 38.01237, mean: 0.09271
[32m[0906 15-32-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10570, current rewards: 43.29736, mean: 0.09412
[32m[0906 15-32-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10588, current rewards: 49.42795, mean: 0.09692
[32m[0906 15-32-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10632, current rewards: 54.82428, mean: 0.09790
[32m[0906 15-32-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10651, current rewards: 60.21890, mean: 0.09872
[32m[0906 15-32-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10659, current rewards: 65.60973, mean: 0.09941
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10674, current rewards: 60.33463, mean: 0.08498
[32m[0906 15-32-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10685, current rewards: 65.28141, mean: 0.08590
[32m[0906 15-33-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10691, current rewards: 70.22731, mean: 0.08670
[32m[0906 15-33-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10700, current rewards: 75.17372, mean: 0.08741
[32m[0906 15-33-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10703, current rewards: 80.06592, mean: 0.08798
[32m[0906 15-33-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10708, current rewards: 85.00820, mean: 0.08855
[32m[0906 15-33-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10715, current rewards: 89.93745, mean: 0.08905
[32m[0906 15-33-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10719, current rewards: 94.86610, mean: 0.08950
[32m[0906 15-33-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10734, current rewards: 99.79515, mean: 0.08991
[32m[0906 15-33-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10755, current rewards: 99.32712, mean: 0.08563
[32m[0906 15-33-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10774, current rewards: 104.40565, mean: 0.08629
[32m[0906 15-33-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10790, current rewards: 109.48354, mean: 0.08689
[32m[0906 15-33-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10808, current rewards: 114.50898, mean: 0.08741
[32m[0906 15-34-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10822, current rewards: 119.51698, mean: 0.08788
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10833, current rewards: 124.84076, mean: 0.08854
[32m[0906 15-34-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10846, current rewards: 130.16442, mean: 0.08915
[32m[0906 15-34-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10856, current rewards: 135.48846, mean: 0.08973
[32m[0906 15-34-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10868, current rewards: 140.81276, mean: 0.09026
[32m[0906 15-34-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10877, current rewards: 146.13877, mean: 0.09077
[32m[0906 15-34-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10887, current rewards: 151.46919, mean: 0.09125
[32m[0906 15-34-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10897, current rewards: 156.79725, mean: 0.09169
[32m[0906 15-34-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10905, current rewards: 162.59863, mean: 0.09239
[32m[0906 15-34-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10907, current rewards: 157.23692, mean: 0.08687
[32m[0906 15-35-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10906, current rewards: 163.55234, mean: 0.08793
[32m[0906 15-35-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10903, current rewards: 169.86777, mean: 0.08894
[32m[0906 15-35-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10900, current rewards: 176.18320, mean: 0.08989
[32m[0906 15-35-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10898, current rewards: 140.82521, mean: 0.07006
[32m[0906 15-35-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10894, current rewards: 90.82521, mean: 0.04409
[32m[0906 15-35-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10890, current rewards: 40.82521, mean: 0.01935
[32m[0906 15-35-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10889, current rewards: -9.17479, mean: -0.00425
[32m[0906 15-35-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10887, current rewards: -59.17479, mean: -0.02678
[32m[0906 15-35-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10883, current rewards: -109.17479, mean: -0.04831
[32m[0906 15-35-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10882, current rewards: -159.17479, mean: -0.06891
[32m[0906 15-35-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10888, current rewards: -209.17479, mean: -0.08863
[32m[0906 15-36-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10893, current rewards: -259.17479, mean: -0.10754
[32m[0906 15-36-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10899, current rewards: -309.17479, mean: -0.12568
[32m[0906 15-36-10 @Agent.py:117][0m Average action selection time: 0.1090
[32m[0906 15-36-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-36-10 @MBExp.py:227][0m Rewards obtained: [-349.1747935783746], Lows: [11], Highs: [538], Total time: 6336.229665
[32m[0906 15-37-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-37-06 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10850, current rewards: -4.23307, mean: -0.42331
[32m[0906 15-37-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10510, current rewards: 1.24782, mean: 0.02080
[32m[0906 15-37-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10471, current rewards: 6.65920, mean: 0.06054
[32m[0906 15-37-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10454, current rewards: 12.12292, mean: 0.07577
[32m[0906 15-37-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10450, current rewards: 17.58163, mean: 0.08372
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10457, current rewards: 23.04242, mean: 0.08862
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10468, current rewards: 28.49935, mean: 0.09193
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10482, current rewards: 33.95966, mean: 0.09433
[32m[0906 15-37-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10513, current rewards: 42.70811, mean: 0.10417
[32m[0906 15-37-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10548, current rewards: 48.24095, mean: 0.10487
[32m[0906 15-38-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10570, current rewards: 53.22153, mean: 0.10436
[32m[0906 15-38-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10600, current rewards: 58.53460, mean: 0.10453
[32m[0906 15-38-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10619, current rewards: 63.84164, mean: 0.10466
[32m[0906 15-38-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10630, current rewards: 69.14996, mean: 0.10477
[32m[0906 15-38-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10639, current rewards: 74.46276, mean: 0.10488
[32m[0906 15-38-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10651, current rewards: 69.25220, mean: 0.09112
[32m[0906 15-38-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10655, current rewards: 74.58476, mean: 0.09208
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10658, current rewards: 79.92418, mean: 0.09294
[32m[0906 15-38-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10666, current rewards: 85.44015, mean: 0.09389
[32m[0906 15-38-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10672, current rewards: 90.82768, mean: 0.09461
[32m[0906 15-38-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10674, current rewards: 96.20998, mean: 0.09526
[32m[0906 15-38-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10678, current rewards: 101.59150, mean: 0.09584
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10694, current rewards: 106.97693, mean: 0.09638
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10713, current rewards: 101.87096, mean: 0.08782
[32m[0906 15-39-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10733, current rewards: 107.08219, mean: 0.08850
[32m[0906 15-39-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10749, current rewards: 112.29952, mean: 0.08913
[32m[0906 15-39-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10762, current rewards: 117.86125, mean: 0.08997
[32m[0906 15-39-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10779, current rewards: 123.11849, mean: 0.09053
[32m[0906 15-39-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10791, current rewards: 128.37030, mean: 0.09104
[32m[0906 15-39-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10802, current rewards: 133.62207, mean: 0.09152
[32m[0906 15-39-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10814, current rewards: 138.87373, mean: 0.09197
[32m[0906 15-39-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10823, current rewards: 144.12878, mean: 0.09239
[32m[0906 15-40-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10835, current rewards: 139.68062, mean: 0.08676
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10844, current rewards: 144.99010, mean: 0.08734
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10852, current rewards: 150.35878, mean: 0.08793
[32m[0906 15-40-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10861, current rewards: 155.65606, mean: 0.08844
[32m[0906 15-40-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10864, current rewards: 160.95186, mean: 0.08892
[32m[0906 15-40-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10860, current rewards: 166.24346, mean: 0.08938
[32m[0906 15-40-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10859, current rewards: 171.54431, mean: 0.08981
[32m[0906 15-40-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10856, current rewards: 167.07778, mean: 0.08524
[32m[0906 15-40-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10852, current rewards: 173.53661, mean: 0.08634
[32m[0906 15-40-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10850, current rewards: 179.99543, mean: 0.08738
[32m[0906 15-40-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10847, current rewards: 186.21791, mean: 0.08825
[32m[0906 15-41-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10845, current rewards: 189.12412, mean: 0.08756
[32m[0906 15-41-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10843, current rewards: 191.93911, mean: 0.08685
[32m[0906 15-41-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10840, current rewards: 194.75409, mean: 0.08617
[32m[0906 15-41-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10837, current rewards: 197.56908, mean: 0.08553
[32m[0906 15-41-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10840, current rewards: 200.38406, mean: 0.08491
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10846, current rewards: 203.19904, mean: 0.08431
[32m[0906 15-41-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10852, current rewards: 206.01403, mean: 0.08375
[32m[0906 15-41-38 @Agent.py:117][0m Average action selection time: 0.1086
[32m[0906 15-41-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-41-38 @MBExp.py:227][0m Rewards obtained: [208.26601707784104], Lows: [20], Highs: [5], Total time: 6608.395098
[32m[0906 15-42-35 @MBExp.py:144][0m ####################################################################
[32m[0906 15-42-35 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 15-42-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10308, current rewards: -3.83617, mean: -0.38362
[32m[0906 15-42-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10453, current rewards: 2.58805, mean: 0.04313
[32m[0906 15-42-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10458, current rewards: 7.84690, mean: 0.07134
[32m[0906 15-42-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10448, current rewards: 13.11165, mean: 0.08195
[32m[0906 15-42-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10450, current rewards: 18.38383, mean: 0.08754
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10446, current rewards: 23.65084, mean: 0.09096
[32m[0906 15-43-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10442, current rewards: 28.91765, mean: 0.09328
[32m[0906 15-43-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10467, current rewards: 34.18921, mean: 0.09497
[32m[0906 15-43-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10516, current rewards: 39.46249, mean: 0.09625
[32m[0906 15-43-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10548, current rewards: 44.59214, mean: 0.09694
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10581, current rewards: 41.17712, mean: 0.08074
[32m[0906 15-43-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10601, current rewards: 44.66846, mean: 0.07977
[32m[0906 15-43-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10619, current rewards: 50.25305, mean: 0.08238
[32m[0906 15-43-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10636, current rewards: 55.83433, mean: 0.08460
[32m[0906 15-43-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10644, current rewards: 61.41756, mean: 0.08650
[32m[0906 15-43-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10652, current rewards: 67.00060, mean: 0.08816
[32m[0906 15-44-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10662, current rewards: 72.58154, mean: 0.08961
[32m[0906 15-44-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10667, current rewards: 78.16385, mean: 0.09089
[32m[0906 15-44-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10672, current rewards: 83.68434, mean: 0.09196
[32m[0906 15-44-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10681, current rewards: 89.27684, mean: 0.09300
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10686, current rewards: 94.86665, mean: 0.09393
[32m[0906 15-44-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10691, current rewards: 100.46134, mean: 0.09477
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10708, current rewards: 106.05074, mean: 0.09554
[32m[0906 15-44-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10728, current rewards: 104.07862, mean: 0.08972
[32m[0906 15-44-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10745, current rewards: 108.75442, mean: 0.08988
[32m[0906 15-44-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10764, current rewards: 113.37255, mean: 0.08998
[32m[0906 15-44-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10780, current rewards: 118.08435, mean: 0.09014
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10793, current rewards: 122.71121, mean: 0.09023
[32m[0906 15-45-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10805, current rewards: 127.33931, mean: 0.09031
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10815, current rewards: 131.96786, mean: 0.09039
[32m[0906 15-45-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10827, current rewards: 136.59498, mean: 0.09046
[32m[0906 15-45-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10836, current rewards: 141.22020, mean: 0.09053
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10845, current rewards: 145.84665, mean: 0.09059
[32m[0906 15-45-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10853, current rewards: 150.47592, mean: 0.09065
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10861, current rewards: 154.98521, mean: 0.09063
[32m[0906 15-45-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10868, current rewards: 159.60476, mean: 0.09068
[32m[0906 15-45-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10873, current rewards: 164.26344, mean: 0.09075
[32m[0906 15-45-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10869, current rewards: 169.41697, mean: 0.09108
[32m[0906 15-46-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10865, current rewards: 174.55310, mean: 0.09139
[32m[0906 15-46-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10863, current rewards: 179.69176, mean: 0.09168
[32m[0906 15-46-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10860, current rewards: 184.82375, mean: 0.09195
[32m[0906 15-46-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10859, current rewards: 189.95519, mean: 0.09221
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10858, current rewards: 195.32476, mean: 0.09257
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10856, current rewards: 200.37789, mean: 0.09277
[32m[0906 15-46-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10854, current rewards: 205.43622, mean: 0.09296
[32m[0906 15-46-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10853, current rewards: 210.49541, mean: 0.09314
[32m[0906 15-46-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10851, current rewards: 215.55660, mean: 0.09331
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10850, current rewards: 210.61080, mean: 0.08924
[32m[0906 15-46-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10858, current rewards: 216.80507, mean: 0.08996
[32m[0906 15-47-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10863, current rewards: 222.99276, mean: 0.09065
[32m[0906 15-47-08 @Agent.py:117][0m Average action selection time: 0.1087
[32m[0906 15-47-08 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-47-08 @MBExp.py:227][0m Rewards obtained: [227.94154603860085], Lows: [11], Highs: [12], Total time: 6880.81941
[32m[0906 15-48-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-48-08 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 15-48-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10314, current rewards: -4.30464, mean: -0.43046
[32m[0906 15-48-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10474, current rewards: 1.62499, mean: 0.02708
[32m[0906 15-48-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10434, current rewards: 7.72286, mean: 0.07021
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10414, current rewards: 13.81885, mean: 0.08637
[32m[0906 15-48-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10433, current rewards: 19.91810, mean: 0.09485
[32m[0906 15-48-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10419, current rewards: 26.01431, mean: 0.10006
[32m[0906 15-48-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10413, current rewards: 32.10513, mean: 0.10356
[32m[0906 15-48-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10431, current rewards: 38.20024, mean: 0.10611
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10468, current rewards: 33.61887, mean: 0.08200
[32m[0906 15-48-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10494, current rewards: 39.43523, mean: 0.08573
[32m[0906 15-49-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10526, current rewards: 44.90102, mean: 0.08804
[32m[0906 15-49-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10532, current rewards: 50.37597, mean: 0.08996
[32m[0906 15-49-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10552, current rewards: 55.84258, mean: 0.09155
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10572, current rewards: 61.30814, mean: 0.09289
[32m[0906 15-49-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10588, current rewards: 66.77657, mean: 0.09405
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10599, current rewards: 63.64723, mean: 0.08375
[32m[0906 15-49-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10614, current rewards: 69.37810, mean: 0.08565
[32m[0906 15-49-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10622, current rewards: 74.37940, mean: 0.08649
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10630, current rewards: 80.03871, mean: 0.08795
[32m[0906 15-49-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10641, current rewards: 85.70120, mean: 0.08927
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10648, current rewards: 91.36387, mean: 0.09046
[32m[0906 15-50-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10654, current rewards: 97.02223, mean: 0.09153
[32m[0906 15-50-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10674, current rewards: 97.22306, mean: 0.08759
[32m[0906 15-50-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10697, current rewards: 102.98511, mean: 0.08878
[32m[0906 15-50-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10716, current rewards: 108.75117, mean: 0.08988
[32m[0906 15-50-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10738, current rewards: 115.20147, mean: 0.09143
[32m[0906 15-50-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10754, current rewards: 121.95252, mean: 0.09309
[32m[0906 15-50-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10770, current rewards: 127.95243, mean: 0.09408
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10787, current rewards: 128.39772, mean: 0.09106
[32m[0906 15-50-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10802, current rewards: 134.30316, mean: 0.09199
[32m[0906 15-50-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10815, current rewards: 140.21288, mean: 0.09286
[32m[0906 15-50-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10828, current rewards: 146.12800, mean: 0.09367
[32m[0906 15-51-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10839, current rewards: 152.03961, mean: 0.09443
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10853, current rewards: 157.95329, mean: 0.09515
[32m[0906 15-51-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10864, current rewards: 163.25890, mean: 0.09547
[32m[0906 15-51-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10873, current rewards: 169.14021, mean: 0.09610
[32m[0906 15-51-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10879, current rewards: 174.73653, mean: 0.09654
[32m[0906 15-51-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10877, current rewards: 180.56202, mean: 0.09708
[32m[0906 15-51-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10874, current rewards: 186.37990, mean: 0.09758
[32m[0906 15-51-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10873, current rewards: 192.18756, mean: 0.09805
[32m[0906 15-51-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10871, current rewards: 198.00549, mean: 0.09851
[32m[0906 15-51-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10871, current rewards: 203.82885, mean: 0.09895
[32m[0906 15-51-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10871, current rewards: 210.18180, mean: 0.09961
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10869, current rewards: 216.24034, mean: 0.10011
[32m[0906 15-52-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10868, current rewards: 211.89531, mean: 0.09588
[32m[0906 15-52-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10868, current rewards: 217.88326, mean: 0.09641
[32m[0906 15-52-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10867, current rewards: 223.87141, mean: 0.09691
[32m[0906 15-52-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10866, current rewards: 229.85983, mean: 0.09740
[32m[0906 15-52-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10873, current rewards: 235.84356, mean: 0.09786
[32m[0906 15-52-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10878, current rewards: 241.83174, mean: 0.09831
[32m[0906 15-52-40 @Agent.py:117][0m Average action selection time: 0.1088
[32m[0906 15-52-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-52-40 @MBExp.py:227][0m Rewards obtained: [241.79835666132462], Lows: [15], Highs: [20], Total time: 7153.603077
[32m[0906 15-53-43 @MBExp.py:144][0m ####################################################################
[32m[0906 15-53-43 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 15-53-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10476, current rewards: -8.82771, mean: -0.88277
[32m[0906 15-53-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10502, current rewards: -4.70250, mean: -0.07837
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10453, current rewards: 0.74853, mean: 0.00680
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10450, current rewards: 6.20552, mean: 0.03878
[32m[0906 15-54-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10467, current rewards: 11.65153, mean: 0.05548
[32m[0906 15-54-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10464, current rewards: 17.04850, mean: 0.06557
[32m[0906 15-54-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10456, current rewards: 22.53586, mean: 0.07270
[32m[0906 15-54-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10468, current rewards: 28.17845, mean: 0.07827
[32m[0906 15-54-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10503, current rewards: 33.81793, mean: 0.08248
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10535, current rewards: 39.29656, mean: 0.08543
[32m[0906 15-54-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10556, current rewards: 44.91658, mean: 0.08807
[32m[0906 15-54-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10556, current rewards: 50.54017, mean: 0.09025
[32m[0906 15-54-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10575, current rewards: 56.15380, mean: 0.09206
[32m[0906 15-54-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10599, current rewards: 61.77601, mean: 0.09360
[32m[0906 15-54-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10613, current rewards: 56.88967, mean: 0.08013
[32m[0906 15-55-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10626, current rewards: 62.30378, mean: 0.08198
[32m[0906 15-55-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10637, current rewards: 67.71957, mean: 0.08360
[32m[0906 15-55-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10645, current rewards: 72.71107, mean: 0.08455
[32m[0906 15-55-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10651, current rewards: 77.91615, mean: 0.08562
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10661, current rewards: 83.15742, mean: 0.08662
[32m[0906 15-55-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10670, current rewards: 88.39406, mean: 0.08752
[32m[0906 15-55-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10676, current rewards: 93.63720, mean: 0.08834
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10693, current rewards: 98.87974, mean: 0.08908
[32m[0906 15-55-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10714, current rewards: 104.11959, mean: 0.08976
[32m[0906 15-55-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10733, current rewards: 109.36164, mean: 0.09038
[32m[0906 15-55-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10755, current rewards: 114.60472, mean: 0.09096
[32m[0906 15-56-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10774, current rewards: 110.00115, mean: 0.08397
[32m[0906 15-56-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10790, current rewards: 116.47809, mean: 0.08565
[32m[0906 15-56-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10805, current rewards: 122.82166, mean: 0.08711
[32m[0906 15-56-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10818, current rewards: 129.15453, mean: 0.08846
[32m[0906 15-56-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10831, current rewards: 135.48759, mean: 0.08973
[32m[0906 15-56-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10842, current rewards: 141.81622, mean: 0.09091
[32m[0906 15-56-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10852, current rewards: 148.13964, mean: 0.09201
[32m[0906 15-56-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10864, current rewards: 154.47544, mean: 0.09306
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10873, current rewards: 150.08267, mean: 0.08777
[32m[0906 15-56-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10881, current rewards: 155.54922, mean: 0.08838
[32m[0906 15-57-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10884, current rewards: 161.01011, mean: 0.08896
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10882, current rewards: 166.47346, mean: 0.08950
[32m[0906 15-57-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10880, current rewards: 171.93627, mean: 0.09002
[32m[0906 15-57-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10879, current rewards: 177.39659, mean: 0.09051
[32m[0906 15-57-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10877, current rewards: 182.85978, mean: 0.09098
[32m[0906 15-57-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10878, current rewards: 188.32162, mean: 0.09142
[32m[0906 15-57-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10881, current rewards: 193.87422, mean: 0.09188
[32m[0906 15-57-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10881, current rewards: 199.34446, mean: 0.09229
[32m[0906 15-57-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10877, current rewards: 199.28509, mean: 0.09017
[32m[0906 15-57-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10875, current rewards: 204.70564, mean: 0.09058
[32m[0906 15-57-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10873, current rewards: 210.12789, mean: 0.09096
[32m[0906 15-58-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10870, current rewards: 215.54682, mean: 0.09133
[32m[0906 15-58-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10872, current rewards: 220.96695, mean: 0.09169
[32m[0906 15-58-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10877, current rewards: 226.38994, mean: 0.09203
[32m[0906 15-58-15 @Agent.py:117][0m Average action selection time: 0.1088
[32m[0906 15-58-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-58-15 @MBExp.py:227][0m Rewards obtained: [230.88129888570808], Lows: [18], Highs: [11], Total time: 7426.348179
[32m[0906 15-59-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-59-19 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 15-59-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10505, current rewards: -4.39871, mean: -0.43987
[32m[0906 15-59-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10439, current rewards: 1.67174, mean: 0.02786
[32m[0906 15-59-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10442, current rewards: 8.05599, mean: 0.07324
[32m[0906 15-59-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10425, current rewards: 14.43972, mean: 0.09025
[32m[0906 15-59-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10424, current rewards: 20.83636, mean: 0.09922
[32m[0906 15-59-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10414, current rewards: 27.22574, mean: 0.10471
[32m[0906 15-59-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10410, current rewards: 33.62423, mean: 0.10847
[32m[0906 15-59-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10417, current rewards: 28.96841, mean: 0.08047
[32m[0906 16-00-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10459, current rewards: 35.00427, mean: 0.08538
[32m[0906 16-00-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10491, current rewards: 41.04414, mean: 0.08923
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10492, current rewards: 47.08373, mean: 0.09232
[32m[0906 16-00-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10492, current rewards: 53.12685, mean: 0.09487
[32m[0906 16-00-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10513, current rewards: 59.16335, mean: 0.09699
[32m[0906 16-00-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10533, current rewards: 65.20671, mean: 0.09880
[32m[0906 16-00-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10549, current rewards: 71.24660, mean: 0.10035
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10564, current rewards: 77.28702, mean: 0.10169
[32m[0906 16-00-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10575, current rewards: 83.17497, mean: 0.10269
[32m[0906 16-00-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10587, current rewards: 89.20317, mean: 0.10372
[32m[0906 16-00-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10598, current rewards: 95.23223, mean: 0.10465
[32m[0906 16-01-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10606, current rewards: 90.73041, mean: 0.09451
[32m[0906 16-01-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10611, current rewards: 97.06111, mean: 0.09610
[32m[0906 16-01-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10620, current rewards: 103.39552, mean: 0.09754
[32m[0906 16-01-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10640, current rewards: 109.72940, mean: 0.09886
[32m[0906 16-01-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10662, current rewards: 116.06248, mean: 0.10005
[32m[0906 16-01-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10684, current rewards: 122.80351, mean: 0.10149
[32m[0906 16-01-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10700, current rewards: 129.59949, mean: 0.10286
[32m[0906 16-01-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10717, current rewards: 135.75243, mean: 0.10363
[32m[0906 16-01-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10734, current rewards: 141.91625, mean: 0.10435
[32m[0906 16-01-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10746, current rewards: 143.08549, mean: 0.10148
[32m[0906 16-01-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10758, current rewards: 149.27116, mean: 0.10224
[32m[0906 16-02-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10773, current rewards: 155.45109, mean: 0.10295
[32m[0906 16-02-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10783, current rewards: 161.63101, mean: 0.10361
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10793, current rewards: 167.81395, mean: 0.10423
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10803, current rewards: 163.28476, mean: 0.09836
[32m[0906 16-02-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10812, current rewards: 169.38890, mean: 0.09906
[32m[0906 16-02-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10821, current rewards: 175.49251, mean: 0.09971
[32m[0906 16-02-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10823, current rewards: 181.59762, mean: 0.10033
[32m[0906 16-02-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10820, current rewards: 187.70243, mean: 0.10092
[32m[0906 16-02-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10819, current rewards: 193.80288, mean: 0.10147
[32m[0906 16-02-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10818, current rewards: 199.90929, mean: 0.10199
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10815, current rewards: 206.01046, mean: 0.10249
[32m[0906 16-03-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10814, current rewards: 211.88098, mean: 0.10285
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10813, current rewards: 217.94975, mean: 0.10329
[32m[0906 16-03-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10812, current rewards: 213.41888, mean: 0.09881
[32m[0906 16-03-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10813, current rewards: 219.11506, mean: 0.09915
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10811, current rewards: 224.81253, mean: 0.09947
[32m[0906 16-03-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10811, current rewards: 230.51125, mean: 0.09979
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10810, current rewards: 236.20782, mean: 0.10009
[32m[0906 16-03-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10812, current rewards: 241.90704, mean: 0.10038
[32m[0906 16-03-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10820, current rewards: 249.37013, mean: 0.10137
[32m[0906 16-03-51 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 16-03-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-03-51 @MBExp.py:227][0m Rewards obtained: [255.82956309804294], Lows: [20], Highs: [10], Total time: 7697.7371809999995
[32m[0906 16-04-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-04-57 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 16-04-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10299, current rewards: -4.05717, mean: -0.40572
[32m[0906 16-05-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10384, current rewards: 1.54839, mean: 0.02581
[32m[0906 16-05-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10416, current rewards: 6.75112, mean: 0.06137
[32m[0906 16-05-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10426, current rewards: 11.95653, mean: 0.07473
[32m[0906 16-05-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10418, current rewards: 8.01494, mean: 0.03817
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10413, current rewards: 13.67796, mean: 0.05261
[32m[0906 16-05-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10419, current rewards: 19.33807, mean: 0.06238
[32m[0906 16-05-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10413, current rewards: 25.00532, mean: 0.06946
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10440, current rewards: 30.75986, mean: 0.07502
[32m[0906 16-05-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10465, current rewards: 36.29821, mean: 0.07891
[32m[0906 16-05-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10462, current rewards: 41.83631, mean: 0.08203
[32m[0906 16-05-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10460, current rewards: 47.37598, mean: 0.08460
[32m[0906 16-06-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10487, current rewards: 42.35770, mean: 0.06944
[32m[0906 16-06-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10509, current rewards: 49.23498, mean: 0.07460
[32m[0906 16-06-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10522, current rewards: 58.28841, mean: 0.08210
[32m[0906 16-06-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10542, current rewards: 67.34184, mean: 0.08861
[32m[0906 16-06-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10556, current rewards: 72.86028, mean: 0.08995
[32m[0906 16-06-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10567, current rewards: 76.33962, mean: 0.08877
[32m[0906 16-06-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10581, current rewards: 79.81895, mean: 0.08771
[32m[0906 16-06-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10587, current rewards: 83.29828, mean: 0.08677
[32m[0906 16-06-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10594, current rewards: 51.48126, mean: 0.05097
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10604, current rewards: 1.48126, mean: 0.00140
[32m[0906 16-06-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10623, current rewards: -48.51874, mean: -0.04371
[32m[0906 16-07-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10647, current rewards: -98.51874, mean: -0.08493
[32m[0906 16-07-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10666, current rewards: -148.51874, mean: -0.12274
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10682, current rewards: -198.51874, mean: -0.15755
[32m[0906 16-07-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10701, current rewards: -248.51874, mean: -0.18971
[32m[0906 16-07-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10716, current rewards: -298.51874, mean: -0.21950
[32m[0906 16-07-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10732, current rewards: -348.51874, mean: -0.24718
[32m[0906 16-07-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10752, current rewards: -398.51874, mean: -0.27296
[32m[0906 16-07-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10765, current rewards: -448.51874, mean: -0.29703
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10776, current rewards: -498.51874, mean: -0.31956
[32m[0906 16-07-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10789, current rewards: -548.51874, mean: -0.34069
[32m[0906 16-07-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10800, current rewards: -598.51874, mean: -0.36055
[32m[0906 16-08-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10809, current rewards: -648.51874, mean: -0.37925
[32m[0906 16-08-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10819, current rewards: -698.51874, mean: -0.39689
[32m[0906 16-08-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10819, current rewards: -748.51874, mean: -0.41355
[32m[0906 16-08-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10817, current rewards: -798.51874, mean: -0.42931
[32m[0906 16-08-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10817, current rewards: -848.51874, mean: -0.44425
[32m[0906 16-08-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10815, current rewards: -898.51874, mean: -0.45843
[32m[0906 16-08-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10812, current rewards: -948.51874, mean: -0.47190
[32m[0906 16-08-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10812, current rewards: -998.51874, mean: -0.48472
[32m[0906 16-08-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10811, current rewards: -1048.51874, mean: -0.49693
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10809, current rewards: -1098.51874, mean: -0.50857
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10809, current rewards: -1148.51874, mean: -0.51969
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10807, current rewards: -1198.51874, mean: -0.53032
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10805, current rewards: -1248.51874, mean: -0.54048
[32m[0906 16-09-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10805, current rewards: -1298.51874, mean: -0.55022
[32m[0906 16-09-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10804, current rewards: -1348.51874, mean: -0.55955
[32m[0906 16-09-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10810, current rewards: -1398.51874, mean: -0.56850
[32m[0906 16-09-28 @Agent.py:117][0m Average action selection time: 0.1082
[32m[0906 16-09-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-09-28 @MBExp.py:227][0m Rewards obtained: [-1438.518742260133], Lows: [11], Highs: [1528], Total time: 7968.870862999999
[32m[0906 16-10-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-10-37 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 16-10-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10133, current rewards: -14.00000, mean: -1.40000
[32m[0906 16-10-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10334, current rewards: -10.65989, mean: -0.17766
[32m[0906 16-10-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10362, current rewards: -5.23917, mean: -0.04763
[32m[0906 16-10-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10351, current rewards: 0.17634, mean: 0.00110
[32m[0906 16-10-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10352, current rewards: 5.59467, mean: 0.02664
[32m[0906 16-11-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10372, current rewards: 11.01081, mean: 0.04235
[32m[0906 16-11-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10379, current rewards: 16.42758, mean: 0.05299
[32m[0906 16-11-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10378, current rewards: 21.65204, mean: 0.06014
[32m[0906 16-11-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10405, current rewards: 26.83623, mean: 0.06545
[32m[0906 16-11-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10406, current rewards: 32.00493, mean: 0.06958
[32m[0906 16-11-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10407, current rewards: 37.17633, mean: 0.07289
[32m[0906 16-11-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10416, current rewards: 42.34463, mean: 0.07562
[32m[0906 16-11-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10442, current rewards: 47.51763, mean: 0.07790
[32m[0906 16-11-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10465, current rewards: 52.68875, mean: 0.07983
[32m[0906 16-11-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10492, current rewards: 48.15117, mean: 0.06782
[32m[0906 16-11-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10510, current rewards: 54.37080, mean: 0.07154
[32m[0906 16-12-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10527, current rewards: 60.47436, mean: 0.07466
[32m[0906 16-12-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10543, current rewards: 66.25280, mean: 0.07704
[32m[0906 16-12-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10555, current rewards: 72.03285, mean: 0.07916
[32m[0906 16-12-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10569, current rewards: 77.81196, mean: 0.08105
[32m[0906 16-12-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10579, current rewards: 83.58868, mean: 0.08276
[32m[0906 16-12-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10587, current rewards: 89.36827, mean: 0.08431
[32m[0906 16-12-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10611, current rewards: 95.14453, mean: 0.08572
[32m[0906 16-12-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10633, current rewards: 100.92029, mean: 0.08700
[32m[0906 16-12-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10655, current rewards: 106.74803, mean: 0.08822
[32m[0906 16-12-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10678, current rewards: 112.54124, mean: 0.08932
[32m[0906 16-12-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10694, current rewards: 118.33451, mean: 0.09033
[32m[0906 16-13-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10709, current rewards: 117.16051, mean: 0.08615
[32m[0906 16-13-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10724, current rewards: 122.68372, mean: 0.08701
[32m[0906 16-13-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10738, current rewards: 128.20189, mean: 0.08781
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10750, current rewards: 133.71706, mean: 0.08855
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10765, current rewards: 139.23647, mean: 0.08925
[32m[0906 16-13-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10776, current rewards: 144.53335, mean: 0.08977
[32m[0906 16-13-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10787, current rewards: 150.09989, mean: 0.09042
[32m[0906 16-13-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10798, current rewards: 155.66445, mean: 0.09103
[32m[0906 16-13-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10807, current rewards: 161.22598, mean: 0.09161
[32m[0906 16-13-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10806, current rewards: 156.27431, mean: 0.08634
[32m[0906 16-13-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10806, current rewards: 161.78096, mean: 0.08698
[32m[0906 16-14-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10805, current rewards: 167.28748, mean: 0.08759
[32m[0906 16-14-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10803, current rewards: 172.80607, mean: 0.08817
[32m[0906 16-14-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10803, current rewards: 178.35724, mean: 0.08873
[32m[0906 16-14-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10801, current rewards: 183.88081, mean: 0.08926
[32m[0906 16-14-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10800, current rewards: 189.39834, mean: 0.08976
[32m[0906 16-14-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10800, current rewards: 194.91924, mean: 0.09024
[32m[0906 16-14-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10798, current rewards: 200.43962, mean: 0.09070
[32m[0906 16-14-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10797, current rewards: 205.95713, mean: 0.09113
[32m[0906 16-14-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10796, current rewards: 211.47636, mean: 0.09155
[32m[0906 16-14-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10795, current rewards: 216.99877, mean: 0.09195
[32m[0906 16-14-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10795, current rewards: 222.66430, mean: 0.09239
[32m[0906 16-15-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10800, current rewards: 217.87757, mean: 0.08857
[32m[0906 16-15-08 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 16-15-08 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-15-08 @MBExp.py:227][0m Rewards obtained: [222.38245798152153], Lows: [20], Highs: [12], Total time: 8239.722399999999
[32m[0906 16-16-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-16-19 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 16-16-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10352, current rewards: -6.67898, mean: -0.66790
[32m[0906 16-16-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10412, current rewards: -1.35059, mean: -0.02251
[32m[0906 16-16-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10398, current rewards: 4.11379, mean: 0.03740
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10412, current rewards: 9.57339, mean: 0.05983
[32m[0906 16-16-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10414, current rewards: 15.03862, mean: 0.07161
[32m[0906 16-16-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10422, current rewards: 20.50475, mean: 0.07886
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10431, current rewards: 25.61928, mean: 0.08264
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10430, current rewards: 30.72550, mean: 0.08535
[32m[0906 16-17-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10430, current rewards: 35.84643, mean: 0.08743
[32m[0906 16-17-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10434, current rewards: 40.94445, mean: 0.08901
[32m[0906 16-17-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10428, current rewards: 46.05579, mean: 0.09031
[32m[0906 16-17-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10428, current rewards: 51.16552, mean: 0.09137
[32m[0906 16-17-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10464, current rewards: 43.58416, mean: 0.07145
[32m[0906 16-17-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10491, current rewards: 48.90933, mean: 0.07411
[32m[0906 16-17-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10521, current rewards: 54.28367, mean: 0.07646
[32m[0906 16-17-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10544, current rewards: 61.82098, mean: 0.08134
[32m[0906 16-17-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10557, current rewards: 69.47606, mean: 0.08577
[32m[0906 16-17-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10566, current rewards: 77.13114, mean: 0.08969
[32m[0906 16-17-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10582, current rewards: 84.78622, mean: 0.09317
[32m[0906 16-18-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10591, current rewards: 92.44130, mean: 0.09629
[32m[0906 16-18-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10598, current rewards: 100.09639, mean: 0.09911
[32m[0906 16-18-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10610, current rewards: 107.75147, mean: 0.10165
[32m[0906 16-18-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10628, current rewards: 114.25345, mean: 0.10293
[32m[0906 16-18-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10649, current rewards: 86.30168, mean: 0.07440
[32m[0906 16-18-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10671, current rewards: 91.50215, mean: 0.07562
[32m[0906 16-18-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10688, current rewards: 96.70060, mean: 0.07675
[32m[0906 16-18-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10704, current rewards: 101.89530, mean: 0.07778
[32m[0906 16-18-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10719, current rewards: 107.09455, mean: 0.07875
[32m[0906 16-18-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10737, current rewards: 112.29177, mean: 0.07964
[32m[0906 16-18-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10752, current rewards: 117.49177, mean: 0.08047
[32m[0906 16-19-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10764, current rewards: 112.54737, mean: 0.07453
[32m[0906 16-19-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10775, current rewards: 118.31703, mean: 0.07584
[32m[0906 16-19-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10788, current rewards: 124.08260, mean: 0.07707
[32m[0906 16-19-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10799, current rewards: 129.83627, mean: 0.07821
[32m[0906 16-19-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10807, current rewards: 135.59445, mean: 0.07930
[32m[0906 16-19-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10817, current rewards: 141.35912, mean: 0.08032
[32m[0906 16-19-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10815, current rewards: 147.12001, mean: 0.08128
[32m[0906 16-19-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10813, current rewards: 152.87973, mean: 0.08219
[32m[0906 16-19-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10813, current rewards: 158.64342, mean: 0.08306
[32m[0906 16-19-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10814, current rewards: 158.76384, mean: 0.08100
[32m[0906 16-19-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10812, current rewards: 164.59859, mean: 0.08189
[32m[0906 16-20-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10812, current rewards: 170.42634, mean: 0.08273
[32m[0906 16-20-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10810, current rewards: 176.25682, mean: 0.08353
[32m[0906 16-20-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10808, current rewards: 182.08429, mean: 0.08430
[32m[0906 16-20-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10808, current rewards: 187.91539, mean: 0.08503
[32m[0906 16-20-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10807, current rewards: 193.74258, mean: 0.08573
[32m[0906 16-20-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10807, current rewards: 199.57440, mean: 0.08640
[32m[0906 16-20-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10807, current rewards: 204.59171, mean: 0.08669
[32m[0906 16-20-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10806, current rewards: 199.38919, mean: 0.08273
[32m[0906 16-20-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10807, current rewards: 204.88898, mean: 0.08329
[32m[0906 16-20-50 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 16-20-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-20-50 @MBExp.py:227][0m Rewards obtained: [209.28647232464127], Lows: [17], Highs: [41], Total time: 8510.818086
[32m[0906 16-22-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-22-03 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 16-22-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10385, current rewards: -6.76650, mean: -0.67665
[32m[0906 16-22-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10479, current rewards: -1.30790, mean: -0.02180
[32m[0906 16-22-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10439, current rewards: 4.12425, mean: 0.03749
[32m[0906 16-22-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10436, current rewards: 9.55376, mean: 0.05971
[32m[0906 16-22-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10437, current rewards: 14.98694, mean: 0.07137
[32m[0906 16-22-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10428, current rewards: 20.97928, mean: 0.08069
[32m[0906 16-22-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10425, current rewards: 27.54527, mean: 0.08886
[32m[0906 16-22-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10431, current rewards: 23.70304, mean: 0.06584
[32m[0906 16-22-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10408, current rewards: 30.16186, mean: 0.07357
[32m[0906 16-22-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10410, current rewards: 36.62069, mean: 0.07961
[32m[0906 16-22-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10410, current rewards: 43.07951, mean: 0.08447
[32m[0906 16-23-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10409, current rewards: 49.53833, mean: 0.08846
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10431, current rewards: 55.99716, mean: 0.09180
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10459, current rewards: 62.45598, mean: 0.09463
[32m[0906 16-23-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10479, current rewards: 66.98441, mean: 0.09434
[32m[0906 16-23-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10494, current rewards: 69.90715, mean: 0.09198
[32m[0906 16-23-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10514, current rewards: 72.82989, mean: 0.08991
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10526, current rewards: 75.75263, mean: 0.08808
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10537, current rewards: 33.16182, mean: 0.03644
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10550, current rewards: -16.83818, mean: -0.01754
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10561, current rewards: -66.83818, mean: -0.06618
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10568, current rewards: -116.83818, mean: -0.11022
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10592, current rewards: -166.83818, mean: -0.15030
[32m[0906 16-24-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10613, current rewards: -216.83818, mean: -0.18693
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10634, current rewards: -266.83818, mean: -0.22053
[32m[0906 16-24-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10656, current rewards: -316.83818, mean: -0.25146
[32m[0906 16-24-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10672, current rewards: -366.83818, mean: -0.28003
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10690, current rewards: -416.83818, mean: -0.30650
[32m[0906 16-24-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10707, current rewards: -466.83818, mean: -0.33109
[32m[0906 16-24-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10723, current rewards: -516.83818, mean: -0.35400
[32m[0906 16-24-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10738, current rewards: -566.83818, mean: -0.37539
[32m[0906 16-24-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10751, current rewards: -616.83818, mean: -0.39541
[32m[0906 16-24-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10762, current rewards: -666.83818, mean: -0.41419
[32m[0906 16-25-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10776, current rewards: -716.83818, mean: -0.43183
[32m[0906 16-25-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10785, current rewards: -766.83818, mean: -0.44844
[32m[0906 16-25-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10791, current rewards: -816.83818, mean: -0.46411
[32m[0906 16-25-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10791, current rewards: -866.83818, mean: -0.47892
[32m[0906 16-25-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10790, current rewards: -916.83818, mean: -0.49292
[32m[0906 16-25-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10789, current rewards: -966.83818, mean: -0.50620
[32m[0906 16-25-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10790, current rewards: -1016.83818, mean: -0.51879
[32m[0906 16-25-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10789, current rewards: -1066.83818, mean: -0.53077
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10789, current rewards: -1116.83818, mean: -0.54215
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10789, current rewards: -1166.83818, mean: -0.55300
[32m[0906 16-25-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10788, current rewards: -1216.83818, mean: -0.56335
[32m[0906 16-26-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10787, current rewards: -1266.83818, mean: -0.57323
[32m[0906 16-26-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10787, current rewards: -1316.83818, mean: -0.58267
[32m[0906 16-26-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10787, current rewards: -1366.83818, mean: -0.59170
[32m[0906 16-26-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10785, current rewards: -1416.83818, mean: -0.60036
[32m[0906 16-26-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10786, current rewards: -1466.83818, mean: -0.60865
[32m[0906 16-26-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10785, current rewards: -1516.83818, mean: -0.61660
[32m[0906 16-26-34 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 16-26-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-26-34 @MBExp.py:227][0m Rewards obtained: [-1556.8381847639794], Lows: [5], Highs: [1640], Total time: 8781.315203
[32m[0906 16-27-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-27-49 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10252, current rewards: -3.86423, mean: -0.38642
[32m[0906 16-27-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10361, current rewards: 3.53383, mean: 0.05890
[32m[0906 16-28-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10388, current rewards: 9.64216, mean: 0.08766
[32m[0906 16-28-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10389, current rewards: 15.74972, mean: 0.09844
[32m[0906 16-28-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10385, current rewards: 21.85745, mean: 0.10408
[32m[0906 16-28-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10392, current rewards: 27.68234, mean: 0.10647
[32m[0906 16-28-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10393, current rewards: 33.91803, mean: 0.10941
[32m[0906 16-28-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10379, current rewards: 40.15380, mean: 0.11154
[32m[0906 16-28-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10346, current rewards: 46.38202, mean: 0.11313
[32m[0906 16-28-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10350, current rewards: 52.61293, mean: 0.11438
[32m[0906 16-28-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10354, current rewards: 49.00894, mean: 0.09610
[32m[0906 16-28-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10367, current rewards: 55.07680, mean: 0.09835
[32m[0906 16-28-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10389, current rewards: 61.14479, mean: 0.10024
[32m[0906 16-28-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10416, current rewards: 66.82633, mean: 0.10125
[32m[0906 16-29-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10443, current rewards: 67.31255, mean: 0.09481
[32m[0906 16-29-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10463, current rewards: 73.12486, mean: 0.09622
[32m[0906 16-29-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10481, current rewards: 78.93290, mean: 0.09745
[32m[0906 16-29-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10499, current rewards: 84.73751, mean: 0.09853
[32m[0906 16-29-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10511, current rewards: 90.54094, mean: 0.09950
[32m[0906 16-29-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10525, current rewards: 96.34933, mean: 0.10036
[32m[0906 16-29-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10538, current rewards: 102.15684, mean: 0.10115
[32m[0906 16-29-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10547, current rewards: 108.28269, mean: 0.10215
[32m[0906 16-29-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10573, current rewards: 114.94332, mean: 0.10355
[32m[0906 16-29-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10596, current rewards: 120.90131, mean: 0.10423
[32m[0906 16-29-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10617, current rewards: 126.86779, mean: 0.10485
[32m[0906 16-30-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10639, current rewards: 132.82835, mean: 0.10542
[32m[0906 16-30-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10657, current rewards: 138.79279, mean: 0.10595
[32m[0906 16-30-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10673, current rewards: 144.75524, mean: 0.10644
[32m[0906 16-30-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10691, current rewards: 150.70841, mean: 0.10689
[32m[0906 16-30-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10705, current rewards: 156.67077, mean: 0.10731
[32m[0906 16-30-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10718, current rewards: 162.36074, mean: 0.10752
[32m[0906 16-30-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10732, current rewards: 169.25060, mean: 0.10849
[32m[0906 16-30-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10745, current rewards: 176.12411, mean: 0.10939
[32m[0906 16-30-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10754, current rewards: 182.99018, mean: 0.11024
[32m[0906 16-30-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10767, current rewards: 189.85098, mean: 0.11102
[32m[0906 16-30-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10772, current rewards: 196.71252, mean: 0.11177
[32m[0906 16-31-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10770, current rewards: 203.58490, mean: 0.11248
[32m[0906 16-31-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10771, current rewards: 210.44597, mean: 0.11314
[32m[0906 16-31-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10769, current rewards: 217.54114, mean: 0.11390
[32m[0906 16-31-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10769, current rewards: 226.89134, mean: 0.11576
[32m[0906 16-31-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10771, current rewards: 223.99350, mean: 0.11144
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10769, current rewards: 230.04802, mean: 0.11167
[32m[0906 16-31-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10769, current rewards: 236.09753, mean: 0.11189
[32m[0906 16-31-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10770, current rewards: 236.63307, mean: 0.10955
[32m[0906 16-31-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10770, current rewards: 242.64536, mean: 0.10979
[32m[0906 16-31-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10769, current rewards: 248.60477, mean: 0.11000
[32m[0906 16-31-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10772, current rewards: 254.56757, mean: 0.11020
[32m[0906 16-32-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10771, current rewards: 260.52447, mean: 0.11039
[32m[0906 16-32-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10770, current rewards: 266.48323, mean: 0.11057
[32m[0906 16-32-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10770, current rewards: 272.43966, mean: 0.11075
[32m[0906 16-32-19 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 16-32-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-32-19 @MBExp.py:227][0m Rewards obtained: [278.1522079085189], Lows: [10], Highs: [15], Total time: 9051.373743
[32m[0906 16-33-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-33-37 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 16-33-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10332, current rewards: -5.73385, mean: -0.57338
[32m[0906 16-33-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10428, current rewards: -0.65604, mean: -0.01093
[32m[0906 16-33-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10442, current rewards: 4.90522, mean: 0.04459
[32m[0906 16-33-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10435, current rewards: 10.45536, mean: 0.06535
[32m[0906 16-33-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10423, current rewards: 16.00703, mean: 0.07622
[32m[0906 16-34-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10433, current rewards: 21.62894, mean: 0.08319
[32m[0906 16-34-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10434, current rewards: 27.20954, mean: 0.08777
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10395, current rewards: 32.74887, mean: 0.09097
[32m[0906 16-34-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10360, current rewards: 38.28480, mean: 0.09338
[32m[0906 16-34-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10353, current rewards: 43.51722, mean: 0.09460
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10358, current rewards: 49.16131, mean: 0.09639
[32m[0906 16-34-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10365, current rewards: 54.45896, mean: 0.09725
[32m[0906 16-34-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10379, current rewards: 59.76119, mean: 0.09797
[32m[0906 16-34-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10407, current rewards: 65.05559, mean: 0.09857
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10437, current rewards: 70.30201, mean: 0.09902
[32m[0906 16-34-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10453, current rewards: 75.59612, mean: 0.09947
[32m[0906 16-35-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10473, current rewards: 80.89584, mean: 0.09987
[32m[0906 16-35-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10492, current rewards: 86.19333, mean: 0.10022
[32m[0906 16-35-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10506, current rewards: 91.48516, mean: 0.10053
[32m[0906 16-35-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10519, current rewards: 96.78133, mean: 0.10081
[32m[0906 16-35-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10533, current rewards: 102.07712, mean: 0.10107
[32m[0906 16-35-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10546, current rewards: 107.36991, mean: 0.10129
[32m[0906 16-35-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10569, current rewards: 113.53238, mean: 0.10228
[32m[0906 16-35-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10597, current rewards: 118.79988, mean: 0.10241
[32m[0906 16-35-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10620, current rewards: 123.79210, mean: 0.10231
[32m[0906 16-35-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10638, current rewards: 129.02707, mean: 0.10240
[32m[0906 16-35-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10660, current rewards: 134.26618, mean: 0.10249
[32m[0906 16-36-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10677, current rewards: 139.50628, mean: 0.10258
[32m[0906 16-36-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10696, current rewards: 144.74820, mean: 0.10266
[32m[0906 16-36-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10712, current rewards: 149.98222, mean: 0.10273
[32m[0906 16-36-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10725, current rewards: 155.06009, mean: 0.10269
[32m[0906 16-36-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10739, current rewards: 150.25060, mean: 0.09631
[32m[0906 16-36-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10752, current rewards: 156.17135, mean: 0.09700
[32m[0906 16-36-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10764, current rewards: 162.08770, mean: 0.09764
[32m[0906 16-36-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10776, current rewards: 167.99872, mean: 0.09824
[32m[0906 16-36-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10781, current rewards: 173.90958, mean: 0.09881
[32m[0906 16-36-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10781, current rewards: 179.82748, mean: 0.09935
[32m[0906 16-36-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10783, current rewards: 185.74691, mean: 0.09986
[32m[0906 16-37-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10782, current rewards: 191.92334, mean: 0.10048
[32m[0906 16-37-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10783, current rewards: 197.82965, mean: 0.10093
[32m[0906 16-37-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10783, current rewards: 203.73284, mean: 0.10136
[32m[0906 16-37-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10783, current rewards: 197.23632, mean: 0.09575
[32m[0906 16-37-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10783, current rewards: 202.68746, mean: 0.09606
[32m[0906 16-37-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10784, current rewards: 208.13925, mean: 0.09636
[32m[0906 16-37-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10787, current rewards: 213.59274, mean: 0.09665
[32m[0906 16-37-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10785, current rewards: 219.04301, mean: 0.09692
[32m[0906 16-37-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10784, current rewards: 224.36295, mean: 0.09713
[32m[0906 16-37-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10783, current rewards: 229.82018, mean: 0.09738
[32m[0906 16-37-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10782, current rewards: 235.27513, mean: 0.09762
[32m[0906 16-38-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10781, current rewards: 239.62007, mean: 0.09741
[32m[0906 16-38-07 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 16-38-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-38-07 @MBExp.py:227][0m Rewards obtained: [240.50434268619782], Lows: [11], Highs: [12], Total time: 9321.633585
[32m[0906 16-39-27 @MBExp.py:144][0m ####################################################################
[32m[0906 16-39-27 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 16-39-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10363, current rewards: -11.32065, mean: -1.13206
[32m[0906 16-39-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10477, current rewards: -9.71453, mean: -0.16191
[32m[0906 16-39-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10496, current rewards: -4.33520, mean: -0.03941
[32m[0906 16-39-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10490, current rewards: 1.05178, mean: 0.00657
[32m[0906 16-39-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10494, current rewards: 6.43773, mean: 0.03066
[32m[0906 16-39-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10505, current rewards: 11.38371, mean: 0.04378
[32m[0906 16-40-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10504, current rewards: 6.59017, mean: 0.02126
[32m[0906 16-40-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10451, current rewards: 12.28412, mean: 0.03412
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10418, current rewards: 17.97806, mean: 0.04385
[32m[0906 16-40-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10399, current rewards: 23.67201, mean: 0.05146
[32m[0906 16-40-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10402, current rewards: 29.37067, mean: 0.05759
[32m[0906 16-40-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10410, current rewards: 35.06635, mean: 0.06262
[32m[0906 16-40-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10415, current rewards: 40.76264, mean: 0.06682
[32m[0906 16-40-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10438, current rewards: 34.08685, mean: 0.05165
[32m[0906 16-40-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10467, current rewards: 39.55977, mean: 0.05572
[32m[0906 16-40-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10483, current rewards: 45.03493, mean: 0.05926
[32m[0906 16-40-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10499, current rewards: 50.51065, mean: 0.06236
[32m[0906 16-40-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10517, current rewards: 55.98752, mean: 0.06510
[32m[0906 16-41-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10526, current rewards: 58.13538, mean: 0.06389
[32m[0906 16-41-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10538, current rewards: 60.21488, mean: 0.06272
[32m[0906 16-41-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10549, current rewards: 65.65393, mean: 0.06500
[32m[0906 16-41-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10558, current rewards: 71.39881, mean: 0.06736
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10580, current rewards: 76.82991, mean: 0.06922
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10604, current rewards: 82.25964, mean: 0.07091
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10626, current rewards: 77.35834, mean: 0.06393
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10649, current rewards: 82.85301, mean: 0.06576
[32m[0906 16-41-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10668, current rewards: 88.35060, mean: 0.06744
[32m[0906 16-41-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10687, current rewards: 93.84592, mean: 0.06900
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10707, current rewards: 99.33847, mean: 0.07045
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10722, current rewards: 104.55365, mean: 0.07161
[32m[0906 16-42-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10737, current rewards: 104.54909, mean: 0.06924
[32m[0906 16-42-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10752, current rewards: 110.18202, mean: 0.07063
[32m[0906 16-42-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10765, current rewards: 115.81447, mean: 0.07193
[32m[0906 16-42-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10777, current rewards: 121.44562, mean: 0.07316
[32m[0906 16-42-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10790, current rewards: 127.06994, mean: 0.07431
[32m[0906 16-42-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10794, current rewards: 132.70499, mean: 0.07540
[32m[0906 16-42-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10794, current rewards: 138.33309, mean: 0.07643
[32m[0906 16-42-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10795, current rewards: 143.96295, mean: 0.07740
[32m[0906 16-42-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10794, current rewards: 149.60418, mean: 0.07833
[32m[0906 16-43-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10794, current rewards: 155.23574, mean: 0.07920
[32m[0906 16-43-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10795, current rewards: 160.87612, mean: 0.08004
[32m[0906 16-43-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10794, current rewards: 166.50495, mean: 0.08083
[32m[0906 16-43-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10793, current rewards: 172.14235, mean: 0.08158
[32m[0906 16-43-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10794, current rewards: 177.76752, mean: 0.08230
[32m[0906 16-43-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10794, current rewards: 172.65815, mean: 0.07813
[32m[0906 16-43-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10793, current rewards: 178.13070, mean: 0.07882
[32m[0906 16-43-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10794, current rewards: 183.60546, mean: 0.07948
[32m[0906 16-43-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10793, current rewards: 189.08040, mean: 0.08012
[32m[0906 16-43-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10793, current rewards: 194.55377, mean: 0.08073
[32m[0906 16-43-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10792, current rewards: 200.02579, mean: 0.08131
[32m[0906 16-43-58 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 16-43-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-43-58 @MBExp.py:227][0m Rewards obtained: [204.40426382576678], Lows: [27], Highs: [17], Total time: 9592.198891
[32m[0906 16-45-20 @MBExp.py:144][0m ####################################################################
[32m[0906 16-45-20 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 16-45-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10297, current rewards: 0.11123, mean: 0.01112
[32m[0906 16-45-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10447, current rewards: 6.32517, mean: 0.10542
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10424, current rewards: 12.15735, mean: 0.11052
[32m[0906 16-45-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10408, current rewards: 17.98956, mean: 0.11243
[32m[0906 16-45-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10404, current rewards: 23.22516, mean: 0.11060
[32m[0906 16-45-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10406, current rewards: 28.90950, mean: 0.11119
[32m[0906 16-45-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10382, current rewards: 34.65999, mean: 0.11181
[32m[0906 16-45-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10342, current rewards: 40.40669, mean: 0.11224
[32m[0906 16-46-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10308, current rewards: 46.15443, mean: 0.11257
[32m[0906 16-46-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10283, current rewards: 47.17082, mean: 0.10255
[32m[0906 16-46-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10300, current rewards: 52.54531, mean: 0.10303
[32m[0906 16-46-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10308, current rewards: 57.92370, mean: 0.10344
[32m[0906 16-46-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10312, current rewards: 63.31026, mean: 0.10379
[32m[0906 16-46-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10348, current rewards: 69.32091, mean: 0.10503
[32m[0906 16-46-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10374, current rewards: 74.85931, mean: 0.10544
[32m[0906 16-46-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10400, current rewards: 80.39421, mean: 0.10578
[32m[0906 16-46-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10428, current rewards: 85.93781, mean: 0.10610
[32m[0906 16-46-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10448, current rewards: 91.47686, mean: 0.10637
[32m[0906 16-46-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10464, current rewards: 97.01198, mean: 0.10661
[32m[0906 16-47-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10482, current rewards: 102.54557, mean: 0.10682
[32m[0906 16-47-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10495, current rewards: 108.07880, mean: 0.10701
[32m[0906 16-47-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10508, current rewards: 104.63687, mean: 0.09871
[32m[0906 16-47-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10535, current rewards: 110.26719, mean: 0.09934
[32m[0906 16-47-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10560, current rewards: 115.89487, mean: 0.09991
[32m[0906 16-47-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10586, current rewards: 121.51936, mean: 0.10043
[32m[0906 16-47-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10613, current rewards: 127.15002, mean: 0.10091
[32m[0906 16-47-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10633, current rewards: 132.78403, mean: 0.10136
[32m[0906 16-47-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10652, current rewards: 138.41368, mean: 0.10177
[32m[0906 16-47-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10671, current rewards: 144.04877, mean: 0.10216
[32m[0906 16-47-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10686, current rewards: 138.91317, mean: 0.09515
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10702, current rewards: 145.75479, mean: 0.09653
[32m[0906 16-48-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10715, current rewards: 152.50979, mean: 0.09776
[32m[0906 16-48-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10728, current rewards: 159.25685, mean: 0.09892
[32m[0906 16-48-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10741, current rewards: 166.01015, mean: 0.10001
[32m[0906 16-48-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10753, current rewards: 172.76265, mean: 0.10103
[32m[0906 16-48-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10755, current rewards: 179.51162, mean: 0.10200
[32m[0906 16-48-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10756, current rewards: 186.26579, mean: 0.10291
[32m[0906 16-48-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10757, current rewards: 193.42098, mean: 0.10399
[32m[0906 16-48-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10757, current rewards: 200.26725, mean: 0.10485
[32m[0906 16-48-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10758, current rewards: 207.03308, mean: 0.10563
[32m[0906 16-48-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10758, current rewards: 207.62533, mean: 0.10330
[32m[0906 16-49-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10758, current rewards: 213.05619, mean: 0.10343
[32m[0906 16-49-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10759, current rewards: 218.49451, mean: 0.10355
[32m[0906 16-49-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10758, current rewards: 223.93092, mean: 0.10367
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10758, current rewards: 229.37523, mean: 0.10379
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10760, current rewards: 234.81763, mean: 0.10390
[32m[0906 16-49-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10759, current rewards: 239.68879, mean: 0.10376
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10759, current rewards: 239.95812, mean: 0.10168
[32m[0906 16-49-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10761, current rewards: 245.48883, mean: 0.10186
[32m[0906 16-49-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10761, current rewards: 251.02689, mean: 0.10204
[32m[0906 16-49-50 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 16-49-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-49-50 @MBExp.py:227][0m Rewards obtained: [255.45539390758105], Lows: [10], Highs: [16], Total time: 9861.933384
[32m[0906 16-51-15 @MBExp.py:144][0m ####################################################################
[32m[0906 16-51-15 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 16-51-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10257, current rewards: 0.64348, mean: 0.06435
[32m[0906 16-51-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10363, current rewards: 6.19595, mean: 0.10327
[32m[0906 16-51-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10364, current rewards: 11.75763, mean: 0.10689
[32m[0906 16-51-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10386, current rewards: 17.32318, mean: 0.10827
[32m[0906 16-51-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10377, current rewards: 23.46941, mean: 0.11176
[32m[0906 16-51-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10383, current rewards: 29.11732, mean: 0.11199
[32m[0906 16-51-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10350, current rewards: 34.77556, mean: 0.11218
[32m[0906 16-51-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10311, current rewards: 40.43211, mean: 0.11231
[32m[0906 16-51-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10284, current rewards: 39.34821, mean: 0.09597
[32m[0906 16-52-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10269, current rewards: 44.78474, mean: 0.09736
[32m[0906 16-52-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10281, current rewards: 50.22615, mean: 0.09848
[32m[0906 16-52-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10291, current rewards: 55.66607, mean: 0.09940
[32m[0906 16-52-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10303, current rewards: 61.12637, mean: 0.10021
[32m[0906 16-52-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10333, current rewards: 66.89673, mean: 0.10136
[32m[0906 16-52-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10364, current rewards: 72.34364, mean: 0.10189
[32m[0906 16-52-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10390, current rewards: 77.79235, mean: 0.10236
[32m[0906 16-52-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10413, current rewards: 73.16541, mean: 0.09033
[32m[0906 16-52-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10431, current rewards: 78.69611, mean: 0.09151
[32m[0906 16-52-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10452, current rewards: 84.22378, mean: 0.09255
[32m[0906 16-52-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10468, current rewards: 89.75850, mean: 0.09350
[32m[0906 16-53-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10483, current rewards: 95.28725, mean: 0.09434
[32m[0906 16-53-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10497, current rewards: 100.26750, mean: 0.09459
[32m[0906 16-53-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10519, current rewards: 105.73884, mean: 0.09526
[32m[0906 16-53-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10547, current rewards: 111.20521, mean: 0.09587
[32m[0906 16-53-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10573, current rewards: 116.67472, mean: 0.09643
[32m[0906 16-53-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10596, current rewards: 122.14569, mean: 0.09694
[32m[0906 16-53-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10615, current rewards: 122.06750, mean: 0.09318
[32m[0906 16-53-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10635, current rewards: 127.66038, mean: 0.09387
[32m[0906 16-53-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10655, current rewards: 132.99702, mean: 0.09432
[32m[0906 16-53-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10670, current rewards: 138.15420, mean: 0.09463
[32m[0906 16-53-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10688, current rewards: 143.44034, mean: 0.09499
[32m[0906 16-54-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10702, current rewards: 148.73799, mean: 0.09534
[32m[0906 16-54-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10717, current rewards: 154.02858, mean: 0.09567
[32m[0906 16-54-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10731, current rewards: 159.32385, mean: 0.09598
[32m[0906 16-54-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10743, current rewards: 164.60953, mean: 0.09626
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10746, current rewards: 169.90402, mean: 0.09654
[32m[0906 16-54-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10748, current rewards: 175.19192, mean: 0.09679
[32m[0906 16-54-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10748, current rewards: 180.72309, mean: 0.09716
[32m[0906 16-54-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10750, current rewards: 186.14906, mean: 0.09746
[32m[0906 16-54-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10751, current rewards: 191.53828, mean: 0.09772
[32m[0906 16-54-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10751, current rewards: 196.93043, mean: 0.09798
[32m[0906 16-54-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10754, current rewards: 202.31648, mean: 0.09821
[32m[0906 16-55-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10755, current rewards: 207.70665, mean: 0.09844
[32m[0906 16-55-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10755, current rewards: 213.09557, mean: 0.09866
[32m[0906 16-55-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10756, current rewards: 218.48921, mean: 0.09886
[32m[0906 16-55-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10756, current rewards: 213.67142, mean: 0.09454
[32m[0906 16-55-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10758, current rewards: 219.28585, mean: 0.09493
[32m[0906 16-55-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10759, current rewards: 224.90233, mean: 0.09530
[32m[0906 16-55-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10759, current rewards: 230.51648, mean: 0.09565
[32m[0906 16-55-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10761, current rewards: 236.13286, mean: 0.09599
[32m[0906 16-55-44 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 16-55-44 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-55-44 @MBExp.py:227][0m Rewards obtained: [240.62843468043164], Lows: [10], Highs: [11], Total time: 10131.733908
[32m[0906 16-57-11 @MBExp.py:144][0m ####################################################################
[32m[0906 16-57-11 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 16-57-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10284, current rewards: 1.68190, mean: 0.16819
[32m[0906 16-57-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10400, current rewards: 6.13515, mean: 0.10225
[32m[0906 16-57-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10418, current rewards: 11.19011, mean: 0.10173
[32m[0906 16-57-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10426, current rewards: 16.24427, mean: 0.10153
[32m[0906 16-57-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10452, current rewards: 21.56925, mean: 0.10271
[32m[0906 16-57-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10458, current rewards: 26.95130, mean: 0.10366
[32m[0906 16-57-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10389, current rewards: 32.01475, mean: 0.10327
[32m[0906 16-57-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10345, current rewards: 37.07299, mean: 0.10298
[32m[0906 16-57-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10315, current rewards: 42.13388, mean: 0.10277
[32m[0906 16-57-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10289, current rewards: 47.19786, mean: 0.10260
[32m[0906 16-58-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10282, current rewards: 52.25914, mean: 0.10247
[32m[0906 16-58-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10294, current rewards: 50.84233, mean: 0.09079
[32m[0906 16-58-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10301, current rewards: 56.06043, mean: 0.09190
[32m[0906 16-58-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10319, current rewards: 61.04933, mean: 0.09250
[32m[0906 16-58-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10355, current rewards: 66.28586, mean: 0.09336
[32m[0906 16-58-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10381, current rewards: 71.51932, mean: 0.09410
[32m[0906 16-58-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10405, current rewards: 76.75214, mean: 0.09476
[32m[0906 16-58-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10426, current rewards: 81.98534, mean: 0.09533
[32m[0906 16-58-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10443, current rewards: 87.22148, mean: 0.09585
[32m[0906 16-58-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10456, current rewards: 92.46126, mean: 0.09631
[32m[0906 16-58-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10472, current rewards: 97.69567, mean: 0.09673
[32m[0906 16-59-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10486, current rewards: 103.37093, mean: 0.09752
[32m[0906 16-59-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10504, current rewards: 108.58539, mean: 0.09782
[32m[0906 16-59-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10533, current rewards: 113.79968, mean: 0.09810
[32m[0906 16-59-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10556, current rewards: 119.02430, mean: 0.09837
[32m[0906 16-59-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10579, current rewards: 124.24199, mean: 0.09860
[32m[0906 16-59-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10602, current rewards: 129.77057, mean: 0.09906
[32m[0906 16-59-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10621, current rewards: 135.30059, mean: 0.09949
[32m[0906 16-59-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10639, current rewards: 140.82898, mean: 0.09988
[32m[0906 16-59-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10656, current rewards: 146.14525, mean: 0.10010
[32m[0906 16-59-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10669, current rewards: 151.60832, mean: 0.10040
[32m[0906 16-59-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10687, current rewards: 157.07713, mean: 0.10069
[32m[0906 17-00-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10699, current rewards: 162.54101, mean: 0.10096
[32m[0906 17-00-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10710, current rewards: 168.00687, mean: 0.10121
[32m[0906 17-00-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10723, current rewards: 173.46884, mean: 0.10144
[32m[0906 17-00-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10722, current rewards: 178.92976, mean: 0.10166
[32m[0906 17-00-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10721, current rewards: 184.39371, mean: 0.10187
[32m[0906 17-00-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10723, current rewards: 190.13294, mean: 0.10222
[32m[0906 17-00-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10722, current rewards: 196.45743, mean: 0.10286
[32m[0906 17-00-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10722, current rewards: 203.40900, mean: 0.10378
[32m[0906 17-00-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10723, current rewards: 210.36514, mean: 0.10466
[32m[0906 17-00-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10722, current rewards: 217.31598, mean: 0.10549
[32m[0906 17-00-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10723, current rewards: 224.28039, mean: 0.10629
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10725, current rewards: 231.24253, mean: 0.10706
[32m[0906 17-01-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10725, current rewards: 238.18561, mean: 0.10778
[32m[0906 17-01-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10725, current rewards: 245.14269, mean: 0.10847
[32m[0906 17-01-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10727, current rewards: 252.10339, mean: 0.10914
[32m[0906 17-01-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10727, current rewards: 259.06301, mean: 0.10977
[32m[0906 17-01-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10727, current rewards: 266.03081, mean: 0.11039
[32m[0906 17-01-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10727, current rewards: 272.98638, mean: 0.11097
[32m[0906 17-01-40 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 17-01-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-01-40 @MBExp.py:227][0m Rewards obtained: [266.8859322926269], Lows: [5], Highs: [6], Total time: 10400.638424
[32m[0906 17-03-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-03-09 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 17-03-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10464, current rewards: -4.51295, mean: -0.45129
[32m[0906 17-03-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10381, current rewards: 0.64156, mean: 0.01069
[32m[0906 17-03-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10378, current rewards: 6.17515, mean: 0.05614
[32m[0906 17-03-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10376, current rewards: 11.70364, mean: 0.07315
[32m[0906 17-03-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10380, current rewards: 18.09015, mean: 0.08614
[32m[0906 17-03-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10353, current rewards: 23.82555, mean: 0.09164
[32m[0906 17-03-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10308, current rewards: 29.56420, mean: 0.09537
[32m[0906 17-03-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10273, current rewards: 35.29923, mean: 0.09805
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10243, current rewards: 35.62492, mean: 0.08689
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10230, current rewards: 41.31496, mean: 0.08982
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10216, current rewards: 47.00492, mean: 0.09217
[32m[0906 17-04-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10233, current rewards: 52.69321, mean: 0.09410
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10251, current rewards: 58.42253, mean: 0.09577
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10265, current rewards: 52.06385, mean: 0.07888
[32m[0906 17-04-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10296, current rewards: 57.68573, mean: 0.08125
[32m[0906 17-04-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10328, current rewards: 63.30796, mean: 0.08330
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10351, current rewards: 68.92972, mean: 0.08510
[32m[0906 17-04-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10374, current rewards: 74.55161, mean: 0.08669
[32m[0906 17-04-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10398, current rewards: 80.17313, mean: 0.08810
[32m[0906 17-04-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10418, current rewards: 85.79367, mean: 0.08937
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10433, current rewards: 91.29689, mean: 0.09039
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10453, current rewards: 96.50786, mean: 0.09105
[32m[0906 17-05-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10472, current rewards: 102.07178, mean: 0.09196
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10502, current rewards: 101.88773, mean: 0.08783
[32m[0906 17-05-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10533, current rewards: 107.35244, mean: 0.08872
[32m[0906 17-05-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10557, current rewards: 112.82245, mean: 0.08954
[32m[0906 17-05-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10582, current rewards: 118.29178, mean: 0.09030
[32m[0906 17-05-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10604, current rewards: 123.76155, mean: 0.09100
[32m[0906 17-05-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10624, current rewards: 129.22887, mean: 0.09165
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10640, current rewards: 135.20809, mean: 0.09261
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10658, current rewards: 140.68479, mean: 0.09317
[32m[0906 17-05-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10675, current rewards: 146.16297, mean: 0.09369
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10689, current rewards: 151.64325, mean: 0.09419
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10702, current rewards: 157.49345, mean: 0.09488
[32m[0906 17-06-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10712, current rewards: 164.60664, mean: 0.09626
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10714, current rewards: 171.69592, mean: 0.09755
[32m[0906 17-06-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10714, current rewards: 178.77667, mean: 0.09877
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10714, current rewards: 185.48437, mean: 0.09972
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10716, current rewards: 192.64793, mean: 0.10086
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10716, current rewards: 199.81228, mean: 0.10195
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10716, current rewards: 206.96845, mean: 0.10297
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10719, current rewards: 214.11272, mean: 0.10394
[32m[0906 17-06-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10719, current rewards: 221.26968, mean: 0.10487
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10720, current rewards: 228.42194, mean: 0.10575
[32m[0906 17-07-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10723, current rewards: 235.57448, mean: 0.10659
[32m[0906 17-07-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10722, current rewards: 243.79772, mean: 0.10788
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10722, current rewards: 239.35742, mean: 0.10362
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10725, current rewards: 244.93830, mean: 0.10379
[32m[0906 17-07-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10727, current rewards: 250.51527, mean: 0.10395
[32m[0906 17-07-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10729, current rewards: 256.09424, mean: 0.10410
[32m[0906 17-07-38 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 17-07-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-07-38 @MBExp.py:227][0m Rewards obtained: [260.56000776145174], Lows: [11], Highs: [15], Total time: 10669.681252
[32m[0906 17-09-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-09-09 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 17-09-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10237, current rewards: 0.98559, mean: 0.09856
[32m[0906 17-09-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10399, current rewards: 6.61859, mean: 0.11031
[32m[0906 17-09-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10381, current rewards: 12.24832, mean: 0.11135
[32m[0906 17-09-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10395, current rewards: 17.88269, mean: 0.11177
[32m[0906 17-09-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10405, current rewards: 24.02864, mean: 0.11442
[32m[0906 17-09-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10346, current rewards: 29.68421, mean: 0.11417
[32m[0906 17-09-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10300, current rewards: 35.33996, mean: 0.11400
[32m[0906 17-09-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10275, current rewards: 40.99508, mean: 0.11388
[32m[0906 17-09-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10252, current rewards: 46.64927, mean: 0.11378
[32m[0906 17-09-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10232, current rewards: 52.30309, mean: 0.11370
[32m[0906 17-10-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10228, current rewards: 51.15385, mean: 0.10030
[32m[0906 17-10-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10238, current rewards: 56.83554, mean: 0.10149
[32m[0906 17-10-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10248, current rewards: 62.51033, mean: 0.10248
[32m[0906 17-10-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10264, current rewards: 68.19202, mean: 0.10332
[32m[0906 17-10-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10293, current rewards: 73.87005, mean: 0.10404
[32m[0906 17-10-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10324, current rewards: 69.29067, mean: 0.09117
[32m[0906 17-10-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10352, current rewards: 74.87776, mean: 0.09244
[32m[0906 17-10-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10376, current rewards: 80.46357, mean: 0.09356
[32m[0906 17-10-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10397, current rewards: 86.05189, mean: 0.09456
[32m[0906 17-10-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10419, current rewards: 91.63990, mean: 0.09546
[32m[0906 17-10-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10437, current rewards: 97.10451, mean: 0.09614
[32m[0906 17-11-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10450, current rewards: 102.71255, mean: 0.09690
[32m[0906 17-11-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10467, current rewards: 108.31388, mean: 0.09758
[32m[0906 17-11-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10496, current rewards: 113.91700, mean: 0.09820
[32m[0906 17-11-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10521, current rewards: 118.40512, mean: 0.09786
[32m[0906 17-11-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10547, current rewards: 119.67199, mean: 0.09498
[32m[0906 17-11-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10570, current rewards: 125.36165, mean: 0.09570
[32m[0906 17-11-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10590, current rewards: 131.05772, mean: 0.09637
[32m[0906 17-11-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10613, current rewards: 136.47209, mean: 0.09679
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10631, current rewards: 142.27687, mean: 0.09745
[32m[0906 17-11-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10648, current rewards: 148.07722, mean: 0.09806
[32m[0906 17-11-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10664, current rewards: 153.88876, mean: 0.09865
[32m[0906 17-12-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10679, current rewards: 159.69633, mean: 0.09919
[32m[0906 17-12-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10696, current rewards: 165.21482, mean: 0.09953
[32m[0906 17-12-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10704, current rewards: 171.72880, mean: 0.10043
[32m[0906 17-12-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10706, current rewards: 177.65336, mean: 0.10094
[32m[0906 17-12-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10710, current rewards: 183.51282, mean: 0.10139
[32m[0906 17-12-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10712, current rewards: 189.47142, mean: 0.10187
[32m[0906 17-12-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10713, current rewards: 195.41513, mean: 0.10231
[32m[0906 17-12-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10716, current rewards: 201.35389, mean: 0.10273
[32m[0906 17-12-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10717, current rewards: 207.28721, mean: 0.10313
[32m[0906 17-12-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10717, current rewards: 213.23124, mean: 0.10351
[32m[0906 17-12-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10720, current rewards: 219.17032, mean: 0.10387
[32m[0906 17-13-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10721, current rewards: 225.09877, mean: 0.10421
[32m[0906 17-13-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10723, current rewards: 231.19843, mean: 0.10461
[32m[0906 17-13-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10725, current rewards: 237.14332, mean: 0.10493
[32m[0906 17-13-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10725, current rewards: 243.07436, mean: 0.10523
[32m[0906 17-13-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10726, current rewards: 248.99362, mean: 0.10551
[32m[0906 17-13-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10728, current rewards: 254.91793, mean: 0.10578
[32m[0906 17-13-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10729, current rewards: 260.84170, mean: 0.10603
[32m[0906 17-13-38 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 17-13-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-13-38 @MBExp.py:227][0m Rewards obtained: [254.85033171757087], Lows: [10], Highs: [11], Total time: 10938.669699
[32m[0906 17-15-12 @MBExp.py:144][0m ####################################################################
[32m[0906 17-15-12 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 17-15-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10156, current rewards: -5.66428, mean: -0.56643
[32m[0906 17-15-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10395, current rewards: -0.11245, mean: -0.00187
[32m[0906 17-15-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10389, current rewards: 5.26638, mean: 0.04788
[32m[0906 17-15-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10395, current rewards: 10.78256, mean: 0.06739
[32m[0906 17-15-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10405, current rewards: 16.33885, mean: 0.07780
[32m[0906 17-15-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10342, current rewards: 21.89895, mean: 0.08423
[32m[0906 17-15-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10299, current rewards: 27.46080, mean: 0.08858
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10268, current rewards: 33.01421, mean: 0.09171
[32m[0906 17-15-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10246, current rewards: 38.57901, mean: 0.09410
[32m[0906 17-15-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10231, current rewards: 44.14479, mean: 0.09597
[32m[0906 17-16-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10212, current rewards: 49.71408, mean: 0.09748
[32m[0906 17-16-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10218, current rewards: 45.23606, mean: 0.08078
[32m[0906 17-16-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10234, current rewards: 50.74048, mean: 0.08318
[32m[0906 17-16-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10249, current rewards: 56.24591, mean: 0.08522
[32m[0906 17-16-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10275, current rewards: 51.26778, mean: 0.07221
[32m[0906 17-16-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10307, current rewards: 56.86833, mean: 0.07483
[32m[0906 17-16-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10336, current rewards: 62.39731, mean: 0.07703
[32m[0906 17-16-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10365, current rewards: 67.92700, mean: 0.07898
[32m[0906 17-16-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10385, current rewards: 73.45653, mean: 0.08072
[32m[0906 17-16-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10402, current rewards: 78.58081, mean: 0.08186
[32m[0906 17-16-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10422, current rewards: 78.40282, mean: 0.07763
[32m[0906 17-17-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10437, current rewards: 83.75491, mean: 0.07901
[32m[0906 17-17-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10454, current rewards: 89.10239, mean: 0.08027
[32m[0906 17-17-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10484, current rewards: 94.45543, mean: 0.08143
[32m[0906 17-17-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10511, current rewards: 99.80440, mean: 0.08248
[32m[0906 17-17-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10542, current rewards: 105.15023, mean: 0.08345
[32m[0906 17-17-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10570, current rewards: 110.49971, mean: 0.08435
[32m[0906 17-17-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10594, current rewards: 115.88100, mean: 0.08521
[32m[0906 17-17-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10616, current rewards: 121.22412, mean: 0.08597
[32m[0906 17-17-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10632, current rewards: 121.45574, mean: 0.08319
[32m[0906 17-17-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10649, current rewards: 127.57114, mean: 0.08448
[32m[0906 17-17-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10665, current rewards: 133.67760, mean: 0.08569
[32m[0906 17-18-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10679, current rewards: 139.78344, mean: 0.08682
[32m[0906 17-18-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10691, current rewards: 145.90230, mean: 0.08789
[32m[0906 17-18-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10698, current rewards: 152.00099, mean: 0.08889
[32m[0906 17-18-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10699, current rewards: 158.79269, mean: 0.09022
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10698, current rewards: 164.77023, mean: 0.09103
[32m[0906 17-18-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10700, current rewards: 170.74769, mean: 0.09180
[32m[0906 17-18-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10702, current rewards: 176.72557, mean: 0.09253
[32m[0906 17-18-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10702, current rewards: 182.24926, mean: 0.09298
[32m[0906 17-18-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10703, current rewards: 187.81822, mean: 0.09344
[32m[0906 17-18-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10704, current rewards: 193.39564, mean: 0.09388
[32m[0906 17-18-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10704, current rewards: 198.97157, mean: 0.09430
[32m[0906 17-19-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10706, current rewards: 204.46591, mean: 0.09466
[32m[0906 17-19-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10706, current rewards: 210.03420, mean: 0.09504
[32m[0906 17-19-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10708, current rewards: 215.60758, mean: 0.09540
[32m[0906 17-19-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10709, current rewards: 221.18079, mean: 0.09575
[32m[0906 17-19-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10709, current rewards: 230.83336, mean: 0.09781
[32m[0906 17-19-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10711, current rewards: 236.85028, mean: 0.09828
[32m[0906 17-19-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10711, current rewards: 242.85331, mean: 0.09872
[32m[0906 17-19-40 @Agent.py:117][0m Average action selection time: 0.1071
[32m[0906 17-19-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-19-41 @MBExp.py:227][0m Rewards obtained: [247.66799528078974], Lows: [10], Highs: [16], Total time: 11207.194084
[32m[0906 17-21-16 @MBExp.py:144][0m ####################################################################
[32m[0906 17-21-16 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10320, current rewards: -4.35311, mean: -0.43531
[32m[0906 17-21-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10337, current rewards: 1.16770, mean: 0.01946
[32m[0906 17-21-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10385, current rewards: 6.56652, mean: 0.05970
[32m[0906 17-21-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10374, current rewards: 12.10387, mean: 0.07565
[32m[0906 17-21-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10356, current rewards: 17.63821, mean: 0.08399
[32m[0906 17-21-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10313, current rewards: 23.17463, mean: 0.08913
[32m[0906 17-21-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10268, current rewards: 28.70943, mean: 0.09261
[32m[0906 17-21-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10239, current rewards: 34.24458, mean: 0.09512
[32m[0906 17-21-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10227, current rewards: 39.78080, mean: 0.09703
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10209, current rewards: 45.31512, mean: 0.09851
[32m[0906 17-22-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10191, current rewards: 50.48890, mean: 0.09900
[32m[0906 17-22-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10184, current rewards: 55.97921, mean: 0.09996
[32m[0906 17-22-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10200, current rewards: 56.67873, mean: 0.09292
[32m[0906 17-22-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10212, current rewards: 63.73969, mean: 0.09658
[32m[0906 17-22-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10230, current rewards: 69.37567, mean: 0.09771
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10267, current rewards: 75.01106, mean: 0.09870
[32m[0906 17-22-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10298, current rewards: 80.64795, mean: 0.09957
[32m[0906 17-22-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10328, current rewards: 86.28247, mean: 0.10033
[32m[0906 17-22-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10351, current rewards: 92.60791, mean: 0.10177
[32m[0906 17-22-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10371, current rewards: 98.71834, mean: 0.10283
[32m[0906 17-23-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10394, current rewards: 92.11297, mean: 0.09120
[32m[0906 17-23-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10413, current rewards: 97.73153, mean: 0.09220
[32m[0906 17-23-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10431, current rewards: 103.34918, mean: 0.09311
[32m[0906 17-23-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10460, current rewards: 108.96848, mean: 0.09394
[32m[0906 17-23-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10489, current rewards: 114.58650, mean: 0.09470
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10513, current rewards: 120.20650, mean: 0.09540
[32m[0906 17-23-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10538, current rewards: 119.47204, mean: 0.09120
[32m[0906 17-23-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10559, current rewards: 125.04863, mean: 0.09195
[32m[0906 17-23-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10582, current rewards: 130.64291, mean: 0.09265
[32m[0906 17-23-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10599, current rewards: 136.23173, mean: 0.09331
[32m[0906 17-23-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10615, current rewards: 141.53782, mean: 0.09373
[32m[0906 17-24-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10633, current rewards: 146.99681, mean: 0.09423
[32m[0906 17-24-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10648, current rewards: 152.46424, mean: 0.09470
[32m[0906 17-24-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10661, current rewards: 157.93048, mean: 0.09514
[32m[0906 17-24-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10668, current rewards: 163.36528, mean: 0.09554
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10671, current rewards: 168.25424, mean: 0.09560
[32m[0906 17-24-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10672, current rewards: 173.63860, mean: 0.09593
[32m[0906 17-24-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10675, current rewards: 179.02455, mean: 0.09625
[32m[0906 17-24-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10676, current rewards: 183.67311, mean: 0.09616
[32m[0906 17-24-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10678, current rewards: 188.47165, mean: 0.09616
[32m[0906 17-24-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10680, current rewards: 193.26685, mean: 0.09615
[32m[0906 17-24-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10681, current rewards: 198.06268, mean: 0.09615
[32m[0906 17-25-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10683, current rewards: 202.85436, mean: 0.09614
[32m[0906 17-25-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10686, current rewards: 207.82183, mean: 0.09621
[32m[0906 17-25-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10688, current rewards: 212.71647, mean: 0.09625
[32m[0906 17-25-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10689, current rewards: 217.61245, mean: 0.09629
[32m[0906 17-25-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10692, current rewards: 222.50864, mean: 0.09632
[32m[0906 17-25-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10692, current rewards: 217.29397, mean: 0.09207
[32m[0906 17-25-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10693, current rewards: 222.82966, mean: 0.09246
[32m[0906 17-25-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10696, current rewards: 228.36603, mean: 0.09283
[32m[0906 17-25-44 @Agent.py:117][0m Average action selection time: 0.1070
[32m[0906 17-25-44 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-25-44 @MBExp.py:227][0m Rewards obtained: [232.79322714559754], Lows: [11], Highs: [16], Total time: 11475.368866
[32m[0906 17-27-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-27-23 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 17-27-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10346, current rewards: -5.55194, mean: -0.55519
[32m[0906 17-27-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10489, current rewards: 1.74681, mean: 0.02911
[32m[0906 17-27-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10492, current rewards: 8.31349, mean: 0.07558
[32m[0906 17-27-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10475, current rewards: 14.66199, mean: 0.09164
[32m[0906 17-27-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10438, current rewards: 21.01581, mean: 0.10008
[32m[0906 17-27-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10368, current rewards: 27.37143, mean: 0.10527
[32m[0906 17-27-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10328, current rewards: 23.07645, mean: 0.07444
[32m[0906 17-28-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10308, current rewards: 29.12510, mean: 0.08090
[32m[0906 17-28-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10277, current rewards: 35.17261, mean: 0.08579
[32m[0906 17-28-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10259, current rewards: 41.22358, mean: 0.08962
[32m[0906 17-28-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10244, current rewards: 47.27707, mean: 0.09270
[32m[0906 17-28-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10232, current rewards: 53.32466, mean: 0.09522
[32m[0906 17-28-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10238, current rewards: 59.37042, mean: 0.09733
[32m[0906 17-28-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10249, current rewards: 59.79824, mean: 0.09060
[32m[0906 17-28-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10266, current rewards: 67.21243, mean: 0.09467
[32m[0906 17-28-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10293, current rewards: 74.58305, mean: 0.09814
[32m[0906 17-28-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10322, current rewards: 81.95863, mean: 0.10118
[32m[0906 17-28-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10354, current rewards: 76.24396, mean: 0.08866
[32m[0906 17-28-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10376, current rewards: 83.11445, mean: 0.09133
[32m[0906 17-29-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10397, current rewards: 89.15971, mean: 0.09287
[32m[0906 17-29-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10418, current rewards: 95.20498, mean: 0.09426
[32m[0906 17-29-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10434, current rewards: 101.25025, mean: 0.09552
[32m[0906 17-29-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10455, current rewards: 107.29551, mean: 0.09666
[32m[0906 17-29-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10476, current rewards: 113.34078, mean: 0.09771
[32m[0906 17-29-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10504, current rewards: 63.34078, mean: 0.05235
[32m[0906 17-29-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10531, current rewards: 13.34078, mean: 0.01059
[32m[0906 17-29-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10553, current rewards: -36.65922, mean: -0.02798
[32m[0906 17-29-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10576, current rewards: -86.65922, mean: -0.06372
[32m[0906 17-29-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10598, current rewards: -136.65922, mean: -0.09692
[32m[0906 17-29-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10618, current rewards: -186.65922, mean: -0.12785
[32m[0906 17-30-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10635, current rewards: -236.65922, mean: -0.15673
[32m[0906 17-30-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10654, current rewards: -286.65922, mean: -0.18376
[32m[0906 17-30-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10670, current rewards: -336.65922, mean: -0.20911
[32m[0906 17-30-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10684, current rewards: -386.65922, mean: -0.23293
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10691, current rewards: -436.65922, mean: -0.25536
[32m[0906 17-30-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10692, current rewards: -486.65922, mean: -0.27651
[32m[0906 17-30-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10695, current rewards: -536.65922, mean: -0.29650
[32m[0906 17-30-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10697, current rewards: -586.65922, mean: -0.31541
[32m[0906 17-30-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10698, current rewards: -636.65922, mean: -0.33333
[32m[0906 17-30-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10699, current rewards: -686.65922, mean: -0.35034
[32m[0906 17-30-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10702, current rewards: -736.65922, mean: -0.36650
[32m[0906 17-31-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10702, current rewards: -786.65922, mean: -0.38187
[32m[0906 17-31-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10703, current rewards: -836.65922, mean: -0.39652
[32m[0906 17-31-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10707, current rewards: -886.65922, mean: -0.41049
[32m[0906 17-31-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10708, current rewards: -936.65922, mean: -0.42383
[32m[0906 17-31-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10709, current rewards: -986.65922, mean: -0.43657
[32m[0906 17-31-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10713, current rewards: -1036.65922, mean: -0.44877
[32m[0906 17-31-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10715, current rewards: -1086.65922, mean: -0.46045
[32m[0906 17-31-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10716, current rewards: -1136.65922, mean: -0.47164
[32m[0906 17-31-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10718, current rewards: -1186.65922, mean: -0.48238
[32m[0906 17-31-51 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 17-31-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-31-51 @MBExp.py:227][0m Rewards obtained: [-1226.6592238570404], Lows: [12], Highs: [1351], Total time: 11744.066476
[32m[0906 17-33-32 @MBExp.py:144][0m ####################################################################
[32m[0906 17-33-32 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 17-33-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10822, current rewards: -4.66626, mean: -0.46663
[32m[0906 17-33-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10619, current rewards: 0.04033, mean: 0.00067
[32m[0906 17-33-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10512, current rewards: 5.27625, mean: 0.04797
[32m[0906 17-33-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10475, current rewards: 10.23270, mean: 0.06395
[32m[0906 17-33-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10441, current rewards: 15.19349, mean: 0.07235
[32m[0906 17-33-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10370, current rewards: 20.14216, mean: 0.07747
[32m[0906 17-34-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10327, current rewards: 25.09847, mean: 0.08096
[32m[0906 17-34-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10298, current rewards: 30.05673, mean: 0.08349
[32m[0906 17-34-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10272, current rewards: 25.37914, mean: 0.06190
[32m[0906 17-34-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10252, current rewards: 31.19030, mean: 0.06780
[32m[0906 17-34-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10243, current rewards: 37.14821, mean: 0.07284
[32m[0906 17-34-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10232, current rewards: 42.96743, mean: 0.07673
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10223, current rewards: 48.79437, mean: 0.07999
[32m[0906 17-34-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10246, current rewards: 49.01480, mean: 0.07426
[32m[0906 17-34-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10260, current rewards: 54.77210, mean: 0.07714
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10271, current rewards: 60.53115, mean: 0.07965
[32m[0906 17-34-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10282, current rewards: 66.28167, mean: 0.08183
[32m[0906 17-35-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10290, current rewards: 72.04055, mean: 0.08377
[32m[0906 17-35-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10296, current rewards: 77.62633, mean: 0.08530
[32m[0906 17-35-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10308, current rewards: 83.32918, mean: 0.08680
[32m[0906 17-35-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10315, current rewards: 89.02558, mean: 0.08814
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10337, current rewards: 94.72588, mean: 0.08936
[32m[0906 17-35-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10360, current rewards: 100.42650, mean: 0.09047
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10380, current rewards: 106.12856, mean: 0.09149
[32m[0906 17-35-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10412, current rewards: 111.48400, mean: 0.09214
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10444, current rewards: 117.02199, mean: 0.09287
[32m[0906 17-35-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10471, current rewards: 122.69564, mean: 0.09366
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10495, current rewards: 128.24107, mean: 0.09429
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10520, current rewards: 133.78263, mean: 0.09488
[32m[0906 17-36-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10542, current rewards: 139.33489, mean: 0.09543
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10565, current rewards: 144.86942, mean: 0.09594
[32m[0906 17-36-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10585, current rewards: 150.41781, mean: 0.09642
[32m[0906 17-36-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10603, current rewards: 155.96316, mean: 0.09687
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10621, current rewards: 161.50924, mean: 0.09729
[32m[0906 17-36-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10628, current rewards: 166.97918, mean: 0.09765
[32m[0906 17-36-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10633, current rewards: 172.51596, mean: 0.09802
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10638, current rewards: 168.43866, mean: 0.09306
[32m[0906 17-36-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10643, current rewards: 174.12749, mean: 0.09362
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10647, current rewards: 179.82755, mean: 0.09415
[32m[0906 17-37-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10652, current rewards: 185.52679, mean: 0.09466
[32m[0906 17-37-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10656, current rewards: 191.22546, mean: 0.09514
[32m[0906 17-37-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10659, current rewards: 196.92306, mean: 0.09559
[32m[0906 17-37-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10664, current rewards: 202.61987, mean: 0.09603
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10667, current rewards: 208.31890, mean: 0.09644
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10670, current rewards: 214.01864, mean: 0.09684
[32m[0906 17-37-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10677, current rewards: 210.98484, mean: 0.09336
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10681, current rewards: 215.77252, mean: 0.09341
[32m[0906 17-37-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10682, current rewards: 220.56733, mean: 0.09346
[32m[0906 17-37-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10685, current rewards: 225.36061, mean: 0.09351
[32m[0906 17-37-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10686, current rewards: 230.14865, mean: 0.09356
[32m[0906 17-38-00 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 17-38-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-38-00 @MBExp.py:227][0m Rewards obtained: [234.2196338936535], Lows: [11], Highs: [16], Total time: 12011.989106
[32m[0906 17-39-43 @MBExp.py:144][0m ####################################################################
[32m[0906 17-39-43 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 17-39-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10642, current rewards: -5.55294, mean: -0.55529
[32m[0906 17-39-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10576, current rewards: -0.02203, mean: -0.00037
[32m[0906 17-39-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10517, current rewards: 5.50025, mean: 0.05000
[32m[0906 17-40-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10491, current rewards: 11.02169, mean: 0.06889
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10414, current rewards: 16.54137, mean: 0.07877
[32m[0906 17-40-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10344, current rewards: 22.06447, mean: 0.08486
[32m[0906 17-40-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10312, current rewards: 27.58102, mean: 0.08897
[32m[0906 17-40-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10281, current rewards: 33.10502, mean: 0.09196
[32m[0906 17-40-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10259, current rewards: 39.02246, mean: 0.09518
[32m[0906 17-40-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10242, current rewards: 44.65897, mean: 0.09708
[32m[0906 17-40-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10229, current rewards: 40.04689, mean: 0.07852
[32m[0906 17-40-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10214, current rewards: 45.94294, mean: 0.08204
[32m[0906 17-40-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10208, current rewards: 51.84371, mean: 0.08499
[32m[0906 17-40-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10216, current rewards: 57.74101, mean: 0.08749
[32m[0906 17-40-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10230, current rewards: 63.64025, mean: 0.08963
[32m[0906 17-41-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10245, current rewards: 59.80109, mean: 0.07869
[32m[0906 17-41-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10253, current rewards: 66.40932, mean: 0.08199
[32m[0906 17-41-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10261, current rewards: 74.60480, mean: 0.08675
[32m[0906 17-41-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10270, current rewards: 82.90492, mean: 0.09110
[32m[0906 17-41-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10274, current rewards: 91.20504, mean: 0.09501
[32m[0906 17-41-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10280, current rewards: 98.33915, mean: 0.09737
[32m[0906 17-41-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10301, current rewards: 48.33915, mean: 0.04560
[32m[0906 17-41-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10321, current rewards: -1.66085, mean: -0.00150
[32m[0906 17-41-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10340, current rewards: -51.66085, mean: -0.04454
[32m[0906 17-41-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10371, current rewards: -101.66085, mean: -0.08402
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10401, current rewards: -151.66085, mean: -0.12037
[32m[0906 17-42-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10430, current rewards: -201.66085, mean: -0.15394
[32m[0906 17-42-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10459, current rewards: -251.66085, mean: -0.18504
[32m[0906 17-42-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10484, current rewards: -301.66085, mean: -0.21394
[32m[0906 17-42-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10507, current rewards: -351.66085, mean: -0.24086
[32m[0906 17-42-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10530, current rewards: -401.66085, mean: -0.26600
[32m[0906 17-42-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10548, current rewards: -451.66085, mean: -0.28953
[32m[0906 17-42-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10570, current rewards: -501.66085, mean: -0.31159
[32m[0906 17-42-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10589, current rewards: -551.66085, mean: -0.33233
[32m[0906 17-42-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10596, current rewards: -601.66085, mean: -0.35185
[32m[0906 17-42-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10603, current rewards: -651.66085, mean: -0.37026
[32m[0906 17-42-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10606, current rewards: -701.66085, mean: -0.38766
[32m[0906 17-43-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10611, current rewards: -751.66085, mean: -0.40412
[32m[0906 17-43-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10617, current rewards: -801.66085, mean: -0.41972
[32m[0906 17-43-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10621, current rewards: -851.66085, mean: -0.43452
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10624, current rewards: -901.66085, mean: -0.44859
[32m[0906 17-43-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10630, current rewards: -951.66085, mean: -0.46197
[32m[0906 17-43-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10633, current rewards: -1001.66085, mean: -0.47472
[32m[0906 17-43-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10636, current rewards: -1051.66085, mean: -0.48688
[32m[0906 17-43-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10640, current rewards: -1101.66085, mean: -0.49849
[32m[0906 17-43-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10641, current rewards: -1151.66085, mean: -0.50958
[32m[0906 17-43-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10644, current rewards: -1201.66085, mean: -0.52020
[32m[0906 17-43-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10648, current rewards: -1251.66085, mean: -0.53036
[32m[0906 17-44-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10650, current rewards: -1301.66085, mean: -0.54011
[32m[0906 17-44-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10652, current rewards: -1351.66085, mean: -0.54946
[32m[0906 17-44-10 @Agent.py:117][0m Average action selection time: 0.1065
[32m[0906 17-44-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-44-10 @MBExp.py:227][0m Rewards obtained: [-1391.6608456464362], Lows: [10], Highs: [1497], Total time: 12279.106031000001
[32m[0906 17-45-55 @MBExp.py:144][0m ####################################################################
[32m[0906 17-45-55 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 17-45-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10768, current rewards: -4.59720, mean: -0.45972
[32m[0906 17-46-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10684, current rewards: 0.79260, mean: 0.01321
[32m[0906 17-46-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10641, current rewards: 6.33384, mean: 0.05758
[32m[0906 17-46-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10595, current rewards: 11.88480, mean: 0.07428
[32m[0906 17-46-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10539, current rewards: 17.43016, mean: 0.08300
[32m[0906 17-46-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10466, current rewards: 22.97272, mean: 0.08836
[32m[0906 17-46-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10420, current rewards: 28.51551, mean: 0.09199
[32m[0906 17-46-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10391, current rewards: 34.05953, mean: 0.09461
[32m[0906 17-46-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10358, current rewards: 39.68661, mean: 0.09680
[32m[0906 17-46-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10330, current rewards: 35.26167, mean: 0.07666
[32m[0906 17-46-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10313, current rewards: 41.52446, mean: 0.08142
[32m[0906 17-46-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10299, current rewards: 47.74536, mean: 0.08526
[32m[0906 17-46-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10289, current rewards: 53.96138, mean: 0.08846
[32m[0906 17-47-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10289, current rewards: 60.18157, mean: 0.09118
[32m[0906 17-47-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10304, current rewards: 65.71720, mean: 0.09256
[32m[0906 17-47-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10313, current rewards: 71.40918, mean: 0.09396
[32m[0906 17-47-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10322, current rewards: 77.09508, mean: 0.09518
[32m[0906 17-47-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10329, current rewards: 82.41672, mean: 0.09583
[32m[0906 17-47-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10340, current rewards: 88.07907, mean: 0.09679
[32m[0906 17-47-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10351, current rewards: 93.73512, mean: 0.09764
[32m[0906 17-47-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10360, current rewards: 99.39469, mean: 0.09841
[32m[0906 17-47-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10368, current rewards: 105.05750, mean: 0.09911
[32m[0906 17-47-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10388, current rewards: 110.71672, mean: 0.09974
[32m[0906 17-47-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10407, current rewards: 116.37526, mean: 0.10032
[32m[0906 17-48-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10426, current rewards: 122.04310, mean: 0.10086
[32m[0906 17-48-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10460, current rewards: 118.42922, mean: 0.09399
[32m[0906 17-48-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10484, current rewards: 125.06843, mean: 0.09547
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10510, current rewards: 131.38386, mean: 0.09661
[32m[0906 17-48-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10534, current rewards: 137.69929, mean: 0.09766
[32m[0906 17-48-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10554, current rewards: 144.01471, mean: 0.09864
[32m[0906 17-48-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10574, current rewards: 150.33014, mean: 0.09956
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10596, current rewards: 105.96168, mean: 0.06792
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10612, current rewards: 55.96168, mean: 0.03476
[32m[0906 17-48-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10628, current rewards: 5.96168, mean: 0.00359
[32m[0906 17-48-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10641, current rewards: -44.03832, mean: -0.02575
[32m[0906 17-49-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10645, current rewards: -94.03832, mean: -0.05343
[32m[0906 17-49-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10648, current rewards: -144.03832, mean: -0.07958
[32m[0906 17-49-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10652, current rewards: -194.03832, mean: -0.10432
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10655, current rewards: -244.03832, mean: -0.12777
[32m[0906 17-49-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10659, current rewards: -294.03832, mean: -0.15002
[32m[0906 17-49-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10663, current rewards: -344.03832, mean: -0.17116
[32m[0906 17-49-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10667, current rewards: -394.03832, mean: -0.19128
[32m[0906 17-49-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10669, current rewards: -444.03832, mean: -0.21044
[32m[0906 17-49-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10672, current rewards: -494.03832, mean: -0.22872
[32m[0906 17-49-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10674, current rewards: -544.03832, mean: -0.24617
[32m[0906 17-49-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10677, current rewards: -594.03832, mean: -0.26285
[32m[0906 17-50-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10679, current rewards: -644.03832, mean: -0.27880
[32m[0906 17-50-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10682, current rewards: -694.03832, mean: -0.29408
[32m[0906 17-50-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10683, current rewards: -744.03832, mean: -0.30873
[32m[0906 17-50-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10686, current rewards: -740.03676, mean: -0.30083
[32m[0906 17-50-23 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 17-50-23 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-50-23 @MBExp.py:227][0m Rewards obtained: [-734.9671633992242], Lows: [10], Highs: [902], Total time: 12547.060132
[32m[0906 17-52-11 @MBExp.py:144][0m ####################################################################
[32m[0906 17-52-11 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 17-52-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10705, current rewards: -4.48224, mean: -0.44822
[32m[0906 17-52-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10531, current rewards: 1.14532, mean: 0.01909
[32m[0906 17-52-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10503, current rewards: 7.34922, mean: 0.06681
[32m[0906 17-52-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10470, current rewards: 13.54964, mean: 0.08469
[32m[0906 17-52-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10425, current rewards: 19.75561, mean: 0.09407
[32m[0906 17-52-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10375, current rewards: 25.95289, mean: 0.09982
[32m[0906 17-52-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10330, current rewards: 32.15835, mean: 0.10374
[32m[0906 17-52-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10297, current rewards: 38.35532, mean: 0.10654
[32m[0906 17-52-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10279, current rewards: 44.56002, mean: 0.10868
[32m[0906 17-52-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10256, current rewards: 40.18571, mean: 0.08736
[32m[0906 17-53-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10242, current rewards: 46.14242, mean: 0.09048
[32m[0906 17-53-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10226, current rewards: 51.85316, mean: 0.09259
[32m[0906 17-53-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10217, current rewards: 57.56389, mean: 0.09437
[32m[0906 17-53-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10209, current rewards: 55.41989, mean: 0.08397
[32m[0906 17-53-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10221, current rewards: 60.98726, mean: 0.08590
[32m[0906 17-53-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10237, current rewards: 66.65490, mean: 0.08770
[32m[0906 17-53-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10248, current rewards: 72.32499, mean: 0.08929
[32m[0906 17-53-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10257, current rewards: 77.99502, mean: 0.09069
[32m[0906 17-53-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10271, current rewards: 83.69772, mean: 0.09198
[32m[0906 17-53-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10280, current rewards: 89.11166, mean: 0.09282
[32m[0906 17-53-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10290, current rewards: 94.73784, mean: 0.09380
[32m[0906 17-54-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10300, current rewards: 100.35922, mean: 0.09468
[32m[0906 17-54-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10320, current rewards: 105.98483, mean: 0.09548
[32m[0906 17-54-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10340, current rewards: 111.61239, mean: 0.09622
[32m[0906 17-54-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10361, current rewards: 114.52489, mean: 0.09465
[32m[0906 17-54-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10388, current rewards: 120.66208, mean: 0.09576
[32m[0906 17-54-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10419, current rewards: 126.25765, mean: 0.09638
[32m[0906 17-54-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10450, current rewards: 132.35639, mean: 0.09732
[32m[0906 17-54-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10475, current rewards: 138.45627, mean: 0.09820
[32m[0906 17-54-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10502, current rewards: 144.54886, mean: 0.09901
[32m[0906 17-54-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10524, current rewards: 150.65621, mean: 0.09977
[32m[0906 17-54-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10545, current rewards: 156.74836, mean: 0.10048
[32m[0906 17-55-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10566, current rewards: 162.60994, mean: 0.10100
[32m[0906 17-55-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10586, current rewards: 167.60368, mean: 0.10097
[32m[0906 17-55-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10598, current rewards: 172.59909, mean: 0.10094
[32m[0906 17-55-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10605, current rewards: 177.60612, mean: 0.10091
[32m[0906 17-55-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10610, current rewards: 182.61131, mean: 0.10089
[32m[0906 17-55-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10614, current rewards: 187.61128, mean: 0.10087
[32m[0906 17-55-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10620, current rewards: 180.32733, mean: 0.09441
[32m[0906 17-55-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10623, current rewards: 186.04368, mean: 0.09492
[32m[0906 17-55-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10626, current rewards: 191.75930, mean: 0.09540
[32m[0906 17-55-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10631, current rewards: 197.48164, mean: 0.09586
[32m[0906 17-55-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10633, current rewards: 203.13255, mean: 0.09627
[32m[0906 17-56-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10637, current rewards: 208.84066, mean: 0.09669
[32m[0906 17-56-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10641, current rewards: 214.55094, mean: 0.09708
[32m[0906 17-56-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10644, current rewards: 220.26351, mean: 0.09746
[32m[0906 17-56-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10647, current rewards: 225.97291, mean: 0.09782
[32m[0906 17-56-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10653, current rewards: 231.68234, mean: 0.09817
[32m[0906 17-56-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10656, current rewards: 237.39029, mean: 0.09850
[32m[0906 17-56-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10659, current rewards: 243.10085, mean: 0.09882
[32m[0906 17-56-38 @Agent.py:117][0m Average action selection time: 0.1066
[32m[0906 17-56-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-56-38 @MBExp.py:227][0m Rewards obtained: [248.12464166489298], Lows: [13], Highs: [12], Total time: 12814.387226
[32m[0906 17-58-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-58-28 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 17-58-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10692, current rewards: -4.11268, mean: -0.41127
[32m[0906 17-58-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10506, current rewards: 2.03523, mean: 0.03392
[32m[0906 17-58-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10442, current rewards: 7.83935, mean: 0.07127
[32m[0906 17-58-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10436, current rewards: 13.64640, mean: 0.08529
[32m[0906 17-58-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10408, current rewards: 13.99321, mean: 0.06663
[32m[0906 17-58-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10336, current rewards: 19.45840, mean: 0.07484
[32m[0906 17-59-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10307, current rewards: 24.92988, mean: 0.08042
[32m[0906 17-59-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10273, current rewards: 30.39950, mean: 0.08444
[32m[0906 17-59-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10248, current rewards: 35.86668, mean: 0.08748
[32m[0906 17-59-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10231, current rewards: 30.38054, mean: 0.06604
[32m[0906 17-59-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10221, current rewards: 36.00574, mean: 0.07060
[32m[0906 17-59-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10206, current rewards: 41.62519, mean: 0.07433
[32m[0906 17-59-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10200, current rewards: 47.24374, mean: 0.07745
[32m[0906 17-59-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10192, current rewards: 52.86325, mean: 0.08010
[32m[0906 17-59-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10190, current rewards: 58.48292, mean: 0.08237
[32m[0906 17-59-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10206, current rewards: 64.09719, mean: 0.08434
[32m[0906 17-59-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10220, current rewards: 69.71450, mean: 0.08607
[32m[0906 17-59-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10229, current rewards: 70.36023, mean: 0.08181
[32m[0906 18-00-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10238, current rewards: 76.07105, mean: 0.08359
[32m[0906 18-00-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10249, current rewards: 81.77726, mean: 0.08518
[32m[0906 18-00-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10256, current rewards: 87.50028, mean: 0.08663
[32m[0906 18-00-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10261, current rewards: 93.21358, mean: 0.08794
[32m[0906 18-00-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10277, current rewards: 98.93690, mean: 0.08913
[32m[0906 18-00-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10298, current rewards: 104.65957, mean: 0.09022
[32m[0906 18-00-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10318, current rewards: 110.38379, mean: 0.09123
[32m[0906 18-00-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10337, current rewards: 116.47946, mean: 0.09244
[32m[0906 18-00-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10367, current rewards: 122.07909, mean: 0.09319
[32m[0906 18-00-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10398, current rewards: 127.57751, mean: 0.09381
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10424, current rewards: 133.07921, mean: 0.09438
[32m[0906 18-01-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10447, current rewards: 138.57268, mean: 0.09491
[32m[0906 18-01-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10472, current rewards: 144.12238, mean: 0.09545
[32m[0906 18-01-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10493, current rewards: 149.84582, mean: 0.09606
[32m[0906 18-01-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10513, current rewards: 155.56556, mean: 0.09662
[32m[0906 18-01-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10534, current rewards: 161.28983, mean: 0.09716
[32m[0906 18-01-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10546, current rewards: 167.09346, mean: 0.09772
[32m[0906 18-01-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10552, current rewards: 172.84666, mean: 0.09821
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10561, current rewards: 178.60265, mean: 0.09868
[32m[0906 18-01-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10566, current rewards: 173.69270, mean: 0.09338
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10572, current rewards: 179.25966, mean: 0.09385
[32m[0906 18-01-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10580, current rewards: 184.82899, mean: 0.09430
[32m[0906 18-02-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10584, current rewards: 190.39777, mean: 0.09473
[32m[0906 18-02-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10588, current rewards: 195.96692, mean: 0.09513
[32m[0906 18-02-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10595, current rewards: 201.27122, mean: 0.09539
[32m[0906 18-02-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10599, current rewards: 206.83842, mean: 0.09576
[32m[0906 18-02-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10603, current rewards: 212.40770, mean: 0.09611
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10608, current rewards: 217.97262, mean: 0.09645
[32m[0906 18-02-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10612, current rewards: 223.54285, mean: 0.09677
[32m[0906 18-02-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10615, current rewards: 229.10813, mean: 0.09708
[32m[0906 18-02-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10620, current rewards: 234.67488, mean: 0.09738
[32m[0906 18-02-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10623, current rewards: 229.67651, mean: 0.09336
[32m[0906 18-02-54 @Agent.py:117][0m Average action selection time: 0.1062
[32m[0906 18-02-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-02-54 @MBExp.py:227][0m Rewards obtained: [234.74325061743033], Lows: [15], Highs: [15], Total time: 13080.769100000001
[32m[0906 18-04-47 @MBExp.py:144][0m ####################################################################
[32m[0906 18-04-47 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 18-04-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11135, current rewards: -4.64332, mean: -0.46433
[32m[0906 18-04-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10650, current rewards: 0.94695, mean: 0.01578
[32m[0906 18-04-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10575, current rewards: 6.56073, mean: 0.05964
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10539, current rewards: 12.16733, mean: 0.07605
[32m[0906 18-05-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10492, current rewards: 17.77951, mean: 0.08466
[32m[0906 18-05-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10412, current rewards: 13.28058, mean: 0.05108
[32m[0906 18-05-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10359, current rewards: 19.33824, mean: 0.06238
[32m[0906 18-05-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10328, current rewards: 25.39737, mean: 0.07055
[32m[0906 18-05-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10298, current rewards: 31.68194, mean: 0.07727
[32m[0906 18-05-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10272, current rewards: 38.38634, mean: 0.08345
[32m[0906 18-05-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10257, current rewards: 44.59101, mean: 0.08743
[32m[0906 18-05-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10241, current rewards: 50.79665, mean: 0.09071
[32m[0906 18-05-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10233, current rewards: 56.19698, mean: 0.09213
[32m[0906 18-05-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10226, current rewards: 61.65051, mean: 0.09341
[32m[0906 18-05-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10217, current rewards: 67.10402, mean: 0.09451
[32m[0906 18-06-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10227, current rewards: 72.55903, mean: 0.09547
[32m[0906 18-06-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10242, current rewards: 58.22952, mean: 0.07189
[32m[0906 18-06-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10254, current rewards: 44.81513, mean: 0.05211
[32m[0906 18-06-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10264, current rewards: -5.18487, mean: -0.00570
[32m[0906 18-06-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10274, current rewards: -55.18487, mean: -0.05748
[32m[0906 18-06-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10283, current rewards: -105.18487, mean: -0.10414
[32m[0906 18-06-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10289, current rewards: -155.18487, mean: -0.14640
[32m[0906 18-06-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10297, current rewards: -205.18487, mean: -0.18485
[32m[0906 18-06-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10316, current rewards: -255.18487, mean: -0.21999
[32m[0906 18-06-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10335, current rewards: -305.18487, mean: -0.25222
[32m[0906 18-06-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10356, current rewards: -355.18487, mean: -0.28189
[32m[0906 18-07-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10380, current rewards: -351.61495, mean: -0.26841
[32m[0906 18-07-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10409, current rewards: -347.87241, mean: -0.25579
[32m[0906 18-07-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10437, current rewards: -344.12988, mean: -0.24406
[32m[0906 18-07-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10462, current rewards: -340.38734, mean: -0.23314
[32m[0906 18-07-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10484, current rewards: -381.78854, mean: -0.25284
[32m[0906 18-07-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10509, current rewards: -431.78854, mean: -0.27679
[32m[0906 18-07-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10532, current rewards: -481.78854, mean: -0.29925
[32m[0906 18-07-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10552, current rewards: -531.78854, mean: -0.32035
[32m[0906 18-07-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10565, current rewards: -581.78854, mean: -0.34023
[32m[0906 18-07-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10571, current rewards: -631.78854, mean: -0.35897
[32m[0906 18-07-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10577, current rewards: -681.78854, mean: -0.37668
[32m[0906 18-08-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10583, current rewards: -731.78854, mean: -0.39343
[32m[0906 18-08-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10589, current rewards: -781.78854, mean: -0.40931
[32m[0906 18-08-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10595, current rewards: -831.78854, mean: -0.42438
[32m[0906 18-08-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10599, current rewards: -881.78854, mean: -0.43870
[32m[0906 18-08-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10603, current rewards: -931.78854, mean: -0.45232
[32m[0906 18-08-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10608, current rewards: -981.78854, mean: -0.46530
[32m[0906 18-08-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10611, current rewards: -1031.78854, mean: -0.47768
[32m[0906 18-08-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10613, current rewards: -1081.78854, mean: -0.48950
[32m[0906 18-08-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10617, current rewards: -1131.78854, mean: -0.50079
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10620, current rewards: -1181.78854, mean: -0.51160
[32m[0906 18-08-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10623, current rewards: -1231.78854, mean: -0.52194
[32m[0906 18-09-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10627, current rewards: -1281.78854, mean: -0.53186
[32m[0906 18-09-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10630, current rewards: -1331.78854, mean: -0.54138
[32m[0906 18-09-13 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 18-09-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-09-13 @MBExp.py:227][0m Rewards obtained: [-1371.788536664007], Lows: [16], Highs: [1454], Total time: 13347.342136000001
[32m[0906 18-11-08 @MBExp.py:144][0m ####################################################################
[32m[0906 18-11-08 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 18-11-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10858, current rewards: -14.00000, mean: -1.40000
[32m[0906 18-11-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10635, current rewards: -8.32617, mean: -0.13877
[32m[0906 18-11-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10566, current rewards: -2.72594, mean: -0.02478
[32m[0906 18-11-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10521, current rewards: 2.87827, mean: 0.01799
[32m[0906 18-11-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10504, current rewards: 8.48190, mean: 0.04039
[32m[0906 18-11-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10419, current rewards: 3.85440, mean: 0.01482
[32m[0906 18-11-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10369, current rewards: 9.45680, mean: 0.03051
[32m[0906 18-11-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10336, current rewards: 15.07122, mean: 0.04186
[32m[0906 18-11-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10308, current rewards: 20.68606, mean: 0.05045
[32m[0906 18-11-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10281, current rewards: 25.73649, mean: 0.05595
[32m[0906 18-12-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10268, current rewards: 31.34757, mean: 0.06147
[32m[0906 18-12-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10252, current rewards: 36.95696, mean: 0.06599
[32m[0906 18-12-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10239, current rewards: 42.56908, mean: 0.06979
[32m[0906 18-12-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10230, current rewards: 38.06716, mean: 0.05768
[32m[0906 18-12-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10220, current rewards: 43.81866, mean: 0.06172
[32m[0906 18-12-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10219, current rewards: 49.57070, mean: 0.06522
[32m[0906 18-12-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10237, current rewards: 55.32186, mean: 0.06830
[32m[0906 18-12-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10247, current rewards: 61.32901, mean: 0.07131
[32m[0906 18-12-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10257, current rewards: 67.88859, mean: 0.07460
[32m[0906 18-12-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10269, current rewards: 73.54972, mean: 0.07661
[32m[0906 18-12-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10280, current rewards: 79.21228, mean: 0.07843
[32m[0906 18-12-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10285, current rewards: 84.87479, mean: 0.08007
[32m[0906 18-13-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10294, current rewards: 83.87144, mean: 0.07556
[32m[0906 18-13-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10307, current rewards: 91.07718, mean: 0.07851
[32m[0906 18-13-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10327, current rewards: 98.28944, mean: 0.08123
[32m[0906 18-13-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10348, current rewards: 105.49879, mean: 0.08373
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10366, current rewards: 113.09120, mean: 0.08633
[32m[0906 18-13-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10398, current rewards: 120.37163, mean: 0.08851
[32m[0906 18-13-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10428, current rewards: 127.66620, mean: 0.09054
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10454, current rewards: 123.25279, mean: 0.08442
[32m[0906 18-13-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10478, current rewards: 128.57146, mean: 0.08515
[32m[0906 18-13-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10503, current rewards: 133.89232, mean: 0.08583
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10524, current rewards: 139.21191, mean: 0.08647
[32m[0906 18-14-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10545, current rewards: 137.14832, mean: 0.08262
[32m[0906 18-14-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10560, current rewards: 144.89698, mean: 0.08474
[32m[0906 18-14-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10567, current rewards: 151.50521, mean: 0.08608
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10575, current rewards: 158.11345, mean: 0.08736
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10582, current rewards: 164.72168, mean: 0.08856
[32m[0906 18-14-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10589, current rewards: 171.32991, mean: 0.08970
[32m[0906 18-14-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10596, current rewards: 177.93814, mean: 0.09078
[32m[0906 18-14-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10602, current rewards: 155.11010, mean: 0.07717
[32m[0906 18-14-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10608, current rewards: 105.11010, mean: 0.05102
[32m[0906 18-14-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10614, current rewards: 55.11010, mean: 0.02612
[32m[0906 18-14-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10619, current rewards: 5.11010, mean: 0.00237
[32m[0906 18-15-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10622, current rewards: -44.88990, mean: -0.02031
[32m[0906 18-15-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10629, current rewards: -94.88990, mean: -0.04199
[32m[0906 18-15-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10634, current rewards: -144.88990, mean: -0.06272
[32m[0906 18-15-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10638, current rewards: -194.88990, mean: -0.08258
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10642, current rewards: -244.88990, mean: -0.10161
[32m[0906 18-15-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10646, current rewards: -294.88990, mean: -0.11987
[32m[0906 18-15-35 @Agent.py:117][0m Average action selection time: 0.1065
[32m[0906 18-15-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-15-35 @MBExp.py:227][0m Rewards obtained: [-334.88990466979396], Lows: [26], Highs: [527], Total time: 13614.370625000001
[32m[0906 18-17-32 @MBExp.py:144][0m ####################################################################
[32m[0906 18-17-32 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 18-17-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10777, current rewards: -12.95208, mean: -1.29521
[32m[0906 18-17-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10590, current rewards: -8.20389, mean: -0.13673
[32m[0906 18-17-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10503, current rewards: -0.48699, mean: -0.00443
[32m[0906 18-17-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10492, current rewards: 7.22828, mean: 0.04518
[32m[0906 18-17-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10451, current rewards: 14.94474, mean: 0.07117
[32m[0906 18-17-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10379, current rewards: 22.66282, mean: 0.08716
[32m[0906 18-18-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10344, current rewards: 30.38148, mean: 0.09800
[32m[0906 18-18-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10302, current rewards: 38.08617, mean: 0.10579
[32m[0906 18-18-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10274, current rewards: 45.79145, mean: 0.11169
[32m[0906 18-18-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10259, current rewards: 31.86363, mean: 0.06927
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10242, current rewards: 39.54026, mean: 0.07753
[32m[0906 18-18-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10231, current rewards: 47.20884, mean: 0.08430
[32m[0906 18-18-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10224, current rewards: 54.87556, mean: 0.08996
[32m[0906 18-18-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10212, current rewards: 62.54315, mean: 0.09476
[32m[0906 18-18-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10201, current rewards: 70.21368, mean: 0.09889
[32m[0906 18-18-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10194, current rewards: 77.88733, mean: 0.10248
[32m[0906 18-18-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10207, current rewards: 85.55831, mean: 0.10563
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10220, current rewards: 93.77694, mean: 0.10904
[32m[0906 18-19-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10231, current rewards: 102.83793, mean: 0.11301
[32m[0906 18-19-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10245, current rewards: 94.65142, mean: 0.09860
[32m[0906 18-19-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10256, current rewards: 44.65142, mean: 0.04421
[32m[0906 18-19-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10264, current rewards: -5.34858, mean: -0.00505
[32m[0906 18-19-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10273, current rewards: -55.34858, mean: -0.04986
[32m[0906 18-19-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10277, current rewards: -105.34858, mean: -0.09082
[32m[0906 18-19-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10299, current rewards: -155.34858, mean: -0.12839
[32m[0906 18-19-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10320, current rewards: -205.34858, mean: -0.16298
[32m[0906 18-19-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10335, current rewards: -255.34858, mean: -0.19492
[32m[0906 18-19-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10361, current rewards: -305.34858, mean: -0.22452
[32m[0906 18-19-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10392, current rewards: -355.34858, mean: -0.25202
[32m[0906 18-20-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10417, current rewards: -405.34858, mean: -0.27764
[32m[0906 18-20-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10443, current rewards: -455.34858, mean: -0.30156
[32m[0906 18-20-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10467, current rewards: -505.34858, mean: -0.32394
[32m[0906 18-20-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10490, current rewards: -555.34858, mean: -0.34494
[32m[0906 18-20-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10512, current rewards: -605.34858, mean: -0.36467
[32m[0906 18-20-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10524, current rewards: -655.34858, mean: -0.38324
[32m[0906 18-20-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10533, current rewards: -705.34858, mean: -0.40077
[32m[0906 18-20-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10543, current rewards: -755.34858, mean: -0.41732
[32m[0906 18-20-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10551, current rewards: -805.34858, mean: -0.43298
[32m[0906 18-20-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10560, current rewards: -855.34858, mean: -0.44783
[32m[0906 18-21-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10570, current rewards: -905.34858, mean: -0.46191
[32m[0906 18-21-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10576, current rewards: -955.34858, mean: -0.47530
[32m[0906 18-21-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10582, current rewards: -1005.34858, mean: -0.48803
[32m[0906 18-21-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10589, current rewards: -1055.34858, mean: -0.50017
[32m[0906 18-21-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10595, current rewards: -1105.34858, mean: -0.51174
[32m[0906 18-21-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10601, current rewards: -1155.34858, mean: -0.52278
[32m[0906 18-21-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10607, current rewards: -1205.34858, mean: -0.53334
[32m[0906 18-21-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10611, current rewards: -1255.34858, mean: -0.54344
[32m[0906 18-21-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10615, current rewards: -1305.34858, mean: -0.55311
[32m[0906 18-21-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10621, current rewards: -1355.34858, mean: -0.56239
[32m[0906 18-21-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10624, current rewards: -1405.34858, mean: -0.57128
[32m[0906 18-21-59 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 18-21-59 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-21-59 @MBExp.py:227][0m Rewards obtained: [-1445.348579968832], Lows: [16], Highs: [1559], Total time: 13880.816198000002
[32m[0906 18-23-58 @MBExp.py:144][0m ####################################################################
[32m[0906 18-23-58 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 18-23-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10726, current rewards: 0.84635, mean: 0.08464
[32m[0906 18-24-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10663, current rewards: 9.39730, mean: 0.15662
[32m[0906 18-24-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10601, current rewards: 13.67448, mean: 0.12431
[32m[0906 18-24-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10554, current rewards: 17.05715, mean: 0.10661
[32m[0906 18-24-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10511, current rewards: 20.43982, mean: 0.09733
[32m[0906 18-24-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10444, current rewards: 23.82250, mean: 0.09162
[32m[0906 18-24-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10393, current rewards: 27.20517, mean: 0.08776
[32m[0906 18-24-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10351, current rewards: 30.58785, mean: 0.08497
[32m[0906 18-24-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10329, current rewards: 33.97052, mean: 0.08285
[32m[0906 18-24-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10305, current rewards: -6.42059, mean: -0.01396
[32m[0906 18-24-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10282, current rewards: -56.42059, mean: -0.11063
[32m[0906 18-24-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10270, current rewards: -106.42059, mean: -0.19004
[32m[0906 18-25-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10259, current rewards: -156.42059, mean: -0.25643
[32m[0906 18-25-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10246, current rewards: -157.16396, mean: -0.23813
[32m[0906 18-25-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10234, current rewards: -154.76328, mean: -0.21798
[32m[0906 18-25-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10230, current rewards: -152.36261, mean: -0.20048
[32m[0906 18-25-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10222, current rewards: -149.96193, mean: -0.18514
[32m[0906 18-25-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10233, current rewards: -164.32947, mean: -0.19108
[32m[0906 18-25-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10248, current rewards: -214.32947, mean: -0.23553
[32m[0906 18-25-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10258, current rewards: -264.32947, mean: -0.27534
[32m[0906 18-25-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10266, current rewards: -314.32947, mean: -0.31122
[32m[0906 18-25-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10277, current rewards: -364.32947, mean: -0.34371
[32m[0906 18-25-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10281, current rewards: -414.32947, mean: -0.37327
[32m[0906 18-25-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10285, current rewards: -464.32947, mean: -0.40028
[32m[0906 18-26-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10298, current rewards: -514.32947, mean: -0.42507
[32m[0906 18-26-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10318, current rewards: -564.32947, mean: -0.44788
[32m[0906 18-26-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10337, current rewards: -614.32947, mean: -0.46895
[32m[0906 18-26-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10357, current rewards: -664.32947, mean: -0.48848
[32m[0906 18-26-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10385, current rewards: -714.32947, mean: -0.50662
[32m[0906 18-26-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10413, current rewards: -764.32947, mean: -0.52351
[32m[0906 18-26-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10440, current rewards: -814.32947, mean: -0.53929
[32m[0906 18-26-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10463, current rewards: -864.32947, mean: -0.55406
[32m[0906 18-26-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10487, current rewards: -914.32947, mean: -0.56791
[32m[0906 18-26-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10509, current rewards: -964.32947, mean: -0.58092
[32m[0906 18-26-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10522, current rewards: -1014.32947, mean: -0.59318
[32m[0906 18-27-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10531, current rewards: -1064.32947, mean: -0.60473
[32m[0906 18-27-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10538, current rewards: -1114.32947, mean: -0.61565
[32m[0906 18-27-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10544, current rewards: -1164.32947, mean: -0.62598
[32m[0906 18-27-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10552, current rewards: -1214.32947, mean: -0.63577
[32m[0906 18-27-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10559, current rewards: -1264.32947, mean: -0.64507
[32m[0906 18-27-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10569, current rewards: -1314.32947, mean: -0.65390
[32m[0906 18-27-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10578, current rewards: -1364.32947, mean: -0.66230
[32m[0906 18-27-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10583, current rewards: -1414.32947, mean: -0.67030
[32m[0906 18-27-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10588, current rewards: -1464.32947, mean: -0.67793
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10594, current rewards: -1514.32947, mean: -0.68522
[32m[0906 18-27-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10599, current rewards: -1564.32947, mean: -0.69218
[32m[0906 18-28-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10603, current rewards: -1614.32947, mean: -0.69884
[32m[0906 18-28-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10609, current rewards: -1664.32947, mean: -0.70522
[32m[0906 18-28-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10613, current rewards: -1714.32947, mean: -0.71134
[32m[0906 18-28-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10618, current rewards: -1764.32947, mean: -0.71721
[32m[0906 18-28-24 @Agent.py:117][0m Average action selection time: 0.1062
[32m[0906 18-28-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-28-24 @MBExp.py:227][0m Rewards obtained: [-1804.3294741164827], Lows: [0], Highs: [1850], Total time: 14147.130005000003
[32m[0906 18-30-26 @MBExp.py:144][0m ####################################################################
[32m[0906 18-30-26 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 18-30-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10794, current rewards: -0.25031, mean: -0.02503
[32m[0906 18-30-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10720, current rewards: 3.81226, mean: 0.06354
[32m[0906 18-30-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10613, current rewards: -38.81082, mean: -0.35283
[32m[0906 18-30-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10548, current rewards: -88.81082, mean: -0.55507
[32m[0906 18-30-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10549, current rewards: -138.81082, mean: -0.66100
[32m[0906 18-30-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10479, current rewards: -188.81082, mean: -0.72620
[32m[0906 18-30-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10418, current rewards: -238.81082, mean: -0.77036
[32m[0906 18-31-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10379, current rewards: -288.81082, mean: -0.80225
[32m[0906 18-31-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10348, current rewards: -338.81082, mean: -0.82637
[32m[0906 18-31-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10319, current rewards: -388.81082, mean: -0.84524
[32m[0906 18-31-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10304, current rewards: -393.32051, mean: -0.77122
[32m[0906 18-31-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10285, current rewards: -405.03302, mean: -0.72327
[32m[0906 18-31-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10273, current rewards: -455.03302, mean: -0.74596
[32m[0906 18-31-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10264, current rewards: -505.03302, mean: -0.76520
[32m[0906 18-31-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10256, current rewards: -555.03302, mean: -0.78174
[32m[0906 18-31-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10246, current rewards: -605.03302, mean: -0.79610
[32m[0906 18-31-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10243, current rewards: -655.03302, mean: -0.80868
[32m[0906 18-31-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10245, current rewards: -705.03302, mean: -0.81981
[32m[0906 18-32-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10260, current rewards: -755.03302, mean: -0.82971
[32m[0906 18-32-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10276, current rewards: -805.03302, mean: -0.83858
[32m[0906 18-32-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10288, current rewards: -855.03302, mean: -0.84657
[32m[0906 18-32-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10298, current rewards: -905.03302, mean: -0.85380
[32m[0906 18-32-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10309, current rewards: -955.03302, mean: -0.86039
[32m[0906 18-32-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10316, current rewards: -1005.03302, mean: -0.86641
[32m[0906 18-32-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10322, current rewards: -1055.03302, mean: -0.87193
[32m[0906 18-32-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10344, current rewards: -1105.03302, mean: -0.87701
[32m[0906 18-32-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10364, current rewards: -1155.03302, mean: -0.88170
[32m[0906 18-32-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10381, current rewards: -1205.03302, mean: -0.88605
[32m[0906 18-32-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10405, current rewards: -1255.03302, mean: -0.89009
[32m[0906 18-32-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10432, current rewards: -1305.03302, mean: -0.89386
[32m[0906 18-33-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10459, current rewards: -1355.03302, mean: -0.89737
[32m[0906 18-33-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10488, current rewards: -1405.03302, mean: -0.90066
[32m[0906 18-33-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10511, current rewards: -1455.03302, mean: -0.90375
[32m[0906 18-33-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10533, current rewards: -1505.03302, mean: -0.90665
[32m[0906 18-33-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10546, current rewards: -1555.03302, mean: -0.90938
[32m[0906 18-33-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10555, current rewards: -1605.03302, mean: -0.91195
[32m[0906 18-33-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10563, current rewards: -1655.03302, mean: -0.91438
[32m[0906 18-33-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10572, current rewards: -1705.03302, mean: -0.91668
[32m[0906 18-33-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10579, current rewards: -1755.03302, mean: -0.91887
[32m[0906 18-33-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10585, current rewards: -1805.03302, mean: -0.92094
[32m[0906 18-33-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10593, current rewards: -1855.03302, mean: -0.92290
[32m[0906 18-34-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10599, current rewards: -1905.03302, mean: -0.92477
[32m[0906 18-34-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10605, current rewards: -1955.03302, mean: -0.92656
[32m[0906 18-34-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10611, current rewards: -2005.03302, mean: -0.92826
[32m[0906 18-34-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10617, current rewards: -2055.03302, mean: -0.92988
[32m[0906 18-34-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10622, current rewards: -2105.03302, mean: -0.93143
[32m[0906 18-34-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10628, current rewards: -2155.03302, mean: -0.93291
[32m[0906 18-34-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10633, current rewards: -2205.03302, mean: -0.93434
[32m[0906 18-34-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10637, current rewards: -2255.03302, mean: -0.93570
[32m[0906 18-34-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10643, current rewards: -2305.03302, mean: -0.93701
[32m[0906 18-34-53 @Agent.py:117][0m Average action selection time: 0.1065
[32m[0906 18-34-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-34-53 @MBExp.py:227][0m Rewards obtained: [-2345.0330203697467], Lows: [3], Highs: [2356], Total time: 14414.054234000003
[32m[0906 18-36-57 @MBExp.py:144][0m ####################################################################
[32m[0906 18-36-57 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 18-36-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10744, current rewards: 0.95370, mean: 0.09537
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10725, current rewards: 7.06552, mean: 0.11776
[32m[0906 18-37-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10644, current rewards: 13.17316, mean: 0.11976
[32m[0906 18-37-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10579, current rewards: 19.28066, mean: 0.12050
[32m[0906 18-37-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10552, current rewards: 25.38884, mean: 0.12090
[32m[0906 18-37-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10491, current rewards: 31.49311, mean: 0.12113
[32m[0906 18-37-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10435, current rewards: 37.60015, mean: 0.12129
[32m[0906 18-37-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10408, current rewards: 43.70399, mean: 0.12140
[32m[0906 18-37-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10381, current rewards: 49.80814, mean: 0.12148
[32m[0906 18-37-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10353, current rewards: 50.30426, mean: 0.10936
[32m[0906 18-37-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10331, current rewards: 56.89570, mean: 0.11156
[32m[0906 18-37-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10318, current rewards: 62.48454, mean: 0.11158
[32m[0906 18-38-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10304, current rewards: 68.07587, mean: 0.11160
[32m[0906 18-38-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10287, current rewards: 73.66426, mean: 0.11161
[32m[0906 18-38-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10277, current rewards: 79.25575, mean: 0.11163
[32m[0906 18-38-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10270, current rewards: 84.85291, mean: 0.11165
[32m[0906 18-38-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10260, current rewards: 90.44459, mean: 0.11166
[32m[0906 18-38-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10254, current rewards: 96.03684, mean: 0.11167
[32m[0906 18-38-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10266, current rewards: 102.25829, mean: 0.11237
[32m[0906 18-38-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10277, current rewards: 107.79554, mean: 0.11229
[32m[0906 18-38-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10287, current rewards: 113.58241, mean: 0.11246
[32m[0906 18-38-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10297, current rewards: 119.37380, mean: 0.11262
[32m[0906 18-38-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10303, current rewards: 125.17130, mean: 0.11277
[32m[0906 18-38-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10309, current rewards: 130.95582, mean: 0.11289
[32m[0906 18-39-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10320, current rewards: 136.74714, mean: 0.11301
[32m[0906 18-39-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10330, current rewards: 142.53786, mean: 0.11313
[32m[0906 18-39-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10350, current rewards: 137.05815, mean: 0.10462
[32m[0906 18-39-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10371, current rewards: 142.64277, mean: 0.10488
[32m[0906 18-39-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10388, current rewards: 148.19524, mean: 0.10510
[32m[0906 18-39-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10416, current rewards: 153.74744, mean: 0.10531
[32m[0906 18-39-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10446, current rewards: 159.29816, mean: 0.10550
[32m[0906 18-39-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10471, current rewards: 164.84623, mean: 0.10567
[32m[0906 18-39-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10497, current rewards: 170.39768, mean: 0.10584
[32m[0906 18-39-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10520, current rewards: 175.95295, mean: 0.10600
[32m[0906 18-39-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10533, current rewards: 181.55658, mean: 0.10617
[32m[0906 18-40-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10544, current rewards: 187.55806, mean: 0.10657
[32m[0906 18-40-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10552, current rewards: 193.22279, mean: 0.10675
[32m[0906 18-40-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10560, current rewards: 198.89613, mean: 0.10693
[32m[0906 18-40-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10569, current rewards: 204.56064, mean: 0.10710
[32m[0906 18-40-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10576, current rewards: 190.16859, mean: 0.09702
[32m[0906 18-40-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10581, current rewards: 197.37891, mean: 0.09820
[32m[0906 18-40-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10589, current rewards: 204.64127, mean: 0.09934
[32m[0906 18-40-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10594, current rewards: 211.89416, mean: 0.10042
[32m[0906 18-40-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10599, current rewards: 218.78590, mean: 0.10129
[32m[0906 18-40-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10605, current rewards: 225.78090, mean: 0.10216
[32m[0906 18-40-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10609, current rewards: 232.78244, mean: 0.10300
[32m[0906 18-41-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10614, current rewards: 239.78241, mean: 0.10380
[32m[0906 18-41-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10620, current rewards: 246.76909, mean: 0.10456
[32m[0906 18-41-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10624, current rewards: 253.75939, mean: 0.10529
[32m[0906 18-41-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10629, current rewards: 260.76230, mean: 0.10600
[32m[0906 18-41-24 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 18-41-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-41-24 @MBExp.py:227][0m Rewards obtained: [266.36431087274764], Lows: [13], Highs: [10], Total time: 14680.651877000002
[32m[0906 18-43-30 @MBExp.py:144][0m ####################################################################
[32m[0906 18-43-30 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 18-43-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10739, current rewards: -4.23217, mean: -0.42322
[32m[0906 18-43-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10771, current rewards: 2.20703, mean: 0.03678
[32m[0906 18-43-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10661, current rewards: 7.64599, mean: 0.06951
[32m[0906 18-43-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10612, current rewards: 13.08718, mean: 0.08179
[32m[0906 18-43-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10598, current rewards: 18.52869, mean: 0.08823
[32m[0906 18-43-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10536, current rewards: 23.96624, mean: 0.09218
[32m[0906 18-44-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10483, current rewards: 29.40596, mean: 0.09486
[32m[0906 18-44-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10440, current rewards: 34.84124, mean: 0.09678
[32m[0906 18-44-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10399, current rewards: 40.28193, mean: 0.09825
[32m[0906 18-44-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10376, current rewards: 34.95301, mean: 0.07598
[32m[0906 18-44-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10351, current rewards: 38.78229, mean: 0.07604
[32m[0906 18-44-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10332, current rewards: 42.94436, mean: 0.07669
[32m[0906 18-44-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10317, current rewards: 47.10541, mean: 0.07722
[32m[0906 18-44-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10305, current rewards: 51.27075, mean: 0.07768
[32m[0906 18-44-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10290, current rewards: 55.43463, mean: 0.07808
[32m[0906 18-44-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10284, current rewards: 59.59968, mean: 0.07842
[32m[0906 18-44-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10278, current rewards: 63.76567, mean: 0.07872
[32m[0906 18-44-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10270, current rewards: 67.93011, mean: 0.07899
[32m[0906 18-45-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10271, current rewards: 72.06016, mean: 0.07919
[32m[0906 18-45-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10285, current rewards: 72.55748, mean: 0.07558
[32m[0906 18-45-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10295, current rewards: 78.82345, mean: 0.07804
[32m[0906 18-45-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10304, current rewards: 85.07672, mean: 0.08026
[32m[0906 18-45-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10316, current rewards: 91.33408, mean: 0.08228
[32m[0906 18-45-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10323, current rewards: 97.59830, mean: 0.08414
[32m[0906 18-45-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10330, current rewards: 103.86182, mean: 0.08584
[32m[0906 18-45-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10342, current rewards: 110.11688, mean: 0.08739
[32m[0906 18-45-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10360, current rewards: 115.91447, mean: 0.08848
[32m[0906 18-45-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10381, current rewards: 122.01956, mean: 0.08972
[32m[0906 18-45-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10402, current rewards: 128.12771, mean: 0.09087
[32m[0906 18-46-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10423, current rewards: 134.23807, mean: 0.09194
[32m[0906 18-46-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10457, current rewards: 140.34771, mean: 0.09295
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10487, current rewards: 146.45178, mean: 0.09388
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10513, current rewards: 152.55065, mean: 0.09475
[32m[0906 18-46-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10541, current rewards: 158.65477, mean: 0.09558
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10557, current rewards: 155.65103, mean: 0.09102
[32m[0906 18-46-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10568, current rewards: 160.64576, mean: 0.09128
[32m[0906 18-46-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10579, current rewards: 165.60799, mean: 0.09150
[32m[0906 18-46-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10588, current rewards: 170.60180, mean: 0.09172
[32m[0906 18-46-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10596, current rewards: 175.58097, mean: 0.09193
[32m[0906 18-46-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10605, current rewards: 180.58190, mean: 0.09213
[32m[0906 18-47-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10612, current rewards: 185.56047, mean: 0.09232
[32m[0906 18-47-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10618, current rewards: 187.37680, mean: 0.09096
[32m[0906 18-47-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10625, current rewards: 194.30915, mean: 0.09209
[32m[0906 18-47-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10631, current rewards: 201.15954, mean: 0.09313
[32m[0906 18-47-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10639, current rewards: 207.64888, mean: 0.09396
[32m[0906 18-47-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10646, current rewards: 214.13646, mean: 0.09475
[32m[0906 18-47-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10655, current rewards: 220.62575, mean: 0.09551
[32m[0906 18-47-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10661, current rewards: 227.12666, mean: 0.09624
[32m[0906 18-47-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10669, current rewards: 233.62179, mean: 0.09694
[32m[0906 18-47-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10678, current rewards: 232.78322, mean: 0.09463
[32m[0906 18-47-58 @Agent.py:117][0m Average action selection time: 0.1068
[32m[0906 18-47-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-47-58 @MBExp.py:227][0m Rewards obtained: [238.45183399365763], Lows: [10], Highs: [20], Total time: 14948.480049000002
[32m[0906 18-50-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-50-07 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 18-50-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10901, current rewards: -14.00000, mean: -1.40000
[32m[0906 18-50-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10848, current rewards: -10.61617, mean: -0.17694
[32m[0906 18-50-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10695, current rewards: -5.55632, mean: -0.05051
[32m[0906 18-50-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10644, current rewards: -0.50346, mean: -0.00315
[32m[0906 18-50-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10603, current rewards: 4.55723, mean: 0.02170
[32m[0906 18-50-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10548, current rewards: 9.61510, mean: 0.03698
[32m[0906 18-50-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10485, current rewards: 14.66939, mean: 0.04732
[32m[0906 18-50-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10431, current rewards: 19.72476, mean: 0.05479
[32m[0906 18-50-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10394, current rewards: 24.77890, mean: 0.06044
[32m[0906 18-50-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10373, current rewards: 29.92365, mean: 0.06505
[32m[0906 18-51-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10346, current rewards: 34.99721, mean: 0.06862
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10327, current rewards: 40.06942, mean: 0.07155
[32m[0906 18-51-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10314, current rewards: 34.90269, mean: 0.05722
[32m[0906 18-51-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10302, current rewards: 40.29100, mean: 0.06105
[32m[0906 18-51-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10294, current rewards: 45.67861, mean: 0.06434
[32m[0906 18-51-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10284, current rewards: 51.06443, mean: 0.06719
[32m[0906 18-51-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10281, current rewards: 56.44860, mean: 0.06969
[32m[0906 18-51-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10275, current rewards: 61.86891, mean: 0.07194
[32m[0906 18-51-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10271, current rewards: 67.25863, mean: 0.07391
[32m[0906 18-51-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10284, current rewards: 72.64971, mean: 0.07568
[32m[0906 18-51-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10294, current rewards: 78.03513, mean: 0.07726
[32m[0906 18-51-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10301, current rewards: 83.42844, mean: 0.07871
[32m[0906 18-52-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10312, current rewards: 88.82038, mean: 0.08002
[32m[0906 18-52-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10320, current rewards: 83.75049, mean: 0.07220
[32m[0906 18-52-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10327, current rewards: 89.32958, mean: 0.07383
[32m[0906 18-52-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10336, current rewards: 94.66408, mean: 0.07513
[32m[0906 18-52-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10346, current rewards: 100.27854, mean: 0.07655
[32m[0906 18-52-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10364, current rewards: 105.89664, mean: 0.07787
[32m[0906 18-52-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10385, current rewards: 111.51219, mean: 0.07909
[32m[0906 18-52-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10403, current rewards: 117.12740, mean: 0.08022
[32m[0906 18-52-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10425, current rewards: 122.74092, mean: 0.08129
[32m[0906 18-52-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10456, current rewards: 128.35847, mean: 0.08228
[32m[0906 18-52-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10483, current rewards: 133.97072, mean: 0.08321
[32m[0906 18-53-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10509, current rewards: 140.09864, mean: 0.08440
[32m[0906 18-53-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10525, current rewards: 147.28006, mean: 0.08613
[32m[0906 18-53-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10538, current rewards: 154.20672, mean: 0.08762
[32m[0906 18-53-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10549, current rewards: 156.57925, mean: 0.08651
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10559, current rewards: 131.98618, mean: 0.07096
[32m[0906 18-53-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10567, current rewards: 137.37492, mean: 0.07192
[32m[0906 18-53-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10577, current rewards: 142.76179, mean: 0.07284
[32m[0906 18-53-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10584, current rewards: 148.14620, mean: 0.07370
[32m[0906 18-53-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10591, current rewards: 153.53256, mean: 0.07453
[32m[0906 18-53-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10598, current rewards: 158.59860, mean: 0.07517
[32m[0906 18-53-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10605, current rewards: 163.98843, mean: 0.07592
[32m[0906 18-54-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10610, current rewards: 169.38160, mean: 0.07664
[32m[0906 18-54-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10616, current rewards: 174.77736, mean: 0.07734
[32m[0906 18-54-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10621, current rewards: 180.17051, mean: 0.07800
[32m[0906 18-54-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10625, current rewards: 180.18795, mean: 0.07635
[32m[0906 18-54-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10632, current rewards: 185.83455, mean: 0.07711
[32m[0906 18-54-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10636, current rewards: 191.48570, mean: 0.07784
[32m[0906 18-54-34 @Agent.py:117][0m Average action selection time: 0.1064
[32m[0906 18-54-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-54-34 @MBExp.py:227][0m Rewards obtained: [196.15004778616805], Lows: [15], Highs: [42], Total time: 15215.241913000002
[32m[0906 18-56-46 @MBExp.py:144][0m ####################################################################
[32m[0906 18-56-46 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 18-56-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10800, current rewards: -9.30617, mean: -0.93062
[32m[0906 18-56-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10833, current rewards: -3.94141, mean: -0.06569
[32m[0906 18-56-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10677, current rewards: 1.60743, mean: 0.01461
[32m[0906 18-57-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10638, current rewards: 7.16712, mean: 0.04479
[32m[0906 18-57-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10590, current rewards: 12.72117, mean: 0.06058
[32m[0906 18-57-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10548, current rewards: 18.27101, mean: 0.07027
[32m[0906 18-57-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10490, current rewards: 23.82565, mean: 0.07686
[32m[0906 18-57-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10439, current rewards: 29.37326, mean: 0.08159
[32m[0906 18-57-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10407, current rewards: 34.91720, mean: 0.08516
[32m[0906 18-57-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10396, current rewards: 40.56495, mean: 0.08818
[32m[0906 18-57-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10375, current rewards: 46.10528, mean: 0.09040
[32m[0906 18-57-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10351, current rewards: 51.66224, mean: 0.09225
[32m[0906 18-57-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10335, current rewards: 47.97857, mean: 0.07865
[32m[0906 18-57-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10319, current rewards: 53.32176, mean: 0.08079
[32m[0906 18-57-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10305, current rewards: 58.65975, mean: 0.08262
[32m[0906 18-58-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10297, current rewards: 63.99087, mean: 0.08420
[32m[0906 18-58-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10290, current rewards: 69.32622, mean: 0.08559
[32m[0906 18-58-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10281, current rewards: 74.65959, mean: 0.08681
[32m[0906 18-58-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10276, current rewards: 79.99172, mean: 0.08790
[32m[0906 18-58-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10274, current rewards: 85.32731, mean: 0.08888
[32m[0906 18-58-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10401, current rewards: 80.67326, mean: 0.07987
[32m[0906 18-58-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10540, current rewards: 86.14938, mean: 0.08127
[32m[0906 18-58-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10674, current rewards: 93.64446, mean: 0.08436
[32m[0906 18-58-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10764, current rewards: 104.35173, mean: 0.08996
[32m[0906 18-58-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10876, current rewards: 113.30142, mean: 0.09364
[32m[0906 18-59-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10923, current rewards: 113.21979, mean: 0.08986
[32m[0906 18-59-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10921, current rewards: 119.61857, mean: 0.09131
[32m[0906 18-59-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10918, current rewards: 126.00999, mean: 0.09265
[32m[0906 18-59-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10917, current rewards: 132.40405, mean: 0.09390
[32m[0906 18-59-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10922, current rewards: 138.79375, mean: 0.09506
[32m[0906 18-59-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10934, current rewards: 145.18508, mean: 0.09615
[32m[0906 18-59-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10945, current rewards: 151.57563, mean: 0.09716
[32m[0906 18-59-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10955, current rewards: 151.61786, mean: 0.09417
[32m[0906 18-59-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10954, current rewards: 156.48236, mean: 0.09427
[32m[0906 18-59-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10951, current rewards: 161.25111, mean: 0.09430
[32m[0906 18-59-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10952, current rewards: 166.06816, mean: 0.09436
[32m[0906 19-00-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10950, current rewards: 170.88319, mean: 0.09441
[32m[0906 19-00-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10948, current rewards: 175.69605, mean: 0.09446
[32m[0906 19-00-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10947, current rewards: 180.51046, mean: 0.09451
[32m[0906 19-00-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10944, current rewards: 168.56544, mean: 0.08600
[32m[0906 19-00-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10942, current rewards: 174.89485, mean: 0.08701
[32m[0906 19-00-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10941, current rewards: 181.16041, mean: 0.08794
[32m[0906 19-00-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10939, current rewards: 187.53931, mean: 0.08888
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10936, current rewards: 193.84443, mean: 0.08974
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10936, current rewards: 200.15359, mean: 0.09057
[32m[0906 19-00-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10935, current rewards: 206.45797, mean: 0.09135
[32m[0906 19-00-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10934, current rewards: 212.77329, mean: 0.09211
[32m[0906 19-01-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10934, current rewards: 219.08111, mean: 0.09283
[32m[0906 19-01-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10933, current rewards: 225.39794, mean: 0.09353
[32m[0906 19-01-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10933, current rewards: 231.71327, mean: 0.09419
[32m[0906 19-01-20 @Agent.py:117][0m Average action selection time: 0.1093
[32m[0906 19-01-20 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-01-20 @MBExp.py:227][0m Rewards obtained: [237.39894255612847], Lows: [30], Highs: [16], Total time: 15489.311459000002
[32m[0906 19-03-34 @MBExp.py:144][0m ####################################################################
[32m[0906 19-03-34 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 19-03-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10434, current rewards: -5.61828, mean: -0.56183
[32m[0906 19-03-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10543, current rewards: -0.22994, mean: -0.00383
[32m[0906 19-03-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10540, current rewards: 5.06636, mean: 0.04606
[32m[0906 19-03-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10545, current rewards: 10.36373, mean: 0.06477
[32m[0906 19-03-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10538, current rewards: 15.66038, mean: 0.07457
[32m[0906 19-04-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10471, current rewards: 20.95721, mean: 0.08060
[32m[0906 19-04-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10437, current rewards: 26.26034, mean: 0.08471
[32m[0906 19-04-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10420, current rewards: 31.56049, mean: 0.08767
[32m[0906 19-04-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10398, current rewards: 37.11150, mean: 0.09052
[32m[0906 19-04-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10377, current rewards: 42.74622, mean: 0.09293
[32m[0906 19-04-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10368, current rewards: 35.83438, mean: 0.07026
[32m[0906 19-04-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10354, current rewards: 41.73794, mean: 0.07453
[32m[0906 19-04-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10342, current rewards: 47.34653, mean: 0.07762
[32m[0906 19-04-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10333, current rewards: 52.95435, mean: 0.08023
[32m[0906 19-04-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10318, current rewards: 58.56198, mean: 0.08248
[32m[0906 19-04-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10307, current rewards: 57.29659, mean: 0.07539
[32m[0906 19-04-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10297, current rewards: 63.23397, mean: 0.07807
[32m[0906 19-05-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10295, current rewards: 68.48898, mean: 0.07964
[32m[0906 19-05-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10289, current rewards: 74.29303, mean: 0.08164
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10298, current rewards: 80.09938, mean: 0.08344
[32m[0906 19-05-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10312, current rewards: 85.89679, mean: 0.08505
[32m[0906 19-05-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10323, current rewards: 91.69864, mean: 0.08651
[32m[0906 19-05-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10333, current rewards: 97.49803, mean: 0.08784
[32m[0906 19-05-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10343, current rewards: 102.91021, mean: 0.08872
[32m[0906 19-05-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10351, current rewards: 108.42042, mean: 0.08960
[32m[0906 19-05-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10357, current rewards: 114.49734, mean: 0.09087
[32m[0906 19-05-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10373, current rewards: 120.42490, mean: 0.09193
[32m[0906 19-05-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10393, current rewards: 125.88998, mean: 0.09257
[32m[0906 19-06-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10411, current rewards: 131.35727, mean: 0.09316
[32m[0906 19-06-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10429, current rewards: 136.82485, mean: 0.09372
[32m[0906 19-06-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10451, current rewards: 142.29258, mean: 0.09423
[32m[0906 19-06-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10479, current rewards: 147.75786, mean: 0.09472
[32m[0906 19-06-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10503, current rewards: 153.22667, mean: 0.09517
[32m[0906 19-06-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10516, current rewards: 158.69120, mean: 0.09560
[32m[0906 19-06-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10531, current rewards: 163.59472, mean: 0.09567
[32m[0906 19-06-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10541, current rewards: 168.34082, mean: 0.09565
[32m[0906 19-06-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10550, current rewards: 173.08708, mean: 0.09563
[32m[0906 19-06-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10562, current rewards: 168.56167, mean: 0.09062
[32m[0906 19-06-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10570, current rewards: 173.95148, mean: 0.09107
[32m[0906 19-07-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10579, current rewards: 179.33885, mean: 0.09150
[32m[0906 19-07-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10589, current rewards: 184.72663, mean: 0.09190
[32m[0906 19-07-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10597, current rewards: 190.11598, mean: 0.09229
[32m[0906 19-07-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10605, current rewards: 194.93635, mean: 0.09239
[32m[0906 19-07-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10613, current rewards: 200.42822, mean: 0.09279
[32m[0906 19-07-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10619, current rewards: 205.92034, mean: 0.09318
[32m[0906 19-07-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10627, current rewards: 206.34439, mean: 0.09130
[32m[0906 19-07-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10636, current rewards: 211.68274, mean: 0.09164
[32m[0906 19-07-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10642, current rewards: 217.00459, mean: 0.09195
[32m[0906 19-07-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10647, current rewards: 222.32803, mean: 0.09225
[32m[0906 19-07-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10654, current rewards: 227.65186, mean: 0.09254
[32m[0906 19-08-01 @Agent.py:117][0m Average action selection time: 0.1066
[32m[0906 19-08-01 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-08-01 @MBExp.py:227][0m Rewards obtained: [232.0499310365326], Lows: [11], Highs: [17], Total time: 15756.581921000003
[32m[0906 19-10-17 @MBExp.py:144][0m ####################################################################
[32m[0906 19-10-17 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10910, current rewards: -4.25465, mean: -0.42547
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10580, current rewards: 0.64921, mean: 0.01082
[32m[0906 19-10-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10540, current rewards: 5.49355, mean: 0.04994
[32m[0906 19-10-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10544, current rewards: 10.34217, mean: 0.06464
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10514, current rewards: 15.18655, mean: 0.07232
[32m[0906 19-10-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10445, current rewards: 20.03642, mean: 0.07706
[32m[0906 19-10-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10407, current rewards: 15.65148, mean: 0.05049
[32m[0906 19-10-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10366, current rewards: 21.29557, mean: 0.05915
[32m[0906 19-11-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10337, current rewards: 27.02063, mean: 0.06590
[32m[0906 19-11-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10325, current rewards: 32.72409, mean: 0.07114
[32m[0906 19-11-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10310, current rewards: 38.41226, mean: 0.07532
[32m[0906 19-11-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10293, current rewards: 44.09466, mean: 0.07874
[32m[0906 19-11-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10286, current rewards: 29.10635, mean: 0.04772
[32m[0906 19-11-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10272, current rewards: 36.56660, mean: 0.05540
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10263, current rewards: 44.02679, mean: 0.06201
[32m[0906 19-11-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10257, current rewards: 51.48698, mean: 0.06775
[32m[0906 19-11-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10252, current rewards: 58.91647, mean: 0.07274
[32m[0906 19-11-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10242, current rewards: 31.51749, mean: 0.03665
[32m[0906 19-11-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10235, current rewards: -18.48251, mean: -0.02031
[32m[0906 19-11-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10234, current rewards: -68.48251, mean: -0.07134
[32m[0906 19-12-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10247, current rewards: -118.48251, mean: -0.11731
[32m[0906 19-12-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10256, current rewards: -168.48251, mean: -0.15895
[32m[0906 19-12-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10269, current rewards: -218.48251, mean: -0.19683
[32m[0906 19-12-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10279, current rewards: -268.48251, mean: -0.23145
[32m[0906 19-12-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10289, current rewards: -318.48251, mean: -0.26321
[32m[0906 19-12-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10301, current rewards: -368.48251, mean: -0.29245
[32m[0906 19-12-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10308, current rewards: -418.48251, mean: -0.31945
[32m[0906 19-12-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10326, current rewards: -468.48251, mean: -0.34447
[32m[0906 19-12-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10347, current rewards: -518.48251, mean: -0.36772
[32m[0906 19-12-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10367, current rewards: -568.48251, mean: -0.38937
[32m[0906 19-12-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10384, current rewards: -618.48251, mean: -0.40959
[32m[0906 19-13-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10412, current rewards: -668.48251, mean: -0.42851
[32m[0906 19-13-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10436, current rewards: -718.48251, mean: -0.44626
[32m[0906 19-13-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10450, current rewards: -768.48251, mean: -0.46294
[32m[0906 19-13-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10464, current rewards: -818.48251, mean: -0.47864
[32m[0906 19-13-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10476, current rewards: -868.48251, mean: -0.49346
[32m[0906 19-13-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10490, current rewards: -918.48251, mean: -0.50745
[32m[0906 19-13-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10499, current rewards: -968.48251, mean: -0.52069
[32m[0906 19-13-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10508, current rewards: -1018.48251, mean: -0.53324
[32m[0906 19-13-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10519, current rewards: -1068.48251, mean: -0.54514
[32m[0906 19-13-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10528, current rewards: -1118.48251, mean: -0.55646
[32m[0906 19-13-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10538, current rewards: -1168.48251, mean: -0.56722
[32m[0906 19-14-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10548, current rewards: -1218.48251, mean: -0.57748
[32m[0906 19-14-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10555, current rewards: -1268.48251, mean: -0.58726
[32m[0906 19-14-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10562, current rewards: -1318.48251, mean: -0.59660
[32m[0906 19-14-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10568, current rewards: -1368.48251, mean: -0.60552
[32m[0906 19-14-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10575, current rewards: -1418.48251, mean: -0.61406
[32m[0906 19-14-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10580, current rewards: -1468.48251, mean: -0.62224
[32m[0906 19-14-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10586, current rewards: -1518.48251, mean: -0.63008
[32m[0906 19-14-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10591, current rewards: -1568.48251, mean: -0.63759
[32m[0906 19-14-43 @Agent.py:117][0m Average action selection time: 0.1060
[32m[0906 19-14-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-14-43 @MBExp.py:227][0m Rewards obtained: [-1608.4825103960782], Lows: [15], Highs: [1674], Total time: 16022.254446000003
[32m[0906 19-17-01 @MBExp.py:144][0m ####################################################################
[32m[0906 19-17-01 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 19-17-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10845, current rewards: -4.58343, mean: -0.45834
[32m[0906 19-17-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10567, current rewards: 0.90489, mean: 0.01508
[32m[0906 19-17-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10554, current rewards: 6.41665, mean: 0.05833
[32m[0906 19-17-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10520, current rewards: 11.92551, mean: 0.07453
[32m[0906 19-17-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10508, current rewards: 17.43426, mean: 0.08302
[32m[0906 19-17-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10451, current rewards: 22.94874, mean: 0.08826
[32m[0906 19-17-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10410, current rewards: 28.46007, mean: 0.09181
[32m[0906 19-17-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10372, current rewards: 28.42384, mean: 0.07896
[32m[0906 19-17-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10342, current rewards: 33.89845, mean: 0.08268
[32m[0906 19-17-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10320, current rewards: 39.37801, mean: 0.08560
[32m[0906 19-17-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10302, current rewards: 44.81780, mean: 0.08788
[32m[0906 19-17-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10294, current rewards: 50.25710, mean: 0.08974
[32m[0906 19-18-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10281, current rewards: 55.69676, mean: 0.09131
[32m[0906 19-18-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10271, current rewards: 61.13945, mean: 0.09264
[32m[0906 19-18-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10265, current rewards: 66.57429, mean: 0.09377
[32m[0906 19-18-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10254, current rewards: 72.01578, mean: 0.09476
[32m[0906 19-18-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10246, current rewards: 77.28848, mean: 0.09542
[32m[0906 19-18-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10241, current rewards: 82.65635, mean: 0.09611
[32m[0906 19-18-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10234, current rewards: 88.02160, mean: 0.09673
[32m[0906 19-18-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10230, current rewards: 93.39150, mean: 0.09728
[32m[0906 19-18-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10233, current rewards: 98.76330, mean: 0.09779
[32m[0906 19-18-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10248, current rewards: 104.13194, mean: 0.09824
[32m[0906 19-18-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10260, current rewards: 109.50474, mean: 0.09865
[32m[0906 19-19-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10272, current rewards: 114.87202, mean: 0.09903
[32m[0906 19-19-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10283, current rewards: 120.23984, mean: 0.09937
[32m[0906 19-19-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10293, current rewards: 125.40834, mean: 0.09953
[32m[0906 19-19-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10301, current rewards: 130.75378, mean: 0.09981
[32m[0906 19-19-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10322, current rewards: 123.05100, mean: 0.09048
[32m[0906 19-19-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10343, current rewards: 125.04617, mean: 0.08869
[32m[0906 19-19-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10361, current rewards: 130.74788, mean: 0.08955
[32m[0906 19-19-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10381, current rewards: 136.44589, mean: 0.09036
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10400, current rewards: 142.13893, mean: 0.09111
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10428, current rewards: 147.82149, mean: 0.09181
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10443, current rewards: 154.53592, mean: 0.09309
[32m[0906 19-20-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10457, current rewards: 160.25334, mean: 0.09372
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10471, current rewards: 165.98076, mean: 0.09431
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10483, current rewards: 171.69436, mean: 0.09486
[32m[0906 19-20-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10494, current rewards: 177.41899, mean: 0.09539
[32m[0906 19-20-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10505, current rewards: 169.65312, mean: 0.08882
[32m[0906 19-20-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10515, current rewards: 175.42445, mean: 0.08950
[32m[0906 19-20-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10525, current rewards: 181.19640, mean: 0.09015
[32m[0906 19-20-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10535, current rewards: 186.80954, mean: 0.09068
[32m[0906 19-20-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10543, current rewards: 192.53536, mean: 0.09125
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10551, current rewards: 198.25782, mean: 0.09179
[32m[0906 19-20-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10560, current rewards: 203.97964, mean: 0.09230
[32m[0906 19-21-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10568, current rewards: 199.64615, mean: 0.08834
[32m[0906 19-21-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10575, current rewards: 205.34394, mean: 0.08889
[32m[0906 19-21-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10583, current rewards: 211.04372, mean: 0.08943
[32m[0906 19-21-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10589, current rewards: 216.74259, mean: 0.08993
[32m[0906 19-21-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10597, current rewards: 222.07928, mean: 0.09028
[32m[0906 19-21-27 @Agent.py:117][0m Average action selection time: 0.1060
[32m[0906 19-21-27 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-21-27 @MBExp.py:227][0m Rewards obtained: [226.62861587889316], Lows: [19], Highs: [15], Total time: 16288.120330000003
[32m[0906 19-23-48 @MBExp.py:144][0m ####################################################################
[32m[0906 19-23-48 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 19-23-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10963, current rewards: -10.51294, mean: -1.05129
[32m[0906 19-23-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10691, current rewards: -5.45328, mean: -0.09089
[32m[0906 19-24-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10623, current rewards: 0.01069, mean: 0.00010
[32m[0906 19-24-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10610, current rewards: 5.47506, mean: 0.03422
[32m[0906 19-24-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10593, current rewards: 0.52299, mean: 0.00249
[32m[0906 19-24-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10528, current rewards: 7.98318, mean: 0.03070
[32m[0906 19-24-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10481, current rewards: 15.44337, mean: 0.04982
[32m[0906 19-24-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10437, current rewards: 22.90356, mean: 0.06362
[32m[0906 19-24-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10403, current rewards: -8.70918, mean: -0.02124
[32m[0906 19-24-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10381, current rewards: -58.70918, mean: -0.12763
[32m[0906 19-24-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10359, current rewards: -108.70918, mean: -0.21316
[32m[0906 19-24-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10339, current rewards: -158.70918, mean: -0.28341
[32m[0906 19-24-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10321, current rewards: -208.70918, mean: -0.34215
[32m[0906 19-24-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10314, current rewards: -258.70918, mean: -0.39198
[32m[0906 19-25-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10303, current rewards: -308.70918, mean: -0.43480
[32m[0906 19-25-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10292, current rewards: -358.70918, mean: -0.47199
[32m[0906 19-25-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10291, current rewards: -408.70918, mean: -0.50458
[32m[0906 19-25-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10284, current rewards: -458.70918, mean: -0.53338
[32m[0906 19-25-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10280, current rewards: -508.70918, mean: -0.55902
[32m[0906 19-25-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10279, current rewards: -558.70918, mean: -0.58199
[32m[0906 19-25-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10276, current rewards: -608.70918, mean: -0.60268
[32m[0906 19-25-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10288, current rewards: -658.70918, mean: -0.62142
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10301, current rewards: -708.70918, mean: -0.63848
[32m[0906 19-25-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10314, current rewards: -758.70918, mean: -0.65406
[32m[0906 19-25-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10323, current rewards: -808.70918, mean: -0.66835
[32m[0906 19-25-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10336, current rewards: -858.70918, mean: -0.68152
[32m[0906 19-26-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10347, current rewards: -908.70918, mean: -0.69367
[32m[0906 19-26-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10354, current rewards: -958.70918, mean: -0.70493
[32m[0906 19-26-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10372, current rewards: -1008.70918, mean: -0.71540
[32m[0906 19-26-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10392, current rewards: -1058.70918, mean: -0.72514
[32m[0906 19-26-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10410, current rewards: -1108.70918, mean: -0.73424
[32m[0906 19-26-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10427, current rewards: -1158.70918, mean: -0.74276
[32m[0906 19-26-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10447, current rewards: -1208.70918, mean: -0.75075
[32m[0906 19-26-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10461, current rewards: -1258.70918, mean: -0.75826
[32m[0906 19-26-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10477, current rewards: -1308.70918, mean: -0.76533
[32m[0906 19-26-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10489, current rewards: -1358.70918, mean: -0.77199
[32m[0906 19-26-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10502, current rewards: -1408.70918, mean: -0.77829
[32m[0906 19-27-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10514, current rewards: -1458.70918, mean: -0.78425
[32m[0906 19-27-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10525, current rewards: -1508.70918, mean: -0.78990
[32m[0906 19-27-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10537, current rewards: -1558.70918, mean: -0.79526
[32m[0906 19-27-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10547, current rewards: -1608.70918, mean: -0.80035
[32m[0906 19-27-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10556, current rewards: -1658.70918, mean: -0.80520
[32m[0906 19-27-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10568, current rewards: -1708.70918, mean: -0.80981
[32m[0906 19-27-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10577, current rewards: -1758.70918, mean: -0.81422
[32m[0906 19-27-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10585, current rewards: -1808.70918, mean: -0.81842
[32m[0906 19-27-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10594, current rewards: -1858.70918, mean: -0.82244
[32m[0906 19-27-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10599, current rewards: -1908.70918, mean: -0.82628
[32m[0906 19-27-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10606, current rewards: -1958.70918, mean: -0.82996
[32m[0906 19-28-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10614, current rewards: -2008.70918, mean: -0.83349
[32m[0906 19-28-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10619, current rewards: -2058.70918, mean: -0.83687
[32m[0906 19-28-14 @Agent.py:117][0m Average action selection time: 0.1062
[32m[0906 19-28-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-28-14 @MBExp.py:227][0m Rewards obtained: [-2098.7091766590006], Lows: [10], Highs: [2129], Total time: 16554.473542000003
[32m[0906 19-30-38 @MBExp.py:144][0m ####################################################################
[32m[0906 19-30-38 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 19-30-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10832, current rewards: -5.57825, mean: -0.55782
[32m[0906 19-30-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10744, current rewards: -0.14540, mean: -0.00242
[32m[0906 19-30-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10652, current rewards: 5.22302, mean: 0.04748
[32m[0906 19-30-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10616, current rewards: 10.59835, mean: 0.06624
[32m[0906 19-31-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10619, current rewards: 15.96667, mean: 0.07603
[32m[0906 19-31-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10572, current rewards: 21.33879, mean: 0.08207
[32m[0906 19-31-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10505, current rewards: 26.70900, mean: 0.08616
[32m[0906 19-31-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10466, current rewards: 32.07786, mean: 0.08911
[32m[0906 19-31-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10432, current rewards: 37.86807, mean: 0.09236
[32m[0906 19-31-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10403, current rewards: 43.60793, mean: 0.09480
[32m[0906 19-31-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10389, current rewards: 49.01984, mean: 0.09612
[32m[0906 19-31-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10371, current rewards: 54.43001, mean: 0.09720
[32m[0906 19-31-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10358, current rewards: 59.84323, mean: 0.09810
[32m[0906 19-31-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10350, current rewards: 53.07468, mean: 0.08042
[32m[0906 19-31-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10338, current rewards: 59.65372, mean: 0.08402
[32m[0906 19-31-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10328, current rewards: 66.23511, mean: 0.08715
[32m[0906 19-32-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10316, current rewards: 72.81266, mean: 0.08989
[32m[0906 19-32-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10309, current rewards: 78.98484, mean: 0.09184
[32m[0906 19-32-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10298, current rewards: 85.57877, mean: 0.09404
[32m[0906 19-32-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10292, current rewards: 92.17433, mean: 0.09601
[32m[0906 19-32-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10290, current rewards: 98.77011, mean: 0.09779
[32m[0906 19-32-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10284, current rewards: 105.36491, mean: 0.09940
[32m[0906 19-32-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10295, current rewards: 111.95944, mean: 0.10086
[32m[0906 19-32-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10308, current rewards: 118.55597, mean: 0.10220
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10318, current rewards: 125.15370, mean: 0.10343
[32m[0906 19-32-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10325, current rewards: 132.63248, mean: 0.10526
[32m[0906 19-32-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10336, current rewards: 122.23399, mean: 0.09331
[32m[0906 19-32-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10344, current rewards: 127.05385, mean: 0.09342
[32m[0906 19-33-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10350, current rewards: 131.86812, mean: 0.09352
[32m[0906 19-33-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10370, current rewards: 136.68120, mean: 0.09362
[32m[0906 19-33-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10388, current rewards: 141.48283, mean: 0.09370
[32m[0906 19-33-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10405, current rewards: 146.29287, mean: 0.09378
[32m[0906 19-33-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10419, current rewards: 140.97322, mean: 0.08756
[32m[0906 19-33-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10433, current rewards: 146.49486, mean: 0.08825
[32m[0906 19-33-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10448, current rewards: 151.81761, mean: 0.08878
[32m[0906 19-33-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10463, current rewards: 157.13715, mean: 0.08928
[32m[0906 19-33-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10477, current rewards: 162.46036, mean: 0.08976
[32m[0906 19-33-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10490, current rewards: 167.77925, mean: 0.09020
[32m[0906 19-33-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10502, current rewards: 173.09856, mean: 0.09063
[32m[0906 19-34-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10514, current rewards: 178.41873, mean: 0.09103
[32m[0906 19-34-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10525, current rewards: 183.73861, mean: 0.09141
[32m[0906 19-34-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10535, current rewards: 189.05705, mean: 0.09178
[32m[0906 19-34-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10543, current rewards: 194.17158, mean: 0.09202
[32m[0906 19-34-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10553, current rewards: 199.13016, mean: 0.09219
[32m[0906 19-34-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10560, current rewards: 204.08529, mean: 0.09235
[32m[0906 19-34-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10568, current rewards: 209.04626, mean: 0.09250
[32m[0906 19-34-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10576, current rewards: 214.00413, mean: 0.09264
[32m[0906 19-34-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10580, current rewards: 218.96316, mean: 0.09278
[32m[0906 19-34-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10587, current rewards: 223.92044, mean: 0.09291
[32m[0906 19-34-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10594, current rewards: 228.83299, mean: 0.09302
[32m[0906 19-35-03 @Agent.py:117][0m Average action selection time: 0.1060
[32m[0906 19-35-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-35-03 @MBExp.py:227][0m Rewards obtained: [232.789668072829], Lows: [16], Highs: [12], Total time: 16820.213571000004
[32m[0906 19-37-29 @MBExp.py:144][0m ####################################################################
[32m[0906 19-37-29 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 19-37-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10990, current rewards: -15.00000, mean: -1.50000
[32m[0906 19-37-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10874, current rewards: -9.58299, mean: -0.15972
[32m[0906 19-37-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10740, current rewards: -4.36519, mean: -0.03968
[32m[0906 19-37-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10669, current rewards: 0.86343, mean: 0.00540
[32m[0906 19-37-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10628, current rewards: 6.08516, mean: 0.02898
[32m[0906 19-37-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10620, current rewards: 11.30469, mean: 0.04348
[32m[0906 19-38-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10543, current rewards: 16.52002, mean: 0.05329
[32m[0906 19-38-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10489, current rewards: 21.74311, mean: 0.06040
[32m[0906 19-38-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10458, current rewards: 26.96400, mean: 0.06577
[32m[0906 19-38-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10426, current rewards: 20.79612, mean: 0.04521
[32m[0906 19-38-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10401, current rewards: 26.80737, mean: 0.05256
[32m[0906 19-38-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10383, current rewards: 32.82981, mean: 0.05862
[32m[0906 19-38-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10367, current rewards: 38.85327, mean: 0.06369
[32m[0906 19-38-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10356, current rewards: 44.86321, mean: 0.06797
[32m[0906 19-38-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10348, current rewards: 50.87962, mean: 0.07166
[32m[0906 19-38-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10338, current rewards: 57.24968, mean: 0.07533
[32m[0906 19-38-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10328, current rewards: 54.50153, mean: 0.06729
[32m[0906 19-38-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10322, current rewards: 60.41334, mean: 0.07025
[32m[0906 19-39-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10316, current rewards: 66.03505, mean: 0.07257
[32m[0906 19-39-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10311, current rewards: 71.66343, mean: 0.07465
[32m[0906 19-39-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10308, current rewards: 77.28484, mean: 0.07652
[32m[0906 19-39-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10301, current rewards: 82.90387, mean: 0.07821
[32m[0906 19-39-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10301, current rewards: 88.52930, mean: 0.07976
[32m[0906 19-39-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10313, current rewards: 83.56011, mean: 0.07203
[32m[0906 19-39-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10322, current rewards: 91.21519, mean: 0.07538
[32m[0906 19-39-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10331, current rewards: 98.87027, mean: 0.07847
[32m[0906 19-39-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10341, current rewards: 106.52535, mean: 0.08132
[32m[0906 19-39-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10347, current rewards: 114.18043, mean: 0.08396
[32m[0906 19-39-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10352, current rewards: 89.54867, mean: 0.06351
[32m[0906 19-40-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10363, current rewards: 39.54867, mean: 0.02709
[32m[0906 19-40-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10382, current rewards: -10.45133, mean: -0.00692
[32m[0906 19-40-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10399, current rewards: -60.45133, mean: -0.03875
[32m[0906 19-40-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10413, current rewards: -110.45133, mean: -0.06860
[32m[0906 19-40-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10418, current rewards: -160.45133, mean: -0.09666
[32m[0906 19-40-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10434, current rewards: -210.45133, mean: -0.12307
[32m[0906 19-40-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10450, current rewards: -260.45133, mean: -0.14798
[32m[0906 19-40-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10464, current rewards: -310.45133, mean: -0.17152
[32m[0906 19-40-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10477, current rewards: -360.45133, mean: -0.19379
[32m[0906 19-40-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10490, current rewards: -410.45133, mean: -0.21490
[32m[0906 19-40-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10500, current rewards: -460.45133, mean: -0.23492
[32m[0906 19-41-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10510, current rewards: -510.45133, mean: -0.25396
[32m[0906 19-41-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10521, current rewards: -560.45133, mean: -0.27206
[32m[0906 19-41-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10529, current rewards: -610.45133, mean: -0.28931
[32m[0906 19-41-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10537, current rewards: -660.45133, mean: -0.30576
[32m[0906 19-41-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10547, current rewards: -710.45133, mean: -0.32147
[32m[0906 19-41-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10556, current rewards: -760.45133, mean: -0.33648
[32m[0906 19-41-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10563, current rewards: -810.45133, mean: -0.35084
[32m[0906 19-41-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10572, current rewards: -860.45133, mean: -0.36460
[32m[0906 19-41-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10579, current rewards: -910.45133, mean: -0.37778
[32m[0906 19-41-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10587, current rewards: -960.45133, mean: -0.39043
[32m[0906 19-41-54 @Agent.py:117][0m Average action selection time: 0.1059
[32m[0906 19-41-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-41-54 @MBExp.py:227][0m Rewards obtained: [-1000.4513314827091], Lows: [22], Highs: [1124], Total time: 17085.856533000006
[32m[0906 19-44-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-44-22 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 19-44-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10645, current rewards: -4.50817, mean: -0.45082
[32m[0906 19-44-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10859, current rewards: 0.90325, mean: 0.01505
[32m[0906 19-44-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10778, current rewards: 6.46966, mean: 0.05882
[32m[0906 19-44-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10693, current rewards: 12.02621, mean: 0.07516
[32m[0906 19-44-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10660, current rewards: 17.58435, mean: 0.08373
[32m[0906 19-44-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10648, current rewards: 23.14663, mean: 0.08903
[32m[0906 19-44-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10596, current rewards: 29.21456, mean: 0.09424
[32m[0906 19-45-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10537, current rewards: 34.92593, mean: 0.09702
[32m[0906 19-45-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10502, current rewards: 40.25821, mean: 0.09819
[32m[0906 19-45-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10467, current rewards: 45.73359, mean: 0.09942
[32m[0906 19-45-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10447, current rewards: 51.49939, mean: 0.10098
[32m[0906 19-45-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10427, current rewards: 57.25671, mean: 0.10224
[32m[0906 19-45-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10408, current rewards: 63.01877, mean: 0.10331
[32m[0906 19-45-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10394, current rewards: 68.78156, mean: 0.10421
[32m[0906 19-45-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10389, current rewards: 74.54567, mean: 0.10499
[32m[0906 19-45-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10376, current rewards: 80.30599, mean: 0.10567
[32m[0906 19-45-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10368, current rewards: 86.07630, mean: 0.10627
[32m[0906 19-45-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10360, current rewards: 91.84031, mean: 0.10679
[32m[0906 19-45-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10353, current rewards: 97.60306, mean: 0.10726
[32m[0906 19-46-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10348, current rewards: 93.00370, mean: 0.09688
[32m[0906 19-46-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10345, current rewards: 99.29160, mean: 0.09831
[32m[0906 19-46-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10342, current rewards: 105.58222, mean: 0.09961
[32m[0906 19-46-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10337, current rewards: 111.87580, mean: 0.10079
[32m[0906 19-46-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10340, current rewards: 117.97335, mean: 0.10170
[32m[0906 19-46-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10349, current rewards: 118.44713, mean: 0.09789
[32m[0906 19-46-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10359, current rewards: 124.18414, mean: 0.09856
[32m[0906 19-46-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10370, current rewards: 129.92472, mean: 0.09918
[32m[0906 19-46-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10378, current rewards: 135.66137, mean: 0.09975
[32m[0906 19-46-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10383, current rewards: 141.40157, mean: 0.10028
[32m[0906 19-46-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10393, current rewards: 147.13663, mean: 0.10078
[32m[0906 19-47-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10403, current rewards: 152.86822, mean: 0.10124
[32m[0906 19-47-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10421, current rewards: 160.70244, mean: 0.10301
[32m[0906 19-47-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10440, current rewards: 167.37757, mean: 0.10396
[32m[0906 19-47-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10447, current rewards: 174.06888, mean: 0.10486
[32m[0906 19-47-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10454, current rewards: 180.75254, mean: 0.10570
[32m[0906 19-47-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10471, current rewards: 177.24001, mean: 0.10070
[32m[0906 19-47-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10488, current rewards: 183.69726, mean: 0.10149
[32m[0906 19-47-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10505, current rewards: 190.16366, mean: 0.10224
[32m[0906 19-47-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10519, current rewards: 196.63157, mean: 0.10295
[32m[0906 19-47-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10530, current rewards: 203.16717, mean: 0.10366
[32m[0906 19-47-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10540, current rewards: 209.71507, mean: 0.10434
[32m[0906 19-48-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10553, current rewards: 216.26034, mean: 0.10498
[32m[0906 19-48-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10562, current rewards: 222.80081, mean: 0.10559
[32m[0906 19-48-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10570, current rewards: 222.37997, mean: 0.10295
[32m[0906 19-48-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10580, current rewards: 228.30372, mean: 0.10330
[32m[0906 19-48-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10588, current rewards: 234.20936, mean: 0.10363
[32m[0906 19-48-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10596, current rewards: 240.12986, mean: 0.10395
[32m[0906 19-48-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10604, current rewards: 246.33423, mean: 0.10438
[32m[0906 19-48-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10610, current rewards: 254.19053, mean: 0.10547
[32m[0906 19-48-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10617, current rewards: 260.97941, mean: 0.10609
[32m[0906 19-48-49 @Agent.py:117][0m Average action selection time: 0.1062
[32m[0906 19-48-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-48-49 @MBExp.py:227][0m Rewards obtained: [266.41182362611477], Lows: [11], Highs: [16], Total time: 17352.262131000007
[32m[0906 19-51-20 @MBExp.py:144][0m ####################################################################
[32m[0906 19-51-20 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 19-51-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10769, current rewards: -11.73343, mean: -1.17334
[32m[0906 19-51-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10911, current rewards: -62.57057, mean: -1.04284
[32m[0906 19-51-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10871, current rewards: -110.19162, mean: -1.00174
[32m[0906 19-51-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10771, current rewards: -122.60958, mean: -0.76631
[32m[0906 19-51-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10729, current rewards: -116.31206, mean: -0.55387
[32m[0906 19-51-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10701, current rewards: -110.00800, mean: -0.42311
[32m[0906 19-51-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10662, current rewards: -103.69830, mean: -0.33451
[32m[0906 19-51-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10604, current rewards: -97.39348, mean: -0.27054
[32m[0906 19-52-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10551, current rewards: -91.08706, mean: -0.22216
[32m[0906 19-52-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10514, current rewards: -84.77883, mean: -0.18430
[32m[0906 19-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10490, current rewards: -78.47474, mean: -0.15387
[32m[0906 19-52-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10467, current rewards: -85.21663, mean: -0.15217
[32m[0906 19-52-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10451, current rewards: -78.62947, mean: -0.12890
[32m[0906 19-52-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10437, current rewards: -70.00729, mean: -0.10607
[32m[0906 19-52-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10421, current rewards: -59.01924, mean: -0.08313
[32m[0906 19-52-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10408, current rewards: -50.53717, mean: -0.06650
[32m[0906 19-52-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10397, current rewards: -42.06214, mean: -0.05193
[32m[0906 19-52-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10383, current rewards: -33.56988, mean: -0.03903
[32m[0906 19-52-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10372, current rewards: -25.07688, mean: -0.02756
[32m[0906 19-53-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10364, current rewards: -16.59302, mean: -0.01728
[32m[0906 19-53-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10361, current rewards: -8.09944, mean: -0.00802
[32m[0906 19-53-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10355, current rewards: -6.10391, mean: -0.00576
[32m[0906 19-53-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10348, current rewards: -0.30019, mean: -0.00027
[32m[0906 19-53-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10346, current rewards: 5.50344, mean: 0.00474
[32m[0906 19-53-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10348, current rewards: 11.29795, mean: 0.00934
[32m[0906 19-53-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10356, current rewards: 17.10477, mean: 0.01358
[32m[0906 19-53-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10366, current rewards: 22.90408, mean: 0.01748
[32m[0906 19-53-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10371, current rewards: 28.70285, mean: 0.02111
[32m[0906 19-53-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10379, current rewards: 34.49841, mean: 0.02447
[32m[0906 19-53-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10387, current rewards: 40.30068, mean: 0.02760
[32m[0906 19-53-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10392, current rewards: 45.93765, mean: 0.03042
[32m[0906 19-54-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10407, current rewards: 42.58136, mean: 0.02730
[32m[0906 19-54-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10425, current rewards: 49.86173, mean: 0.03097
[32m[0906 19-54-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10439, current rewards: 57.13647, mean: 0.03442
[32m[0906 19-54-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10444, current rewards: 64.41699, mean: 0.03767
[32m[0906 19-54-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10451, current rewards: 71.68664, mean: 0.04073
[32m[0906 19-54-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10465, current rewards: 78.96166, mean: 0.04363
[32m[0906 19-54-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10479, current rewards: 79.07239, mean: 0.04251
[32m[0906 19-54-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10492, current rewards: 85.76589, mean: 0.04490
[32m[0906 19-54-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10503, current rewards: 92.75617, mean: 0.04732
[32m[0906 19-54-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10516, current rewards: 99.76812, mean: 0.04964
[32m[0906 19-54-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10526, current rewards: 106.77162, mean: 0.05183
[32m[0906 19-55-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10535, current rewards: 113.78049, mean: 0.05392
[32m[0906 19-55-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10546, current rewards: 120.77678, mean: 0.05592
[32m[0906 19-55-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10555, current rewards: 127.77904, mean: 0.05782
[32m[0906 19-55-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10563, current rewards: 134.78549, mean: 0.05964
[32m[0906 19-55-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10573, current rewards: 141.79553, mean: 0.06138
[32m[0906 19-55-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10580, current rewards: 148.79382, mean: 0.06305
[32m[0906 19-55-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10588, current rewards: 155.78760, mean: 0.06464
[32m[0906 19-55-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10597, current rewards: 162.79521, mean: 0.06618
[32m[0906 19-55-46 @Agent.py:117][0m Average action selection time: 0.1060
[32m[0906 19-55-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-55-46 @MBExp.py:227][0m Rewards obtained: [168.39097561801148], Lows: [79], Highs: [18], Total time: 17618.119975000005
[32m[0906 19-58-19 @MBExp.py:144][0m ####################################################################
[32m[0906 19-58-19 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 19-58-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10846, current rewards: -5.59197, mean: -0.55920
[32m[0906 19-58-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10869, current rewards: 0.59247, mean: 0.00987
[32m[0906 19-58-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10846, current rewards: 5.42526, mean: 0.04932
[32m[0906 19-58-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10766, current rewards: 10.25420, mean: 0.06409
[32m[0906 19-58-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10719, current rewards: 15.50755, mean: 0.07385
[32m[0906 19-58-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10685, current rewards: 20.44391, mean: 0.07863
[32m[0906 19-58-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10668, current rewards: 25.36321, mean: 0.08182
[32m[0906 19-58-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10604, current rewards: 30.28400, mean: 0.08412
[32m[0906 19-59-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10556, current rewards: 31.00797, mean: 0.07563
[32m[0906 19-59-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10838, current rewards: 30.94890, mean: 0.06728
[32m[0906 19-59-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11060, current rewards: 38.94632, mean: 0.07637
[32m[0906 19-59-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11222, current rewards: 46.93846, mean: 0.08382
[32m[0906 19-59-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11366, current rewards: 54.86560, mean: 0.08994
[32m[0906 19-59-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11327, current rewards: 50.88644, mean: 0.07710
[32m[0906 19-59-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11251, current rewards: 58.20214, mean: 0.08197
[32m[0906 19-59-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11180, current rewards: 65.51316, mean: 0.08620
[32m[0906 19-59-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11123, current rewards: 72.82771, mean: 0.08991
[32m[0906 19-59-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11074, current rewards: 80.13992, mean: 0.09319
[32m[0906 20-00-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11029, current rewards: 87.45230, mean: 0.09610
[32m[0906 20-00-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10987, current rewards: 94.76384, mean: 0.09871
[32m[0906 20-00-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10948, current rewards: 102.07976, mean: 0.10107
[32m[0906 20-00-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10926, current rewards: 72.86935, mean: 0.06874
[32m[0906 20-00-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10937, current rewards: 17.40576, mean: 0.01568
[32m[0906 20-00-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10934, current rewards: -39.66155, mean: -0.03419
[32m[0906 20-00-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10921, current rewards: -53.18740, mean: -0.04396
[32m[0906 20-00-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10906, current rewards: -48.81870, mean: -0.03875
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10895, current rewards: -44.45213, mean: -0.03393
[32m[0906 20-00-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10884, current rewards: -40.08614, mean: -0.02948
[32m[0906 20-00-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10873, current rewards: -35.71891, mean: -0.02533
[32m[0906 20-00-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10864, current rewards: -31.02348, mean: -0.02125
[32m[0906 20-01-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10859, current rewards: -26.48459, mean: -0.01754
[32m[0906 20-01-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10861, current rewards: -21.94423, mean: -0.01407
[32m[0906 20-01-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10861, current rewards: -43.21929, mean: -0.02684
[32m[0906 20-01-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10860, current rewards: -84.10994, mean: -0.05067
[32m[0906 20-01-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10851, current rewards: -122.38106, mean: -0.07157
[32m[0906 20-01-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10857, current rewards: -155.83057, mean: -0.08854
[32m[0906 20-01-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10859, current rewards: -185.44861, mean: -0.10246
[32m[0906 20-01-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10861, current rewards: -177.17384, mean: -0.09525
[32m[0906 20-01-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10864, current rewards: -165.91282, mean: -0.08687
[32m[0906 20-01-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10866, current rewards: -154.68537, mean: -0.07892
[32m[0906 20-01-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10869, current rewards: -143.36390, mean: -0.07133
[32m[0906 20-02-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10872, current rewards: -132.04021, mean: -0.06410
[32m[0906 20-02-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10876, current rewards: -120.75818, mean: -0.05723
[32m[0906 20-02-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10877, current rewards: -109.50703, mean: -0.05070
[32m[0906 20-02-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10880, current rewards: -98.23023, mean: -0.04445
[32m[0906 20-02-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10884, current rewards: -85.24301, mean: -0.03772
[32m[0906 20-02-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10885, current rewards: -75.00840, mean: -0.03247
[32m[0906 20-02-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10887, current rewards: -64.97058, mean: -0.02753
[32m[0906 20-02-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10888, current rewards: -54.93394, mean: -0.02279
[32m[0906 20-02-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10889, current rewards: -44.89274, mean: -0.01825
[32m[0906 20-02-52 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 20-02-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-02-52 @MBExp.py:227][0m Rewards obtained: [-36.86057291588548], Lows: [197], Highs: [12], Total time: 17891.199359000006
[32m[0906 20-05-28 @MBExp.py:144][0m ####################################################################
[32m[0906 20-05-28 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 20-05-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10995, current rewards: -5.71733, mean: -0.57173
[32m[0906 20-05-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10862, current rewards: 1.59951, mean: 0.02666
[32m[0906 20-05-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10720, current rewards: 7.75566, mean: 0.07051
[32m[0906 20-05-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10676, current rewards: 13.92614, mean: 0.08704
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10660, current rewards: 20.52574, mean: 0.09774
[32m[0906 20-05-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10635, current rewards: 26.62214, mean: 0.10239
[32m[0906 20-06-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10561, current rewards: 32.70714, mean: 0.10551
[32m[0906 20-06-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10521, current rewards: 38.79245, mean: 0.10776
[32m[0906 20-06-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10482, current rewards: 44.87679, mean: 0.10946
[32m[0906 20-06-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10451, current rewards: 50.96572, mean: 0.11080
[32m[0906 20-06-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10432, current rewards: 57.05697, mean: 0.11188
[32m[0906 20-06-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10431, current rewards: 57.53651, mean: 0.10274
[32m[0906 20-06-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10423, current rewards: 12.19630, mean: 0.01999
[32m[0906 20-06-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10413, current rewards: -36.08674, mean: -0.05468
[32m[0906 20-06-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10402, current rewards: -84.93215, mean: -0.11962
[32m[0906 20-06-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10394, current rewards: -130.66265, mean: -0.17192
[32m[0906 20-06-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10385, current rewards: -175.38848, mean: -0.21653
[32m[0906 20-06-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10373, current rewards: -220.10761, mean: -0.25594
[32m[0906 20-07-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10363, current rewards: -266.91865, mean: -0.29332
[32m[0906 20-07-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10355, current rewards: -316.09362, mean: -0.32926
[32m[0906 20-07-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10347, current rewards: -365.03095, mean: -0.36142
[32m[0906 20-07-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10341, current rewards: -412.78254, mean: -0.38942
[32m[0906 20-07-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10336, current rewards: -457.48748, mean: -0.41215
[32m[0906 20-07-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10331, current rewards: -502.20200, mean: -0.43293
[32m[0906 20-07-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10335, current rewards: -546.89478, mean: -0.45198
[32m[0906 20-07-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10349, current rewards: -595.96998, mean: -0.47299
[32m[0906 20-07-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10355, current rewards: -645.01880, mean: -0.49238
[32m[0906 20-07-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10361, current rewards: -681.50010, mean: -0.50110
[32m[0906 20-07-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10371, current rewards: -673.68482, mean: -0.47779
[32m[0906 20-07-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10377, current rewards: -667.44823, mean: -0.45716
[32m[0906 20-08-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10382, current rewards: -661.21195, mean: -0.43789
[32m[0906 20-08-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10396, current rewards: -654.97770, mean: -0.41986
[32m[0906 20-08-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10411, current rewards: -648.73892, mean: -0.40294
[32m[0906 20-08-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10414, current rewards: -642.50555, mean: -0.38705
[32m[0906 20-08-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10421, current rewards: -636.26953, mean: -0.37209
[32m[0906 20-08-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10425, current rewards: -630.03455, mean: -0.35797
[32m[0906 20-08-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10440, current rewards: -624.48178, mean: -0.34502
[32m[0906 20-08-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10452, current rewards: -617.41009, mean: -0.33194
[32m[0906 20-08-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10465, current rewards: -610.36454, mean: -0.31956
[32m[0906 20-08-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10478, current rewards: -603.32016, mean: -0.30782
[32m[0906 20-08-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10491, current rewards: -620.03440, mean: -0.30847
[32m[0906 20-09-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10501, current rewards: -617.93504, mean: -0.29997
[32m[0906 20-09-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10510, current rewards: -609.38385, mean: -0.28881
[32m[0906 20-09-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10522, current rewards: -601.47069, mean: -0.27846
[32m[0906 20-09-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10529, current rewards: -592.11234, mean: -0.26792
[32m[0906 20-09-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10536, current rewards: -583.58378, mean: -0.25822
[32m[0906 20-09-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10548, current rewards: -585.97307, mean: -0.25367
[32m[0906 20-09-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10564, current rewards: -579.95950, mean: -0.24575
[32m[0906 20-09-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10570, current rewards: -571.07543, mean: -0.23696
[32m[0906 20-09-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10577, current rewards: -562.17558, mean: -0.22853
[32m[0906 20-09-53 @Agent.py:117][0m Average action selection time: 0.1058
[32m[0906 20-09-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-09-53 @MBExp.py:227][0m Rewards obtained: [-555.0610463065507], Lows: [383], Highs: [76], Total time: 18156.553140000007
[32m[0906 20-12-30 @MBExp.py:144][0m ####################################################################
[32m[0906 20-12-30 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 20-12-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10860, current rewards: -8.01133, mean: -0.80113
[32m[0906 20-12-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10787, current rewards: -66.06499, mean: -1.10108
[32m[0906 20-12-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10688, current rewards: -111.31520, mean: -1.01196
[32m[0906 20-12-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10636, current rewards: -103.99071, mean: -0.64994
[32m[0906 20-12-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10603, current rewards: -97.27383, mean: -0.46321
[32m[0906 20-12-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10602, current rewards: -90.57029, mean: -0.34835
[32m[0906 20-13-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10542, current rewards: -83.85753, mean: -0.27051
[32m[0906 20-13-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10486, current rewards: -77.13772, mean: -0.21427
[32m[0906 20-13-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10447, current rewards: -81.32387, mean: -0.19835
[32m[0906 20-13-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10415, current rewards: -75.49513, mean: -0.16412
[32m[0906 20-13-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10387, current rewards: -69.66934, mean: -0.13661
[32m[0906 20-13-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10370, current rewards: -63.87493, mean: -0.11406
[32m[0906 20-13-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10353, current rewards: -58.05603, mean: -0.09517
[32m[0906 20-13-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10336, current rewards: -52.23544, mean: -0.07914
[32m[0906 20-13-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10328, current rewards: -56.80017, mean: -0.08000
[32m[0906 20-13-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10312, current rewards: -50.71935, mean: -0.06674
[32m[0906 20-13-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10305, current rewards: -44.63466, mean: -0.05510
[32m[0906 20-13-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10299, current rewards: -38.55288, mean: -0.04483
[32m[0906 20-14-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10292, current rewards: -32.46968, mean: -0.03568
[32m[0906 20-14-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10283, current rewards: -26.70703, mean: -0.02782
[32m[0906 20-14-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10274, current rewards: -20.88998, mean: -0.02068
[32m[0906 20-14-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10271, current rewards: -14.86361, mean: -0.01402
[32m[0906 20-14-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10267, current rewards: -8.83469, mean: -0.00796
[32m[0906 20-14-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10262, current rewards: -2.81042, mean: -0.00242
[32m[0906 20-14-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10262, current rewards: 3.21526, mean: 0.00266
[32m[0906 20-14-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10267, current rewards: 9.24151, mean: 0.00733
[32m[0906 20-14-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10275, current rewards: 10.24687, mean: 0.00782
[32m[0906 20-14-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10286, current rewards: 15.99898, mean: 0.01176
[32m[0906 20-14-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10295, current rewards: 21.59446, mean: 0.01532
[32m[0906 20-15-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10301, current rewards: 27.34596, mean: 0.01873
[32m[0906 20-15-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10308, current rewards: 33.10180, mean: 0.02192
[32m[0906 20-15-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10313, current rewards: 38.85943, mean: 0.02491
[32m[0906 20-15-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10330, current rewards: 44.60551, mean: 0.02771
[32m[0906 20-15-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10334, current rewards: 50.35751, mean: 0.03034
[32m[0906 20-15-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10340, current rewards: 56.11386, mean: 0.03282
[32m[0906 20-15-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10344, current rewards: 61.86684, mean: 0.03515
[32m[0906 20-15-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10353, current rewards: 67.69099, mean: 0.03740
[32m[0906 20-15-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10368, current rewards: 73.44019, mean: 0.03948
[32m[0906 20-15-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10380, current rewards: 79.19978, mean: 0.04147
[32m[0906 20-15-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10394, current rewards: 84.95788, mean: 0.04335
[32m[0906 20-15-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10405, current rewards: 90.71400, mean: 0.04513
[32m[0906 20-16-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10415, current rewards: 96.46983, mean: 0.04683
[32m[0906 20-16-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10427, current rewards: 102.22464, mean: 0.04845
[32m[0906 20-16-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10436, current rewards: 97.35401, mean: 0.04507
[32m[0906 20-16-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10445, current rewards: 103.78577, mean: 0.04696
[32m[0906 20-16-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10455, current rewards: 109.53557, mean: 0.04847
[32m[0906 20-16-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10463, current rewards: 115.28576, mean: 0.04991
[32m[0906 20-16-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10471, current rewards: 121.03929, mean: 0.05129
[32m[0906 20-16-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10479, current rewards: 112.62930, mean: 0.04673
[32m[0906 20-16-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10486, current rewards: 118.60235, mean: 0.04821
[32m[0906 20-16-53 @Agent.py:117][0m Average action selection time: 0.1049
[32m[0906 20-16-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-16-53 @MBExp.py:227][0m Rewards obtained: [123.48544653043184], Lows: [83], Highs: [10], Total time: 18419.68242200001
[32m[0906 20-19-32 @MBExp.py:144][0m ####################################################################
[32m[0906 20-19-32 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 20-19-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10918, current rewards: -9.57409, mean: -0.95741
[32m[0906 20-19-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10852, current rewards: -76.38351, mean: -1.27306
[32m[0906 20-19-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10704, current rewards: -143.75596, mean: -1.30687
[32m[0906 20-19-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10653, current rewards: -208.15652, mean: -1.30098
[32m[0906 20-19-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10611, current rewards: -275.80069, mean: -1.31334
[32m[0906 20-20-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10583, current rewards: -345.69975, mean: -1.32961
[32m[0906 20-20-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10567, current rewards: -415.47278, mean: -1.34023
[32m[0906 20-20-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10508, current rewards: -485.16768, mean: -1.34769
[32m[0906 20-20-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10470, current rewards: -552.80890, mean: -1.34831
[32m[0906 20-20-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10439, current rewards: -620.46596, mean: -1.34884
[32m[0906 20-20-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10417, current rewards: -683.19274, mean: -1.33959
[32m[0906 20-20-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10402, current rewards: -750.43016, mean: -1.34005
[32m[0906 20-20-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10385, current rewards: -753.43444, mean: -1.23514
[32m[0906 20-20-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10369, current rewards: -748.25249, mean: -1.13372
[32m[0906 20-20-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10352, current rewards: -743.07209, mean: -1.04658
[32m[0906 20-20-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10341, current rewards: -737.89237, mean: -0.97091
[32m[0906 20-20-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10333, current rewards: -732.71595, mean: -0.90459
[32m[0906 20-21-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10324, current rewards: -727.53768, mean: -0.84597
[32m[0906 20-21-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10319, current rewards: -722.15600, mean: -0.79358
[32m[0906 20-21-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10312, current rewards: -716.91555, mean: -0.74679
[32m[0906 20-21-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10315, current rewards: -726.71182, mean: -0.71952
[32m[0906 20-21-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10318, current rewards: -738.23177, mean: -0.69645
[32m[0906 20-21-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10314, current rewards: -732.44735, mean: -0.65986
[32m[0906 20-21-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10306, current rewards: -726.65161, mean: -0.62642
[32m[0906 20-21-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10300, current rewards: -720.86619, mean: -0.59576
[32m[0906 20-21-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10296, current rewards: -720.04969, mean: -0.57147
[32m[0906 20-21-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10315, current rewards: -800.41191, mean: -0.61100
[32m[0906 20-21-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10335, current rewards: -878.50643, mean: -0.64596
[32m[0906 20-21-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10346, current rewards: -959.06045, mean: -0.68018
[32m[0906 20-22-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10371, current rewards: -1036.77852, mean: -0.71012
[32m[0906 20-22-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10382, current rewards: -1065.74788, mean: -0.70579
[32m[0906 20-22-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10387, current rewards: -1060.09954, mean: -0.67955
[32m[0906 20-22-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10394, current rewards: -1054.45292, mean: -0.65494
[32m[0906 20-22-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10398, current rewards: -1048.80638, mean: -0.63181
[32m[0906 20-22-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10402, current rewards: -1043.15667, mean: -0.61003
[32m[0906 20-22-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10405, current rewards: -1037.40880, mean: -0.58944
[32m[0906 20-22-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10408, current rewards: -1031.75428, mean: -0.57003
[32m[0906 20-22-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10419, current rewards: -1031.11048, mean: -0.55436
[32m[0906 20-22-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10431, current rewards: -1025.68091, mean: -0.53701
[32m[0906 20-22-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10442, current rewards: -1020.24399, mean: -0.52053
[32m[0906 20-23-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10454, current rewards: -1014.81146, mean: -0.50488
[32m[0906 20-23-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10465, current rewards: -1009.37965, mean: -0.48999
[32m[0906 20-23-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10474, current rewards: -1003.94632, mean: -0.47580
[32m[0906 20-23-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10485, current rewards: -999.03558, mean: -0.46252
[32m[0906 20-23-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10493, current rewards: -1017.92293, mean: -0.46060
[32m[0906 20-23-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10502, current rewards: -1069.66370, mean: -0.47330
[32m[0906 20-23-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10512, current rewards: -1113.26768, mean: -0.48193
[32m[0906 20-23-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10520, current rewards: -1168.15822, mean: -0.49498
[32m[0906 20-23-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10528, current rewards: -1211.64131, mean: -0.50276
[32m[0906 20-23-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10536, current rewards: -1264.36127, mean: -0.51397
[32m[0906 20-23-56 @Agent.py:117][0m Average action selection time: 0.1054
[32m[0906 20-23-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-23-56 @MBExp.py:227][0m Rewards obtained: [-1301.2800135799107], Lows: [759], Highs: [15], Total time: 18684.03276200001
[32m[0906 20-26-38 @MBExp.py:144][0m ####################################################################
[32m[0906 20-26-38 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 20-26-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11511, current rewards: -7.30667, mean: -0.73067
[32m[0906 20-26-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11490, current rewards: -14.80083, mean: -0.24668
[32m[0906 20-26-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11061, current rewards: -8.22806, mean: -0.07480
[32m[0906 20-26-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10880, current rewards: -1.33912, mean: -0.00837
[32m[0906 20-27-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10800, current rewards: 5.54680, mean: 0.02641
[32m[0906 20-27-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10743, current rewards: 12.41835, mean: 0.04776
[32m[0906 20-27-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10686, current rewards: 19.29111, mean: 0.06223
[32m[0906 20-27-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10617, current rewards: 26.16842, mean: 0.07269
[32m[0906 20-27-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10560, current rewards: 33.04091, mean: 0.08059
[32m[0906 20-27-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10510, current rewards: 39.91879, mean: 0.08678
[32m[0906 20-27-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10484, current rewards: 46.52862, mean: 0.09123
[32m[0906 20-27-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10461, current rewards: 53.58158, mean: 0.09568
[32m[0906 20-27-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10436, current rewards: 48.79985, mean: 0.08000
[32m[0906 20-27-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10416, current rewards: 53.64068, mean: 0.08127
[32m[0906 20-27-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10390, current rewards: 58.48042, mean: 0.08237
[32m[0906 20-27-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10372, current rewards: 63.32209, mean: 0.08332
[32m[0906 20-28-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10362, current rewards: 68.16539, mean: 0.08415
[32m[0906 20-28-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10350, current rewards: 73.00583, mean: 0.08489
[32m[0906 20-28-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10336, current rewards: 77.76682, mean: 0.08546
[32m[0906 20-28-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10327, current rewards: 75.12747, mean: 0.07826
[32m[0906 20-28-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10317, current rewards: 73.25748, mean: 0.07253
[32m[0906 20-28-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10310, current rewards: 79.04253, mean: 0.07457
[32m[0906 20-28-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10302, current rewards: 84.82390, mean: 0.07642
[32m[0906 20-28-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10298, current rewards: 90.60104, mean: 0.07810
[32m[0906 20-28-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10291, current rewards: 96.38121, mean: 0.07965
[32m[0906 20-28-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10285, current rewards: 102.15356, mean: 0.08107
[32m[0906 20-28-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10284, current rewards: 108.21329, mean: 0.08261
[32m[0906 20-28-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10290, current rewards: 113.98674, mean: 0.08381
[32m[0906 20-29-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10298, current rewards: 119.76300, mean: 0.08494
[32m[0906 20-29-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10306, current rewards: 125.53625, mean: 0.08598
[32m[0906 20-29-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10311, current rewards: 131.31620, mean: 0.08696
[32m[0906 20-29-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10316, current rewards: 137.09064, mean: 0.08788
[32m[0906 20-29-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10322, current rewards: 142.86632, mean: 0.08874
[32m[0906 20-29-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10324, current rewards: 138.06428, mean: 0.08317
[32m[0906 20-29-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10328, current rewards: 143.97332, mean: 0.08419
[32m[0906 20-29-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10334, current rewards: 149.59737, mean: 0.08500
[32m[0906 20-29-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10338, current rewards: 155.21943, mean: 0.08576
[32m[0906 20-29-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10342, current rewards: 160.83999, mean: 0.08647
[32m[0906 20-29-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10355, current rewards: 166.46707, mean: 0.08716
[32m[0906 20-30-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10367, current rewards: 172.09231, mean: 0.08780
[32m[0906 20-30-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10378, current rewards: 177.71908, mean: 0.08842
[32m[0906 20-30-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10391, current rewards: 183.34501, mean: 0.08900
[32m[0906 20-30-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10401, current rewards: 188.92200, mean: 0.08954
[32m[0906 20-30-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10411, current rewards: 194.55143, mean: 0.09007
[32m[0906 20-30-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10420, current rewards: 200.18034, mean: 0.09058
[32m[0906 20-30-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10429, current rewards: 205.80629, mean: 0.09106
[32m[0906 20-30-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10437, current rewards: 211.43366, mean: 0.09153
[32m[0906 20-30-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10447, current rewards: 217.06074, mean: 0.09197
[32m[0906 20-30-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10455, current rewards: 222.69295, mean: 0.09240
[32m[0906 20-30-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10462, current rewards: 222.75846, mean: 0.09055
[32m[0906 20-31-00 @Agent.py:117][0m Average action selection time: 0.1047
[32m[0906 20-31-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-31-00 @MBExp.py:227][0m Rewards obtained: [162.35832951729435], Lows: [54], Highs: [16], Total time: 18946.54223600001
[32m[0906 20-33-44 @MBExp.py:144][0m ####################################################################
[32m[0906 20-33-44 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 20-33-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10809, current rewards: -14.00000, mean: -1.40000
[32m[0906 20-33-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11253, current rewards: -103.32188, mean: -1.72203
[32m[0906 20-33-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11115, current rewards: -188.00982, mean: -1.70918
[32m[0906 20-34-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10907, current rewards: -288.00982, mean: -1.80006
[32m[0906 20-34-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10798, current rewards: -388.00982, mean: -1.84767
[32m[0906 20-34-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10737, current rewards: -488.00982, mean: -1.87696
[32m[0906 20-34-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10688, current rewards: -588.00982, mean: -1.89681
[32m[0906 20-34-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10619, current rewards: -688.00982, mean: -1.91114
[32m[0906 20-34-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10560, current rewards: -788.00982, mean: -1.92198
[32m[0906 20-34-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10512, current rewards: -888.00982, mean: -1.93046
[32m[0906 20-34-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10475, current rewards: -988.00982, mean: -1.93727
[32m[0906 20-34-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10453, current rewards: -1088.00982, mean: -1.94287
[32m[0906 20-34-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10429, current rewards: -1188.00982, mean: -1.94756
[32m[0906 20-34-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10406, current rewards: -1288.00982, mean: -1.95153
[32m[0906 20-34-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10391, current rewards: -1388.00982, mean: -1.95494
[32m[0906 20-35-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10371, current rewards: -1488.00982, mean: -1.95791
[32m[0906 20-35-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10357, current rewards: -1588.00982, mean: -1.96051
[32m[0906 20-35-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10346, current rewards: -1688.00982, mean: -1.96280
[32m[0906 20-35-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10334, current rewards: -1788.00982, mean: -1.96485
[32m[0906 20-35-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10326, current rewards: -1888.00982, mean: -1.96668
[32m[0906 20-35-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10320, current rewards: -1988.00982, mean: -1.96833
[32m[0906 20-35-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10311, current rewards: -2088.00982, mean: -1.96982
[32m[0906 20-35-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10305, current rewards: -2188.00982, mean: -1.97118
[32m[0906 20-35-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10301, current rewards: -2288.00982, mean: -1.97242
[32m[0906 20-35-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10294, current rewards: -2388.00982, mean: -1.97356
[32m[0906 20-35-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10288, current rewards: -2488.00982, mean: -1.97461
[32m[0906 20-35-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10282, current rewards: -2588.00982, mean: -1.97558
[32m[0906 20-36-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10284, current rewards: -2688.00982, mean: -1.97648
[32m[0906 20-36-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10293, current rewards: -2788.00982, mean: -1.97731
[32m[0906 20-36-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10302, current rewards: -2888.00982, mean: -1.97809
[32m[0906 20-36-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10307, current rewards: -2988.00982, mean: -1.97881
[32m[0906 20-36-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10312, current rewards: -3088.00982, mean: -1.97949
[32m[0906 20-36-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10319, current rewards: -3188.00982, mean: -1.98013
[32m[0906 20-36-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10316, current rewards: -3288.00982, mean: -1.98073
[32m[0906 20-36-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10322, current rewards: -3388.00982, mean: -1.98129
[32m[0906 20-36-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10327, current rewards: -3488.00982, mean: -1.98182
[32m[0906 20-36-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10332, current rewards: -3588.00982, mean: -1.98233
[32m[0906 20-36-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10338, current rewards: -3688.00982, mean: -1.98280
[32m[0906 20-37-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10342, current rewards: -3788.00982, mean: -1.98325
[32m[0906 20-37-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10356, current rewards: -3888.00982, mean: -1.98368
[32m[0906 20-37-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10368, current rewards: -3988.00982, mean: -1.98408
[32m[0906 20-37-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10381, current rewards: -4088.00982, mean: -1.98447
[32m[0906 20-37-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10392, current rewards: -4188.00982, mean: -1.98484
[32m[0906 20-37-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10402, current rewards: -4288.00982, mean: -1.98519
[32m[0906 20-37-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10417, current rewards: -4388.00982, mean: -1.98552
[32m[0906 20-37-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10427, current rewards: -4488.00982, mean: -1.98585
[32m[0906 20-37-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10436, current rewards: -4588.00982, mean: -1.98615
[32m[0906 20-37-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10446, current rewards: -4688.00982, mean: -1.98644
[32m[0906 20-37-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10454, current rewards: -4788.00982, mean: -1.98673
[32m[0906 20-38-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10462, current rewards: -4888.00982, mean: -1.98700
[32m[0906 20-38-06 @Agent.py:117][0m Average action selection time: 0.1047
[32m[0906 20-38-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-38-06 @MBExp.py:227][0m Rewards obtained: [-4968.009817739059], Lows: [2482], Highs: [6], Total time: 19209.089087000008
[32m[0906 20-40-52 @MBExp.py:144][0m ####################################################################
[32m[0906 20-40-52 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 20-40-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.13224, current rewards: -6.53123, mean: -0.65312
[32m[0906 20-40-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11259, current rewards: -2.18496, mean: -0.03642
[32m[0906 20-41-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11072, current rewards: 4.40848, mean: 0.04008
[32m[0906 20-41-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10884, current rewards: 10.99118, mean: 0.06869
[32m[0906 20-41-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10788, current rewards: 17.57648, mean: 0.08370
[32m[0906 20-41-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10744, current rewards: 24.17271, mean: 0.09297
[32m[0906 20-41-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10701, current rewards: 30.76309, mean: 0.09924
[32m[0906 20-41-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10658, current rewards: 37.35498, mean: 0.10376
[32m[0906 20-41-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10601, current rewards: 43.93682, mean: 0.10716
[32m[0906 20-41-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10551, current rewards: 50.52637, mean: 0.10984
[32m[0906 20-41-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10507, current rewards: 57.10962, mean: 0.11198
[32m[0906 20-41-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10481, current rewards: 63.69700, mean: 0.11374
[32m[0906 20-41-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10450, current rewards: 70.16381, mean: 0.11502
[32m[0906 20-42-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10431, current rewards: 68.37895, mean: 0.10360
[32m[0906 20-42-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10416, current rewards: 76.27861, mean: 0.10743
[32m[0906 20-42-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10399, current rewards: 84.16651, mean: 0.11075
[32m[0906 20-42-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10384, current rewards: 92.08010, mean: 0.11368
[32m[0906 20-42-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10373, current rewards: 102.13766, mean: 0.11876
[32m[0906 20-42-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10357, current rewards: 97.50615, mean: 0.10715
[32m[0906 20-42-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10346, current rewards: 106.42590, mean: 0.11086
[32m[0906 20-42-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10339, current rewards: 115.31637, mean: 0.11417
[32m[0906 20-42-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10328, current rewards: 124.22595, mean: 0.11719
[32m[0906 20-42-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10319, current rewards: 117.03366, mean: 0.10544
[32m[0906 20-42-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10313, current rewards: 127.89739, mean: 0.11026
[32m[0906 20-42-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10306, current rewards: 138.77612, mean: 0.11469
[32m[0906 20-43-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10298, current rewards: 147.39024, mean: 0.11698
[32m[0906 20-43-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10291, current rewards: 149.60529, mean: 0.11420
[32m[0906 20-43-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10286, current rewards: 157.26799, mean: 0.11564
[32m[0906 20-43-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10287, current rewards: 164.41494, mean: 0.11661
[32m[0906 20-43-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10294, current rewards: 171.53086, mean: 0.11749
[32m[0906 20-43-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10302, current rewards: 178.66577, mean: 0.11832
[32m[0906 20-43-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10307, current rewards: 185.79391, mean: 0.11910
[32m[0906 20-43-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10311, current rewards: 192.92451, mean: 0.11983
[32m[0906 20-43-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10317, current rewards: 199.86670, mean: 0.12040
[32m[0906 20-43-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10325, current rewards: 207.19381, mean: 0.12117
[32m[0906 20-43-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10332, current rewards: 214.42957, mean: 0.12183
[32m[0906 20-44-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10337, current rewards: 221.65690, mean: 0.12246
[32m[0906 20-44-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10341, current rewards: 228.88745, mean: 0.12306
[32m[0906 20-44-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10343, current rewards: 236.10715, mean: 0.12362
[32m[0906 20-44-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10349, current rewards: 232.32840, mean: 0.11853
[32m[0906 20-44-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10360, current rewards: 225.59633, mean: 0.11224
[32m[0906 20-44-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10372, current rewards: 233.95219, mean: 0.11357
[32m[0906 20-44-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10383, current rewards: 242.77411, mean: 0.11506
[32m[0906 20-44-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10392, current rewards: 250.86613, mean: 0.11614
[32m[0906 20-44-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10402, current rewards: 258.95650, mean: 0.11717
[32m[0906 20-44-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10412, current rewards: 267.04183, mean: 0.11816
[32m[0906 20-44-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10421, current rewards: 275.12837, mean: 0.11910
[32m[0906 20-44-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10430, current rewards: 283.21876, mean: 0.12001
[32m[0906 20-45-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10438, current rewards: 291.31924, mean: 0.12088
[32m[0906 20-45-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10446, current rewards: 285.80525, mean: 0.11618
[32m[0906 20-45-14 @Agent.py:117][0m Average action selection time: 0.1045
[32m[0906 20-45-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-45-14 @MBExp.py:227][0m Rewards obtained: [292.01176639857], Lows: [40], Highs: [13], Total time: 19471.19267400001
[32m[0906 20-48-02 @MBExp.py:144][0m ####################################################################
[32m[0906 20-48-02 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 20-48-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11813, current rewards: -6.62827, mean: -0.66283
[32m[0906 20-48-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10906, current rewards: -4.35994, mean: -0.07267
[32m[0906 20-48-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10874, current rewards: 1.84304, mean: 0.01675
[32m[0906 20-48-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10727, current rewards: 8.05007, mean: 0.05031
[32m[0906 20-48-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10663, current rewards: 14.25379, mean: 0.06788
[32m[0906 20-48-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10630, current rewards: 20.46116, mean: 0.07870
[32m[0906 20-48-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10596, current rewards: 26.66665, mean: 0.08602
[32m[0906 20-48-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10570, current rewards: 32.87232, mean: 0.09131
[32m[0906 20-48-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10514, current rewards: 35.38612, mean: 0.08631
[32m[0906 20-48-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10463, current rewards: 38.07817, mean: 0.08278
[32m[0906 20-48-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10429, current rewards: 43.49539, mean: 0.08529
[32m[0906 20-49-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10402, current rewards: 48.90708, mean: 0.08733
[32m[0906 20-49-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10376, current rewards: 54.32325, mean: 0.08905
[32m[0906 20-49-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10352, current rewards: 59.73949, mean: 0.09051
[32m[0906 20-49-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10340, current rewards: 65.14955, mean: 0.09176
[32m[0906 20-49-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10324, current rewards: 70.38875, mean: 0.09262
[32m[0906 20-49-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10311, current rewards: 75.80283, mean: 0.09358
[32m[0906 20-49-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10305, current rewards: 80.86616, mean: 0.09403
[32m[0906 20-49-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10295, current rewards: 86.20297, mean: 0.09473
[32m[0906 20-49-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10286, current rewards: 91.53419, mean: 0.09535
[32m[0906 20-49-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10278, current rewards: 96.86771, mean: 0.09591
[32m[0906 20-49-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10272, current rewards: 102.19577, mean: 0.09641
[32m[0906 20-49-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10264, current rewards: 107.52722, mean: 0.09687
[32m[0906 20-50-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10262, current rewards: 108.64775, mean: 0.09366
[32m[0906 20-50-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10255, current rewards: 110.03006, mean: 0.09093
[32m[0906 20-50-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10250, current rewards: 115.64653, mean: 0.09178
[32m[0906 20-50-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10246, current rewards: 121.26400, mean: 0.09257
[32m[0906 20-50-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10241, current rewards: 126.87808, mean: 0.09329
[32m[0906 20-50-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10236, current rewards: 132.49674, mean: 0.09397
[32m[0906 20-50-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10239, current rewards: 138.11052, mean: 0.09460
[32m[0906 20-50-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10248, current rewards: 143.72488, mean: 0.09518
[32m[0906 20-50-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10252, current rewards: 149.34294, mean: 0.09573
[32m[0906 20-50-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10259, current rewards: 154.95805, mean: 0.09625
[32m[0906 20-50-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10267, current rewards: 162.79989, mean: 0.09807
[32m[0906 20-50-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10271, current rewards: 171.33781, mean: 0.10020
[32m[0906 20-51-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10281, current rewards: 136.55767, mean: 0.07759
[32m[0906 20-51-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10293, current rewards: 86.55767, mean: 0.04782
[32m[0906 20-51-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10298, current rewards: 36.55767, mean: 0.01965
[32m[0906 20-51-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10303, current rewards: -13.44233, mean: -0.00704
[32m[0906 20-51-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10309, current rewards: -63.44233, mean: -0.03237
[32m[0906 20-51-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10316, current rewards: -113.44233, mean: -0.05644
[32m[0906 20-51-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10328, current rewards: -163.44233, mean: -0.07934
[32m[0906 20-51-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10340, current rewards: -213.44233, mean: -0.10116
[32m[0906 20-51-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10351, current rewards: -263.44233, mean: -0.12196
[32m[0906 20-51-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10361, current rewards: -313.44233, mean: -0.14183
[32m[0906 20-51-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10373, current rewards: -363.44233, mean: -0.16082
[32m[0906 20-52-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10383, current rewards: -413.44233, mean: -0.17898
[32m[0906 20-52-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10392, current rewards: -463.44233, mean: -0.19637
[32m[0906 20-52-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10402, current rewards: -513.44233, mean: -0.21305
[32m[0906 20-52-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10411, current rewards: -563.44233, mean: -0.22904
[32m[0906 20-52-23 @Agent.py:117][0m Average action selection time: 0.1042
[32m[0906 20-52-23 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-52-23 @MBExp.py:227][0m Rewards obtained: [-603.4423323094306], Lows: [9], Highs: [787], Total time: 19732.41288800001
[32m[0906 20-55-13 @MBExp.py:144][0m ####################################################################
[32m[0906 20-55-13 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 20-55-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11346, current rewards: -12.84396, mean: -1.28440
[32m[0906 20-55-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11077, current rewards: -8.07882, mean: -0.13465
[32m[0906 20-55-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10968, current rewards: -1.68210, mean: -0.01529
[32m[0906 20-55-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10855, current rewards: 4.70993, mean: 0.02944
[32m[0906 20-55-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10774, current rewards: 11.10571, mean: 0.05288
[32m[0906 20-55-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10723, current rewards: 17.50335, mean: 0.06732
[32m[0906 20-55-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10678, current rewards: 23.89224, mean: 0.07707
[32m[0906 20-55-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10654, current rewards: 19.00855, mean: 0.05280
[32m[0906 20-55-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10610, current rewards: 24.32227, mean: 0.05932
[32m[0906 20-56-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10561, current rewards: 29.73643, mean: 0.06464
[32m[0906 20-56-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10518, current rewards: 35.13961, mean: 0.06890
[32m[0906 20-56-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10482, current rewards: 40.54094, mean: 0.07239
[32m[0906 20-56-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10450, current rewards: 45.94414, mean: 0.07532
[32m[0906 20-56-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10429, current rewards: 51.34510, mean: 0.07780
[32m[0906 20-56-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10411, current rewards: 56.74658, mean: 0.07992
[32m[0906 20-56-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10392, current rewards: 62.15519, mean: 0.08178
[32m[0906 20-56-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10376, current rewards: 67.62330, mean: 0.08349
[32m[0906 20-56-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10363, current rewards: 73.02769, mean: 0.08492
[32m[0906 20-56-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10352, current rewards: 78.43724, mean: 0.08619
[32m[0906 20-56-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10338, current rewards: 83.85171, mean: 0.08735
[32m[0906 20-56-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10331, current rewards: 79.38000, mean: 0.07859
[32m[0906 20-57-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10320, current rewards: 85.21423, mean: 0.08039
[32m[0906 20-57-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10310, current rewards: 91.04138, mean: 0.08202
[32m[0906 20-57-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10301, current rewards: 96.86279, mean: 0.08350
[32m[0906 20-57-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10293, current rewards: 102.75747, mean: 0.08492
[32m[0906 20-57-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10287, current rewards: 108.58222, mean: 0.08618
[32m[0906 20-57-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10282, current rewards: 114.40014, mean: 0.08733
[32m[0906 20-57-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10278, current rewards: 104.67350, mean: 0.07697
[32m[0906 20-57-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10340, current rewards: 55.62570, mean: 0.03945
[32m[0906 20-57-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10358, current rewards: 3.21400, mean: 0.00220
[32m[0906 20-57-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10413, current rewards: -59.19813, mean: -0.03920
[32m[0906 20-57-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10459, current rewards: -115.53503, mean: -0.07406
[32m[0906 20-58-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10519, current rewards: -166.47705, mean: -0.10340
[32m[0906 20-58-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10565, current rewards: -209.95465, mean: -0.12648
[32m[0906 20-58-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10562, current rewards: -202.39267, mean: -0.11836
[32m[0906 20-58-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10618, current rewards: -236.76710, mean: -0.13453
[32m[0906 20-58-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10686, current rewards: -279.61676, mean: -0.15448
[32m[0906 20-58-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10744, current rewards: -316.56899, mean: -0.17020
[32m[0906 20-58-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10788, current rewards: -352.06089, mean: -0.18433
[32m[0906 20-58-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10815, current rewards: -381.78333, mean: -0.19479
[32m[0906 20-58-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10870, current rewards: -420.79899, mean: -0.20935
[32m[0906 20-58-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10921, current rewards: -461.54780, mean: -0.22405
[32m[0906 20-59-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10945, current rewards: -515.49820, mean: -0.24431
[32m[0906 20-59-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10942, current rewards: -579.31392, mean: -0.26820
[32m[0906 20-59-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10940, current rewards: -635.61165, mean: -0.28761
[32m[0906 20-59-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10938, current rewards: -697.04767, mean: -0.30843
[32m[0906 20-59-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10958, current rewards: -753.13944, mean: -0.32603
[32m[0906 20-59-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11006, current rewards: -805.95276, mean: -0.34151
[32m[0906 20-59-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11003, current rewards: -797.72983, mean: -0.33101
[32m[0906 20-59-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10999, current rewards: -791.45705, mean: -0.32173
[32m[0906 20-59-49 @Agent.py:117][0m Average action selection time: 0.1100
[32m[0906 20-59-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-59-49 @MBExp.py:227][0m Rewards obtained: [-786.0688197432684], Lows: [519], Highs: [28], Total time: 20008.13913400001
[32m[0906 21-02-40 @MBExp.py:144][0m ####################################################################
[32m[0906 21-02-40 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 21-02-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10635, current rewards: -4.56570, mean: -0.45657
[32m[0906 21-02-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10467, current rewards: 1.47277, mean: 0.02455
[32m[0906 21-02-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10431, current rewards: 6.93302, mean: 0.06303
[32m[0906 21-02-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10432, current rewards: 12.39200, mean: 0.07745
[32m[0906 21-03-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10437, current rewards: 17.84939, mean: 0.08500
[32m[0906 21-03-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10431, current rewards: 23.31061, mean: 0.08966
[32m[0906 21-03-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10407, current rewards: 28.76743, mean: 0.09280
[32m[0906 21-03-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10363, current rewards: 34.22497, mean: 0.09507
[32m[0906 21-03-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10328, current rewards: 39.38076, mean: 0.09605
[32m[0906 21-03-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10303, current rewards: 44.88622, mean: 0.09758
[32m[0906 21-03-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10296, current rewards: 41.28154, mean: 0.08094
[32m[0906 21-03-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10276, current rewards: 46.05702, mean: 0.08224
[32m[0906 21-03-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10257, current rewards: 50.78158, mean: 0.08325
[32m[0906 21-03-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10246, current rewards: 55.50617, mean: 0.08410
[32m[0906 21-03-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10232, current rewards: 60.22709, mean: 0.08483
[32m[0906 21-03-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10220, current rewards: 64.95313, mean: 0.08546
[32m[0906 21-04-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10215, current rewards: 69.95549, mean: 0.08636
[32m[0906 21-04-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10205, current rewards: 74.63235, mean: 0.08678
[32m[0906 21-04-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10231, current rewards: 44.13376, mean: 0.04850
[32m[0906 21-04-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10242, current rewards: -0.82266, mean: -0.00086
[32m[0906 21-04-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10232, current rewards: 3.98556, mean: 0.00395
[32m[0906 21-04-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10221, current rewards: 8.79488, mean: 0.00830
[32m[0906 21-04-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10214, current rewards: 13.60299, mean: 0.01225
[32m[0906 21-04-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10210, current rewards: 18.40774, mean: 0.01587
[32m[0906 21-04-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10204, current rewards: 23.18264, mean: 0.01916
[32m[0906 21-04-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10199, current rewards: 28.00900, mean: 0.02223
[32m[0906 21-04-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10196, current rewards: 32.84270, mean: 0.02507
[32m[0906 21-04-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10191, current rewards: 25.22886, mean: 0.01855
[32m[0906 21-05-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10196, current rewards: 29.50113, mean: 0.02092
[32m[0906 21-05-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10205, current rewards: 33.77317, mean: 0.02313
[32m[0906 21-05-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10212, current rewards: 38.04535, mean: 0.02520
[32m[0906 21-05-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10216, current rewards: 42.31732, mean: 0.02713
[32m[0906 21-05-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10224, current rewards: 41.54106, mean: 0.02580
[32m[0906 21-05-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10229, current rewards: 45.45691, mean: 0.02738
[32m[0906 21-05-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10241, current rewards: 49.37444, mean: 0.02887
[32m[0906 21-05-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10256, current rewards: 53.29311, mean: 0.03028
[32m[0906 21-05-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10264, current rewards: 57.21057, mean: 0.03161
[32m[0906 21-05-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10267, current rewards: 61.12704, mean: 0.03286
[32m[0906 21-05-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10271, current rewards: 65.04584, mean: 0.03406
[32m[0906 21-06-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10279, current rewards: 59.67502, mean: 0.03045
[32m[0906 21-06-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10297, current rewards: -10.57146, mean: -0.00526
[32m[0906 21-06-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10319, current rewards: -88.69377, mean: -0.04306
[32m[0906 21-06-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10334, current rewards: -149.53983, mean: -0.07087
[32m[0906 21-06-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10351, current rewards: -223.72113, mean: -0.10357
[32m[0906 21-06-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10363, current rewards: -277.76773, mean: -0.12569
[32m[0906 21-06-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10375, current rewards: -333.09001, mean: -0.14738
[32m[0906 21-06-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10390, current rewards: -405.13299, mean: -0.17538
[32m[0906 21-06-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10405, current rewards: -446.40062, mean: -0.18915
[32m[0906 21-06-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10411, current rewards: -441.11858, mean: -0.18304
[32m[0906 21-06-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10416, current rewards: -436.42249, mean: -0.17741
[32m[0906 21-07-01 @Agent.py:117][0m Average action selection time: 0.1042
[32m[0906 21-07-01 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-07-02 @MBExp.py:227][0m Rewards obtained: [-432.6244721032764], Lows: [318], Highs: [21], Total time: 20269.46352000001
[32m[0906 21-09-54 @MBExp.py:144][0m ####################################################################
[32m[0906 21-09-54 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 21-09-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12927, current rewards: -9.17379, mean: -0.91738
[32m[0906 21-10-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10755, current rewards: -8.85366, mean: -0.14756
[32m[0906 21-10-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10565, current rewards: -2.15366, mean: -0.01958
[32m[0906 21-10-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10502, current rewards: 4.55034, mean: 0.02844
[32m[0906 21-10-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10450, current rewards: 11.24656, mean: 0.05356
[32m[0906 21-10-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10428, current rewards: 17.94047, mean: 0.06900
[32m[0906 21-10-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10399, current rewards: 24.64040, mean: 0.07949
[32m[0906 21-10-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10342, current rewards: 31.71155, mean: 0.08809
[32m[0906 21-10-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10302, current rewards: 38.22236, mean: 0.09323
[32m[0906 21-10-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10284, current rewards: 44.73212, mean: 0.09724
[32m[0906 21-10-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10262, current rewards: 51.23635, mean: 0.10046
[32m[0906 21-10-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10240, current rewards: 57.74020, mean: 0.10311
[32m[0906 21-10-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10269, current rewards: 9.87610, mean: 0.01619
[32m[0906 21-11-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10249, current rewards: 16.98332, mean: 0.02573
[32m[0906 21-11-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10235, current rewards: 23.92132, mean: 0.03369
[32m[0906 21-11-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10222, current rewards: 31.11148, mean: 0.04094
[32m[0906 21-11-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10213, current rewards: 37.99089, mean: 0.04690
[32m[0906 21-11-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10203, current rewards: 44.90034, mean: 0.05221
[32m[0906 21-11-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10195, current rewards: 39.15415, mean: 0.04303
[32m[0906 21-11-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10189, current rewards: 44.87455, mean: 0.04674
[32m[0906 21-11-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10181, current rewards: 50.59429, mean: 0.05009
[32m[0906 21-11-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10173, current rewards: 56.30768, mean: 0.05312
[32m[0906 21-11-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10166, current rewards: 62.02087, mean: 0.05587
[32m[0906 21-11-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10160, current rewards: 67.63733, mean: 0.05831
[32m[0906 21-11-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10154, current rewards: 73.28662, mean: 0.06057
[32m[0906 21-12-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10152, current rewards: 78.94079, mean: 0.06265
[32m[0906 21-12-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10148, current rewards: 84.59139, mean: 0.06457
[32m[0906 21-12-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10143, current rewards: 75.19807, mean: 0.05529
[32m[0906 21-12-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10142, current rewards: 82.08198, mean: 0.05821
[32m[0906 21-12-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10147, current rewards: 88.38402, mean: 0.06054
[32m[0906 21-12-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10153, current rewards: 94.67042, mean: 0.06270
[32m[0906 21-12-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10160, current rewards: 100.91859, mean: 0.06469
[32m[0906 21-12-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10164, current rewards: 107.30990, mean: 0.06665
[32m[0906 21-12-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10167, current rewards: 113.70997, mean: 0.06850
[32m[0906 21-12-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10173, current rewards: 120.12079, mean: 0.07025
[32m[0906 21-12-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10186, current rewards: 126.51858, mean: 0.07189
[32m[0906 21-12-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10195, current rewards: 132.91940, mean: 0.07344
[32m[0906 21-13-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10200, current rewards: 129.05110, mean: 0.06938
[32m[0906 21-13-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10204, current rewards: 140.19857, mean: 0.07340
[32m[0906 21-13-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10206, current rewards: 151.39750, mean: 0.07724
[32m[0906 21-13-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10214, current rewards: 162.46990, mean: 0.08083
[32m[0906 21-13-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10225, current rewards: 173.55083, mean: 0.08425
[32m[0906 21-13-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10235, current rewards: 184.64052, mean: 0.08751
[32m[0906 21-13-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10246, current rewards: 195.71385, mean: 0.09061
[32m[0906 21-13-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10256, current rewards: 206.77680, mean: 0.09356
[32m[0906 21-13-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10264, current rewards: 217.83626, mean: 0.09639
[32m[0906 21-13-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10273, current rewards: 228.90775, mean: 0.09909
[32m[0906 21-13-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10281, current rewards: 239.98069, mean: 0.10169
[32m[0906 21-14-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10289, current rewards: 251.05600, mean: 0.10417
[32m[0906 21-14-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10300, current rewards: 253.24435, mean: 0.10294
[32m[0906 21-14-12 @Agent.py:117][0m Average action selection time: 0.1031
[32m[0906 21-14-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-14-12 @MBExp.py:227][0m Rewards obtained: [257.5011813087409], Lows: [50], Highs: [13], Total time: 20527.89447500001
[32m[0906 21-17-06 @MBExp.py:144][0m ####################################################################
[32m[0906 21-17-06 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 21-17-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10931, current rewards: -15.00000, mean: -1.50000
[32m[0906 21-17-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10498, current rewards: -18.22640, mean: -0.30377
[32m[0906 21-17-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10429, current rewards: 0.09783, mean: 0.00089
[32m[0906 21-17-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10398, current rewards: 18.42448, mean: 0.11515
[32m[0906 21-17-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10382, current rewards: 36.71043, mean: 0.17481
[32m[0906 21-17-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10391, current rewards: 55.00432, mean: 0.21156
[32m[0906 21-17-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10387, current rewards: 71.97430, mean: 0.23218
[32m[0906 21-17-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10339, current rewards: 81.84407, mean: 0.22734
[32m[0906 21-17-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10307, current rewards: 91.70068, mean: 0.22366
[32m[0906 21-17-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10277, current rewards: 101.55446, mean: 0.22077
[32m[0906 21-17-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10255, current rewards: 111.42282, mean: 0.21848
[32m[0906 21-18-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10242, current rewards: 121.26872, mean: 0.21655
[32m[0906 21-18-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10226, current rewards: 131.12945, mean: 0.21497
[32m[0906 21-18-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10212, current rewards: 140.97375, mean: 0.21360
[32m[0906 21-18-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10200, current rewards: 150.83089, mean: 0.21244
[32m[0906 21-18-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10252, current rewards: 89.62081, mean: 0.11792
[32m[0906 21-18-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10275, current rewards: 29.92562, mean: 0.03695
[32m[0906 21-18-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10264, current rewards: 7.08471, mean: 0.00824
[32m[0906 21-18-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10251, current rewards: 13.36825, mean: 0.01469
[32m[0906 21-18-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10241, current rewards: 19.66609, mean: 0.02049
[32m[0906 21-18-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10231, current rewards: -19.99534, mean: -0.01980
[32m[0906 21-18-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10220, current rewards: -11.78285, mean: -0.01112
[32m[0906 21-19-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10210, current rewards: -4.59181, mean: -0.00414
[32m[0906 21-19-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10200, current rewards: 2.71664, mean: 0.00234
[32m[0906 21-19-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10196, current rewards: 10.03506, mean: 0.00829
[32m[0906 21-19-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10190, current rewards: 17.34697, mean: 0.01377
[32m[0906 21-19-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10186, current rewards: 24.65389, mean: 0.01882
[32m[0906 21-19-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10181, current rewards: 31.97288, mean: 0.02351
[32m[0906 21-19-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10175, current rewards: 39.28937, mean: 0.02786
[32m[0906 21-19-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10173, current rewards: 46.60689, mean: 0.03192
[32m[0906 21-19-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10185, current rewards: 39.26206, mean: 0.02600
[32m[0906 21-19-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10190, current rewards: 44.70267, mean: 0.02866
[32m[0906 21-19-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10192, current rewards: 50.14648, mean: 0.03115
[32m[0906 21-19-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10197, current rewards: 55.58842, mean: 0.03349
[32m[0906 21-20-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10199, current rewards: 61.03363, mean: 0.03569
[32m[0906 21-20-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10206, current rewards: 66.47633, mean: 0.03777
[32m[0906 21-20-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10215, current rewards: 71.92251, mean: 0.03974
[32m[0906 21-20-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10218, current rewards: 77.36656, mean: 0.04159
[32m[0906 21-20-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10220, current rewards: 83.40499, mean: 0.04367
[32m[0906 21-20-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10224, current rewards: 88.93778, mean: 0.04538
[32m[0906 21-20-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10229, current rewards: 42.67274, mean: 0.02123
[32m[0906 21-20-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10249, current rewards: -25.11967, mean: -0.01219
[32m[0906 21-20-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10266, current rewards: -88.63344, mean: -0.04201
[32m[0906 21-20-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10279, current rewards: -164.70890, mean: -0.07625
[32m[0906 21-20-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10293, current rewards: -240.42636, mean: -0.10879
[32m[0906 21-21-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10310, current rewards: -308.37919, mean: -0.13645
[32m[0906 21-21-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10321, current rewards: -382.08955, mean: -0.16541
[32m[0906 21-21-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10359, current rewards: -434.79235, mean: -0.18423
[32m[0906 21-21-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10386, current rewards: -466.03921, mean: -0.19338
[32m[0906 21-21-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10419, current rewards: -503.26485, mean: -0.20458
[32m[0906 21-21-28 @Agent.py:117][0m Average action selection time: 0.1045
[32m[0906 21-21-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-21-28 @MBExp.py:227][0m Rewards obtained: [-537.3877962170985], Lows: [452], Highs: [15], Total time: 20789.85329900001
[32m[0906 21-24-25 @MBExp.py:144][0m ####################################################################
[32m[0906 21-24-25 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 21-24-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10581, current rewards: -9.66555, mean: -0.96655
[32m[0906 21-24-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10527, current rewards: -35.56369, mean: -0.59273
[32m[0906 21-24-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10416, current rewards: -30.26734, mean: -0.27516
[32m[0906 21-24-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10400, current rewards: -24.97617, mean: -0.15610
[32m[0906 21-24-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10375, current rewards: -19.68883, mean: -0.09376
[32m[0906 21-24-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10359, current rewards: -14.64864, mean: -0.05634
[32m[0906 21-24-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10338, current rewards: -9.29654, mean: -0.02999
[32m[0906 21-25-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10288, current rewards: -13.88327, mean: -0.03856
[32m[0906 21-25-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10249, current rewards: -7.76191, mean: -0.01893
[32m[0906 21-25-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10229, current rewards: -1.64072, mean: -0.00357
[32m[0906 21-25-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10204, current rewards: 4.46803, mean: 0.00876
[32m[0906 21-25-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10186, current rewards: -1.53622, mean: -0.00274
[32m[0906 21-25-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10177, current rewards: 11.00007, mean: 0.01803
[32m[0906 21-25-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10166, current rewards: 25.47032, mean: 0.03859
[32m[0906 21-25-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10155, current rewards: 38.89866, mean: 0.05479
[32m[0906 21-25-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10147, current rewards: 52.33829, mean: 0.06887
[32m[0906 21-25-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10137, current rewards: 65.77442, mean: 0.08120
[32m[0906 21-25-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10133, current rewards: 79.23395, mean: 0.09213
[32m[0906 21-25-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10127, current rewards: 60.41700, mean: 0.06639
[32m[0906 21-26-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10124, current rewards: 66.07187, mean: 0.06882
[32m[0906 21-26-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10116, current rewards: 71.72349, mean: 0.07101
[32m[0906 21-26-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10111, current rewards: 77.60020, mean: 0.07321
[32m[0906 21-26-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10108, current rewards: 76.31814, mean: 0.06876
[32m[0906 21-26-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10105, current rewards: 17.03350, mean: 0.01468
[32m[0906 21-26-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10099, current rewards: -32.10443, mean: -0.02653
[32m[0906 21-26-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10096, current rewards: -54.07497, mean: -0.04292
[32m[0906 21-26-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10092, current rewards: -73.47246, mean: -0.05609
[32m[0906 21-26-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10088, current rewards: -45.27160, mean: -0.03329
[32m[0906 21-26-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10084, current rewards: -17.27551, mean: -0.01225
[32m[0906 21-26-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10083, current rewards: 5.67763, mean: 0.00389
[32m[0906 21-26-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10091, current rewards: 27.61583, mean: 0.01829
[32m[0906 21-27-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10099, current rewards: 49.26183, mean: 0.03158
[32m[0906 21-27-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10107, current rewards: 38.57182, mean: 0.02396
[32m[0906 21-27-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10113, current rewards: 36.02389, mean: 0.02170
[32m[0906 21-27-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10119, current rewards: 44.81010, mean: 0.02620
[32m[0906 21-27-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10126, current rewards: 53.58724, mean: 0.03045
[32m[0906 21-27-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10139, current rewards: 62.37382, mean: 0.03446
[32m[0906 21-27-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10151, current rewards: 71.53573, mean: 0.03846
[32m[0906 21-27-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10155, current rewards: 81.37399, mean: 0.04260
[32m[0906 21-27-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10159, current rewards: 90.50631, mean: 0.04618
[32m[0906 21-27-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10164, current rewards: 99.64403, mean: 0.04957
[32m[0906 21-27-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10169, current rewards: 53.30921, mean: 0.02588
[32m[0906 21-28-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10180, current rewards: 78.43214, mean: 0.03717
[32m[0906 21-28-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10191, current rewards: 103.43603, mean: 0.04789
[32m[0906 21-28-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10199, current rewards: 128.75045, mean: 0.05826
[32m[0906 21-28-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10208, current rewards: 121.03259, mean: 0.05355
[32m[0906 21-28-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10218, current rewards: 129.30301, mean: 0.05598
[32m[0906 21-28-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10226, current rewards: 138.01398, mean: 0.05848
[32m[0906 21-28-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10233, current rewards: 146.71645, mean: 0.06088
[32m[0906 21-28-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10241, current rewards: 155.40221, mean: 0.06317
[32m[0906 21-28-41 @Agent.py:117][0m Average action selection time: 0.1025
[32m[0906 21-28-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-28-42 @MBExp.py:227][0m Rewards obtained: [162.3627251048874], Lows: [186], Highs: [22], Total time: 21046.79792600001
[32m[0906 21-31-39 @MBExp.py:144][0m ####################################################################
[32m[0906 21-31-39 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 21-31-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12190, current rewards: -6.08363, mean: -0.60836
[32m[0906 21-31-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10685, current rewards: -2.94375, mean: -0.04906
[32m[0906 21-31-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10509, current rewards: 2.56062, mean: 0.02328
[32m[0906 21-31-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10429, current rewards: 8.06961, mean: 0.05044
[32m[0906 21-32-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10403, current rewards: 13.33627, mean: 0.06351
[32m[0906 21-32-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10384, current rewards: 18.82779, mean: 0.07241
[32m[0906 21-32-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10368, current rewards: 24.31389, mean: 0.07843
[32m[0906 21-32-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10319, current rewards: 29.79629, mean: 0.08277
[32m[0906 21-32-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10277, current rewards: 35.27897, mean: 0.08605
[32m[0906 21-32-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10244, current rewards: 40.76456, mean: 0.08862
[32m[0906 21-32-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10217, current rewards: 46.24618, mean: 0.09068
[32m[0906 21-32-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10198, current rewards: 51.72663, mean: 0.09237
[32m[0906 21-32-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10181, current rewards: 57.39922, mean: 0.09410
[32m[0906 21-32-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10166, current rewards: 64.14164, mean: 0.09718
[32m[0906 21-32-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10157, current rewards: 69.67128, mean: 0.09813
[32m[0906 21-32-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10145, current rewards: 57.78663, mean: 0.07604
[32m[0906 21-33-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10135, current rewards: 63.70828, mean: 0.07865
[32m[0906 21-33-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10127, current rewards: 69.62868, mean: 0.08096
[32m[0906 21-33-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10121, current rewards: 75.54601, mean: 0.08302
[32m[0906 21-33-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10117, current rewards: 81.46672, mean: 0.08486
[32m[0906 21-33-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10115, current rewards: 87.39101, mean: 0.08653
[32m[0906 21-33-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10108, current rewards: 92.71864, mean: 0.08747
[32m[0906 21-33-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10104, current rewards: 98.61812, mean: 0.08885
[32m[0906 21-33-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10101, current rewards: 104.53479, mean: 0.09012
[32m[0906 21-33-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10099, current rewards: 100.58419, mean: 0.08313
[32m[0906 21-33-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10095, current rewards: 107.29762, mean: 0.08516
[32m[0906 21-33-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10094, current rewards: 114.00748, mean: 0.08703
[32m[0906 21-33-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10093, current rewards: 120.71733, mean: 0.08876
[32m[0906 21-34-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10089, current rewards: 127.42437, mean: 0.09037
[32m[0906 21-34-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10088, current rewards: 134.14183, mean: 0.09188
[32m[0906 21-34-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10098, current rewards: 119.02512, mean: 0.07882
[32m[0906 21-34-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10104, current rewards: 125.25760, mean: 0.08029
[32m[0906 21-34-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10108, current rewards: 131.43518, mean: 0.08164
[32m[0906 21-34-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10113, current rewards: 137.61633, mean: 0.08290
[32m[0906 21-34-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10119, current rewards: 143.79502, mean: 0.08409
[32m[0906 21-34-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10124, current rewards: 149.97707, mean: 0.08521
[32m[0906 21-34-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10131, current rewards: 101.16520, mean: 0.05589
[32m[0906 21-34-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10143, current rewards: 31.97844, mean: 0.01719
[32m[0906 21-34-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10148, current rewards: -29.76862, mean: -0.01559
[32m[0906 21-34-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10153, current rewards: -85.18017, mean: -0.04346
[32m[0906 21-35-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10155, current rewards: -132.13273, mean: -0.06574
[32m[0906 21-35-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10159, current rewards: -115.13784, mean: -0.05589
[32m[0906 21-35-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10166, current rewards: -98.69005, mean: -0.04677
[32m[0906 21-35-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10196, current rewards: -124.07671, mean: -0.05744
[32m[0906 21-35-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10203, current rewards: -116.22271, mean: -0.05259
[32m[0906 21-35-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10211, current rewards: -109.09533, mean: -0.04827
[32m[0906 21-35-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10219, current rewards: -102.42841, mean: -0.04434
[32m[0906 21-35-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10226, current rewards: -94.85322, mean: -0.04019
[32m[0906 21-35-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10233, current rewards: -87.28655, mean: -0.03622
[32m[0906 21-35-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10238, current rewards: -79.72112, mean: -0.03241
[32m[0906 21-35-56 @Agent.py:117][0m Average action selection time: 0.1024
[32m[0906 21-35-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-35-56 @MBExp.py:227][0m Rewards obtained: [-73.66098772621038], Lows: [192], Highs: [20], Total time: 21303.66197500001
[32m[0906 21-38-56 @MBExp.py:144][0m ####################################################################
[32m[0906 21-38-56 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 21-38-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10583, current rewards: -15.00000, mean: -1.50000
[32m[0906 21-39-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10488, current rewards: -28.27723, mean: -0.47129
[32m[0906 21-39-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10349, current rewards: -21.98747, mean: -0.19989
[32m[0906 21-39-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10214, current rewards: -15.68253, mean: -0.09802
[32m[0906 21-39-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10087, current rewards: -9.53934, mean: -0.04543
[32m[0906 21-39-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10014, current rewards: -3.11544, mean: -0.01198
[32m[0906 21-39-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09963, current rewards: 4.22582, mean: 0.01363
[32m[0906 21-39-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09889, current rewards: 11.55494, mean: 0.03210
[32m[0906 21-39-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09820, current rewards: 18.88732, mean: 0.04607
[32m[0906 21-39-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09773, current rewards: 26.21891, mean: 0.05700
[32m[0906 21-39-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09731, current rewards: 33.56585, mean: 0.06582
[32m[0906 21-39-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09697, current rewards: 40.92110, mean: 0.07307
[32m[0906 21-39-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09674, current rewards: 48.28780, mean: 0.07916
[32m[0906 21-39-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09651, current rewards: 55.68678, mean: 0.08437
[32m[0906 21-40-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09630, current rewards: 53.09446, mean: 0.07478
[32m[0906 21-40-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09612, current rewards: 59.60909, mean: 0.07843
[32m[0906 21-40-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09597, current rewards: 66.09461, mean: 0.08160
[32m[0906 21-40-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09584, current rewards: 72.58276, mean: 0.08440
[32m[0906 21-40-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09573, current rewards: 79.07612, mean: 0.08690
[32m[0906 21-40-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09563, current rewards: 85.57550, mean: 0.08914
[32m[0906 21-40-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09554, current rewards: 92.06357, mean: 0.09115
[32m[0906 21-40-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09544, current rewards: 99.99605, mean: 0.09434
[32m[0906 21-40-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09537, current rewards: 106.91393, mean: 0.09632
[32m[0906 21-40-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09530, current rewards: 97.16421, mean: 0.08376
[32m[0906 21-40-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09525, current rewards: 103.13231, mean: 0.08523
[32m[0906 21-40-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09520, current rewards: 108.20655, mean: 0.08588
[32m[0906 21-41-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09515, current rewards: 113.27811, mean: 0.08647
[32m[0906 21-41-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09512, current rewards: 118.34752, mean: 0.08702
[32m[0906 21-41-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09507, current rewards: 123.42458, mean: 0.08754
[32m[0906 21-41-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09503, current rewards: 128.92721, mean: 0.08831
[32m[0906 21-41-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09507, current rewards: 135.70613, mean: 0.08987
[32m[0906 21-41-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09514, current rewards: 141.47061, mean: 0.09069
[32m[0906 21-41-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09519, current rewards: 147.22752, mean: 0.09145
[32m[0906 21-41-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09526, current rewards: 152.98837, mean: 0.09216
[32m[0906 21-41-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09532, current rewards: 158.75003, mean: 0.09284
[32m[0906 21-41-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09539, current rewards: 164.51355, mean: 0.09347
[32m[0906 21-41-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09551, current rewards: 170.27156, mean: 0.09407
[32m[0906 21-41-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09563, current rewards: 176.03153, mean: 0.09464
[32m[0906 21-41-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09567, current rewards: 181.69437, mean: 0.09513
[32m[0906 21-42-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09572, current rewards: 187.42994, mean: 0.09563
[32m[0906 21-42-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09575, current rewards: 193.17471, mean: 0.09611
[32m[0906 21-42-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09580, current rewards: 198.90986, mean: 0.09656
[32m[0906 21-42-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09593, current rewards: 192.13598, mean: 0.09106
[32m[0906 21-42-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09612, current rewards: 199.04535, mean: 0.09215
[32m[0906 21-42-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09621, current rewards: 206.08922, mean: 0.09325
[32m[0906 21-42-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09630, current rewards: 213.09529, mean: 0.09429
[32m[0906 21-42-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09637, current rewards: 220.82322, mean: 0.09559
[32m[0906 21-42-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09645, current rewards: 227.55818, mean: 0.09642
[32m[0906 21-42-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09653, current rewards: 235.95302, mean: 0.09791
[32m[0906 21-42-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09659, current rewards: 243.17991, mean: 0.09885
[32m[0906 21-42-58 @Agent.py:117][0m Average action selection time: 0.0967
[32m[0906 21-42-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-42-58 @MBExp.py:227][0m Rewards obtained: [217.98947803053878], Lows: [44], Highs: [16], Total time: 21546.05167500001
[32m[0906 21-45-35 @MBExp.py:144][0m ####################################################################
[32m[0906 21-45-35 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 21-45-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09766, current rewards: -6.52328, mean: -0.65233
[32m[0906 21-45-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09023, current rewards: -3.70022, mean: -0.06167
[32m[0906 21-45-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08870, current rewards: 1.01755, mean: 0.00925
[32m[0906 21-45-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08814, current rewards: 5.73764, mean: 0.03586
[32m[0906 21-45-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08780, current rewards: 10.45751, mean: 0.04980
[32m[0906 21-45-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08778, current rewards: -23.79228, mean: -0.09151
[32m[0906 21-46-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08771, current rewards: -71.99874, mean: -0.23225
[32m[0906 21-46-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08751, current rewards: -75.73846, mean: -0.21038
[32m[0906 21-46-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08714, current rewards: -69.49954, mean: -0.16951
[32m[0906 21-46-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08685, current rewards: -63.26414, mean: -0.13753
[32m[0906 21-46-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08661, current rewards: -57.02847, mean: -0.11182
[32m[0906 21-46-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08641, current rewards: -50.78461, mean: -0.09069
[32m[0906 21-46-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08627, current rewards: -56.79035, mean: -0.09310
[32m[0906 21-46-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08616, current rewards: -51.44643, mean: -0.07795
[32m[0906 21-46-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08603, current rewards: -45.62453, mean: -0.06426
[32m[0906 21-46-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08593, current rewards: -39.75691, mean: -0.05231
[32m[0906 21-46-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08583, current rewards: -33.88697, mean: -0.04184
[32m[0906 21-46-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08575, current rewards: -28.02348, mean: -0.03259
[32m[0906 21-46-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08569, current rewards: -22.15698, mean: -0.02435
[32m[0906 21-46-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08564, current rewards: -16.29068, mean: -0.01697
[32m[0906 21-47-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08561, current rewards: -10.42504, mean: -0.01032
[32m[0906 21-47-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08555, current rewards: -4.55829, mean: -0.00430
[32m[0906 21-47-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08552, current rewards: 1.30913, mean: 0.00118
[32m[0906 21-47-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08549, current rewards: -12.56425, mean: -0.01083
[32m[0906 21-47-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08544, current rewards: -6.98155, mean: -0.00577
[32m[0906 21-47-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08540, current rewards: -1.26278, mean: -0.00100
[32m[0906 21-47-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08538, current rewards: 4.46271, mean: 0.00341
[32m[0906 21-47-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08535, current rewards: 10.18759, mean: 0.00749
[32m[0906 21-47-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08532, current rewards: 15.90863, mean: 0.01128
[32m[0906 21-47-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08531, current rewards: 21.64714, mean: 0.01483
[32m[0906 21-47-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08530, current rewards: 27.42725, mean: 0.01816
[32m[0906 21-47-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08536, current rewards: 33.15037, mean: 0.02125
[32m[0906 21-47-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08542, current rewards: 38.86834, mean: 0.02414
[32m[0906 21-47-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08546, current rewards: 44.58771, mean: 0.02686
[32m[0906 21-48-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08550, current rewards: 50.31204, mean: 0.02942
[32m[0906 21-48-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08554, current rewards: 56.04050, mean: 0.03184
[32m[0906 21-48-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08565, current rewards: 61.76497, mean: 0.03412
[32m[0906 21-48-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08576, current rewards: 67.48955, mean: 0.03628
[32m[0906 21-48-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08578, current rewards: 74.49440, mean: 0.03900
[32m[0906 21-48-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08582, current rewards: 80.17751, mean: 0.04091
[32m[0906 21-48-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08586, current rewards: 59.54673, mean: 0.02963
[32m[0906 21-48-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08590, current rewards: 34.03886, mean: 0.01652
[32m[0906 21-48-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08595, current rewards: 44.21812, mean: 0.02096
[32m[0906 21-48-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08604, current rewards: 54.41561, mean: 0.02519
[32m[0906 21-48-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08612, current rewards: 64.62290, mean: 0.02924
[32m[0906 21-48-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08621, current rewards: 74.83772, mean: 0.03311
[32m[0906 21-48-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08628, current rewards: 84.60806, mean: 0.03663
[32m[0906 21-48-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08641, current rewards: 50.03967, mean: 0.02120
[32m[0906 21-49-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08647, current rewards: 49.43513, mean: 0.02051
[32m[0906 21-49-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08654, current rewards: 56.77116, mean: 0.02308
[32m[0906 21-49-12 @Agent.py:117][0m Average action selection time: 0.0866
[32m[0906 21-49-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-49-12 @MBExp.py:227][0m Rewards obtained: [62.64448499086176], Lows: [118], Highs: [21], Total time: 21763.21885000001
[32m[0906 21-51-42 @MBExp.py:144][0m ####################################################################
[32m[0906 21-51-42 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 21-51-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08962, current rewards: -7.44078, mean: -0.74408
[32m[0906 21-51-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08920, current rewards: -5.90200, mean: -0.09837
[32m[0906 21-51-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08807, current rewards: -0.38825, mean: -0.00353
[32m[0906 21-51-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08770, current rewards: 5.12152, mean: 0.03201
[32m[0906 21-52-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08744, current rewards: 10.48464, mean: 0.04993
[32m[0906 21-52-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08740, current rewards: 15.78477, mean: 0.06071
[32m[0906 21-52-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08729, current rewards: 21.29213, mean: 0.06868
[32m[0906 21-52-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08725, current rewards: 26.79380, mean: 0.07443
[32m[0906 21-52-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08691, current rewards: 32.29749, mean: 0.07877
[32m[0906 21-52-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08670, current rewards: 37.63789, mean: 0.08182
[32m[0906 21-52-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08647, current rewards: 43.99497, mean: 0.08626
[32m[0906 21-52-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08631, current rewards: 49.84377, mean: 0.08901
[32m[0906 21-52-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08617, current rewards: 55.70091, mean: 0.09131
[32m[0906 21-52-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08607, current rewards: 61.55483, mean: 0.09326
[32m[0906 21-52-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08597, current rewards: 67.42078, mean: 0.09496
[32m[0906 21-52-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08587, current rewards: 73.27531, mean: 0.09641
[32m[0906 21-52-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08578, current rewards: 79.13430, mean: 0.09770
[32m[0906 21-52-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08573, current rewards: 84.99758, mean: 0.09883
[32m[0906 21-53-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08567, current rewards: 90.85915, mean: 0.09985
[32m[0906 21-53-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08561, current rewards: 96.71704, mean: 0.10075
[32m[0906 21-53-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08558, current rewards: 90.82033, mean: 0.08992
[32m[0906 21-53-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08553, current rewards: 96.20301, mean: 0.09076
[32m[0906 21-53-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08548, current rewards: 101.74384, mean: 0.09166
[32m[0906 21-53-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08546, current rewards: 107.28438, mean: 0.09249
[32m[0906 21-53-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08541, current rewards: 112.82330, mean: 0.09324
[32m[0906 21-53-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08538, current rewards: 118.36196, mean: 0.09394
[32m[0906 21-53-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08536, current rewards: 123.89785, mean: 0.09458
[32m[0906 21-53-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08533, current rewards: 129.43831, mean: 0.09518
[32m[0906 21-53-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08532, current rewards: 134.97780, mean: 0.09573
[32m[0906 21-53-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08530, current rewards: 138.54164, mean: 0.09489
[32m[0906 21-53-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08528, current rewards: 144.09629, mean: 0.09543
[32m[0906 21-53-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08530, current rewards: 149.64855, mean: 0.09593
[32m[0906 21-54-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08535, current rewards: 155.20590, mean: 0.09640
[32m[0906 21-54-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08541, current rewards: 160.75351, mean: 0.09684
[32m[0906 21-54-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08547, current rewards: 166.30830, mean: 0.09726
[32m[0906 21-54-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08551, current rewards: 171.86485, mean: 0.09765
[32m[0906 21-54-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08557, current rewards: 177.41844, mean: 0.09802
[32m[0906 21-54-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08569, current rewards: 183.59548, mean: 0.09871
[32m[0906 21-54-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08577, current rewards: 189.16877, mean: 0.09904
[32m[0906 21-54-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08581, current rewards: 194.74203, mean: 0.09936
[32m[0906 21-54-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08586, current rewards: 200.31965, mean: 0.09966
[32m[0906 21-54-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08588, current rewards: 188.12721, mean: 0.09132
[32m[0906 21-54-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08591, current rewards: 194.89907, mean: 0.09237
[32m[0906 21-54-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08599, current rewards: 201.67131, mean: 0.09337
[32m[0906 21-54-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08608, current rewards: 202.61104, mean: 0.09168
[32m[0906 21-54-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08615, current rewards: 212.54582, mean: 0.09405
[32m[0906 21-55-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08622, current rewards: 219.81773, mean: 0.09516
[32m[0906 21-55-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08630, current rewards: 228.76637, mean: 0.09693
[32m[0906 21-55-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08638, current rewards: 237.70754, mean: 0.09863
[32m[0906 21-55-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08645, current rewards: 246.65568, mean: 0.10027
[32m[0906 21-55-19 @Agent.py:117][0m Average action selection time: 0.0865
[32m[0906 21-55-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-55-19 @MBExp.py:227][0m Rewards obtained: [253.8061204319323], Lows: [18], Highs: [12], Total time: 21980.16858200001
[32m[0906 21-57-52 @MBExp.py:144][0m ####################################################################
[32m[0906 21-57-52 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 21-57-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08908, current rewards: -13.00000, mean: -1.30000
[32m[0906 21-57-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08944, current rewards: -13.98915, mean: -0.23315
[32m[0906 21-58-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08818, current rewards: -8.71550, mean: -0.07923
[32m[0906 21-58-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08770, current rewards: -3.44087, mean: -0.02151
[32m[0906 21-58-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08757, current rewards: 1.83396, mean: 0.00873
[32m[0906 21-58-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08746, current rewards: 7.11054, mean: 0.02735
[32m[0906 21-58-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08734, current rewards: 12.38681, mean: 0.03996
[32m[0906 21-58-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08730, current rewards: 17.66156, mean: 0.04906
[32m[0906 21-58-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08707, current rewards: 9.99764, mean: 0.02438
[32m[0906 21-58-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08678, current rewards: 14.26568, mean: 0.03101
[32m[0906 21-58-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08659, current rewards: 18.49073, mean: 0.03626
[32m[0906 21-58-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08640, current rewards: 22.71743, mean: 0.04057
[32m[0906 21-58-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08624, current rewards: 26.96743, mean: 0.04421
[32m[0906 21-58-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08610, current rewards: 31.17911, mean: 0.04724
[32m[0906 21-58-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08602, current rewards: 35.39202, mean: 0.04985
[32m[0906 21-58-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08590, current rewards: 39.60511, mean: 0.05211
[32m[0906 21-59-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08583, current rewards: 43.81722, mean: 0.05410
[32m[0906 21-59-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08577, current rewards: 48.02954, mean: 0.05585
[32m[0906 21-59-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08569, current rewards: 52.24213, mean: 0.05741
[32m[0906 21-59-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08564, current rewards: 49.92722, mean: 0.05201
[32m[0906 21-59-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08614, current rewards: -5.17901, mean: -0.00513
[32m[0906 21-59-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08634, current rewards: -21.41202, mean: -0.02020
[32m[0906 21-59-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08638, current rewards: -64.74850, mean: -0.05833
[32m[0906 21-59-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08661, current rewards: -124.61420, mean: -0.10743
[32m[0906 21-59-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08682, current rewards: -174.07150, mean: -0.14386
[32m[0906 21-59-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08712, current rewards: -233.22240, mean: -0.18510
[32m[0906 21-59-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08702, current rewards: -298.65955, mean: -0.22798
[32m[0906 21-59-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08717, current rewards: -356.42691, mean: -0.26208
[32m[0906 21-59-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08719, current rewards: -419.49341, mean: -0.29751
[32m[0906 21-59-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08724, current rewards: -494.39291, mean: -0.33863
[32m[0906 22-00-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08734, current rewards: -550.26314, mean: -0.36441
[32m[0906 22-00-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08731, current rewards: -548.01640, mean: -0.35129
[32m[0906 22-00-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08731, current rewards: -541.56311, mean: -0.33637
[32m[0906 22-00-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08729, current rewards: -535.11937, mean: -0.32236
[32m[0906 22-00-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08728, current rewards: -528.68210, mean: -0.30917
[32m[0906 22-00-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08727, current rewards: -522.23263, mean: -0.29672
[32m[0906 22-00-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08730, current rewards: -515.75206, mean: -0.28495
[32m[0906 22-00-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08737, current rewards: -509.08754, mean: -0.27370
[32m[0906 22-00-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08743, current rewards: -502.74332, mean: -0.26322
[32m[0906 22-00-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08762, current rewards: -534.56138, mean: -0.27274
[32m[0906 22-00-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08761, current rewards: -527.32001, mean: -0.26235
[32m[0906 22-00-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08760, current rewards: -519.80344, mean: -0.25233
[32m[0906 22-00-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08759, current rewards: -512.34949, mean: -0.24282
[32m[0906 22-01-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08764, current rewards: -504.93753, mean: -0.23377
[32m[0906 22-01-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08769, current rewards: -497.42435, mean: -0.22508
[32m[0906 22-01-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08774, current rewards: -490.23152, mean: -0.21692
[32m[0906 22-01-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08778, current rewards: -482.64350, mean: -0.20894
[32m[0906 22-01-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08782, current rewards: -475.10509, mean: -0.20132
[32m[0906 22-01-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08787, current rewards: -468.20593, mean: -0.19428
[32m[0906 22-01-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08792, current rewards: -461.67022, mean: -0.18767
[32m[0906 22-01-32 @Agent.py:117][0m Average action selection time: 0.0880
[32m[0906 22-01-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-01-32 @MBExp.py:227][0m Rewards obtained: [-456.8143422596967], Lows: [348], Highs: [22], Total time: 22200.79617700001
[32m[0906 22-04-06 @MBExp.py:144][0m ####################################################################
[32m[0906 22-04-06 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 22-04-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08874, current rewards: -14.00000, mean: -1.40000
[32m[0906 22-04-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08908, current rewards: -94.34639, mean: -1.57244
[32m[0906 22-04-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08932, current rewards: -162.97515, mean: -1.48159
[32m[0906 22-04-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08859, current rewards: -240.14941, mean: -1.50093
[32m[0906 22-04-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08832, current rewards: -315.23684, mean: -1.50113
[32m[0906 22-04-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08814, current rewards: -373.62232, mean: -1.43701
[32m[0906 22-04-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08795, current rewards: -369.08878, mean: -1.19061
[32m[0906 22-04-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08768, current rewards: -364.55013, mean: -1.01264
[32m[0906 22-04-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08730, current rewards: -366.28129, mean: -0.89337
[32m[0906 22-04-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08804, current rewards: -409.97859, mean: -0.89126
[32m[0906 22-04-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08868, current rewards: -467.60947, mean: -0.91688
[32m[0906 22-04-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08831, current rewards: -459.14970, mean: -0.81991
[32m[0906 22-05-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08802, current rewards: -453.56608, mean: -0.74355
[32m[0906 22-05-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08865, current rewards: -495.55257, mean: -0.75084
[32m[0906 22-05-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08916, current rewards: -550.90729, mean: -0.77593
[32m[0906 22-05-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08969, current rewards: -612.36463, mean: -0.80574
[32m[0906 22-05-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09006, current rewards: -675.46021, mean: -0.83390
[32m[0906 22-05-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09005, current rewards: -724.91472, mean: -0.84292
[32m[0906 22-05-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08975, current rewards: -734.42896, mean: -0.80706
[32m[0906 22-05-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08948, current rewards: -727.30669, mean: -0.75761
[32m[0906 22-05-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08926, current rewards: -720.92972, mean: -0.71379
[32m[0906 22-05-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08904, current rewards: -714.64368, mean: -0.67419
[32m[0906 22-05-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08884, current rewards: -708.45176, mean: -0.63824
[32m[0906 22-05-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08867, current rewards: -702.24671, mean: -0.60539
[32m[0906 22-05-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08851, current rewards: -697.26622, mean: -0.57625
[32m[0906 22-05-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08838, current rewards: -692.84809, mean: -0.54988
[32m[0906 22-06-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08824, current rewards: -688.43500, mean: -0.52552
[32m[0906 22-06-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08811, current rewards: -684.02253, mean: -0.50296
[32m[0906 22-06-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08800, current rewards: -679.65332, mean: -0.48202
[32m[0906 22-06-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08788, current rewards: -675.22831, mean: -0.46249
[32m[0906 22-06-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08778, current rewards: -670.80832, mean: -0.44424
[32m[0906 22-06-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08789, current rewards: -702.09711, mean: -0.45006
[32m[0906 22-06-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08795, current rewards: -769.11615, mean: -0.47771
[32m[0906 22-06-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08800, current rewards: -821.90114, mean: -0.49512
[32m[0906 22-06-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08798, current rewards: -814.70602, mean: -0.47644
[32m[0906 22-06-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08795, current rewards: -807.78674, mean: -0.45897
[32m[0906 22-06-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08799, current rewards: -800.47334, mean: -0.44225
[32m[0906 22-06-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08803, current rewards: -792.89333, mean: -0.42629
[32m[0906 22-06-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08808, current rewards: -785.35345, mean: -0.41118
[32m[0906 22-06-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08806, current rewards: -798.19184, mean: -0.40724
[32m[0906 22-07-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08804, current rewards: -792.98839, mean: -0.39452
[32m[0906 22-07-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08802, current rewards: -787.77814, mean: -0.38242
[32m[0906 22-07-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08802, current rewards: -782.56727, mean: -0.37088
[32m[0906 22-07-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08806, current rewards: -777.35734, mean: -0.35989
[32m[0906 22-07-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08810, current rewards: -772.43639, mean: -0.34952
[32m[0906 22-07-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08813, current rewards: -767.10238, mean: -0.33943
[32m[0906 22-07-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08817, current rewards: -761.76926, mean: -0.32977
[32m[0906 22-07-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08821, current rewards: -760.86170, mean: -0.32240
[32m[0906 22-07-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08826, current rewards: -819.33048, mean: -0.33997
[32m[0906 22-07-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08828, current rewards: -817.90884, mean: -0.33248
[32m[0906 22-07-47 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0906 22-07-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-07-47 @MBExp.py:227][0m Rewards obtained: [-813.1128709863881], Lows: [505], Highs: [50], Total time: 22422.288101000013
[32m[0906 22-10-23 @MBExp.py:144][0m ####################################################################
[32m[0906 22-10-23 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 22-10-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08569, current rewards: -14.00000, mean: -1.40000
[32m[0906 22-10-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08654, current rewards: -11.63157, mean: -0.19386
[32m[0906 22-10-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08669, current rewards: -5.85360, mean: -0.05321
[32m[0906 22-10-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08684, current rewards: -0.36475, mean: -0.00228
[32m[0906 22-10-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08689, current rewards: 5.40438, mean: 0.02574
[32m[0906 22-10-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08686, current rewards: 11.17534, mean: 0.04298
[32m[0906 22-10-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08690, current rewards: 16.94435, mean: 0.05466
[32m[0906 22-10-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08658, current rewards: 22.70957, mean: 0.06308
[32m[0906 22-10-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08637, current rewards: 28.48503, mean: 0.06948
[32m[0906 22-11-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08618, current rewards: 34.25044, mean: 0.07446
[32m[0906 22-11-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08604, current rewards: 40.02689, mean: 0.07848
[32m[0906 22-11-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08594, current rewards: 45.99687, mean: 0.08214
[32m[0906 22-11-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08582, current rewards: 52.26325, mean: 0.08568
[32m[0906 22-11-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08573, current rewards: 57.96397, mean: 0.08782
[32m[0906 22-11-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08562, current rewards: 63.66454, mean: 0.08967
[32m[0906 22-11-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08553, current rewards: 69.35154, mean: 0.09125
[32m[0906 22-11-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08546, current rewards: 75.05535, mean: 0.09266
[32m[0906 22-11-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08539, current rewards: 80.75902, mean: 0.09391
[32m[0906 22-11-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08536, current rewards: 86.44838, mean: 0.09500
[32m[0906 22-11-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08532, current rewards: 91.99913, mean: 0.09583
[32m[0906 22-11-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08528, current rewards: 97.74262, mean: 0.09677
[32m[0906 22-11-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08524, current rewards: 103.49258, mean: 0.09763
[32m[0906 22-11-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08521, current rewards: 109.23431, mean: 0.09841
[32m[0906 22-12-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08518, current rewards: 104.15913, mean: 0.08979
[32m[0906 22-12-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08516, current rewards: 109.55910, mean: 0.09054
[32m[0906 22-12-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08515, current rewards: 114.95942, mean: 0.09124
[32m[0906 22-12-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08513, current rewards: 120.36569, mean: 0.09188
[32m[0906 22-12-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08511, current rewards: 126.19698, mean: 0.09279
[32m[0906 22-12-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08511, current rewards: 131.61770, mean: 0.09335
[32m[0906 22-12-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08508, current rewards: 137.04009, mean: 0.09386
[32m[0906 22-12-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08507, current rewards: 142.46149, mean: 0.09435
[32m[0906 22-12-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08509, current rewards: 147.88160, mean: 0.09480
[32m[0906 22-12-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08514, current rewards: 141.17034, mean: 0.08768
[32m[0906 22-12-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08520, current rewards: 148.05930, mean: 0.08919
[32m[0906 22-12-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08525, current rewards: 154.94587, mean: 0.09061
[32m[0906 22-12-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08531, current rewards: 162.91247, mean: 0.09256
[32m[0906 22-12-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08536, current rewards: 170.01486, mean: 0.09393
[32m[0906 22-13-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08547, current rewards: 176.49126, mean: 0.09489
[32m[0906 22-13-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08558, current rewards: 182.96732, mean: 0.09579
[32m[0906 22-13-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08562, current rewards: 168.04644, mean: 0.08574
[32m[0906 22-13-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08566, current rewards: 173.42378, mean: 0.08628
[32m[0906 22-13-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08570, current rewards: 178.80054, mean: 0.08680
[32m[0906 22-13-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08574, current rewards: 184.18357, mean: 0.08729
[32m[0906 22-13-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08582, current rewards: 164.36119, mean: 0.07609
[32m[0906 22-13-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08590, current rewards: 168.19883, mean: 0.07611
[32m[0906 22-13-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08600, current rewards: 172.11832, mean: 0.07616
[32m[0906 22-13-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08608, current rewards: 176.03568, mean: 0.07621
[32m[0906 22-13-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08616, current rewards: 179.95414, mean: 0.07625
[32m[0906 22-13-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08623, current rewards: 183.87473, mean: 0.07630
[32m[0906 22-13-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08631, current rewards: 187.79304, mean: 0.07634
[32m[0906 22-13-59 @Agent.py:117][0m Average action selection time: 0.0864
[32m[0906 22-13-59 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-14-00 @MBExp.py:227][0m Rewards obtained: [190.92766623011096], Lows: [36], Highs: [13], Total time: 22638.93987700001
[32m[0906 22-16-37 @MBExp.py:144][0m ####################################################################
[32m[0906 22-16-37 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 22-16-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11255, current rewards: -8.67176, mean: -0.86718
[32m[0906 22-16-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10989, current rewards: -56.93635, mean: -0.94894
[32m[0906 22-16-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10109, current rewards: -83.10668, mean: -0.75552
[32m[0906 22-16-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09660, current rewards: -77.75934, mean: -0.48600
[32m[0906 22-16-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09426, current rewards: -72.40421, mean: -0.34478
[32m[0906 22-17-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09280, current rewards: -67.05398, mean: -0.25790
[32m[0906 22-17-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09185, current rewards: -61.70447, mean: -0.19905
[32m[0906 22-17-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09084, current rewards: -56.35837, mean: -0.15655
[32m[0906 22-17-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09009, current rewards: -60.87448, mean: -0.14847
[32m[0906 22-17-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08955, current rewards: -64.76896, mean: -0.14080
[32m[0906 22-17-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08904, current rewards: -78.18141, mean: -0.15330
[32m[0906 22-17-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08865, current rewards: -87.35875, mean: -0.15600
[32m[0906 22-17-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08831, current rewards: -99.96393, mean: -0.16388
[32m[0906 22-17-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08802, current rewards: -110.72714, mean: -0.16777
[32m[0906 22-17-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08867, current rewards: -126.89279, mean: -0.17872
[32m[0906 22-17-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08840, current rewards: -121.45974, mean: -0.15982
[32m[0906 22-17-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08819, current rewards: -116.02481, mean: -0.14324
[32m[0906 22-17-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08799, current rewards: -110.59153, mean: -0.12859
[32m[0906 22-17-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08780, current rewards: -105.33860, mean: -0.11576
[32m[0906 22-18-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08766, current rewards: -100.02621, mean: -0.10419
[32m[0906 22-18-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08752, current rewards: -94.63812, mean: -0.09370
[32m[0906 22-18-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08736, current rewards: -89.25044, mean: -0.08420
[32m[0906 22-18-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08724, current rewards: -93.74771, mean: -0.08446
[32m[0906 22-18-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08713, current rewards: -88.09001, mean: -0.07594
[32m[0906 22-18-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08706, current rewards: -82.43669, mean: -0.06813
[32m[0906 22-18-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08698, current rewards: -76.77996, mean: -0.06094
[32m[0906 22-18-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08690, current rewards: -71.12776, mean: -0.05430
[32m[0906 22-18-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08682, current rewards: -65.06199, mean: -0.04784
[32m[0906 22-18-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08675, current rewards: -59.47835, mean: -0.04218
[32m[0906 22-18-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08667, current rewards: -53.89670, mean: -0.03692
[32m[0906 22-18-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08661, current rewards: -48.31464, mean: -0.03200
[32m[0906 22-18-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08654, current rewards: -42.73438, mean: -0.02739
[32m[0906 22-18-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08652, current rewards: -37.15622, mean: -0.02308
[32m[0906 22-19-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08654, current rewards: -31.57583, mean: -0.01902
[32m[0906 22-19-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08656, current rewards: -30.85397, mean: -0.01804
[32m[0906 22-19-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08657, current rewards: -23.55709, mean: -0.01338
[32m[0906 22-19-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08659, current rewards: -17.36446, mean: -0.00959
[32m[0906 22-19-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08668, current rewards: -11.17202, mean: -0.00601
[32m[0906 22-19-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08677, current rewards: -4.97764, mean: -0.00261
[32m[0906 22-19-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08678, current rewards: 1.21771, mean: 0.00062
[32m[0906 22-19-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08679, current rewards: 7.41062, mean: 0.00369
[32m[0906 22-19-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08680, current rewards: 8.15539, mean: 0.00396
[32m[0906 22-19-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08680, current rewards: 14.28311, mean: 0.00677
[32m[0906 22-19-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08684, current rewards: 19.85324, mean: 0.00919
[32m[0906 22-19-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08691, current rewards: 26.11944, mean: 0.01182
[32m[0906 22-19-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08698, current rewards: 32.55667, mean: 0.01441
[32m[0906 22-19-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08705, current rewards: 38.98855, mean: 0.01688
[32m[0906 22-20-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08710, current rewards: 45.42902, mean: 0.01925
[32m[0906 22-20-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08716, current rewards: 51.85930, mean: 0.02152
[32m[0906 22-20-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08722, current rewards: 58.29439, mean: 0.02370
[32m[0906 22-20-16 @Agent.py:117][0m Average action selection time: 0.0873
[32m[0906 22-20-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-20-16 @MBExp.py:227][0m Rewards obtained: [48.35988056058892], Lows: [119], Highs: [22], Total time: 22858.01059300001
[32m[0906 22-22-55 @MBExp.py:144][0m ####################################################################
[32m[0906 22-22-55 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 22-22-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09210, current rewards: -14.00000, mean: -1.40000
[32m[0906 22-23-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08776, current rewards: -55.54888, mean: -0.92581
[32m[0906 22-23-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08739, current rewards: -113.39991, mean: -1.03091
[32m[0906 22-23-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08724, current rewards: -166.20590, mean: -1.03879
[32m[0906 22-23-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08718, current rewards: -215.24392, mean: -1.02497
[32m[0906 22-23-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08721, current rewards: -266.22559, mean: -1.02394
[32m[0906 22-23-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08717, current rewards: -310.11290, mean: -1.00036
[32m[0906 22-23-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08679, current rewards: -300.33470, mean: -0.83426
[32m[0906 22-23-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08654, current rewards: -290.55128, mean: -0.70866
[32m[0906 22-23-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08632, current rewards: -280.77852, mean: -0.61039
[32m[0906 22-23-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08614, current rewards: -271.42545, mean: -0.53221
[32m[0906 22-23-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08598, current rewards: -261.46062, mean: -0.46689
[32m[0906 22-23-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08587, current rewards: -251.50981, mean: -0.41231
[32m[0906 22-23-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08576, current rewards: -280.78023, mean: -0.42542
[32m[0906 22-23-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08580, current rewards: -337.26316, mean: -0.47502
[32m[0906 22-24-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08571, current rewards: -398.83648, mean: -0.52478
[32m[0906 22-24-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08572, current rewards: -455.54798, mean: -0.56240
[32m[0906 22-24-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08567, current rewards: -516.24740, mean: -0.60029
[32m[0906 22-24-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08576, current rewards: -576.60278, mean: -0.63363
[32m[0906 22-24-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08575, current rewards: -641.70567, mean: -0.66844
[32m[0906 22-24-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08577, current rewards: -694.75013, mean: -0.68787
[32m[0906 22-24-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08577, current rewards: -755.74421, mean: -0.71297
[32m[0906 22-24-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08588, current rewards: -812.70785, mean: -0.73217
[32m[0906 22-24-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08585, current rewards: -865.42244, mean: -0.74605
[32m[0906 22-24-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08585, current rewards: -916.16278, mean: -0.75716
[32m[0906 22-24-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08582, current rewards: -970.36442, mean: -0.77013
[32m[0906 22-24-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08578, current rewards: -963.46508, mean: -0.73547
[32m[0906 22-24-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08575, current rewards: -957.22829, mean: -0.70384
[32m[0906 22-24-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08570, current rewards: -950.98796, mean: -0.67446
[32m[0906 22-25-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08565, current rewards: -944.75374, mean: -0.64709
[32m[0906 22-25-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08562, current rewards: -938.51352, mean: -0.62153
[32m[0906 22-25-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08560, current rewards: -932.28409, mean: -0.59762
[32m[0906 22-25-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08559, current rewards: -926.05614, mean: -0.57519
[32m[0906 22-25-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08564, current rewards: -919.82120, mean: -0.55411
[32m[0906 22-25-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08567, current rewards: -913.68485, mean: -0.53432
[32m[0906 22-25-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08571, current rewards: -907.80158, mean: -0.51580
[32m[0906 22-25-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08574, current rewards: -901.61851, mean: -0.49813
[32m[0906 22-25-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08584, current rewards: -895.43355, mean: -0.48142
[32m[0906 22-25-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08596, current rewards: -918.47931, mean: -0.48088
[32m[0906 22-25-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08599, current rewards: -910.97366, mean: -0.46478
[32m[0906 22-25-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08602, current rewards: -904.68323, mean: -0.45009
[32m[0906 22-25-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08605, current rewards: -898.40034, mean: -0.43612
[32m[0906 22-25-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08608, current rewards: -892.12800, mean: -0.42281
[32m[0906 22-26-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08610, current rewards: -886.00023, mean: -0.41019
[32m[0906 22-26-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08618, current rewards: -879.75353, mean: -0.39808
[32m[0906 22-26-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08626, current rewards: -873.51833, mean: -0.38651
[32m[0906 22-26-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08634, current rewards: -867.27186, mean: -0.37544
[32m[0906 22-26-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08641, current rewards: -861.02777, mean: -0.36484
[32m[0906 22-26-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08648, current rewards: -868.12999, mean: -0.36022
[32m[0906 22-26-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08655, current rewards: -861.93227, mean: -0.35038
[32m[0906 22-26-33 @Agent.py:117][0m Average action selection time: 0.0866
[32m[0906 22-26-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-26-33 @MBExp.py:227][0m Rewards obtained: [-857.1184984362562], Lows: [586], Highs: [15], Total time: 23075.22985800001
[32m[0906 22-29-28 @MBExp.py:144][0m ####################################################################
[32m[0906 22-29-28 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 22-29-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09565, current rewards: -4.52759, mean: -0.45276
[32m[0906 22-29-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09647, current rewards: 2.15406, mean: 0.03590
[32m[0906 22-29-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09646, current rewards: 9.73204, mean: 0.08847
[32m[0906 22-29-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09647, current rewards: 16.42318, mean: 0.10264
[32m[0906 22-29-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09658, current rewards: 23.11517, mean: 0.11007
[32m[0906 22-29-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09664, current rewards: 29.79800, mean: 0.11461
[32m[0906 22-29-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09671, current rewards: 22.55197, mean: 0.07275
[32m[0906 22-30-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09640, current rewards: 29.48665, mean: 0.08191
[32m[0906 22-30-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09610, current rewards: 35.86090, mean: 0.08747
[32m[0906 22-30-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09589, current rewards: 42.23550, mean: 0.09182
[32m[0906 22-30-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09568, current rewards: 49.03153, mean: 0.09614
[32m[0906 22-30-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09551, current rewards: 55.44899, mean: 0.09902
[32m[0906 22-30-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09536, current rewards: 61.86649, mean: 0.10142
[32m[0906 22-30-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09524, current rewards: 68.28428, mean: 0.10346
[32m[0906 22-30-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09515, current rewards: 74.70134, mean: 0.10521
[32m[0906 22-30-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09504, current rewards: 73.51152, mean: 0.09673
[32m[0906 22-30-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09496, current rewards: 68.53988, mean: 0.08462
[32m[0906 22-30-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09489, current rewards: 72.17992, mean: 0.08393
[32m[0906 22-30-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09482, current rewards: 75.82093, mean: 0.08332
[32m[0906 22-30-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09478, current rewards: 79.46013, mean: 0.08277
[32m[0906 22-31-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09472, current rewards: 73.05971, mean: 0.07234
[32m[0906 22-31-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09468, current rewards: 80.21926, mean: 0.07568
[32m[0906 22-31-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09462, current rewards: 87.38263, mean: 0.07872
[32m[0906 22-31-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09458, current rewards: 94.55402, mean: 0.08151
[32m[0906 22-31-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09454, current rewards: 101.72282, mean: 0.08407
[32m[0906 22-31-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09453, current rewards: 108.88231, mean: 0.08641
[32m[0906 22-31-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09449, current rewards: 115.68423, mean: 0.08831
[32m[0906 22-31-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09447, current rewards: 122.62072, mean: 0.09016
[32m[0906 22-31-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09444, current rewards: 129.55381, mean: 0.09188
[32m[0906 22-31-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09441, current rewards: 136.49300, mean: 0.09349
[32m[0906 22-31-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09437, current rewards: 137.36954, mean: 0.09097
[32m[0906 22-31-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09435, current rewards: 143.46694, mean: 0.09197
[32m[0906 22-32-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09434, current rewards: 149.56385, mean: 0.09290
[32m[0906 22-32-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09435, current rewards: 155.66040, mean: 0.09377
[32m[0906 22-32-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09443, current rewards: 161.11988, mean: 0.09422
[32m[0906 22-32-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09450, current rewards: 167.07374, mean: 0.09493
[32m[0906 22-32-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09456, current rewards: 173.02633, mean: 0.09559
[32m[0906 22-32-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09463, current rewards: 178.97997, mean: 0.09623
[32m[0906 22-32-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09477, current rewards: 184.92778, mean: 0.09682
[32m[0906 22-32-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09482, current rewards: 190.87801, mean: 0.09739
[32m[0906 22-32-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09488, current rewards: 196.83303, mean: 0.09793
[32m[0906 22-32-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09493, current rewards: 202.78966, mean: 0.09844
[32m[0906 22-32-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09497, current rewards: 208.80584, mean: 0.09896
[32m[0906 22-32-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09502, current rewards: 214.41537, mean: 0.09927
[32m[0906 22-32-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09507, current rewards: 219.96753, mean: 0.09953
[32m[0906 22-33-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09518, current rewards: 225.51374, mean: 0.09978
[32m[0906 22-33-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09528, current rewards: 231.06163, mean: 0.10003
[32m[0906 22-33-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09539, current rewards: 236.60769, mean: 0.10026
[32m[0906 22-33-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09548, current rewards: 242.15962, mean: 0.10048
[32m[0906 22-33-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09558, current rewards: 247.70509, mean: 0.10069
[32m[0906 22-33-27 @Agent.py:117][0m Average action selection time: 0.0955
[32m[0906 22-33-27 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-33-28 @MBExp.py:227][0m Rewards obtained: [252.13858647825012], Lows: [20], Highs: [17], Total time: 23314.80266100001
[32m[0906 22-36-11 @MBExp.py:144][0m ####################################################################
[32m[0906 22-36-11 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 22-36-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10341, current rewards: -7.88357, mean: -0.78836
[32m[0906 22-36-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08989, current rewards: -4.01267, mean: -0.06688
[32m[0906 22-36-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08859, current rewards: 1.38110, mean: 0.01256
[32m[0906 22-36-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08803, current rewards: 6.77351, mean: 0.04233
[32m[0906 22-36-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08777, current rewards: 12.16553, mean: 0.05793
[32m[0906 22-36-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08767, current rewards: 17.56070, mean: 0.06754
[32m[0906 22-36-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08758, current rewards: 22.95764, mean: 0.07406
[32m[0906 22-36-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08731, current rewards: 28.35177, mean: 0.07875
[32m[0906 22-36-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08694, current rewards: 33.74932, mean: 0.08232
[32m[0906 22-36-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08668, current rewards: 40.24799, mean: 0.08750
[32m[0906 22-36-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08643, current rewards: 45.64486, mean: 0.08950
[32m[0906 22-36-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08626, current rewards: 51.03488, mean: 0.09113
[32m[0906 22-37-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08613, current rewards: 56.42635, mean: 0.09250
[32m[0906 22-37-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08601, current rewards: 53.58312, mean: 0.08119
[32m[0906 22-37-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08592, current rewards: 59.25096, mean: 0.08345
[32m[0906 22-37-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08581, current rewards: 64.91402, mean: 0.08541
[32m[0906 22-37-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08575, current rewards: 64.88578, mean: 0.08011
[32m[0906 22-37-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08570, current rewards: 71.28264, mean: 0.08289
[32m[0906 22-37-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08564, current rewards: 77.40387, mean: 0.08506
[32m[0906 22-37-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08559, current rewards: 83.66393, mean: 0.08715
[32m[0906 22-37-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08556, current rewards: 89.92220, mean: 0.08903
[32m[0906 22-37-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08553, current rewards: 83.52299, mean: 0.07880
[32m[0906 22-37-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08558, current rewards: 89.79734, mean: 0.08090
[32m[0906 22-37-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08553, current rewards: 96.06793, mean: 0.08282
[32m[0906 22-37-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08550, current rewards: 102.33896, mean: 0.08458
[32m[0906 22-37-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08546, current rewards: 108.60728, mean: 0.08620
[32m[0906 22-38-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08542, current rewards: 114.74142, mean: 0.08759
[32m[0906 22-38-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08539, current rewards: 120.97429, mean: 0.08895
[32m[0906 22-38-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08537, current rewards: 127.20724, mean: 0.09022
[32m[0906 22-38-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08533, current rewards: 133.43950, mean: 0.09140
[32m[0906 22-38-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08531, current rewards: 123.86497, mean: 0.08203
[32m[0906 22-38-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08527, current rewards: 128.85798, mean: 0.08260
[32m[0906 22-38-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08525, current rewards: 133.85307, mean: 0.08314
[32m[0906 22-38-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08524, current rewards: 138.85350, mean: 0.08365
[32m[0906 22-38-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08527, current rewards: 139.64644, mean: 0.08166
[32m[0906 22-38-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08531, current rewards: 140.64731, mean: 0.07991
[32m[0906 22-38-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08536, current rewards: 147.46817, mean: 0.08147
[32m[0906 22-38-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08540, current rewards: 154.28056, mean: 0.08295
[32m[0906 22-38-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08548, current rewards: 161.10825, mean: 0.08435
[32m[0906 22-38-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08553, current rewards: 167.92559, mean: 0.08568
[32m[0906 22-39-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08557, current rewards: 174.73530, mean: 0.08693
[32m[0906 22-39-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08560, current rewards: 181.55241, mean: 0.08813
[32m[0906 22-39-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08564, current rewards: 187.69331, mean: 0.08895
[32m[0906 22-39-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08568, current rewards: 194.60654, mean: 0.09010
[32m[0906 22-39-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08572, current rewards: 201.50581, mean: 0.09118
[32m[0906 22-39-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08576, current rewards: 208.40827, mean: 0.09222
[32m[0906 22-39-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08585, current rewards: 215.30719, mean: 0.09321
[32m[0906 22-39-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08592, current rewards: 222.20919, mean: 0.09416
[32m[0906 22-39-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08601, current rewards: 229.10222, mean: 0.09506
[32m[0906 22-39-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08608, current rewards: 236.00534, mean: 0.09594
[32m[0906 22-39-47 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0906 22-39-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-39-47 @MBExp.py:227][0m Rewards obtained: [241.58771224613665], Lows: [21], Highs: [19], Total time: 23530.886446000008
[32m[0906 22-42-31 @MBExp.py:144][0m ####################################################################
[32m[0906 22-42-31 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 22-42-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08817, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-42-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09423, current rewards: -33.82966, mean: -0.56383
[32m[0906 22-42-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09640, current rewards: -51.41078, mean: -0.46737
[32m[0906 22-42-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09691, current rewards: -67.38072, mean: -0.42113
[32m[0906 22-42-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09574, current rewards: -83.94476, mean: -0.39974
[32m[0906 22-42-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09592, current rewards: -101.33796, mean: -0.38976
[32m[0906 22-43-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09586, current rewards: -115.09813, mean: -0.37128
[32m[0906 22-43-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09588, current rewards: -134.53590, mean: -0.37371
[32m[0906 22-43-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09535, current rewards: -148.96566, mean: -0.36333
[32m[0906 22-43-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09481, current rewards: -161.13319, mean: -0.35029
[32m[0906 22-43-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09436, current rewards: -178.83590, mean: -0.35066
[32m[0906 22-43-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09393, current rewards: -191.90181, mean: -0.34268
[32m[0906 22-43-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09367, current rewards: -208.02211, mean: -0.34102
[32m[0906 22-43-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09324, current rewards: -227.76999, mean: -0.34511
[32m[0906 22-43-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09264, current rewards: -271.94939, mean: -0.38303
[32m[0906 22-43-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09209, current rewards: -321.94939, mean: -0.42362
[32m[0906 22-43-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09161, current rewards: -371.94939, mean: -0.45920
[32m[0906 22-43-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09118, current rewards: -421.94939, mean: -0.49064
[32m[0906 22-43-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09081, current rewards: -471.94939, mean: -0.51863
[32m[0906 22-43-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09049, current rewards: -521.94939, mean: -0.54370
[32m[0906 22-44-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09019, current rewards: -571.94939, mean: -0.56629
[32m[0906 22-44-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08992, current rewards: -621.94939, mean: -0.58674
[32m[0906 22-44-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08966, current rewards: -671.94939, mean: -0.60536
[32m[0906 22-44-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08945, current rewards: -721.94939, mean: -0.62237
[32m[0906 22-44-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08926, current rewards: -771.94939, mean: -0.63797
[32m[0906 22-44-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08906, current rewards: -821.94939, mean: -0.65234
[32m[0906 22-44-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08890, current rewards: -871.94939, mean: -0.66561
[32m[0906 22-44-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08873, current rewards: -921.94939, mean: -0.67790
[32m[0906 22-44-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08858, current rewards: -971.94939, mean: -0.68933
[32m[0906 22-44-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08844, current rewards: -1021.94939, mean: -0.69997
[32m[0906 22-44-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08831, current rewards: -1071.94939, mean: -0.70990
[32m[0906 22-44-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08819, current rewards: -1121.94939, mean: -0.71920
[32m[0906 22-44-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08807, current rewards: -1171.94939, mean: -0.72792
[32m[0906 22-44-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08796, current rewards: -1221.94939, mean: -0.73611
[32m[0906 22-45-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08794, current rewards: -1271.94939, mean: -0.74383
[32m[0906 22-45-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08791, current rewards: -1321.94939, mean: -0.75111
[32m[0906 22-45-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08789, current rewards: -1371.94939, mean: -0.75798
[32m[0906 22-45-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08786, current rewards: -1421.94939, mean: -0.76449
[32m[0906 22-45-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08780, current rewards: -1449.36586, mean: -0.75883
[32m[0906 22-45-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08772, current rewards: -1442.90703, mean: -0.73618
[32m[0906 22-45-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08768, current rewards: -1436.44821, mean: -0.71465
[32m[0906 22-45-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08767, current rewards: -1429.98939, mean: -0.69417
[32m[0906 22-45-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08766, current rewards: -1423.53056, mean: -0.67466
[32m[0906 22-45-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08765, current rewards: -1417.07174, mean: -0.65605
[32m[0906 22-45-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08764, current rewards: -1410.61292, mean: -0.63829
[32m[0906 22-45-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08766, current rewards: -1404.15409, mean: -0.62131
[32m[0906 22-45-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08770, current rewards: -1397.69527, mean: -0.60506
[32m[0906 22-45-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08774, current rewards: -1426.24092, mean: -0.60434
[32m[0906 22-46-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08778, current rewards: -1476.24092, mean: -0.61255
[32m[0906 22-46-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08783, current rewards: -1526.24092, mean: -0.62042
[32m[0906 22-46-12 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0906 22-46-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-46-12 @MBExp.py:227][0m Rewards obtained: [-1566.2409169202874], Lows: [2], Highs: [1654], Total time: 23751.282929000008
[32m[0906 22-48-59 @MBExp.py:144][0m ####################################################################
[32m[0906 22-48-59 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 22-48-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09098, current rewards: -4.54665, mean: -0.45467
[32m[0906 22-49-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09980, current rewards: -2.03946, mean: -0.03399
[32m[0906 22-49-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09551, current rewards: -9.25781, mean: -0.08416
[32m[0906 22-49-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09312, current rewards: -16.39151, mean: -0.10245
[32m[0906 22-49-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09169, current rewards: -27.20642, mean: -0.12955
[32m[0906 22-49-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09096, current rewards: -46.96191, mean: -0.18062
[32m[0906 22-49-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09072, current rewards: -67.45497, mean: -0.21760
[32m[0906 22-49-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09139, current rewards: -79.02519, mean: -0.21951
[32m[0906 22-49-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09069, current rewards: -105.68257, mean: -0.25776
[32m[0906 22-49-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09022, current rewards: -124.23829, mean: -0.27008
[32m[0906 22-49-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08981, current rewards: -118.43903, mean: -0.23223
[32m[0906 22-49-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08938, current rewards: -131.81339, mean: -0.23538
[32m[0906 22-49-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08897, current rewards: -129.86097, mean: -0.21289
[32m[0906 22-49-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08862, current rewards: -121.67530, mean: -0.18436
[32m[0906 22-50-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08833, current rewards: -117.10983, mean: -0.16494
[32m[0906 22-50-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08809, current rewards: -111.43546, mean: -0.14663
[32m[0906 22-50-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08786, current rewards: -133.26628, mean: -0.16453
[32m[0906 22-50-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08771, current rewards: -147.81432, mean: -0.17188
[32m[0906 22-50-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08760, current rewards: -164.58432, mean: -0.18086
[32m[0906 22-50-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08748, current rewards: -181.11568, mean: -0.18866
[32m[0906 22-50-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08733, current rewards: -195.82303, mean: -0.19388
[32m[0906 22-50-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08719, current rewards: -196.00704, mean: -0.18491
[32m[0906 22-50-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08706, current rewards: -180.67613, mean: -0.16277
[32m[0906 22-50-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08695, current rewards: -165.26035, mean: -0.14247
[32m[0906 22-50-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08686, current rewards: -153.69828, mean: -0.12702
[32m[0906 22-50-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08677, current rewards: -166.56941, mean: -0.13220
[32m[0906 22-50-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08669, current rewards: -180.26877, mean: -0.13761
[32m[0906 22-50-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08662, current rewards: -174.68772, mean: -0.12845
[32m[0906 22-51-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08656, current rewards: -169.19184, mean: -0.11999
[32m[0906 22-51-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08649, current rewards: -163.69661, mean: -0.11212
[32m[0906 22-51-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08642, current rewards: -158.20092, mean: -0.10477
[32m[0906 22-51-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08635, current rewards: -152.70533, mean: -0.09789
[32m[0906 22-51-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08629, current rewards: -147.20228, mean: -0.09143
[32m[0906 22-51-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08624, current rewards: -139.88642, mean: -0.08427
[32m[0906 22-51-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08624, current rewards: -133.70874, mean: -0.07819
[32m[0906 22-51-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08627, current rewards: -127.53106, mean: -0.07246
[32m[0906 22-51-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08628, current rewards: -123.60048, mean: -0.06829
[32m[0906 22-51-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08630, current rewards: -173.60048, mean: -0.09333
[32m[0906 22-51-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08629, current rewards: -223.60048, mean: -0.11707
[32m[0906 22-51-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08624, current rewards: -273.60048, mean: -0.13959
[32m[0906 22-51-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08621, current rewards: -323.60048, mean: -0.16100
[32m[0906 22-51-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08624, current rewards: -362.93281, mean: -0.17618
[32m[0906 22-52-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08636, current rewards: -406.85322, mean: -0.19282
[32m[0906 22-52-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08644, current rewards: -453.84983, mean: -0.21012
[32m[0906 22-52-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08649, current rewards: -472.71667, mean: -0.21390
[32m[0906 22-52-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08654, current rewards: -513.55585, mean: -0.22724
[32m[0906 22-52-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08685, current rewards: -519.77844, mean: -0.22501
[32m[0906 22-52-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08691, current rewards: -528.26455, mean: -0.22384
[32m[0906 22-52-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08698, current rewards: -540.74724, mean: -0.22438
[32m[0906 22-52-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08716, current rewards: -541.13636, mean: -0.21997
[32m[0906 22-52-37 @Agent.py:117][0m Average action selection time: 0.0873
[32m[0906 22-52-37 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-52-37 @MBExp.py:227][0m Rewards obtained: [-565.100574766326], Lows: [280], Highs: [407], Total time: 23970.171188000008
[32m[0906 22-55-26 @MBExp.py:144][0m ####################################################################
[32m[0906 22-55-26 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 22-55-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09504, current rewards: -4.47821, mean: -0.44782
[32m[0906 22-55-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08993, current rewards: -0.07987, mean: -0.00133
[32m[0906 22-55-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08846, current rewards: 4.55149, mean: 0.04138
[32m[0906 22-55-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08799, current rewards: 9.17935, mean: 0.05737
[32m[0906 22-55-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08774, current rewards: 13.80694, mean: 0.06575
[32m[0906 22-55-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08761, current rewards: 18.43650, mean: 0.07091
[32m[0906 22-55-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08756, current rewards: 11.07055, mean: 0.03571
[32m[0906 22-55-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08720, current rewards: 16.32235, mean: 0.04534
[32m[0906 22-56-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08685, current rewards: 21.57516, mean: 0.05262
[32m[0906 22-56-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08657, current rewards: 29.21996, mean: 0.06352
[32m[0906 22-56-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08637, current rewards: 36.14663, mean: 0.07088
[32m[0906 22-56-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08617, current rewards: 43.07329, mean: 0.07692
[32m[0906 22-56-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08601, current rewards: 34.06048, mean: 0.05584
[32m[0906 22-56-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08588, current rewards: -15.93952, mean: -0.02415
[32m[0906 22-56-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08579, current rewards: -65.93952, mean: -0.09287
[32m[0906 22-56-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08567, current rewards: -115.93952, mean: -0.15255
[32m[0906 22-56-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08558, current rewards: -165.93952, mean: -0.20486
[32m[0906 22-56-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08550, current rewards: -215.93952, mean: -0.25109
[32m[0906 22-56-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08544, current rewards: -265.93952, mean: -0.29224
[32m[0906 22-56-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08541, current rewards: -315.93952, mean: -0.32910
[32m[0906 22-56-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08536, current rewards: -365.93952, mean: -0.36232
[32m[0906 22-56-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08533, current rewards: -415.93952, mean: -0.39240
[32m[0906 22-57-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08528, current rewards: -465.93952, mean: -0.41977
[32m[0906 22-57-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08525, current rewards: -515.93952, mean: -0.44478
[32m[0906 22-57-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08523, current rewards: -565.93952, mean: -0.46772
[32m[0906 22-57-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08519, current rewards: -618.01056, mean: -0.49048
[32m[0906 22-57-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08514, current rewards: -623.29220, mean: -0.47580
[32m[0906 22-57-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08511, current rewards: -617.29960, mean: -0.45390
[32m[0906 22-57-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08510, current rewards: -611.29494, mean: -0.43354
[32m[0906 22-57-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08508, current rewards: -605.28785, mean: -0.41458
[32m[0906 22-57-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08507, current rewards: -612.17131, mean: -0.40541
[32m[0906 22-57-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08508, current rewards: -618.31057, mean: -0.39635
[32m[0906 22-57-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08516, current rewards: -619.04741, mean: -0.38450
[32m[0906 22-57-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08515, current rewards: -628.62027, mean: -0.37869
[32m[0906 22-57-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08521, current rewards: -654.66950, mean: -0.38285
[32m[0906 22-57-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08531, current rewards: -679.69740, mean: -0.38619
[32m[0906 22-58-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08539, current rewards: -704.56572, mean: -0.38926
[32m[0906 22-58-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08550, current rewards: -734.78132, mean: -0.39504
[32m[0906 22-58-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08554, current rewards: -755.98978, mean: -0.39581
[32m[0906 22-58-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08561, current rewards: -786.67931, mean: -0.40137
[32m[0906 22-58-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08566, current rewards: -805.76579, mean: -0.40088
[32m[0906 22-58-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08580, current rewards: -838.60337, mean: -0.40709
[32m[0906 22-58-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08592, current rewards: -858.53212, mean: -0.40689
[32m[0906 22-58-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08602, current rewards: -869.02919, mean: -0.40233
[32m[0906 22-58-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08613, current rewards: -901.62116, mean: -0.40797
[32m[0906 22-58-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08616, current rewards: -914.30019, mean: -0.40456
[32m[0906 22-58-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08625, current rewards: -923.71916, mean: -0.39988
[32m[0906 22-58-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08632, current rewards: -927.77565, mean: -0.39313
[32m[0906 22-58-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08642, current rewards: -935.64292, mean: -0.38823
[32m[0906 22-58-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08652, current rewards: -946.84128, mean: -0.38489
[32m[0906 22-59-03 @Agent.py:117][0m Average action selection time: 0.0866
[32m[0906 22-59-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-59-03 @MBExp.py:227][0m Rewards obtained: [-942.2519288700087], Lows: [265], Highs: [676], Total time: 24187.327403000007
[32m[0906 23-01-52 @MBExp.py:144][0m ####################################################################
[32m[0906 23-01-52 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 23-01-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08888, current rewards: -14.00000, mean: -1.40000
[32m[0906 23-01-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08890, current rewards: -16.23939, mean: -0.27066
[32m[0906 23-02-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08796, current rewards: -10.30258, mean: -0.09366
[32m[0906 23-02-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08757, current rewards: -3.55074, mean: -0.02219
[32m[0906 23-02-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08741, current rewards: 2.89991, mean: 0.01381
[32m[0906 23-02-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08726, current rewards: 8.89061, mean: 0.03419
[32m[0906 23-02-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08718, current rewards: 15.74650, mean: 0.05080
[32m[0906 23-02-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08697, current rewards: 8.70103, mean: 0.02417
[32m[0906 23-02-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08667, current rewards: 12.40410, mean: 0.03025
[32m[0906 23-02-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08643, current rewards: 16.19610, mean: 0.03521
[32m[0906 23-02-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08624, current rewards: 19.89575, mean: 0.03901
[32m[0906 23-02-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08610, current rewards: 23.59832, mean: 0.04214
[32m[0906 23-02-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08599, current rewards: 27.31110, mean: 0.04477
[32m[0906 23-02-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08589, current rewards: 27.79569, mean: 0.04211
[32m[0906 23-02-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08601, current rewards: -14.51882, mean: -0.02045
[32m[0906 23-02-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08592, current rewards: -53.85659, mean: -0.07086
[32m[0906 23-03-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08581, current rewards: -48.32262, mean: -0.05966
[32m[0906 23-03-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08573, current rewards: -42.68593, mean: -0.04963
[32m[0906 23-03-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08564, current rewards: -37.40774, mean: -0.04111
[32m[0906 23-03-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08559, current rewards: -32.12967, mean: -0.03347
[32m[0906 23-03-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08555, current rewards: -32.49858, mean: -0.03218
[32m[0906 23-03-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08548, current rewards: -26.98416, mean: -0.02546
[32m[0906 23-03-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08543, current rewards: -21.46975, mean: -0.01934
[32m[0906 23-03-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08538, current rewards: -15.95785, mean: -0.01376
[32m[0906 23-03-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08534, current rewards: -10.44412, mean: -0.00863
[32m[0906 23-03-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08529, current rewards: -4.59814, mean: -0.00365
[32m[0906 23-03-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08526, current rewards: 0.94753, mean: 0.00072
[32m[0906 23-03-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08523, current rewards: 6.49089, mean: 0.00477
[32m[0906 23-03-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08521, current rewards: 12.02937, mean: 0.00853
[32m[0906 23-03-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08519, current rewards: 17.33147, mean: 0.01187
[32m[0906 23-04-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08517, current rewards: 15.56719, mean: 0.01031
[32m[0906 23-04-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08515, current rewards: 21.62769, mean: 0.01386
[32m[0906 23-04-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08513, current rewards: 27.67702, mean: 0.01719
[32m[0906 23-04-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08511, current rewards: 33.73598, mean: 0.02032
[32m[0906 23-04-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08509, current rewards: 39.79013, mean: 0.02327
[32m[0906 23-04-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08514, current rewards: 45.84825, mean: 0.02605
[32m[0906 23-04-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08517, current rewards: 51.90914, mean: 0.02868
[32m[0906 23-04-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08522, current rewards: 57.95972, mean: 0.03116
[32m[0906 23-04-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08526, current rewards: 64.00902, mean: 0.03351
[32m[0906 23-04-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08541, current rewards: 63.33874, mean: 0.03232
[32m[0906 23-04-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08559, current rewards: 49.86813, mean: 0.02481
[32m[0906 23-04-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08573, current rewards: 40.63397, mean: 0.01973
[32m[0906 23-04-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08582, current rewards: 45.34158, mean: 0.02149
[32m[0906 23-04-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08590, current rewards: 49.75954, mean: 0.02304
[32m[0906 23-05-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08594, current rewards: 54.00526, mean: 0.02444
[32m[0906 23-05-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08597, current rewards: 58.29698, mean: 0.02580
[32m[0906 23-05-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08600, current rewards: 59.58547, mean: 0.02579
[32m[0906 23-05-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08607, current rewards: 61.33390, mean: 0.02599
[32m[0906 23-05-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08615, current rewards: 67.29030, mean: 0.02792
[32m[0906 23-05-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08622, current rewards: 73.91368, mean: 0.03005
[32m[0906 23-05-29 @Agent.py:117][0m Average action selection time: 0.0863
[32m[0906 23-05-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-05-29 @MBExp.py:227][0m Rewards obtained: [82.5231887169039], Lows: [37], Highs: [102], Total time: 24403.746975000005
[32m[0906 23-08-20 @MBExp.py:144][0m ####################################################################
[32m[0906 23-08-20 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 23-08-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08999, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-08-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08928, current rewards: -8.98765, mean: -0.14979
[32m[0906 23-08-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08827, current rewards: -4.24343, mean: -0.03858
[32m[0906 23-08-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08782, current rewards: 0.50266, mean: 0.00314
[32m[0906 23-08-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08750, current rewards: 5.24963, mean: 0.02500
[32m[0906 23-08-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08737, current rewards: 9.99600, mean: 0.03845
[32m[0906 23-08-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08726, current rewards: 14.74442, mean: 0.04756
[32m[0906 23-08-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08705, current rewards: 16.20448, mean: 0.04501
[32m[0906 23-08-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08675, current rewards: 16.60110, mean: 0.04049
[32m[0906 23-09-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08651, current rewards: 23.19506, mean: 0.05042
[32m[0906 23-09-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08632, current rewards: 29.76635, mean: 0.05837
[32m[0906 23-09-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08617, current rewards: 36.33863, mean: 0.06489
[32m[0906 23-09-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08617, current rewards: 32.09747, mean: 0.05262
[32m[0906 23-09-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08605, current rewards: 36.50107, mean: 0.05530
[32m[0906 23-09-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08596, current rewards: 40.89301, mean: 0.05760
[32m[0906 23-09-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08586, current rewards: 45.28520, mean: 0.05959
[32m[0906 23-09-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08577, current rewards: 49.66752, mean: 0.06132
[32m[0906 23-09-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08570, current rewards: 40.72448, mean: 0.04735
[32m[0906 23-09-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08563, current rewards: 44.31705, mean: 0.04870
[32m[0906 23-09-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08558, current rewards: 47.91058, mean: 0.04991
[32m[0906 23-09-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08552, current rewards: 51.50347, mean: 0.05099
[32m[0906 23-09-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08550, current rewards: 55.09516, mean: 0.05198
[32m[0906 23-09-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08545, current rewards: 58.68702, mean: 0.05287
[32m[0906 23-10-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08540, current rewards: 62.27900, mean: 0.05369
[32m[0906 23-10-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08536, current rewards: 65.87195, mean: 0.05444
[32m[0906 23-10-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08532, current rewards: 69.77795, mean: 0.05538
[32m[0906 23-10-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08528, current rewards: 73.40342, mean: 0.05603
[32m[0906 23-10-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08525, current rewards: 68.60014, mean: 0.05044
[32m[0906 23-10-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08521, current rewards: 73.16600, mean: 0.05189
[32m[0906 23-10-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08519, current rewards: 77.73292, mean: 0.05324
[32m[0906 23-10-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08516, current rewards: 82.30017, mean: 0.05450
[32m[0906 23-10-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08515, current rewards: 86.86653, mean: 0.05568
[32m[0906 23-10-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08512, current rewards: 91.43387, mean: 0.05679
[32m[0906 23-10-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08509, current rewards: 95.96355, mean: 0.05781
[32m[0906 23-10-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08507, current rewards: 100.08273, mean: 0.05853
[32m[0906 23-10-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08505, current rewards: 104.34028, mean: 0.05928
[32m[0906 23-10-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08509, current rewards: 108.60543, mean: 0.06000
[32m[0906 23-10-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08514, current rewards: 112.86801, mean: 0.06068
[32m[0906 23-11-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08518, current rewards: 117.12976, mean: 0.06132
[32m[0906 23-11-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08521, current rewards: 121.39099, mean: 0.06193
[32m[0906 23-11-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08525, current rewards: 125.65891, mean: 0.06252
[32m[0906 23-11-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08529, current rewards: 129.94586, mean: 0.06308
[32m[0906 23-11-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08538, current rewards: 134.20054, mean: 0.06360
[32m[0906 23-11-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08547, current rewards: 138.38661, mean: 0.06407
[32m[0906 23-11-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08552, current rewards: 142.57778, mean: 0.06451
[32m[0906 23-11-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08556, current rewards: 146.76517, mean: 0.06494
[32m[0906 23-11-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08559, current rewards: 150.95011, mean: 0.06535
[32m[0906 23-11-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08564, current rewards: 155.13433, mean: 0.06573
[32m[0906 23-11-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08576, current rewards: 151.91607, mean: 0.06304
[32m[0906 23-11-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08584, current rewards: 156.46018, mean: 0.06360
[32m[0906 23-11-56 @Agent.py:117][0m Average action selection time: 0.0859
[32m[0906 23-11-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-11-56 @MBExp.py:227][0m Rewards obtained: [159.7808348747104], Lows: [16], Highs: [31], Total time: 24619.239286000007
[32m[0906 23-14-49 @MBExp.py:144][0m ####################################################################
[32m[0906 23-14-49 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 23-14-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08821, current rewards: -11.59827, mean: -1.15983
[32m[0906 23-14-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08946, current rewards: -13.83400, mean: -0.23057
[32m[0906 23-14-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08960, current rewards: -9.19458, mean: -0.08359
[32m[0906 23-15-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08954, current rewards: -4.55107, mean: -0.02844
[32m[0906 23-15-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08951, current rewards: 0.09814, mean: 0.00047
[32m[0906 23-15-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08956, current rewards: 4.73817, mean: 0.01822
[32m[0906 23-15-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08931, current rewards: 9.38015, mean: 0.03026
[32m[0906 23-15-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08896, current rewards: 14.02173, mean: 0.03895
[32m[0906 23-15-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08842, current rewards: 6.10726, mean: 0.01490
[32m[0906 23-15-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08796, current rewards: 12.11701, mean: 0.02634
[32m[0906 23-15-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08759, current rewards: 18.12915, mean: 0.03555
[32m[0906 23-15-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08731, current rewards: 24.15150, mean: 0.04313
[32m[0906 23-15-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08706, current rewards: 30.16253, mean: 0.04945
[32m[0906 23-15-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08688, current rewards: 36.17210, mean: 0.05481
[32m[0906 23-15-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08668, current rewards: 42.18826, mean: 0.05942
[32m[0906 23-15-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08656, current rewards: 43.48330, mean: 0.05721
[32m[0906 23-15-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08644, current rewards: 49.57563, mean: 0.06120
[32m[0906 23-16-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08633, current rewards: 56.89385, mean: 0.06616
[32m[0906 23-16-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08625, current rewards: 62.99741, mean: 0.06923
[32m[0906 23-16-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08617, current rewards: 69.09620, mean: 0.07198
[32m[0906 23-16-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08608, current rewards: 75.19433, mean: 0.07445
[32m[0906 23-16-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08602, current rewards: 81.28917, mean: 0.07669
[32m[0906 23-16-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08595, current rewards: 87.39858, mean: 0.07874
[32m[0906 23-16-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08589, current rewards: 66.39266, mean: 0.05724
[32m[0906 23-16-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08582, current rewards: 65.02435, mean: 0.05374
[32m[0906 23-16-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08578, current rewards: 69.92557, mean: 0.05550
[32m[0906 23-16-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08574, current rewards: 72.45314, mean: 0.05531
[32m[0906 23-16-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08570, current rewards: 74.98070, mean: 0.05513
[32m[0906 23-16-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08565, current rewards: 61.75000, mean: 0.04379
[32m[0906 23-16-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08560, current rewards: 11.75000, mean: 0.00805
[32m[0906 23-16-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08556, current rewards: -38.25000, mean: -0.02533
[32m[0906 23-17-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08553, current rewards: -88.25000, mean: -0.05657
[32m[0906 23-17-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08550, current rewards: -138.25000, mean: -0.08587
[32m[0906 23-17-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08546, current rewards: -188.25000, mean: -0.11340
[32m[0906 23-17-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08543, current rewards: -238.25000, mean: -0.13933
[32m[0906 23-17-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08541, current rewards: -288.25000, mean: -0.16378
[32m[0906 23-17-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08539, current rewards: -338.25000, mean: -0.18688
[32m[0906 23-17-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08544, current rewards: -388.25000, mean: -0.20874
[32m[0906 23-17-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08546, current rewards: -438.25000, mean: -0.22945
[32m[0906 23-17-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08550, current rewards: -488.25000, mean: -0.24911
[32m[0906 23-17-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08553, current rewards: -538.25000, mean: -0.26779
[32m[0906 23-17-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08556, current rewards: -588.25000, mean: -0.28556
[32m[0906 23-17-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08559, current rewards: -638.25000, mean: -0.30249
[32m[0906 23-17-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08563, current rewards: -688.25000, mean: -0.31863
[32m[0906 23-17-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08565, current rewards: -738.25000, mean: -0.33405
[32m[0906 23-18-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08565, current rewards: -788.25000, mean: -0.34878
[32m[0906 23-18-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08564, current rewards: -838.25000, mean: -0.36288
[32m[0906 23-18-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08568, current rewards: -888.25000, mean: -0.37638
[32m[0906 23-18-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08572, current rewards: -938.25000, mean: -0.38932
[32m[0906 23-18-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08580, current rewards: -988.25000, mean: -0.40173
[32m[0906 23-18-24 @Agent.py:117][0m Average action selection time: 0.0859
[32m[0906 23-18-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-18-25 @MBExp.py:227][0m Rewards obtained: [-1028.2499985869338], Lows: [30], Highs: [1116], Total time: 24834.626538000008
[32m[0906 23-21-20 @MBExp.py:144][0m ####################################################################
[32m[0906 23-21-20 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 23-21-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08903, current rewards: -4.70315, mean: -0.47031
[32m[0906 23-21-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08974, current rewards: 1.13448, mean: 0.01891
[32m[0906 23-21-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08964, current rewards: 6.78965, mean: 0.06172
[32m[0906 23-21-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08958, current rewards: 12.44842, mean: 0.07780
[32m[0906 23-21-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08961, current rewards: 15.99506, mean: 0.07617
[32m[0906 23-21-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08972, current rewards: 8.82592, mean: 0.03395
[32m[0906 23-21-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08968, current rewards: 14.52591, mean: 0.04686
[32m[0906 23-21-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08934, current rewards: 20.22782, mean: 0.05619
[32m[0906 23-21-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08904, current rewards: 25.93227, mean: 0.06325
[32m[0906 23-22-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08851, current rewards: 31.26753, mean: 0.06797
[32m[0906 23-22-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08813, current rewards: 36.80088, mean: 0.07216
[32m[0906 23-22-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08781, current rewards: 42.56906, mean: 0.07602
[32m[0906 23-22-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08753, current rewards: 48.33173, mean: 0.07923
[32m[0906 23-22-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08731, current rewards: 54.09006, mean: 0.08195
[32m[0906 23-22-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08713, current rewards: 59.86183, mean: 0.08431
[32m[0906 23-22-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08696, current rewards: 65.62103, mean: 0.08634
[32m[0906 23-22-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08680, current rewards: 71.38322, mean: 0.08813
[32m[0906 23-22-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08665, current rewards: 70.80749, mean: 0.08233
[32m[0906 23-22-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08656, current rewards: 76.14911, mean: 0.08368
[32m[0906 23-22-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08646, current rewards: 84.53244, mean: 0.08805
[32m[0906 23-22-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08638, current rewards: 92.92040, mean: 0.09200
[32m[0906 23-22-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08629, current rewards: 101.31264, mean: 0.09558
[32m[0906 23-22-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08620, current rewards: 109.69721, mean: 0.09883
[32m[0906 23-23-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08613, current rewards: 118.09106, mean: 0.10180
[32m[0906 23-23-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08606, current rewards: 126.47876, mean: 0.10453
[32m[0906 23-23-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08599, current rewards: 134.74760, mean: 0.10694
[32m[0906 23-23-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08594, current rewards: 139.24516, mean: 0.10629
[32m[0906 23-23-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08588, current rewards: 144.07996, mean: 0.10594
[32m[0906 23-23-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08585, current rewards: 148.91596, mean: 0.10561
[32m[0906 23-23-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08580, current rewards: 153.74841, mean: 0.10531
[32m[0906 23-23-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08575, current rewards: 158.58559, mean: 0.10502
[32m[0906 23-23-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08571, current rewards: 163.42174, mean: 0.10476
[32m[0906 23-23-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08569, current rewards: 168.25694, mean: 0.10451
[32m[0906 23-23-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08565, current rewards: 173.09075, mean: 0.10427
[32m[0906 23-23-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08562, current rewards: 169.87651, mean: 0.09934
[32m[0906 23-23-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08559, current rewards: 176.57505, mean: 0.10033
[32m[0906 23-23-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08556, current rewards: 183.03388, mean: 0.10112
[32m[0906 23-23-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08556, current rewards: 189.49271, mean: 0.10188
[32m[0906 23-24-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08560, current rewards: 195.95154, mean: 0.10259
[32m[0906 23-24-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08563, current rewards: 167.40589, mean: 0.08541
[32m[0906 23-24-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08567, current rewards: 117.40589, mean: 0.05841
[32m[0906 23-24-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08571, current rewards: 67.40589, mean: 0.03272
[32m[0906 23-24-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08574, current rewards: 17.40589, mean: 0.00825
[32m[0906 23-24-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08578, current rewards: -32.59411, mean: -0.01509
[32m[0906 23-24-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08581, current rewards: -82.59411, mean: -0.03737
[32m[0906 23-24-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08580, current rewards: -132.59411, mean: -0.05867
[32m[0906 23-24-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08579, current rewards: -182.59411, mean: -0.07905
[32m[0906 23-24-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08577, current rewards: -232.59411, mean: -0.09856
[32m[0906 23-24-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08580, current rewards: -282.59411, mean: -0.11726
[32m[0906 23-24-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08582, current rewards: -332.59411, mean: -0.13520
[32m[0906 23-24-55 @Agent.py:117][0m Average action selection time: 0.0859
[32m[0906 23-24-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-24-55 @MBExp.py:227][0m Rewards obtained: [-372.5941097239146], Lows: [18], Highs: [576], Total time: 25050.07817100001
[32m[0906 23-27-52 @MBExp.py:144][0m ####################################################################
[32m[0906 23-27-52 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 23-27-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09156, current rewards: -6.59853, mean: -0.65985
[32m[0906 23-27-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09150, current rewards: -20.53970, mean: -0.34233
[32m[0906 23-28-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09087, current rewards: -16.67161, mean: -0.15156
[32m[0906 23-28-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09050, current rewards: -12.77677, mean: -0.07985
[32m[0906 23-28-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09072, current rewards: -8.88203, mean: -0.04230
[32m[0906 23-28-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09062, current rewards: -4.98095, mean: -0.01916
[32m[0906 23-28-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09063, current rewards: -1.09102, mean: -0.00352
[32m[0906 23-28-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09062, current rewards: 2.80142, mean: 0.00778
[32m[0906 23-28-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09073, current rewards: -5.72932, mean: -0.01397
[32m[0906 23-28-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09028, current rewards: -1.82756, mean: -0.00397
[32m[0906 23-28-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08972, current rewards: 2.02019, mean: 0.00396
[32m[0906 23-28-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08927, current rewards: 5.86821, mean: 0.01048
[32m[0906 23-28-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08892, current rewards: 9.71709, mean: 0.01593
[32m[0906 23-28-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08861, current rewards: 13.56620, mean: 0.02055
[32m[0906 23-28-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08833, current rewards: 17.41314, mean: 0.02453
[32m[0906 23-28-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08809, current rewards: 21.26096, mean: 0.02797
[32m[0906 23-29-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08787, current rewards: 25.10962, mean: 0.03100
[32m[0906 23-29-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08767, current rewards: 29.22211, mean: 0.03398
[32m[0906 23-29-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08821, current rewards: 12.50395, mean: 0.01374
[32m[0906 23-29-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08827, current rewards: 15.73006, mean: 0.01639
[32m[0906 23-29-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08810, current rewards: 20.92523, mean: 0.02072
[32m[0906 23-29-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08792, current rewards: 26.11244, mean: 0.02463
[32m[0906 23-29-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08779, current rewards: 31.30145, mean: 0.02820
[32m[0906 23-29-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08766, current rewards: 36.49966, mean: 0.03147
[32m[0906 23-29-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08754, current rewards: 41.69045, mean: 0.03445
[32m[0906 23-29-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08743, current rewards: 46.88238, mean: 0.03721
[32m[0906 23-29-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08754, current rewards: 51.01029, mean: 0.03894
[32m[0906 23-29-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08773, current rewards: 55.05670, mean: 0.04048
[32m[0906 23-29-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08764, current rewards: 49.81355, mean: 0.03533
[32m[0906 23-30-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08752, current rewards: 56.20330, mean: 0.03850
[32m[0906 23-30-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08742, current rewards: 62.58405, mean: 0.04145
[32m[0906 23-30-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08732, current rewards: 68.96882, mean: 0.04421
[32m[0906 23-30-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08725, current rewards: 75.35201, mean: 0.04680
[32m[0906 23-30-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08717, current rewards: 81.73391, mean: 0.04924
[32m[0906 23-30-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08710, current rewards: 87.87321, mean: 0.05139
[32m[0906 23-30-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08706, current rewards: 81.44964, mean: 0.04628
[32m[0906 23-30-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08700, current rewards: 45.61956, mean: 0.02520
[32m[0906 23-30-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08696, current rewards: -0.48141, mean: -0.00026
[32m[0906 23-30-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08696, current rewards: -1.32214, mean: -0.00069
[32m[0906 23-30-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08696, current rewards: 4.03786, mean: 0.00206
[32m[0906 23-30-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08697, current rewards: 9.39099, mean: 0.00467
[32m[0906 23-30-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08696, current rewards: 14.74611, mean: 0.00716
[32m[0906 23-30-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08696, current rewards: 18.50808, mean: 0.00877
[32m[0906 23-31-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08696, current rewards: 16.09201, mean: 0.00745
[32m[0906 23-31-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08696, current rewards: 20.33329, mean: 0.00920
[32m[0906 23-31-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08691, current rewards: 24.57456, mean: 0.01087
[32m[0906 23-31-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08686, current rewards: 14.71310, mean: 0.00637
[32m[0906 23-31-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08682, current rewards: -35.28690, mean: -0.01495
[32m[0906 23-31-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08677, current rewards: -85.28690, mean: -0.03539
[32m[0906 23-31-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08673, current rewards: -135.28690, mean: -0.05499
[32m[0906 23-31-30 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0906 23-31-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-31-30 @MBExp.py:227][0m Rewards obtained: [-175.28689564052655], Lows: [86], Highs: [221], Total time: 25267.63058100001
[32m[0906 23-34-29 @MBExp.py:144][0m ####################################################################
[32m[0906 23-34-29 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 23-34-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08887, current rewards: -6.49448, mean: -0.64945
[32m[0906 23-34-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08958, current rewards: -15.52042, mean: -0.25867
[32m[0906 23-34-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08954, current rewards: -41.08800, mean: -0.37353
[32m[0906 23-34-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08947, current rewards: -65.32666, mean: -0.40829
[32m[0906 23-34-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08948, current rewards: -105.70117, mean: -0.50334
[32m[0906 23-34-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08949, current rewards: -122.99921, mean: -0.47307
[32m[0906 23-34-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08949, current rewards: -123.46947, mean: -0.39829
[32m[0906 23-35-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08951, current rewards: -118.32335, mean: -0.32868
[32m[0906 23-35-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08951, current rewards: -122.97536, mean: -0.29994
[32m[0906 23-35-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08946, current rewards: -116.31138, mean: -0.25285
[32m[0906 23-35-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08895, current rewards: -109.51340, mean: -0.21473
[32m[0906 23-35-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08861, current rewards: -102.70941, mean: -0.18341
[32m[0906 23-35-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08828, current rewards: -100.34990, mean: -0.16451
[32m[0906 23-35-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08799, current rewards: -100.35332, mean: -0.15205
[32m[0906 23-35-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08774, current rewards: -94.83729, mean: -0.13357
[32m[0906 23-35-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08750, current rewards: -89.31702, mean: -0.11752
[32m[0906 23-35-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08733, current rewards: -83.80064, mean: -0.10346
[32m[0906 23-35-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08718, current rewards: -78.80444, mean: -0.09163
[32m[0906 23-35-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08703, current rewards: -73.22014, mean: -0.08046
[32m[0906 23-35-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08690, current rewards: -67.63359, mean: -0.07045
[32m[0906 23-35-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08680, current rewards: -78.02601, mean: -0.07725
[32m[0906 23-36-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08667, current rewards: -72.67675, mean: -0.06856
[32m[0906 23-36-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08656, current rewards: -67.32063, mean: -0.06065
[32m[0906 23-36-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08647, current rewards: -61.96304, mean: -0.05342
[32m[0906 23-36-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08638, current rewards: -56.60389, mean: -0.04678
[32m[0906 23-36-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08631, current rewards: -51.18463, mean: -0.04062
[32m[0906 23-36-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08623, current rewards: -45.82422, mean: -0.03498
[32m[0906 23-36-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08617, current rewards: -40.45716, mean: -0.02975
[32m[0906 23-36-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08611, current rewards: -35.09727, mean: -0.02489
[32m[0906 23-36-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08605, current rewards: -29.73738, mean: -0.02037
[32m[0906 23-36-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08599, current rewards: -24.37499, mean: -0.01614
[32m[0906 23-36-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08595, current rewards: -36.66539, mean: -0.02350
[32m[0906 23-36-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08592, current rewards: -29.24204, mean: -0.01816
[32m[0906 23-36-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08588, current rewards: -20.95752, mean: -0.01263
[32m[0906 23-36-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08585, current rewards: -12.62111, mean: -0.00738
[32m[0906 23-37-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08580, current rewards: -4.54579, mean: -0.00258
[32m[0906 23-37-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08578, current rewards: 3.53454, mean: 0.00195
[32m[0906 23-37-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08575, current rewards: 11.62025, mean: 0.00625
[32m[0906 23-37-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08575, current rewards: 3.12114, mean: 0.00163
[32m[0906 23-37-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08579, current rewards: -26.79206, mean: -0.01367
[32m[0906 23-37-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08581, current rewards: -59.19558, mean: -0.02945
[32m[0906 23-37-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08584, current rewards: -95.13577, mean: -0.04618
[32m[0906 23-37-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08586, current rewards: -155.91838, mean: -0.07389
[32m[0906 23-37-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08588, current rewards: -208.54340, mean: -0.09655
[32m[0906 23-37-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08591, current rewards: -254.71394, mean: -0.11526
[32m[0906 23-37-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08593, current rewards: -306.75786, mean: -0.13573
[32m[0906 23-37-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08593, current rewards: -347.53369, mean: -0.15045
[32m[0906 23-37-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08590, current rewards: -381.10164, mean: -0.16148
[32m[0906 23-37-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08587, current rewards: -418.15632, mean: -0.17351
[32m[0906 23-38-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08585, current rewards: -412.98330, mean: -0.16788
[32m[0906 23-38-04 @Agent.py:117][0m Average action selection time: 0.0858
[32m[0906 23-38-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-38-04 @MBExp.py:227][0m Rewards obtained: [-409.1067257939784], Lows: [370], Highs: [22], Total time: 25482.96099700001
[32m[0906 23-41-04 @MBExp.py:144][0m ####################################################################
[32m[0906 23-41-04 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 23-41-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12499, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-41-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09865, current rewards: -88.96346, mean: -1.48272
[32m[0906 23-41-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09718, current rewards: -174.24176, mean: -1.58402
[32m[0906 23-41-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09739, current rewards: -251.68908, mean: -1.57306
[32m[0906 23-41-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09819, current rewards: -322.21262, mean: -1.53435
[32m[0906 23-41-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09767, current rewards: -408.84519, mean: -1.57248
[32m[0906 23-41-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09698, current rewards: -498.41458, mean: -1.60779
[32m[0906 23-41-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09727, current rewards: -587.62452, mean: -1.63229
[32m[0906 23-41-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09739, current rewards: -675.12565, mean: -1.64665
[32m[0906 23-41-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09798, current rewards: -749.01898, mean: -1.62830
[32m[0906 23-41-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09773, current rewards: -822.13140, mean: -1.61202
[32m[0906 23-41-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09687, current rewards: -908.29832, mean: -1.62196
[32m[0906 23-42-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09651, current rewards: -977.75189, mean: -1.60287
[32m[0906 23-42-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09575, current rewards: -1043.26454, mean: -1.58070
[32m[0906 23-42-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09518, current rewards: -1088.74574, mean: -1.53344
[32m[0906 23-42-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09482, current rewards: -1146.57017, mean: -1.50864
[32m[0906 23-42-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09433, current rewards: -1185.28106, mean: -1.46331
[32m[0906 23-42-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09389, current rewards: -1221.27971, mean: -1.42009
[32m[0906 23-42-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09343, current rewards: -1261.72632, mean: -1.38651
[32m[0906 23-42-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09295, current rewards: -1307.36925, mean: -1.36184
[32m[0906 23-42-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09306, current rewards: -1367.00137, mean: -1.35347
[32m[0906 23-42-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09268, current rewards: -1467.00137, mean: -1.38396
[32m[0906 23-42-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09232, current rewards: -1567.00137, mean: -1.41171
[32m[0906 23-42-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09198, current rewards: -1667.00137, mean: -1.43707
[32m[0906 23-42-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09167, current rewards: -1767.00137, mean: -1.46033
[32m[0906 23-43-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09139, current rewards: -1867.00137, mean: -1.48175
[32m[0906 23-43-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09112, current rewards: -1967.00137, mean: -1.50153
[32m[0906 23-43-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09088, current rewards: -2067.00137, mean: -1.51985
[32m[0906 23-43-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09064, current rewards: -2167.00137, mean: -1.53688
[32m[0906 23-43-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09044, current rewards: -2267.00137, mean: -1.55274
[32m[0906 23-43-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09024, current rewards: -2367.00137, mean: -1.56755
[32m[0906 23-43-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09006, current rewards: -2467.00137, mean: -1.58141
[32m[0906 23-43-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08988, current rewards: -2567.00137, mean: -1.59441
[32m[0906 23-43-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08971, current rewards: -2667.00137, mean: -1.60663
[32m[0906 23-43-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08957, current rewards: -2767.00137, mean: -1.61813
[32m[0906 23-43-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08942, current rewards: -2867.00137, mean: -1.62898
[32m[0906 23-43-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08928, current rewards: -2967.00137, mean: -1.63923
[32m[0906 23-43-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08916, current rewards: -3067.00137, mean: -1.64893
[32m[0906 23-43-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08910, current rewards: -3167.00137, mean: -1.65812
[32m[0906 23-43-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08904, current rewards: -3267.00137, mean: -1.66684
[32m[0906 23-44-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08899, current rewards: -3367.00137, mean: -1.67513
[32m[0906 23-44-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08894, current rewards: -3467.00137, mean: -1.68301
[32m[0906 23-44-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08889, current rewards: -3567.00137, mean: -1.69052
[32m[0906 23-44-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08884, current rewards: -3667.00137, mean: -1.69769
[32m[0906 23-44-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08879, current rewards: -3767.00137, mean: -1.70453
[32m[0906 23-44-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08871, current rewards: -3867.00137, mean: -1.71106
[32m[0906 23-44-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08862, current rewards: -3967.00137, mean: -1.71732
[32m[0906 23-44-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08854, current rewards: -4067.00137, mean: -1.72331
[32m[0906 23-44-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08846, current rewards: -4167.00137, mean: -1.72905
[32m[0906 23-44-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08838, current rewards: -4267.00137, mean: -1.73455
[32m[0906 23-44-46 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0906 23-44-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-44-46 @MBExp.py:227][0m Rewards obtained: [-4347.001371326631], Lows: [2018], Highs: [330], Total time: 25704.48864600001
[32m[0906 23-47-48 @MBExp.py:144][0m ####################################################################
[32m[0906 23-47-48 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 23-47-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12019, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-47-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09752, current rewards: -36.35277, mean: -0.60588
[32m[0906 23-47-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09412, current rewards: -56.20810, mean: -0.51098
[32m[0906 23-48-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09429, current rewards: -71.95836, mean: -0.44974
[32m[0906 23-48-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09319, current rewards: -66.42418, mean: -0.31631
[32m[0906 23-48-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09255, current rewards: -59.51532, mean: -0.22891
[32m[0906 23-48-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09218, current rewards: -76.52359, mean: -0.24685
[32m[0906 23-48-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09183, current rewards: -68.23490, mean: -0.18954
[32m[0906 23-48-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09160, current rewards: -59.94784, mean: -0.14621
[32m[0906 23-48-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09128, current rewards: -51.50978, mean: -0.11198
[32m[0906 23-48-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09070, current rewards: -43.07902, mean: -0.08447
[32m[0906 23-48-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09015, current rewards: -34.64811, mean: -0.06187
[32m[0906 23-48-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08965, current rewards: -50.67820, mean: -0.08308
[32m[0906 23-48-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08954, current rewards: -102.76004, mean: -0.15570
[32m[0906 23-48-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08964, current rewards: -144.95004, mean: -0.20415
[32m[0906 23-48-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08967, current rewards: -195.72035, mean: -0.25753
[32m[0906 23-49-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08954, current rewards: -249.34481, mean: -0.30783
[32m[0906 23-49-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08959, current rewards: -294.65902, mean: -0.34263
[32m[0906 23-49-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08983, current rewards: -334.82671, mean: -0.36794
[32m[0906 23-49-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08967, current rewards: -374.56771, mean: -0.39017
[32m[0906 23-49-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08941, current rewards: -424.56771, mean: -0.42036
[32m[0906 23-49-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08959, current rewards: -471.12360, mean: -0.44446
[32m[0906 23-49-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08935, current rewards: -492.16494, mean: -0.44339
[32m[0906 23-49-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08936, current rewards: -500.41409, mean: -0.43139
[32m[0906 23-49-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08959, current rewards: -531.07296, mean: -0.43890
[32m[0906 23-49-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08950, current rewards: -573.85460, mean: -0.45544
[32m[0906 23-49-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08966, current rewards: -616.77713, mean: -0.47082
[32m[0906 23-49-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08980, current rewards: -657.97426, mean: -0.48380
[32m[0906 23-49-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08974, current rewards: -702.93667, mean: -0.49854
[32m[0906 23-49-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08974, current rewards: -752.93404, mean: -0.51571
[32m[0906 23-50-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08985, current rewards: -794.51308, mean: -0.52617
[32m[0906 23-50-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08976, current rewards: -831.87367, mean: -0.53325
[32m[0906 23-50-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08970, current rewards: -870.78983, mean: -0.54086
[32m[0906 23-50-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08955, current rewards: -917.41410, mean: -0.55266
[32m[0906 23-50-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08939, current rewards: -967.41410, mean: -0.56574
[32m[0906 23-50-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08925, current rewards: -1017.41410, mean: -0.57808
[32m[0906 23-50-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08912, current rewards: -1067.41410, mean: -0.58973
[32m[0906 23-50-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08906, current rewards: -1117.41410, mean: -0.60076
[32m[0906 23-50-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08901, current rewards: -1167.41410, mean: -0.61121
[32m[0906 23-50-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08896, current rewards: -1217.41410, mean: -0.62113
[32m[0906 23-50-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08892, current rewards: -1267.41410, mean: -0.63055
[32m[0906 23-50-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08888, current rewards: -1317.41410, mean: -0.63952
[32m[0906 23-50-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08884, current rewards: -1367.41410, mean: -0.64806
[32m[0906 23-51-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08879, current rewards: -1417.41410, mean: -0.65621
[32m[0906 23-51-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08875, current rewards: -1467.41410, mean: -0.66399
[32m[0906 23-51-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08867, current rewards: -1517.41410, mean: -0.67142
[32m[0906 23-51-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08858, current rewards: -1567.41410, mean: -0.67853
[32m[0906 23-51-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08850, current rewards: -1617.41410, mean: -0.68534
[32m[0906 23-51-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08842, current rewards: -1649.28812, mean: -0.68435
[32m[0906 23-51-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08834, current rewards: -1644.67335, mean: -0.66857
[32m[0906 23-51-29 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0906 23-51-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-51-30 @MBExp.py:227][0m Rewards obtained: [-1640.9815282208724], Lows: [185], Highs: [1401], Total time: 25925.94605100001
[32m[0906 23-54-33 @MBExp.py:144][0m ####################################################################
[32m[0906 23-54-33 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 23-54-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08990, current rewards: -4.72703, mean: -0.47270
[32m[0906 23-54-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08973, current rewards: 0.38407, mean: 0.00640
[32m[0906 23-54-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08977, current rewards: 5.68762, mean: 0.05171
[32m[0906 23-54-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08972, current rewards: 10.98855, mean: 0.06868
[32m[0906 23-54-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08971, current rewards: 16.29757, mean: 0.07761
[32m[0906 23-54-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08964, current rewards: 21.60288, mean: 0.08309
[32m[0906 23-55-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08966, current rewards: 26.90518, mean: 0.08679
[32m[0906 23-55-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08968, current rewards: 32.33782, mean: 0.08983
[32m[0906 23-55-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08967, current rewards: 37.62397, mean: 0.09177
[32m[0906 23-55-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08932, current rewards: 42.91538, mean: 0.09329
[32m[0906 23-55-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08884, current rewards: 48.20575, mean: 0.09452
[32m[0906 23-55-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08850, current rewards: 42.90194, mean: 0.07661
[32m[0906 23-55-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08819, current rewards: 48.24420, mean: 0.07909
[32m[0906 23-55-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08794, current rewards: 53.51973, mean: 0.08109
[32m[0906 23-55-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08769, current rewards: 58.79821, mean: 0.08281
[32m[0906 23-55-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08751, current rewards: 64.48004, mean: 0.08484
[32m[0906 23-55-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08733, current rewards: 69.79688, mean: 0.08617
[32m[0906 23-55-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08718, current rewards: 75.11224, mean: 0.08734
[32m[0906 23-55-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08703, current rewards: 80.43153, mean: 0.08839
[32m[0906 23-55-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08692, current rewards: 85.75090, mean: 0.08932
[32m[0906 23-56-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08681, current rewards: 91.06512, mean: 0.09016
[32m[0906 23-56-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08671, current rewards: 84.30155, mean: 0.07953
[32m[0906 23-56-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08662, current rewards: 91.10551, mean: 0.08208
[32m[0906 23-56-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08653, current rewards: 98.59994, mean: 0.08500
[32m[0906 23-56-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08657, current rewards: 101.96502, mean: 0.08427
[32m[0906 23-56-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08663, current rewards: 105.02846, mean: 0.08336
[32m[0906 23-56-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08664, current rewards: 112.16038, mean: 0.08562
[32m[0906 23-56-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08677, current rewards: 114.39308, mean: 0.08411
[32m[0906 23-56-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08685, current rewards: 117.81388, mean: 0.08356
[32m[0906 23-56-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08697, current rewards: 124.62222, mean: 0.08536
[32m[0906 23-56-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08712, current rewards: 120.16784, mean: 0.07958
[32m[0906 23-56-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08704, current rewards: 124.77294, mean: 0.07998
[32m[0906 23-56-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08695, current rewards: 129.82282, mean: 0.08064
[32m[0906 23-56-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08688, current rewards: 135.22017, mean: 0.08146
[32m[0906 23-57-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08682, current rewards: 140.74920, mean: 0.08231
[32m[0906 23-57-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08675, current rewards: 138.23421, mean: 0.07854
[32m[0906 23-57-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08670, current rewards: 143.92271, mean: 0.07952
[32m[0906 23-57-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08668, current rewards: 149.61210, mean: 0.08044
[32m[0906 23-57-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08669, current rewards: 155.29487, mean: 0.08131
[32m[0906 23-57-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08669, current rewards: 160.92657, mean: 0.08211
[32m[0906 23-57-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08670, current rewards: 166.41286, mean: 0.08279
[32m[0906 23-57-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08670, current rewards: 172.11374, mean: 0.08355
[32m[0906 23-57-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08670, current rewards: 177.81354, mean: 0.08427
[32m[0906 23-57-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08670, current rewards: 165.36660, mean: 0.07656
[32m[0906 23-57-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08671, current rewards: 171.32835, mean: 0.07752
[32m[0906 23-57-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08670, current rewards: 177.30429, mean: 0.07845
[32m[0906 23-57-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08666, current rewards: 183.26497, mean: 0.07934
[32m[0906 23-57-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08662, current rewards: 189.23499, mean: 0.08018
[32m[0906 23-58-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08658, current rewards: 194.90991, mean: 0.08088
[32m[0906 23-58-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08654, current rewards: 200.83926, mean: 0.08164
[32m[0906 23-58-10 @Agent.py:117][0m Average action selection time: 0.0865
[32m[0906 23-58-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-58-10 @MBExp.py:227][0m Rewards obtained: [205.57285970402236], Lows: [33], Highs: [17], Total time: 26142.95680800001
[32m[0907 00-01-16 @MBExp.py:144][0m ####################################################################
[32m[0907 00-01-16 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 00-01-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08879, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-01-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09252, current rewards: -48.56248, mean: -0.80937
[32m[0907 00-01-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09109, current rewards: -78.96339, mean: -0.71785
[32m[0907 00-01-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09169, current rewards: -107.27120, mean: -0.67045
[32m[0907 00-01-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09146, current rewards: -141.24376, mean: -0.67259
[32m[0907 00-01-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09309, current rewards: -177.47516, mean: -0.68260
[32m[0907 00-01-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09374, current rewards: -207.31318, mean: -0.66875
[32m[0907 00-01-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09315, current rewards: -251.96006, mean: -0.69989
[32m[0907 00-01-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09272, current rewards: -301.96006, mean: -0.73649
[32m[0907 00-01-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09334, current rewards: -334.76643, mean: -0.72775
[32m[0907 00-02-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09386, current rewards: -346.81471, mean: -0.68003
[32m[0907 00-02-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09382, current rewards: -377.77997, mean: -0.67461
[32m[0907 00-02-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09401, current rewards: -402.16120, mean: -0.65928
[32m[0907 00-02-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09419, current rewards: -436.61932, mean: -0.66154
[32m[0907 00-02-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09420, current rewards: -460.03758, mean: -0.64794
[32m[0907 00-02-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09431, current rewards: -499.21599, mean: -0.65686
[32m[0907 00-02-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09445, current rewards: -521.39727, mean: -0.64370
[32m[0907 00-02-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09449, current rewards: -550.50700, mean: -0.64012
[32m[0907 00-02-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09398, current rewards: -599.45855, mean: -0.65875
[32m[0907 00-02-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09348, current rewards: -649.45855, mean: -0.67652
[32m[0907 00-02-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09304, current rewards: -699.45855, mean: -0.69253
[32m[0907 00-02-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09265, current rewards: -749.45855, mean: -0.70704
[32m[0907 00-02-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09230, current rewards: -799.45855, mean: -0.72023
[32m[0907 00-03-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09197, current rewards: -843.13606, mean: -0.72684
[32m[0907 00-03-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09176, current rewards: -875.17056, mean: -0.72328
[32m[0907 00-03-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09160, current rewards: -909.35665, mean: -0.72171
[32m[0907 00-03-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09139, current rewards: -943.53800, mean: -0.72026
[32m[0907 00-03-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09130, current rewards: -976.64743, mean: -0.71812
[32m[0907 00-03-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09111, current rewards: -1000.57417, mean: -0.70963
[32m[0907 00-03-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09088, current rewards: -996.33024, mean: -0.68242
[32m[0907 00-03-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09067, current rewards: -992.06466, mean: -0.65700
[32m[0907 00-03-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09047, current rewards: -987.97046, mean: -0.63331
[32m[0907 00-03-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09030, current rewards: -983.70406, mean: -0.61100
[32m[0907 00-03-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09013, current rewards: -979.60279, mean: -0.59012
[32m[0907 00-03-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08996, current rewards: -975.49079, mean: -0.57046
[32m[0907 00-03-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08980, current rewards: -971.40636, mean: -0.55194
[32m[0907 00-03-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08966, current rewards: -967.27669, mean: -0.53441
[32m[0907 00-04-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08957, current rewards: -963.16970, mean: -0.51783
[32m[0907 00-04-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08951, current rewards: -959.04741, mean: -0.50212
[32m[0907 00-04-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08944, current rewards: -954.93311, mean: -0.48721
[32m[0907 00-04-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08957, current rewards: -966.40024, mean: -0.48080
[32m[0907 00-04-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08982, current rewards: -1003.51336, mean: -0.48714
[32m[0907 00-04-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09006, current rewards: -1034.03825, mean: -0.49007
[32m[0907 00-04-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09033, current rewards: -1059.57767, mean: -0.49055
[32m[0907 00-04-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09050, current rewards: -1094.64174, mean: -0.49531
[32m[0907 00-04-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09059, current rewards: -1133.85144, mean: -0.50170
[32m[0907 00-04-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09076, current rewards: -1170.93227, mean: -0.50690
[32m[0907 00-04-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09069, current rewards: -1187.40389, mean: -0.50314
[32m[0907 00-04-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09056, current rewards: -1181.70508, mean: -0.49033
[32m[0907 00-04-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09051, current rewards: -1221.96501, mean: -0.49673
[32m[0907 00-05-03 @Agent.py:117][0m Average action selection time: 0.0905
[32m[0907 00-05-03 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-05-03 @MBExp.py:227][0m Rewards obtained: [-1221.323408933491], Lows: [94], Highs: [1146], Total time: 26369.83581900001
[32m[0907 00-08-11 @MBExp.py:144][0m ####################################################################
[32m[0907 00-08-11 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 00-08-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09053, current rewards: -8.94814, mean: -0.89481
[32m[0907 00-08-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09583, current rewards: -38.23912, mean: -0.63732
[32m[0907 00-08-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09747, current rewards: -78.17940, mean: -0.71072
[32m[0907 00-08-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09539, current rewards: -102.25090, mean: -0.63907
[32m[0907 00-08-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09566, current rewards: -141.11291, mean: -0.67197
[32m[0907 00-08-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09538, current rewards: -170.55449, mean: -0.65598
[32m[0907 00-08-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09483, current rewards: -191.14989, mean: -0.61661
[32m[0907 00-08-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09437, current rewards: -221.86282, mean: -0.61629
[32m[0907 00-08-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09397, current rewards: -247.47138, mean: -0.60359
[32m[0907 00-08-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09358, current rewards: -260.51592, mean: -0.56634
[32m[0907 00-08-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09376, current rewards: -283.44176, mean: -0.55577
[32m[0907 00-09-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09349, current rewards: -302.12892, mean: -0.53952
[32m[0907 00-09-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09351, current rewards: -327.08252, mean: -0.53620
[32m[0907 00-09-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09365, current rewards: -356.76964, mean: -0.54056
[32m[0907 00-09-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09333, current rewards: -404.06884, mean: -0.56911
[32m[0907 00-09-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09271, current rewards: -504.06884, mean: -0.66325
[32m[0907 00-09-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09222, current rewards: -604.06884, mean: -0.74576
[32m[0907 00-09-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09179, current rewards: -704.06884, mean: -0.81868
[32m[0907 00-09-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09137, current rewards: -804.06884, mean: -0.88359
[32m[0907 00-09-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09101, current rewards: -904.06884, mean: -0.94174
[32m[0907 00-09-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09068, current rewards: -1004.06884, mean: -0.99413
[32m[0907 00-09-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09040, current rewards: -1104.06884, mean: -1.04157
[32m[0907 00-09-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09014, current rewards: -1204.06884, mean: -1.08475
[32m[0907 00-09-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08991, current rewards: -1304.06884, mean: -1.12420
[32m[0907 00-09-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08967, current rewards: -1404.06884, mean: -1.16039
[32m[0907 00-10-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08946, current rewards: -1504.06884, mean: -1.19371
[32m[0907 00-10-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08927, current rewards: -1604.06884, mean: -1.22448
[32m[0907 00-10-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08910, current rewards: -1704.06884, mean: -1.25299
[32m[0907 00-10-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08895, current rewards: -1804.06884, mean: -1.27948
[32m[0907 00-10-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08881, current rewards: -1904.06884, mean: -1.30416
[32m[0907 00-10-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08866, current rewards: -2004.06884, mean: -1.32720
[32m[0907 00-10-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08853, current rewards: -2104.06884, mean: -1.34876
[32m[0907 00-10-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08841, current rewards: -2204.06884, mean: -1.36899
[32m[0907 00-10-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08828, current rewards: -2304.06884, mean: -1.38799
[32m[0907 00-10-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08818, current rewards: -2404.06884, mean: -1.40589
[32m[0907 00-10-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08809, current rewards: -2504.06884, mean: -1.42277
[32m[0907 00-10-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08807, current rewards: -2604.06884, mean: -1.43871
[32m[0907 00-10-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08803, current rewards: -2704.06884, mean: -1.45380
[32m[0907 00-10-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08801, current rewards: -2804.06884, mean: -1.46810
[32m[0907 00-11-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08798, current rewards: -2904.06884, mean: -1.48167
[32m[0907 00-11-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08795, current rewards: -3004.06884, mean: -1.49456
[32m[0907 00-11-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08793, current rewards: -3104.06884, mean: -1.50683
[32m[0907 00-11-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08790, current rewards: -3204.06884, mean: -1.51852
[32m[0907 00-11-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08786, current rewards: -3304.06884, mean: -1.52966
[32m[0907 00-11-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08779, current rewards: -3404.06884, mean: -1.54030
[32m[0907 00-11-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08772, current rewards: -3504.06884, mean: -1.55047
[32m[0907 00-11-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08766, current rewards: -3604.06884, mean: -1.56020
[32m[0907 00-11-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08759, current rewards: -3704.06884, mean: -1.56952
[32m[0907 00-11-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08753, current rewards: -3804.06884, mean: -1.57845
[32m[0907 00-11-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08747, current rewards: -3904.06884, mean: -1.58702
[32m[0907 00-11-50 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0907 00-11-50 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-11-50 @MBExp.py:227][0m Rewards obtained: [-3984.068841595936], Lows: [1947], Highs: [146], Total time: 26589.14531900001
[32m[0907 00-14-59 @MBExp.py:144][0m ####################################################################
[32m[0907 00-14-59 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 00-15-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09176, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-15-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08961, current rewards: -14.26965, mean: -0.23783
[32m[0907 00-15-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08956, current rewards: -9.66028, mean: -0.08782
[32m[0907 00-15-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08965, current rewards: -5.04400, mean: -0.03153
[32m[0907 00-15-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08963, current rewards: -0.41803, mean: -0.00199
[32m[0907 00-15-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08961, current rewards: 4.21198, mean: 0.01620
[32m[0907 00-15-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08956, current rewards: 8.82593, mean: 0.02847
[32m[0907 00-15-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08899, current rewards: 13.57626, mean: 0.03771
[32m[0907 00-15-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08845, current rewards: 18.16182, mean: 0.04430
[32m[0907 00-15-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08805, current rewards: 22.74443, mean: 0.04944
[32m[0907 00-15-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08797, current rewards: 10.32027, mean: 0.02024
[32m[0907 00-15-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08769, current rewards: -33.18577, mean: -0.05926
[32m[0907 00-15-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08740, current rewards: -83.18577, mean: -0.13637
[32m[0907 00-15-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08717, current rewards: -133.18577, mean: -0.20180
[32m[0907 00-16-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08698, current rewards: -183.18577, mean: -0.25801
[32m[0907 00-16-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08683, current rewards: -233.18577, mean: -0.30682
[32m[0907 00-16-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08666, current rewards: -283.18577, mean: -0.34961
[32m[0907 00-16-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08655, current rewards: -333.18577, mean: -0.38743
[32m[0907 00-16-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08644, current rewards: -383.18577, mean: -0.42108
[32m[0907 00-16-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08634, current rewards: -433.18577, mean: -0.45124
[32m[0907 00-16-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08624, current rewards: -483.18577, mean: -0.47840
[32m[0907 00-16-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08616, current rewards: -533.18577, mean: -0.50301
[32m[0907 00-16-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08609, current rewards: -583.18577, mean: -0.52539
[32m[0907 00-16-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08602, current rewards: -633.18577, mean: -0.54585
[32m[0907 00-16-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08595, current rewards: -683.18577, mean: -0.56462
[32m[0907 00-16-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08589, current rewards: -733.18577, mean: -0.58189
[32m[0907 00-16-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08585, current rewards: -783.18577, mean: -0.59785
[32m[0907 00-16-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08579, current rewards: -833.18577, mean: -0.61264
[32m[0907 00-17-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08576, current rewards: -883.18577, mean: -0.62637
[32m[0907 00-17-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08572, current rewards: -933.18577, mean: -0.63917
[32m[0907 00-17-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08568, current rewards: -983.18577, mean: -0.65112
[32m[0907 00-17-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08565, current rewards: -1033.18577, mean: -0.66230
[32m[0907 00-17-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08561, current rewards: -1038.94454, mean: -0.64531
[32m[0907 00-17-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08557, current rewards: -1064.71126, mean: -0.64139
[32m[0907 00-17-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08553, current rewards: -1114.71126, mean: -0.65188
[32m[0907 00-17-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08551, current rewards: -1164.71126, mean: -0.66177
[32m[0907 00-17-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08548, current rewards: -1214.71126, mean: -0.67111
[32m[0907 00-17-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08549, current rewards: -1264.71126, mean: -0.67995
[32m[0907 00-17-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08554, current rewards: -1314.71126, mean: -0.68833
[32m[0907 00-17-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08557, current rewards: -1364.71126, mean: -0.69628
[32m[0907 00-17-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08561, current rewards: -1414.71126, mean: -0.70384
[32m[0907 00-17-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08565, current rewards: -1464.71126, mean: -0.71102
[32m[0907 00-18-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08568, current rewards: -1514.71126, mean: -0.71787
[32m[0907 00-18-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08572, current rewards: -1564.71126, mean: -0.72440
[32m[0907 00-18-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08574, current rewards: -1614.71126, mean: -0.73064
[32m[0907 00-18-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08571, current rewards: -1664.71126, mean: -0.73660
[32m[0907 00-18-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08569, current rewards: -1714.71126, mean: -0.74230
[32m[0907 00-18-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08567, current rewards: -1764.71126, mean: -0.74776
[32m[0907 00-18-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08565, current rewards: -1814.71126, mean: -0.75299
[32m[0907 00-18-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08563, current rewards: -1864.71126, mean: -0.75801
[32m[0907 00-18-34 @Agent.py:117][0m Average action selection time: 0.0856
[32m[0907 00-18-34 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-18-34 @MBExp.py:227][0m Rewards obtained: [-1904.7112567333654], Lows: [5], Highs: [1943], Total time: 26803.93112300001
[32m[0907 00-21-45 @MBExp.py:144][0m ####################################################################
[32m[0907 00-21-45 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 00-21-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10044, current rewards: -12.90839, mean: -1.29084
[32m[0907 00-21-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10913, current rewards: -44.40316, mean: -0.74005
[32m[0907 00-21-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10034, current rewards: -93.20383, mean: -0.84731
[32m[0907 00-22-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10043, current rewards: -154.20383, mean: -0.96377
[32m[0907 00-22-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10170, current rewards: -209.88896, mean: -0.99947
[32m[0907 00-22-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10274, current rewards: -249.92688, mean: -0.96126
[32m[0907 00-22-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10371, current rewards: -282.14688, mean: -0.91015
[32m[0907 00-22-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10296, current rewards: -297.55734, mean: -0.82655
[32m[0907 00-22-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10300, current rewards: -326.01496, mean: -0.79516
[32m[0907 00-22-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10270, current rewards: -355.46620, mean: -0.77275
[32m[0907 00-22-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10091, current rewards: -392.68234, mean: -0.76997
[32m[0907 00-22-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09946, current rewards: -442.68234, mean: -0.79050
[32m[0907 00-22-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09823, current rewards: -492.68234, mean: -0.80768
[32m[0907 00-22-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09722, current rewards: -542.68234, mean: -0.82225
[32m[0907 00-22-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09632, current rewards: -592.68234, mean: -0.83476
[32m[0907 00-22-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09557, current rewards: -642.68234, mean: -0.84563
[32m[0907 00-23-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09489, current rewards: -692.68234, mean: -0.85516
[32m[0907 00-23-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09429, current rewards: -742.68234, mean: -0.86358
[32m[0907 00-23-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09374, current rewards: -792.68234, mean: -0.87108
[32m[0907 00-23-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09326, current rewards: -842.68234, mean: -0.87779
[32m[0907 00-23-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09285, current rewards: -892.68234, mean: -0.88384
[32m[0907 00-23-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09248, current rewards: -942.68234, mean: -0.88932
[32m[0907 00-23-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09214, current rewards: -992.68234, mean: -0.89431
[32m[0907 00-23-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09182, current rewards: -1042.68234, mean: -0.89886
[32m[0907 00-23-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09154, current rewards: -1092.68234, mean: -0.90304
[32m[0907 00-23-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09126, current rewards: -1142.68234, mean: -0.90689
[32m[0907 00-23-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09102, current rewards: -1192.68234, mean: -0.91044
[32m[0907 00-23-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09077, current rewards: -1242.68234, mean: -0.91374
[32m[0907 00-23-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09058, current rewards: -1292.68234, mean: -0.91680
[32m[0907 00-23-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09037, current rewards: -1342.68234, mean: -0.91965
[32m[0907 00-24-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09017, current rewards: -1392.68234, mean: -0.92231
[32m[0907 00-24-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08999, current rewards: -1442.68234, mean: -0.92480
[32m[0907 00-24-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08983, current rewards: -1492.68234, mean: -0.92713
[32m[0907 00-24-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08969, current rewards: -1542.68234, mean: -0.92933
[32m[0907 00-24-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08955, current rewards: -1592.68234, mean: -0.93139
[32m[0907 00-24-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08940, current rewards: -1642.68234, mean: -0.93334
[32m[0907 00-24-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08928, current rewards: -1692.68234, mean: -0.93518
[32m[0907 00-24-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08922, current rewards: -1742.68234, mean: -0.93693
[32m[0907 00-24-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08917, current rewards: -1792.68234, mean: -0.93858
[32m[0907 00-24-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08912, current rewards: -1842.68234, mean: -0.94014
[32m[0907 00-24-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08908, current rewards: -1892.68234, mean: -0.94163
[32m[0907 00-24-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08902, current rewards: -1942.68234, mean: -0.94305
[32m[0907 00-24-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08897, current rewards: -1992.68234, mean: -0.94440
[32m[0907 00-24-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08892, current rewards: -2042.68234, mean: -0.94569
[32m[0907 00-25-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08889, current rewards: -2092.68234, mean: -0.94692
[32m[0907 00-25-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08880, current rewards: -2142.68234, mean: -0.94809
[32m[0907 00-25-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08871, current rewards: -2192.68234, mean: -0.94921
[32m[0907 00-25-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08863, current rewards: -2242.68234, mean: -0.95029
[32m[0907 00-25-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08855, current rewards: -2292.68234, mean: -0.95132
[32m[0907 00-25-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08847, current rewards: -2342.68234, mean: -0.95231
[32m[0907 00-25-27 @Agent.py:117][0m Average action selection time: 0.0884
[32m[0907 00-25-27 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-25-27 @MBExp.py:227][0m Rewards obtained: [-2382.682342194228], Lows: [128], Highs: [2155], Total time: 27025.69617800001
[32m[0907 00-28-40 @MBExp.py:144][0m ####################################################################
[32m[0907 00-28-40 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 00-28-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08918, current rewards: -15.00000, mean: -1.50000
[32m[0907 00-28-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09191, current rewards: -16.24012, mean: -0.27067
[32m[0907 00-28-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09240, current rewards: -14.46454, mean: -0.13150
[32m[0907 00-28-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09151, current rewards: -8.74766, mean: -0.05467
[32m[0907 00-28-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09174, current rewards: -2.20370, mean: -0.01049
[32m[0907 00-29-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09131, current rewards: 3.82426, mean: 0.01471
[32m[0907 00-29-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09150, current rewards: 7.46155, mean: 0.02407
[32m[0907 00-29-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09103, current rewards: -21.87401, mean: -0.06076
[32m[0907 00-29-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09053, current rewards: -66.58014, mean: -0.16239
[32m[0907 00-29-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09007, current rewards: -114.48003, mean: -0.24887
[32m[0907 00-29-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08949, current rewards: -159.19221, mean: -0.31214
[32m[0907 00-29-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08905, current rewards: -184.16274, mean: -0.32886
[32m[0907 00-29-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08868, current rewards: -180.12120, mean: -0.29528
[32m[0907 00-29-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08837, current rewards: -176.07967, mean: -0.26679
[32m[0907 00-29-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08809, current rewards: -172.03813, mean: -0.24231
[32m[0907 00-29-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08785, current rewards: -175.81987, mean: -0.23134
[32m[0907 00-29-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08764, current rewards: -225.81987, mean: -0.27879
[32m[0907 00-29-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08744, current rewards: -275.81987, mean: -0.32072
[32m[0907 00-29-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08727, current rewards: -325.81987, mean: -0.35804
[32m[0907 00-30-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08710, current rewards: -375.81987, mean: -0.39148
[32m[0907 00-30-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08697, current rewards: -425.81987, mean: -0.42160
[32m[0907 00-30-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08685, current rewards: -475.81987, mean: -0.44889
[32m[0907 00-30-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08673, current rewards: -525.81987, mean: -0.47371
[32m[0907 00-30-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08664, current rewards: -575.81987, mean: -0.49640
[32m[0907 00-30-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08656, current rewards: -577.52287, mean: -0.47729
[32m[0907 00-30-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08647, current rewards: -575.02432, mean: -0.45637
[32m[0907 00-30-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08640, current rewards: -612.42466, mean: -0.46750
[32m[0907 00-30-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08632, current rewards: -662.42466, mean: -0.48708
[32m[0907 00-30-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08625, current rewards: -712.42466, mean: -0.50527
[32m[0907 00-30-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08618, current rewards: -762.42466, mean: -0.52221
[32m[0907 00-30-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08613, current rewards: -812.42466, mean: -0.53803
[32m[0907 00-30-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08608, current rewards: -862.42466, mean: -0.55284
[32m[0907 00-30-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08604, current rewards: -912.42466, mean: -0.56672
[32m[0907 00-31-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08600, current rewards: -962.42466, mean: -0.57977
[32m[0907 00-31-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08594, current rewards: -1012.42466, mean: -0.59206
[32m[0907 00-31-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08589, current rewards: -1062.42466, mean: -0.60365
[32m[0907 00-31-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08586, current rewards: -1112.42466, mean: -0.61460
[32m[0907 00-31-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08583, current rewards: -1162.42466, mean: -0.62496
[32m[0907 00-31-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08584, current rewards: -1212.42466, mean: -0.63478
[32m[0907 00-31-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08588, current rewards: -1262.42466, mean: -0.64409
[32m[0907 00-31-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08590, current rewards: -1312.42466, mean: -0.65295
[32m[0907 00-31-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08593, current rewards: -1362.42466, mean: -0.66137
[32m[0907 00-31-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08595, current rewards: -1412.42466, mean: -0.66940
[32m[0907 00-31-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08598, current rewards: -1462.42466, mean: -0.67705
[32m[0907 00-31-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08600, current rewards: -1512.42466, mean: -0.68436
[32m[0907 00-31-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08602, current rewards: -1562.42466, mean: -0.69134
[32m[0907 00-31-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08604, current rewards: -1612.42466, mean: -0.69802
[32m[0907 00-32-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08607, current rewards: -1662.42466, mean: -0.70442
[32m[0907 00-32-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08609, current rewards: -1712.42466, mean: -0.71055
[32m[0907 00-32-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08611, current rewards: -1762.42466, mean: -0.71643
[32m[0907 00-32-16 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 00-32-16 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-32-16 @MBExp.py:227][0m Rewards obtained: [-1802.424663240924], Lows: [18], Highs: [1829], Total time: 27241.62849200001
[32m[0907 00-35-31 @MBExp.py:144][0m ####################################################################
[32m[0907 00-35-31 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 00-35-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08900, current rewards: -15.00000, mean: -1.50000
[32m[0907 00-35-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08944, current rewards: -37.24279, mean: -0.62071
[32m[0907 00-35-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08939, current rewards: -63.43577, mean: -0.57669
[32m[0907 00-35-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08996, current rewards: -92.19904, mean: -0.57624
[32m[0907 00-35-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09055, current rewards: -115.71498, mean: -0.55102
[32m[0907 00-35-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09035, current rewards: -138.67600, mean: -0.53337
[32m[0907 00-35-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09044, current rewards: -155.85157, mean: -0.50275
[32m[0907 00-36-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09047, current rewards: -200.17467, mean: -0.55604
[32m[0907 00-36-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09050, current rewards: -232.62416, mean: -0.56738
[32m[0907 00-36-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09006, current rewards: -240.79145, mean: -0.52346
[32m[0907 00-36-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08950, current rewards: -234.75601, mean: -0.46031
[32m[0907 00-36-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08905, current rewards: -228.71643, mean: -0.40842
[32m[0907 00-36-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08867, current rewards: -222.68040, mean: -0.36505
[32m[0907 00-36-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08836, current rewards: -216.64285, mean: -0.32825
[32m[0907 00-36-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08809, current rewards: -210.60050, mean: -0.29662
[32m[0907 00-36-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08786, current rewards: -203.35540, mean: -0.26757
[32m[0907 00-36-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08765, current rewards: -197.56330, mean: -0.24391
[32m[0907 00-36-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08750, current rewards: -191.77881, mean: -0.22300
[32m[0907 00-36-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08733, current rewards: -191.59939, mean: -0.21055
[32m[0907 00-36-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08719, current rewards: -185.90414, mean: -0.19365
[32m[0907 00-36-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08706, current rewards: -180.24388, mean: -0.17846
[32m[0907 00-37-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08696, current rewards: -174.58308, mean: -0.16470
[32m[0907 00-37-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08687, current rewards: -168.93274, mean: -0.15219
[32m[0907 00-37-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08679, current rewards: -163.33839, mean: -0.14081
[32m[0907 00-37-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08671, current rewards: -157.68764, mean: -0.13032
[32m[0907 00-37-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08663, current rewards: -151.98564, mean: -0.12062
[32m[0907 00-37-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08655, current rewards: -146.29079, mean: -0.11167
[32m[0907 00-37-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08648, current rewards: -140.59442, mean: -0.10338
[32m[0907 00-37-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08641, current rewards: -133.62080, mean: -0.09477
[32m[0907 00-37-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08636, current rewards: -125.50009, mean: -0.08596
[32m[0907 00-37-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08630, current rewards: -117.46169, mean: -0.07779
[32m[0907 00-37-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08625, current rewards: -109.42278, mean: -0.07014
[32m[0907 00-37-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08620, current rewards: -102.13398, mean: -0.06344
[32m[0907 00-37-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08614, current rewards: -94.55406, mean: -0.05696
[32m[0907 00-37-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08609, current rewards: -86.97976, mean: -0.05087
[32m[0907 00-38-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08605, current rewards: -79.38350, mean: -0.04510
[32m[0907 00-38-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08600, current rewards: -71.80459, mean: -0.03967
[32m[0907 00-38-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08597, current rewards: -106.80438, mean: -0.05742
[32m[0907 00-38-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08593, current rewards: -143.68171, mean: -0.07523
[32m[0907 00-38-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08597, current rewards: -180.91050, mean: -0.09230
[32m[0907 00-38-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08600, current rewards: -206.13470, mean: -0.10255
[32m[0907 00-38-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08603, current rewards: -195.04907, mean: -0.09468
[32m[0907 00-38-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08609, current rewards: -194.51610, mean: -0.09219
[32m[0907 00-38-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08611, current rewards: -187.98389, mean: -0.08703
[32m[0907 00-38-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08613, current rewards: -181.79626, mean: -0.08226
[32m[0907 00-38-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08615, current rewards: -175.61233, mean: -0.07770
[32m[0907 00-38-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08616, current rewards: -169.42596, mean: -0.07334
[32m[0907 00-38-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08617, current rewards: -163.25401, mean: -0.06918
[32m[0907 00-38-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08619, current rewards: -156.71345, mean: -0.06503
[32m[0907 00-39-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08619, current rewards: -139.27318, mean: -0.05662
[32m[0907 00-39-07 @Agent.py:117][0m Average action selection time: 0.0862
[32m[0907 00-39-07 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-39-07 @MBExp.py:227][0m Rewards obtained: [-125.66284438514231], Lows: [216], Highs: [25], Total time: 27457.77614400001
[32m[0907 00-42-23 @MBExp.py:144][0m ####################################################################
[32m[0907 00-42-23 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 00-42-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08895, current rewards: -5.65473, mean: -0.56547
[32m[0907 00-42-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08953, current rewards: -21.12631, mean: -0.35211
[32m[0907 00-42-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08947, current rewards: -36.96896, mean: -0.33608
[32m[0907 00-42-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08954, current rewards: -46.26550, mean: -0.28916
[32m[0907 00-42-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08994, current rewards: -62.18597, mean: -0.29612
[32m[0907 00-42-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08989, current rewards: -67.84200, mean: -0.26093
[32m[0907 00-42-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08981, current rewards: -75.43342, mean: -0.24333
[32m[0907 00-42-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08977, current rewards: -85.21954, mean: -0.23672
[32m[0907 00-43-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08983, current rewards: -84.21553, mean: -0.20540
[32m[0907 00-43-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08970, current rewards: -84.55144, mean: -0.18381
[32m[0907 00-43-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08917, current rewards: -93.53455, mean: -0.18340
[32m[0907 00-43-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08899, current rewards: -101.88788, mean: -0.18194
[32m[0907 00-43-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08862, current rewards: -95.56749, mean: -0.15667
[32m[0907 00-43-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08833, current rewards: -89.23549, mean: -0.13521
[32m[0907 00-43-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08810, current rewards: -83.04567, mean: -0.11697
[32m[0907 00-43-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08788, current rewards: -76.76761, mean: -0.10101
[32m[0907 00-43-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08768, current rewards: -70.07813, mean: -0.08652
[32m[0907 00-43-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08751, current rewards: -63.38567, mean: -0.07370
[32m[0907 00-43-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08734, current rewards: -68.66594, mean: -0.07546
[32m[0907 00-43-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08720, current rewards: -61.43329, mean: -0.06399
[32m[0907 00-43-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08706, current rewards: -54.19054, mean: -0.05365
[32m[0907 00-43-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08696, current rewards: -46.96388, mean: -0.04431
[32m[0907 00-44-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08685, current rewards: -39.73384, mean: -0.03580
[32m[0907 00-44-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08676, current rewards: -31.83591, mean: -0.02744
[32m[0907 00-44-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08667, current rewards: -25.12282, mean: -0.02076
[32m[0907 00-44-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08659, current rewards: -18.40780, mean: -0.01461
[32m[0907 00-44-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08651, current rewards: -11.69601, mean: -0.00893
[32m[0907 00-44-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08644, current rewards: -4.98502, mean: -0.00367
[32m[0907 00-44-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08635, current rewards: 1.72157, mean: 0.00122
[32m[0907 00-44-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08628, current rewards: 8.43000, mean: 0.00577
[32m[0907 00-44-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08621, current rewards: 4.27693, mean: 0.00283
[32m[0907 00-44-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08615, current rewards: -33.41626, mean: -0.02142
[32m[0907 00-44-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08612, current rewards: -76.51896, mean: -0.04753
[32m[0907 00-44-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08607, current rewards: -109.09366, mean: -0.06572
[32m[0907 00-44-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08603, current rewards: -148.36089, mean: -0.08676
[32m[0907 00-44-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08599, current rewards: -191.51625, mean: -0.10882
[32m[0907 00-44-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08596, current rewards: -225.56587, mean: -0.12462
[32m[0907 00-45-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08591, current rewards: -261.06246, mean: -0.14036
[32m[0907 00-45-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08586, current rewards: -287.99531, mean: -0.15078
[32m[0907 00-45-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08583, current rewards: -281.08934, mean: -0.14341
[32m[0907 00-45-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08586, current rewards: -274.24155, mean: -0.13644
[32m[0907 00-45-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08588, current rewards: -267.39771, mean: -0.12980
[32m[0907 00-45-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08591, current rewards: -260.55072, mean: -0.12348
[32m[0907 00-45-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08599, current rewards: -268.70327, mean: -0.12440
[32m[0907 00-45-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08602, current rewards: -262.20410, mean: -0.11864
[32m[0907 00-45-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08604, current rewards: -255.71150, mean: -0.11315
[32m[0907 00-45-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08605, current rewards: -249.21849, mean: -0.10789
[32m[0907 00-45-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08607, current rewards: -242.87985, mean: -0.10292
[32m[0907 00-45-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08609, current rewards: -248.98153, mean: -0.10331
[32m[0907 00-45-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08611, current rewards: -241.65511, mean: -0.09823
[32m[0907 00-45-59 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 00-45-59 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-45-59 @MBExp.py:227][0m Rewards obtained: [-235.80043576463703], Lows: [293], Highs: [18], Total time: 27673.71487100001
[32m[0907 00-49-17 @MBExp.py:144][0m ####################################################################
[32m[0907 00-49-17 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 00-49-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08855, current rewards: -8.94085, mean: -0.89409
[32m[0907 00-49-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08938, current rewards: -8.60120, mean: -0.14335
[32m[0907 00-49-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08933, current rewards: -5.02046, mean: -0.04564
[32m[0907 00-49-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08933, current rewards: -1.43972, mean: -0.00900
[32m[0907 00-49-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08946, current rewards: 2.14102, mean: 0.01020
[32m[0907 00-49-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08945, current rewards: 5.72176, mean: 0.02201
[32m[0907 00-49-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08947, current rewards: 9.04402, mean: 0.02917
[32m[0907 00-49-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08950, current rewards: 12.33446, mean: 0.03426
[32m[0907 00-49-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08950, current rewards: 15.62490, mean: 0.03811
[32m[0907 00-49-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08935, current rewards: 18.91534, mean: 0.04112
[32m[0907 00-50-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08888, current rewards: 22.20578, mean: 0.04354
[32m[0907 00-50-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08851, current rewards: 25.49621, mean: 0.04553
[32m[0907 00-50-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08822, current rewards: 6.40467, mean: 0.01050
[32m[0907 00-50-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08799, current rewards: -43.59533, mean: -0.06605
[32m[0907 00-50-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08776, current rewards: -93.59533, mean: -0.13182
[32m[0907 00-50-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08758, current rewards: -143.59533, mean: -0.18894
[32m[0907 00-50-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08740, current rewards: -193.59533, mean: -0.23901
[32m[0907 00-50-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08724, current rewards: -243.59533, mean: -0.28325
[32m[0907 00-50-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08708, current rewards: -293.59533, mean: -0.32263
[32m[0907 00-50-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08695, current rewards: -343.59533, mean: -0.35791
[32m[0907 00-50-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08683, current rewards: -393.59533, mean: -0.38970
[32m[0907 00-50-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08671, current rewards: -443.59533, mean: -0.41849
[32m[0907 00-50-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08661, current rewards: -493.59533, mean: -0.44468
[32m[0907 00-50-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08653, current rewards: -543.59533, mean: -0.46862
[32m[0907 00-51-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08644, current rewards: -593.59533, mean: -0.49057
[32m[0907 00-51-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08636, current rewards: -643.59533, mean: -0.51079
[32m[0907 00-51-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08629, current rewards: -693.59533, mean: -0.52946
[32m[0907 00-51-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08623, current rewards: -743.59533, mean: -0.54676
[32m[0907 00-51-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08615, current rewards: -793.59533, mean: -0.56283
[32m[0907 00-51-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08610, current rewards: -843.59533, mean: -0.57781
[32m[0907 00-51-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08605, current rewards: -893.59533, mean: -0.59178
[32m[0907 00-51-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08600, current rewards: -943.59533, mean: -0.60487
[32m[0907 00-51-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08595, current rewards: -993.59533, mean: -0.61714
[32m[0907 00-51-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08592, current rewards: -1043.59533, mean: -0.62867
[32m[0907 00-51-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08588, current rewards: -1093.59533, mean: -0.63953
[32m[0907 00-51-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08585, current rewards: -1143.59533, mean: -0.64977
[32m[0907 00-51-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08582, current rewards: -1193.59533, mean: -0.65944
[32m[0907 00-51-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08578, current rewards: -1243.59533, mean: -0.66860
[32m[0907 00-52-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08573, current rewards: -1293.59533, mean: -0.67728
[32m[0907 00-52-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08569, current rewards: -1343.59533, mean: -0.68551
[32m[0907 00-52-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08569, current rewards: -1393.59533, mean: -0.69333
[32m[0907 00-52-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08572, current rewards: -1443.59533, mean: -0.70077
[32m[0907 00-52-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08575, current rewards: -1493.59533, mean: -0.70787
[32m[0907 00-52-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08578, current rewards: -1543.59533, mean: -0.71463
[32m[0907 00-52-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08581, current rewards: -1593.59533, mean: -0.72108
[32m[0907 00-52-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08583, current rewards: -1643.59533, mean: -0.72725
[32m[0907 00-52-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08585, current rewards: -1693.59533, mean: -0.73316
[32m[0907 00-52-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08587, current rewards: -1743.59533, mean: -0.73881
[32m[0907 00-52-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08589, current rewards: -1793.59533, mean: -0.74423
[32m[0907 00-52-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08591, current rewards: -1843.59533, mean: -0.74943
[32m[0907 00-52-53 @Agent.py:117][0m Average action selection time: 0.0859
[32m[0907 00-52-53 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-52-53 @MBExp.py:227][0m Rewards obtained: [-1883.5953323558101], Lows: [1], Highs: [1921], Total time: 27889.21799700001
[32m[0907 00-56-13 @MBExp.py:144][0m ####################################################################
[32m[0907 00-56-13 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 00-56-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11015, current rewards: -7.80044, mean: -0.78004
[32m[0907 00-56-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09695, current rewards: -20.15744, mean: -0.33596
[32m[0907 00-56-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09420, current rewards: -29.33177, mean: -0.26665
[32m[0907 00-56-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09405, current rewards: -44.95761, mean: -0.28099
[32m[0907 00-56-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09437, current rewards: -56.03069, mean: -0.26681
[32m[0907 00-56-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09518, current rewards: -75.75767, mean: -0.29138
[32m[0907 00-56-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09425, current rewards: -71.35311, mean: -0.23017
[32m[0907 00-56-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09355, current rewards: -66.86664, mean: -0.18574
[32m[0907 00-56-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09306, current rewards: -62.38634, mean: -0.15216
[32m[0907 00-56-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09255, current rewards: -57.90137, mean: -0.12587
[32m[0907 00-57-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09199, current rewards: -53.41820, mean: -0.10474
[32m[0907 00-57-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09154, current rewards: -78.48832, mean: -0.14016
[32m[0907 00-57-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09099, current rewards: -98.58592, mean: -0.16162
[32m[0907 00-57-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09050, current rewards: -148.58592, mean: -0.22513
[32m[0907 00-57-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09007, current rewards: -198.58592, mean: -0.27970
[32m[0907 00-57-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08970, current rewards: -248.58592, mean: -0.32709
[32m[0907 00-57-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08939, current rewards: -298.58592, mean: -0.36862
[32m[0907 00-57-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08910, current rewards: -348.58592, mean: -0.40533
[32m[0907 00-57-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08884, current rewards: -398.58592, mean: -0.43801
[32m[0907 00-57-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08867, current rewards: -418.99420, mean: -0.43645
[32m[0907 00-57-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08848, current rewards: -414.17485, mean: -0.41007
[32m[0907 00-57-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08827, current rewards: -409.39291, mean: -0.38622
[32m[0907 00-57-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08810, current rewards: -404.72734, mean: -0.36462
[32m[0907 00-57-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08794, current rewards: -399.88050, mean: -0.34472
[32m[0907 00-57-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08779, current rewards: -395.03668, mean: -0.32648
[32m[0907 00-58-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08766, current rewards: -390.20705, mean: -0.30969
[32m[0907 00-58-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08756, current rewards: -385.37518, mean: -0.29418
[32m[0907 00-58-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08744, current rewards: -380.49519, mean: -0.27978
[32m[0907 00-58-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08741, current rewards: -400.36504, mean: -0.28395
[32m[0907 00-58-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08731, current rewards: -395.15900, mean: -0.27066
[32m[0907 00-58-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08722, current rewards: -389.40541, mean: -0.25788
[32m[0907 00-58-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08712, current rewards: -384.02670, mean: -0.24617
[32m[0907 00-58-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08704, current rewards: -378.64588, mean: -0.23518
[32m[0907 00-58-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08696, current rewards: -373.28113, mean: -0.22487
[32m[0907 00-58-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08689, current rewards: -367.94537, mean: -0.21517
[32m[0907 00-58-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08682, current rewards: -362.60481, mean: -0.20603
[32m[0907 00-58-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08676, current rewards: -357.24538, mean: -0.19737
[32m[0907 00-58-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08668, current rewards: -351.88815, mean: -0.18919
[32m[0907 00-58-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08663, current rewards: -358.53714, mean: -0.18772
[32m[0907 00-59-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08659, current rewards: -355.89267, mean: -0.18158
[32m[0907 00-59-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08653, current rewards: -353.26236, mean: -0.17575
[32m[0907 00-59-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08654, current rewards: -350.54927, mean: -0.17017
[32m[0907 00-59-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08655, current rewards: -347.96867, mean: -0.16491
[32m[0907 00-59-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08656, current rewards: -345.34565, mean: -0.15988
[32m[0907 00-59-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08657, current rewards: -342.67194, mean: -0.15506
[32m[0907 00-59-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08657, current rewards: -340.10516, mean: -0.15049
[32m[0907 00-59-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08659, current rewards: -365.51283, mean: -0.15823
[32m[0907 00-59-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08661, current rewards: -365.34079, mean: -0.15481
[32m[0907 00-59-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08662, current rewards: -360.52866, mean: -0.14960
[32m[0907 00-59-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08663, current rewards: -355.71998, mean: -0.14460
[32m[0907 00-59-50 @Agent.py:117][0m Average action selection time: 0.0866
[32m[0907 00-59-50 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-59-50 @MBExp.py:227][0m Rewards obtained: [-351.8691457143415], Lows: [37], Highs: [453], Total time: 28106.49233200001
[32m[0907 01-03-12 @MBExp.py:144][0m ####################################################################
[32m[0907 01-03-12 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 01-03-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08803, current rewards: -2.63396, mean: -0.26340
[32m[0907 01-03-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08950, current rewards: -17.64896, mean: -0.29415
[32m[0907 01-03-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08950, current rewards: -37.82357, mean: -0.34385
[32m[0907 01-03-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08959, current rewards: -52.04047, mean: -0.32525
[32m[0907 01-03-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08953, current rewards: -63.09938, mean: -0.30047
[32m[0907 01-03-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08956, current rewards: -77.25995, mean: -0.29715
[32m[0907 01-03-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08959, current rewards: -104.24667, mean: -0.33628
[32m[0907 01-03-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08959, current rewards: -138.01744, mean: -0.38338
[32m[0907 01-03-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08961, current rewards: -166.11508, mean: -0.40516
[32m[0907 01-03-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08958, current rewards: -181.73458, mean: -0.39508
[32m[0907 01-03-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08930, current rewards: -207.50866, mean: -0.40688
[32m[0907 01-04-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08907, current rewards: -234.22711, mean: -0.41826
[32m[0907 01-04-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08886, current rewards: -334.22711, mean: -0.54791
[32m[0907 01-04-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08871, current rewards: -434.22711, mean: -0.65792
[32m[0907 01-04-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08859, current rewards: -534.22711, mean: -0.75243
[32m[0907 01-04-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08847, current rewards: -634.22711, mean: -0.83451
[32m[0907 01-04-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08839, current rewards: -734.22711, mean: -0.90645
[32m[0907 01-04-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08822, current rewards: -834.22711, mean: -0.97003
[32m[0907 01-04-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08803, current rewards: -934.22711, mean: -1.02662
[32m[0907 01-04-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08785, current rewards: -1034.22711, mean: -1.07732
[32m[0907 01-04-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08769, current rewards: -1134.22711, mean: -1.12300
[32m[0907 01-04-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08755, current rewards: -1234.22711, mean: -1.16437
[32m[0907 01-04-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08742, current rewards: -1316.76055, mean: -1.18627
[32m[0907 01-04-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08728, current rewards: -1383.99194, mean: -1.19310
[32m[0907 01-04-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08717, current rewards: -1441.77430, mean: -1.19155
[32m[0907 01-05-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08708, current rewards: -1503.24113, mean: -1.19305
[32m[0907 01-05-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08699, current rewards: -1553.50173, mean: -1.18588
[32m[0907 01-05-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08690, current rewards: -1619.11292, mean: -1.19052
[32m[0907 01-05-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08681, current rewards: -1684.27707, mean: -1.19452
[32m[0907 01-05-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08674, current rewards: -1751.27196, mean: -1.19950
[32m[0907 01-05-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08666, current rewards: -1818.08644, mean: -1.20403
[32m[0907 01-05-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08659, current rewards: -1860.26746, mean: -1.19248
[32m[0907 01-05-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08653, current rewards: -1850.08493, mean: -1.14912
[32m[0907 01-05-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08647, current rewards: -1839.90358, mean: -1.10838
[32m[0907 01-05-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08642, current rewards: -1829.70938, mean: -1.07001
[32m[0907 01-05-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08636, current rewards: -1819.53176, mean: -1.03382
[32m[0907 01-05-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08631, current rewards: -1809.33936, mean: -0.99964
[32m[0907 01-05-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08626, current rewards: -1799.18034, mean: -0.96730
[32m[0907 01-05-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08621, current rewards: -1799.78206, mean: -0.94229
[32m[0907 01-06-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08616, current rewards: -1804.62653, mean: -0.92073
[32m[0907 01-06-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08613, current rewards: -1847.82001, mean: -0.91931
[32m[0907 01-06-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08609, current rewards: -1887.13255, mean: -0.91608
[32m[0907 01-06-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08609, current rewards: -1928.83836, mean: -0.91414
[32m[0907 01-06-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08611, current rewards: -1972.93239, mean: -0.91339
[32m[0907 01-06-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08613, current rewards: -2017.03948, mean: -0.91269
[32m[0907 01-06-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08615, current rewards: -2058.87534, mean: -0.91101
[32m[0907 01-06-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08617, current rewards: -2098.37751, mean: -0.90839
[32m[0907 01-06-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08619, current rewards: -2137.71043, mean: -0.90581
[32m[0907 01-06-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08621, current rewards: -2179.36806, mean: -0.90430
[32m[0907 01-06-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08622, current rewards: -2223.48738, mean: -0.90386
[32m[0907 01-06-48 @Agent.py:117][0m Average action selection time: 0.0862
[32m[0907 01-06-48 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-06-48 @MBExp.py:227][0m Rewards obtained: [-2259.332753492435], Lows: [1312], Highs: [10], Total time: 28322.83406000001
[32m[0907 01-10-12 @MBExp.py:144][0m ####################################################################
[32m[0907 01-10-12 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 01-10-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08589, current rewards: -0.54838, mean: -0.05484
[32m[0907 01-10-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08851, current rewards: -7.32255, mean: -0.12204
[32m[0907 01-10-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08906, current rewards: -14.03838, mean: -0.12762
[32m[0907 01-10-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08927, current rewards: -20.00667, mean: -0.12504
[32m[0907 01-10-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08935, current rewards: -37.89279, mean: -0.18044
[32m[0907 01-10-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08936, current rewards: -62.92855, mean: -0.24203
[32m[0907 01-10-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08982, current rewards: -89.79599, mean: -0.28966
[32m[0907 01-10-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08979, current rewards: -106.34459, mean: -0.29540
[32m[0907 01-10-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08979, current rewards: -125.41101, mean: -0.30588
[32m[0907 01-10-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08978, current rewards: -142.02404, mean: -0.30875
[32m[0907 01-10-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08977, current rewards: -171.73404, mean: -0.33673
[32m[0907 01-11-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08977, current rewards: -200.27512, mean: -0.35763
[32m[0907 01-11-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08981, current rewards: -222.25248, mean: -0.36435
[32m[0907 01-11-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08974, current rewards: -251.77300, mean: -0.38147
[32m[0907 01-11-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08958, current rewards: -276.09549, mean: -0.38887
[32m[0907 01-11-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08941, current rewards: -273.61027, mean: -0.36001
[32m[0907 01-11-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08926, current rewards: -268.62297, mean: -0.33163
[32m[0907 01-11-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08912, current rewards: -263.63640, mean: -0.30655
[32m[0907 01-11-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08900, current rewards: -258.65023, mean: -0.28423
[32m[0907 01-11-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08883, current rewards: -253.66356, mean: -0.26423
[32m[0907 01-11-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08863, current rewards: -248.67513, mean: -0.24621
[32m[0907 01-11-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08845, current rewards: -244.08185, mean: -0.23027
[32m[0907 01-11-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08829, current rewards: -239.26013, mean: -0.21555
[32m[0907 01-11-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08812, current rewards: -234.43872, mean: -0.20210
[32m[0907 01-11-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08796, current rewards: -290.60488, mean: -0.24017
[32m[0907 01-12-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08784, current rewards: -341.83354, mean: -0.27130
[32m[0907 01-12-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08781, current rewards: -393.03309, mean: -0.30003
[32m[0907 01-12-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08770, current rewards: -440.16431, mean: -0.32365
[32m[0907 01-12-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08758, current rewards: -492.32625, mean: -0.34917
[32m[0907 01-12-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08749, current rewards: -547.07486, mean: -0.37471
[32m[0907 01-12-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08740, current rewards: -594.68913, mean: -0.39383
[32m[0907 01-12-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08733, current rewards: -647.15777, mean: -0.41484
[32m[0907 01-12-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08727, current rewards: -699.60970, mean: -0.43454
[32m[0907 01-12-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08718, current rewards: -747.93087, mean: -0.45056
[32m[0907 01-12-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08711, current rewards: -805.21250, mean: -0.47088
[32m[0907 01-12-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08703, current rewards: -850.67881, mean: -0.48334
[32m[0907 01-12-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08696, current rewards: -867.92206, mean: -0.47951
[32m[0907 01-12-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08690, current rewards: -863.06836, mean: -0.46402
[32m[0907 01-12-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08684, current rewards: -858.21499, mean: -0.44933
[32m[0907 01-13-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08677, current rewards: -853.34405, mean: -0.43538
[32m[0907 01-13-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08672, current rewards: -848.48014, mean: -0.42213
[32m[0907 01-13-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08667, current rewards: -843.61441, mean: -0.40952
[32m[0907 01-13-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08662, current rewards: -838.74511, mean: -0.39751
[32m[0907 01-13-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08660, current rewards: -840.66045, mean: -0.38919
[32m[0907 01-13-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08661, current rewards: -834.90884, mean: -0.37779
[32m[0907 01-13-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08662, current rewards: -829.14752, mean: -0.36688
[32m[0907 01-13-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08663, current rewards: -823.38622, mean: -0.35644
[32m[0907 01-13-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08664, current rewards: -817.62646, mean: -0.34645
[32m[0907 01-13-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08664, current rewards: -811.86534, mean: -0.33687
[32m[0907 01-13-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08664, current rewards: -806.10452, mean: -0.32768
[32m[0907 01-13-49 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0907 01-13-49 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-13-49 @MBExp.py:227][0m Rewards obtained: [-801.4959024534644], Lows: [514], Highs: [18], Total time: 28540.231207000008
[32m[0907 01-17-15 @MBExp.py:144][0m ####################################################################
[32m[0907 01-17-15 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 01-17-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09205, current rewards: -14.00000, mean: -1.40000
[32m[0907 01-17-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09066, current rewards: -15.19987, mean: -0.25333
[32m[0907 01-17-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09073, current rewards: -11.61144, mean: -0.10556
[32m[0907 01-17-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09036, current rewards: -6.46228, mean: -0.04039
[32m[0907 01-17-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09018, current rewards: -0.75795, mean: -0.00361
[32m[0907 01-17-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09007, current rewards: 4.68361, mean: 0.01801
[32m[0907 01-17-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08997, current rewards: 10.12993, mean: 0.03268
[32m[0907 01-17-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08989, current rewards: 15.57453, mean: 0.04326
[32m[0907 01-17-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08986, current rewards: 8.93819, mean: 0.02180
[32m[0907 01-17-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08987, current rewards: 14.37175, mean: 0.03124
[32m[0907 01-18-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08984, current rewards: 19.80800, mean: 0.03884
[32m[0907 01-18-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08980, current rewards: 25.24945, mean: 0.04509
[32m[0907 01-18-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08981, current rewards: 30.47033, mean: 0.04995
[32m[0907 01-18-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08981, current rewards: 35.78781, mean: 0.05422
[32m[0907 01-18-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08963, current rewards: 39.91657, mean: 0.05622
[32m[0907 01-18-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08948, current rewards: 45.46437, mean: 0.05982
[32m[0907 01-18-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08931, current rewards: 51.00184, mean: 0.06297
[32m[0907 01-18-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08914, current rewards: 56.55030, mean: 0.06576
[32m[0907 01-18-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08903, current rewards: 62.10830, mean: 0.06825
[32m[0907 01-18-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08885, current rewards: 63.44025, mean: 0.06608
[32m[0907 01-18-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08864, current rewards: 61.61155, mean: 0.06100
[32m[0907 01-18-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08845, current rewards: 65.90296, mean: 0.06217
[32m[0907 01-18-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08828, current rewards: 70.19545, mean: 0.06324
[32m[0907 01-18-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08811, current rewards: 74.48784, mean: 0.06421
[32m[0907 01-19-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08795, current rewards: 78.77958, mean: 0.06511
[32m[0907 01-19-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08780, current rewards: 70.16461, mean: 0.05569
[32m[0907 01-19-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08769, current rewards: 28.44165, mean: 0.02171
[32m[0907 01-19-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08758, current rewards: -5.71468, mean: -0.00420
[32m[0907 01-19-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08748, current rewards: -36.81349, mean: -0.02611
[32m[0907 01-19-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08738, current rewards: -78.89685, mean: -0.05404
[32m[0907 01-19-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08728, current rewards: -119.59626, mean: -0.07920
[32m[0907 01-19-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08720, current rewards: -160.39767, mean: -0.10282
[32m[0907 01-19-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08713, current rewards: -201.24624, mean: -0.12500
[32m[0907 01-19-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08705, current rewards: -242.04528, mean: -0.14581
[32m[0907 01-19-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08697, current rewards: -284.02356, mean: -0.16610
[32m[0907 01-19-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08690, current rewards: -324.24855, mean: -0.18423
[32m[0907 01-19-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08684, current rewards: -319.20086, mean: -0.17635
[32m[0907 01-19-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08678, current rewards: -312.24632, mean: -0.16787
[32m[0907 01-20-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08672, current rewards: -305.29348, mean: -0.15984
[32m[0907 01-20-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08666, current rewards: -298.33923, mean: -0.15221
[32m[0907 01-20-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08661, current rewards: -291.38647, mean: -0.14497
[32m[0907 01-20-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08656, current rewards: -284.42317, mean: -0.13807
[32m[0907 01-20-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08652, current rewards: -277.46101, mean: -0.13150
[32m[0907 01-20-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08648, current rewards: -287.43282, mean: -0.13307
[32m[0907 01-20-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08643, current rewards: -284.25800, mean: -0.12862
[32m[0907 01-20-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08644, current rewards: -281.13845, mean: -0.12440
[32m[0907 01-20-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08646, current rewards: -278.01822, mean: -0.12035
[32m[0907 01-20-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08647, current rewards: -274.90403, mean: -0.11648
[32m[0907 01-20-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08649, current rewards: -284.10655, mean: -0.11789
[32m[0907 01-20-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08650, current rewards: -280.06517, mean: -0.11385
[32m[0907 01-20-51 @Agent.py:117][0m Average action selection time: 0.0865
[32m[0907 01-20-51 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-20-52 @MBExp.py:227][0m Rewards obtained: [-277.1078774298556], Lows: [42], Highs: [413], Total time: 28757.273535000008
[32m[0907 01-24-19 @MBExp.py:144][0m ####################################################################
[32m[0907 01-24-19 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 01-24-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08614, current rewards: -8.94880, mean: -0.89488
[32m[0907 01-24-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08801, current rewards: -29.95173, mean: -0.49920
[32m[0907 01-24-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08867, current rewards: -53.75206, mean: -0.48866
[32m[0907 01-24-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08906, current rewards: -87.83289, mean: -0.54896
[32m[0907 01-24-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08918, current rewards: -131.79045, mean: -0.62757
[32m[0907 01-24-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08925, current rewards: -175.48849, mean: -0.67496
[32m[0907 01-24-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08929, current rewards: -208.87131, mean: -0.67378
[32m[0907 01-24-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08936, current rewards: -231.49836, mean: -0.64305
[32m[0907 01-24-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08940, current rewards: -258.34973, mean: -0.63012
[32m[0907 01-25-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08943, current rewards: -296.07437, mean: -0.64364
[32m[0907 01-25-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08943, current rewards: -326.12623, mean: -0.63946
[32m[0907 01-25-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08947, current rewards: -356.49052, mean: -0.63659
[32m[0907 01-25-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08947, current rewards: -375.63497, mean: -0.61580
[32m[0907 01-25-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08949, current rewards: -391.11159, mean: -0.59259
[32m[0907 01-25-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08944, current rewards: -394.21627, mean: -0.55523
[32m[0907 01-25-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08926, current rewards: -395.09955, mean: -0.51987
[32m[0907 01-25-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08911, current rewards: -398.65987, mean: -0.49217
[32m[0907 01-25-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08897, current rewards: -400.12102, mean: -0.46526
[32m[0907 01-25-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08886, current rewards: -399.35857, mean: -0.43886
[32m[0907 01-25-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08871, current rewards: -400.61279, mean: -0.41730
[32m[0907 01-25-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08850, current rewards: -402.70095, mean: -0.39871
[32m[0907 01-25-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08830, current rewards: -408.72365, mean: -0.38559
[32m[0907 01-25-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08813, current rewards: -415.38281, mean: -0.37422
[32m[0907 01-26-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08797, current rewards: -419.06209, mean: -0.36126
[32m[0907 01-26-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08783, current rewards: -440.52916, mean: -0.36407
[32m[0907 01-26-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08770, current rewards: -456.53835, mean: -0.36233
[32m[0907 01-26-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08758, current rewards: -482.34628, mean: -0.36820
[32m[0907 01-26-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08747, current rewards: -505.51921, mean: -0.37171
[32m[0907 01-26-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08736, current rewards: -549.43451, mean: -0.38967
[32m[0907 01-26-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08726, current rewards: -582.42176, mean: -0.39892
[32m[0907 01-26-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08718, current rewards: -614.27725, mean: -0.40681
[32m[0907 01-26-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08710, current rewards: -635.01476, mean: -0.40706
[32m[0907 01-26-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08701, current rewards: -668.46560, mean: -0.41520
[32m[0907 01-26-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08693, current rewards: -699.66237, mean: -0.42148
[32m[0907 01-26-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08686, current rewards: -708.49656, mean: -0.41433
[32m[0907 01-26-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08679, current rewards: -705.40800, mean: -0.40080
[32m[0907 01-26-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08672, current rewards: -706.07083, mean: -0.39009
[32m[0907 01-27-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08666, current rewards: -700.74865, mean: -0.37675
[32m[0907 01-27-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08660, current rewards: -695.51094, mean: -0.36414
[32m[0907 01-27-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08653, current rewards: -690.27013, mean: -0.35218
[32m[0907 01-27-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08649, current rewards: -685.00822, mean: -0.34080
[32m[0907 01-27-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08643, current rewards: -681.92385, mean: -0.33103
[32m[0907 01-27-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08639, current rewards: -685.36562, mean: -0.32482
[32m[0907 01-27-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08637, current rewards: -679.22723, mean: -0.31446
[32m[0907 01-27-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08633, current rewards: -672.41533, mean: -0.30426
[32m[0907 01-27-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08632, current rewards: -664.99423, mean: -0.29425
[32m[0907 01-27-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08633, current rewards: -657.72197, mean: -0.28473
[32m[0907 01-27-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08635, current rewards: -652.07756, mean: -0.27630
[32m[0907 01-27-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08636, current rewards: -644.22595, mean: -0.26731
[32m[0907 01-27-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08637, current rewards: -647.96337, mean: -0.26340
[32m[0907 01-27-55 @Agent.py:117][0m Average action selection time: 0.0864
[32m[0907 01-27-55 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-27-55 @MBExp.py:227][0m Rewards obtained: [-644.6246648877109], Lows: [144], Highs: [589], Total time: 28973.995379000007
[32m[0907 01-31-24 @MBExp.py:144][0m ####################################################################
[32m[0907 01-31-24 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 01-31-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08591, current rewards: -3.97687, mean: -0.39769
[32m[0907 01-31-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08828, current rewards: -36.01929, mean: -0.60032
[32m[0907 01-31-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08895, current rewards: -100.34176, mean: -0.91220
[32m[0907 01-31-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08925, current rewards: -200.34176, mean: -1.25214
[32m[0907 01-31-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08930, current rewards: -300.34176, mean: -1.43020
[32m[0907 01-31-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08936, current rewards: -393.59968, mean: -1.51384
[32m[0907 01-31-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08937, current rewards: -385.43206, mean: -1.24333
[32m[0907 01-31-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08937, current rewards: -377.90300, mean: -1.04973
[32m[0907 01-32-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08936, current rewards: -370.36688, mean: -0.90333
[32m[0907 01-32-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08938, current rewards: -362.83229, mean: -0.78877
[32m[0907 01-32-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08944, current rewards: -359.56028, mean: -0.70502
[32m[0907 01-32-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08947, current rewards: -351.02413, mean: -0.62683
[32m[0907 01-32-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08948, current rewards: -342.98688, mean: -0.56227
[32m[0907 01-32-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08946, current rewards: -334.94295, mean: -0.50749
[32m[0907 01-32-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08947, current rewards: -326.85666, mean: -0.46036
[32m[0907 01-32-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08951, current rewards: -342.00662, mean: -0.45001
[32m[0907 01-32-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08952, current rewards: -339.49713, mean: -0.41913
[32m[0907 01-32-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08940, current rewards: -325.04554, mean: -0.37796
[32m[0907 01-32-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08926, current rewards: -310.57080, mean: -0.34129
[32m[0907 01-32-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08914, current rewards: -299.32522, mean: -0.31180
[32m[0907 01-32-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08889, current rewards: -280.41773, mean: -0.27764
[32m[0907 01-32-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08867, current rewards: -279.63134, mean: -0.26380
[32m[0907 01-33-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08848, current rewards: -271.39865, mean: -0.24450
[32m[0907 01-33-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08830, current rewards: -264.22410, mean: -0.22778
[32m[0907 01-33-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08815, current rewards: -257.05756, mean: -0.21244
[32m[0907 01-33-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08800, current rewards: -249.89440, mean: -0.19833
[32m[0907 01-33-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08788, current rewards: -242.73048, mean: -0.18529
[32m[0907 01-33-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08775, current rewards: -253.09487, mean: -0.18610
[32m[0907 01-33-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08764, current rewards: -324.94585, mean: -0.23046
[32m[0907 01-33-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08753, current rewards: -368.92499, mean: -0.25269
[32m[0907 01-33-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08744, current rewards: -412.91350, mean: -0.27345
[32m[0907 01-33-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08735, current rewards: -463.52052, mean: -0.29713
[32m[0907 01-33-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08731, current rewards: -521.01941, mean: -0.32361
[32m[0907 01-33-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08723, current rewards: -570.14920, mean: -0.34346
[32m[0907 01-33-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08716, current rewards: -591.79516, mean: -0.34608
[32m[0907 01-33-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08708, current rewards: -635.22443, mean: -0.36092
[32m[0907 01-34-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08701, current rewards: -675.17639, mean: -0.37303
[32m[0907 01-34-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08694, current rewards: -727.16721, mean: -0.39095
[32m[0907 01-34-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08688, current rewards: -776.73469, mean: -0.40667
[32m[0907 01-34-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08686, current rewards: -842.45893, mean: -0.42983
[32m[0907 01-34-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08683, current rewards: -919.44084, mean: -0.45743
[32m[0907 01-34-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08680, current rewards: -929.87401, mean: -0.45140
[32m[0907 01-34-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08674, current rewards: -922.33840, mean: -0.43713
[32m[0907 01-34-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08669, current rewards: -914.80279, mean: -0.42352
[32m[0907 01-34-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08664, current rewards: -906.98019, mean: -0.41040
[32m[0907 01-34-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08662, current rewards: -899.57059, mean: -0.39804
[32m[0907 01-34-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08663, current rewards: -892.16055, mean: -0.38622
[32m[0907 01-34-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08663, current rewards: -884.73945, mean: -0.37489
[32m[0907 01-34-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08664, current rewards: -877.33210, mean: -0.36404
[32m[0907 01-34-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08667, current rewards: -875.89229, mean: -0.35605
[32m[0907 01-35-01 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0907 01-35-01 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-35-02 @MBExp.py:227][0m Rewards obtained: [-870.4111980875169], Lows: [630], Highs: [18], Total time: 29191.529536000005
[32m[0907 01-38-32 @MBExp.py:144][0m ####################################################################
[32m[0907 01-38-32 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 01-38-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08602, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-38-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09206, current rewards: -70.39597, mean: -1.17327
[32m[0907 01-38-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09513, current rewards: -117.55737, mean: -1.06870
[32m[0907 01-38-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09706, current rewards: -169.68481, mean: -1.06053
[32m[0907 01-38-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09933, current rewards: -213.05300, mean: -1.01454
[32m[0907 01-38-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09951, current rewards: -254.61560, mean: -0.97929
[32m[0907 01-39-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09938, current rewards: -306.05816, mean: -0.98728
[32m[0907 01-39-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09839, current rewards: -347.66847, mean: -0.96575
[32m[0907 01-39-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09795, current rewards: -391.32126, mean: -0.95444
[32m[0907 01-39-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09802, current rewards: -445.78424, mean: -0.96910
[32m[0907 01-39-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09768, current rewards: -496.32606, mean: -0.97319
[32m[0907 01-39-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09760, current rewards: -548.97693, mean: -0.98032
[32m[0907 01-39-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09736, current rewards: -603.06733, mean: -0.98863
[32m[0907 01-39-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09765, current rewards: -649.12420, mean: -0.98352
[32m[0907 01-39-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09740, current rewards: -698.92242, mean: -0.98440
[32m[0907 01-39-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09730, current rewards: -751.52023, mean: -0.98884
[32m[0907 01-39-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09696, current rewards: -797.65466, mean: -0.98476
[32m[0907 01-39-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09663, current rewards: -845.12806, mean: -0.98271
[32m[0907 01-40-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09632, current rewards: -899.90004, mean: -0.98890
[32m[0907 01-40-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09593, current rewards: -950.43790, mean: -0.99004
[32m[0907 01-40-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09537, current rewards: -1000.43790, mean: -0.99053
[32m[0907 01-40-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09486, current rewards: -1050.43790, mean: -0.99098
[32m[0907 01-40-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09440, current rewards: -1100.43790, mean: -0.99139
[32m[0907 01-40-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09397, current rewards: -1150.43790, mean: -0.99176
[32m[0907 01-40-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09357, current rewards: -1200.43790, mean: -0.99210
[32m[0907 01-40-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09322, current rewards: -1250.43790, mean: -0.99241
[32m[0907 01-40-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09287, current rewards: -1300.43790, mean: -0.99270
[32m[0907 01-40-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09257, current rewards: -1350.43790, mean: -0.99297
[32m[0907 01-40-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09227, current rewards: -1400.43790, mean: -0.99322
[32m[0907 01-40-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09200, current rewards: -1450.43790, mean: -0.99345
[32m[0907 01-40-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09175, current rewards: -1500.43790, mean: -0.99367
[32m[0907 01-40-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09151, current rewards: -1550.43790, mean: -0.99387
[32m[0907 01-40-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09130, current rewards: -1600.43790, mean: -0.99406
[32m[0907 01-41-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09109, current rewards: -1650.43790, mean: -0.99424
[32m[0907 01-41-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09089, current rewards: -1700.43790, mean: -0.99441
[32m[0907 01-41-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09071, current rewards: -1750.43790, mean: -0.99457
[32m[0907 01-41-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09053, current rewards: -1800.43790, mean: -0.99472
[32m[0907 01-41-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09038, current rewards: -1850.43790, mean: -0.99486
[32m[0907 01-41-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09022, current rewards: -1900.43790, mean: -0.99499
[32m[0907 01-41-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09008, current rewards: -1950.43790, mean: -0.99512
[32m[0907 01-41-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08994, current rewards: -2000.43790, mean: -0.99524
[32m[0907 01-41-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08982, current rewards: -2050.43790, mean: -0.99536
[32m[0907 01-41-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08970, current rewards: -2100.43790, mean: -0.99547
[32m[0907 01-41-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08958, current rewards: -2150.43790, mean: -0.99557
[32m[0907 01-41-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08952, current rewards: -2200.43790, mean: -0.99567
[32m[0907 01-41-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08945, current rewards: -2250.43790, mean: -0.99577
[32m[0907 01-41-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08940, current rewards: -2300.43790, mean: -0.99586
[32m[0907 01-42-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08934, current rewards: -2350.43790, mean: -0.99595
[32m[0907 01-42-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08930, current rewards: -2400.43790, mean: -0.99603
[32m[0907 01-42-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08924, current rewards: -2450.43790, mean: -0.99611
[32m[0907 01-42-15 @Agent.py:117][0m Average action selection time: 0.0892
[32m[0907 01-42-15 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-42-16 @MBExp.py:227][0m Rewards obtained: [-2490.4379027392265], Lows: [379], Highs: [1788], Total time: 29415.221129000005
[32m[0907 01-45-48 @MBExp.py:144][0m ####################################################################
[32m[0907 01-45-48 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 01-45-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09151, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-45-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09216, current rewards: -115.00000, mean: -1.91667
[32m[0907 01-45-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09109, current rewards: -215.00000, mean: -1.95455
[32m[0907 01-46-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09054, current rewards: -315.00000, mean: -1.96875
[32m[0907 01-46-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09034, current rewards: -415.00000, mean: -1.97619
[32m[0907 01-46-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09018, current rewards: -515.00000, mean: -1.98077
[32m[0907 01-46-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09004, current rewards: -615.00000, mean: -1.98387
[32m[0907 01-46-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08997, current rewards: -715.00000, mean: -1.98611
[32m[0907 01-46-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08994, current rewards: -815.00000, mean: -1.98780
[32m[0907 01-46-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08989, current rewards: -915.00000, mean: -1.98913
[32m[0907 01-46-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08984, current rewards: -1015.00000, mean: -1.99020
[32m[0907 01-46-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08979, current rewards: -1115.00000, mean: -1.99107
[32m[0907 01-46-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08974, current rewards: -1215.00000, mean: -1.99180
[32m[0907 01-46-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08971, current rewards: -1315.00000, mean: -1.99242
[32m[0907 01-46-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08969, current rewards: -1415.00000, mean: -1.99296
[32m[0907 01-46-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08969, current rewards: -1515.00000, mean: -1.99342
[32m[0907 01-47-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08959, current rewards: -1615.00000, mean: -1.99383
[32m[0907 01-47-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08943, current rewards: -1715.00000, mean: -1.99419
[32m[0907 01-47-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08928, current rewards: -1815.00000, mean: -1.99451
[32m[0907 01-47-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08907, current rewards: -1915.00000, mean: -1.99479
[32m[0907 01-47-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08883, current rewards: -2015.00000, mean: -1.99505
[32m[0907 01-47-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08863, current rewards: -2115.00000, mean: -1.99528
[32m[0907 01-47-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08844, current rewards: -2215.00000, mean: -1.99550
[32m[0907 01-47-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08828, current rewards: -2315.00000, mean: -1.99569
[32m[0907 01-47-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08812, current rewards: -2415.00000, mean: -1.99587
[32m[0907 01-47-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08798, current rewards: -2515.00000, mean: -1.99603
[32m[0907 01-47-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08784, current rewards: -2615.00000, mean: -1.99618
[32m[0907 01-47-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08773, current rewards: -2715.00000, mean: -1.99632
[32m[0907 01-47-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08761, current rewards: -2815.00000, mean: -1.99645
[32m[0907 01-47-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08749, current rewards: -2915.00000, mean: -1.99658
[32m[0907 01-48-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08739, current rewards: -3015.00000, mean: -1.99669
[32m[0907 01-48-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08730, current rewards: -3115.00000, mean: -1.99679
[32m[0907 01-48-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08721, current rewards: -3215.00000, mean: -1.99689
[32m[0907 01-48-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08713, current rewards: -3315.00000, mean: -1.99699
[32m[0907 01-48-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08705, current rewards: -3415.00000, mean: -1.99708
[32m[0907 01-48-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08698, current rewards: -3515.00000, mean: -1.99716
[32m[0907 01-48-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08691, current rewards: -3615.00000, mean: -1.99724
[32m[0907 01-48-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08685, current rewards: -3715.00000, mean: -1.99731
[32m[0907 01-48-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08679, current rewards: -3815.00000, mean: -1.99738
[32m[0907 01-48-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08673, current rewards: -3915.00000, mean: -1.99745
[32m[0907 01-48-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08668, current rewards: -4015.00000, mean: -1.99751
[32m[0907 01-48-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08662, current rewards: -4115.00000, mean: -1.99757
[32m[0907 01-48-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08658, current rewards: -4215.00000, mean: -1.99763
[32m[0907 01-48-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08653, current rewards: -4315.00000, mean: -1.99769
[32m[0907 01-49-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08649, current rewards: -4415.00000, mean: -1.99774
[32m[0907 01-49-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08645, current rewards: -4515.00000, mean: -1.99779
[32m[0907 01-49-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08639, current rewards: -4615.00000, mean: -1.99784
[32m[0907 01-49-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08635, current rewards: -4715.00000, mean: -1.99788
[32m[0907 01-49-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08632, current rewards: -4815.00000, mean: -1.99793
[32m[0907 01-49-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08627, current rewards: -4915.00000, mean: -1.99797
[32m[0907 01-49-24 @Agent.py:117][0m Average action selection time: 0.0862
[32m[0907 01-49-24 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-49-25 @MBExp.py:227][0m Rewards obtained: [-4995], Lows: [2495], Highs: [5], Total time: 29631.547585000004
[32m[0907 01-52-59 @MBExp.py:144][0m ####################################################################
[32m[0907 01-52-59 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 01-53-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12701, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-53-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09812, current rewards: -66.91827, mean: -1.11530
[32m[0907 01-53-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09392, current rewards: -114.76947, mean: -1.04336
[32m[0907 01-53-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09251, current rewards: -161.54152, mean: -1.00963
[32m[0907 01-53-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09174, current rewards: -207.07649, mean: -0.98608
[32m[0907 01-53-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09126, current rewards: -254.95259, mean: -0.98059
[32m[0907 01-53-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09091, current rewards: -302.80198, mean: -0.97678
[32m[0907 01-53-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09075, current rewards: -349.55633, mean: -0.97099
[32m[0907 01-53-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09076, current rewards: -399.55633, mean: -0.97453
[32m[0907 01-53-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09062, current rewards: -448.50510, mean: -0.97501
[32m[0907 01-53-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09053, current rewards: -498.50510, mean: -0.97746
[32m[0907 01-53-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09042, current rewards: -548.50510, mean: -0.97947
[32m[0907 01-53-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09034, current rewards: -598.50510, mean: -0.98116
[32m[0907 01-53-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09029, current rewards: -648.50510, mean: -0.98258
[32m[0907 01-54-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09023, current rewards: -698.50510, mean: -0.98381
[32m[0907 01-54-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09018, current rewards: -746.39662, mean: -0.98210
[32m[0907 01-54-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09014, current rewards: -793.20154, mean: -0.97926
[32m[0907 01-54-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09012, current rewards: -840.02003, mean: -0.97677
[32m[0907 01-54-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08994, current rewards: -890.02003, mean: -0.97804
[32m[0907 01-54-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08971, current rewards: -940.02003, mean: -0.97919
[32m[0907 01-54-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08945, current rewards: -990.02003, mean: -0.98022
[32m[0907 01-54-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08921, current rewards: -1040.02003, mean: -0.98115
[32m[0907 01-54-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08900, current rewards: -1090.02003, mean: -0.98200
[32m[0907 01-54-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08880, current rewards: -1140.02003, mean: -0.98278
[32m[0907 01-54-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08863, current rewards: -1190.02003, mean: -0.98349
[32m[0907 01-54-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08847, current rewards: -1240.02003, mean: -0.98414
[32m[0907 01-54-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08832, current rewards: -1285.82182, mean: -0.98154
[32m[0907 01-54-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08818, current rewards: -1335.82182, mean: -0.98222
[32m[0907 01-55-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08804, current rewards: -1385.82182, mean: -0.98285
[32m[0907 01-55-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08791, current rewards: -1435.82182, mean: -0.98344
[32m[0907 01-55-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08780, current rewards: -1485.82182, mean: -0.98399
[32m[0907 01-55-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08769, current rewards: -1535.82182, mean: -0.98450
[32m[0907 01-55-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08760, current rewards: -1585.82182, mean: -0.98498
[32m[0907 01-55-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08752, current rewards: -1635.82182, mean: -0.98543
[32m[0907 01-55-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08744, current rewards: -1685.82182, mean: -0.98586
[32m[0907 01-55-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08736, current rewards: -1735.82182, mean: -0.98626
[32m[0907 01-55-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08727, current rewards: -1785.82182, mean: -0.98664
[32m[0907 01-55-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08720, current rewards: -1835.82182, mean: -0.98700
[32m[0907 01-55-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08713, current rewards: -1885.82182, mean: -0.98734
[32m[0907 01-55-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08706, current rewards: -1935.82182, mean: -0.98766
[32m[0907 01-55-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08700, current rewards: -1985.82182, mean: -0.98797
[32m[0907 01-55-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08693, current rewards: -2035.82182, mean: -0.98826
[32m[0907 01-56-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08686, current rewards: -2085.82182, mean: -0.98854
[32m[0907 01-56-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08681, current rewards: -2135.82182, mean: -0.98881
[32m[0907 01-56-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08676, current rewards: -2185.82182, mean: -0.98906
[32m[0907 01-56-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08671, current rewards: -2235.82182, mean: -0.98930
[32m[0907 01-56-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08667, current rewards: -2285.82182, mean: -0.98953
[32m[0907 01-56-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08662, current rewards: -2335.82182, mean: -0.98976
[32m[0907 01-56-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08657, current rewards: -2385.82182, mean: -0.98997
[32m[0907 01-56-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08653, current rewards: -2435.82182, mean: -0.99017
[32m[0907 01-56-36 @Agent.py:117][0m Average action selection time: 0.0865
[32m[0907 01-56-36 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-56-36 @MBExp.py:227][0m Rewards obtained: [-2475.8218189083573], Lows: [8], Highs: [2462], Total time: 29848.537457000002
[32m[0907 02-00-12 @MBExp.py:144][0m ####################################################################
[32m[0907 02-00-12 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08877, current rewards: -10.92503, mean: -1.09250
[32m[0907 02-00-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09130, current rewards: -60.83898, mean: -1.01398
[32m[0907 02-00-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09403, current rewards: -110.83898, mean: -1.00763
[32m[0907 02-00-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09367, current rewards: -160.83898, mean: -1.00524
[32m[0907 02-00-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09300, current rewards: -210.83898, mean: -1.00400
[32m[0907 02-00-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09233, current rewards: -260.83898, mean: -1.00323
[32m[0907 02-00-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09186, current rewards: -310.83898, mean: -1.00271
[32m[0907 02-00-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09165, current rewards: -360.83898, mean: -1.00233
[32m[0907 02-00-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09144, current rewards: -407.62827, mean: -0.99422
[32m[0907 02-00-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09122, current rewards: -457.62827, mean: -0.99484
[32m[0907 02-00-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09103, current rewards: -507.62827, mean: -0.99535
[32m[0907 02-01-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09090, current rewards: -557.62827, mean: -0.99576
[32m[0907 02-01-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09078, current rewards: -607.62827, mean: -0.99611
[32m[0907 02-01-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09070, current rewards: -657.62827, mean: -0.99641
[32m[0907 02-01-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09061, current rewards: -707.62827, mean: -0.99666
[32m[0907 02-01-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09054, current rewards: -757.62827, mean: -0.99688
[32m[0907 02-01-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09047, current rewards: -807.62827, mean: -0.99707
[32m[0907 02-01-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09040, current rewards: -857.62827, mean: -0.99724
[32m[0907 02-01-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09028, current rewards: -907.62827, mean: -0.99739
[32m[0907 02-01-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09005, current rewards: -957.62827, mean: -0.99753
[32m[0907 02-01-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08977, current rewards: -1007.62827, mean: -0.99765
[32m[0907 02-01-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08953, current rewards: -1057.62827, mean: -0.99776
[32m[0907 02-01-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08930, current rewards: -1107.62827, mean: -0.99786
[32m[0907 02-01-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08911, current rewards: -1157.62827, mean: -0.99796
[32m[0907 02-02-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08890, current rewards: -1207.62827, mean: -0.99804
[32m[0907 02-02-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08873, current rewards: -1257.62827, mean: -0.99812
[32m[0907 02-02-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08858, current rewards: -1300.25585, mean: -0.99256
[32m[0907 02-02-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08843, current rewards: -1350.25585, mean: -0.99284
[32m[0907 02-02-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08829, current rewards: -1400.25585, mean: -0.99309
[32m[0907 02-02-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08815, current rewards: -1450.25585, mean: -0.99333
[32m[0907 02-02-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08802, current rewards: -1500.25585, mean: -0.99355
[32m[0907 02-02-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08792, current rewards: -1550.25585, mean: -0.99375
[32m[0907 02-02-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08782, current rewards: -1600.25585, mean: -0.99395
[32m[0907 02-02-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08773, current rewards: -1650.25585, mean: -0.99413
[32m[0907 02-02-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08764, current rewards: -1700.25585, mean: -0.99430
[32m[0907 02-02-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08754, current rewards: -1750.25585, mean: -0.99446
[32m[0907 02-02-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08746, current rewards: -1800.25585, mean: -0.99462
[32m[0907 02-02-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08739, current rewards: -1850.25585, mean: -0.99476
[32m[0907 02-02-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08732, current rewards: -1900.25585, mean: -0.99490
[32m[0907 02-03-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08724, current rewards: -1950.25585, mean: -0.99503
[32m[0907 02-03-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08718, current rewards: -2000.25585, mean: -0.99515
[32m[0907 02-03-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08713, current rewards: -2050.25585, mean: -0.99527
[32m[0907 02-03-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08707, current rewards: -2100.25585, mean: -0.99538
[32m[0907 02-03-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08702, current rewards: -2150.25585, mean: -0.99549
[32m[0907 02-03-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08696, current rewards: -2200.25585, mean: -0.99559
[32m[0907 02-03-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08691, current rewards: -2250.25585, mean: -0.99569
[32m[0907 02-03-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08687, current rewards: -2300.25585, mean: -0.99578
[32m[0907 02-03-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08682, current rewards: -2350.25585, mean: -0.99587
[32m[0907 02-03-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08678, current rewards: -2400.25585, mean: -0.99596
[32m[0907 02-03-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08673, current rewards: -2450.25585, mean: -0.99604
[32m[0907 02-03-49 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0907 02-03-49 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-03-49 @MBExp.py:227][0m Rewards obtained: [-2490.255850466566], Lows: [3], Highs: [2485], Total time: 30066.025627000003
[32m[0907 02-07-27 @MBExp.py:144][0m ####################################################################
[32m[0907 02-07-27 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 02-07-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08919, current rewards: -11.59243, mean: -1.15924
[32m[0907 02-07-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09012, current rewards: -107.40586, mean: -1.79010
[32m[0907 02-07-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09075, current rewards: -149.18849, mean: -1.35626
[32m[0907 02-07-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09129, current rewards: -170.19827, mean: -1.06374
[32m[0907 02-07-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09181, current rewards: -192.52993, mean: -0.91681
[32m[0907 02-07-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09151, current rewards: -234.82102, mean: -0.90316
[32m[0907 02-07-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09137, current rewards: -260.36926, mean: -0.83990
[32m[0907 02-08-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09114, current rewards: -282.37338, mean: -0.78437
[32m[0907 02-08-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09095, current rewards: -303.46091, mean: -0.74015
[32m[0907 02-08-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09080, current rewards: -326.00650, mean: -0.70871
[32m[0907 02-08-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09065, current rewards: -347.39474, mean: -0.68117
[32m[0907 02-08-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09054, current rewards: -368.98623, mean: -0.65890
[32m[0907 02-08-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09046, current rewards: -386.86417, mean: -0.63420
[32m[0907 02-08-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09039, current rewards: -383.10294, mean: -0.58046
[32m[0907 02-08-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09029, current rewards: -379.27989, mean: -0.53420
[32m[0907 02-08-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09023, current rewards: -375.44916, mean: -0.49401
[32m[0907 02-08-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09017, current rewards: -371.51793, mean: -0.45866
[32m[0907 02-08-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09011, current rewards: -367.67944, mean: -0.42753
[32m[0907 02-08-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09008, current rewards: -363.76195, mean: -0.39974
[32m[0907 02-08-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08992, current rewards: -359.93182, mean: -0.37493
[32m[0907 02-08-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08975, current rewards: -356.01733, mean: -0.35249
[32m[0907 02-09-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08963, current rewards: -352.18099, mean: -0.33225
[32m[0907 02-09-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08958, current rewards: -358.64100, mean: -0.32310
[32m[0907 02-09-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08947, current rewards: -404.07957, mean: -0.34834
[32m[0907 02-09-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08935, current rewards: -454.07957, mean: -0.37527
[32m[0907 02-09-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08914, current rewards: -504.07957, mean: -0.40006
[32m[0907 02-09-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08896, current rewards: -554.07957, mean: -0.42296
[32m[0907 02-09-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08879, current rewards: -604.07957, mean: -0.44418
[32m[0907 02-09-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08863, current rewards: -654.07957, mean: -0.46389
[32m[0907 02-09-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08849, current rewards: -704.07957, mean: -0.48225
[32m[0907 02-09-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08835, current rewards: -754.07957, mean: -0.49939
[32m[0907 02-09-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08822, current rewards: -804.07957, mean: -0.51544
[32m[0907 02-09-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08810, current rewards: -854.07957, mean: -0.53048
[32m[0907 02-09-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08800, current rewards: -904.07957, mean: -0.54463
[32m[0907 02-09-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08789, current rewards: -954.07957, mean: -0.55794
[32m[0907 02-10-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08778, current rewards: -1004.07957, mean: -0.57050
[32m[0907 02-10-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08769, current rewards: -1054.07957, mean: -0.58236
[32m[0907 02-10-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08761, current rewards: -1104.07957, mean: -0.59359
[32m[0907 02-10-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08752, current rewards: -1154.07957, mean: -0.60423
[32m[0907 02-10-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08743, current rewards: -1204.07957, mean: -0.61433
[32m[0907 02-10-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08736, current rewards: -1254.07957, mean: -0.62392
[32m[0907 02-10-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08728, current rewards: -1286.15301, mean: -0.62435
[32m[0907 02-10-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08722, current rewards: -1283.37251, mean: -0.60823
[32m[0907 02-10-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08715, current rewards: -1280.59201, mean: -0.59287
[32m[0907 02-10-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08709, current rewards: -1277.81151, mean: -0.57820
[32m[0907 02-10-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08701, current rewards: -1275.03102, mean: -0.56417
[32m[0907 02-10-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08696, current rewards: -1272.25052, mean: -0.55076
[32m[0907 02-10-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08691, current rewards: -1269.47002, mean: -0.53791
[32m[0907 02-10-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08686, current rewards: -1266.68952, mean: -0.52560
[32m[0907 02-11-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08680, current rewards: -1263.98637, mean: -0.51382
[32m[0907 02-11-04 @Agent.py:117][0m Average action selection time: 0.0868
[32m[0907 02-11-04 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-11-05 @MBExp.py:227][0m Rewards obtained: [-1262.0546576195336], Lows: [87], Highs: [1183], Total time: 30283.706784
