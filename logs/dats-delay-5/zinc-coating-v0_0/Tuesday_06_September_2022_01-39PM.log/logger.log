[32m[0906 13-39-11 @logger.py:99][0m Log file set to /app/logs/dats-delay-5/zinc-coating-v0_0/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-11 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: -6.64410, mean: -0.66441
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -50.73882, mean: -0.84565
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -100.65833, mean: -0.91508
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -156.19093, mean: -0.97619
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -193.52460, mean: -0.92155
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -239.54949, mean: -0.92134
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -288.59583, mean: -0.93095
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -340.66434, mean: -0.94629
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -387.64179, mean: -0.94547
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -440.77325, mean: -0.95820
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -499.87309, mean: -0.98014
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -556.69606, mean: -0.99410
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -620.99884, mean: -1.01803
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -673.83021, mean: -1.02095
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -737.26988, mean: -1.03841
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -819.30876, mean: -1.07804
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -903.48739, mean: -1.11542
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -991.51689, mean: -1.15293
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1074.80291, mean: -1.18110
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1158.46001, mean: -1.20673
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1244.35844, mean: -1.23204
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1339.59652, mean: -1.26377
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1421.13109, mean: -1.28030
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1513.51371, mean: -1.30475
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1585.36147, mean: -1.31022
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1652.60537, mean: -1.31159
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1708.50253, mean: -1.30420
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1761.09736, mean: -1.29492
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1826.74625, mean: -1.29556
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1893.80518, mean: -1.29713
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1955.08451, mean: -1.29476
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -2016.67011, mean: -1.29274
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -2071.21542, mean: -1.28647
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -2127.20020, mean: -1.28145
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -2179.59027, mean: -1.27461
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2230.77034, mean: -1.26748
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2289.37829, mean: -1.26485
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2331.44819, mean: -1.25347
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2382.85244, mean: -1.24757
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2429.31021, mean: -1.23944
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2479.95284, mean: -1.23381
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2529.54498, mean: -1.22793
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2580.89355, mean: -1.22317
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2633.37258, mean: -1.21915
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2695.64317, mean: -1.21975
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2750.46291, mean: -1.21702
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2798.96958, mean: -1.21168
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2865.25889, mean: -1.21409
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2925.83175, mean: -1.21404
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -2975.14904, mean: -1.20941
[32m[0906 13-39-11 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-39-13 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-13 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.07082, current rewards: -13.00000, mean: -1.30000
[32m[0906 13-39-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.06242, current rewards: -107.55960, mean: -1.79266
[32m[0906 13-39-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.06171, current rewards: -207.55960, mean: -1.88691
[32m[0906 13-39-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.06147, current rewards: -307.55960, mean: -1.92225
[32m[0906 13-39-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.06139, current rewards: -407.55960, mean: -1.94076
[32m[0906 13-39-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.06134, current rewards: -507.55960, mean: -1.95215
[32m[0906 13-39-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.06127, current rewards: -577.36160, mean: -1.86246
[32m[0906 13-39-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.06126, current rewards: -568.96673, mean: -1.58046
[32m[0906 13-39-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.06127, current rewards: -561.86568, mean: -1.37040
[32m[0906 13-39-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.06126, current rewards: -555.19924, mean: -1.20695
[32m[0906 13-39-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.06129, current rewards: -548.52873, mean: -1.07555
[32m[0906 13-39-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.06128, current rewards: -541.85815, mean: -0.96760
[32m[0906 13-39-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.06141, current rewards: -535.18350, mean: -0.87735
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.06152, current rewards: -528.52279, mean: -0.80079
[32m[0906 13-39-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.06227, current rewards: -521.84757, mean: -0.73500
[32m[0906 13-40-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.06309, current rewards: -515.17399, mean: -0.67786
[32m[0906 13-40-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.06374, current rewards: -509.14816, mean: -0.62858
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.06442, current rewards: -503.51169, mean: -0.58548
[32m[0906 13-40-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.06511, current rewards: -509.92458, mean: -0.56036
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.06615, current rewards: -501.08552, mean: -0.52196
[32m[0906 13-40-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.06709, current rewards: -492.23540, mean: -0.48736
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.06796, current rewards: -483.39867, mean: -0.45604
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.06884, current rewards: -474.55565, mean: -0.42753
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.06972, current rewards: -465.71214, mean: -0.40148
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.07085, current rewards: -453.41023, mean: -0.37472
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.07195, current rewards: -440.53341, mean: -0.34963
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.07298, current rewards: -461.90696, mean: -0.35260
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.07391, current rewards: -498.46301, mean: -0.36652
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.07478, current rewards: -534.94831, mean: -0.37940
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.07561, current rewards: -573.87382, mean: -0.39306
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.07637, current rewards: -615.38273, mean: -0.40754
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.07709, current rewards: -656.85430, mean: -0.42106
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.07783, current rewards: -682.28335, mean: -0.42378
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.07852, current rewards: -659.98087, mean: -0.39758
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.07941, current rewards: -637.75450, mean: -0.37296
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08036, current rewards: -630.49065, mean: -0.35823
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08126, current rewards: -622.75700, mean: -0.34406
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08210, current rewards: -614.70804, mean: -0.33049
[32m[0906 13-41-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08291, current rewards: -606.65147, mean: -0.31762
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08365, current rewards: -598.59686, mean: -0.30541
[32m[0906 13-42-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08438, current rewards: -590.35965, mean: -0.29371
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08507, current rewards: -580.01877, mean: -0.28156
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08572, current rewards: -569.93781, mean: -0.27011
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08633, current rewards: -559.85328, mean: -0.25919
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08693, current rewards: -549.77559, mean: -0.24877
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08748, current rewards: -543.28967, mean: -0.24039
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08802, current rewards: -537.29508, mean: -0.23260
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08855, current rewards: -514.64928, mean: -0.21807
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08903, current rewards: -491.89519, mean: -0.20411
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08950, current rewards: -478.22751, mean: -0.19440
[32m[0906 13-42-58 @Agent.py:117][0m Average action selection time: 0.0899
[32m[0906 13-42-58 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-42-58 @MBExp.py:227][0m Rewards obtained: [-467.4271628509091], Lows: [460], Highs: [19], Total time: 225.308848
[32m[0906 13-43-03 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-03 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11160, current rewards: 0.71818, mean: 0.07182
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11182, current rewards: 4.29014, mean: 0.07150
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11163, current rewards: 7.89268, mean: 0.07175
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11152, current rewards: 11.49649, mean: 0.07185
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11160, current rewards: 15.10087, mean: 0.07191
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11150, current rewards: 18.70473, mean: 0.07194
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11149, current rewards: 22.30905, mean: 0.07196
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11155, current rewards: 19.26984, mean: 0.05353
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11153, current rewards: 22.60857, mean: 0.05514
[32m[0906 13-43-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11146, current rewards: 25.94819, mean: 0.05641
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11154, current rewards: 29.28881, mean: 0.05743
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11152, current rewards: 32.63080, mean: 0.05827
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11148, current rewards: 29.57771, mean: 0.04849
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11142, current rewards: 32.82955, mean: 0.04974
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11127, current rewards: 36.08080, mean: 0.05082
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11129, current rewards: 39.21265, mean: 0.05160
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11134, current rewards: 42.25088, mean: 0.05216
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11135, current rewards: 45.28670, mean: 0.05266
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11132, current rewards: 48.32454, mean: 0.05310
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11124, current rewards: 51.36211, mean: 0.05350
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11124, current rewards: 54.39940, mean: 0.05386
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11128, current rewards: 57.43698, mean: 0.05419
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11130, current rewards: 60.47507, mean: 0.05448
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11127, current rewards: 63.91546, mean: 0.05510
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11120, current rewards: 56.61188, mean: 0.04679
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11119, current rewards: 63.69441, mean: 0.05055
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11118, current rewards: 70.78337, mean: 0.05403
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11121, current rewards: 77.87318, mean: 0.05726
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11120, current rewards: 84.95685, mean: 0.06025
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11121, current rewards: 92.05350, mean: 0.06305
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11121, current rewards: 99.14496, mean: 0.06566
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11121, current rewards: 106.18493, mean: 0.06807
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11121, current rewards: 111.90332, mean: 0.06951
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11122, current rewards: 110.52745, mean: 0.06658
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11115, current rewards: 114.03996, mean: 0.06669
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11113, current rewards: 117.54848, mean: 0.06679
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11114, current rewards: 121.06339, mean: 0.06689
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11116, current rewards: 124.57557, mean: 0.06698
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11116, current rewards: 129.09732, mean: 0.06759
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11118, current rewards: 133.97354, mean: 0.06835
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11120, current rewards: 138.35057, mean: 0.06883
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11122, current rewards: 142.71951, mean: 0.06928
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11122, current rewards: 147.08778, mean: 0.06971
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11123, current rewards: 151.45745, mean: 0.07012
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11125, current rewards: 155.82190, mean: 0.07051
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11125, current rewards: 147.87966, mean: 0.06543
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11125, current rewards: 153.05253, mean: 0.06626
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11128, current rewards: 158.22758, mean: 0.06705
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11131, current rewards: 161.95672, mean: 0.06720
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11134, current rewards: 165.35795, mean: 0.06722
[32m[0906 13-47-42 @Agent.py:117][0m Average action selection time: 0.1113
[32m[0906 13-47-42 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-47-42 @MBExp.py:227][0m Rewards obtained: [168.07950077935038], Lows: [12], Highs: [18], Total time: 504.37052
[32m[0906 13-47-49 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-49 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11302, current rewards: -5.77208, mean: -0.57721
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11198, current rewards: -2.95674, mean: -0.04928
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11141, current rewards: -0.14348, mean: -0.00130
[32m[0906 13-48-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11125, current rewards: 2.66834, mean: 0.01668
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11135, current rewards: 5.48100, mean: 0.02610
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11138, current rewards: 8.29162, mean: 0.03189
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11137, current rewards: 11.31705, mean: 0.03651
[32m[0906 13-48-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11146, current rewards: 4.32189, mean: 0.01201
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11149, current rewards: 8.10834, mean: 0.01978
[32m[0906 13-48-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11149, current rewards: 11.89786, mean: 0.02586
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11153, current rewards: 15.68235, mean: 0.03075
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11156, current rewards: 19.47153, mean: 0.03477
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11160, current rewards: 23.25868, mean: 0.03813
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11151, current rewards: 27.04587, mean: 0.04098
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11137, current rewards: 25.60281, mean: 0.03606
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11144, current rewards: 29.98943, mean: 0.03946
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11154, current rewards: 34.39197, mean: 0.04246
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11158, current rewards: 38.79241, mean: 0.04511
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11148, current rewards: 43.19189, mean: 0.04746
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11139, current rewards: 47.59299, mean: 0.04958
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11143, current rewards: 51.99729, mean: 0.05148
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11148, current rewards: 46.16272, mean: 0.04355
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11149, current rewards: 50.50238, mean: 0.04550
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11141, current rewards: 54.05669, mean: 0.04660
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11131, current rewards: 57.62495, mean: 0.04762
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11132, current rewards: 61.19608, mean: 0.04857
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11132, current rewards: 64.76724, mean: 0.04944
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11134, current rewards: 68.33856, mean: 0.05025
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11134, current rewards: 71.90654, mean: 0.05100
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11135, current rewards: 75.47448, mean: 0.05169
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11136, current rewards: 79.04197, mean: 0.05235
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11134, current rewards: 82.18791, mean: 0.05268
[32m[0906 13-50-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11135, current rewards: 79.00880, mean: 0.04907
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11136, current rewards: 82.09562, mean: 0.04946
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11125, current rewards: 85.18292, mean: 0.04981
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11121, current rewards: 88.27025, mean: 0.05015
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11123, current rewards: 91.35632, mean: 0.05047
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11126, current rewards: 94.44095, mean: 0.05077
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11127, current rewards: 97.52929, mean: 0.05106
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11130, current rewards: 89.66645, mean: 0.04575
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11131, current rewards: 95.81249, mean: 0.04767
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11133, current rewards: 101.99366, mean: 0.04951
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11134, current rewards: 108.17505, mean: 0.05127
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11135, current rewards: 114.35613, mean: 0.05294
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11137, current rewards: 120.53768, mean: 0.05454
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11138, current rewards: 126.71874, mean: 0.05607
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11137, current rewards: 124.88618, mean: 0.05406
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11139, current rewards: 125.46477, mean: 0.05316
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11139, current rewards: 100.63368, mean: 0.04176
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11139, current rewards: 75.80265, mean: 0.03081
[32m[0906 13-52-29 @Agent.py:117][0m Average action selection time: 0.1114
[32m[0906 13-52-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-52-29 @MBExp.py:227][0m Rewards obtained: [57.82677738411724], Lows: [16], Highs: [98], Total time: 783.577573
[32m[0906 13-52-38 @MBExp.py:144][0m ####################################################################
[32m[0906 13-52-38 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11274, current rewards: -5.76580, mean: -0.57658
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11206, current rewards: -2.68771, mean: -0.04480
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11196, current rewards: 0.44343, mean: 0.00403
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11179, current rewards: 3.57259, mean: 0.02233
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11176, current rewards: 6.70389, mean: 0.03192
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11165, current rewards: 9.83520, mean: 0.03783
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11156, current rewards: 13.13951, mean: 0.04239
[32m[0906 13-53-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11160, current rewards: 14.39259, mean: 0.03998
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11157, current rewards: 9.65643, mean: 0.02355
[32m[0906 13-53-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11150, current rewards: 13.18585, mean: 0.02866
[32m[0906 13-53-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11155, current rewards: 16.71527, mean: 0.03278
[32m[0906 13-53-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11149, current rewards: 20.24469, mean: 0.03615
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11153, current rewards: 23.77411, mean: 0.03897
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11124, current rewards: 27.30353, mean: 0.04137
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11104, current rewards: 30.83296, mean: 0.04343
[32m[0906 13-54-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11110, current rewards: 34.36238, mean: 0.04521
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11110, current rewards: 37.89180, mean: 0.04678
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11112, current rewards: 41.42122, mean: 0.04816
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11098, current rewards: -6.43760, mean: -0.00707
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11086, current rewards: -56.43760, mean: -0.05879
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11089, current rewards: -106.43760, mean: -0.10538
[32m[0906 13-54-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11096, current rewards: -156.43760, mean: -0.14758
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11098, current rewards: -206.43760, mean: -0.18598
[32m[0906 13-54-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11089, current rewards: -256.43760, mean: -0.22107
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11082, current rewards: -306.43760, mean: -0.25325
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11086, current rewards: -356.43760, mean: -0.28289
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11086, current rewards: -406.43760, mean: -0.31026
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11091, current rewards: -456.43760, mean: -0.33562
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11092, current rewards: -506.43760, mean: -0.35918
[32m[0906 13-55-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11094, current rewards: -556.43760, mean: -0.38112
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11097, current rewards: -606.43760, mean: -0.40161
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11098, current rewards: -656.43760, mean: -0.42079
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11101, current rewards: -706.43760, mean: -0.43878
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11097, current rewards: -756.43760, mean: -0.45569
[32m[0906 13-55-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11089, current rewards: -806.43760, mean: -0.47160
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11089, current rewards: -856.43760, mean: -0.48661
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11092, current rewards: -906.43760, mean: -0.50079
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11092, current rewards: -956.43760, mean: -0.51421
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11095, current rewards: -1006.43760, mean: -0.52693
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11096, current rewards: -1056.43760, mean: -0.53900
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11096, current rewards: -1106.43760, mean: -0.55047
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11098, current rewards: -1156.43760, mean: -0.56138
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11098, current rewards: -1206.43760, mean: -0.57177
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11100, current rewards: -1256.43760, mean: -0.58168
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11103, current rewards: -1306.43760, mean: -0.59115
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11102, current rewards: -1356.43760, mean: -0.60019
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11102, current rewards: -1406.43760, mean: -0.60885
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11104, current rewards: -1456.43760, mean: -0.61713
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11105, current rewards: -1506.43760, mean: -0.62508
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11106, current rewards: -1556.43760, mean: -0.63270
[32m[0906 13-57-16 @Agent.py:117][0m Average action selection time: 0.1111
[32m[0906 13-57-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-57-17 @MBExp.py:227][0m Rewards obtained: [-1596.4376048191652], Lows: [5], Highs: [1644], Total time: 1061.95192
[32m[0906 13-57-28 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-28 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-57-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11617, current rewards: -4.44934, mean: -0.44493
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11255, current rewards: 0.14097, mean: 0.00235
[32m[0906 13-57-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11190, current rewards: 5.00731, mean: 0.04552
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11180, current rewards: 9.87621, mean: 0.06173
[32m[0906 13-57-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11169, current rewards: 14.74575, mean: 0.07022
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11159, current rewards: 19.62868, mean: 0.07549
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11158, current rewards: 25.27343, mean: 0.08153
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11147, current rewards: 24.90341, mean: 0.06918
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11140, current rewards: 29.23538, mean: 0.07131
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11143, current rewards: 33.57119, mean: 0.07298
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11141, current rewards: 37.90673, mean: 0.07433
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11151, current rewards: 42.24061, mean: 0.07543
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11156, current rewards: 46.57129, mean: 0.07635
[32m[0906 13-58-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11139, current rewards: 50.75105, mean: 0.07690
[32m[0906 13-58-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11130, current rewards: 54.53639, mean: 0.07681
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11140, current rewards: 58.39086, mean: 0.07683
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11141, current rewards: 62.24323, mean: 0.07684
[32m[0906 13-59-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11144, current rewards: 66.09681, mean: 0.07686
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11130, current rewards: 69.95395, mean: 0.07687
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11116, current rewards: 73.81137, mean: 0.07689
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11124, current rewards: 77.66434, mean: 0.07690
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11128, current rewards: 81.51923, mean: 0.07690
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11126, current rewards: 85.24073, mean: 0.07679
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11116, current rewards: 79.41104, mean: 0.06846
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11103, current rewards: 84.50283, mean: 0.06984
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11108, current rewards: 89.59621, mean: 0.07111
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11112, current rewards: 94.68571, mean: 0.07228
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11116, current rewards: 99.77580, mean: 0.07336
[32m[0906 14-00-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11114, current rewards: 104.86297, mean: 0.07437
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11116, current rewards: 109.95679, mean: 0.07531
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11116, current rewards: 114.70960, mean: 0.07597
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11117, current rewards: 120.24773, mean: 0.07708
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11118, current rewards: 125.77330, mean: 0.07812
[32m[0906 14-00-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11110, current rewards: 131.30289, mean: 0.07910
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11101, current rewards: 136.82754, mean: 0.08002
[32m[0906 14-00-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11099, current rewards: 142.34960, mean: 0.08088
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11100, current rewards: 147.87755, mean: 0.08170
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11102, current rewards: 153.40886, mean: 0.08248
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11103, current rewards: 153.84315, mean: 0.08055
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11103, current rewards: 156.16596, mean: 0.07968
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11105, current rewards: 165.30649, mean: 0.08224
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11106, current rewards: 174.44944, mean: 0.08468
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11106, current rewards: 183.57714, mean: 0.08700
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11108, current rewards: 185.40086, mean: 0.08583
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11108, current rewards: 189.77664, mean: 0.08587
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11109, current rewards: 194.15425, mean: 0.08591
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11109, current rewards: 198.53188, mean: 0.08594
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11109, current rewards: 202.55889, mean: 0.08583
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11109, current rewards: 206.75259, mean: 0.08579
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11110, current rewards: 210.94509, mean: 0.08575
[32m[0906 14-02-07 @Agent.py:117][0m Average action selection time: 0.1111
[32m[0906 14-02-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-02-07 @MBExp.py:227][0m Rewards obtained: [214.29772836069728], Lows: [10], Highs: [20], Total time: 1340.408722
[32m[0906 14-02-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-21 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11093, current rewards: -2.58123, mean: -0.25812
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11158, current rewards: 1.43460, mean: 0.02391
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11184, current rewards: 5.43424, mean: 0.04940
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11178, current rewards: 9.43439, mean: 0.05896
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11169, current rewards: 13.43396, mean: 0.06397
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11178, current rewards: 17.79347, mean: 0.06844
[32m[0906 14-02-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11175, current rewards: 23.03816, mean: 0.07432
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11170, current rewards: -17.01780, mean: -0.04727
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11179, current rewards: -67.01780, mean: -0.16346
[32m[0906 14-03-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11180, current rewards: -117.01780, mean: -0.25439
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11178, current rewards: -167.01780, mean: -0.32749
[32m[0906 14-03-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11171, current rewards: -217.01780, mean: -0.38753
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11141, current rewards: -267.01780, mean: -0.43773
[32m[0906 14-03-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11117, current rewards: -317.01780, mean: -0.48033
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11101, current rewards: -367.01780, mean: -0.51693
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11102, current rewards: -417.01780, mean: -0.54871
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11109, current rewards: -467.01780, mean: -0.57657
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11093, current rewards: -517.01780, mean: -0.60118
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11074, current rewards: -567.01780, mean: -0.62310
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11062, current rewards: -617.01780, mean: -0.64273
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11067, current rewards: -667.01780, mean: -0.66041
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11071, current rewards: -717.01780, mean: -0.67643
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11067, current rewards: -767.01780, mean: -0.69101
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11054, current rewards: -817.01780, mean: -0.70433
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11046, current rewards: -867.01780, mean: -0.71654
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11054, current rewards: -917.01780, mean: -0.72779
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11061, current rewards: -967.01780, mean: -0.73818
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11064, current rewards: -1017.01780, mean: -0.74781
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11070, current rewards: -1067.01780, mean: -0.75675
[32m[0906 14-05-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11074, current rewards: -1117.01780, mean: -0.76508
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11078, current rewards: -1167.01780, mean: -0.77286
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11084, current rewards: -1217.01780, mean: -0.78014
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11085, current rewards: -1267.01780, mean: -0.78697
[32m[0906 14-05-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11076, current rewards: -1317.01780, mean: -0.79338
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11071, current rewards: -1367.01780, mean: -0.79943
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11068, current rewards: -1417.01780, mean: -0.80512
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11074, current rewards: -1467.01780, mean: -0.81051
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11075, current rewards: -1517.01780, mean: -0.81560
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11077, current rewards: -1567.01780, mean: -0.82043
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11080, current rewards: -1617.01780, mean: -0.82501
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11080, current rewards: -1667.01780, mean: -0.82936
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11081, current rewards: -1717.01780, mean: -0.83350
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11083, current rewards: -1767.01780, mean: -0.83745
[32m[0906 14-06-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11084, current rewards: -1817.01780, mean: -0.84121
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11086, current rewards: -1867.01780, mean: -0.84480
[32m[0906 14-06-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11088, current rewards: -1917.01780, mean: -0.84824
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11088, current rewards: -1967.01780, mean: -0.85152
[32m[0906 14-06-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11088, current rewards: -2017.01780, mean: -0.85467
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11091, current rewards: -2067.01780, mean: -0.85768
[32m[0906 14-06-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11092, current rewards: -2117.01780, mean: -0.86058
[32m[0906 14-06-59 @Agent.py:117][0m Average action selection time: 0.1109
[32m[0906 14-06-59 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-06-59 @MBExp.py:227][0m Rewards obtained: [-2157.0177971737735], Lows: [0], Highs: [2184], Total time: 1618.4354879999999
[32m[0906 14-07-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-15 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11313, current rewards: -7.65378, mean: -0.76538
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11215, current rewards: 6.43491, mean: 0.10725
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11196, current rewards: 21.08282, mean: 0.19166
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11222, current rewards: 35.72791, mean: 0.22330
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11200, current rewards: 33.72350, mean: 0.16059
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11179, current rewards: -42.73861, mean: -0.16438
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11166, current rewards: -104.06206, mean: -0.33568
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11157, current rewards: -167.63005, mean: -0.46564
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11148, current rewards: -157.61077, mean: -0.38442
[32m[0906 14-08-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11182, current rewards: -149.28983, mean: -0.32454
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11200, current rewards: -140.95682, mean: -0.27639
[32m[0906 14-08-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11217, current rewards: -132.63088, mean: -0.23684
[32m[0906 14-08-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11197, current rewards: -124.42112, mean: -0.20397
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11165, current rewards: -115.20267, mean: -0.17455
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11143, current rewards: -104.37066, mean: -0.14700
[32m[0906 14-08-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11145, current rewards: -98.40719, mean: -0.12948
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11143, current rewards: -142.95084, mean: -0.17648
[32m[0906 14-08-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11122, current rewards: -189.39035, mean: -0.22022
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11106, current rewards: -235.80351, mean: -0.25912
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11087, current rewards: -282.24073, mean: -0.29400
[32m[0906 14-09-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11088, current rewards: -324.26136, mean: -0.32105
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11090, current rewards: -364.99638, mean: -0.34434
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11076, current rewards: -405.59496, mean: -0.36540
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11064, current rewards: -450.82683, mean: -0.38864
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11054, current rewards: -496.07531, mean: -0.40998
[32m[0906 14-09-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11058, current rewards: -541.35994, mean: -0.42965
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11063, current rewards: -582.11314, mean: -0.44436
[32m[0906 14-09-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11064, current rewards: -595.99530, mean: -0.43823
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11067, current rewards: -588.76081, mean: -0.41756
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11071, current rewards: -580.81104, mean: -0.39782
[32m[0906 14-10-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11073, current rewards: -573.58116, mean: -0.37986
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11075, current rewards: -566.36117, mean: -0.36305
[32m[0906 14-10-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11072, current rewards: -559.13208, mean: -0.34729
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11062, current rewards: -551.90799, mean: -0.33247
[32m[0906 14-10-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11052, current rewards: -544.68778, mean: -0.31853
[32m[0906 14-10-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11049, current rewards: -542.59687, mean: -0.30829
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11052, current rewards: -534.66816, mean: -0.29540
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11054, current rewards: -527.09876, mean: -0.28339
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11058, current rewards: -518.72179, mean: -0.27158
[32m[0906 14-10-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11060, current rewards: -510.33425, mean: -0.26037
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11061, current rewards: -501.96060, mean: -0.24973
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11064, current rewards: -493.57956, mean: -0.23960
[32m[0906 14-11-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11067, current rewards: -485.20662, mean: -0.22996
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11069, current rewards: -476.82259, mean: -0.22075
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11070, current rewards: -468.44685, mean: -0.21197
[32m[0906 14-11-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11070, current rewards: -471.79240, mean: -0.20876
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11073, current rewards: -460.85573, mean: -0.19950
[32m[0906 14-11-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11074, current rewards: -449.90348, mean: -0.19064
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11074, current rewards: -438.95911, mean: -0.18214
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11076, current rewards: -428.02210, mean: -0.17399
[32m[0906 14-11-53 @Agent.py:117][0m Average action selection time: 0.1108
[32m[0906 14-11-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-11-53 @MBExp.py:227][0m Rewards obtained: [-419.2954810435637], Lows: [405], Highs: [24], Total time: 1896.0669359999997
[32m[0906 14-12-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-12 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11271, current rewards: -5.65033, mean: -0.56503
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11144, current rewards: -0.86720, mean: -0.01445
[32m[0906 14-12-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11124, current rewards: 4.37520, mean: 0.03977
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11142, current rewards: 9.61972, mean: 0.06012
[32m[0906 14-12-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11153, current rewards: 14.95332, mean: 0.07121
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11142, current rewards: 20.13621, mean: 0.07745
[32m[0906 14-12-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11134, current rewards: 25.31072, mean: 0.08165
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11138, current rewards: 30.49149, mean: 0.08470
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11134, current rewards: 35.67402, mean: 0.08701
[32m[0906 14-13-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11133, current rewards: 40.85820, mean: 0.08882
[32m[0906 14-13-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11134, current rewards: 46.04267, mean: 0.09028
[32m[0906 14-13-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11107, current rewards: 51.22856, mean: 0.09148
[32m[0906 14-13-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11073, current rewards: 57.29455, mean: 0.09393
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11051, current rewards: 62.20446, mean: 0.09425
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11040, current rewards: 61.82971, mean: 0.08708
[32m[0906 14-13-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11046, current rewards: 66.72904, mean: 0.08780
[32m[0906 14-13-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11049, current rewards: 71.62755, mean: 0.08843
[32m[0906 14-13-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11032, current rewards: 76.52276, mean: 0.08898
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11017, current rewards: 81.41923, mean: 0.08947
[32m[0906 14-13-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11007, current rewards: 86.31314, mean: 0.08991
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11013, current rewards: 91.45603, mean: 0.09055
[32m[0906 14-14-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11008, current rewards: 86.64209, mean: 0.08174
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10998, current rewards: 92.24319, mean: 0.08310
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10988, current rewards: 97.80634, mean: 0.08432
[32m[0906 14-14-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10981, current rewards: 103.36949, mean: 0.08543
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10990, current rewards: 108.93264, mean: 0.08645
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10996, current rewards: 114.49579, mean: 0.08740
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11002, current rewards: 120.05894, mean: 0.08828
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11006, current rewards: 125.43567, mean: 0.08896
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11011, current rewards: 100.72487, mean: 0.06899
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11018, current rewards: 105.92355, mean: 0.07015
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11021, current rewards: 111.11560, mean: 0.07123
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11014, current rewards: 102.06859, mean: 0.06340
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11006, current rewards: 107.43608, mean: 0.06472
[32m[0906 14-15-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11000, current rewards: 112.78495, mean: 0.06596
[32m[0906 14-15-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10999, current rewards: 118.14140, mean: 0.06713
[32m[0906 14-15-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11003, current rewards: 123.48618, mean: 0.06822
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11006, current rewards: 130.49318, mean: 0.07016
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11009, current rewards: 136.99751, mean: 0.07173
[32m[0906 14-15-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11013, current rewards: 143.46933, mean: 0.07320
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11015, current rewards: 138.99412, mean: 0.06915
[32m[0906 14-15-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11018, current rewards: 143.53785, mean: 0.06968
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11020, current rewards: 148.07546, mean: 0.07018
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11022, current rewards: 152.61745, mean: 0.07066
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11024, current rewards: 157.15299, mean: 0.07111
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11027, current rewards: 161.65750, mean: 0.07153
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11030, current rewards: 165.94075, mean: 0.07184
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11034, current rewards: 170.44167, mean: 0.07222
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11036, current rewards: 174.93936, mean: 0.07259
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11038, current rewards: 179.43548, mean: 0.07294
[32m[0906 14-16-48 @Agent.py:117][0m Average action selection time: 0.1104
[32m[0906 14-16-48 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-16-48 @MBExp.py:227][0m Rewards obtained: [183.0359252219708], Lows: [14], Highs: [44], Total time: 2172.743466
[32m[0906 14-17-09 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-09 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-17-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11157, current rewards: 1.63653, mean: 0.16365
[32m[0906 14-17-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11131, current rewards: 7.61362, mean: 0.12689
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11157, current rewards: 13.65458, mean: 0.12413
[32m[0906 14-17-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11163, current rewards: 19.69449, mean: 0.12309
[32m[0906 14-17-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11174, current rewards: 25.03965, mean: 0.11924
[32m[0906 14-17-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11177, current rewards: 31.00456, mean: 0.11925
[32m[0906 14-17-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11172, current rewards: 36.96979, mean: 0.11926
[32m[0906 14-17-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11162, current rewards: 42.93183, mean: 0.11926
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11159, current rewards: 48.89938, mean: 0.11927
[32m[0906 14-18-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11150, current rewards: 54.86183, mean: 0.11926
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11143, current rewards: 60.82619, mean: 0.11927
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11116, current rewards: 66.78900, mean: 0.11927
[32m[0906 14-18-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11084, current rewards: 73.53331, mean: 0.12055
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11056, current rewards: 62.63362, mean: 0.09490
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11045, current rewards: 63.29411, mean: 0.08915
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11053, current rewards: 69.70294, mean: 0.09171
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11036, current rewards: 76.12851, mean: 0.09399
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11020, current rewards: 82.54531, mean: 0.09598
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11005, current rewards: 88.96570, mean: 0.09776
[32m[0906 14-18-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10991, current rewards: 95.37479, mean: 0.09935
[32m[0906 14-19-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10994, current rewards: 102.32752, mean: 0.10131
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10982, current rewards: 107.59565, mean: 0.10151
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10971, current rewards: 112.72282, mean: 0.10155
[32m[0906 14-19-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10963, current rewards: 117.84986, mean: 0.10159
[32m[0906 14-19-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10955, current rewards: 122.97713, mean: 0.10163
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10965, current rewards: 128.10768, mean: 0.10167
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10971, current rewards: 133.23302, mean: 0.10170
[32m[0906 14-19-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10977, current rewards: 138.36704, mean: 0.10174
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10986, current rewards: 143.49397, mean: 0.10177
[32m[0906 14-19-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10990, current rewards: 148.94513, mean: 0.10202
[32m[0906 14-19-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10995, current rewards: 154.19599, mean: 0.10212
[32m[0906 14-20-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10996, current rewards: 146.97889, mean: 0.09422
[32m[0906 14-20-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10987, current rewards: 153.15516, mean: 0.09513
[32m[0906 14-20-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10981, current rewards: 159.32560, mean: 0.09598
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10976, current rewards: 165.49841, mean: 0.09678
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10975, current rewards: 171.67469, mean: 0.09754
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10980, current rewards: 177.84653, mean: 0.09826
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10985, current rewards: 184.04951, mean: 0.09895
[32m[0906 14-20-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10988, current rewards: 191.02571, mean: 0.10001
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10992, current rewards: 197.11191, mean: 0.10057
[32m[0906 14-20-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10996, current rewards: 203.20266, mean: 0.10110
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11000, current rewards: 209.28918, mean: 0.10160
[32m[0906 14-21-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11003, current rewards: 209.91578, mean: 0.09949
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11006, current rewards: 216.25061, mean: 0.10012
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11008, current rewards: 222.59816, mean: 0.10072
[32m[0906 14-21-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11011, current rewards: 228.94011, mean: 0.10130
[32m[0906 14-21-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11013, current rewards: 234.16795, mean: 0.10137
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11016, current rewards: 239.46833, mean: 0.10147
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11021, current rewards: 244.77760, mean: 0.10157
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11022, current rewards: 250.08355, mean: 0.10166
[32m[0906 14-21-46 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-21-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-21-46 @MBExp.py:227][0m Rewards obtained: [244.06699177100762], Lows: [11], Highs: [27], Total time: 2449.019785
[32m[0906 14-22-09 @MBExp.py:144][0m ####################################################################
[32m[0906 14-22-09 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-22-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11142, current rewards: -5.51880, mean: -0.55188
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11145, current rewards: 0.05024, mean: 0.00084
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11150, current rewards: 5.54252, mean: 0.05039
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11174, current rewards: 11.03499, mean: 0.06897
[32m[0906 14-22-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11158, current rewards: 16.86681, mean: 0.08032
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11153, current rewards: 22.63600, mean: 0.08706
[32m[0906 14-22-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11159, current rewards: 28.36278, mean: 0.09149
[32m[0906 14-22-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11152, current rewards: 34.09228, mean: 0.09470
[32m[0906 14-22-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11153, current rewards: 39.81856, mean: 0.09712
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11148, current rewards: 45.54578, mean: 0.09901
[32m[0906 14-23-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11124, current rewards: 44.04582, mean: 0.08636
[32m[0906 14-23-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11093, current rewards: 49.50338, mean: 0.08840
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11067, current rewards: 54.95892, mean: 0.09010
[32m[0906 14-23-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11046, current rewards: 59.42269, mean: 0.09003
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11034, current rewards: 64.05846, mean: 0.09022
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11038, current rewards: 68.69335, mean: 0.09039
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11022, current rewards: 73.32861, mean: 0.09053
[32m[0906 14-23-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11012, current rewards: 77.96202, mean: 0.09065
[32m[0906 14-23-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11003, current rewards: 82.59295, mean: 0.09076
[32m[0906 14-23-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10991, current rewards: 87.22518, mean: 0.09086
[32m[0906 14-24-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10991, current rewards: 91.86133, mean: 0.09095
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10980, current rewards: 96.50051, mean: 0.09104
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10974, current rewards: 101.12955, mean: 0.09111
[32m[0906 14-24-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10968, current rewards: 95.76300, mean: 0.08255
[32m[0906 14-24-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10961, current rewards: 101.22755, mean: 0.08366
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10972, current rewards: 106.69205, mean: 0.08468
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10980, current rewards: 112.15110, mean: 0.08561
[32m[0906 14-24-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10987, current rewards: 117.61603, mean: 0.08648
[32m[0906 14-24-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10991, current rewards: 123.07729, mean: 0.08729
[32m[0906 14-24-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10998, current rewards: 129.57863, mean: 0.08875
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11001, current rewards: 129.65457, mean: 0.08586
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10995, current rewards: 134.24858, mean: 0.08606
[32m[0906 14-25-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10988, current rewards: 138.78105, mean: 0.08620
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10982, current rewards: 143.31044, mean: 0.08633
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10978, current rewards: 147.85069, mean: 0.08646
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10978, current rewards: 152.40419, mean: 0.08659
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10982, current rewards: 156.93635, mean: 0.08671
[32m[0906 14-25-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10987, current rewards: 161.67746, mean: 0.08692
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10991, current rewards: 65.93250, mean: 0.03452
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10994, current rewards: -34.06750, mean: -0.01738
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10998, current rewards: -134.06750, mean: -0.06670
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11001, current rewards: -234.06750, mean: -0.11363
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11004, current rewards: -334.06750, mean: -0.15833
[32m[0906 14-26-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11008, current rewards: -434.06750, mean: -0.20096
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11010, current rewards: -534.06750, mean: -0.24166
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11011, current rewards: -634.06750, mean: -0.28056
[32m[0906 14-26-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11015, current rewards: -734.06750, mean: -0.31778
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11017, current rewards: -759.99211, mean: -0.32203
[32m[0906 14-26-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11018, current rewards: -793.06907, mean: -0.32907
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11020, current rewards: -819.36929, mean: -0.33308
[32m[0906 14-26-45 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-26-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-26-45 @MBExp.py:227][0m Rewards obtained: [-848.0082286882873], Lows: [526], Highs: [21], Total time: 2725.262918
[32m[0906 14-27-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-11 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-27-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11001, current rewards: -4.94234, mean: -0.49423
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11094, current rewards: 0.06497, mean: 0.00108
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11093, current rewards: 4.60613, mean: 0.04187
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11137, current rewards: 9.09744, mean: 0.05686
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11152, current rewards: 13.55892, mean: 0.06457
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11142, current rewards: 18.04669, mean: 0.06941
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11137, current rewards: 22.53927, mean: 0.07271
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11137, current rewards: 27.02585, mean: 0.07507
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11143, current rewards: 31.52085, mean: 0.07688
[32m[0906 14-28-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11138, current rewards: 36.01443, mean: 0.07829
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11098, current rewards: 40.50593, mean: 0.07942
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11069, current rewards: 44.99743, mean: 0.08035
[32m[0906 14-28-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11041, current rewards: 49.48860, mean: 0.08113
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11013, current rewards: 53.97896, mean: 0.08179
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11003, current rewards: 58.47249, mean: 0.08236
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10998, current rewards: 52.52265, mean: 0.06911
[32m[0906 14-28-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10983, current rewards: 57.62990, mean: 0.07115
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10974, current rewards: 62.89235, mean: 0.07313
[32m[0906 14-28-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10962, current rewards: 68.15735, mean: 0.07490
[32m[0906 14-28-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10950, current rewards: 73.41895, mean: 0.07648
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10942, current rewards: 79.44707, mean: 0.07866
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10933, current rewards: 84.84424, mean: 0.08004
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10924, current rewards: 90.24377, mean: 0.08130
[32m[0906 14-29-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10918, current rewards: 95.63982, mean: 0.08245
[32m[0906 14-29-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10914, current rewards: 101.04031, mean: 0.08350
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10924, current rewards: 106.43739, mean: 0.08447
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10933, current rewards: 111.66196, mean: 0.08524
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10940, current rewards: 117.14129, mean: 0.08613
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10947, current rewards: 122.00692, mean: 0.08653
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10956, current rewards: 127.26116, mean: 0.08717
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10958, current rewards: 132.51667, mean: 0.08776
[32m[0906 14-30-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10952, current rewards: 137.76641, mean: 0.08831
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10946, current rewards: 143.01299, mean: 0.08883
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10939, current rewards: 148.26879, mean: 0.08932
[32m[0906 14-30-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10933, current rewards: 153.52382, mean: 0.08978
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10934, current rewards: 158.77861, mean: 0.09022
[32m[0906 14-30-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10939, current rewards: 164.44389, mean: 0.09085
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10946, current rewards: 169.80397, mean: 0.09129
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10951, current rewards: 175.16402, mean: 0.09171
[32m[0906 14-30-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10954, current rewards: 180.52941, mean: 0.09211
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10960, current rewards: 185.88832, mean: 0.09248
[32m[0906 14-30-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10963, current rewards: 180.69775, mean: 0.08772
[32m[0906 14-31-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10967, current rewards: 186.25954, mean: 0.08827
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10972, current rewards: 191.82342, mean: 0.08881
[32m[0906 14-31-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10975, current rewards: 197.59621, mean: 0.08941
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10978, current rewards: 203.87140, mean: 0.09021
[32m[0906 14-31-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10982, current rewards: 203.85523, mean: 0.08825
[32m[0906 14-31-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10985, current rewards: 211.08167, mean: 0.08944
[32m[0906 14-31-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10987, current rewards: 218.30197, mean: 0.09058
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10991, current rewards: 225.53243, mean: 0.09168
[32m[0906 14-31-46 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-31-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-31-46 @MBExp.py:227][0m Rewards obtained: [231.3138388561791], Lows: [10], Highs: [13], Total time: 3000.775185
[32m[0906 14-32-14 @MBExp.py:144][0m ####################################################################
[32m[0906 14-32-14 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 14-32-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11075, current rewards: -5.59397, mean: -0.55940
[32m[0906 14-32-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11113, current rewards: 1.18863, mean: 0.01981
[32m[0906 14-32-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11143, current rewards: 7.09186, mean: 0.06447
[32m[0906 14-32-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11143, current rewards: 13.00598, mean: 0.08129
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11130, current rewards: 18.90402, mean: 0.09002
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11129, current rewards: 24.80879, mean: 0.09542
[32m[0906 14-32-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11129, current rewards: 30.71435, mean: 0.09908
[32m[0906 14-32-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11130, current rewards: 36.61852, mean: 0.10172
[32m[0906 14-33-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11138, current rewards: 42.52992, mean: 0.10373
[32m[0906 14-33-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11118, current rewards: 47.61447, mean: 0.10351
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11084, current rewards: 52.20499, mean: 0.10236
[32m[0906 14-33-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11059, current rewards: 56.55722, mean: 0.10100
[32m[0906 14-33-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11031, current rewards: 61.18667, mean: 0.10031
[32m[0906 14-33-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11008, current rewards: 65.83164, mean: 0.09974
[32m[0906 14-33-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10998, current rewards: 70.47290, mean: 0.09926
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10981, current rewards: 75.12059, mean: 0.09884
[32m[0906 14-33-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10969, current rewards: 79.76712, mean: 0.09848
[32m[0906 14-33-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10963, current rewards: 84.41587, mean: 0.09816
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10952, current rewards: 89.06062, mean: 0.09787
[32m[0906 14-34-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10936, current rewards: 93.71020, mean: 0.09761
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10925, current rewards: 85.92350, mean: 0.08507
[32m[0906 14-34-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10918, current rewards: 89.30805, mean: 0.08425
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10911, current rewards: 92.69073, mean: 0.08351
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10907, current rewards: 96.07340, mean: 0.08282
[32m[0906 14-34-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10903, current rewards: 96.25312, mean: 0.07955
[32m[0906 14-34-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10915, current rewards: 46.25312, mean: 0.03671
[32m[0906 14-34-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10925, current rewards: -3.74688, mean: -0.00286
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10934, current rewards: -53.74688, mean: -0.03952
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10945, current rewards: -103.74688, mean: -0.07358
[32m[0906 14-34-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10953, current rewards: -153.74688, mean: -0.10531
[32m[0906 14-35-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10956, current rewards: -203.74688, mean: -0.13493
[32m[0906 14-35-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10953, current rewards: -253.74688, mean: -0.16266
[32m[0906 14-35-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10948, current rewards: -303.74688, mean: -0.18866
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10944, current rewards: -353.74688, mean: -0.21310
[32m[0906 14-35-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10942, current rewards: -403.74688, mean: -0.23611
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10943, current rewards: -453.74688, mean: -0.25781
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10948, current rewards: -503.74688, mean: -0.27831
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10956, current rewards: -553.74688, mean: -0.29771
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10960, current rewards: -603.74688, mean: -0.31610
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10966, current rewards: -653.74688, mean: -0.33354
[32m[0906 14-35-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10972, current rewards: -703.74688, mean: -0.35012
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10977, current rewards: -753.74688, mean: -0.36590
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10980, current rewards: -803.74688, mean: -0.38092
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10985, current rewards: -853.74688, mean: -0.39525
[32m[0906 14-36-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10989, current rewards: -903.74688, mean: -0.40894
[32m[0906 14-36-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10991, current rewards: -953.74688, mean: -0.42201
[32m[0906 14-36-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10996, current rewards: -1003.74688, mean: -0.43452
[32m[0906 14-36-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10998, current rewards: -1053.74688, mean: -0.44650
[32m[0906 14-36-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11002, current rewards: -1103.74688, mean: -0.45799
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11006, current rewards: -1153.74688, mean: -0.46900
[32m[0906 14-36-50 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-36-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-36-50 @MBExp.py:227][0m Rewards obtained: [-1193.7468819127848], Lows: [6], Highs: [1299], Total time: 3276.671592
[32m[0906 14-37-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-37-21 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-37-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11168, current rewards: -14.00000, mean: -1.40000
[32m[0906 14-37-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11228, current rewards: -8.95189, mean: -0.14920
[32m[0906 14-37-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11279, current rewards: -1.95015, mean: -0.01773
[32m[0906 14-37-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11252, current rewards: 4.99520, mean: 0.03122
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11256, current rewards: 11.93565, mean: 0.05684
[32m[0906 14-37-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11234, current rewards: 18.87754, mean: 0.07261
[32m[0906 14-37-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11226, current rewards: 25.82341, mean: 0.08330
[32m[0906 14-38-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11222, current rewards: 32.77314, mean: 0.09104
[32m[0906 14-38-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11212, current rewards: 39.71979, mean: 0.09688
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11173, current rewards: 46.65579, mean: 0.10143
[32m[0906 14-38-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11145, current rewards: 53.59619, mean: 0.10509
[32m[0906 14-38-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11116, current rewards: 61.09541, mean: 0.10910
[32m[0906 14-38-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11092, current rewards: 68.37602, mean: 0.11209
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11073, current rewards: 64.51444, mean: 0.09775
[32m[0906 14-38-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11051, current rewards: 70.47558, mean: 0.09926
[32m[0906 14-38-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11034, current rewards: 76.43692, mean: 0.10057
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11023, current rewards: 82.40192, mean: 0.10173
[32m[0906 14-38-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11012, current rewards: 88.35918, mean: 0.10274
[32m[0906 14-39-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10999, current rewards: 94.30919, mean: 0.10364
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10978, current rewards: 99.70342, mean: 0.10386
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10962, current rewards: 105.46746, mean: 0.10442
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10951, current rewards: 111.22818, mean: 0.10493
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10949, current rewards: 116.99640, mean: 0.10540
[32m[0906 14-39-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10942, current rewards: 122.76549, mean: 0.10583
[32m[0906 14-39-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10938, current rewards: 128.52819, mean: 0.10622
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10951, current rewards: 134.29376, mean: 0.10658
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10960, current rewards: 129.18339, mean: 0.09861
[32m[0906 14-39-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10967, current rewards: 134.15209, mean: 0.09864
[32m[0906 14-39-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10975, current rewards: 140.27081, mean: 0.09948
[32m[0906 14-40-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10982, current rewards: 145.16798, mean: 0.09943
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10977, current rewards: 150.05768, mean: 0.09938
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10974, current rewards: 154.95275, mean: 0.09933
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10969, current rewards: 149.70258, mean: 0.09298
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10965, current rewards: 154.87150, mean: 0.09330
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10960, current rewards: 160.03634, mean: 0.09359
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10959, current rewards: 165.20350, mean: 0.09387
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10968, current rewards: 170.05469, mean: 0.09395
[32m[0906 14-40-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10973, current rewards: 175.40352, mean: 0.09430
[32m[0906 14-40-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10979, current rewards: 180.74776, mean: 0.09463
[32m[0906 14-40-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10986, current rewards: 186.09309, mean: 0.09495
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10992, current rewards: 191.44297, mean: 0.09525
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10996, current rewards: 196.79256, mean: 0.09553
[32m[0906 14-41-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11001, current rewards: 202.14063, mean: 0.09580
[32m[0906 14-41-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11005, current rewards: 197.02724, mean: 0.09122
[32m[0906 14-41-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11011, current rewards: 202.63565, mean: 0.09169
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11016, current rewards: 208.37366, mean: 0.09220
[32m[0906 14-41-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11019, current rewards: 214.09006, mean: 0.09268
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11022, current rewards: 219.80796, mean: 0.09314
[32m[0906 14-41-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11027, current rewards: 225.52450, mean: 0.09358
[32m[0906 14-41-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11030, current rewards: 231.23939, mean: 0.09400
[32m[0906 14-41-57 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-41-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-41-57 @MBExp.py:227][0m Rewards obtained: [235.81085955427804], Lows: [25], Highs: [6], Total time: 3553.195783
[32m[0906 14-42-30 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-30 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-42-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11361, current rewards: 1.30793, mean: 0.13079
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11169, current rewards: 8.55349, mean: 0.14256
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11165, current rewards: 15.77672, mean: 0.14342
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11172, current rewards: 22.92691, mean: 0.14329
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11164, current rewards: 24.39009, mean: 0.11614
[32m[0906 14-42-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11169, current rewards: 28.87790, mean: 0.11107
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11181, current rewards: 34.49091, mean: 0.11126
[32m[0906 14-43-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11176, current rewards: 40.10746, mean: 0.11141
[32m[0906 14-43-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11163, current rewards: 33.88144, mean: 0.08264
[32m[0906 14-43-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11128, current rewards: 39.43353, mean: 0.08573
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11093, current rewards: 44.97300, mean: 0.08818
[32m[0906 14-43-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11064, current rewards: 50.51569, mean: 0.09021
[32m[0906 14-43-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11046, current rewards: 50.70031, mean: 0.08312
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11026, current rewards: 59.73189, mean: 0.09050
[32m[0906 14-43-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10997, current rewards: 67.85994, mean: 0.09558
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10988, current rewards: 76.01485, mean: 0.10002
[32m[0906 14-43-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10975, current rewards: 84.17756, mean: 0.10392
[32m[0906 14-44-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10963, current rewards: 92.30014, mean: 0.10733
[32m[0906 14-44-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10951, current rewards: 89.78152, mean: 0.09866
[32m[0906 14-44-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10924, current rewards: 95.11963, mean: 0.09908
[32m[0906 14-44-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10912, current rewards: 100.51281, mean: 0.09952
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10908, current rewards: 105.90044, mean: 0.09991
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10901, current rewards: 111.28481, mean: 0.10026
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10898, current rewards: 116.67147, mean: 0.10058
[32m[0906 14-44-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10898, current rewards: 122.05703, mean: 0.10087
[32m[0906 14-44-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10909, current rewards: 127.44538, mean: 0.10115
[32m[0906 14-44-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10920, current rewards: 132.83161, mean: 0.10140
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10930, current rewards: 138.07366, mean: 0.10152
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10937, current rewards: 143.47616, mean: 0.10176
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10941, current rewards: 144.03112, mean: 0.09865
[32m[0906 14-45-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10934, current rewards: 149.70648, mean: 0.09914
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10930, current rewards: 155.38128, mean: 0.09960
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10927, current rewards: 161.06234, mean: 0.10004
[32m[0906 14-45-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10921, current rewards: 166.74375, mean: 0.10045
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10915, current rewards: 172.41602, mean: 0.10083
[32m[0906 14-45-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10915, current rewards: 178.34095, mean: 0.10133
[32m[0906 14-45-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10921, current rewards: 183.96638, mean: 0.10164
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10927, current rewards: 189.59150, mean: 0.10193
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10935, current rewards: 195.21516, mean: 0.10221
[32m[0906 14-46-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10940, current rewards: 200.83769, mean: 0.10247
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10947, current rewards: 206.46766, mean: 0.10272
[32m[0906 14-46-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10953, current rewards: 212.08861, mean: 0.10296
[32m[0906 14-46-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10958, current rewards: 217.70941, mean: 0.10318
[32m[0906 14-46-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10964, current rewards: 223.69892, mean: 0.10356
[32m[0906 14-46-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10969, current rewards: 229.18853, mean: 0.10371
[32m[0906 14-46-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10973, current rewards: 234.67263, mean: 0.10384
[32m[0906 14-46-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10978, current rewards: 240.15373, mean: 0.10396
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10983, current rewards: 233.67242, mean: 0.09901
[32m[0906 14-46-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10986, current rewards: 239.67571, mean: 0.09945
[32m[0906 14-47-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10991, current rewards: 245.16361, mean: 0.09966
[32m[0906 14-47-05 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-47-05 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-47-06 @MBExp.py:227][0m Rewards obtained: [249.55483055969543], Lows: [17], Highs: [16], Total time: 3828.7375070000003
[32m[0906 14-47-41 @MBExp.py:144][0m ####################################################################
[32m[0906 14-47-41 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-47-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11217, current rewards: -6.66144, mean: -0.66614
[32m[0906 14-47-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11174, current rewards: -1.06098, mean: -0.01768
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11175, current rewards: 5.00579, mean: 0.04551
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11182, current rewards: 10.69013, mean: 0.06681
[32m[0906 14-48-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11171, current rewards: 16.37815, mean: 0.07799
[32m[0906 14-48-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11164, current rewards: 22.05988, mean: 0.08485
[32m[0906 14-48-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11156, current rewards: 27.74439, mean: 0.08950
[32m[0906 14-48-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11156, current rewards: 33.41872, mean: 0.09283
[32m[0906 14-48-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11125, current rewards: 39.10346, mean: 0.09537
[32m[0906 14-48-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11092, current rewards: 34.46777, mean: 0.07493
[32m[0906 14-48-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11064, current rewards: 39.56762, mean: 0.07758
[32m[0906 14-48-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11034, current rewards: 45.43105, mean: 0.08113
[32m[0906 14-48-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11013, current rewards: 51.29369, mean: 0.08409
[32m[0906 14-48-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11000, current rewards: 57.15882, mean: 0.08660
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10964, current rewards: 63.01756, mean: 0.08876
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10954, current rewards: 68.88264, mean: 0.09064
[32m[0906 14-49-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10946, current rewards: 74.74343, mean: 0.09228
[32m[0906 14-49-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10938, current rewards: 74.25698, mean: 0.08635
[32m[0906 14-49-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10919, current rewards: 76.51339, mean: 0.08408
[32m[0906 14-49-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10897, current rewards: 82.29969, mean: 0.08573
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10881, current rewards: 87.83077, mean: 0.08696
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10878, current rewards: 93.36142, mean: 0.08808
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10876, current rewards: 98.89167, mean: 0.08909
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10873, current rewards: 104.42284, mean: 0.09002
[32m[0906 14-49-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10871, current rewards: 109.95295, mean: 0.09087
[32m[0906 14-49-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10887, current rewards: 115.48185, mean: 0.09165
[32m[0906 14-50-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10897, current rewards: 121.01346, mean: 0.09238
[32m[0906 14-50-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10908, current rewards: 120.43943, mean: 0.08856
[32m[0906 14-50-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10920, current rewards: 125.91121, mean: 0.08930
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10917, current rewards: 131.38054, mean: 0.08999
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10913, current rewards: 136.85804, mean: 0.09063
[32m[0906 14-50-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10913, current rewards: 142.33010, mean: 0.09124
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10910, current rewards: 147.80712, mean: 0.09181
[32m[0906 14-50-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10906, current rewards: 153.28388, mean: 0.09234
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10905, current rewards: 158.76072, mean: 0.09284
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10906, current rewards: 164.24173, mean: 0.09332
[32m[0906 14-50-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10915, current rewards: 169.71935, mean: 0.09377
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10925, current rewards: 165.14186, mean: 0.08879
[32m[0906 14-51-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10933, current rewards: 170.85936, mean: 0.08946
[32m[0906 14-51-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10943, current rewards: 176.57756, mean: 0.09009
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10951, current rewards: 182.29805, mean: 0.09070
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10961, current rewards: 188.02323, mean: 0.09127
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10971, current rewards: 193.74164, mean: 0.09182
[32m[0906 14-51-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10978, current rewards: 199.69530, mean: 0.09245
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10985, current rewards: 195.06252, mean: 0.08826
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10992, current rewards: 200.51844, mean: 0.08872
[32m[0906 14-51-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10998, current rewards: 205.97250, mean: 0.08917
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11002, current rewards: 211.43044, mean: 0.08959
[32m[0906 14-52-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11008, current rewards: 216.88576, mean: 0.08999
[32m[0906 14-52-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11012, current rewards: 222.34139, mean: 0.09038
[32m[0906 14-52-17 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-52-17 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-52-17 @MBExp.py:227][0m Rewards obtained: [226.70678547629578], Lows: [21], Highs: [11], Total time: 4104.838650000001
[32m[0906 14-52-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-54 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-52-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11117, current rewards: -4.30905, mean: -0.43091
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11185, current rewards: 1.54231, mean: 0.02571
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11205, current rewards: 7.21580, mean: 0.06560
[32m[0906 14-53-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11205, current rewards: 12.88822, mean: 0.08055
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11206, current rewards: 18.55553, mean: 0.08836
[32m[0906 14-53-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11217, current rewards: 24.22698, mean: 0.09318
[32m[0906 14-53-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11215, current rewards: 29.89919, mean: 0.09645
[32m[0906 14-53-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11209, current rewards: 35.57350, mean: 0.09882
[32m[0906 14-53-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11167, current rewards: 41.24780, mean: 0.10060
[32m[0906 14-53-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11126, current rewards: 47.68696, mean: 0.10367
[32m[0906 14-53-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11091, current rewards: 56.42189, mean: 0.11063
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11068, current rewards: 65.16425, mean: 0.11636
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11051, current rewards: 73.90896, mean: 0.12116
[32m[0906 14-54-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11021, current rewards: 82.64909, mean: 0.12523
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10988, current rewards: 91.39031, mean: 0.12872
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10975, current rewards: 100.14253, mean: 0.13177
[32m[0906 14-54-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10964, current rewards: 108.90173, mean: 0.13445
[32m[0906 14-54-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10959, current rewards: 118.55125, mean: 0.13785
[32m[0906 14-54-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10934, current rewards: 127.85794, mean: 0.14050
[32m[0906 14-54-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10910, current rewards: 137.03827, mean: 0.14275
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10898, current rewards: 139.67900, mean: 0.13830
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10893, current rewards: 141.15231, mean: 0.13316
[32m[0906 14-54-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10891, current rewards: 146.92095, mean: 0.13236
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10890, current rewards: 152.69126, mean: 0.13163
[32m[0906 14-55-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10889, current rewards: 158.46199, mean: 0.13096
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10899, current rewards: 164.23215, mean: 0.13034
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10912, current rewards: 170.97620, mean: 0.13052
[32m[0906 14-55-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10924, current rewards: 173.51097, mean: 0.12758
[32m[0906 14-55-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10931, current rewards: 177.32283, mean: 0.12576
[32m[0906 14-55-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10930, current rewards: 183.28989, mean: 0.12554
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10927, current rewards: 189.25682, mean: 0.12534
[32m[0906 14-55-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10924, current rewards: 195.22420, mean: 0.12514
[32m[0906 14-55-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10922, current rewards: 188.85448, mean: 0.11730
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10920, current rewards: 180.09997, mean: 0.10849
[32m[0906 14-56-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10919, current rewards: 181.61854, mean: 0.10621
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10921, current rewards: 188.83720, mean: 0.10729
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10929, current rewards: 196.06732, mean: 0.10832
[32m[0906 14-56-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10937, current rewards: 203.28775, mean: 0.10929
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10944, current rewards: 210.51020, mean: 0.11021
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10950, current rewards: 203.22419, mean: 0.10369
[32m[0906 14-56-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10957, current rewards: 208.05979, mean: 0.10351
[32m[0906 14-56-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10962, current rewards: 212.89441, mean: 0.10335
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10967, current rewards: 217.42303, mean: 0.10304
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10974, current rewards: 222.20531, mean: 0.10287
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10979, current rewards: 226.98759, mean: 0.10271
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10985, current rewards: 231.76649, mean: 0.10255
[32m[0906 14-57-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10990, current rewards: 236.54567, mean: 0.10240
[32m[0906 14-57-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10993, current rewards: 241.32454, mean: 0.10226
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10997, current rewards: 246.10362, mean: 0.10212
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11002, current rewards: 245.74337, mean: 0.09990
[32m[0906 14-57-30 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-57-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-57-30 @MBExp.py:227][0m Rewards obtained: [250.29538201522968], Lows: [26], Highs: [20], Total time: 4380.734839000001
[32m[0906 14-58-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-58-10 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-58-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11151, current rewards: -4.51354, mean: -0.45135
[32m[0906 14-58-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11148, current rewards: -40.23861, mean: -0.67064
[32m[0906 14-58-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11168, current rewards: -70.39345, mean: -0.63994
[32m[0906 14-58-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11186, current rewards: -115.02869, mean: -0.71893
[32m[0906 14-58-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11194, current rewards: -153.09479, mean: -0.72902
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11195, current rewards: -187.28676, mean: -0.72033
[32m[0906 14-58-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11201, current rewards: -235.56653, mean: -0.75989
[32m[0906 14-58-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11171, current rewards: -265.31507, mean: -0.73699
[32m[0906 14-58-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11129, current rewards: -306.13359, mean: -0.74667
[32m[0906 14-59-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11101, current rewards: -347.55315, mean: -0.75555
[32m[0906 14-59-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11073, current rewards: -373.92593, mean: -0.73319
[32m[0906 14-59-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11049, current rewards: -408.04993, mean: -0.72866
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11031, current rewards: -466.80844, mean: -0.76526
[32m[0906 14-59-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10992, current rewards: -527.65866, mean: -0.79948
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10964, current rewards: -601.83709, mean: -0.84766
[32m[0906 14-59-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10957, current rewards: -662.59195, mean: -0.87183
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10953, current rewards: -736.54651, mean: -0.90932
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10940, current rewards: -794.57491, mean: -0.92392
[32m[0906 14-59-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10914, current rewards: -856.14920, mean: -0.94082
[32m[0906 14-59-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10892, current rewards: -917.52475, mean: -0.95575
[32m[0906 15-00-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10879, current rewards: -972.47159, mean: -0.96284
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10877, current rewards: -1029.84796, mean: -0.97155
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10874, current rewards: -1088.79352, mean: -0.98090
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10875, current rewards: -1150.36625, mean: -0.99170
[32m[0906 15-00-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10875, current rewards: -1211.82353, mean: -1.00151
[32m[0906 15-00-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10889, current rewards: -1268.74601, mean: -1.00694
[32m[0906 15-00-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10905, current rewards: -1336.90389, mean: -1.02054
[32m[0906 15-00-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10916, current rewards: -1419.64566, mean: -1.04386
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10916, current rewards: -1504.83782, mean: -1.06726
[32m[0906 15-00-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10915, current rewards: -1582.60224, mean: -1.08397
[32m[0906 15-00-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10913, current rewards: -1662.38097, mean: -1.10091
[32m[0906 15-01-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10910, current rewards: -1737.45294, mean: -1.11375
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10910, current rewards: -1814.18682, mean: -1.12682
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10908, current rewards: -1894.23900, mean: -1.14111
[32m[0906 15-01-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10906, current rewards: -1994.23900, mean: -1.16622
[32m[0906 15-01-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10907, current rewards: -2094.23900, mean: -1.18991
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10917, current rewards: -2194.23900, mean: -1.21229
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10925, current rewards: -2294.23900, mean: -1.23346
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10933, current rewards: -2394.23900, mean: -1.25353
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10937, current rewards: -2441.27593, mean: -1.24555
[32m[0906 15-01-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10943, current rewards: -2435.52935, mean: -1.21171
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10950, current rewards: -2429.78360, mean: -1.17951
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10955, current rewards: -2424.16967, mean: -1.14890
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10959, current rewards: -2418.45020, mean: -1.11965
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10964, current rewards: -2412.72525, mean: -1.09173
[32m[0906 15-02-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10968, current rewards: -2407.00508, mean: -1.06505
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10973, current rewards: -2433.87371, mean: -1.05362
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10977, current rewards: -2495.66916, mean: -1.05749
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10981, current rewards: -2563.76270, mean: -1.06380
[32m[0906 15-02-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10985, current rewards: -2631.94273, mean: -1.06990
[32m[0906 15-02-45 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 15-02-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-02-45 @MBExp.py:227][0m Rewards obtained: [-2684.2956087813436], Lows: [1420], Highs: [11], Total time: 4656.133914000001
[32m[0906 15-03-27 @MBExp.py:144][0m ####################################################################
[32m[0906 15-03-27 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-03-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11176, current rewards: -3.90557, mean: -0.39056
[32m[0906 15-03-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11149, current rewards: -0.13683, mean: -0.00228
[32m[0906 15-03-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11117, current rewards: 3.61572, mean: 0.03287
[32m[0906 15-03-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11151, current rewards: 7.36536, mean: 0.04603
[32m[0906 15-03-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11142, current rewards: 11.11240, mean: 0.05292
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11146, current rewards: 14.86149, mean: 0.05716
[32m[0906 15-04-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11152, current rewards: 18.60527, mean: 0.06002
[32m[0906 15-04-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11102, current rewards: 22.35289, mean: 0.06209
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11059, current rewards: 25.84425, mean: 0.06303
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11030, current rewards: 29.17415, mean: 0.06342
[32m[0906 15-04-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11004, current rewards: 27.56136, mean: 0.05404
[32m[0906 15-04-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10990, current rewards: 32.11563, mean: 0.05735
[32m[0906 15-04-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10968, current rewards: 36.62442, mean: 0.06004
[32m[0906 15-04-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10927, current rewards: 41.12202, mean: 0.06231
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10898, current rewards: 45.63209, mean: 0.06427
[32m[0906 15-04-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10898, current rewards: 50.13427, mean: 0.06597
[32m[0906 15-04-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10891, current rewards: 54.91759, mean: 0.06780
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10871, current rewards: 60.21876, mean: 0.07002
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10850, current rewards: 65.50878, mean: 0.07199
[32m[0906 15-05-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10830, current rewards: 70.79463, mean: 0.07374
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10817, current rewards: 76.08711, mean: 0.07533
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10818, current rewards: 84.18923, mean: 0.07942
[32m[0906 15-05-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10818, current rewards: 89.82921, mean: 0.08093
[32m[0906 15-05-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10814, current rewards: 95.47281, mean: 0.08230
[32m[0906 15-05-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10815, current rewards: 101.08589, mean: 0.08354
[32m[0906 15-05-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10827, current rewards: 106.65359, mean: 0.08465
[32m[0906 15-05-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10842, current rewards: 102.62261, mean: 0.07834
[32m[0906 15-05-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10853, current rewards: 109.16803, mean: 0.08027
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10851, current rewards: 115.71523, mean: 0.08207
[32m[0906 15-06-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10850, current rewards: 122.25486, mean: 0.08374
[32m[0906 15-06-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10847, current rewards: 128.79396, mean: 0.08529
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10845, current rewards: 135.33691, mean: 0.08675
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10845, current rewards: 141.87823, mean: 0.08812
[32m[0906 15-06-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10844, current rewards: 148.36855, mean: 0.08938
[32m[0906 15-06-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10842, current rewards: 154.89855, mean: 0.09058
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10845, current rewards: 161.42757, mean: 0.09172
[32m[0906 15-06-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10852, current rewards: 157.65949, mean: 0.08710
[32m[0906 15-06-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10863, current rewards: 164.30592, mean: 0.08834
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10874, current rewards: 170.95375, mean: 0.08950
[32m[0906 15-07-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10884, current rewards: 177.59912, mean: 0.09061
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10892, current rewards: 184.24328, mean: 0.09166
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10902, current rewards: 190.00454, mean: 0.09224
[32m[0906 15-07-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10910, current rewards: 196.42053, mean: 0.09309
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10918, current rewards: 202.83082, mean: 0.09390
[32m[0906 15-07-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10927, current rewards: 209.24186, mean: 0.09468
[32m[0906 15-07-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10935, current rewards: 215.65401, mean: 0.09542
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10940, current rewards: 222.06623, mean: 0.09613
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10945, current rewards: 228.47449, mean: 0.09681
[32m[0906 15-07-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10950, current rewards: 234.88777, mean: 0.09746
[32m[0906 15-07-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10955, current rewards: 241.35818, mean: 0.09811
[32m[0906 15-08-02 @Agent.py:117][0m Average action selection time: 0.1096
[32m[0906 15-08-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-08-02 @MBExp.py:227][0m Rewards obtained: [243.13098994033098], Lows: [10], Highs: [13], Total time: 4930.814676000001
[32m[0906 15-08-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-08-46 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 15-08-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11252, current rewards: -7.61646, mean: -0.76165
[32m[0906 15-08-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11187, current rewards: -1.77571, mean: -0.02960
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11189, current rewards: 3.73028, mean: 0.03391
[32m[0906 15-09-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11195, current rewards: 9.23613, mean: 0.05773
[32m[0906 15-09-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11181, current rewards: 14.74801, mean: 0.07023
[32m[0906 15-09-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11168, current rewards: 20.26801, mean: 0.07795
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11145, current rewards: 25.78303, mean: 0.08317
[32m[0906 15-09-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11090, current rewards: 31.00858, mean: 0.08613
[32m[0906 15-09-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11054, current rewards: 20.75311, mean: 0.05062
[32m[0906 15-09-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11036, current rewards: 26.54277, mean: 0.05770
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11008, current rewards: 32.33294, mean: 0.06340
[32m[0906 15-09-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10993, current rewards: 38.12252, mean: 0.06808
[32m[0906 15-09-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10964, current rewards: 43.91198, mean: 0.07199
[32m[0906 15-09-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10923, current rewards: 49.69729, mean: 0.07530
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10894, current rewards: 55.48256, mean: 0.07814
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10894, current rewards: 61.27122, mean: 0.08062
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10885, current rewards: 67.20796, mean: 0.08297
[32m[0906 15-10-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10859, current rewards: 73.01426, mean: 0.08490
[32m[0906 15-10-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10837, current rewards: 78.81833, mean: 0.08661
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10818, current rewards: 84.62498, mean: 0.08815
[32m[0906 15-10-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10802, current rewards: 90.42780, mean: 0.08953
[32m[0906 15-10-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10802, current rewards: 92.88034, mean: 0.08762
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10801, current rewards: 96.26186, mean: 0.08672
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10801, current rewards: 101.81902, mean: 0.08778
[32m[0906 15-10-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10800, current rewards: 108.37946, mean: 0.08957
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10813, current rewards: 114.16942, mean: 0.09061
[32m[0906 15-11-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10830, current rewards: 119.96544, mean: 0.09158
[32m[0906 15-11-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10836, current rewards: 125.75989, mean: 0.09247
[32m[0906 15-11-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10834, current rewards: 131.55684, mean: 0.09330
[32m[0906 15-11-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10837, current rewards: 137.35416, mean: 0.09408
[32m[0906 15-11-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10836, current rewards: 143.14981, mean: 0.09480
[32m[0906 15-11-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10836, current rewards: 143.89203, mean: 0.09224
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10836, current rewards: 150.25146, mean: 0.09332
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10836, current rewards: 156.07913, mean: 0.09402
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10835, current rewards: 161.90087, mean: 0.09468
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10836, current rewards: 167.59638, mean: 0.09523
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10848, current rewards: 173.47569, mean: 0.09584
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10859, current rewards: 179.47716, mean: 0.09649
[32m[0906 15-12-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10869, current rewards: 185.48803, mean: 0.09711
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10879, current rewards: 191.49257, mean: 0.09770
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10887, current rewards: 197.46593, mean: 0.09824
[32m[0906 15-12-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10896, current rewards: 192.65581, mean: 0.09352
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10902, current rewards: 198.23798, mean: 0.09395
[32m[0906 15-12-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10909, current rewards: 203.82383, mean: 0.09436
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10916, current rewards: 209.40798, mean: 0.09475
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10921, current rewards: 214.99036, mean: 0.09513
[32m[0906 15-12-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10928, current rewards: 210.22300, mean: 0.09101
[32m[0906 15-13-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10932, current rewards: 216.02824, mean: 0.09154
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10937, current rewards: 221.77502, mean: 0.09202
[32m[0906 15-13-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10943, current rewards: 227.33564, mean: 0.09241
[32m[0906 15-13-21 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-13-21 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-13-21 @MBExp.py:227][0m Rewards obtained: [231.97254662272988], Lows: [17], Highs: [20], Total time: 5205.181730000001
[32m[0906 15-14-07 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-07 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 15-14-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11278, current rewards: -3.83099, mean: -0.38310
[32m[0906 15-14-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11161, current rewards: 1.92385, mean: 0.03206
[32m[0906 15-14-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11168, current rewards: 7.43788, mean: 0.06762
[32m[0906 15-14-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11152, current rewards: 12.95398, mean: 0.08096
[32m[0906 15-14-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11147, current rewards: 13.13390, mean: 0.06254
[32m[0906 15-14-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11152, current rewards: 18.78167, mean: 0.07224
[32m[0906 15-14-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11104, current rewards: 24.42304, mean: 0.07878
[32m[0906 15-14-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11061, current rewards: 28.95575, mean: 0.08043
[32m[0906 15-14-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11033, current rewards: 33.89427, mean: 0.08267
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11008, current rewards: 38.82389, mean: 0.08440
[32m[0906 15-15-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10984, current rewards: 43.75754, mean: 0.08580
[32m[0906 15-15-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10971, current rewards: 48.68348, mean: 0.08693
[32m[0906 15-15-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10931, current rewards: 42.95322, mean: 0.07042
[32m[0906 15-15-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10893, current rewards: 49.13807, mean: 0.07445
[32m[0906 15-15-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10868, current rewards: 55.31187, mean: 0.07790
[32m[0906 15-15-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10865, current rewards: 61.72964, mean: 0.08122
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10849, current rewards: 70.03057, mean: 0.08646
[32m[0906 15-15-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10828, current rewards: 76.79184, mean: 0.08929
[32m[0906 15-15-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10806, current rewards: 83.54206, mean: 0.09180
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10788, current rewards: 90.30464, mean: 0.09407
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10776, current rewards: 97.05876, mean: 0.09610
[32m[0906 15-16-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10778, current rewards: 103.30561, mean: 0.09746
[32m[0906 15-16-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10777, current rewards: 109.59081, mean: 0.09873
[32m[0906 15-16-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10780, current rewards: 115.87279, mean: 0.09989
[32m[0906 15-16-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10779, current rewards: 122.33350, mean: 0.10110
[32m[0906 15-16-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10790, current rewards: 128.66369, mean: 0.10211
[32m[0906 15-16-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10806, current rewards: 134.99473, mean: 0.10305
[32m[0906 15-16-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10811, current rewards: 141.33437, mean: 0.10392
[32m[0906 15-16-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10810, current rewards: 147.67768, mean: 0.10474
[32m[0906 15-16-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10811, current rewards: 154.01225, mean: 0.10549
[32m[0906 15-16-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10810, current rewards: 147.33648, mean: 0.09757
[32m[0906 15-16-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10812, current rewards: 153.60482, mean: 0.09846
[32m[0906 15-17-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10814, current rewards: 159.25248, mean: 0.09891
[32m[0906 15-17-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10814, current rewards: 165.37005, mean: 0.09962
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10814, current rewards: 171.48083, mean: 0.10028
[32m[0906 15-17-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10815, current rewards: 177.58506, mean: 0.10090
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10825, current rewards: 183.69145, mean: 0.10149
[32m[0906 15-17-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10838, current rewards: 189.80467, mean: 0.10205
[32m[0906 15-17-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10851, current rewards: 195.91462, mean: 0.10257
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10859, current rewards: 202.02353, mean: 0.10307
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10868, current rewards: 208.24530, mean: 0.10360
[32m[0906 15-17-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10876, current rewards: 214.33211, mean: 0.10404
[32m[0906 15-17-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10885, current rewards: 220.43698, mean: 0.10447
[32m[0906 15-18-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10892, current rewards: 216.34452, mean: 0.10016
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10898, current rewards: 222.11083, mean: 0.10050
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10903, current rewards: 227.88457, mean: 0.10083
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10910, current rewards: 233.64882, mean: 0.10115
[32m[0906 15-18-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10914, current rewards: 239.41964, mean: 0.10145
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10919, current rewards: 245.29982, mean: 0.10178
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10925, current rewards: 251.74628, mean: 0.10234
[32m[0906 15-18-41 @Agent.py:117][0m Average action selection time: 0.1093
[32m[0906 15-18-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-18-41 @MBExp.py:227][0m Rewards obtained: [256.5909668193572], Lows: [13], Highs: [16], Total time: 5479.085800000001
[32m[0906 15-19-30 @MBExp.py:144][0m ####################################################################
[32m[0906 15-19-30 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 15-19-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11222, current rewards: -5.56872, mean: -0.55687
[32m[0906 15-19-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11184, current rewards: -0.94714, mean: -0.01579
[32m[0906 15-19-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11171, current rewards: 3.45884, mean: 0.03144
[32m[0906 15-19-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11163, current rewards: 7.86340, mean: 0.04915
[32m[0906 15-19-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11168, current rewards: 12.27288, mean: 0.05844
[32m[0906 15-19-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11143, current rewards: 16.67639, mean: 0.06414
[32m[0906 15-20-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11079, current rewards: 15.92027, mean: 0.05136
[32m[0906 15-20-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11041, current rewards: 21.00203, mean: 0.05834
[32m[0906 15-20-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11007, current rewards: 26.38295, mean: 0.06435
[32m[0906 15-20-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10979, current rewards: 31.75986, mean: 0.06904
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10962, current rewards: 37.13721, mean: 0.07282
[32m[0906 15-20-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10943, current rewards: 42.52075, mean: 0.07593
[32m[0906 15-20-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10901, current rewards: 47.90031, mean: 0.07853
[32m[0906 15-20-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10867, current rewards: 53.27972, mean: 0.08073
[32m[0906 15-20-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10841, current rewards: 58.65696, mean: 0.08262
[32m[0906 15-20-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10838, current rewards: 58.86336, mean: 0.07745
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10822, current rewards: 64.28927, mean: 0.07937
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10799, current rewards: 69.70913, mean: 0.08106
[32m[0906 15-21-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10779, current rewards: 75.12961, mean: 0.08256
[32m[0906 15-21-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10764, current rewards: 80.54812, mean: 0.08390
[32m[0906 15-21-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10749, current rewards: 85.96612, mean: 0.08511
[32m[0906 15-21-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10751, current rewards: 91.38892, mean: 0.08622
[32m[0906 15-21-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10754, current rewards: 96.81108, mean: 0.08722
[32m[0906 15-21-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10755, current rewards: 102.55096, mean: 0.08841
[32m[0906 15-21-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10757, current rewards: 108.35792, mean: 0.08955
[32m[0906 15-21-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10771, current rewards: 113.88602, mean: 0.09039
[32m[0906 15-21-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10785, current rewards: 119.40839, mean: 0.09115
[32m[0906 15-21-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10783, current rewards: 115.78651, mean: 0.08514
[32m[0906 15-22-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10784, current rewards: 122.85999, mean: 0.08713
[32m[0906 15-22-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10783, current rewards: 129.92979, mean: 0.08899
[32m[0906 15-22-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10784, current rewards: 137.00519, mean: 0.09073
[32m[0906 15-22-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10785, current rewards: 131.90609, mean: 0.08456
[32m[0906 15-22-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10784, current rewards: 137.34814, mean: 0.08531
[32m[0906 15-22-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10782, current rewards: 141.96292, mean: 0.08552
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10783, current rewards: 147.03293, mean: 0.08598
[32m[0906 15-22-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10783, current rewards: 152.15944, mean: 0.08645
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10792, current rewards: 157.28658, mean: 0.08690
[32m[0906 15-22-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10805, current rewards: 160.20824, mean: 0.08613
[32m[0906 15-22-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10813, current rewards: 159.87062, mean: 0.08370
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10821, current rewards: 165.01262, mean: 0.08419
[32m[0906 15-23-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10832, current rewards: 170.30651, mean: 0.08473
[32m[0906 15-23-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10839, current rewards: 175.52072, mean: 0.08520
[32m[0906 15-23-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10848, current rewards: 180.73945, mean: 0.08566
[32m[0906 15-23-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10854, current rewards: 185.95397, mean: 0.08609
[32m[0906 15-23-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10860, current rewards: 180.75986, mean: 0.08179
[32m[0906 15-23-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10868, current rewards: 185.80952, mean: 0.08222
[32m[0906 15-23-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10873, current rewards: 190.85579, mean: 0.08262
[32m[0906 15-23-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10878, current rewards: 195.90330, mean: 0.08301
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10884, current rewards: 200.45191, mean: 0.08318
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10889, current rewards: 205.87133, mean: 0.08369
[32m[0906 15-24-03 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 15-24-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-24-03 @MBExp.py:227][0m Rewards obtained: [210.1858676463671], Lows: [16], Highs: [23], Total time: 5752.118646000001
[32m[0906 15-24-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-54 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 15-24-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11381, current rewards: -5.66976, mean: -0.56698
[32m[0906 15-25-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11205, current rewards: 0.18535, mean: 0.00309
[32m[0906 15-25-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11203, current rewards: 6.14450, mean: 0.05586
[32m[0906 15-25-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11200, current rewards: 12.09224, mean: 0.07558
[32m[0906 15-25-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11193, current rewards: 18.03844, mean: 0.08590
[32m[0906 15-25-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11139, current rewards: 23.98478, mean: 0.09225
[32m[0906 15-25-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11094, current rewards: 29.93019, mean: 0.09655
[32m[0906 15-25-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11052, current rewards: 35.82357, mean: 0.09951
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11016, current rewards: 41.76424, mean: 0.10186
[32m[0906 15-25-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10993, current rewards: 47.70298, mean: 0.10370
[32m[0906 15-25-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10971, current rewards: 53.63921, mean: 0.10517
[32m[0906 15-25-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10938, current rewards: 48.84877, mean: 0.08723
[32m[0906 15-26-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10902, current rewards: 54.18651, mean: 0.08883
[32m[0906 15-26-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10867, current rewards: 59.51023, mean: 0.09017
[32m[0906 15-26-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10843, current rewards: 64.83508, mean: 0.09132
[32m[0906 15-26-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10839, current rewards: 70.16169, mean: 0.09232
[32m[0906 15-26-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10814, current rewards: 75.48611, mean: 0.09319
[32m[0906 15-26-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10793, current rewards: 80.81121, mean: 0.09397
[32m[0906 15-26-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10774, current rewards: 86.13691, mean: 0.09466
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10757, current rewards: 78.81792, mean: 0.08210
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10741, current rewards: 85.30633, mean: 0.08446
[32m[0906 15-26-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10742, current rewards: 91.68361, mean: 0.08649
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10743, current rewards: 98.06819, mean: 0.08835
[32m[0906 15-26-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10744, current rewards: 105.14860, mean: 0.09065
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10746, current rewards: 111.68192, mean: 0.09230
[32m[0906 15-27-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10757, current rewards: 118.21669, mean: 0.09382
[32m[0906 15-27-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10766, current rewards: 124.74956, mean: 0.09523
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10768, current rewards: 131.28214, mean: 0.09653
[32m[0906 15-27-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10768, current rewards: 137.81504, mean: 0.09774
[32m[0906 15-27-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10774, current rewards: 144.34759, mean: 0.09887
[32m[0906 15-27-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10776, current rewards: 150.87915, mean: 0.09992
[32m[0906 15-27-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10777, current rewards: 151.85432, mean: 0.09734
[32m[0906 15-27-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10776, current rewards: 157.48641, mean: 0.09782
[32m[0906 15-27-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10776, current rewards: 163.11582, mean: 0.09826
[32m[0906 15-27-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10776, current rewards: 168.75177, mean: 0.09869
[32m[0906 15-28-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10774, current rewards: 174.38367, mean: 0.09908
[32m[0906 15-28-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10784, current rewards: 180.01699, mean: 0.09946
[32m[0906 15-28-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10794, current rewards: 180.94341, mean: 0.09728
[32m[0906 15-28-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10804, current rewards: 186.74961, mean: 0.09777
[32m[0906 15-28-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10814, current rewards: 192.47297, mean: 0.09820
[32m[0906 15-28-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10823, current rewards: 198.27113, mean: 0.09864
[32m[0906 15-28-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10835, current rewards: 204.07333, mean: 0.09906
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10843, current rewards: 209.87739, mean: 0.09947
[32m[0906 15-28-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10851, current rewards: 215.67891, mean: 0.09985
[32m[0906 15-28-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10861, current rewards: 210.47288, mean: 0.09524
[32m[0906 15-29-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10870, current rewards: 215.33674, mean: 0.09528
[32m[0906 15-29-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10877, current rewards: 220.20860, mean: 0.09533
[32m[0906 15-29-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10885, current rewards: 225.08255, mean: 0.09537
[32m[0906 15-29-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10891, current rewards: 229.95309, mean: 0.09542
[32m[0906 15-29-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10897, current rewards: 234.82598, mean: 0.09546
[32m[0906 15-29-27 @Agent.py:117][0m Average action selection time: 0.1090
[32m[0906 15-29-27 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-29-27 @MBExp.py:227][0m Rewards obtained: [238.7203079883643], Lows: [16], Highs: [16], Total time: 6025.418049000001
[32m[0906 15-30-21 @MBExp.py:144][0m ####################################################################
[32m[0906 15-30-21 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 15-30-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11189, current rewards: -5.64515, mean: -0.56451
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11135, current rewards: 0.74006, mean: 0.01233
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11168, current rewards: 6.31271, mean: 0.05739
[32m[0906 15-30-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11150, current rewards: 11.88342, mean: 0.07427
[32m[0906 15-30-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11148, current rewards: 15.23271, mean: 0.07254
[32m[0906 15-30-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11076, current rewards: 17.08036, mean: 0.06569
[32m[0906 15-30-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11020, current rewards: 22.09326, mean: 0.07127
[32m[0906 15-31-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10997, current rewards: 27.22910, mean: 0.07564
[32m[0906 15-31-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10970, current rewards: 32.36146, mean: 0.07893
[32m[0906 15-31-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10948, current rewards: 37.49558, mean: 0.08151
[32m[0906 15-31-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10935, current rewards: 42.62856, mean: 0.08359
[32m[0906 15-31-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10899, current rewards: 47.76155, mean: 0.08529
[32m[0906 15-31-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10861, current rewards: 52.89498, mean: 0.08671
[32m[0906 15-31-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10833, current rewards: 58.02903, mean: 0.08792
[32m[0906 15-31-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10807, current rewards: 63.03959, mean: 0.08879
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10791, current rewards: 68.12452, mean: 0.08964
[32m[0906 15-31-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10772, current rewards: 73.20808, mean: 0.09038
[32m[0906 15-31-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10752, current rewards: 77.94070, mean: 0.09063
[32m[0906 15-31-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10734, current rewards: 82.50527, mean: 0.09067
[32m[0906 15-32-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10721, current rewards: 87.07072, mean: 0.09070
[32m[0906 15-32-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10706, current rewards: 91.63603, mean: 0.09073
[32m[0906 15-32-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10704, current rewards: 96.20133, mean: 0.09076
[32m[0906 15-32-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10711, current rewards: 100.69951, mean: 0.09072
[32m[0906 15-32-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10715, current rewards: 105.24839, mean: 0.09073
[32m[0906 15-32-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10717, current rewards: 109.80238, mean: 0.09075
[32m[0906 15-32-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10730, current rewards: 114.35650, mean: 0.09076
[32m[0906 15-32-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10737, current rewards: 108.79313, mean: 0.08305
[32m[0906 15-32-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10739, current rewards: 113.62724, mean: 0.08355
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10743, current rewards: 118.45868, mean: 0.08401
[32m[0906 15-32-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10745, current rewards: 123.28892, mean: 0.08444
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10746, current rewards: 128.64434, mean: 0.08519
[32m[0906 15-33-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10750, current rewards: 133.56616, mean: 0.08562
[32m[0906 15-33-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10751, current rewards: 138.38088, mean: 0.08595
[32m[0906 15-33-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10752, current rewards: 143.19791, mean: 0.08626
[32m[0906 15-33-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10755, current rewards: 148.01243, mean: 0.08656
[32m[0906 15-33-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10757, current rewards: 142.93119, mean: 0.08121
[32m[0906 15-33-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10765, current rewards: 148.34697, mean: 0.08196
[32m[0906 15-33-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10778, current rewards: 153.77718, mean: 0.08268
[32m[0906 15-33-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10788, current rewards: 159.20740, mean: 0.08335
[32m[0906 15-33-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10798, current rewards: 164.52054, mean: 0.08394
[32m[0906 15-33-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10808, current rewards: 169.91414, mean: 0.08453
[32m[0906 15-34-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10817, current rewards: 168.67941, mean: 0.08188
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10825, current rewards: 174.05710, mean: 0.08249
[32m[0906 15-34-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10835, current rewards: 179.43433, mean: 0.08307
[32m[0906 15-34-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10842, current rewards: 184.81560, mean: 0.08363
[32m[0906 15-34-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10850, current rewards: 190.19873, mean: 0.08416
[32m[0906 15-34-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10857, current rewards: 190.10739, mean: 0.08230
[32m[0906 15-34-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10863, current rewards: 194.51641, mean: 0.08242
[32m[0906 15-34-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10871, current rewards: 199.08287, mean: 0.08261
[32m[0906 15-34-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10876, current rewards: 203.64874, mean: 0.08278
[32m[0906 15-34-53 @Agent.py:117][0m Average action selection time: 0.1088
[32m[0906 15-34-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-34-54 @MBExp.py:227][0m Rewards obtained: [207.30541256175175], Lows: [10], Highs: [22], Total time: 6298.147695000001
[32m[0906 15-35-49 @MBExp.py:144][0m ####################################################################
[32m[0906 15-35-49 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 15-35-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11096, current rewards: -4.67492, mean: -0.46749
[32m[0906 15-35-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11162, current rewards: 0.69000, mean: 0.01150
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11163, current rewards: 6.06098, mean: 0.05510
[32m[0906 15-36-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11184, current rewards: 11.42782, mean: 0.07142
[32m[0906 15-36-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11125, current rewards: 16.79108, mean: 0.07996
[32m[0906 15-36-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11072, current rewards: 22.86434, mean: 0.08794
[32m[0906 15-36-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11028, current rewards: 22.81075, mean: 0.07358
[32m[0906 15-36-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10997, current rewards: 27.54301, mean: 0.07651
[32m[0906 15-36-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10983, current rewards: 32.27678, mean: 0.07872
[32m[0906 15-36-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10959, current rewards: 37.00854, mean: 0.08045
[32m[0906 15-36-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10937, current rewards: 41.74316, mean: 0.08185
[32m[0906 15-36-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10903, current rewards: 46.34024, mean: 0.08275
[32m[0906 15-36-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10867, current rewards: 51.46930, mean: 0.08438
[32m[0906 15-37-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10835, current rewards: 56.42749, mean: 0.08550
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10813, current rewards: 61.07528, mean: 0.08602
[32m[0906 15-37-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10791, current rewards: 65.96853, mean: 0.08680
[32m[0906 15-37-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10769, current rewards: 70.86177, mean: 0.08748
[32m[0906 15-37-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10750, current rewards: 64.89178, mean: 0.07546
[32m[0906 15-37-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10732, current rewards: 71.18115, mean: 0.07822
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10721, current rewards: 77.47044, mean: 0.08070
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10712, current rewards: 83.76669, mean: 0.08294
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10703, current rewards: 90.05384, mean: 0.08496
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10704, current rewards: 97.38836, mean: 0.08774
[32m[0906 15-37-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10710, current rewards: 102.92631, mean: 0.08873
[32m[0906 15-37-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10711, current rewards: 108.46015, mean: 0.08964
[32m[0906 15-38-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10720, current rewards: 105.70000, mean: 0.08389
[32m[0906 15-38-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10723, current rewards: 110.59010, mean: 0.08442
[32m[0906 15-38-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10725, current rewards: 115.47721, mean: 0.08491
[32m[0906 15-38-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10727, current rewards: 120.36388, mean: 0.08536
[32m[0906 15-38-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10731, current rewards: 125.25274, mean: 0.08579
[32m[0906 15-38-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10732, current rewards: 130.27051, mean: 0.08627
[32m[0906 15-38-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10733, current rewards: 125.29787, mean: 0.08032
[32m[0906 15-38-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10734, current rewards: 130.80414, mean: 0.08124
[32m[0906 15-38-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10734, current rewards: 136.31185, mean: 0.08212
[32m[0906 15-38-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10736, current rewards: 141.81831, mean: 0.08293
[32m[0906 15-38-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10738, current rewards: 147.32742, mean: 0.08371
[32m[0906 15-39-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10744, current rewards: 152.83151, mean: 0.08444
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10754, current rewards: 158.33824, mean: 0.08513
[32m[0906 15-39-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10767, current rewards: 163.84519, mean: 0.08578
[32m[0906 15-39-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10777, current rewards: 158.21646, mean: 0.08072
[32m[0906 15-39-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10786, current rewards: 165.49068, mean: 0.08233
[32m[0906 15-39-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10797, current rewards: 172.76489, mean: 0.08387
[32m[0906 15-39-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10804, current rewards: 180.03910, mean: 0.08533
[32m[0906 15-39-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10811, current rewards: 187.31332, mean: 0.08672
[32m[0906 15-39-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10819, current rewards: 194.58753, mean: 0.08805
[32m[0906 15-39-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10826, current rewards: 201.86174, mean: 0.08932
[32m[0906 15-40-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10833, current rewards: 209.13596, mean: 0.09054
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10841, current rewards: 186.26428, mean: 0.07893
[32m[0906 15-40-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10846, current rewards: 136.26428, mean: 0.05654
[32m[0906 15-40-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10853, current rewards: 86.26428, mean: 0.03507
[32m[0906 15-40-21 @Agent.py:117][0m Average action selection time: 0.1086
[32m[0906 15-40-21 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-40-22 @MBExp.py:227][0m Rewards obtained: [46.26427579936188], Lows: [16], Highs: [184], Total time: 6570.289922000001
[32m[0906 15-41-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-19 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11301, current rewards: -6.01074, mean: -0.60107
[32m[0906 15-41-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11129, current rewards: -3.79142, mean: -0.06319
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11119, current rewards: 1.54605, mean: 0.01405
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11158, current rewards: 6.88354, mean: 0.04302
[32m[0906 15-41-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11064, current rewards: 12.21873, mean: 0.05818
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10994, current rewards: 17.65001, mean: 0.06788
[32m[0906 15-41-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10960, current rewards: 23.11681, mean: 0.07457
[32m[0906 15-41-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10925, current rewards: 28.45028, mean: 0.07903
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10900, current rewards: 33.78582, mean: 0.08240
[32m[0906 15-42-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10893, current rewards: 39.11904, mean: 0.08504
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10873, current rewards: 44.45657, mean: 0.08717
[32m[0906 15-42-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10830, current rewards: 37.84311, mean: 0.06758
[32m[0906 15-42-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10795, current rewards: 43.63835, mean: 0.07154
[32m[0906 15-42-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10768, current rewards: 49.43359, mean: 0.07490
[32m[0906 15-42-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10737, current rewards: 56.47597, mean: 0.07954
[32m[0906 15-42-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10720, current rewards: 63.57252, mean: 0.08365
[32m[0906 15-42-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10702, current rewards: 70.66907, mean: 0.08725
[32m[0906 15-42-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10685, current rewards: 54.92701, mean: 0.06387
[32m[0906 15-42-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10677, current rewards: 4.92701, mean: 0.00541
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10666, current rewards: -45.07299, mean: -0.04695
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10656, current rewards: -95.07299, mean: -0.09413
[32m[0906 15-43-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10653, current rewards: -145.07299, mean: -0.13686
[32m[0906 15-43-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10661, current rewards: -195.07299, mean: -0.17574
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10668, current rewards: -245.07299, mean: -0.21127
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10678, current rewards: -295.07299, mean: -0.24386
[32m[0906 15-43-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10684, current rewards: -345.07299, mean: -0.27387
[32m[0906 15-43-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10688, current rewards: -395.07299, mean: -0.30158
[32m[0906 15-43-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10695, current rewards: -445.07299, mean: -0.32726
[32m[0906 15-43-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10697, current rewards: -495.07299, mean: -0.35112
[32m[0906 15-43-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10699, current rewards: -545.07299, mean: -0.37334
[32m[0906 15-44-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10701, current rewards: -595.07299, mean: -0.39409
[32m[0906 15-44-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10702, current rewards: -645.07299, mean: -0.41351
[32m[0906 15-44-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10704, current rewards: -695.07299, mean: -0.43172
[32m[0906 15-44-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10707, current rewards: -745.07299, mean: -0.44884
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10710, current rewards: -795.07299, mean: -0.46495
[32m[0906 15-44-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10712, current rewards: -845.07299, mean: -0.48016
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10720, current rewards: -895.07299, mean: -0.49452
[32m[0906 15-44-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10733, current rewards: -945.07299, mean: -0.50810
[32m[0906 15-44-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10744, current rewards: -995.07299, mean: -0.52098
[32m[0906 15-44-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10757, current rewards: -1045.07299, mean: -0.53320
[32m[0906 15-44-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10765, current rewards: -1095.07299, mean: -0.54481
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10774, current rewards: -1145.07299, mean: -0.55586
[32m[0906 15-45-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10783, current rewards: -1195.07299, mean: -0.56639
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10790, current rewards: -1245.07299, mean: -0.57642
[32m[0906 15-45-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10798, current rewards: -1295.07299, mean: -0.58601
[32m[0906 15-45-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10806, current rewards: -1345.07299, mean: -0.59517
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10813, current rewards: -1395.07299, mean: -0.60393
[32m[0906 15-45-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10820, current rewards: -1445.07299, mean: -0.61232
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10825, current rewards: -1495.07299, mean: -0.62036
[32m[0906 15-45-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10831, current rewards: -1545.07299, mean: -0.62808
[32m[0906 15-45-51 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 15-45-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-45-51 @MBExp.py:227][0m Rewards obtained: [-1585.0729949910424], Lows: [9], Highs: [1665], Total time: 6841.913466000001
[32m[0906 15-46-51 @MBExp.py:144][0m ####################################################################
[32m[0906 15-46-51 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11101, current rewards: -4.51249, mean: -0.45125
[32m[0906 15-46-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11204, current rewards: 1.51706, mean: 0.02528
[32m[0906 15-47-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11149, current rewards: 7.74749, mean: 0.07043
[32m[0906 15-47-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11105, current rewards: 13.97308, mean: 0.08733
[32m[0906 15-47-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11031, current rewards: 20.20037, mean: 0.09619
[32m[0906 15-47-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10981, current rewards: 27.30227, mean: 0.10501
[32m[0906 15-47-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10946, current rewards: 33.57621, mean: 0.10831
[32m[0906 15-47-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10935, current rewards: 39.78923, mean: 0.11053
[32m[0906 15-47-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10916, current rewards: 46.00598, mean: 0.11221
[32m[0906 15-47-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10908, current rewards: 52.21984, mean: 0.11352
[32m[0906 15-47-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10880, current rewards: 46.23379, mean: 0.09065
[32m[0906 15-47-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10841, current rewards: 51.80425, mean: 0.09251
[32m[0906 15-47-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10809, current rewards: 57.28383, mean: 0.09391
[32m[0906 15-48-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10779, current rewards: 62.74816, mean: 0.09507
[32m[0906 15-48-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10740, current rewards: 67.92055, mean: 0.09566
[32m[0906 15-48-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10721, current rewards: 68.71171, mean: 0.09041
[32m[0906 15-48-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10703, current rewards: 74.73943, mean: 0.09227
[32m[0906 15-48-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10683, current rewards: 80.76598, mean: 0.09391
[32m[0906 15-48-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10670, current rewards: 86.78764, mean: 0.09537
[32m[0906 15-48-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10658, current rewards: 90.68978, mean: 0.09447
[32m[0906 15-48-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10645, current rewards: 88.30627, mean: 0.08743
[32m[0906 15-48-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10632, current rewards: 94.45591, mean: 0.08911
[32m[0906 15-48-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10642, current rewards: 100.63696, mean: 0.09066
[32m[0906 15-48-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10644, current rewards: 106.66201, mean: 0.09195
[32m[0906 15-49-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10649, current rewards: 112.68896, mean: 0.09313
[32m[0906 15-49-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10648, current rewards: 118.71410, mean: 0.09422
[32m[0906 15-49-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10653, current rewards: 124.73681, mean: 0.09522
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10660, current rewards: 130.76335, mean: 0.09615
[32m[0906 15-49-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10666, current rewards: 136.78941, mean: 0.09701
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10670, current rewards: 142.81866, mean: 0.09782
[32m[0906 15-49-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10676, current rewards: 148.89471, mean: 0.09861
[32m[0906 15-49-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10679, current rewards: 155.43953, mean: 0.09964
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10681, current rewards: 159.71949, mean: 0.09920
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10685, current rewards: 162.15113, mean: 0.09768
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10688, current rewards: 166.52856, mean: 0.09739
[32m[0906 15-50-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10692, current rewards: 170.91047, mean: 0.09711
[32m[0906 15-50-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10700, current rewards: 175.28765, mean: 0.09684
[32m[0906 15-50-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10712, current rewards: 179.66264, mean: 0.09659
[32m[0906 15-50-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10724, current rewards: 183.79089, mean: 0.09623
[32m[0906 15-50-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10736, current rewards: 187.95626, mean: 0.09590
[32m[0906 15-50-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10747, current rewards: 192.11849, mean: 0.09558
[32m[0906 15-50-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10757, current rewards: 197.17348, mean: 0.09572
[32m[0906 15-50-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10768, current rewards: 202.80210, mean: 0.09611
[32m[0906 15-50-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10777, current rewards: 208.47587, mean: 0.09652
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10786, current rewards: 214.15372, mean: 0.09690
[32m[0906 15-50-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10796, current rewards: 219.82494, mean: 0.09727
[32m[0906 15-51-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10805, current rewards: 225.92408, mean: 0.09780
[32m[0906 15-51-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10813, current rewards: 231.84452, mean: 0.09824
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10821, current rewards: 227.40291, mean: 0.09436
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10830, current rewards: 233.61833, mean: 0.09497
[32m[0906 15-51-23 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 15-51-23 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-51-23 @MBExp.py:227][0m Rewards obtained: [238.59561097280945], Lows: [16], Highs: [16], Total time: 7113.50884
[32m[0906 15-52-26 @MBExp.py:144][0m ####################################################################
[32m[0906 15-52-26 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 15-52-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11161, current rewards: -11.15268, mean: -1.11527
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11187, current rewards: -9.79330, mean: -0.16322
[32m[0906 15-52-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11155, current rewards: -4.70514, mean: -0.04277
[32m[0906 15-52-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11083, current rewards: 0.37570, mean: 0.00235
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11018, current rewards: 5.45839, mean: 0.02599
[32m[0906 15-52-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10978, current rewards: 10.22967, mean: 0.03934
[32m[0906 15-53-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10957, current rewards: 15.20068, mean: 0.04903
[32m[0906 15-53-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10936, current rewards: 20.17421, mean: 0.05604
[32m[0906 15-53-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10913, current rewards: 11.42291, mean: 0.02786
[32m[0906 15-53-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10904, current rewards: 17.26494, mean: 0.03753
[32m[0906 15-53-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10873, current rewards: 23.11110, mean: 0.04532
[32m[0906 15-53-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10831, current rewards: 28.95876, mean: 0.05171
[32m[0906 15-53-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10804, current rewards: 34.80635, mean: 0.05706
[32m[0906 15-53-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10778, current rewards: 40.69269, mean: 0.06166
[32m[0906 15-53-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10730, current rewards: 46.53026, mean: 0.06554
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10714, current rewards: 52.37552, mean: 0.06892
[32m[0906 15-53-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10697, current rewards: 58.21570, mean: 0.07187
[32m[0906 15-53-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10683, current rewards: 64.05983, mean: 0.07449
[32m[0906 15-54-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10674, current rewards: 69.89864, mean: 0.07681
[32m[0906 15-54-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10664, current rewards: 75.74109, mean: 0.07890
[32m[0906 15-54-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10651, current rewards: 81.58368, mean: 0.08078
[32m[0906 15-54-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10644, current rewards: 88.23485, mean: 0.08324
[32m[0906 15-54-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10647, current rewards: 94.02454, mean: 0.08471
[32m[0906 15-54-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10654, current rewards: 99.55691, mean: 0.08582
[32m[0906 15-54-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10661, current rewards: 98.38379, mean: 0.08131
[32m[0906 15-54-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10651, current rewards: 103.77653, mean: 0.08236
[32m[0906 15-54-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10656, current rewards: 109.16456, mean: 0.08333
[32m[0906 15-54-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10663, current rewards: 114.55777, mean: 0.08423
[32m[0906 15-54-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10668, current rewards: 119.94766, mean: 0.08507
[32m[0906 15-55-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10672, current rewards: 125.34317, mean: 0.08585
[32m[0906 15-55-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10677, current rewards: 131.31460, mean: 0.08696
[32m[0906 15-55-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10682, current rewards: 136.45890, mean: 0.08747
[32m[0906 15-55-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10686, current rewards: 141.65299, mean: 0.08798
[32m[0906 15-55-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10691, current rewards: 146.84002, mean: 0.08846
[32m[0906 15-55-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10695, current rewards: 152.02459, mean: 0.08890
[32m[0906 15-55-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10697, current rewards: 157.21090, mean: 0.08932
[32m[0906 15-55-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10704, current rewards: 152.18066, mean: 0.08408
[32m[0906 15-55-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10716, current rewards: 158.29447, mean: 0.08510
[32m[0906 15-55-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10727, current rewards: 163.76480, mean: 0.08574
[32m[0906 15-55-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10739, current rewards: 169.36171, mean: 0.08641
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10749, current rewards: 174.95483, mean: 0.08704
[32m[0906 15-56-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10759, current rewards: 174.95908, mean: 0.08493
[32m[0906 15-56-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10770, current rewards: 180.58229, mean: 0.08558
[32m[0906 15-56-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10779, current rewards: 186.20532, mean: 0.08621
[32m[0906 15-56-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10787, current rewards: 191.82867, mean: 0.08680
[32m[0906 15-56-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10797, current rewards: 197.44929, mean: 0.08737
[32m[0906 15-56-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10806, current rewards: 202.82628, mean: 0.08780
[32m[0906 15-56-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10815, current rewards: 208.44524, mean: 0.08832
[32m[0906 15-56-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10822, current rewards: 214.06022, mean: 0.08882
[32m[0906 15-56-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10828, current rewards: 219.68304, mean: 0.08930
[32m[0906 15-56-57 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 15-56-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-56-57 @MBExp.py:227][0m Rewards obtained: [224.18579526991385], Lows: [16], Highs: [18], Total time: 7385.065544
[32m[0906 15-58-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-58-02 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 15-58-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11072, current rewards: -5.64798, mean: -0.56480
[32m[0906 15-58-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11077, current rewards: 0.11908, mean: 0.00198
[32m[0906 15-58-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11084, current rewards: 5.39339, mean: 0.04903
[32m[0906 15-58-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10991, current rewards: 10.66423, mean: 0.06665
[32m[0906 15-58-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10928, current rewards: 15.94661, mean: 0.07594
[32m[0906 15-58-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10885, current rewards: 21.67773, mean: 0.08338
[32m[0906 15-58-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10870, current rewards: 21.47518, mean: 0.06927
[32m[0906 15-58-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10850, current rewards: 26.87422, mean: 0.07465
[32m[0906 15-58-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10826, current rewards: 32.27166, mean: 0.07871
[32m[0906 15-58-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10820, current rewards: 37.66911, mean: 0.08189
[32m[0906 15-58-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10785, current rewards: 43.07311, mean: 0.08446
[32m[0906 15-59-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10750, current rewards: 48.47353, mean: 0.08656
[32m[0906 15-59-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10724, current rewards: 53.87392, mean: 0.08832
[32m[0906 15-59-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10699, current rewards: 58.75245, mean: 0.08902
[32m[0906 15-59-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10652, current rewards: 64.01408, mean: 0.09016
[32m[0906 15-59-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10634, current rewards: 69.28404, mean: 0.09116
[32m[0906 15-59-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10618, current rewards: 74.55047, mean: 0.09204
[32m[0906 15-59-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10606, current rewards: 79.64644, mean: 0.09261
[32m[0906 15-59-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10597, current rewards: 84.66712, mean: 0.09304
[32m[0906 15-59-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10586, current rewards: 89.68911, mean: 0.09343
[32m[0906 15-59-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10577, current rewards: 94.71830, mean: 0.09378
[32m[0906 15-59-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10570, current rewards: 99.55881, mean: 0.09392
[32m[0906 16-00-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10570, current rewards: 104.53362, mean: 0.09417
[32m[0906 16-00-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10576, current rewards: 109.51556, mean: 0.09441
[32m[0906 16-00-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10579, current rewards: 114.49610, mean: 0.09462
[32m[0906 16-00-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10571, current rewards: 119.47866, mean: 0.09482
[32m[0906 16-00-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10575, current rewards: 124.27983, mean: 0.09487
[32m[0906 16-00-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10583, current rewards: 129.24636, mean: 0.09503
[32m[0906 16-00-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10587, current rewards: 134.21967, mean: 0.09519
[32m[0906 16-00-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10593, current rewards: 139.10833, mean: 0.09528
[32m[0906 16-00-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10600, current rewards: 144.00878, mean: 0.09537
[32m[0906 16-00-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10604, current rewards: 148.89625, mean: 0.09545
[32m[0906 16-00-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10609, current rewards: 153.78053, mean: 0.09552
[32m[0906 16-00-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10616, current rewards: 158.67104, mean: 0.09558
[32m[0906 16-01-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10621, current rewards: 163.55861, mean: 0.09565
[32m[0906 16-01-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10624, current rewards: 168.44763, mean: 0.09571
[32m[0906 16-01-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10630, current rewards: 173.33733, mean: 0.09577
[32m[0906 16-01-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10642, current rewards: 178.34981, mean: 0.09589
[32m[0906 16-01-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10654, current rewards: 183.88302, mean: 0.09627
[32m[0906 16-01-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10667, current rewards: 189.21277, mean: 0.09654
[32m[0906 16-01-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10677, current rewards: 194.53341, mean: 0.09678
[32m[0906 16-01-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10688, current rewards: 199.86721, mean: 0.09702
[32m[0906 16-01-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10700, current rewards: 205.18564, mean: 0.09724
[32m[0906 16-01-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10710, current rewards: 210.52011, mean: 0.09746
[32m[0906 16-02-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10720, current rewards: 215.84512, mean: 0.09767
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10729, current rewards: 219.06339, mean: 0.09693
[32m[0906 16-02-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10738, current rewards: 213.38102, mean: 0.09237
[32m[0906 16-02-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10746, current rewards: 218.54526, mean: 0.09260
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10754, current rewards: 223.71048, mean: 0.09283
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10761, current rewards: 228.87406, mean: 0.09304
[32m[0906 16-02-32 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 16-02-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-02-32 @MBExp.py:227][0m Rewards obtained: [233.00396052057937], Lows: [6], Highs: [11], Total time: 7654.957276
[32m[0906 16-03-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-03-39 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11089, current rewards: -12.93257, mean: -1.29326
[32m[0906 16-03-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11146, current rewards: -9.47073, mean: -0.15785
[32m[0906 16-03-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11124, current rewards: -3.78112, mean: -0.03437
[32m[0906 16-03-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11016, current rewards: 1.90032, mean: 0.01188
[32m[0906 16-04-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10951, current rewards: 8.20672, mean: 0.03908
[32m[0906 16-04-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10918, current rewards: 1.71683, mean: 0.00660
[32m[0906 16-04-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10893, current rewards: 7.58331, mean: 0.02446
[32m[0906 16-04-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10870, current rewards: 13.44991, mean: 0.03736
[32m[0906 16-04-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10862, current rewards: 19.31657, mean: 0.04711
[32m[0906 16-04-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10845, current rewards: 25.18310, mean: 0.05475
[32m[0906 16-04-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10805, current rewards: 31.04969, mean: 0.06088
[32m[0906 16-04-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10768, current rewards: 36.91618, mean: 0.06592
[32m[0906 16-04-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10736, current rewards: 36.23711, mean: 0.05941
[32m[0906 16-04-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10701, current rewards: 42.09695, mean: 0.06378
[32m[0906 16-04-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10662, current rewards: 48.30998, mean: 0.06804
[32m[0906 16-05-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10642, current rewards: 54.52923, mean: 0.07175
[32m[0906 16-05-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10628, current rewards: 60.74860, mean: 0.07500
[32m[0906 16-05-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10620, current rewards: 66.97742, mean: 0.07788
[32m[0906 16-05-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10606, current rewards: 73.18788, mean: 0.08043
[32m[0906 16-05-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10595, current rewards: 79.40052, mean: 0.08271
[32m[0906 16-05-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10588, current rewards: 85.61668, mean: 0.08477
[32m[0906 16-05-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10579, current rewards: 92.02698, mean: 0.08682
[32m[0906 16-05-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10574, current rewards: 92.17932, mean: 0.08304
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10584, current rewards: 98.00142, mean: 0.08448
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10579, current rewards: 103.82479, mean: 0.08581
[32m[0906 16-05-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10570, current rewards: 109.64192, mean: 0.08702
[32m[0906 16-05-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10573, current rewards: 115.46479, mean: 0.08814
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10579, current rewards: 121.29040, mean: 0.08918
[32m[0906 16-06-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10585, current rewards: 127.11423, mean: 0.09015
[32m[0906 16-06-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10592, current rewards: 132.41842, mean: 0.09070
[32m[0906 16-06-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10598, current rewards: 137.78183, mean: 0.09125
[32m[0906 16-06-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10603, current rewards: 143.14831, mean: 0.09176
[32m[0906 16-06-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10609, current rewards: 148.23208, mean: 0.09207
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10614, current rewards: 153.85495, mean: 0.09268
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10617, current rewards: 159.31458, mean: 0.09317
[32m[0906 16-06-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10622, current rewards: 164.77596, mean: 0.09362
[32m[0906 16-06-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10626, current rewards: 170.23321, mean: 0.09405
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10639, current rewards: 176.02820, mean: 0.09464
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10653, current rewards: 181.69103, mean: 0.09513
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10663, current rewards: 187.36537, mean: 0.09559
[32m[0906 16-07-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10674, current rewards: 182.36924, mean: 0.09073
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10688, current rewards: 188.14511, mean: 0.09133
[32m[0906 16-07-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10697, current rewards: 193.91956, mean: 0.09191
[32m[0906 16-07-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10709, current rewards: 199.69347, mean: 0.09245
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10721, current rewards: 205.47164, mean: 0.09297
[32m[0906 16-07-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10729, current rewards: 211.29629, mean: 0.09349
[32m[0906 16-07-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10736, current rewards: 217.32586, mean: 0.09408
[32m[0906 16-07-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10745, current rewards: 222.99494, mean: 0.09449
[32m[0906 16-07-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10753, current rewards: 224.31512, mean: 0.09308
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10760, current rewards: 230.10446, mean: 0.09354
[32m[0906 16-08-09 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 16-08-09 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-08-09 @MBExp.py:227][0m Rewards obtained: [234.73165312552615], Lows: [16], Highs: [21], Total time: 7924.827235
[32m[0906 16-09-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-09-19 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 16-09-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10949, current rewards: -5.22185, mean: -0.52219
[32m[0906 16-09-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11121, current rewards: 0.33903, mean: 0.00565
[32m[0906 16-09-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11001, current rewards: 5.83526, mean: 0.05305
[32m[0906 16-09-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10913, current rewards: 11.32393, mean: 0.07077
[32m[0906 16-09-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10884, current rewards: 16.58689, mean: 0.07899
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10849, current rewards: 22.06340, mean: 0.08486
[32m[0906 16-09-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10827, current rewards: 27.53597, mean: 0.08883
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10822, current rewards: 33.00574, mean: 0.09168
[32m[0906 16-10-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10807, current rewards: 38.48476, mean: 0.09387
[32m[0906 16-10-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10791, current rewards: 43.96157, mean: 0.09557
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10756, current rewards: 49.43440, mean: 0.09693
[32m[0906 16-10-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10725, current rewards: 44.37765, mean: 0.07925
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10696, current rewards: 51.05682, mean: 0.08370
[32m[0906 16-10-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10658, current rewards: 58.15337, mean: 0.08811
[32m[0906 16-10-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10616, current rewards: 65.24992, mean: 0.09190
[32m[0906 16-10-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10589, current rewards: 72.34647, mean: 0.09519
[32m[0906 16-10-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10577, current rewards: 79.44302, mean: 0.09808
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10565, current rewards: 81.97185, mean: 0.09532
[32m[0906 16-10-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10554, current rewards: 31.97185, mean: 0.03513
[32m[0906 16-11-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10547, current rewards: -18.02815, mean: -0.01878
[32m[0906 16-11-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10539, current rewards: -68.02815, mean: -0.06735
[32m[0906 16-11-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10532, current rewards: -118.02815, mean: -0.11135
[32m[0906 16-11-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10527, current rewards: -168.02815, mean: -0.15138
[32m[0906 16-11-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10531, current rewards: -218.02815, mean: -0.18796
[32m[0906 16-11-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10526, current rewards: -268.02815, mean: -0.22151
[32m[0906 16-11-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10521, current rewards: -318.02815, mean: -0.25240
[32m[0906 16-11-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10521, current rewards: -368.02815, mean: -0.28094
[32m[0906 16-11-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10529, current rewards: -418.02815, mean: -0.30737
[32m[0906 16-11-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10539, current rewards: -468.02815, mean: -0.33193
[32m[0906 16-11-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10546, current rewards: -518.02815, mean: -0.35481
[32m[0906 16-11-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10554, current rewards: -568.02815, mean: -0.37618
[32m[0906 16-12-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10561, current rewards: -618.02815, mean: -0.39617
[32m[0906 16-12-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10566, current rewards: -668.02815, mean: -0.41492
[32m[0906 16-12-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10572, current rewards: -718.02815, mean: -0.43255
[32m[0906 16-12-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10579, current rewards: -768.02815, mean: -0.44914
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10583, current rewards: -818.02815, mean: -0.46479
[32m[0906 16-12-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10587, current rewards: -868.02815, mean: -0.47957
[32m[0906 16-12-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10601, current rewards: -918.02815, mean: -0.49356
[32m[0906 16-12-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10615, current rewards: -968.02815, mean: -0.50682
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10629, current rewards: -1018.02815, mean: -0.51940
[32m[0906 16-12-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10644, current rewards: -1068.02815, mean: -0.53136
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10654, current rewards: -1118.02815, mean: -0.54273
[32m[0906 16-13-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10665, current rewards: -1168.02815, mean: -0.55357
[32m[0906 16-13-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10677, current rewards: -1218.02815, mean: -0.56390
[32m[0906 16-13-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10687, current rewards: -1268.02815, mean: -0.57377
[32m[0906 16-13-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10697, current rewards: -1318.02815, mean: -0.58320
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10707, current rewards: -1368.02815, mean: -0.59222
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10716, current rewards: -1418.02815, mean: -0.60086
[32m[0906 16-13-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10725, current rewards: -1468.02815, mean: -0.60914
[32m[0906 16-13-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10734, current rewards: -1518.02815, mean: -0.61708
[32m[0906 16-13-48 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 16-13-48 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-13-48 @MBExp.py:227][0m Rewards obtained: [-1558.0281520451358], Lows: [5], Highs: [1650], Total time: 8194.082198
[32m[0906 16-15-00 @MBExp.py:144][0m ####################################################################
[32m[0906 16-15-00 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 16-15-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11227, current rewards: -4.44008, mean: -0.44401
[32m[0906 16-15-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11109, current rewards: 1.08026, mean: 0.01800
[32m[0906 16-15-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10973, current rewards: 6.68924, mean: 0.06081
[32m[0906 16-15-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10891, current rewards: 12.72292, mean: 0.07952
[32m[0906 16-15-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10852, current rewards: 18.38677, mean: 0.08756
[32m[0906 16-15-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10832, current rewards: 24.04460, mean: 0.09248
[32m[0906 16-15-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10822, current rewards: 29.70299, mean: 0.09582
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10809, current rewards: 35.32864, mean: 0.09814
[32m[0906 16-15-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10801, current rewards: 41.06267, mean: 0.10015
[32m[0906 16-15-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10795, current rewards: 46.79377, mean: 0.10173
[32m[0906 16-15-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10758, current rewards: 52.52477, mean: 0.10299
[32m[0906 16-16-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10725, current rewards: 58.24054, mean: 0.10400
[32m[0906 16-16-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10704, current rewards: 63.78697, mean: 0.10457
[32m[0906 16-16-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10680, current rewards: 61.11489, mean: 0.09260
[32m[0906 16-16-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10649, current rewards: 64.96877, mean: 0.09151
[32m[0906 16-16-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10623, current rewards: 70.58979, mean: 0.09288
[32m[0906 16-16-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10612, current rewards: 76.21063, mean: 0.09409
[32m[0906 16-16-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10597, current rewards: 81.83172, mean: 0.09515
[32m[0906 16-16-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10589, current rewards: 87.45570, mean: 0.09611
[32m[0906 16-16-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10581, current rewards: 93.07660, mean: 0.09695
[32m[0906 16-16-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10575, current rewards: 98.54602, mean: 0.09757
[32m[0906 16-16-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10571, current rewards: 104.15791, mean: 0.09826
[32m[0906 16-16-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10564, current rewards: 109.76951, mean: 0.09889
[32m[0906 16-17-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10559, current rewards: 115.38399, mean: 0.09947
[32m[0906 16-17-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10557, current rewards: 115.62338, mean: 0.09556
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10551, current rewards: 110.60518, mean: 0.08778
[32m[0906 16-17-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10549, current rewards: 116.10621, mean: 0.08863
[32m[0906 16-17-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10560, current rewards: 121.61148, mean: 0.08942
[32m[0906 16-17-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10569, current rewards: 127.60343, mean: 0.09050
[32m[0906 16-17-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10582, current rewards: 133.00483, mean: 0.09110
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10591, current rewards: 138.40318, mean: 0.09166
[32m[0906 16-17-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10596, current rewards: 143.80713, mean: 0.09218
[32m[0906 16-17-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10602, current rewards: 152.22997, mean: 0.09455
[32m[0906 16-17-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10608, current rewards: 157.90613, mean: 0.09512
[32m[0906 16-18-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10613, current rewards: 163.54933, mean: 0.09564
[32m[0906 16-18-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10617, current rewards: 169.18973, mean: 0.09613
[32m[0906 16-18-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10622, current rewards: 174.48391, mean: 0.09640
[32m[0906 16-18-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10635, current rewards: 180.46506, mean: 0.09702
[32m[0906 16-18-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10648, current rewards: 186.62236, mean: 0.09771
[32m[0906 16-18-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10661, current rewards: 192.77753, mean: 0.09836
[32m[0906 16-18-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10673, current rewards: 198.93300, mean: 0.09897
[32m[0906 16-18-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10685, current rewards: 194.16448, mean: 0.09425
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10696, current rewards: 199.72031, mean: 0.09465
[32m[0906 16-18-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10704, current rewards: 205.27434, mean: 0.09503
[32m[0906 16-18-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10714, current rewards: 210.83008, mean: 0.09540
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10722, current rewards: 216.15763, mean: 0.09564
[32m[0906 16-19-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10731, current rewards: 221.63594, mean: 0.09595
[32m[0906 16-19-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10739, current rewards: 227.11496, mean: 0.09624
[32m[0906 16-19-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10746, current rewards: 232.59563, mean: 0.09651
[32m[0906 16-19-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10753, current rewards: 238.07428, mean: 0.09678
[32m[0906 16-19-29 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 16-19-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-19-29 @MBExp.py:227][0m Rewards obtained: [242.45703380351824], Lows: [15], Highs: [10], Total time: 8463.813673
[32m[0906 16-20-43 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-43 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 16-20-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11163, current rewards: -4.18376, mean: -0.41838
[32m[0906 16-20-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11112, current rewards: 2.85321, mean: 0.04755
[32m[0906 16-20-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10943, current rewards: 9.66439, mean: 0.08786
[32m[0906 16-21-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10867, current rewards: 16.52396, mean: 0.10327
[32m[0906 16-21-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10848, current rewards: 23.32652, mean: 0.11108
[32m[0906 16-21-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10833, current rewards: 30.13843, mean: 0.11592
[32m[0906 16-21-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10813, current rewards: 36.94107, mean: 0.11916
[32m[0906 16-21-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10813, current rewards: 43.74429, mean: 0.12151
[32m[0906 16-21-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10801, current rewards: 39.77993, mean: 0.09702
[32m[0906 16-21-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10780, current rewards: 45.68144, mean: 0.09931
[32m[0906 16-21-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10744, current rewards: 51.57457, mean: 0.10113
[32m[0906 16-21-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10712, current rewards: 57.26308, mean: 0.10226
[32m[0906 16-21-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10691, current rewards: 63.16351, mean: 0.10355
[32m[0906 16-21-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10653, current rewards: 69.05936, mean: 0.10464
[32m[0906 16-21-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10614, current rewards: 64.28628, mean: 0.09054
[32m[0906 16-22-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10585, current rewards: 69.80961, mean: 0.09185
[32m[0906 16-22-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10582, current rewards: 75.33853, mean: 0.09301
[32m[0906 16-22-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10572, current rewards: 80.86790, mean: 0.09403
[32m[0906 16-22-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10563, current rewards: 86.39690, mean: 0.09494
[32m[0906 16-22-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10558, current rewards: 92.54221, mean: 0.09640
[32m[0906 16-22-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10551, current rewards: 97.87569, mean: 0.09691
[32m[0906 16-22-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10543, current rewards: 103.21207, mean: 0.09737
[32m[0906 16-22-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10538, current rewards: 108.54703, mean: 0.09779
[32m[0906 16-22-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10523, current rewards: 113.88251, mean: 0.09817
[32m[0906 16-22-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10519, current rewards: 110.76169, mean: 0.09154
[32m[0906 16-22-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10516, current rewards: 117.68835, mean: 0.09340
[32m[0906 16-23-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10512, current rewards: 124.61501, mean: 0.09513
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10518, current rewards: 131.39128, mean: 0.09661
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10529, current rewards: 123.98569, mean: 0.08793
[32m[0906 16-23-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10535, current rewards: 73.98569, mean: 0.05068
[32m[0906 16-23-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10542, current rewards: 23.98569, mean: 0.01588
[32m[0906 16-23-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10551, current rewards: -26.01431, mean: -0.01668
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10558, current rewards: -76.01431, mean: -0.04721
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10564, current rewards: -126.01431, mean: -0.07591
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10570, current rewards: -176.01431, mean: -0.10293
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10574, current rewards: -226.01431, mean: -0.12842
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10579, current rewards: -276.01431, mean: -0.15249
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10594, current rewards: -326.01431, mean: -0.17528
[32m[0906 16-24-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10606, current rewards: -376.01431, mean: -0.19687
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10618, current rewards: -426.01431, mean: -0.21735
[32m[0906 16-24-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10632, current rewards: -476.01431, mean: -0.23682
[32m[0906 16-24-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10644, current rewards: -526.01431, mean: -0.25535
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10656, current rewards: -576.01431, mean: -0.27299
[32m[0906 16-24-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10667, current rewards: -626.01431, mean: -0.28982
[32m[0906 16-24-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10678, current rewards: -676.01431, mean: -0.30589
[32m[0906 16-24-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10689, current rewards: -726.01431, mean: -0.32125
[32m[0906 16-24-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10698, current rewards: -776.01431, mean: -0.33594
[32m[0906 16-24-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10707, current rewards: -826.01431, mean: -0.35001
[32m[0906 16-25-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10717, current rewards: -876.01431, mean: -0.36349
[32m[0906 16-25-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10725, current rewards: -926.01431, mean: -0.37643
[32m[0906 16-25-12 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 16-25-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-25-12 @MBExp.py:227][0m Rewards obtained: [-966.0143133179049], Lows: [15], Highs: [1107], Total time: 8732.85092
[32m[0906 16-26-29 @MBExp.py:144][0m ####################################################################
[32m[0906 16-26-29 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 16-26-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11064, current rewards: -3.34744, mean: -0.33474
[32m[0906 16-26-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10945, current rewards: 2.63275, mean: 0.04388
[32m[0906 16-26-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10868, current rewards: 8.46518, mean: 0.07696
[32m[0906 16-26-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10823, current rewards: 14.44361, mean: 0.09027
[32m[0906 16-26-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10805, current rewards: 20.42456, mean: 0.09726
[32m[0906 16-26-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10804, current rewards: 26.40477, mean: 0.10156
[32m[0906 16-27-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10781, current rewards: 32.38640, mean: 0.10447
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10772, current rewards: 38.36426, mean: 0.10657
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10773, current rewards: 44.34566, mean: 0.10816
[32m[0906 16-27-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10750, current rewards: 50.32668, mean: 0.10941
[32m[0906 16-27-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10717, current rewards: 56.20640, mean: 0.11021
[32m[0906 16-27-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10696, current rewards: 62.23049, mean: 0.11113
[32m[0906 16-27-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10677, current rewards: 68.25427, mean: 0.11189
[32m[0906 16-27-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10631, current rewards: 74.28193, mean: 0.11255
[32m[0906 16-27-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10592, current rewards: 80.30440, mean: 0.11310
[32m[0906 16-27-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10556, current rewards: 80.61001, mean: 0.10607
[32m[0906 16-27-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10548, current rewards: 86.46235, mean: 0.10674
[32m[0906 16-28-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10540, current rewards: 92.32071, mean: 0.10735
[32m[0906 16-28-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10531, current rewards: 98.41727, mean: 0.10815
[32m[0906 16-28-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10526, current rewards: 104.24487, mean: 0.10859
[32m[0906 16-28-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10520, current rewards: 110.06763, mean: 0.10898
[32m[0906 16-28-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10515, current rewards: 115.89501, mean: 0.10933
[32m[0906 16-28-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10507, current rewards: 121.72004, mean: 0.10966
[32m[0906 16-28-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10490, current rewards: 127.55054, mean: 0.10996
[32m[0906 16-28-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10486, current rewards: 133.38070, mean: 0.11023
[32m[0906 16-28-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10485, current rewards: 139.20671, mean: 0.11048
[32m[0906 16-28-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10485, current rewards: 145.41883, mean: 0.11101
[32m[0906 16-28-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10491, current rewards: 152.23928, mean: 0.11194
[32m[0906 16-28-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10499, current rewards: 157.77396, mean: 0.11190
[32m[0906 16-29-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10509, current rewards: 157.76983, mean: 0.10806
[32m[0906 16-29-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10519, current rewards: 163.34715, mean: 0.10818
[32m[0906 16-29-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10525, current rewards: 168.92427, mean: 0.10828
[32m[0906 16-29-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10532, current rewards: 168.94209, mean: 0.10493
[32m[0906 16-29-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10538, current rewards: 175.82118, mean: 0.10592
[32m[0906 16-29-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10544, current rewards: 182.76516, mean: 0.10688
[32m[0906 16-29-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10551, current rewards: 189.49395, mean: 0.10767
[32m[0906 16-29-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10556, current rewards: 196.32894, mean: 0.10847
[32m[0906 16-29-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10568, current rewards: 203.17341, mean: 0.10923
[32m[0906 16-29-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10585, current rewards: 210.03069, mean: 0.10996
[32m[0906 16-29-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10598, current rewards: 216.87482, mean: 0.11065
[32m[0906 16-30-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10613, current rewards: 223.71358, mean: 0.11130
[32m[0906 16-30-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10624, current rewards: 230.56610, mean: 0.11193
[32m[0906 16-30-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10636, current rewards: 226.42285, mean: 0.10731
[32m[0906 16-30-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10649, current rewards: 231.68908, mean: 0.10726
[32m[0906 16-30-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10659, current rewards: 237.74856, mean: 0.10758
[32m[0906 16-30-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10669, current rewards: 243.82566, mean: 0.10789
[32m[0906 16-30-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10681, current rewards: 249.89170, mean: 0.10818
[32m[0906 16-30-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10690, current rewards: 255.96334, mean: 0.10846
[32m[0906 16-30-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10699, current rewards: 256.29476, mean: 0.10635
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10708, current rewards: 261.86745, mean: 0.10645
[32m[0906 16-30-57 @Agent.py:117][0m Average action selection time: 0.1071
[32m[0906 16-30-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-30-57 @MBExp.py:227][0m Rewards obtained: [266.32098249617775], Lows: [5], Highs: [24], Total time: 9001.451849000001
[32m[0906 16-32-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-32-16 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 16-32-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11101, current rewards: -5.62027, mean: -0.56203
[32m[0906 16-32-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10880, current rewards: 0.30204, mean: 0.00503
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10857, current rewards: 6.40223, mean: 0.05820
[32m[0906 16-32-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10802, current rewards: 12.20008, mean: 0.07625
[32m[0906 16-32-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10781, current rewards: 17.99585, mean: 0.08569
[32m[0906 16-32-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10774, current rewards: 23.79310, mean: 0.09151
[32m[0906 16-32-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10769, current rewards: 29.59155, mean: 0.09546
[32m[0906 16-32-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10762, current rewards: 35.39227, mean: 0.09831
[32m[0906 16-33-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10763, current rewards: 41.18912, mean: 0.10046
[32m[0906 16-33-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10744, current rewards: 46.98603, mean: 0.10214
[32m[0906 16-33-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10710, current rewards: 52.67744, mean: 0.10329
[32m[0906 16-33-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10692, current rewards: 53.07667, mean: 0.09478
[32m[0906 16-33-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10664, current rewards: 59.69468, mean: 0.09786
[32m[0906 16-33-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10623, current rewards: 65.90118, mean: 0.09985
[32m[0906 16-33-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10593, current rewards: 72.10209, mean: 0.10155
[32m[0906 16-33-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10561, current rewards: 78.30560, mean: 0.10303
[32m[0906 16-33-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10549, current rewards: 84.50338, mean: 0.10433
[32m[0906 16-33-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10546, current rewards: 90.70802, mean: 0.10547
[32m[0906 16-33-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10540, current rewards: 97.37715, mean: 0.10701
[32m[0906 16-33-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10532, current rewards: 92.77642, mean: 0.09664
[32m[0906 16-34-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10530, current rewards: 98.31765, mean: 0.09734
[32m[0906 16-34-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10526, current rewards: 103.85891, mean: 0.09798
[32m[0906 16-34-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10516, current rewards: 109.40010, mean: 0.09856
[32m[0906 16-34-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10500, current rewards: 114.94131, mean: 0.09909
[32m[0906 16-34-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10492, current rewards: 120.48245, mean: 0.09957
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10488, current rewards: 126.02369, mean: 0.10002
[32m[0906 16-34-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10488, current rewards: 131.28951, mean: 0.10022
[32m[0906 16-34-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10489, current rewards: 134.57287, mean: 0.09895
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10499, current rewards: 136.94959, mean: 0.09713
[32m[0906 16-34-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10509, current rewards: 142.43549, mean: 0.09756
[32m[0906 16-34-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10518, current rewards: 147.92616, mean: 0.09796
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10526, current rewards: 153.41301, mean: 0.09834
[32m[0906 16-35-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10535, current rewards: 158.90513, mean: 0.09870
[32m[0906 16-35-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10542, current rewards: 164.39398, mean: 0.09903
[32m[0906 16-35-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10548, current rewards: 169.87745, mean: 0.09934
[32m[0906 16-35-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10557, current rewards: 173.26072, mean: 0.09844
[32m[0906 16-35-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10561, current rewards: 170.56111, mean: 0.09423
[32m[0906 16-35-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10573, current rewards: 176.27681, mean: 0.09477
[32m[0906 16-35-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10589, current rewards: 181.98704, mean: 0.09528
[32m[0906 16-35-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10603, current rewards: 187.71075, mean: 0.09577
[32m[0906 16-35-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10616, current rewards: 193.42374, mean: 0.09623
[32m[0906 16-35-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10629, current rewards: 192.91947, mean: 0.09365
[32m[0906 16-36-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10641, current rewards: 198.46217, mean: 0.09406
[32m[0906 16-36-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10653, current rewards: 203.95462, mean: 0.09442
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10665, current rewards: 209.44336, mean: 0.09477
[32m[0906 16-36-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10675, current rewards: 214.93750, mean: 0.09511
[32m[0906 16-36-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10685, current rewards: 209.91292, mean: 0.09087
[32m[0906 16-36-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10696, current rewards: 215.70849, mean: 0.09140
[32m[0906 16-36-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10705, current rewards: 221.50656, mean: 0.09191
[32m[0906 16-36-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10715, current rewards: 227.30430, mean: 0.09240
[32m[0906 16-36-45 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 16-36-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-36-45 @MBExp.py:227][0m Rewards obtained: [231.9401362648429], Lows: [16], Highs: [22], Total time: 9270.224987000001
[32m[0906 16-38-06 @MBExp.py:144][0m ####################################################################
[32m[0906 16-38-06 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11156, current rewards: -6.13629, mean: -0.61363
[32m[0906 16-38-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10794, current rewards: -1.58735, mean: -0.02646
[32m[0906 16-38-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10780, current rewards: 3.16267, mean: 0.02875
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10766, current rewards: 7.91082, mean: 0.04944
[32m[0906 16-38-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10785, current rewards: 12.65379, mean: 0.06026
[32m[0906 16-38-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10806, current rewards: 17.40259, mean: 0.06693
[32m[0906 16-38-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10812, current rewards: 22.15494, mean: 0.07147
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10819, current rewards: 26.90432, mean: 0.07473
[32m[0906 16-38-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10826, current rewards: 31.65544, mean: 0.07721
[32m[0906 16-38-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10799, current rewards: 37.00687, mean: 0.08045
[32m[0906 16-39-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10759, current rewards: 30.73510, mean: 0.06026
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10734, current rewards: 37.05052, mean: 0.06616
[32m[0906 16-39-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10698, current rewards: 43.36595, mean: 0.07109
[32m[0906 16-39-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10653, current rewards: 49.68137, mean: 0.07527
[32m[0906 16-39-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10618, current rewards: 55.99680, mean: 0.07887
[32m[0906 16-39-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10585, current rewards: 45.41760, mean: 0.05976
[32m[0906 16-39-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10578, current rewards: -4.58240, mean: -0.00566
[32m[0906 16-39-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10576, current rewards: -54.58240, mean: -0.06347
[32m[0906 16-39-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10570, current rewards: -104.58240, mean: -0.11493
[32m[0906 16-39-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10565, current rewards: -154.58240, mean: -0.16102
[32m[0906 16-39-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10567, current rewards: -204.58240, mean: -0.20256
[32m[0906 16-39-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10563, current rewards: -254.58240, mean: -0.24017
[32m[0906 16-40-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10550, current rewards: -304.58240, mean: -0.27440
[32m[0906 16-40-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10535, current rewards: -354.58240, mean: -0.30567
[32m[0906 16-40-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10519, current rewards: -404.58240, mean: -0.33437
[32m[0906 16-40-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10515, current rewards: -454.58240, mean: -0.36078
[32m[0906 16-40-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10514, current rewards: -504.58240, mean: -0.38518
[32m[0906 16-40-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10510, current rewards: -554.58240, mean: -0.40778
[32m[0906 16-40-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10518, current rewards: -604.58240, mean: -0.42878
[32m[0906 16-40-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10526, current rewards: -654.58240, mean: -0.44834
[32m[0906 16-40-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10533, current rewards: -704.58240, mean: -0.46661
[32m[0906 16-40-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10542, current rewards: -754.58240, mean: -0.48371
[32m[0906 16-40-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10550, current rewards: -804.58240, mean: -0.49974
[32m[0906 16-41-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10555, current rewards: -854.58240, mean: -0.51481
[32m[0906 16-41-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10559, current rewards: -904.58240, mean: -0.52900
[32m[0906 16-41-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10566, current rewards: -954.58240, mean: -0.54238
[32m[0906 16-41-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10571, current rewards: -1004.58240, mean: -0.55502
[32m[0906 16-41-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10581, current rewards: -1054.58240, mean: -0.56698
[32m[0906 16-41-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10596, current rewards: -1104.58240, mean: -0.57832
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10610, current rewards: -1154.58240, mean: -0.58907
[32m[0906 16-41-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10624, current rewards: -1204.58240, mean: -0.59929
[32m[0906 16-41-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10639, current rewards: -1254.58240, mean: -0.60902
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10652, current rewards: -1304.58240, mean: -0.61829
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10665, current rewards: -1354.58240, mean: -0.62712
[32m[0906 16-42-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10676, current rewards: -1404.58240, mean: -0.63556
[32m[0906 16-42-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10687, current rewards: -1454.58240, mean: -0.64362
[32m[0906 16-42-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10698, current rewards: -1504.58240, mean: -0.65133
[32m[0906 16-42-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10708, current rewards: -1554.58240, mean: -0.65872
[32m[0906 16-42-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10717, current rewards: -1604.58240, mean: -0.66580
[32m[0906 16-42-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10726, current rewards: -1654.58240, mean: -0.67259
[32m[0906 16-42-35 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 16-42-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-42-35 @MBExp.py:227][0m Rewards obtained: [-1694.5824038646433], Lows: [7], Highs: [1760], Total time: 9539.293992
[32m[0906 16-43-59 @MBExp.py:144][0m ####################################################################
[32m[0906 16-43-59 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 16-44-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10700, current rewards: -5.50218, mean: -0.55022
[32m[0906 16-44-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10773, current rewards: 0.70084, mean: 0.01168
[32m[0906 16-44-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10747, current rewards: 6.65999, mean: 0.06055
[32m[0906 16-44-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10739, current rewards: 12.62474, mean: 0.07890
[32m[0906 16-44-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10731, current rewards: 18.58778, mean: 0.08851
[32m[0906 16-44-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10726, current rewards: 24.54976, mean: 0.09442
[32m[0906 16-44-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10718, current rewards: 30.51580, mean: 0.09844
[32m[0906 16-44-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10725, current rewards: 36.47332, mean: 0.10131
[32m[0906 16-44-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10725, current rewards: 42.93483, mean: 0.10472
[32m[0906 16-44-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10698, current rewards: 49.70181, mean: 0.10805
[32m[0906 16-44-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10673, current rewards: 55.50577, mean: 0.10883
[32m[0906 16-44-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10645, current rewards: 61.31018, mean: 0.10948
[32m[0906 16-45-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10612, current rewards: 61.98921, mean: 0.10162
[32m[0906 16-45-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10571, current rewards: 67.62537, mean: 0.10246
[32m[0906 16-45-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10536, current rewards: 73.26309, mean: 0.10319
[32m[0906 16-45-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10504, current rewards: 78.89646, mean: 0.10381
[32m[0906 16-45-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10496, current rewards: 84.53433, mean: 0.10436
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10492, current rewards: 90.17263, mean: 0.10485
[32m[0906 16-45-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10486, current rewards: 95.81472, mean: 0.10529
[32m[0906 16-45-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10484, current rewards: 101.45806, mean: 0.10569
[32m[0906 16-45-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10480, current rewards: 107.09598, mean: 0.10604
[32m[0906 16-45-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10480, current rewards: 107.55196, mean: 0.10146
[32m[0906 16-45-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10464, current rewards: 113.75109, mean: 0.10248
[32m[0906 16-46-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10449, current rewards: 119.95179, mean: 0.10341
[32m[0906 16-46-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10433, current rewards: 126.15005, mean: 0.10426
[32m[0906 16-46-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10425, current rewards: 132.46259, mean: 0.10513
[32m[0906 16-46-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10425, current rewards: 138.72563, mean: 0.10590
[32m[0906 16-46-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10423, current rewards: 144.98737, mean: 0.10661
[32m[0906 16-46-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10428, current rewards: 151.25412, mean: 0.10727
[32m[0906 16-46-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10439, current rewards: 146.58891, mean: 0.10040
[32m[0906 16-46-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10449, current rewards: 152.28990, mean: 0.10085
[32m[0906 16-46-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10460, current rewards: 157.99370, mean: 0.10128
[32m[0906 16-46-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10471, current rewards: 163.69484, mean: 0.10167
[32m[0906 16-46-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10480, current rewards: 169.72004, mean: 0.10224
[32m[0906 16-46-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10487, current rewards: 175.42561, mean: 0.10259
[32m[0906 16-47-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10495, current rewards: 181.13252, mean: 0.10292
[32m[0906 16-47-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10502, current rewards: 186.83287, mean: 0.10322
[32m[0906 16-47-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10511, current rewards: 192.20853, mean: 0.10334
[32m[0906 16-47-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10529, current rewards: 197.75717, mean: 0.10354
[32m[0906 16-47-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10543, current rewards: 203.30018, mean: 0.10372
[32m[0906 16-47-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10561, current rewards: 208.83781, mean: 0.10390
[32m[0906 16-47-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10576, current rewards: 214.34732, mean: 0.10405
[32m[0906 16-47-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10589, current rewards: 219.89096, mean: 0.10421
[32m[0906 16-47-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10602, current rewards: 225.43192, mean: 0.10437
[32m[0906 16-47-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10615, current rewards: 230.97259, mean: 0.10451
[32m[0906 16-47-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10627, current rewards: 236.51429, mean: 0.10465
[32m[0906 16-48-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10640, current rewards: 237.25680, mean: 0.10271
[32m[0906 16-48-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10649, current rewards: 242.90311, mean: 0.10293
[32m[0906 16-48-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10659, current rewards: 248.53819, mean: 0.10313
[32m[0906 16-48-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10671, current rewards: 253.93658, mean: 0.10323
[32m[0906 16-48-26 @Agent.py:117][0m Average action selection time: 0.1068
[32m[0906 16-48-26 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-48-26 @MBExp.py:227][0m Rewards obtained: [258.5303053927382], Lows: [5], Highs: [21], Total time: 9806.981635
[32m[0906 16-49-52 @MBExp.py:144][0m ####################################################################
[32m[0906 16-49-52 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 16-49-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10615, current rewards: -5.40454, mean: -0.54045
[32m[0906 16-49-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10746, current rewards: 1.18308, mean: 0.01972
[32m[0906 16-50-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10749, current rewards: 7.33226, mean: 0.06666
[32m[0906 16-50-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10754, current rewards: 13.48056, mean: 0.08425
[32m[0906 16-50-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10761, current rewards: 19.63352, mean: 0.09349
[32m[0906 16-50-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10759, current rewards: 25.78929, mean: 0.09919
[32m[0906 16-50-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10751, current rewards: 31.94582, mean: 0.10305
[32m[0906 16-50-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10751, current rewards: 28.79220, mean: 0.07998
[32m[0906 16-50-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10742, current rewards: 34.65991, mean: 0.08454
[32m[0906 16-50-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10723, current rewards: 40.34034, mean: 0.08770
[32m[0906 16-50-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10693, current rewards: 40.45258, mean: 0.07932
[32m[0906 16-50-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10690, current rewards: 42.98513, mean: 0.07676
[32m[0906 16-50-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10653, current rewards: 49.35084, mean: 0.08090
[32m[0906 16-51-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10610, current rewards: 55.72485, mean: 0.08443
[32m[0906 16-51-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10570, current rewards: 62.10101, mean: 0.08747
[32m[0906 16-51-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10537, current rewards: 68.47233, mean: 0.09010
[32m[0906 16-51-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10522, current rewards: 74.93963, mean: 0.09252
[32m[0906 16-51-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10517, current rewards: 81.33129, mean: 0.09457
[32m[0906 16-51-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10510, current rewards: 77.14309, mean: 0.08477
[32m[0906 16-51-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10506, current rewards: 82.75372, mean: 0.08620
[32m[0906 16-51-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10504, current rewards: 88.28329, mean: 0.08741
[32m[0906 16-51-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10498, current rewards: 93.82042, mean: 0.08851
[32m[0906 16-51-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10481, current rewards: 99.35773, mean: 0.08951
[32m[0906 16-51-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10464, current rewards: 104.89192, mean: 0.09042
[32m[0906 16-51-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10447, current rewards: 109.94919, mean: 0.09087
[32m[0906 16-52-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10439, current rewards: 115.74987, mean: 0.09186
[32m[0906 16-52-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10438, current rewards: 121.54802, mean: 0.09278
[32m[0906 16-52-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10438, current rewards: 127.35194, mean: 0.09364
[32m[0906 16-52-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10441, current rewards: 133.15117, mean: 0.09443
[32m[0906 16-52-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10452, current rewards: 138.95040, mean: 0.09517
[32m[0906 16-52-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10462, current rewards: 144.74737, mean: 0.09586
[32m[0906 16-52-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10474, current rewards: 150.54757, mean: 0.09650
[32m[0906 16-52-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10486, current rewards: 147.64969, mean: 0.09171
[32m[0906 16-52-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10493, current rewards: 152.70913, mean: 0.09199
[32m[0906 16-52-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10502, current rewards: 157.76178, mean: 0.09226
[32m[0906 16-52-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10509, current rewards: 162.81340, mean: 0.09251
[32m[0906 16-53-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10517, current rewards: 167.86474, mean: 0.09274
[32m[0906 16-53-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10525, current rewards: 166.61185, mean: 0.08958
[32m[0906 16-53-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10540, current rewards: 168.36919, mean: 0.08815
[32m[0906 16-53-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10555, current rewards: 174.67929, mean: 0.08912
[32m[0906 16-53-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10571, current rewards: 180.79750, mean: 0.08995
[32m[0906 16-53-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10585, current rewards: 187.00626, mean: 0.09078
[32m[0906 16-53-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10599, current rewards: 193.21816, mean: 0.09157
[32m[0906 16-53-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10612, current rewards: 194.25222, mean: 0.08993
[32m[0906 16-53-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10624, current rewards: 200.44582, mean: 0.09070
[32m[0906 16-53-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10637, current rewards: 206.64080, mean: 0.09143
[32m[0906 16-53-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10648, current rewards: 212.81561, mean: 0.09213
[32m[0906 16-54-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10658, current rewards: 219.00533, mean: 0.09280
[32m[0906 16-54-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10669, current rewards: 225.45363, mean: 0.09355
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10678, current rewards: 231.72172, mean: 0.09420
[32m[0906 16-54-20 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 16-54-20 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-54-20 @MBExp.py:227][0m Rewards obtained: [236.74351323304433], Lows: [18], Highs: [23], Total time: 10074.891748
[32m[0906 16-55-48 @MBExp.py:144][0m ####################################################################
[32m[0906 16-55-48 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 16-55-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10727, current rewards: -5.63492, mean: -0.56349
[32m[0906 16-55-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10758, current rewards: -0.28270, mean: -0.00471
[32m[0906 16-56-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10779, current rewards: 5.35731, mean: 0.04870
[32m[0906 16-56-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10777, current rewards: 10.99970, mean: 0.06875
[32m[0906 16-56-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10764, current rewards: 16.64098, mean: 0.07924
[32m[0906 16-56-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10765, current rewards: 22.28195, mean: 0.08570
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10758, current rewards: 17.23125, mean: 0.05558
[32m[0906 16-56-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10759, current rewards: 24.19287, mean: 0.06720
[32m[0906 16-56-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10769, current rewards: 30.16843, mean: 0.07358
[32m[0906 16-56-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10740, current rewards: 36.13892, mean: 0.07856
[32m[0906 16-56-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10707, current rewards: 42.10898, mean: 0.08257
[32m[0906 16-56-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10684, current rewards: 48.07919, mean: 0.08586
[32m[0906 16-56-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10647, current rewards: 54.04910, mean: 0.08861
[32m[0906 16-56-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10603, current rewards: 60.01957, mean: 0.09094
[32m[0906 16-57-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10568, current rewards: 58.20942, mean: 0.08199
[32m[0906 16-57-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10535, current rewards: 64.13338, mean: 0.08439
[32m[0906 16-57-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10517, current rewards: 69.83202, mean: 0.08621
[32m[0906 16-57-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10514, current rewards: 75.59280, mean: 0.08790
[32m[0906 16-57-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10513, current rewards: 81.36392, mean: 0.08941
[32m[0906 16-57-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10511, current rewards: 87.12590, mean: 0.09076
[32m[0906 16-57-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10513, current rewards: 92.88836, mean: 0.09197
[32m[0906 16-57-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10505, current rewards: 98.65619, mean: 0.09307
[32m[0906 16-57-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10485, current rewards: 93.57175, mean: 0.08430
[32m[0906 16-57-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10469, current rewards: 99.22558, mean: 0.08554
[32m[0906 16-57-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10452, current rewards: 104.88290, mean: 0.08668
[32m[0906 16-57-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10438, current rewards: 110.54340, mean: 0.08773
[32m[0906 16-58-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10432, current rewards: 116.20298, mean: 0.08870
[32m[0906 16-58-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10434, current rewards: 121.85563, mean: 0.08960
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10434, current rewards: 127.51572, mean: 0.09044
[32m[0906 16-58-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10441, current rewards: 133.17573, mean: 0.09122
[32m[0906 16-58-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10453, current rewards: 138.83601, mean: 0.09194
[32m[0906 16-58-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10464, current rewards: 144.49219, mean: 0.09262
[32m[0906 16-58-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10472, current rewards: 141.60724, mean: 0.08795
[32m[0906 16-58-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10481, current rewards: 145.59081, mean: 0.08771
[32m[0906 16-58-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10488, current rewards: 151.49392, mean: 0.08859
[32m[0906 16-58-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10494, current rewards: 157.39877, mean: 0.08943
[32m[0906 16-58-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10504, current rewards: 163.30182, mean: 0.09022
[32m[0906 16-59-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10509, current rewards: 169.20642, mean: 0.09097
[32m[0906 16-59-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10523, current rewards: 175.11019, mean: 0.09168
[32m[0906 16-59-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10538, current rewards: 175.38081, mean: 0.08948
[32m[0906 16-59-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10551, current rewards: 181.81462, mean: 0.09046
[32m[0906 16-59-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10566, current rewards: 187.72214, mean: 0.09113
[32m[0906 16-59-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10580, current rewards: 193.63315, mean: 0.09177
[32m[0906 16-59-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10593, current rewards: 199.53702, mean: 0.09238
[32m[0906 16-59-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10606, current rewards: 205.44480, mean: 0.09296
[32m[0906 16-59-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10619, current rewards: 211.35232, mean: 0.09352
[32m[0906 16-59-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10629, current rewards: 207.15399, mean: 0.08968
[32m[0906 16-59-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10641, current rewards: 213.15799, mean: 0.09032
[32m[0906 17-00-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10651, current rewards: 219.12817, mean: 0.09092
[32m[0906 17-00-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10660, current rewards: 225.09834, mean: 0.09150
[32m[0906 17-00-15 @Agent.py:117][0m Average action selection time: 0.1067
[32m[0906 17-00-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-00-15 @MBExp.py:227][0m Rewards obtained: [229.87459768374717], Lows: [20], Highs: [18], Total time: 10342.317458
[32m[0906 17-01-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-01-45 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 17-01-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10712, current rewards: -5.38965, mean: -0.53896
[32m[0906 17-01-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10774, current rewards: 0.07166, mean: 0.00119
[32m[0906 17-01-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10734, current rewards: 5.52743, mean: 0.05025
[32m[0906 17-02-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10727, current rewards: 10.97616, mean: 0.06860
[32m[0906 17-02-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10735, current rewards: 16.43282, mean: 0.07825
[32m[0906 17-02-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10732, current rewards: 21.88634, mean: 0.08418
[32m[0906 17-02-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10727, current rewards: 27.28323, mean: 0.08801
[32m[0906 17-02-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10733, current rewards: 32.72659, mean: 0.09091
[32m[0906 17-02-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10729, current rewards: 38.17669, mean: 0.09311
[32m[0906 17-02-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10705, current rewards: 43.62269, mean: 0.09483
[32m[0906 17-02-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10678, current rewards: 49.07133, mean: 0.09622
[32m[0906 17-02-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10654, current rewards: 54.51857, mean: 0.09735
[32m[0906 17-02-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10618, current rewards: 49.53704, mean: 0.08121
[32m[0906 17-02-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10580, current rewards: 54.95673, mean: 0.08327
[32m[0906 17-03-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10544, current rewards: 60.37133, mean: 0.08503
[32m[0906 17-03-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10511, current rewards: 65.79284, mean: 0.08657
[32m[0906 17-03-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10490, current rewards: 71.21679, mean: 0.08792
[32m[0906 17-03-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10484, current rewards: 76.62643, mean: 0.08910
[32m[0906 17-03-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10479, current rewards: 76.57529, mean: 0.08415
[32m[0906 17-03-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10476, current rewards: 82.04450, mean: 0.08546
[32m[0906 17-03-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10472, current rewards: 87.52278, mean: 0.08666
[32m[0906 17-03-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10463, current rewards: 93.00004, mean: 0.08774
[32m[0906 17-03-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10448, current rewards: 98.95450, mean: 0.08915
[32m[0906 17-03-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10434, current rewards: 104.50130, mean: 0.09009
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10420, current rewards: 110.04885, mean: 0.09095
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10409, current rewards: 116.01098, mean: 0.09207
[32m[0906 17-04-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10400, current rewards: 122.21867, mean: 0.09330
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10400, current rewards: 128.43354, mean: 0.09444
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10403, current rewards: 134.63353, mean: 0.09548
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10405, current rewards: 140.84209, mean: 0.09647
[32m[0906 17-04-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10416, current rewards: 147.74603, mean: 0.09785
[32m[0906 17-04-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10429, current rewards: 153.76447, mean: 0.09857
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10438, current rewards: 159.52991, mean: 0.09909
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10447, current rewards: 165.28818, mean: 0.09957
[32m[0906 17-04-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10459, current rewards: 159.31565, mean: 0.09317
[32m[0906 17-04-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10467, current rewards: 165.77447, mean: 0.09419
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10476, current rewards: 172.23330, mean: 0.09516
[32m[0906 17-05-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10486, current rewards: 178.69212, mean: 0.09607
[32m[0906 17-05-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10497, current rewards: 185.15095, mean: 0.09694
[32m[0906 17-05-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10513, current rewards: 190.24395, mean: 0.09706
[32m[0906 17-05-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10531, current rewards: 195.79913, mean: 0.09741
[32m[0906 17-05-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10547, current rewards: 195.79787, mean: 0.09505
[32m[0906 17-05-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10561, current rewards: 201.94647, mean: 0.09571
[32m[0906 17-05-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10576, current rewards: 207.25067, mean: 0.09595
[32m[0906 17-05-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10589, current rewards: 212.55655, mean: 0.09618
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10601, current rewards: 217.86214, mean: 0.09640
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10614, current rewards: 223.17256, mean: 0.09661
[32m[0906 17-05-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10625, current rewards: 228.48073, mean: 0.09681
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10635, current rewards: 233.79181, mean: 0.09701
[32m[0906 17-06-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10645, current rewards: 239.10746, mean: 0.09720
[32m[0906 17-06-12 @Agent.py:117][0m Average action selection time: 0.1065
[32m[0906 17-06-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-06-12 @MBExp.py:227][0m Rewards obtained: [243.35038274207903], Lows: [11], Highs: [17], Total time: 10609.367323999999
[32m[0906 17-07-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-07-45 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 17-07-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10684, current rewards: -5.79920, mean: -0.57992
[32m[0906 17-07-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10727, current rewards: -0.30314, mean: -0.00505
[32m[0906 17-07-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10744, current rewards: 5.13784, mean: 0.04671
[32m[0906 17-08-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10742, current rewards: 10.57425, mean: 0.06609
[32m[0906 17-08-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10724, current rewards: 16.01704, mean: 0.07627
[32m[0906 17-08-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10727, current rewards: 21.51673, mean: 0.08276
[32m[0906 17-08-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10725, current rewards: 26.93565, mean: 0.08689
[32m[0906 17-08-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10721, current rewards: 32.36089, mean: 0.08989
[32m[0906 17-08-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10727, current rewards: 37.78380, mean: 0.09216
[32m[0906 17-08-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10703, current rewards: 43.20506, mean: 0.09392
[32m[0906 17-08-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10674, current rewards: 48.62828, mean: 0.09535
[32m[0906 17-08-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10650, current rewards: 54.04714, mean: 0.09651
[32m[0906 17-08-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10613, current rewards: 59.46402, mean: 0.09748
[32m[0906 17-08-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10570, current rewards: 53.29226, mean: 0.08075
[32m[0906 17-09-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10539, current rewards: 58.75145, mean: 0.08275
[32m[0906 17-09-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10506, current rewards: 64.21187, mean: 0.08449
[32m[0906 17-09-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10480, current rewards: 69.67255, mean: 0.08602
[32m[0906 17-09-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10480, current rewards: 75.13339, mean: 0.08736
[32m[0906 17-09-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10475, current rewards: 80.59441, mean: 0.08857
[32m[0906 17-09-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10471, current rewards: 86.05473, mean: 0.08964
[32m[0906 17-09-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10470, current rewards: 91.51522, mean: 0.09061
[32m[0906 17-09-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10456, current rewards: 96.61446, mean: 0.09115
[32m[0906 17-09-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10440, current rewards: 102.00279, mean: 0.09189
[32m[0906 17-09-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10429, current rewards: 100.97910, mean: 0.08705
[32m[0906 17-09-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10417, current rewards: 106.51994, mean: 0.08803
[32m[0906 17-09-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10405, current rewards: 112.05221, mean: 0.08893
[32m[0906 17-10-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10396, current rewards: 117.59038, mean: 0.08976
[32m[0906 17-10-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10396, current rewards: 123.12638, mean: 0.09053
[32m[0906 17-10-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10397, current rewards: 128.66192, mean: 0.09125
[32m[0906 17-10-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10400, current rewards: 134.20214, mean: 0.09192
[32m[0906 17-10-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10409, current rewards: 139.80136, mean: 0.09258
[32m[0906 17-10-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10422, current rewards: 145.34441, mean: 0.09317
[32m[0906 17-10-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10434, current rewards: 150.88945, mean: 0.09372
[32m[0906 17-10-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10444, current rewards: 156.43616, mean: 0.09424
[32m[0906 17-10-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10453, current rewards: 161.98355, mean: 0.09473
[32m[0906 17-10-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10463, current rewards: 167.53190, mean: 0.09519
[32m[0906 17-10-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10471, current rewards: 173.08052, mean: 0.09562
[32m[0906 17-11-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10479, current rewards: 168.06508, mean: 0.09036
[32m[0906 17-11-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10487, current rewards: 173.42839, mean: 0.09080
[32m[0906 17-11-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10504, current rewards: 178.80265, mean: 0.09123
[32m[0906 17-11-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10520, current rewards: 184.17511, mean: 0.09163
[32m[0906 17-11-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10536, current rewards: 189.54901, mean: 0.09201
[32m[0906 17-11-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10551, current rewards: 194.91504, mean: 0.09238
[32m[0906 17-11-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10564, current rewards: 200.28212, mean: 0.09272
[32m[0906 17-11-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10578, current rewards: 205.65321, mean: 0.09306
[32m[0906 17-11-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10590, current rewards: 211.02209, mean: 0.09337
[32m[0906 17-11-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10601, current rewards: 216.25523, mean: 0.09362
[32m[0906 17-11-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10613, current rewards: 221.68591, mean: 0.09393
[32m[0906 17-12-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10623, current rewards: 227.11621, mean: 0.09424
[32m[0906 17-12-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10634, current rewards: 232.53138, mean: 0.09452
[32m[0906 17-12-11 @Agent.py:117][0m Average action selection time: 0.1064
[32m[0906 17-12-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-12-11 @MBExp.py:227][0m Rewards obtained: [234.20942393733876], Lows: [11], Highs: [17], Total time: 10876.192518
[32m[0906 17-13-46 @MBExp.py:144][0m ####################################################################
[32m[0906 17-13-46 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 17-13-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10803, current rewards: -5.65579, mean: -0.56558
[32m[0906 17-13-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10740, current rewards: 0.95431, mean: 0.01591
[32m[0906 17-13-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10740, current rewards: 7.55866, mean: 0.06872
[32m[0906 17-14-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10743, current rewards: 14.16610, mean: 0.08854
[32m[0906 17-14-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10723, current rewards: 20.84350, mean: 0.09925
[32m[0906 17-14-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10733, current rewards: 27.47820, mean: 0.10569
[32m[0906 17-14-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10742, current rewards: 34.11252, mean: 0.11004
[32m[0906 17-14-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10743, current rewards: 40.73690, mean: 0.11316
[32m[0906 17-14-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10749, current rewards: 47.36455, mean: 0.11552
[32m[0906 17-14-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10732, current rewards: 54.00182, mean: 0.11740
[32m[0906 17-14-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10698, current rewards: 60.63903, mean: 0.11890
[32m[0906 17-14-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10675, current rewards: 67.26398, mean: 0.12011
[32m[0906 17-14-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10640, current rewards: 68.20040, mean: 0.11180
[32m[0906 17-14-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10598, current rewards: 75.68034, mean: 0.11467
[32m[0906 17-15-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10560, current rewards: 83.16120, mean: 0.11713
[32m[0906 17-15-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10530, current rewards: 90.64068, mean: 0.11926
[32m[0906 17-15-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10502, current rewards: 98.11827, mean: 0.12113
[32m[0906 17-15-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10494, current rewards: 105.59123, mean: 0.12278
[32m[0906 17-15-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10494, current rewards: 113.07024, mean: 0.12425
[32m[0906 17-15-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10491, current rewards: 120.53932, mean: 0.12556
[32m[0906 17-15-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10487, current rewards: 128.93008, mean: 0.12765
[32m[0906 17-15-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10474, current rewards: 136.55480, mean: 0.12883
[32m[0906 17-15-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10457, current rewards: 144.19134, mean: 0.12990
[32m[0906 17-15-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10442, current rewards: 149.20763, mean: 0.12863
[32m[0906 17-15-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10428, current rewards: 159.23033, mean: 0.13160
[32m[0906 17-15-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10414, current rewards: 169.23704, mean: 0.13432
[32m[0906 17-16-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10401, current rewards: 179.30002, mean: 0.13687
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10395, current rewards: 189.36499, mean: 0.13924
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10397, current rewards: 198.04963, mean: 0.14046
[32m[0906 17-16-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10398, current rewards: 207.71012, mean: 0.14227
[32m[0906 17-16-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10403, current rewards: 206.37836, mean: 0.13667
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10414, current rewards: 212.75884, mean: 0.13638
[32m[0906 17-16-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10425, current rewards: 219.49197, mean: 0.13633
[32m[0906 17-16-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10438, current rewards: 226.23425, mean: 0.13629
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10446, current rewards: 232.97501, mean: 0.13624
[32m[0906 17-16-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10455, current rewards: 239.70918, mean: 0.13620
[32m[0906 17-16-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10467, current rewards: 247.02740, mean: 0.13648
[32m[0906 17-17-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10475, current rewards: 253.95645, mean: 0.13654
[32m[0906 17-17-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10483, current rewards: 260.67329, mean: 0.13648
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10498, current rewards: 267.40542, mean: 0.13643
[32m[0906 17-17-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10515, current rewards: 274.12547, mean: 0.13638
[32m[0906 17-17-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10530, current rewards: 280.84477, mean: 0.13633
[32m[0906 17-17-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10548, current rewards: 287.56550, mean: 0.13629
[32m[0906 17-17-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10563, current rewards: 294.28521, mean: 0.13624
[32m[0906 17-17-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10578, current rewards: 301.01403, mean: 0.13621
[32m[0906 17-17-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10590, current rewards: 309.47292, mean: 0.13693
[32m[0906 17-17-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10602, current rewards: 316.19511, mean: 0.13688
[32m[0906 17-17-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10614, current rewards: 315.89492, mean: 0.13385
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10623, current rewards: 322.35710, mean: 0.13376
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10634, current rewards: 328.82243, mean: 0.13367
[32m[0906 17-18-13 @Agent.py:117][0m Average action selection time: 0.1064
[32m[0906 17-18-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-18-13 @MBExp.py:227][0m Rewards obtained: [333.9942830889015], Lows: [6], Highs: [17], Total time: 11142.996849
[32m[0906 17-19-50 @MBExp.py:144][0m ####################################################################
[32m[0906 17-19-50 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 17-19-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10658, current rewards: -5.66461, mean: -0.56646
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10729, current rewards: 0.96639, mean: 0.01611
[32m[0906 17-20-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10729, current rewards: 8.19226, mean: 0.07448
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10742, current rewards: 15.89253, mean: 0.09933
[32m[0906 17-20-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10740, current rewards: 23.84682, mean: 0.11356
[32m[0906 17-20-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10738, current rewards: 30.84320, mean: 0.11863
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10745, current rewards: 37.83843, mean: 0.12206
[32m[0906 17-20-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10748, current rewards: 44.83520, mean: 0.12454
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10742, current rewards: 51.83868, mean: 0.12644
[32m[0906 17-20-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10737, current rewards: 58.84076, mean: 0.12791
[32m[0906 17-20-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10698, current rewards: 65.83616, mean: 0.12909
[32m[0906 17-20-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10670, current rewards: 72.82970, mean: 0.13005
[32m[0906 17-20-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10640, current rewards: 80.30864, mean: 0.13165
[32m[0906 17-21-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10599, current rewards: 77.85581, mean: 0.11796
[32m[0906 17-21-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10561, current rewards: 84.30041, mean: 0.11873
[32m[0906 17-21-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10532, current rewards: 90.75632, mean: 0.11942
[32m[0906 17-21-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10502, current rewards: 97.21366, mean: 0.12002
[32m[0906 17-21-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10495, current rewards: 103.66521, mean: 0.12054
[32m[0906 17-21-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10493, current rewards: 110.11281, mean: 0.12100
[32m[0906 17-21-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10487, current rewards: 104.20669, mean: 0.10855
[32m[0906 17-21-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10483, current rewards: 109.94594, mean: 0.10886
[32m[0906 17-21-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10468, current rewards: 116.00035, mean: 0.10943
[32m[0906 17-21-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10450, current rewards: 122.05715, mean: 0.10996
[32m[0906 17-21-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10435, current rewards: 128.11155, mean: 0.11044
[32m[0906 17-21-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10424, current rewards: 134.16569, mean: 0.11088
[32m[0906 17-22-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10413, current rewards: 140.22085, mean: 0.11129
[32m[0906 17-22-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10401, current rewards: 146.27207, mean: 0.11166
[32m[0906 17-22-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10391, current rewards: 146.53004, mean: 0.10774
[32m[0906 17-22-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10388, current rewards: 153.38900, mean: 0.10879
[32m[0906 17-22-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10387, current rewards: 160.32854, mean: 0.10981
[32m[0906 17-22-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10390, current rewards: 167.26777, mean: 0.11077
[32m[0906 17-22-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10398, current rewards: 174.20621, mean: 0.11167
[32m[0906 17-22-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10410, current rewards: 181.14488, mean: 0.11251
[32m[0906 17-22-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10425, current rewards: 188.09427, mean: 0.11331
[32m[0906 17-22-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10435, current rewards: 195.03192, mean: 0.11405
[32m[0906 17-22-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10445, current rewards: 201.97690, mean: 0.11476
[32m[0906 17-22-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10455, current rewards: 209.23411, mean: 0.11560
[32m[0906 17-23-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10463, current rewards: 216.19865, mean: 0.11624
[32m[0906 17-23-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10471, current rewards: 223.17426, mean: 0.11685
[32m[0906 17-23-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10485, current rewards: 230.14972, mean: 0.11742
[32m[0906 17-23-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10501, current rewards: 225.63489, mean: 0.11226
[32m[0906 17-23-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10517, current rewards: 231.38110, mean: 0.11232
[32m[0906 17-23-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10533, current rewards: 237.12355, mean: 0.11238
[32m[0906 17-23-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10547, current rewards: 242.86759, mean: 0.11244
[32m[0906 17-23-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10561, current rewards: 248.32295, mean: 0.11236
[32m[0906 17-23-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10575, current rewards: 253.92113, mean: 0.11235
[32m[0906 17-23-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10588, current rewards: 259.67125, mean: 0.11241
[32m[0906 17-24-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10599, current rewards: 265.42342, mean: 0.11247
[32m[0906 17-24-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10611, current rewards: 271.17891, mean: 0.11252
[32m[0906 17-24-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10621, current rewards: 276.93832, mean: 0.11258
[32m[0906 17-24-16 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 17-24-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-24-16 @MBExp.py:227][0m Rewards obtained: [281.5425309406453], Lows: [16], Highs: [12], Total time: 11409.449627
[32m[0906 17-25-56 @MBExp.py:144][0m ####################################################################
[32m[0906 17-25-56 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 17-25-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10687, current rewards: -4.84658, mean: -0.48466
[32m[0906 17-26-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10721, current rewards: 0.85069, mean: 0.01418
[32m[0906 17-26-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10708, current rewards: 6.26131, mean: 0.05692
[32m[0906 17-26-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10726, current rewards: 11.40467, mean: 0.07128
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10712, current rewards: 16.78143, mean: 0.07991
[32m[0906 17-26-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10716, current rewards: 22.15723, mean: 0.08522
[32m[0906 17-26-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10718, current rewards: 27.53257, mean: 0.08881
[32m[0906 17-26-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10719, current rewards: 32.91313, mean: 0.09143
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10719, current rewards: 38.29609, mean: 0.09341
[32m[0906 17-26-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10711, current rewards: 43.66679, mean: 0.09493
[32m[0906 17-26-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10680, current rewards: 49.03940, mean: 0.09616
[32m[0906 17-26-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10657, current rewards: 55.05794, mean: 0.09832
[32m[0906 17-27-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10637, current rewards: 60.27666, mean: 0.09881
[32m[0906 17-27-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10595, current rewards: 65.44007, mean: 0.09915
[32m[0906 17-27-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10560, current rewards: 70.58417, mean: 0.09941
[32m[0906 17-27-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10532, current rewards: 75.73327, mean: 0.09965
[32m[0906 17-27-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10506, current rewards: 70.81473, mean: 0.08743
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10495, current rewards: 77.15505, mean: 0.08972
[32m[0906 17-27-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10500, current rewards: 83.00450, mean: 0.09121
[32m[0906 17-27-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10499, current rewards: 88.81882, mean: 0.09252
[32m[0906 17-27-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10495, current rewards: 94.05739, mean: 0.09313
[32m[0906 17-27-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10479, current rewards: 99.62025, mean: 0.09398
[32m[0906 17-27-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10464, current rewards: 105.18004, mean: 0.09476
[32m[0906 17-27-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10450, current rewards: 110.73920, mean: 0.09546
[32m[0906 17-28-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10439, current rewards: 116.30170, mean: 0.09612
[32m[0906 17-28-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10425, current rewards: 121.86285, mean: 0.09672
[32m[0906 17-28-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10413, current rewards: 127.42315, mean: 0.09727
[32m[0906 17-28-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10402, current rewards: 132.98574, mean: 0.09778
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10393, current rewards: 132.79616, mean: 0.09418
[32m[0906 17-28-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10396, current rewards: 138.31220, mean: 0.09473
[32m[0906 17-28-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10401, current rewards: 143.77227, mean: 0.09521
[32m[0906 17-28-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10404, current rewards: 149.23600, mean: 0.09566
[32m[0906 17-28-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10416, current rewards: 154.70146, mean: 0.09609
[32m[0906 17-28-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10430, current rewards: 160.16647, mean: 0.09649
[32m[0906 17-28-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10440, current rewards: 165.63043, mean: 0.09686
[32m[0906 17-29-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10450, current rewards: 171.09098, mean: 0.09721
[32m[0906 17-29-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10460, current rewards: 166.42633, mean: 0.09195
[32m[0906 17-29-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10470, current rewards: 172.01149, mean: 0.09248
[32m[0906 17-29-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10478, current rewards: 177.35524, mean: 0.09286
[32m[0906 17-29-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10486, current rewards: 182.69732, mean: 0.09321
[32m[0906 17-29-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10502, current rewards: 188.03975, mean: 0.09355
[32m[0906 17-29-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10517, current rewards: 193.38108, mean: 0.09387
[32m[0906 17-29-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10533, current rewards: 193.53366, mean: 0.09172
[32m[0906 17-29-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10546, current rewards: 199.33851, mean: 0.09229
[32m[0906 17-29-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10560, current rewards: 205.11419, mean: 0.09281
[32m[0906 17-29-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10574, current rewards: 210.59602, mean: 0.09318
[32m[0906 17-30-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10586, current rewards: 216.30906, mean: 0.09364
[32m[0906 17-30-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10598, current rewards: 222.02192, mean: 0.09408
[32m[0906 17-30-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10611, current rewards: 215.31224, mean: 0.08934
[32m[0906 17-30-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10622, current rewards: 221.06044, mean: 0.08986
[32m[0906 17-30-22 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 17-30-22 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-30-22 @MBExp.py:227][0m Rewards obtained: [225.64560483080228], Lows: [16], Highs: [17], Total time: 11675.986456
[32m[0906 17-32-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-32-04 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 17-32-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10660, current rewards: -12.88697, mean: -1.28870
[32m[0906 17-32-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10765, current rewards: -15.40855, mean: -0.25681
[32m[0906 17-32-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10790, current rewards: -9.84144, mean: -0.08947
[32m[0906 17-32-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10783, current rewards: -4.46377, mean: -0.02790
[32m[0906 17-32-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10760, current rewards: 1.15984, mean: 0.00552
[32m[0906 17-32-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10758, current rewards: 6.77011, mean: 0.02604
[32m[0906 17-32-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10754, current rewards: 12.38171, mean: 0.03994
[32m[0906 17-32-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10752, current rewards: 17.99509, mean: 0.04999
[32m[0906 17-32-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10760, current rewards: 23.61278, mean: 0.05759
[32m[0906 17-32-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10754, current rewards: 29.22621, mean: 0.06354
[32m[0906 17-32-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10717, current rewards: 34.84116, mean: 0.06832
[32m[0906 17-33-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10692, current rewards: 30.28525, mean: 0.05408
[32m[0906 17-33-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10667, current rewards: 36.36020, mean: 0.05961
[32m[0906 17-33-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10646, current rewards: 42.08405, mean: 0.06376
[32m[0906 17-33-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10633, current rewards: 47.81072, mean: 0.06734
[32m[0906 17-33-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10614, current rewards: 47.93277, mean: 0.06307
[32m[0906 17-33-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10602, current rewards: 53.75809, mean: 0.06637
[32m[0906 17-33-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10605, current rewards: 59.58643, mean: 0.06929
[32m[0906 17-33-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10595, current rewards: 65.41698, mean: 0.07189
[32m[0906 17-33-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10587, current rewards: 71.24800, mean: 0.07422
[32m[0906 17-33-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10580, current rewards: 76.40106, mean: 0.07564
[32m[0906 17-33-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10557, current rewards: 82.16344, mean: 0.07751
[32m[0906 17-34-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10535, current rewards: 87.91633, mean: 0.07920
[32m[0906 17-34-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10518, current rewards: 93.67627, mean: 0.08076
[32m[0906 17-34-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10501, current rewards: 93.86202, mean: 0.07757
[32m[0906 17-34-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10485, current rewards: 99.05283, mean: 0.07861
[32m[0906 17-34-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10472, current rewards: 103.26940, mean: 0.07883
[32m[0906 17-34-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10458, current rewards: 107.49060, mean: 0.07904
[32m[0906 17-34-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10444, current rewards: 111.90237, mean: 0.07936
[32m[0906 17-34-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10442, current rewards: 116.31084, mean: 0.07966
[32m[0906 17-34-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10441, current rewards: 120.71650, mean: 0.07994
[32m[0906 17-34-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10440, current rewards: 125.12058, mean: 0.08021
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10440, current rewards: 129.52603, mean: 0.08045
[32m[0906 17-34-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10441, current rewards: 133.93493, mean: 0.08068
[32m[0906 17-35-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10441, current rewards: 138.34188, mean: 0.08090
[32m[0906 17-35-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10443, current rewards: 142.74846, mean: 0.08111
[32m[0906 17-35-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10443, current rewards: 134.96803, mean: 0.07457
[32m[0906 17-35-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10447, current rewards: 140.77010, mean: 0.07568
[32m[0906 17-35-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10457, current rewards: 146.56067, mean: 0.07673
[32m[0906 17-35-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10466, current rewards: 152.34885, mean: 0.07773
[32m[0906 17-35-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10479, current rewards: 158.14043, mean: 0.07868
[32m[0906 17-35-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10497, current rewards: 163.93255, mean: 0.07958
[32m[0906 17-35-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10512, current rewards: 169.71888, mean: 0.08044
[32m[0906 17-35-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10527, current rewards: 175.50985, mean: 0.08125
[32m[0906 17-35-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10543, current rewards: 181.35471, mean: 0.08206
[32m[0906 17-36-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10557, current rewards: 180.36075, mean: 0.07981
[32m[0906 17-36-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10570, current rewards: 186.12915, mean: 0.08058
[32m[0906 17-36-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10583, current rewards: 191.90094, mean: 0.08131
[32m[0906 17-36-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10595, current rewards: 197.67079, mean: 0.08202
[32m[0906 17-36-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10606, current rewards: 198.98133, mean: 0.08089
[32m[0906 17-36-30 @Agent.py:117][0m Average action selection time: 0.1062
[32m[0906 17-36-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-36-30 @MBExp.py:227][0m Rewards obtained: [201.6710960403655], Lows: [20], Highs: [27], Total time: 11942.14408
[32m[0906 17-38-14 @MBExp.py:144][0m ####################################################################
[32m[0906 17-38-14 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 17-38-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10749, current rewards: -4.32344, mean: -0.43234
[32m[0906 17-38-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10784, current rewards: 1.09787, mean: 0.01830
[32m[0906 17-38-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10750, current rewards: 6.50712, mean: 0.05916
[32m[0906 17-38-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10742, current rewards: 11.32776, mean: 0.07080
[32m[0906 17-38-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10751, current rewards: 16.63220, mean: 0.07920
[32m[0906 17-38-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10733, current rewards: 22.09323, mean: 0.08497
[32m[0906 17-38-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10729, current rewards: 27.55415, mean: 0.08888
[32m[0906 17-38-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10732, current rewards: 33.01409, mean: 0.09171
[32m[0906 17-38-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10730, current rewards: 38.47686, mean: 0.09385
[32m[0906 17-39-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10729, current rewards: 43.93383, mean: 0.09551
[32m[0906 17-39-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10697, current rewards: 49.39643, mean: 0.09686
[32m[0906 17-39-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10665, current rewards: 54.85609, mean: 0.09796
[32m[0906 17-39-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10639, current rewards: 60.67704, mean: 0.09947
[32m[0906 17-39-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10624, current rewards: 55.56906, mean: 0.08420
[32m[0906 17-39-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10606, current rewards: 61.02041, mean: 0.08594
[32m[0906 17-39-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10592, current rewards: 66.47103, mean: 0.08746
[32m[0906 17-39-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10582, current rewards: 71.92425, mean: 0.08880
[32m[0906 17-39-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10582, current rewards: 77.37611, mean: 0.08997
[32m[0906 17-39-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10572, current rewards: 82.82921, mean: 0.09102
[32m[0906 17-39-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10565, current rewards: 88.28018, mean: 0.09196
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10557, current rewards: 88.72997, mean: 0.08785
[32m[0906 17-40-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10533, current rewards: 94.19624, mean: 0.08886
[32m[0906 17-40-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10515, current rewards: 99.66788, mean: 0.08979
[32m[0906 17-40-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10497, current rewards: 105.12997, mean: 0.09063
[32m[0906 17-40-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10481, current rewards: 110.59502, mean: 0.09140
[32m[0906 17-40-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10468, current rewards: 116.06159, mean: 0.09211
[32m[0906 17-40-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10454, current rewards: 121.52785, mean: 0.09277
[32m[0906 17-40-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10439, current rewards: 126.99318, mean: 0.09338
[32m[0906 17-40-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10427, current rewards: 131.94461, mean: 0.09358
[32m[0906 17-40-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10419, current rewards: 137.44357, mean: 0.09414
[32m[0906 17-40-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10419, current rewards: 142.91214, mean: 0.09464
[32m[0906 17-40-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10419, current rewards: 148.38183, mean: 0.09512
[32m[0906 17-41-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10419, current rewards: 153.85190, mean: 0.09556
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10419, current rewards: 159.32444, mean: 0.09598
[32m[0906 17-41-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10418, current rewards: 150.83948, mean: 0.08821
[32m[0906 17-41-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10419, current rewards: 157.13185, mean: 0.08928
[32m[0906 17-41-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10419, current rewards: 163.44499, mean: 0.09030
[32m[0906 17-41-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10420, current rewards: 170.81641, mean: 0.09184
[32m[0906 17-41-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10430, current rewards: 177.41141, mean: 0.09289
[32m[0906 17-41-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10438, current rewards: 184.00530, mean: 0.09388
[32m[0906 17-41-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10446, current rewards: 190.60446, mean: 0.09483
[32m[0906 17-41-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10465, current rewards: 197.20599, mean: 0.09573
[32m[0906 17-41-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10481, current rewards: 203.80525, mean: 0.09659
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10497, current rewards: 209.16819, mean: 0.09684
[32m[0906 17-42-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10511, current rewards: 214.53434, mean: 0.09707
[32m[0906 17-42-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10526, current rewards: 219.88257, mean: 0.09729
[32m[0906 17-42-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10541, current rewards: 225.25919, mean: 0.09751
[32m[0906 17-42-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10554, current rewards: 230.62787, mean: 0.09772
[32m[0906 17-42-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10566, current rewards: 235.99611, mean: 0.09792
[32m[0906 17-42-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10580, current rewards: 209.74612, mean: 0.08526
[32m[0906 17-42-40 @Agent.py:117][0m Average action selection time: 0.1059
[32m[0906 17-42-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-42-40 @MBExp.py:227][0m Rewards obtained: [169.1116271425917], Lows: [50], Highs: [15], Total time: 12207.67205
[32m[0906 17-44-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-44-26 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 17-44-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10677, current rewards: -7.89377, mean: -0.78938
[32m[0906 17-44-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10742, current rewards: -1.84281, mean: -0.03071
[32m[0906 17-44-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10756, current rewards: 3.88735, mean: 0.03534
[32m[0906 17-44-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10773, current rewards: 10.01070, mean: 0.06257
[32m[0906 17-44-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10758, current rewards: 15.69308, mean: 0.07473
[32m[0906 17-44-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10751, current rewards: 21.37421, mean: 0.08221
[32m[0906 17-45-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10767, current rewards: 27.05859, mean: 0.08729
[32m[0906 17-45-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10768, current rewards: 32.74351, mean: 0.09095
[32m[0906 17-45-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10763, current rewards: 38.42374, mean: 0.09372
[32m[0906 17-45-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10766, current rewards: 44.10516, mean: 0.09588
[32m[0906 17-45-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10729, current rewards: 49.78722, mean: 0.09762
[32m[0906 17-45-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10701, current rewards: 56.05302, mean: 0.10009
[32m[0906 17-45-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10682, current rewards: 61.69712, mean: 0.10114
[32m[0906 17-45-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10668, current rewards: 67.33364, mean: 0.10202
[32m[0906 17-45-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10651, current rewards: 72.97012, mean: 0.10277
[32m[0906 17-45-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10643, current rewards: 72.84798, mean: 0.09585
[32m[0906 17-45-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10630, current rewards: 78.00497, mean: 0.09630
[32m[0906 17-45-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10634, current rewards: 83.16844, mean: 0.09671
[32m[0906 17-46-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10629, current rewards: 88.33037, mean: 0.09707
[32m[0906 17-46-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10623, current rewards: 93.86197, mean: 0.09777
[32m[0906 17-46-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10617, current rewards: 99.46526, mean: 0.09848
[32m[0906 17-46-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10599, current rewards: 100.00764, mean: 0.09435
[32m[0906 17-46-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10580, current rewards: 107.51076, mean: 0.09686
[32m[0906 17-46-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10563, current rewards: 115.01210, mean: 0.09915
[32m[0906 17-46-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10546, current rewards: 111.76625, mean: 0.09237
[32m[0906 17-46-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10530, current rewards: 118.31922, mean: 0.09390
[32m[0906 17-46-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10513, current rewards: 124.08281, mean: 0.09472
[32m[0906 17-46-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10502, current rewards: 129.84846, mean: 0.09548
[32m[0906 17-46-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10490, current rewards: 135.65485, mean: 0.09621
[32m[0906 17-47-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10478, current rewards: 141.41961, mean: 0.09686
[32m[0906 17-47-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10476, current rewards: 141.63282, mean: 0.09380
[32m[0906 17-47-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10475, current rewards: 147.25233, mean: 0.09439
[32m[0906 17-47-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10475, current rewards: 152.87326, mean: 0.09495
[32m[0906 17-47-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10477, current rewards: 158.49138, mean: 0.09548
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10475, current rewards: 164.10598, mean: 0.09597
[32m[0906 17-47-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10477, current rewards: 169.72495, mean: 0.09643
[32m[0906 17-47-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10492, current rewards: 162.33359, mean: 0.08969
[32m[0906 17-47-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10494, current rewards: 150.10986, mean: 0.08070
[32m[0906 17-47-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10505, current rewards: 139.90734, mean: 0.07325
[32m[0906 17-47-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10522, current rewards: 129.76324, mean: 0.06621
[32m[0906 17-47-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10530, current rewards: 117.44984, mean: 0.05843
[32m[0906 17-48-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10551, current rewards: 107.28402, mean: 0.05208
[32m[0906 17-48-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10573, current rewards: 97.14349, mean: 0.04604
[32m[0906 17-48-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10595, current rewards: 84.85382, mean: 0.03928
[32m[0906 17-48-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10618, current rewards: 75.77546, mean: 0.03429
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10649, current rewards: 65.69305, mean: 0.02907
[32m[0906 17-48-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10674, current rewards: 53.51249, mean: 0.02317
[32m[0906 17-48-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10703, current rewards: 41.50878, mean: 0.01759
[32m[0906 17-48-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10712, current rewards: 49.29726, mean: 0.02046
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10722, current rewards: 56.90251, mean: 0.02313
[32m[0906 17-48-55 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 17-48-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-48-55 @MBExp.py:227][0m Rewards obtained: [63.00203534040452], Lows: [103], Highs: [27], Total time: 12476.709159
[32m[0906 17-50-44 @MBExp.py:144][0m ####################################################################
[32m[0906 17-50-44 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 17-50-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10708, current rewards: -14.00000, mean: -1.40000
[32m[0906 17-50-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10838, current rewards: -9.13839, mean: -0.15231
[32m[0906 17-50-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10797, current rewards: -1.36914, mean: -0.01245
[32m[0906 17-51-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10786, current rewards: 7.19062, mean: 0.04494
[32m[0906 17-51-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10787, current rewards: 14.41811, mean: 0.06866
[32m[0906 17-51-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10778, current rewards: 21.67132, mean: 0.08335
[32m[0906 17-51-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10783, current rewards: 17.89144, mean: 0.05771
[32m[0906 17-51-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10786, current rewards: 23.38278, mean: 0.06495
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10784, current rewards: 28.87139, mean: 0.07042
[32m[0906 17-51-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10770, current rewards: 34.35754, mean: 0.07469
[32m[0906 17-51-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10733, current rewards: 39.84551, mean: 0.07813
[32m[0906 17-51-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10706, current rewards: 45.02628, mean: 0.08040
[32m[0906 17-51-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10684, current rewards: 50.50104, mean: 0.08279
[32m[0906 17-51-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10665, current rewards: 55.97694, mean: 0.08481
[32m[0906 17-52-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10646, current rewards: 61.45032, mean: 0.08655
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10635, current rewards: 66.92533, mean: 0.08806
[32m[0906 17-52-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10625, current rewards: 72.39722, mean: 0.08938
[32m[0906 17-52-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10621, current rewards: 77.86870, mean: 0.09054
[32m[0906 17-52-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10613, current rewards: 71.16235, mean: 0.07820
[32m[0906 17-52-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10606, current rewards: 78.51802, mean: 0.08179
[32m[0906 17-52-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10597, current rewards: 85.63875, mean: 0.08479
[32m[0906 17-52-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10576, current rewards: 92.75439, mean: 0.08750
[32m[0906 17-52-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10558, current rewards: 99.88370, mean: 0.08999
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10539, current rewards: 107.00308, mean: 0.09224
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10521, current rewards: 114.11590, mean: 0.09431
[32m[0906 17-52-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10508, current rewards: 121.23193, mean: 0.09622
[32m[0906 17-53-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10493, current rewards: 128.34816, mean: 0.09798
[32m[0906 17-53-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10479, current rewards: 136.32995, mean: 0.10024
[32m[0906 17-53-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10469, current rewards: 143.45087, mean: 0.10174
[32m[0906 17-53-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10457, current rewards: 150.57324, mean: 0.10313
[32m[0906 17-53-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10452, current rewards: 143.49608, mean: 0.09503
[32m[0906 17-53-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10454, current rewards: 149.01423, mean: 0.09552
[32m[0906 17-53-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10454, current rewards: 154.53333, mean: 0.09598
[32m[0906 17-53-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10453, current rewards: 160.05528, mean: 0.09642
[32m[0906 17-53-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10455, current rewards: 165.57725, mean: 0.09683
[32m[0906 17-53-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10456, current rewards: 170.74095, mean: 0.09701
[32m[0906 17-53-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10454, current rewards: 176.28921, mean: 0.09740
[32m[0906 17-53-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10458, current rewards: 181.82746, mean: 0.09776
[32m[0906 17-54-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10463, current rewards: 187.36314, mean: 0.09810
[32m[0906 17-54-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10473, current rewards: 192.90360, mean: 0.09842
[32m[0906 17-54-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10483, current rewards: 198.43743, mean: 0.09873
[32m[0906 17-54-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10494, current rewards: 195.86811, mean: 0.09508
[32m[0906 17-54-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10510, current rewards: 201.44352, mean: 0.09547
[32m[0906 17-54-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10527, current rewards: 207.17839, mean: 0.09592
[32m[0906 17-54-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10541, current rewards: 213.01744, mean: 0.09639
[32m[0906 17-54-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10556, current rewards: 218.64395, mean: 0.09675
[32m[0906 17-54-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10571, current rewards: 224.26442, mean: 0.09708
[32m[0906 17-54-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10583, current rewards: 229.89396, mean: 0.09741
[32m[0906 17-55-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10595, current rewards: 235.51777, mean: 0.09773
[32m[0906 17-55-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10607, current rewards: 241.13890, mean: 0.09802
[32m[0906 17-55-10 @Agent.py:117][0m Average action selection time: 0.1062
[32m[0906 17-55-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-55-10 @MBExp.py:227][0m Rewards obtained: [235.0409778475288], Lows: [28], Highs: [12], Total time: 12742.879947
[32m[0906 17-57-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-57-01 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 17-57-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10733, current rewards: -5.63826, mean: -0.56383
[32m[0906 17-57-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10831, current rewards: -0.21647, mean: -0.00361
[32m[0906 17-57-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10808, current rewards: 5.95613, mean: 0.05415
[32m[0906 17-57-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10795, current rewards: 11.33700, mean: 0.07086
[32m[0906 17-57-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10806, current rewards: 16.71846, mean: 0.07961
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10807, current rewards: 22.10362, mean: 0.08501
[32m[0906 17-57-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10834, current rewards: 27.48792, mean: 0.08867
[32m[0906 17-57-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10834, current rewards: 32.87446, mean: 0.09132
[32m[0906 17-57-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10817, current rewards: 38.25669, mean: 0.09331
[32m[0906 17-57-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10792, current rewards: 33.80240, mean: 0.07348
[32m[0906 17-57-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10755, current rewards: 38.87015, mean: 0.07622
[32m[0906 17-58-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10724, current rewards: 44.33530, mean: 0.07917
[32m[0906 17-58-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10694, current rewards: 49.83723, mean: 0.08170
[32m[0906 17-58-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10671, current rewards: 55.33476, mean: 0.08384
[32m[0906 17-58-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10648, current rewards: 60.83593, mean: 0.08568
[32m[0906 17-58-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10631, current rewards: 66.33653, mean: 0.08728
[32m[0906 17-58-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10623, current rewards: 71.83492, mean: 0.08869
[32m[0906 17-58-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10619, current rewards: 71.73198, mean: 0.08341
[32m[0906 17-58-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10606, current rewards: 77.29974, mean: 0.08494
[32m[0906 17-58-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10598, current rewards: 82.60970, mean: 0.08605
[32m[0906 17-58-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10587, current rewards: 88.16486, mean: 0.08729
[32m[0906 17-58-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10562, current rewards: 93.71435, mean: 0.08841
[32m[0906 17-58-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10542, current rewards: 99.26807, mean: 0.08943
[32m[0906 17-59-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10523, current rewards: 104.82498, mean: 0.09037
[32m[0906 17-59-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10506, current rewards: 110.37313, mean: 0.09122
[32m[0906 17-59-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10488, current rewards: 115.92604, mean: 0.09200
[32m[0906 17-59-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10474, current rewards: 121.49202, mean: 0.09274
[32m[0906 17-59-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10460, current rewards: 127.13423, mean: 0.09348
[32m[0906 17-59-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10447, current rewards: 132.69032, mean: 0.09411
[32m[0906 17-59-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10436, current rewards: 138.24874, mean: 0.09469
[32m[0906 17-59-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10423, current rewards: 143.80348, mean: 0.09523
[32m[0906 17-59-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10424, current rewards: 149.35990, mean: 0.09574
[32m[0906 17-59-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10426, current rewards: 141.81296, mean: 0.08808
[32m[0906 17-59-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10425, current rewards: 147.03870, mean: 0.08858
[32m[0906 18-00-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10426, current rewards: 152.26284, mean: 0.08904
[32m[0906 18-00-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10426, current rewards: 158.83980, mean: 0.09025
[32m[0906 18-00-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10425, current rewards: 165.44803, mean: 0.09141
[32m[0906 18-00-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10424, current rewards: 172.05627, mean: 0.09250
[32m[0906 18-00-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10425, current rewards: 178.66450, mean: 0.09354
[32m[0906 18-00-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10434, current rewards: 175.08325, mean: 0.08933
[32m[0906 18-00-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10441, current rewards: 125.08325, mean: 0.06223
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10450, current rewards: 75.08325, mean: 0.03645
[32m[0906 18-00-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10463, current rewards: 25.08325, mean: 0.01189
[32m[0906 18-00-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10479, current rewards: -24.91675, mean: -0.01154
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10495, current rewards: -74.91675, mean: -0.03390
[32m[0906 18-00-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10509, current rewards: -124.91675, mean: -0.05527
[32m[0906 18-01-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10521, current rewards: -174.91675, mean: -0.07572
[32m[0906 18-01-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10534, current rewards: -224.91675, mean: -0.09530
[32m[0906 18-01-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10546, current rewards: -274.91675, mean: -0.11407
[32m[0906 18-01-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10559, current rewards: -324.91675, mean: -0.13208
[32m[0906 18-01-26 @Agent.py:117][0m Average action selection time: 0.1057
[32m[0906 18-01-26 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-01-26 @MBExp.py:227][0m Rewards obtained: [-364.91674988695655], Lows: [11], Highs: [560], Total time: 13007.859496
[32m[0906 18-03-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-03-19 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 18-03-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10687, current rewards: -5.48800, mean: -0.54880
[32m[0906 18-03-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10756, current rewards: -0.00340, mean: -0.00006
[32m[0906 18-03-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10784, current rewards: 6.21946, mean: 0.05654
[32m[0906 18-03-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10773, current rewards: 11.67356, mean: 0.07296
[32m[0906 18-03-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10772, current rewards: 17.12706, mean: 0.08156
[32m[0906 18-03-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10772, current rewards: 22.58473, mean: 0.08686
[32m[0906 18-03-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10765, current rewards: 28.04449, mean: 0.09047
[32m[0906 18-03-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10777, current rewards: 33.58088, mean: 0.09328
[32m[0906 18-04-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10783, current rewards: 39.11804, mean: 0.09541
[32m[0906 18-04-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10773, current rewards: 44.64289, mean: 0.09705
[32m[0906 18-04-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10737, current rewards: 49.94761, mean: 0.09794
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10714, current rewards: 55.21673, mean: 0.09860
[32m[0906 18-04-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10687, current rewards: 56.58324, mean: 0.09276
[32m[0906 18-04-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10669, current rewards: 63.04707, mean: 0.09553
[32m[0906 18-04-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10657, current rewards: 69.49507, mean: 0.09788
[32m[0906 18-04-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10646, current rewards: 75.93224, mean: 0.09991
[32m[0906 18-04-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10633, current rewards: 82.40558, mean: 0.10174
[32m[0906 18-04-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10635, current rewards: 88.92114, mean: 0.10340
[32m[0906 18-04-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10653, current rewards: 83.00516, mean: 0.09121
[32m[0906 18-05-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10642, current rewards: 88.64051, mean: 0.09233
[32m[0906 18-05-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10636, current rewards: 94.26634, mean: 0.09333
[32m[0906 18-05-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10613, current rewards: 99.89260, mean: 0.09424
[32m[0906 18-05-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10591, current rewards: 99.83755, mean: 0.08994
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10573, current rewards: 105.41915, mean: 0.09088
[32m[0906 18-05-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10555, current rewards: 111.00150, mean: 0.09174
[32m[0906 18-05-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10539, current rewards: 116.58381, mean: 0.09253
[32m[0906 18-05-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10526, current rewards: 121.95520, mean: 0.09310
[32m[0906 18-05-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10510, current rewards: 127.06403, mean: 0.09343
[32m[0906 18-05-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10495, current rewards: 132.70977, mean: 0.09412
[32m[0906 18-05-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10483, current rewards: 138.35867, mean: 0.09477
[32m[0906 18-05-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10469, current rewards: 141.89426, mean: 0.09397
[32m[0906 18-06-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10462, current rewards: 136.85298, mean: 0.08773
[32m[0906 18-06-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10463, current rewards: 142.67663, mean: 0.08862
[32m[0906 18-06-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10462, current rewards: 148.49661, mean: 0.08946
[32m[0906 18-06-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10461, current rewards: 154.31515, mean: 0.09024
[32m[0906 18-06-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10461, current rewards: 161.31461, mean: 0.09166
[32m[0906 18-06-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10462, current rewards: 168.48095, mean: 0.09308
[32m[0906 18-06-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10461, current rewards: 175.57750, mean: 0.09440
[32m[0906 18-06-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10461, current rewards: 182.67406, mean: 0.09564
[32m[0906 18-06-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10469, current rewards: 189.77061, mean: 0.09682
[32m[0906 18-06-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10477, current rewards: 196.86716, mean: 0.09794
[32m[0906 18-06-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10486, current rewards: 203.96371, mean: 0.09901
[32m[0906 18-07-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10496, current rewards: 184.79584, mean: 0.08758
[32m[0906 18-07-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10512, current rewards: 134.79584, mean: 0.06241
[32m[0906 18-07-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10528, current rewards: 84.79584, mean: 0.03837
[32m[0906 18-07-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10540, current rewards: 34.79584, mean: 0.01540
[32m[0906 18-07-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10554, current rewards: -15.20416, mean: -0.00658
[32m[0906 18-07-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10568, current rewards: -65.20416, mean: -0.02763
[32m[0906 18-07-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10582, current rewards: -115.20416, mean: -0.04780
[32m[0906 18-07-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10595, current rewards: -165.20416, mean: -0.06716
[32m[0906 18-07-45 @Agent.py:117][0m Average action selection time: 0.1061
[32m[0906 18-07-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-07-45 @MBExp.py:227][0m Rewards obtained: [-205.20415561333732], Lows: [15], Highs: [424], Total time: 13273.766185999999
[32m[0906 18-09-41 @MBExp.py:144][0m ####################################################################
[32m[0906 18-09-41 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 18-09-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10696, current rewards: -15.00000, mean: -1.50000
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10765, current rewards: -11.75908, mean: -0.19598
[32m[0906 18-09-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10795, current rewards: -6.72000, mean: -0.06109
[32m[0906 18-09-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10794, current rewards: -1.36455, mean: -0.00853
[32m[0906 18-10-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10784, current rewards: 3.98450, mean: 0.01897
[32m[0906 18-10-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10796, current rewards: 9.34744, mean: 0.03595
[32m[0906 18-10-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10794, current rewards: 14.70439, mean: 0.04743
[32m[0906 18-10-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10791, current rewards: 20.05458, mean: 0.05571
[32m[0906 18-10-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10797, current rewards: 25.40700, mean: 0.06197
[32m[0906 18-10-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10786, current rewards: 30.76091, mean: 0.06687
[32m[0906 18-10-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10751, current rewards: 36.11269, mean: 0.07081
[32m[0906 18-10-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10724, current rewards: 41.47276, mean: 0.07406
[32m[0906 18-10-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10699, current rewards: 46.82997, mean: 0.07677
[32m[0906 18-10-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10677, current rewards: 54.94996, mean: 0.08326
[32m[0906 18-10-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10662, current rewards: 60.29362, mean: 0.08492
[32m[0906 18-11-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10646, current rewards: 65.60195, mean: 0.08632
[32m[0906 18-11-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10631, current rewards: 70.92428, mean: 0.08756
[32m[0906 18-11-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10636, current rewards: 76.24086, mean: 0.08865
[32m[0906 18-11-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10625, current rewards: 81.44107, mean: 0.08950
[32m[0906 18-11-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10617, current rewards: 86.68039, mean: 0.09029
[32m[0906 18-11-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10611, current rewards: 92.00733, mean: 0.09110
[32m[0906 18-11-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10588, current rewards: 97.33439, mean: 0.09182
[32m[0906 18-11-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10567, current rewards: 102.66002, mean: 0.09249
[32m[0906 18-11-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10548, current rewards: 107.98965, mean: 0.09309
[32m[0906 18-11-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10531, current rewards: 113.31666, mean: 0.09365
[32m[0906 18-11-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10514, current rewards: 118.64604, mean: 0.09416
[32m[0906 18-11-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10500, current rewards: 123.97906, mean: 0.09464
[32m[0906 18-12-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10486, current rewards: 130.16587, mean: 0.09571
[32m[0906 18-12-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10473, current rewards: 135.48035, mean: 0.09609
[32m[0906 18-12-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10462, current rewards: 128.19559, mean: 0.08781
[32m[0906 18-12-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10452, current rewards: 133.72917, mean: 0.08856
[32m[0906 18-12-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10441, current rewards: 139.26238, mean: 0.08927
[32m[0906 18-12-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10443, current rewards: 144.79440, mean: 0.08993
[32m[0906 18-12-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10443, current rewards: 150.32697, mean: 0.09056
[32m[0906 18-12-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10443, current rewards: 155.85826, mean: 0.09115
[32m[0906 18-12-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10444, current rewards: 161.36138, mean: 0.09168
[32m[0906 18-12-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10446, current rewards: 154.22913, mean: 0.08521
[32m[0906 18-12-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10447, current rewards: 159.47827, mean: 0.08574
[32m[0906 18-13-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10448, current rewards: 164.84250, mean: 0.08630
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10450, current rewards: 170.20658, mean: 0.08684
[32m[0906 18-13-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10459, current rewards: 175.57072, mean: 0.08735
[32m[0906 18-13-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10468, current rewards: 180.93498, mean: 0.08783
[32m[0906 18-13-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10477, current rewards: 186.29953, mean: 0.08829
[32m[0906 18-13-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10491, current rewards: 191.47441, mean: 0.08865
[32m[0906 18-13-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10507, current rewards: 196.78316, mean: 0.08904
[32m[0906 18-13-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10522, current rewards: 202.09383, mean: 0.08942
[32m[0906 18-13-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10536, current rewards: 200.81030, mean: 0.08693
[32m[0906 18-13-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10551, current rewards: 206.27832, mean: 0.08741
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10565, current rewards: 211.74259, mean: 0.08786
[32m[0906 18-14-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10577, current rewards: 217.20826, mean: 0.08830
[32m[0906 18-14-06 @Agent.py:117][0m Average action selection time: 0.1059
[32m[0906 18-14-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-14-06 @MBExp.py:227][0m Rewards obtained: [221.57628534838412], Lows: [18], Highs: [11], Total time: 13539.228201999998
[32m[0906 18-16-05 @MBExp.py:144][0m ####################################################################
[32m[0906 18-16-05 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 18-16-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10763, current rewards: -5.48016, mean: -0.54802
[32m[0906 18-16-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10861, current rewards: -0.02275, mean: -0.00038
[32m[0906 18-16-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10836, current rewards: 4.67331, mean: 0.04248
[32m[0906 18-16-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10820, current rewards: 9.95081, mean: 0.06219
[32m[0906 18-16-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10824, current rewards: 15.23200, mean: 0.07253
[32m[0906 18-16-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10815, current rewards: 7.53755, mean: 0.02899
[32m[0906 18-16-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10804, current rewards: 12.73633, mean: 0.04108
[32m[0906 18-16-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10807, current rewards: 17.93495, mean: 0.04982
[32m[0906 18-16-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10807, current rewards: 23.13215, mean: 0.05642
[32m[0906 18-16-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10808, current rewards: 28.33391, mean: 0.06160
[32m[0906 18-17-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10780, current rewards: 34.39428, mean: 0.06744
[32m[0906 18-17-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10751, current rewards: 23.21565, mean: 0.04146
[32m[0906 18-17-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10730, current rewards: -26.78435, mean: -0.04391
[32m[0906 18-17-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10712, current rewards: -76.78435, mean: -0.11634
[32m[0906 18-17-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10692, current rewards: -126.78435, mean: -0.17857
[32m[0906 18-17-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10676, current rewards: -176.78435, mean: -0.23261
[32m[0906 18-17-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10672, current rewards: -226.78435, mean: -0.27998
[32m[0906 18-17-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10676, current rewards: -276.78435, mean: -0.32184
[32m[0906 18-17-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10662, current rewards: -326.78435, mean: -0.35910
[32m[0906 18-17-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10652, current rewards: -376.78435, mean: -0.39248
[32m[0906 18-17-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10640, current rewards: -426.78435, mean: -0.42256
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10615, current rewards: -460.00109, mean: -0.43396
[32m[0906 18-18-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10593, current rewards: -457.55339, mean: -0.41221
[32m[0906 18-18-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10575, current rewards: -455.10568, mean: -0.39233
[32m[0906 18-18-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10555, current rewards: -452.65798, mean: -0.37410
[32m[0906 18-18-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10538, current rewards: -450.21028, mean: -0.35731
[32m[0906 18-18-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10521, current rewards: -447.76258, mean: -0.34180
[32m[0906 18-18-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10506, current rewards: -445.31487, mean: -0.32744
[32m[0906 18-18-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10491, current rewards: -449.16090, mean: -0.31855
[32m[0906 18-18-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10479, current rewards: -499.16090, mean: -0.34189
[32m[0906 18-18-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10466, current rewards: -549.16090, mean: -0.36368
[32m[0906 18-18-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10453, current rewards: -599.16090, mean: -0.38408
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10449, current rewards: -649.16090, mean: -0.40321
[32m[0906 18-18-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10451, current rewards: -699.16090, mean: -0.42118
[32m[0906 18-19-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10451, current rewards: -749.16090, mean: -0.43811
[32m[0906 18-19-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10451, current rewards: -799.16090, mean: -0.45407
[32m[0906 18-19-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10450, current rewards: -849.16090, mean: -0.46915
[32m[0906 18-19-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10450, current rewards: -899.16090, mean: -0.48342
[32m[0906 18-19-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10450, current rewards: -949.16090, mean: -0.49694
[32m[0906 18-19-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10449, current rewards: -999.16090, mean: -0.50978
[32m[0906 18-19-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10453, current rewards: -1049.16090, mean: -0.52197
[32m[0906 18-19-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10462, current rewards: -1099.16090, mean: -0.53357
[32m[0906 18-19-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10469, current rewards: -1149.16090, mean: -0.54463
[32m[0906 18-19-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10477, current rewards: -1199.16090, mean: -0.55517
[32m[0906 18-19-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10494, current rewards: -1249.16090, mean: -0.56523
[32m[0906 18-20-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10508, current rewards: -1299.16090, mean: -0.57485
[32m[0906 18-20-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10522, current rewards: -1349.16090, mean: -0.58405
[32m[0906 18-20-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10537, current rewards: -1399.16090, mean: -0.59286
[32m[0906 18-20-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10549, current rewards: -1449.16090, mean: -0.60131
[32m[0906 18-20-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10562, current rewards: -1499.16090, mean: -0.60941
[32m[0906 18-20-30 @Agent.py:117][0m Average action selection time: 0.1057
[32m[0906 18-20-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-20-30 @MBExp.py:227][0m Rewards obtained: [-1539.1608964644893], Lows: [6], Highs: [1601], Total time: 13804.304046999998
[32m[0906 18-22-30 @MBExp.py:144][0m ####################################################################
[32m[0906 18-22-30 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 18-22-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10792, current rewards: -12.18077, mean: -1.21808
[32m[0906 18-22-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10827, current rewards: -8.53593, mean: -0.14227
[32m[0906 18-22-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10778, current rewards: -3.14483, mean: -0.02859
[32m[0906 18-22-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10765, current rewards: 2.07495, mean: 0.01297
[32m[0906 18-22-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10767, current rewards: 7.29621, mean: 0.03474
[32m[0906 18-22-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10764, current rewards: 12.51803, mean: 0.04815
[32m[0906 18-23-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10769, current rewards: 15.63723, mean: 0.05044
[32m[0906 18-23-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10777, current rewards: 12.97566, mean: 0.03604
[32m[0906 18-23-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10770, current rewards: 18.44839, mean: 0.04500
[32m[0906 18-23-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10771, current rewards: 23.92479, mean: 0.05201
[32m[0906 18-23-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10751, current rewards: 29.42374, mean: 0.05769
[32m[0906 18-23-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10722, current rewards: 34.88455, mean: 0.06229
[32m[0906 18-23-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10699, current rewards: 29.94917, mean: 0.04910
[32m[0906 18-23-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10683, current rewards: 37.80871, mean: 0.05729
[32m[0906 18-23-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10665, current rewards: 45.66825, mean: 0.06432
[32m[0906 18-23-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10651, current rewards: 53.52779, mean: 0.07043
[32m[0906 18-23-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10640, current rewards: 61.38732, mean: 0.07579
[32m[0906 18-24-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10647, current rewards: 69.24686, mean: 0.08052
[32m[0906 18-24-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10637, current rewards: 73.63059, mean: 0.08091
[32m[0906 18-24-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10631, current rewards: 77.01326, mean: 0.08022
[32m[0906 18-24-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10625, current rewards: 37.68980, mean: 0.03732
[32m[0906 18-24-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10607, current rewards: -12.31020, mean: -0.01161
[32m[0906 18-24-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10588, current rewards: -62.31020, mean: -0.05614
[32m[0906 18-24-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10570, current rewards: -112.31020, mean: -0.09682
[32m[0906 18-24-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10553, current rewards: -162.31020, mean: -0.13414
[32m[0906 18-24-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10539, current rewards: -212.31020, mean: -0.16850
[32m[0906 18-24-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10524, current rewards: -262.31020, mean: -0.20024
[32m[0906 18-24-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10509, current rewards: -312.31020, mean: -0.22964
[32m[0906 18-24-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10497, current rewards: -362.31020, mean: -0.25696
[32m[0906 18-25-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10484, current rewards: -412.31020, mean: -0.28240
[32m[0906 18-25-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10471, current rewards: -462.31020, mean: -0.30617
[32m[0906 18-25-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10461, current rewards: -512.31020, mean: -0.32840
[32m[0906 18-25-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10450, current rewards: -562.31020, mean: -0.34926
[32m[0906 18-25-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10449, current rewards: -612.31020, mean: -0.36886
[32m[0906 18-25-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10450, current rewards: -662.31020, mean: -0.38732
[32m[0906 18-25-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10450, current rewards: -712.31020, mean: -0.40472
[32m[0906 18-25-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10450, current rewards: -762.31020, mean: -0.42117
[32m[0906 18-25-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10451, current rewards: -812.31020, mean: -0.43673
[32m[0906 18-25-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10450, current rewards: -862.31020, mean: -0.45147
[32m[0906 18-25-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10449, current rewards: -912.31020, mean: -0.46546
[32m[0906 18-26-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10450, current rewards: -962.31020, mean: -0.47876
[32m[0906 18-26-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10459, current rewards: -1012.31020, mean: -0.49141
[32m[0906 18-26-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10467, current rewards: -1062.31020, mean: -0.50346
[32m[0906 18-26-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10476, current rewards: -1112.31020, mean: -0.51496
[32m[0906 18-26-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10489, current rewards: -1162.31020, mean: -0.52593
[32m[0906 18-26-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10504, current rewards: -1212.31020, mean: -0.53642
[32m[0906 18-26-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10520, current rewards: -1262.31020, mean: -0.54645
[32m[0906 18-26-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10534, current rewards: -1312.31020, mean: -0.55606
[32m[0906 18-26-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10548, current rewards: -1362.31020, mean: -0.56527
[32m[0906 18-26-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10562, current rewards: -1412.31020, mean: -0.57411
[32m[0906 18-26-55 @Agent.py:117][0m Average action selection time: 0.1057
[32m[0906 18-26-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-26-55 @MBExp.py:227][0m Rewards obtained: [-1452.3102041795482], Lows: [16], Highs: [1535], Total time: 14069.373047999998
[32m[0906 18-28-58 @MBExp.py:144][0m ####################################################################
[32m[0906 18-28-58 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 18-28-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10717, current rewards: -6.57022, mean: -0.65702
[32m[0906 18-29-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10794, current rewards: -1.88339, mean: -0.03139
[32m[0906 18-29-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10808, current rewards: 2.65832, mean: 0.02417
[32m[0906 18-29-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10813, current rewards: 7.19725, mean: 0.04498
[32m[0906 18-29-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10814, current rewards: 11.74200, mean: 0.05591
[32m[0906 18-29-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10829, current rewards: 16.28583, mean: 0.06264
[32m[0906 18-29-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10818, current rewards: 20.82937, mean: 0.06719
[32m[0906 18-29-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10814, current rewards: 25.37206, mean: 0.07048
[32m[0906 18-29-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10818, current rewards: 29.91471, mean: 0.07296
[32m[0906 18-29-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10814, current rewards: 34.46090, mean: 0.07491
[32m[0906 18-29-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10793, current rewards: 38.84515, mean: 0.07617
[32m[0906 18-29-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10762, current rewards: 42.96845, mean: 0.07673
[32m[0906 18-30-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10736, current rewards: 47.08805, mean: 0.07719
[32m[0906 18-30-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10716, current rewards: 51.21060, mean: 0.07759
[32m[0906 18-30-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10697, current rewards: 55.33409, mean: 0.07794
[32m[0906 18-30-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10678, current rewards: 59.45992, mean: 0.07824
[32m[0906 18-30-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10660, current rewards: 63.58291, mean: 0.07850
[32m[0906 18-30-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10667, current rewards: 57.51648, mean: 0.06688
[32m[0906 18-30-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10654, current rewards: 61.82348, mean: 0.06794
[32m[0906 18-30-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10643, current rewards: 65.64176, mean: 0.06838
[32m[0906 18-30-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10638, current rewards: 69.46069, mean: 0.06877
[32m[0906 18-30-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10621, current rewards: 73.28071, mean: 0.06913
[32m[0906 18-30-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10598, current rewards: 77.09914, mean: 0.06946
[32m[0906 18-31-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10580, current rewards: 80.91892, mean: 0.06976
[32m[0906 18-31-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10560, current rewards: 84.73878, mean: 0.07003
[32m[0906 18-31-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10543, current rewards: 88.44393, mean: 0.07019
[32m[0906 18-31-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10527, current rewards: 92.13228, mean: 0.07033
[32m[0906 18-31-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10515, current rewards: 87.10697, mean: 0.06405
[32m[0906 18-31-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10500, current rewards: 92.98325, mean: 0.06595
[32m[0906 18-31-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10487, current rewards: 99.01265, mean: 0.06782
[32m[0906 18-31-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10477, current rewards: 104.91592, mean: 0.06948
[32m[0906 18-31-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10466, current rewards: 110.79557, mean: 0.07102
[32m[0906 18-31-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10456, current rewards: 116.82321, mean: 0.07256
[32m[0906 18-31-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10450, current rewards: 122.67509, mean: 0.07390
[32m[0906 18-31-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10452, current rewards: 128.18434, mean: 0.07496
[32m[0906 18-32-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10454, current rewards: 129.06501, mean: 0.07333
[32m[0906 18-32-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10458, current rewards: 134.25630, mean: 0.07417
[32m[0906 18-32-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10458, current rewards: 139.44576, mean: 0.07497
[32m[0906 18-32-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10459, current rewards: 144.63735, mean: 0.07573
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10461, current rewards: 149.82897, mean: 0.07644
[32m[0906 18-32-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10461, current rewards: 155.01860, mean: 0.07712
[32m[0906 18-32-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10464, current rewards: 160.20958, mean: 0.07777
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10475, current rewards: 165.96693, mean: 0.07866
[32m[0906 18-32-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10483, current rewards: 171.35633, mean: 0.07933
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10492, current rewards: 176.74355, mean: 0.07997
[32m[0906 18-32-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10509, current rewards: 182.13480, mean: 0.08059
[32m[0906 18-33-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10526, current rewards: 176.91595, mean: 0.07659
[32m[0906 18-33-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10541, current rewards: 182.03441, mean: 0.07713
[32m[0906 18-33-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10556, current rewards: 187.13515, mean: 0.07765
[32m[0906 18-33-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10570, current rewards: 192.23442, mean: 0.07814
[32m[0906 18-33-24 @Agent.py:117][0m Average action selection time: 0.1058
[32m[0906 18-33-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-33-24 @MBExp.py:227][0m Rewards obtained: [195.91017459673978], Lows: [16], Highs: [9], Total time: 14334.658694999998
[32m[0906 18-35-29 @MBExp.py:144][0m ####################################################################
[32m[0906 18-35-29 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 18-35-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10865, current rewards: -12.95086, mean: -1.29509
[32m[0906 18-35-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10853, current rewards: -112.95086, mean: -1.88251
[32m[0906 18-35-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10818, current rewards: -212.95086, mean: -1.93592
[32m[0906 18-35-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10801, current rewards: -312.95086, mean: -1.95594
[32m[0906 18-35-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10818, current rewards: -412.95086, mean: -1.96643
[32m[0906 18-35-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10812, current rewards: -512.95086, mean: -1.97289
[32m[0906 18-36-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10808, current rewards: -612.95086, mean: -1.97726
[32m[0906 18-36-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10818, current rewards: -712.95086, mean: -1.98042
[32m[0906 18-36-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10820, current rewards: -812.95086, mean: -1.98281
[32m[0906 18-36-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10816, current rewards: -912.95086, mean: -1.98468
[32m[0906 18-36-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10801, current rewards: -1012.95086, mean: -1.98618
[32m[0906 18-36-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10768, current rewards: -1112.95086, mean: -1.98741
[32m[0906 18-36-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10742, current rewards: -1212.95086, mean: -1.98844
[32m[0906 18-36-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10722, current rewards: -1312.95086, mean: -1.98932
[32m[0906 18-36-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10706, current rewards: -1412.95086, mean: -1.99007
[32m[0906 18-36-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10690, current rewards: -1512.95086, mean: -1.99072
[32m[0906 18-36-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10677, current rewards: -1612.95086, mean: -1.99130
[32m[0906 18-37-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10682, current rewards: -1712.95086, mean: -1.99180
[32m[0906 18-37-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10672, current rewards: -1812.95086, mean: -1.99225
[32m[0906 18-37-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10664, current rewards: -1912.95086, mean: -1.99266
[32m[0906 18-37-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10654, current rewards: -2012.95086, mean: -1.99302
[32m[0906 18-37-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10639, current rewards: -2112.95086, mean: -1.99335
[32m[0906 18-37-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10618, current rewards: -2212.95086, mean: -1.99365
[32m[0906 18-37-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10602, current rewards: -2312.95086, mean: -1.99392
[32m[0906 18-37-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10585, current rewards: -2412.95086, mean: -1.99417
[32m[0906 18-37-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10569, current rewards: -2512.95086, mean: -1.99441
[32m[0906 18-37-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10552, current rewards: -2612.95086, mean: -1.99462
[32m[0906 18-37-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10537, current rewards: -2712.95086, mean: -1.99482
[32m[0906 18-37-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10527, current rewards: -2812.95086, mean: -1.99500
[32m[0906 18-38-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10513, current rewards: -2912.95086, mean: -1.99517
[32m[0906 18-38-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10499, current rewards: -3012.95086, mean: -1.99533
[32m[0906 18-38-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10487, current rewards: -3112.95086, mean: -1.99548
[32m[0906 18-38-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10476, current rewards: -3212.95086, mean: -1.99562
[32m[0906 18-38-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10467, current rewards: -3312.95086, mean: -1.99575
[32m[0906 18-38-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10466, current rewards: -3412.95086, mean: -1.99588
[32m[0906 18-38-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10467, current rewards: -3512.95086, mean: -1.99599
[32m[0906 18-38-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10466, current rewards: -3612.95086, mean: -1.99611
[32m[0906 18-38-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10468, current rewards: -3712.95086, mean: -1.99621
[32m[0906 18-38-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10467, current rewards: -3812.95086, mean: -1.99631
[32m[0906 18-38-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10467, current rewards: -3912.95086, mean: -1.99640
[32m[0906 18-39-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10469, current rewards: -4012.95086, mean: -1.99649
[32m[0906 18-39-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10469, current rewards: -4112.95086, mean: -1.99658
[32m[0906 18-39-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10476, current rewards: -4212.95086, mean: -1.99666
[32m[0906 18-39-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10487, current rewards: -4312.95086, mean: -1.99674
[32m[0906 18-39-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10494, current rewards: -4412.95086, mean: -1.99681
[32m[0906 18-39-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10504, current rewards: -4512.95086, mean: -1.99688
[32m[0906 18-39-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10522, current rewards: -4612.95086, mean: -1.99695
[32m[0906 18-39-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10536, current rewards: -4712.95086, mean: -1.99701
[32m[0906 18-39-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10551, current rewards: -4812.95086, mean: -1.99708
[32m[0906 18-39-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10566, current rewards: -4912.95086, mean: -1.99713
[32m[0906 18-39-54 @Agent.py:117][0m Average action selection time: 0.1058
[32m[0906 18-39-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-39-54 @MBExp.py:227][0m Rewards obtained: [-4992.950861750718], Lows: [2494], Highs: [5], Total time: 14599.867159999998
[32m[0906 18-42-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-42-02 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 18-42-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10851, current rewards: -12.92465, mean: -1.29246
[32m[0906 18-42-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10920, current rewards: -7.04929, mean: -0.11749
[32m[0906 18-42-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10880, current rewards: -1.48438, mean: -0.01349
[32m[0906 18-42-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10858, current rewards: 4.07685, mean: 0.02548
[32m[0906 18-42-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10847, current rewards: 9.63265, mean: 0.04587
[32m[0906 18-42-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10859, current rewards: 15.19513, mean: 0.05844
[32m[0906 18-42-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10852, current rewards: 20.76093, mean: 0.06697
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10850, current rewards: 26.32175, mean: 0.07312
[32m[0906 18-42-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10850, current rewards: 31.88754, mean: 0.07777
[32m[0906 18-42-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10845, current rewards: 38.01886, mean: 0.08265
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10831, current rewards: 43.59387, mean: 0.08548
[32m[0906 18-43-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10803, current rewards: 39.15519, mean: 0.06992
[32m[0906 18-43-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10772, current rewards: 44.79924, mean: 0.07344
[32m[0906 18-43-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10747, current rewards: 50.44302, mean: 0.07643
[32m[0906 18-43-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10731, current rewards: 56.08550, mean: 0.07899
[32m[0906 18-43-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10715, current rewards: 61.72939, mean: 0.08122
[32m[0906 18-43-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10701, current rewards: 67.37332, mean: 0.08318
[32m[0906 18-43-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10706, current rewards: 72.80571, mean: 0.08466
[32m[0906 18-43-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10702, current rewards: 78.25114, mean: 0.08599
[32m[0906 18-43-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10693, current rewards: 83.88564, mean: 0.08738
[32m[0906 18-43-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10686, current rewards: 89.52237, mean: 0.08864
[32m[0906 18-43-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10675, current rewards: 95.16080, mean: 0.08977
[32m[0906 18-44-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10653, current rewards: 83.53046, mean: 0.07525
[32m[0906 18-44-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10635, current rewards: 86.75351, mean: 0.07479
[32m[0906 18-44-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10618, current rewards: 91.83614, mean: 0.07590
[32m[0906 18-44-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10600, current rewards: 96.91928, mean: 0.07692
[32m[0906 18-44-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10585, current rewards: 101.79818, mean: 0.07771
[32m[0906 18-44-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10569, current rewards: 106.78307, mean: 0.07852
[32m[0906 18-44-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10554, current rewards: 111.76803, mean: 0.07927
[32m[0906 18-44-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10559, current rewards: 106.76431, mean: 0.07313
[32m[0906 18-44-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10544, current rewards: 112.40827, mean: 0.07444
[32m[0906 18-44-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10531, current rewards: 118.02384, mean: 0.07566
[32m[0906 18-44-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10522, current rewards: 123.64792, mean: 0.07680
[32m[0906 18-44-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10510, current rewards: 129.26959, mean: 0.07787
[32m[0906 18-45-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10501, current rewards: 134.88966, mean: 0.07888
[32m[0906 18-45-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10501, current rewards: 140.50803, mean: 0.07983
[32m[0906 18-45-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10501, current rewards: 146.12649, mean: 0.08073
[32m[0906 18-45-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10501, current rewards: 141.05220, mean: 0.07583
[32m[0906 18-45-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10502, current rewards: 146.97927, mean: 0.07695
[32m[0906 18-45-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10502, current rewards: 152.66202, mean: 0.07789
[32m[0906 18-45-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10503, current rewards: 158.34514, mean: 0.07878
[32m[0906 18-45-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10505, current rewards: 164.03310, mean: 0.07963
[32m[0906 18-45-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10509, current rewards: 169.78451, mean: 0.08047
[32m[0906 18-45-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10518, current rewards: 175.46231, mean: 0.08123
[32m[0906 18-45-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10528, current rewards: 181.13855, mean: 0.08196
[32m[0906 18-46-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10537, current rewards: 186.81811, mean: 0.08266
[32m[0906 18-46-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10551, current rewards: 192.49840, mean: 0.08333
[32m[0906 18-46-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10570, current rewards: 198.17992, mean: 0.08397
[32m[0906 18-46-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10585, current rewards: 203.85504, mean: 0.08459
[32m[0906 18-46-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10600, current rewards: 209.53403, mean: 0.08518
[32m[0906 18-46-28 @Agent.py:117][0m Average action selection time: 0.1061
[32m[0906 18-46-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-46-28 @MBExp.py:227][0m Rewards obtained: [214.07616130684747], Lows: [25], Highs: [11], Total time: 14865.960992999999
[32m[0906 18-48-39 @MBExp.py:144][0m ####################################################################
[32m[0906 18-48-39 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 18-48-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10811, current rewards: -5.74428, mean: -0.57443
[32m[0906 18-48-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10859, current rewards: -0.37001, mean: -0.00617
[32m[0906 18-48-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10890, current rewards: 5.04264, mean: 0.04584
[32m[0906 18-48-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10879, current rewards: 10.46050, mean: 0.06538
[32m[0906 18-49-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10876, current rewards: 15.87349, mean: 0.07559
[32m[0906 18-49-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10887, current rewards: 21.28718, mean: 0.08187
[32m[0906 18-49-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10871, current rewards: 26.70881, mean: 0.08616
[32m[0906 18-49-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10859, current rewards: 19.01612, mean: 0.05282
[32m[0906 18-49-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10859, current rewards: 25.65753, mean: 0.06258
[32m[0906 18-49-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10856, current rewards: 31.61111, mean: 0.06872
[32m[0906 18-49-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10848, current rewards: 37.56561, mean: 0.07366
[32m[0906 18-49-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10822, current rewards: 43.51686, mean: 0.07771
[32m[0906 18-49-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10794, current rewards: 49.47491, mean: 0.08111
[32m[0906 18-49-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10772, current rewards: 55.43348, mean: 0.08399
[32m[0906 18-49-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10758, current rewards: 50.93283, mean: 0.07174
[32m[0906 18-50-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10744, current rewards: 56.29998, mean: 0.07408
[32m[0906 18-50-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10725, current rewards: 61.61268, mean: 0.07607
[32m[0906 18-50-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10727, current rewards: 66.92030, mean: 0.07781
[32m[0906 18-50-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10722, current rewards: 72.23033, mean: 0.07937
[32m[0906 18-50-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10711, current rewards: 77.87325, mean: 0.08112
[32m[0906 18-50-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10704, current rewards: 83.99524, mean: 0.08316
[32m[0906 18-50-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10695, current rewards: 90.11929, mean: 0.08502
[32m[0906 18-50-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10673, current rewards: 96.24397, mean: 0.08671
[32m[0906 18-50-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10653, current rewards: 102.36707, mean: 0.08825
[32m[0906 18-50-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10634, current rewards: 108.14088, mean: 0.08937
[32m[0906 18-50-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10616, current rewards: 114.20862, mean: 0.09064
[32m[0906 18-50-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10602, current rewards: 106.94861, mean: 0.08164
[32m[0906 18-51-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10588, current rewards: 112.37262, mean: 0.08263
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10571, current rewards: 117.79584, mean: 0.08354
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10559, current rewards: 123.21438, mean: 0.08439
[32m[0906 18-51-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10547, current rewards: 128.63621, mean: 0.08519
[32m[0906 18-51-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10536, current rewards: 134.05906, mean: 0.08594
[32m[0906 18-51-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10527, current rewards: 139.50360, mean: 0.08665
[32m[0906 18-51-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10517, current rewards: 147.66781, mean: 0.08896
[32m[0906 18-51-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10509, current rewards: 152.15515, mean: 0.08898
[32m[0906 18-51-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10503, current rewards: 154.55582, mean: 0.08782
[32m[0906 18-51-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10503, current rewards: 156.95650, mean: 0.08672
[32m[0906 18-51-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10504, current rewards: 159.35717, mean: 0.08568
[32m[0906 18-52-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10507, current rewards: 161.75785, mean: 0.08469
[32m[0906 18-52-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10507, current rewards: 164.15852, mean: 0.08375
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10507, current rewards: 166.55920, mean: 0.08287
[32m[0906 18-52-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10508, current rewards: 136.47145, mean: 0.06625
[32m[0906 18-52-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10508, current rewards: 86.47145, mean: 0.04098
[32m[0906 18-52-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10514, current rewards: 36.47145, mean: 0.01688
[32m[0906 18-52-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10524, current rewards: -13.52855, mean: -0.00612
[32m[0906 18-52-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10532, current rewards: -63.52855, mean: -0.02811
[32m[0906 18-52-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10541, current rewards: -113.52855, mean: -0.04915
[32m[0906 18-52-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10558, current rewards: -163.52855, mean: -0.06929
[32m[0906 18-52-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10573, current rewards: -213.52855, mean: -0.08860
[32m[0906 18-53-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10587, current rewards: -263.52855, mean: -0.10713
[32m[0906 18-53-04 @Agent.py:117][0m Average action selection time: 0.1060
[32m[0906 18-53-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-53-05 @MBExp.py:227][0m Rewards obtained: [-303.5285453407473], Lows: [15], Highs: [482], Total time: 15131.779266999998
[32m[0906 18-55-17 @MBExp.py:144][0m ####################################################################
[32m[0906 18-55-17 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10809, current rewards: 1.01530, mean: 0.10153
[32m[0906 18-55-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10783, current rewards: 6.80357, mean: 0.11339
[32m[0906 18-55-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10805, current rewards: 12.59871, mean: 0.11453
[32m[0906 18-55-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10809, current rewards: 18.39265, mean: 0.11495
[32m[0906 18-55-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10814, current rewards: 24.18544, mean: 0.11517
[32m[0906 18-55-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10823, current rewards: 23.07675, mean: 0.08876
[32m[0906 18-55-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10825, current rewards: 28.69774, mean: 0.09257
[32m[0906 18-55-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10825, current rewards: 34.18152, mean: 0.09495
[32m[0906 18-56-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10830, current rewards: 39.50536, mean: 0.09635
[32m[0906 18-56-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10830, current rewards: 45.08972, mean: 0.09802
[32m[0906 18-56-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10830, current rewards: 50.66387, mean: 0.09934
[32m[0906 18-56-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10797, current rewards: 56.24535, mean: 0.10044
[32m[0906 18-56-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10767, current rewards: 48.87438, mean: 0.08012
[32m[0906 18-56-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10746, current rewards: 54.55969, mean: 0.08267
[32m[0906 18-56-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10731, current rewards: 60.23805, mean: 0.08484
[32m[0906 18-56-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10716, current rewards: 65.91738, mean: 0.08673
[32m[0906 18-56-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10702, current rewards: 71.91030, mean: 0.08878
[32m[0906 18-56-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10707, current rewards: 70.77329, mean: 0.08229
[32m[0906 18-56-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10705, current rewards: 77.13820, mean: 0.08477
[32m[0906 18-57-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10696, current rewards: 83.41692, mean: 0.08689
[32m[0906 18-57-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10687, current rewards: 89.70376, mean: 0.08882
[32m[0906 18-57-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10677, current rewards: 95.98459, mean: 0.09055
[32m[0906 18-57-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10657, current rewards: 102.27022, mean: 0.09214
[32m[0906 18-57-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10638, current rewards: 108.55946, mean: 0.09359
[32m[0906 18-57-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10620, current rewards: 114.60949, mean: 0.09472
[32m[0906 18-57-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10607, current rewards: 121.05790, mean: 0.09608
[32m[0906 18-57-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10597, current rewards: 130.24284, mean: 0.09942
[32m[0906 18-57-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10581, current rewards: 139.13828, mean: 0.10231
[32m[0906 18-57-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10565, current rewards: 148.04988, mean: 0.10500
[32m[0906 18-57-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10554, current rewards: 156.93207, mean: 0.10749
[32m[0906 18-57-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10539, current rewards: 165.80717, mean: 0.10981
[32m[0906 18-58-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10526, current rewards: 174.67099, mean: 0.11197
[32m[0906 18-58-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10516, current rewards: 183.99948, mean: 0.11429
[32m[0906 18-58-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10504, current rewards: 193.01892, mean: 0.11628
[32m[0906 18-58-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10495, current rewards: 202.00843, mean: 0.11813
[32m[0906 18-58-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10488, current rewards: 211.02564, mean: 0.11990
[32m[0906 18-58-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10486, current rewards: 220.02596, mean: 0.12156
[32m[0906 18-58-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10487, current rewards: 229.02297, mean: 0.12313
[32m[0906 18-58-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10490, current rewards: 238.00003, mean: 0.12461
[32m[0906 18-58-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10490, current rewards: 234.25314, mean: 0.11952
[32m[0906 18-58-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10491, current rewards: 239.39153, mean: 0.11910
[32m[0906 18-58-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10491, current rewards: 244.67090, mean: 0.11877
[32m[0906 18-58-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10492, current rewards: 249.95532, mean: 0.11846
[32m[0906 18-59-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10494, current rewards: 255.23712, mean: 0.11817
[32m[0906 18-59-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10504, current rewards: 260.51922, mean: 0.11788
[32m[0906 18-59-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10511, current rewards: 265.79599, mean: 0.11761
[32m[0906 18-59-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10519, current rewards: 271.07935, mean: 0.11735
[32m[0906 18-59-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10533, current rewards: 276.35911, mean: 0.11710
[32m[0906 18-59-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10548, current rewards: 282.11823, mean: 0.11706
[32m[0906 18-59-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10562, current rewards: 267.63041, mean: 0.10879
[32m[0906 18-59-42 @Agent.py:117][0m Average action selection time: 0.1057
[32m[0906 18-59-42 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-59-43 @MBExp.py:227][0m Rewards obtained: [272.5725595562278], Lows: [20], Highs: [14], Total time: 15396.947398999999
[32m[0906 19-01-58 @MBExp.py:144][0m ####################################################################
[32m[0906 19-01-58 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 19-01-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10793, current rewards: -5.64407, mean: -0.56441
[32m[0906 19-02-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10887, current rewards: -0.22039, mean: -0.00367
[32m[0906 19-02-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10865, current rewards: 5.07526, mean: 0.04614
[32m[0906 19-02-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10845, current rewards: 10.37149, mean: 0.06482
[32m[0906 19-02-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10865, current rewards: 15.66600, mean: 0.07460
[32m[0906 19-02-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10855, current rewards: 20.95473, mean: 0.08060
[32m[0906 19-02-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10856, current rewards: 26.24989, mean: 0.08468
[32m[0906 19-02-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10862, current rewards: 21.75047, mean: 0.06042
[32m[0906 19-02-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10858, current rewards: 27.24773, mean: 0.06646
[32m[0906 19-02-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10856, current rewards: 32.68517, mean: 0.07105
[32m[0906 19-02-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10864, current rewards: 38.12583, mean: 0.07476
[32m[0906 19-02-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10836, current rewards: 43.56948, mean: 0.07780
[32m[0906 19-03-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10804, current rewards: 38.58758, mean: 0.06326
[32m[0906 19-03-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10782, current rewards: 44.22379, mean: 0.06701
[32m[0906 19-03-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10762, current rewards: 49.68015, mean: 0.06997
[32m[0906 19-03-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10742, current rewards: 55.13600, mean: 0.07255
[32m[0906 19-03-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10731, current rewards: 59.86166, mean: 0.07390
[32m[0906 19-03-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10716, current rewards: 65.73467, mean: 0.07644
[32m[0906 19-03-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10705, current rewards: 66.02284, mean: 0.07255
[32m[0906 19-03-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10700, current rewards: 71.37400, mean: 0.07435
[32m[0906 19-03-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10691, current rewards: 76.72150, mean: 0.07596
[32m[0906 19-03-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10683, current rewards: 82.06783, mean: 0.07742
[32m[0906 19-03-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10671, current rewards: 87.40968, mean: 0.07875
[32m[0906 19-04-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10653, current rewards: 92.76495, mean: 0.07997
[32m[0906 19-04-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10634, current rewards: 96.92051, mean: 0.08010
[32m[0906 19-04-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10622, current rewards: 102.93132, mean: 0.08169
[32m[0906 19-04-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10608, current rewards: 108.59118, mean: 0.08289
[32m[0906 19-04-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10595, current rewards: 114.25146, mean: 0.08401
[32m[0906 19-04-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10583, current rewards: 119.91003, mean: 0.08504
[32m[0906 19-04-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10570, current rewards: 125.57804, mean: 0.08601
[32m[0906 19-04-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10558, current rewards: 131.23842, mean: 0.08691
[32m[0906 19-04-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10548, current rewards: 124.45350, mean: 0.07978
[32m[0906 19-04-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10536, current rewards: 131.72771, mean: 0.08182
[32m[0906 19-04-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10524, current rewards: 136.37217, mean: 0.08215
[32m[0906 19-04-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10515, current rewards: 141.81688, mean: 0.08293
[32m[0906 19-05-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10505, current rewards: 147.25734, mean: 0.08367
[32m[0906 19-05-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10496, current rewards: 152.69787, mean: 0.08436
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10495, current rewards: 158.13903, mean: 0.08502
[32m[0906 19-05-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10498, current rewards: 163.58049, mean: 0.08564
[32m[0906 19-05-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10499, current rewards: 169.02185, mean: 0.08624
[32m[0906 19-05-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10499, current rewards: 168.62543, mean: 0.08389
[32m[0906 19-05-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10500, current rewards: 174.30866, mean: 0.08462
[32m[0906 19-05-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10501, current rewards: 179.94049, mean: 0.08528
[32m[0906 19-05-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10502, current rewards: 185.57028, mean: 0.08591
[32m[0906 19-05-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10508, current rewards: 191.20502, mean: 0.08652
[32m[0906 19-05-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10518, current rewards: 196.83675, mean: 0.08710
[32m[0906 19-06-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10525, current rewards: 202.47151, mean: 0.08765
[32m[0906 19-06-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10533, current rewards: 208.10859, mean: 0.08818
[32m[0906 19-06-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10547, current rewards: 213.73853, mean: 0.08869
[32m[0906 19-06-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10564, current rewards: 219.75120, mean: 0.08933
[32m[0906 19-06-23 @Agent.py:117][0m Average action selection time: 0.1058
[32m[0906 19-06-23 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-06-23 @MBExp.py:227][0m Rewards obtained: [224.28857621444985], Lows: [17], Highs: [17], Total time: 15662.135186
[32m[0906 19-08-41 @MBExp.py:144][0m ####################################################################
[32m[0906 19-08-41 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 19-08-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11730, current rewards: -9.98243, mean: -0.99824
[32m[0906 19-08-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11046, current rewards: -8.34792, mean: -0.13913
[32m[0906 19-08-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10977, current rewards: -1.61595, mean: -0.01469
[32m[0906 19-08-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10973, current rewards: 5.12180, mean: 0.03201
[32m[0906 19-09-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10952, current rewards: 11.86025, mean: 0.05648
[32m[0906 19-09-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10944, current rewards: 18.59191, mean: 0.07151
[32m[0906 19-09-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10943, current rewards: 25.32650, mean: 0.08170
[32m[0906 19-09-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10937, current rewards: 31.73119, mean: 0.08814
[32m[0906 19-09-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10928, current rewards: 36.99903, mean: 0.09024
[32m[0906 19-09-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10931, current rewards: 42.87326, mean: 0.09320
[32m[0906 19-09-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10927, current rewards: 48.74433, mean: 0.09558
[32m[0906 19-09-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10907, current rewards: 54.61696, mean: 0.09753
[32m[0906 19-09-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10884, current rewards: 49.32302, mean: 0.08086
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10860, current rewards: 54.49004, mean: 0.08256
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10838, current rewards: 59.65668, mean: 0.08402
[32m[0906 19-10-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10822, current rewards: 64.82128, mean: 0.08529
[32m[0906 19-10-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10803, current rewards: 71.13178, mean: 0.08782
[32m[0906 19-10-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10787, current rewards: 77.17705, mean: 0.08974
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10776, current rewards: 83.22231, mean: 0.09145
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10765, current rewards: 89.26758, mean: 0.09299
[32m[0906 19-10-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10752, current rewards: 95.31284, mean: 0.09437
[32m[0906 19-10-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10743, current rewards: 101.35811, mean: 0.09562
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10729, current rewards: 83.86436, mean: 0.07555
[32m[0906 19-10-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10705, current rewards: 33.86436, mean: 0.02919
[32m[0906 19-10-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10684, current rewards: -16.13564, mean: -0.01334
[32m[0906 19-10-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10663, current rewards: -66.13564, mean: -0.05249
[32m[0906 19-11-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10643, current rewards: -116.13564, mean: -0.08865
[32m[0906 19-11-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10627, current rewards: -166.13564, mean: -0.12216
[32m[0906 19-11-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10611, current rewards: -216.13564, mean: -0.15329
[32m[0906 19-11-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10597, current rewards: -266.13564, mean: -0.18228
[32m[0906 19-11-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10585, current rewards: -316.13564, mean: -0.20936
[32m[0906 19-11-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10571, current rewards: -366.13564, mean: -0.23470
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10559, current rewards: -416.13564, mean: -0.25847
[32m[0906 19-11-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10549, current rewards: -466.13564, mean: -0.28080
[32m[0906 19-11-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10537, current rewards: -516.13564, mean: -0.30183
[32m[0906 19-11-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10526, current rewards: -566.13564, mean: -0.32167
[32m[0906 19-11-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10517, current rewards: -616.13564, mean: -0.34041
[32m[0906 19-11-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10512, current rewards: -666.13564, mean: -0.35814
[32m[0906 19-12-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10511, current rewards: -716.13564, mean: -0.37494
[32m[0906 19-12-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10512, current rewards: -766.13564, mean: -0.39089
[32m[0906 19-12-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10514, current rewards: -816.13564, mean: -0.40604
[32m[0906 19-12-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10514, current rewards: -866.13564, mean: -0.42045
[32m[0906 19-12-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10514, current rewards: -916.13564, mean: -0.43419
[32m[0906 19-12-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10516, current rewards: -966.13564, mean: -0.44729
[32m[0906 19-12-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10515, current rewards: -1016.13564, mean: -0.45979
[32m[0906 19-12-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10523, current rewards: -1066.13564, mean: -0.47174
[32m[0906 19-12-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10531, current rewards: -1116.13564, mean: -0.48318
[32m[0906 19-12-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10538, current rewards: -1166.13564, mean: -0.49413
[32m[0906 19-12-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10547, current rewards: -1216.13564, mean: -0.50462
[32m[0906 19-13-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10562, current rewards: -1266.13564, mean: -0.51469
[32m[0906 19-13-06 @Agent.py:117][0m Average action selection time: 0.1057
[32m[0906 19-13-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-13-06 @MBExp.py:227][0m Rewards obtained: [-1306.1356392170228], Lows: [11], Highs: [1416], Total time: 15927.270926
[32m[0906 19-15-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-15-25 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 19-15-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10827, current rewards: 1.37044, mean: 0.13704
[32m[0906 19-15-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10803, current rewards: -30.48745, mean: -0.50812
[32m[0906 19-15-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10818, current rewards: -80.48745, mean: -0.73170
[32m[0906 19-15-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10799, current rewards: -130.48745, mean: -0.81555
[32m[0906 19-15-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10795, current rewards: -180.48745, mean: -0.85946
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10811, current rewards: -230.48745, mean: -0.88649
[32m[0906 19-15-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10816, current rewards: -280.48745, mean: -0.90480
[32m[0906 19-16-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10819, current rewards: -330.48745, mean: -0.91802
[32m[0906 19-16-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10828, current rewards: -380.48745, mean: -0.92802
[32m[0906 19-16-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10828, current rewards: -430.48745, mean: -0.93584
[32m[0906 19-16-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10826, current rewards: -480.48745, mean: -0.94213
[32m[0906 19-16-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10824, current rewards: -530.48745, mean: -0.94730
[32m[0906 19-16-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10792, current rewards: -580.48745, mean: -0.95162
[32m[0906 19-16-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10767, current rewards: -630.48745, mean: -0.95528
[32m[0906 19-16-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10750, current rewards: -680.48745, mean: -0.95843
[32m[0906 19-16-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10729, current rewards: -730.48745, mean: -0.96117
[32m[0906 19-16-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10712, current rewards: -780.48745, mean: -0.96356
[32m[0906 19-16-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10702, current rewards: -830.48745, mean: -0.96568
[32m[0906 19-17-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10696, current rewards: -880.48745, mean: -0.96757
[32m[0906 19-17-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10684, current rewards: -930.48745, mean: -0.96926
[32m[0906 19-17-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10676, current rewards: -980.48745, mean: -0.97078
[32m[0906 19-17-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10666, current rewards: -1030.48745, mean: -0.97216
[32m[0906 19-17-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10655, current rewards: -1080.48745, mean: -0.97341
[32m[0906 19-17-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10635, current rewards: -1130.48745, mean: -0.97456
[32m[0906 19-17-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10619, current rewards: -1180.48745, mean: -0.97561
[32m[0906 19-17-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10601, current rewards: -1230.48745, mean: -0.97658
[32m[0906 19-17-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10585, current rewards: -1280.48745, mean: -0.97747
[32m[0906 19-17-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10568, current rewards: -1330.48745, mean: -0.97830
[32m[0906 19-17-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10553, current rewards: -1380.48745, mean: -0.97907
[32m[0906 19-18-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10542, current rewards: -1430.48745, mean: -0.97979
[32m[0906 19-18-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10529, current rewards: -1480.48745, mean: -0.98046
[32m[0906 19-18-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10517, current rewards: -1530.48745, mean: -0.98108
[32m[0906 19-18-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10508, current rewards: -1580.48745, mean: -0.98167
[32m[0906 19-18-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10496, current rewards: -1630.48745, mean: -0.98222
[32m[0906 19-18-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10485, current rewards: -1680.48745, mean: -0.98274
[32m[0906 19-18-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10476, current rewards: -1730.48745, mean: -0.98323
[32m[0906 19-18-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10465, current rewards: -1780.48745, mean: -0.98369
[32m[0906 19-18-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10457, current rewards: -1830.48745, mean: -0.98413
[32m[0906 19-18-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10455, current rewards: -1880.48745, mean: -0.98455
[32m[0906 19-18-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10456, current rewards: -1930.48745, mean: -0.98494
[32m[0906 19-18-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10457, current rewards: -1980.48745, mean: -0.98532
[32m[0906 19-19-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10461, current rewards: -2030.48745, mean: -0.98567
[32m[0906 19-19-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10462, current rewards: -2080.48745, mean: -0.98601
[32m[0906 19-19-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10463, current rewards: -2130.48745, mean: -0.98634
[32m[0906 19-19-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10464, current rewards: -2180.48745, mean: -0.98665
[32m[0906 19-19-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10468, current rewards: -2230.48745, mean: -0.98694
[32m[0906 19-19-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10477, current rewards: -2280.48745, mean: -0.98722
[32m[0906 19-19-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10486, current rewards: -2330.48745, mean: -0.98749
[32m[0906 19-19-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10494, current rewards: -2380.48745, mean: -0.98775
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10505, current rewards: -2430.48745, mean: -0.98800
[32m[0906 19-19-49 @Agent.py:117][0m Average action selection time: 0.1052
[32m[0906 19-19-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-19-49 @MBExp.py:227][0m Rewards obtained: [-2470.4874549768742], Lows: [0], Highs: [2473], Total time: 16191.00325
[32m[0906 19-22-11 @MBExp.py:144][0m ####################################################################
[32m[0906 19-22-11 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 19-22-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11074, current rewards: 0.97547, mean: 0.09755
[32m[0906 19-22-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10945, current rewards: 8.32012, mean: 0.13867
[32m[0906 19-22-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10909, current rewards: 15.59433, mean: 0.14177
[32m[0906 19-22-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10914, current rewards: 22.86855, mean: 0.14293
[32m[0906 19-22-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10907, current rewards: -20.25855, mean: -0.09647
[32m[0906 19-22-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10895, current rewards: -70.25855, mean: -0.27023
[32m[0906 19-22-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10897, current rewards: -120.25855, mean: -0.38793
[32m[0906 19-22-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10893, current rewards: -170.25855, mean: -0.47294
[32m[0906 19-22-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10884, current rewards: -220.25855, mean: -0.53722
[32m[0906 19-23-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10886, current rewards: -270.25855, mean: -0.58752
[32m[0906 19-23-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10880, current rewards: -320.25855, mean: -0.62796
[32m[0906 19-23-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10868, current rewards: -370.25855, mean: -0.66118
[32m[0906 19-23-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10842, current rewards: -420.25855, mean: -0.68895
[32m[0906 19-23-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10816, current rewards: -470.25855, mean: -0.71251
[32m[0906 19-23-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10795, current rewards: -520.25855, mean: -0.73276
[32m[0906 19-23-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10780, current rewards: -570.25855, mean: -0.75034
[32m[0906 19-23-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10765, current rewards: -620.25855, mean: -0.76575
[32m[0906 19-23-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10750, current rewards: -670.25855, mean: -0.77937
[32m[0906 19-23-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10743, current rewards: -720.25855, mean: -0.79149
[32m[0906 19-23-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10738, current rewards: -770.25855, mean: -0.80235
[32m[0906 19-24-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10727, current rewards: -820.25855, mean: -0.81214
[32m[0906 19-24-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10721, current rewards: -870.25855, mean: -0.82100
[32m[0906 19-24-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10712, current rewards: -920.25855, mean: -0.82906
[32m[0906 19-24-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10693, current rewards: -970.25855, mean: -0.83643
[32m[0906 19-24-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10673, current rewards: -1020.25855, mean: -0.84319
[32m[0906 19-24-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10652, current rewards: -1070.25855, mean: -0.84941
[32m[0906 19-24-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10633, current rewards: -1120.25855, mean: -0.85516
[32m[0906 19-24-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10618, current rewards: -1170.25855, mean: -0.86048
[32m[0906 19-24-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10601, current rewards: -1220.25855, mean: -0.86543
[32m[0906 19-24-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10586, current rewards: -1270.25855, mean: -0.87004
[32m[0906 19-24-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10571, current rewards: -1320.25855, mean: -0.87434
[32m[0906 19-24-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10561, current rewards: -1370.25855, mean: -0.87837
[32m[0906 19-25-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10548, current rewards: -1420.25855, mean: -0.88215
[32m[0906 19-25-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10536, current rewards: -1470.25855, mean: -0.88570
[32m[0906 19-25-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10527, current rewards: -1520.25855, mean: -0.88904
[32m[0906 19-25-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10517, current rewards: -1570.25855, mean: -0.89219
[32m[0906 19-25-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10508, current rewards: -1620.25855, mean: -0.89517
[32m[0906 19-25-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10501, current rewards: -1670.25855, mean: -0.89799
[32m[0906 19-25-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10493, current rewards: -1720.25855, mean: -0.90066
[32m[0906 19-25-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10493, current rewards: -1770.25855, mean: -0.90319
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10495, current rewards: -1820.25855, mean: -0.90560
[32m[0906 19-25-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10496, current rewards: -1870.25855, mean: -0.90789
[32m[0906 19-25-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10498, current rewards: -1920.25855, mean: -0.91008
[32m[0906 19-25-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10501, current rewards: -1970.25855, mean: -0.91216
[32m[0906 19-26-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10502, current rewards: -2020.25855, mean: -0.91414
[32m[0906 19-26-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10504, current rewards: -2070.25855, mean: -0.91604
[32m[0906 19-26-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10512, current rewards: -2120.25855, mean: -0.91786
[32m[0906 19-26-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10521, current rewards: -2170.25855, mean: -0.91960
[32m[0906 19-26-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10529, current rewards: -2220.25855, mean: -0.92127
[32m[0906 19-26-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10537, current rewards: -2270.25855, mean: -0.92287
[32m[0906 19-26-36 @Agent.py:117][0m Average action selection time: 0.1055
[32m[0906 19-26-36 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-26-36 @MBExp.py:227][0m Rewards obtained: [-2310.2585460499645], Lows: [0], Highs: [2334], Total time: 16455.46499
[32m[0906 19-29-01 @MBExp.py:144][0m ####################################################################
[32m[0906 19-29-01 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 19-29-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10838, current rewards: -4.57356, mean: -0.45736
[32m[0906 19-29-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10895, current rewards: 0.48166, mean: 0.00803
[32m[0906 19-29-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10865, current rewards: 5.54644, mean: 0.05042
[32m[0906 19-29-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10867, current rewards: 10.61673, mean: 0.06635
[32m[0906 19-29-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10883, current rewards: 15.68462, mean: 0.07469
[32m[0906 19-29-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10884, current rewards: 20.75049, mean: 0.07981
[32m[0906 19-29-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10881, current rewards: 25.81872, mean: 0.08329
[32m[0906 19-29-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10881, current rewards: 30.88446, mean: 0.08579
[32m[0906 19-29-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10881, current rewards: 36.15585, mean: 0.08818
[32m[0906 19-29-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10879, current rewards: 41.20930, mean: 0.08959
[32m[0906 19-29-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10882, current rewards: 46.26900, mean: 0.09072
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10880, current rewards: 42.52022, mean: 0.07593
[32m[0906 19-30-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10860, current rewards: 50.59041, mean: 0.08294
[32m[0906 19-30-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10835, current rewards: 58.66525, mean: 0.08889
[32m[0906 19-30-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10814, current rewards: 66.72754, mean: 0.09398
[32m[0906 19-30-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10797, current rewards: 74.78465, mean: 0.09840
[32m[0906 19-30-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10784, current rewards: 81.16192, mean: 0.10020
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10767, current rewards: 88.60950, mean: 0.10303
[32m[0906 19-30-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10757, current rewards: 96.02368, mean: 0.10552
[32m[0906 19-30-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10757, current rewards: 103.45074, mean: 0.10776
[32m[0906 19-30-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10748, current rewards: 105.14986, mean: 0.10411
[32m[0906 19-30-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10739, current rewards: 91.67653, mean: 0.08649
[32m[0906 19-31-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10733, current rewards: 98.46689, mean: 0.08871
[32m[0906 19-31-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10717, current rewards: 105.25160, mean: 0.09073
[32m[0906 19-31-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10694, current rewards: 112.03714, mean: 0.09259
[32m[0906 19-31-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10678, current rewards: 118.81552, mean: 0.09430
[32m[0906 19-31-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10660, current rewards: 125.59454, mean: 0.09587
[32m[0906 19-31-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10643, current rewards: 132.37000, mean: 0.09733
[32m[0906 19-31-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10630, current rewards: 139.14087, mean: 0.09868
[32m[0906 19-31-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10615, current rewards: 145.92884, mean: 0.09995
[32m[0906 19-31-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10601, current rewards: 152.69972, mean: 0.10113
[32m[0906 19-31-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10590, current rewards: 159.49004, mean: 0.10224
[32m[0906 19-31-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10578, current rewards: 166.66003, mean: 0.10352
[32m[0906 19-31-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10566, current rewards: 162.76734, mean: 0.09805
[32m[0906 19-32-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10555, current rewards: 168.60780, mean: 0.09860
[32m[0906 19-32-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10545, current rewards: 174.44339, mean: 0.09912
[32m[0906 19-32-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10534, current rewards: 180.28264, mean: 0.09960
[32m[0906 19-32-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10524, current rewards: 185.83050, mean: 0.09991
[32m[0906 19-32-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10516, current rewards: 191.54608, mean: 0.10029
[32m[0906 19-32-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10507, current rewards: 197.26115, mean: 0.10064
[32m[0906 19-32-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10508, current rewards: 202.97498, mean: 0.10098
[32m[0906 19-32-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10510, current rewards: 208.68746, mean: 0.10130
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10510, current rewards: 214.40146, mean: 0.10161
[32m[0906 19-32-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10510, current rewards: 209.42127, mean: 0.09695
[32m[0906 19-32-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10512, current rewards: 214.68641, mean: 0.09714
[32m[0906 19-32-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10512, current rewards: 219.95246, mean: 0.09732
[32m[0906 19-33-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10513, current rewards: 225.21834, mean: 0.09750
[32m[0906 19-33-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10522, current rewards: 230.48378, mean: 0.09766
[32m[0906 19-33-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10529, current rewards: 235.74891, mean: 0.09782
[32m[0906 19-33-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10537, current rewards: 240.98332, mean: 0.09796
[32m[0906 19-33-25 @Agent.py:117][0m Average action selection time: 0.1054
[32m[0906 19-33-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-33-25 @MBExp.py:227][0m Rewards obtained: [238.42332979683277], Lows: [25], Highs: [18], Total time: 16719.864127
[32m[0906 19-35-52 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-52 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 19-35-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10753, current rewards: -15.00000, mean: -1.50000
[32m[0906 19-35-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10861, current rewards: -24.73325, mean: -0.41222
[32m[0906 19-36-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10892, current rewards: -17.49906, mean: -0.15908
[32m[0906 19-36-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10884, current rewards: -10.25728, mean: -0.06411
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10867, current rewards: -3.01388, mean: -0.01435
[32m[0906 19-36-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10864, current rewards: 4.22518, mean: 0.01625
[32m[0906 19-36-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10858, current rewards: 11.47510, mean: 0.03702
[32m[0906 19-36-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10852, current rewards: 18.52300, mean: 0.05145
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10853, current rewards: 25.81445, mean: 0.06296
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10850, current rewards: 33.12088, mean: 0.07200
[32m[0906 19-36-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10845, current rewards: 40.41482, mean: 0.07924
[32m[0906 19-36-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10844, current rewards: 47.73153, mean: 0.08523
[32m[0906 19-36-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10830, current rewards: 55.03041, mean: 0.09021
[32m[0906 19-37-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10801, current rewards: 62.35650, mean: 0.09448
[32m[0906 19-37-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10780, current rewards: 69.65013, mean: 0.09810
[32m[0906 19-37-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10761, current rewards: 74.74493, mean: 0.09835
[32m[0906 19-37-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10750, current rewards: 71.42367, mean: 0.08818
[32m[0906 19-37-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10737, current rewards: 78.56532, mean: 0.09136
[32m[0906 19-37-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10730, current rewards: 85.69724, mean: 0.09417
[32m[0906 19-37-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10740, current rewards: 92.83033, mean: 0.09670
[32m[0906 19-37-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10732, current rewards: 99.97012, mean: 0.09898
[32m[0906 19-37-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10720, current rewards: 107.09310, mean: 0.10103
[32m[0906 19-37-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10710, current rewards: 114.23670, mean: 0.10292
[32m[0906 19-37-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10702, current rewards: 120.67459, mean: 0.10403
[32m[0906 19-38-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10679, current rewards: 127.26686, mean: 0.10518
[32m[0906 19-38-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10659, current rewards: 133.49991, mean: 0.10595
[32m[0906 19-38-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10644, current rewards: 139.73363, mean: 0.10667
[32m[0906 19-38-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10628, current rewards: 145.97132, mean: 0.10733
[32m[0906 19-38-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10610, current rewards: 152.19282, mean: 0.10794
[32m[0906 19-38-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10598, current rewards: 145.37399, mean: 0.09957
[32m[0906 19-38-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10585, current rewards: 151.17273, mean: 0.10011
[32m[0906 19-38-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10573, current rewards: 156.97197, mean: 0.10062
[32m[0906 19-38-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10563, current rewards: 162.02546, mean: 0.10064
[32m[0906 19-38-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10553, current rewards: 167.35701, mean: 0.10082
[32m[0906 19-38-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10542, current rewards: 172.68748, mean: 0.10099
[32m[0906 19-38-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10534, current rewards: 178.02105, mean: 0.10115
[32m[0906 19-39-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10525, current rewards: 183.35216, mean: 0.10130
[32m[0906 19-39-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10517, current rewards: 188.68896, mean: 0.10145
[32m[0906 19-39-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10509, current rewards: 194.02313, mean: 0.10158
[32m[0906 19-39-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10502, current rewards: 199.35538, mean: 0.10171
[32m[0906 19-39-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10498, current rewards: 205.76017, mean: 0.10237
[32m[0906 19-39-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10500, current rewards: 189.91616, mean: 0.09219
[32m[0906 19-39-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10502, current rewards: 139.91616, mean: 0.06631
[32m[0906 19-39-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10503, current rewards: 89.91616, mean: 0.04163
[32m[0906 19-39-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10505, current rewards: 39.91616, mean: 0.01806
[32m[0906 19-39-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10505, current rewards: -10.08384, mean: -0.00446
[32m[0906 19-39-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10506, current rewards: -60.08384, mean: -0.02601
[32m[0906 19-40-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10511, current rewards: -110.08384, mean: -0.04665
[32m[0906 19-40-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10520, current rewards: -160.08384, mean: -0.06642
[32m[0906 19-40-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10528, current rewards: -210.08384, mean: -0.08540
[32m[0906 19-40-16 @Agent.py:117][0m Average action selection time: 0.1054
[32m[0906 19-40-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-40-16 @MBExp.py:227][0m Rewards obtained: [-250.08383600287954], Lows: [25], Highs: [468], Total time: 16984.065032000002
[32m[0906 19-42-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-42-46 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 19-42-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11535, current rewards: -10.37408, mean: -1.03741
[32m[0906 19-42-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11139, current rewards: -32.79008, mean: -0.54650
[32m[0906 19-42-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11046, current rewards: -31.24218, mean: -0.28402
[32m[0906 19-43-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10987, current rewards: -50.48917, mean: -0.31556
[32m[0906 19-43-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11052, current rewards: -74.44514, mean: -0.35450
[32m[0906 19-43-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11040, current rewards: -74.46448, mean: -0.28640
[32m[0906 19-43-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11066, current rewards: -105.85648, mean: -0.34147
[32m[0906 19-43-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11161, current rewards: -149.34017, mean: -0.41483
[32m[0906 19-43-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11202, current rewards: -195.54815, mean: -0.47695
[32m[0906 19-43-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11169, current rewards: -201.24731, mean: -0.43749
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11147, current rewards: -202.50013, mean: -0.39706
[32m[0906 19-43-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11135, current rewards: -207.81518, mean: -0.37110
[32m[0906 19-43-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11108, current rewards: -214.34885, mean: -0.35139
[32m[0906 19-43-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11083, current rewards: -216.70917, mean: -0.32835
[32m[0906 19-44-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11056, current rewards: -232.87910, mean: -0.32800
[32m[0906 19-44-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11026, current rewards: -226.95132, mean: -0.29862
[32m[0906 19-44-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11001, current rewards: -221.35384, mean: -0.27328
[32m[0906 19-44-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10974, current rewards: -215.84599, mean: -0.25098
[32m[0906 19-44-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10964, current rewards: -210.33729, mean: -0.23114
[32m[0906 19-44-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10960, current rewards: -204.82837, mean: -0.21336
[32m[0906 19-44-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10941, current rewards: -199.32532, mean: -0.19735
[32m[0906 19-44-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10921, current rewards: -193.82255, mean: -0.18285
[32m[0906 19-44-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10908, current rewards: -188.31801, mean: -0.16966
[32m[0906 19-44-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10892, current rewards: -182.80502, mean: -0.15759
[32m[0906 19-44-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10865, current rewards: -177.72412, mean: -0.14688
[32m[0906 19-45-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10842, current rewards: -172.23848, mean: -0.13670
[32m[0906 19-45-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10817, current rewards: -166.76609, mean: -0.12730
[32m[0906 19-45-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10794, current rewards: -174.03494, mean: -0.12797
[32m[0906 19-45-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10775, current rewards: -168.28751, mean: -0.11935
[32m[0906 19-45-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10757, current rewards: -162.71606, mean: -0.11145
[32m[0906 19-45-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10741, current rewards: -157.15214, mean: -0.10407
[32m[0906 19-45-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10725, current rewards: -151.58550, mean: -0.09717
[32m[0906 19-45-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10711, current rewards: -145.14698, mean: -0.09015
[32m[0906 19-45-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10697, current rewards: -139.45279, mean: -0.08401
[32m[0906 19-45-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10685, current rewards: -133.83169, mean: -0.07826
[32m[0906 19-45-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10673, current rewards: -128.21055, mean: -0.07285
[32m[0906 19-45-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10663, current rewards: -122.58922, mean: -0.06773
[32m[0906 19-46-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10652, current rewards: -116.96827, mean: -0.06289
[32m[0906 19-46-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10643, current rewards: -111.34652, mean: -0.05830
[32m[0906 19-46-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10632, current rewards: -112.46136, mean: -0.05738
[32m[0906 19-46-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10623, current rewards: -106.91020, mean: -0.05319
[32m[0906 19-46-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10623, current rewards: -101.76515, mean: -0.04940
[32m[0906 19-46-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10623, current rewards: -96.22690, mean: -0.04561
[32m[0906 19-46-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10622, current rewards: -90.69535, mean: -0.04199
[32m[0906 19-46-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10623, current rewards: -85.16151, mean: -0.03853
[32m[0906 19-46-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10622, current rewards: -79.62329, mean: -0.03523
[32m[0906 19-46-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10621, current rewards: -74.08724, mean: -0.03207
[32m[0906 19-46-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10621, current rewards: -68.55224, mean: -0.02905
[32m[0906 19-47-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10627, current rewards: -63.01623, mean: -0.02615
[32m[0906 19-47-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10634, current rewards: -57.54698, mean: -0.02339
[32m[0906 19-47-12 @Agent.py:117][0m Average action selection time: 0.1064
[32m[0906 19-47-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-47-13 @MBExp.py:227][0m Rewards obtained: [-53.11889379450163], Lows: [143], Highs: [51], Total time: 17250.861902
[32m[0906 19-49-45 @MBExp.py:144][0m ####################################################################
[32m[0906 19-49-45 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 19-49-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10804, current rewards: -6.70463, mean: -0.67046
[32m[0906 19-49-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10986, current rewards: -1.80385, mean: -0.03006
[32m[0906 19-49-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10955, current rewards: 2.70799, mean: 0.02462
[32m[0906 19-50-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10957, current rewards: 7.21703, mean: 0.04511
[32m[0906 19-50-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10959, current rewards: 11.73074, mean: 0.05586
[32m[0906 19-50-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10951, current rewards: 16.24225, mean: 0.06247
[32m[0906 19-50-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10941, current rewards: 20.75313, mean: 0.06695
[32m[0906 19-50-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10946, current rewards: 24.91396, mean: 0.06921
[32m[0906 19-50-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10945, current rewards: 29.36820, mean: 0.07163
[32m[0906 19-50-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10944, current rewards: 33.83577, mean: 0.07356
[32m[0906 19-50-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10947, current rewards: 38.30092, mean: 0.07510
[32m[0906 19-50-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10959, current rewards: 26.39873, mean: 0.04714
[32m[0906 19-50-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10971, current rewards: -7.22749, mean: -0.01185
[32m[0906 19-50-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10949, current rewards: -46.61013, mean: -0.07062
[32m[0906 19-51-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10938, current rewards: -77.27614, mean: -0.10884
[32m[0906 19-51-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10924, current rewards: -113.62665, mean: -0.14951
[32m[0906 19-51-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10940, current rewards: -153.50271, mean: -0.18951
[32m[0906 19-51-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10948, current rewards: -184.59891, mean: -0.21465
[32m[0906 19-51-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10993, current rewards: -216.67371, mean: -0.23810
[32m[0906 19-51-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11002, current rewards: -256.73635, mean: -0.26743
[32m[0906 19-51-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11005, current rewards: -296.92220, mean: -0.29398
[32m[0906 19-51-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11006, current rewards: -342.64946, mean: -0.32325
[32m[0906 19-51-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10989, current rewards: -371.17452, mean: -0.33439
[32m[0906 19-51-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10968, current rewards: -365.42123, mean: -0.31502
[32m[0906 19-51-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10938, current rewards: -359.46279, mean: -0.29708
[32m[0906 19-52-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10909, current rewards: -353.73136, mean: -0.28074
[32m[0906 19-52-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10881, current rewards: -348.00048, mean: -0.26565
[32m[0906 19-52-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10859, current rewards: -342.27717, mean: -0.25167
[32m[0906 19-52-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10841, current rewards: -372.94634, mean: -0.26450
[32m[0906 19-52-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10823, current rewards: -403.90266, mean: -0.27665
[32m[0906 19-52-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10804, current rewards: -396.36669, mean: -0.26249
[32m[0906 19-52-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10786, current rewards: -388.81476, mean: -0.24924
[32m[0906 19-52-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10770, current rewards: -380.56621, mean: -0.23638
[32m[0906 19-52-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10753, current rewards: -373.02383, mean: -0.22471
[32m[0906 19-52-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10739, current rewards: -365.48251, mean: -0.21373
[32m[0906 19-52-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10724, current rewards: -357.94011, mean: -0.20338
[32m[0906 19-53-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10751, current rewards: -403.90745, mean: -0.22315
[32m[0906 19-53-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10759, current rewards: -429.78565, mean: -0.23107
[32m[0906 19-53-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10745, current rewards: -424.74310, mean: -0.22238
[32m[0906 19-53-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10733, current rewards: -419.69397, mean: -0.21413
[32m[0906 19-53-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10724, current rewards: -414.42463, mean: -0.20618
[32m[0906 19-53-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10720, current rewards: -407.29201, mean: -0.19771
[32m[0906 19-53-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10717, current rewards: -401.62666, mean: -0.19034
[32m[0906 19-53-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10715, current rewards: -395.95110, mean: -0.18331
[32m[0906 19-53-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10711, current rewards: -390.27941, mean: -0.17660
[32m[0906 19-53-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10708, current rewards: -384.60701, mean: -0.17018
[32m[0906 19-53-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10707, current rewards: -378.93737, mean: -0.16404
[32m[0906 19-53-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10703, current rewards: -373.26544, mean: -0.15816
[32m[0906 19-54-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10707, current rewards: -367.51798, mean: -0.15250
[32m[0906 19-54-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10712, current rewards: -372.57419, mean: -0.15145
[32m[0906 19-54-13 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 19-54-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-54-14 @MBExp.py:227][0m Rewards obtained: [-368.75934029257394], Lows: [311], Highs: [13], Total time: 17519.554906
[32m[0906 19-56-48 @MBExp.py:144][0m ####################################################################
[32m[0906 19-56-48 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 19-56-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11684, current rewards: -14.00000, mean: -1.40000
[32m[0906 19-56-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11885, current rewards: -80.03765, mean: -1.33396
[32m[0906 19-57-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11636, current rewards: -133.52390, mean: -1.21385
[32m[0906 19-57-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11413, current rewards: -127.10308, mean: -0.79439
[32m[0906 19-57-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11292, current rewards: -120.77745, mean: -0.57513
[32m[0906 19-57-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11231, current rewards: -114.47284, mean: -0.44028
[32m[0906 19-57-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11179, current rewards: -107.80209, mean: -0.34775
[32m[0906 19-57-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11139, current rewards: -110.87239, mean: -0.30798
[32m[0906 19-57-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11133, current rewards: -104.72280, mean: -0.25542
[32m[0906 19-57-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11114, current rewards: -98.57387, mean: -0.21429
[32m[0906 19-57-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11094, current rewards: -92.42140, mean: -0.18122
[32m[0906 19-57-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11081, current rewards: -86.27099, mean: -0.15406
[32m[0906 19-57-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11047, current rewards: -80.12050, mean: -0.13135
[32m[0906 19-58-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11009, current rewards: -73.96780, mean: -0.11207
[32m[0906 19-58-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10984, current rewards: -67.81394, mean: -0.09551
[32m[0906 19-58-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10954, current rewards: -72.85814, mean: -0.09587
[32m[0906 19-58-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10930, current rewards: -66.91504, mean: -0.08261
[32m[0906 19-58-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10920, current rewards: -60.96068, mean: -0.07088
[32m[0906 19-58-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10925, current rewards: -55.00540, mean: -0.06045
[32m[0906 19-58-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10913, current rewards: -49.05212, mean: -0.05110
[32m[0906 19-58-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10897, current rewards: -43.10036, mean: -0.04267
[32m[0906 19-58-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10880, current rewards: -37.15140, mean: -0.03505
[32m[0906 19-58-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10866, current rewards: -31.19841, mean: -0.02811
[32m[0906 19-58-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10852, current rewards: -25.47957, mean: -0.02197
[32m[0906 19-58-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10827, current rewards: -19.42610, mean: -0.01605
[32m[0906 19-59-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10803, current rewards: -13.25288, mean: -0.01052
[32m[0906 19-59-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10784, current rewards: -7.08305, mean: -0.00541
[32m[0906 19-59-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10763, current rewards: -0.91156, mean: -0.00067
[32m[0906 19-59-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10744, current rewards: -10.35171, mean: -0.00734
[32m[0906 19-59-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10727, current rewards: -10.04304, mean: -0.00688
[32m[0906 19-59-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10711, current rewards: -12.48018, mean: -0.00827
[32m[0906 19-59-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10694, current rewards: -12.97216, mean: -0.00832
[32m[0906 19-59-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10680, current rewards: -13.03028, mean: -0.00809
[32m[0906 19-59-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10667, current rewards: -13.35666, mean: -0.00805
[32m[0906 19-59-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10655, current rewards: -13.50893, mean: -0.00790
[32m[0906 19-59-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10644, current rewards: -13.73559, mean: -0.00780
[32m[0906 20-00-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10632, current rewards: -16.14033, mean: -0.00892
[32m[0906 20-00-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10622, current rewards: -16.40413, mean: -0.00882
[32m[0906 20-00-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10613, current rewards: -16.63926, mean: -0.00871
[32m[0906 20-00-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10603, current rewards: -16.93790, mean: -0.00864
[32m[0906 20-00-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10594, current rewards: -11.98312, mean: -0.00596
[32m[0906 20-00-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10588, current rewards: -4.57368, mean: -0.00222
[32m[0906 20-00-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10590, current rewards: -10.88444, mean: -0.00516
[32m[0906 20-00-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10590, current rewards: -5.44751, mean: -0.00252
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10591, current rewards: -0.00927, mean: -0.00000
[32m[0906 20-00-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10591, current rewards: 5.42797, mean: 0.00240
[32m[0906 20-00-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10590, current rewards: 10.86258, mean: 0.00470
[32m[0906 20-00-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10590, current rewards: 16.30212, mean: 0.00691
[32m[0906 20-01-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10592, current rewards: 22.17278, mean: 0.00920
[32m[0906 20-01-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10598, current rewards: 27.53047, mean: 0.01119
[32m[0906 20-01-13 @Agent.py:117][0m Average action selection time: 0.1060
[32m[0906 20-01-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-01-14 @MBExp.py:227][0m Rewards obtained: [21.759236404814086], Lows: [141], Highs: [13], Total time: 17785.470206
[32m[0906 20-03-50 @MBExp.py:144][0m ####################################################################
[32m[0906 20-03-50 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 20-03-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10836, current rewards: 1.01379, mean: 0.10138
[32m[0906 20-03-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10965, current rewards: 6.84407, mean: 0.11407
[32m[0906 20-04-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10947, current rewards: 12.67675, mean: 0.11524
[32m[0906 20-04-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10917, current rewards: 18.51096, mean: 0.11569
[32m[0906 20-04-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10933, current rewards: 17.24053, mean: 0.08210
[32m[0906 20-04-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10922, current rewards: 22.31608, mean: 0.08583
[32m[0906 20-04-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10920, current rewards: 26.98820, mean: 0.08706
[32m[0906 20-04-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10932, current rewards: 32.15637, mean: 0.08932
[32m[0906 20-04-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10931, current rewards: 37.32524, mean: 0.09104
[32m[0906 20-04-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10932, current rewards: 42.48769, mean: 0.09236
[32m[0906 20-04-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10938, current rewards: 47.65531, mean: 0.09344
[32m[0906 20-04-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10936, current rewards: 42.56193, mean: 0.07600
[32m[0906 20-04-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10930, current rewards: 48.24051, mean: 0.07908
[32m[0906 20-05-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10903, current rewards: 53.91996, mean: 0.08170
[32m[0906 20-05-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10875, current rewards: 59.59933, mean: 0.08394
[32m[0906 20-05-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10857, current rewards: 66.43018, mean: 0.08741
[32m[0906 20-05-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10840, current rewards: 72.42182, mean: 0.08941
[32m[0906 20-05-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10827, current rewards: 78.41242, mean: 0.09118
[32m[0906 20-05-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10823, current rewards: 84.40731, mean: 0.09276
[32m[0906 20-05-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10822, current rewards: 90.40199, mean: 0.09417
[32m[0906 20-05-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10808, current rewards: 96.39747, mean: 0.09544
[32m[0906 20-05-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10800, current rewards: 102.39280, mean: 0.09660
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10792, current rewards: 108.38295, mean: 0.09764
[32m[0906 20-05-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10822, current rewards: 56.69868, mean: 0.04888
[32m[0906 20-06-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10810, current rewards: 44.23833, mean: 0.03656
[32m[0906 20-06-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10787, current rewards: 49.70169, mean: 0.03945
[32m[0906 20-06-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10765, current rewards: 55.16003, mean: 0.04211
[32m[0906 20-06-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10746, current rewards: 60.62993, mean: 0.04458
[32m[0906 20-06-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10729, current rewards: 66.09515, mean: 0.04688
[32m[0906 20-06-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10711, current rewards: 71.56247, mean: 0.04902
[32m[0906 20-06-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10696, current rewards: 77.02469, mean: 0.05101
[32m[0906 20-06-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10683, current rewards: 82.85793, mean: 0.05311
[32m[0906 20-06-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10672, current rewards: 88.36988, mean: 0.05489
[32m[0906 20-06-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10658, current rewards: 93.91188, mean: 0.05657
[32m[0906 20-06-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10646, current rewards: 99.45668, mean: 0.05816
[32m[0906 20-06-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10634, current rewards: 105.00237, mean: 0.05966
[32m[0906 20-07-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10622, current rewards: 110.54812, mean: 0.06108
[32m[0906 20-07-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10612, current rewards: 116.09156, mean: 0.06241
[32m[0906 20-07-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10602, current rewards: 121.64574, mean: 0.06369
[32m[0906 20-07-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10593, current rewards: 127.32384, mean: 0.06496
[32m[0906 20-07-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10584, current rewards: 133.15645, mean: 0.06625
[32m[0906 20-07-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10576, current rewards: 128.50470, mean: 0.06238
[32m[0906 20-07-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10575, current rewards: 134.31769, mean: 0.06366
[32m[0906 20-07-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10577, current rewards: 140.13475, mean: 0.06488
[32m[0906 20-07-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10577, current rewards: 145.95966, mean: 0.06605
[32m[0906 20-07-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10577, current rewards: 151.78038, mean: 0.06716
[32m[0906 20-07-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10578, current rewards: 157.60352, mean: 0.06823
[32m[0906 20-08-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10576, current rewards: 163.28238, mean: 0.06919
[32m[0906 20-08-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10575, current rewards: 168.01198, mean: 0.06971
[32m[0906 20-08-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10582, current rewards: 173.49847, mean: 0.07053
[32m[0906 20-08-16 @Agent.py:117][0m Average action selection time: 0.1059
[32m[0906 20-08-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-08-16 @MBExp.py:227][0m Rewards obtained: [177.8930107433636], Lows: [44], Highs: [11], Total time: 18050.959493000002
[32m[0906 20-10-54 @MBExp.py:144][0m ####################################################################
[32m[0906 20-10-54 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 20-10-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10686, current rewards: -14.00000, mean: -1.40000
[32m[0906 20-11-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10817, current rewards: -114.00000, mean: -1.90000
[32m[0906 20-11-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10850, current rewards: -214.00000, mean: -1.94545
[32m[0906 20-11-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10840, current rewards: -314.00000, mean: -1.96250
[32m[0906 20-11-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10837, current rewards: -414.00000, mean: -1.97143
[32m[0906 20-11-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10852, current rewards: -514.00000, mean: -1.97692
[32m[0906 20-11-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10851, current rewards: -614.00000, mean: -1.98065
[32m[0906 20-11-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10853, current rewards: -714.00000, mean: -1.98333
[32m[0906 20-11-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10861, current rewards: -814.00000, mean: -1.98537
[32m[0906 20-11-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10859, current rewards: -914.00000, mean: -1.98696
[32m[0906 20-11-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10857, current rewards: -1014.00000, mean: -1.98824
[32m[0906 20-11-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10864, current rewards: -1114.00000, mean: -1.98929
[32m[0906 20-12-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10856, current rewards: -1214.00000, mean: -1.99016
[32m[0906 20-12-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10828, current rewards: -1314.00000, mean: -1.99091
[32m[0906 20-12-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10807, current rewards: -1414.00000, mean: -1.99155
[32m[0906 20-12-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10784, current rewards: -1514.00000, mean: -1.99211
[32m[0906 20-12-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10764, current rewards: -1614.00000, mean: -1.99259
[32m[0906 20-12-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10752, current rewards: -1714.00000, mean: -1.99302
[32m[0906 20-12-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10748, current rewards: -1814.00000, mean: -1.99341
[32m[0906 20-12-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10746, current rewards: -1914.00000, mean: -1.99375
[32m[0906 20-12-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10737, current rewards: -2014.00000, mean: -1.99406
[32m[0906 20-12-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10725, current rewards: -2114.00000, mean: -1.99434
[32m[0906 20-12-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10712, current rewards: -2214.00000, mean: -1.99459
[32m[0906 20-12-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10708, current rewards: -2314.00000, mean: -1.99483
[32m[0906 20-13-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10689, current rewards: -2414.00000, mean: -1.99504
[32m[0906 20-13-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10667, current rewards: -2514.00000, mean: -1.99524
[32m[0906 20-13-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10649, current rewards: -2614.00000, mean: -1.99542
[32m[0906 20-13-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10632, current rewards: -2714.00000, mean: -1.99559
[32m[0906 20-13-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10614, current rewards: -2814.00000, mean: -1.99574
[32m[0906 20-13-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10600, current rewards: -2914.00000, mean: -1.99589
[32m[0906 20-13-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10585, current rewards: -3014.00000, mean: -1.99603
[32m[0906 20-13-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10571, current rewards: -3114.00000, mean: -1.99615
[32m[0906 20-13-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10560, current rewards: -3214.00000, mean: -1.99627
[32m[0906 20-13-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10548, current rewards: -3314.00000, mean: -1.99639
[32m[0906 20-13-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10537, current rewards: -3414.00000, mean: -1.99649
[32m[0906 20-14-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10528, current rewards: -3514.00000, mean: -1.99659
[32m[0906 20-14-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10517, current rewards: -3614.00000, mean: -1.99669
[32m[0906 20-14-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10506, current rewards: -3714.00000, mean: -1.99677
[32m[0906 20-14-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10498, current rewards: -3814.00000, mean: -1.99686
[32m[0906 20-14-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10490, current rewards: -3914.00000, mean: -1.99694
[32m[0906 20-14-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10482, current rewards: -4014.00000, mean: -1.99701
[32m[0906 20-14-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10474, current rewards: -4114.00000, mean: -1.99709
[32m[0906 20-14-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10467, current rewards: -4214.00000, mean: -1.99716
[32m[0906 20-14-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10467, current rewards: -4314.00000, mean: -1.99722
[32m[0906 20-14-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10467, current rewards: -4414.00000, mean: -1.99729
[32m[0906 20-14-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10469, current rewards: -4514.00000, mean: -1.99735
[32m[0906 20-14-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10469, current rewards: -4614.00000, mean: -1.99740
[32m[0906 20-15-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10470, current rewards: -4714.00000, mean: -1.99746
[32m[0906 20-15-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10470, current rewards: -4814.00000, mean: -1.99751
[32m[0906 20-15-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10470, current rewards: -4914.00000, mean: -1.99756
[32m[0906 20-15-16 @Agent.py:117][0m Average action selection time: 0.1048
[32m[0906 20-15-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-15-17 @MBExp.py:227][0m Rewards obtained: [-4994], Lows: [2494], Highs: [6], Total time: 18313.653636000003
[32m[0906 20-17-56 @MBExp.py:144][0m ####################################################################
[32m[0906 20-17-56 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 20-17-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11718, current rewards: -15.00000, mean: -1.50000
[32m[0906 20-18-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10973, current rewards: -33.18896, mean: -0.55315
[32m[0906 20-18-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10881, current rewards: -26.63322, mean: -0.24212
[32m[0906 20-18-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10882, current rewards: -20.07292, mean: -0.12546
[32m[0906 20-18-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10854, current rewards: -13.51213, mean: -0.06434
[32m[0906 20-18-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10846, current rewards: -6.93898, mean: -0.02669
[32m[0906 20-18-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10847, current rewards: 0.69298, mean: 0.00224
[32m[0906 20-18-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10840, current rewards: 7.22215, mean: 0.02006
[32m[0906 20-18-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10836, current rewards: 13.75190, mean: 0.03354
[32m[0906 20-18-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10842, current rewards: 20.27439, mean: 0.04407
[32m[0906 20-18-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10839, current rewards: 26.80279, mean: 0.05255
[32m[0906 20-18-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10836, current rewards: 33.32081, mean: 0.05950
[32m[0906 20-19-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10840, current rewards: 39.85608, mean: 0.06534
[32m[0906 20-19-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10820, current rewards: 46.37905, mean: 0.07027
[32m[0906 20-19-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10820, current rewards: 39.58480, mean: 0.05575
[32m[0906 20-19-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10801, current rewards: 45.09079, mean: 0.05933
[32m[0906 20-19-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10780, current rewards: 50.56080, mean: 0.06242
[32m[0906 20-19-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10759, current rewards: 56.03007, mean: 0.06515
[32m[0906 20-19-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10753, current rewards: 61.50017, mean: 0.06758
[32m[0906 20-19-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10757, current rewards: 66.97133, mean: 0.06976
[32m[0906 20-19-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10740, current rewards: 72.44104, mean: 0.07172
[32m[0906 20-19-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10733, current rewards: 77.91088, mean: 0.07350
[32m[0906 20-19-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10721, current rewards: 83.38276, mean: 0.07512
[32m[0906 20-20-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10713, current rewards: 88.85585, mean: 0.07660
[32m[0906 20-20-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10700, current rewards: 94.32500, mean: 0.07795
[32m[0906 20-20-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10679, current rewards: 99.79131, mean: 0.07920
[32m[0906 20-20-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10660, current rewards: 105.26196, mean: 0.08035
[32m[0906 20-20-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10644, current rewards: 110.73113, mean: 0.08142
[32m[0906 20-20-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10636, current rewards: 84.21090, mean: 0.05972
[32m[0906 20-20-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10621, current rewards: 88.50931, mean: 0.06062
[32m[0906 20-20-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10608, current rewards: 95.13699, mean: 0.06300
[32m[0906 20-20-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10594, current rewards: 101.72905, mean: 0.06521
[32m[0906 20-20-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10582, current rewards: 108.26653, mean: 0.06725
[32m[0906 20-20-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10571, current rewards: 114.82262, mean: 0.06917
[32m[0906 20-20-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10560, current rewards: 121.36396, mean: 0.07097
[32m[0906 20-21-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10549, current rewards: 127.91049, mean: 0.07268
[32m[0906 20-21-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10541, current rewards: 134.45276, mean: 0.07428
[32m[0906 20-21-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10531, current rewards: 140.99964, mean: 0.07581
[32m[0906 20-21-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10521, current rewards: 147.51804, mean: 0.07723
[32m[0906 20-21-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10514, current rewards: 153.93570, mean: 0.07854
[32m[0906 20-21-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10507, current rewards: 158.08867, mean: 0.07865
[32m[0906 20-21-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10498, current rewards: 174.48861, mean: 0.08470
[32m[0906 20-21-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10492, current rewards: 190.76150, mean: 0.09041
[32m[0906 20-21-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10487, current rewards: 207.15073, mean: 0.09590
[32m[0906 20-21-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10488, current rewards: 223.37866, mean: 0.10108
[32m[0906 20-21-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10489, current rewards: 239.69533, mean: 0.10606
[32m[0906 20-21-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10490, current rewards: 256.02259, mean: 0.11083
[32m[0906 20-22-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10490, current rewards: 274.30644, mean: 0.11623
[32m[0906 20-22-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10491, current rewards: 290.53207, mean: 0.12055
[32m[0906 20-22-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10493, current rewards: 306.55110, mean: 0.12461
[32m[0906 20-22-19 @Agent.py:117][0m Average action selection time: 0.1050
[32m[0906 20-22-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-22-19 @MBExp.py:227][0m Rewards obtained: [319.2851088908475], Lows: [34], Highs: [20], Total time: 18576.853289000002
[32m[0906 20-25-02 @MBExp.py:144][0m ####################################################################
[32m[0906 20-25-02 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 20-25-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10791, current rewards: -6.07693, mean: -0.60769
[32m[0906 20-25-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10910, current rewards: -2.59416, mean: -0.04324
[32m[0906 20-25-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10857, current rewards: 2.82360, mean: 0.02567
[32m[0906 20-25-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10843, current rewards: 8.23850, mean: 0.05149
[32m[0906 20-25-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10843, current rewards: 13.65106, mean: 0.06501
[32m[0906 20-25-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10834, current rewards: 18.65581, mean: 0.07175
[32m[0906 20-25-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10831, current rewards: 24.05722, mean: 0.07760
[32m[0906 20-25-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10843, current rewards: 29.45430, mean: 0.08182
[32m[0906 20-25-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10837, current rewards: 34.84826, mean: 0.08500
[32m[0906 20-25-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10831, current rewards: 40.24478, mean: 0.08749
[32m[0906 20-25-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10840, current rewards: 45.64155, mean: 0.08949
[32m[0906 20-26-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10837, current rewards: 51.04138, mean: 0.09115
[32m[0906 20-26-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10833, current rewards: 56.43308, mean: 0.09251
[32m[0906 20-26-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10849, current rewards: 15.51413, mean: 0.02351
[32m[0906 20-26-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10832, current rewards: -42.14979, mean: -0.05937
[32m[0906 20-26-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10830, current rewards: -93.89486, mean: -0.12355
[32m[0906 20-26-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10830, current rewards: -149.80376, mean: -0.18494
[32m[0906 20-26-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10819, current rewards: -207.01142, mean: -0.24071
[32m[0906 20-26-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10829, current rewards: -274.42887, mean: -0.30157
[32m[0906 20-26-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10840, current rewards: -335.41193, mean: -0.34939
[32m[0906 20-26-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10830, current rewards: -400.75470, mean: -0.39679
[32m[0906 20-26-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10823, current rewards: -463.74808, mean: -0.43750
[32m[0906 20-27-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10821, current rewards: -526.19840, mean: -0.47405
[32m[0906 20-27-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10812, current rewards: -570.63569, mean: -0.49193
[32m[0906 20-27-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10791, current rewards: -564.02733, mean: -0.46614
[32m[0906 20-27-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10767, current rewards: -557.42001, mean: -0.44240
[32m[0906 20-27-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10745, current rewards: -550.80724, mean: -0.42046
[32m[0906 20-27-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10723, current rewards: -544.19617, mean: -0.40014
[32m[0906 20-27-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10707, current rewards: -537.59269, mean: -0.38127
[32m[0906 20-27-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10690, current rewards: -530.89749, mean: -0.36363
[32m[0906 20-27-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10673, current rewards: -524.26269, mean: -0.34719
[32m[0906 20-27-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10658, current rewards: -517.62885, mean: -0.33181
[32m[0906 20-27-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10642, current rewards: -515.52676, mean: -0.32020
[32m[0906 20-27-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10630, current rewards: -524.81323, mean: -0.31615
[32m[0906 20-28-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10618, current rewards: -518.38991, mean: -0.30315
[32m[0906 20-28-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10605, current rewards: -511.96256, mean: -0.29089
[32m[0906 20-28-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10594, current rewards: -505.54030, mean: -0.27930
[32m[0906 20-28-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10584, current rewards: -498.66101, mean: -0.26810
[32m[0906 20-28-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10572, current rewards: -492.03332, mean: -0.25761
[32m[0906 20-28-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10562, current rewards: -485.66234, mean: -0.24779
[32m[0906 20-28-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10554, current rewards: -479.28173, mean: -0.23845
[32m[0906 20-28-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10545, current rewards: -544.59317, mean: -0.26437
[32m[0906 20-28-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10536, current rewards: -629.80486, mean: -0.29849
[32m[0906 20-28-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10527, current rewards: -715.01359, mean: -0.33102
[32m[0906 20-28-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10523, current rewards: -800.22151, mean: -0.36209
[32m[0906 20-29-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10523, current rewards: -885.42931, mean: -0.39178
[32m[0906 20-29-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10524, current rewards: -970.82448, mean: -0.42027
[32m[0906 20-29-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10523, current rewards: -1054.16108, mean: -0.44668
[32m[0906 20-29-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10523, current rewards: -1139.58517, mean: -0.47286
[32m[0906 20-29-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10523, current rewards: -1225.00564, mean: -0.49797
[32m[0906 20-29-26 @Agent.py:117][0m Average action selection time: 0.1052
[32m[0906 20-29-26 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-29-26 @MBExp.py:227][0m Rewards obtained: [-1292.5101559122309], Lows: [748], Highs: [20], Total time: 18840.727120000003
[32m[0906 20-32-09 @MBExp.py:144][0m ####################################################################
[32m[0906 20-32-09 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 20-32-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10823, current rewards: -14.00000, mean: -1.40000
[32m[0906 20-32-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10927, current rewards: -16.38930, mean: -0.27316
[32m[0906 20-32-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10880, current rewards: 1.96245, mean: 0.01784
[32m[0906 20-32-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10862, current rewards: 20.33490, mean: 0.12709
[32m[0906 20-32-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10863, current rewards: 18.15042, mean: 0.08643
[32m[0906 20-32-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10858, current rewards: 24.45815, mean: 0.09407
[32m[0906 20-32-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10857, current rewards: 37.29417, mean: 0.12030
[32m[0906 20-32-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10862, current rewards: 50.07033, mean: 0.13908
[32m[0906 20-32-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10853, current rewards: 62.90470, mean: 0.15343
[32m[0906 20-32-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10846, current rewards: 75.69476, mean: 0.16455
[32m[0906 20-33-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10848, current rewards: 88.49345, mean: 0.17352
[32m[0906 20-33-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10845, current rewards: 101.31314, mean: 0.18092
[32m[0906 20-33-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10850, current rewards: 97.27236, mean: 0.15946
[32m[0906 20-33-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10836, current rewards: 103.02893, mean: 0.15610
[32m[0906 20-33-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10812, current rewards: 108.78260, mean: 0.15321
[32m[0906 20-33-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10791, current rewards: 114.53834, mean: 0.15071
[32m[0906 20-33-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10775, current rewards: 120.29186, mean: 0.14851
[32m[0906 20-33-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10758, current rewards: 126.04411, mean: 0.14656
[32m[0906 20-33-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10756, current rewards: 131.79688, mean: 0.14483
[32m[0906 20-33-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10761, current rewards: 132.24056, mean: 0.13775
[32m[0906 20-33-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10747, current rewards: 139.70064, mean: 0.13832
[32m[0906 20-34-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10735, current rewards: 147.23215, mean: 0.13890
[32m[0906 20-34-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10725, current rewards: 154.62422, mean: 0.13930
[32m[0906 20-34-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10713, current rewards: 162.01492, mean: 0.13967
[32m[0906 20-34-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10700, current rewards: 169.41291, mean: 0.14001
[32m[0906 20-34-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10678, current rewards: 176.80781, mean: 0.14032
[32m[0906 20-34-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10660, current rewards: 184.19700, mean: 0.14061
[32m[0906 20-34-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10639, current rewards: 191.58672, mean: 0.14087
[32m[0906 20-34-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10621, current rewards: 193.02595, mean: 0.13690
[32m[0906 20-34-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10606, current rewards: 199.17456, mean: 0.13642
[32m[0906 20-34-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10590, current rewards: 205.89726, mean: 0.13636
[32m[0906 20-34-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10578, current rewards: 212.62814, mean: 0.13630
[32m[0906 20-35-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10565, current rewards: 219.33955, mean: 0.13624
[32m[0906 20-35-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10553, current rewards: 226.05386, mean: 0.13618
[32m[0906 20-35-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10541, current rewards: 229.36603, mean: 0.13413
[32m[0906 20-35-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10531, current rewards: 153.91017, mean: 0.08745
[32m[0906 20-35-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10521, current rewards: 68.42972, mean: 0.03781
[32m[0906 20-35-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10512, current rewards: -17.03862, mean: -0.00916
[32m[0906 20-35-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10503, current rewards: -102.50765, mean: -0.05367
[32m[0906 20-35-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10494, current rewards: -187.97657, mean: -0.09591
[32m[0906 20-35-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10487, current rewards: -271.37119, mean: -0.13501
[32m[0906 20-35-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10481, current rewards: -356.84350, mean: -0.17323
[32m[0906 20-35-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10474, current rewards: -442.31456, mean: -0.20963
[32m[0906 20-35-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10465, current rewards: -527.78644, mean: -0.24435
[32m[0906 20-36-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10459, current rewards: -558.35149, mean: -0.25265
[32m[0906 20-36-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10461, current rewards: -552.77310, mean: -0.24459
[32m[0906 20-36-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10463, current rewards: -547.30811, mean: -0.23693
[32m[0906 20-36-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10465, current rewards: -541.84664, mean: -0.22960
[32m[0906 20-36-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10465, current rewards: -536.37966, mean: -0.22256
[32m[0906 20-36-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10466, current rewards: -530.91616, mean: -0.21582
[32m[0906 20-36-32 @Agent.py:117][0m Average action selection time: 0.1047
[32m[0906 20-36-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-36-32 @MBExp.py:227][0m Rewards obtained: [-526.5514151516452], Lows: [428], Highs: [22], Total time: 19103.243338000004
[32m[0906 20-39-18 @MBExp.py:144][0m ####################################################################
[32m[0906 20-39-18 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 20-39-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11484, current rewards: -9.50732, mean: -0.95073
[32m[0906 20-39-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.12338, current rewards: -77.51523, mean: -1.29192
[32m[0906 20-39-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.12476, current rewards: -143.58086, mean: -1.30528
[32m[0906 20-39-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.12519, current rewards: -206.03694, mean: -1.28773
[32m[0906 20-39-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.12633, current rewards: -275.01906, mean: -1.30961
[32m[0906 20-39-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.12645, current rewards: -329.62430, mean: -1.26779
[32m[0906 20-39-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.12628, current rewards: -394.66025, mean: -1.27310
[32m[0906 20-40-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.12571, current rewards: -456.77906, mean: -1.26883
[32m[0906 20-40-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.12500, current rewards: -524.50634, mean: -1.27928
[32m[0906 20-40-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.12517, current rewards: -580.23985, mean: -1.26139
[32m[0906 20-40-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.12533, current rewards: -647.35623, mean: -1.26933
[32m[0906 20-40-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.12454, current rewards: -700.32557, mean: -1.25058
[32m[0906 20-40-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.12314, current rewards: -756.10373, mean: -1.23951
[32m[0906 20-40-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.12190, current rewards: -811.91716, mean: -1.23018
[32m[0906 20-40-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.12088, current rewards: -867.91536, mean: -1.22242
[32m[0906 20-40-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.12007, current rewards: -924.04160, mean: -1.21584
[32m[0906 20-40-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11953, current rewards: -980.30204, mean: -1.21025
[32m[0906 20-41-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11917, current rewards: -1036.37854, mean: -1.20509
[32m[0906 20-41-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11860, current rewards: -1092.46110, mean: -1.20051
[32m[0906 20-41-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11805, current rewards: -1148.54114, mean: -1.19640
[32m[0906 20-41-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11758, current rewards: -1204.81107, mean: -1.19288
[32m[0906 20-41-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11718, current rewards: -1260.77939, mean: -1.18941
[32m[0906 20-41-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11670, current rewards: -1271.64640, mean: -1.14563
[32m[0906 20-41-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11609, current rewards: -1265.94499, mean: -1.09133
[32m[0906 20-41-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11549, current rewards: -1260.25752, mean: -1.04154
[32m[0906 20-41-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11495, current rewards: -1254.56032, mean: -0.99568
[32m[0906 20-41-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11447, current rewards: -1248.86917, mean: -0.95334
[32m[0906 20-41-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11400, current rewards: -1243.17526, mean: -0.91410
[32m[0906 20-41-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11356, current rewards: -1238.25924, mean: -0.87820
[32m[0906 20-42-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11317, current rewards: -1233.07164, mean: -0.84457
[32m[0906 20-42-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11281, current rewards: -1227.76265, mean: -0.81309
[32m[0906 20-42-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11247, current rewards: -1221.96914, mean: -0.78331
[32m[0906 20-42-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11212, current rewards: -1227.10181, mean: -0.76218
[32m[0906 20-42-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11180, current rewards: -1222.08463, mean: -0.73620
[32m[0906 20-42-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11149, current rewards: -1217.07013, mean: -0.71174
[32m[0906 20-42-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11121, current rewards: -1212.05158, mean: -0.68867
[32m[0906 20-42-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11096, current rewards: -1206.05124, mean: -0.66633
[32m[0906 20-42-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11070, current rewards: -1199.59242, mean: -0.64494
[32m[0906 20-42-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11046, current rewards: -1193.13360, mean: -0.62468
[32m[0906 20-42-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11024, current rewards: -1186.67477, mean: -0.60545
[32m[0906 20-43-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11003, current rewards: -1235.54560, mean: -0.61470
[32m[0906 20-43-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10981, current rewards: -1285.54560, mean: -0.62405
[32m[0906 20-43-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10961, current rewards: -1335.54560, mean: -0.63296
[32m[0906 20-43-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10943, current rewards: -1385.54560, mean: -0.64146
[32m[0906 20-43-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10932, current rewards: -1435.54560, mean: -0.64957
[32m[0906 20-43-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10923, current rewards: -1485.54560, mean: -0.65732
[32m[0906 20-43-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10914, current rewards: -1535.54560, mean: -0.66474
[32m[0906 20-43-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10904, current rewards: -1585.54560, mean: -0.67184
[32m[0906 20-43-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10898, current rewards: -1635.54560, mean: -0.67865
[32m[0906 20-43-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10888, current rewards: -1652.67723, mean: -0.67182
[32m[0906 20-43-51 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 20-43-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-43-51 @MBExp.py:227][0m Rewards obtained: [-1648.852739381112], Lows: [681], Highs: [475], Total time: 19376.215924000004
[32m[0906 20-46-40 @MBExp.py:144][0m ####################################################################
[32m[0906 20-46-40 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 20-46-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12122, current rewards: -5.98500, mean: -0.59850
[32m[0906 20-46-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11950, current rewards: -71.21278, mean: -1.18688
[32m[0906 20-46-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11969, current rewards: -129.00414, mean: -1.17276
[32m[0906 20-46-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.12155, current rewards: -193.02722, mean: -1.20642
[32m[0906 20-47-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.12170, current rewards: -249.81705, mean: -1.18960
[32m[0906 20-47-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.12139, current rewards: -304.06462, mean: -1.16948
[32m[0906 20-47-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11968, current rewards: -350.45859, mean: -1.13051
[32m[0906 20-47-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11897, current rewards: -423.88365, mean: -1.17745
[32m[0906 20-47-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11937, current rewards: -498.25552, mean: -1.21526
[32m[0906 20-47-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11978, current rewards: -549.68388, mean: -1.19496
[32m[0906 20-47-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11957, current rewards: -591.85606, mean: -1.16050
[32m[0906 20-47-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11819, current rewards: -576.04570, mean: -1.02865
[32m[0906 20-47-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11706, current rewards: -548.02656, mean: -0.89840
[32m[0906 20-47-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11612, current rewards: -519.63682, mean: -0.78733
[32m[0906 20-48-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11526, current rewards: -491.67261, mean: -0.69250
[32m[0906 20-48-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11476, current rewards: -463.28610, mean: -0.60959
[32m[0906 20-48-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11438, current rewards: -435.06704, mean: -0.53712
[32m[0906 20-48-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11386, current rewards: -407.04635, mean: -0.47331
[32m[0906 20-48-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11336, current rewards: -378.99278, mean: -0.41648
[32m[0906 20-48-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11314, current rewards: -387.74220, mean: -0.40390
[32m[0906 20-48-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11286, current rewards: -397.56426, mean: -0.39363
[32m[0906 20-48-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11246, current rewards: -361.80861, mean: -0.34133
[32m[0906 20-48-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11207, current rewards: -341.47660, mean: -0.30764
[32m[0906 20-48-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11158, current rewards: -335.49509, mean: -0.28922
[32m[0906 20-48-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11112, current rewards: -329.43531, mean: -0.27226
[32m[0906 20-48-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11074, current rewards: -323.37902, mean: -0.25665
[32m[0906 20-49-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11035, current rewards: -317.31801, mean: -0.24223
[32m[0906 20-49-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10999, current rewards: -311.49777, mean: -0.22904
[32m[0906 20-49-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10968, current rewards: -305.48913, mean: -0.21666
[32m[0906 20-49-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10939, current rewards: -299.48141, mean: -0.20512
[32m[0906 20-49-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10910, current rewards: -293.46703, mean: -0.19435
[32m[0906 20-49-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10886, current rewards: -287.44895, mean: -0.18426
[32m[0906 20-49-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10862, current rewards: -281.44354, mean: -0.17481
[32m[0906 20-49-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10840, current rewards: -275.42373, mean: -0.16592
[32m[0906 20-49-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10819, current rewards: -269.40853, mean: -0.15755
[32m[0906 20-49-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10800, current rewards: -263.16735, mean: -0.14953
[32m[0906 20-49-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10781, current rewards: -256.94801, mean: -0.14196
[32m[0906 20-50-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10764, current rewards: -250.89209, mean: -0.13489
[32m[0906 20-50-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10748, current rewards: -260.71515, mean: -0.13650
[32m[0906 20-50-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10731, current rewards: -266.04772, mean: -0.13574
[32m[0906 20-50-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10716, current rewards: -278.00102, mean: -0.13831
[32m[0906 20-50-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10703, current rewards: -291.81994, mean: -0.14166
[32m[0906 20-50-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10689, current rewards: -293.20509, mean: -0.13896
[32m[0906 20-50-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10680, current rewards: -308.98491, mean: -0.14305
[32m[0906 20-50-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10679, current rewards: -340.57047, mean: -0.15410
[32m[0906 20-50-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10682, current rewards: -372.26881, mean: -0.16472
[32m[0906 20-50-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10677, current rewards: -404.01973, mean: -0.17490
[32m[0906 20-50-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10678, current rewards: -435.49787, mean: -0.18453
[32m[0906 20-50-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10676, current rewards: -467.00038, mean: -0.19378
[32m[0906 20-51-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10679, current rewards: -498.24267, mean: -0.20254
[32m[0906 20-51-07 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 20-51-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-51-08 @MBExp.py:227][0m Rewards obtained: [-531.1326016219132], Lows: [521], Highs: [16], Total time: 19644.207809000003
[32m[0906 20-53-58 @MBExp.py:144][0m ####################################################################
[32m[0906 20-53-58 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 20-53-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11736, current rewards: -9.44686, mean: -0.94469
[32m[0906 20-54-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11445, current rewards: -39.29757, mean: -0.65496
[32m[0906 20-54-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11256, current rewards: -52.17249, mean: -0.47430
[32m[0906 20-54-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11129, current rewards: -45.01184, mean: -0.28132
[32m[0906 20-54-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11068, current rewards: -37.84413, mean: -0.18021
[32m[0906 20-54-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11015, current rewards: -30.67432, mean: -0.11798
[32m[0906 20-54-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10985, current rewards: -34.42776, mean: -0.11106
[32m[0906 20-54-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10960, current rewards: -28.92140, mean: -0.08034
[32m[0906 20-54-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10938, current rewards: -23.41147, mean: -0.05710
[32m[0906 20-54-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10929, current rewards: -17.90271, mean: -0.03892
[32m[0906 20-54-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10940, current rewards: -58.84237, mean: -0.11538
[32m[0906 20-55-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10974, current rewards: -118.42305, mean: -0.21147
[32m[0906 20-55-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10996, current rewards: -173.87764, mean: -0.28505
[32m[0906 20-55-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10958, current rewards: -256.64739, mean: -0.38886
[32m[0906 20-55-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10938, current rewards: -326.27601, mean: -0.45954
[32m[0906 20-55-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10972, current rewards: -396.06630, mean: -0.52114
[32m[0906 20-55-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10979, current rewards: -473.16104, mean: -0.58415
[32m[0906 20-55-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11009, current rewards: -545.75215, mean: -0.63460
[32m[0906 20-55-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10991, current rewards: -619.34254, mean: -0.68060
[32m[0906 20-55-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10962, current rewards: -658.91894, mean: -0.68637
[32m[0906 20-55-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10938, current rewards: -653.41738, mean: -0.64695
[32m[0906 20-55-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10919, current rewards: -647.91379, mean: -0.61124
[32m[0906 20-55-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10884, current rewards: -642.40852, mean: -0.57875
[32m[0906 20-56-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10849, current rewards: -636.90324, mean: -0.54905
[32m[0906 20-56-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10821, current rewards: -631.39923, mean: -0.52182
[32m[0906 20-56-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10793, current rewards: -625.89509, mean: -0.49674
[32m[0906 20-56-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10768, current rewards: -620.50011, mean: -0.47366
[32m[0906 20-56-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10760, current rewards: -657.67556, mean: -0.48358
[32m[0906 20-56-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10746, current rewards: -710.18197, mean: -0.50368
[32m[0906 20-56-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10727, current rewards: -766.27394, mean: -0.52485
[32m[0906 20-56-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10720, current rewards: -814.34677, mean: -0.53930
[32m[0906 20-56-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10709, current rewards: -862.64320, mean: -0.55298
[32m[0906 20-56-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10694, current rewards: -913.87730, mean: -0.56763
[32m[0906 20-56-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10686, current rewards: -949.58478, mean: -0.57204
[32m[0906 20-57-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10683, current rewards: -1017.95105, mean: -0.59529
[32m[0906 20-57-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10670, current rewards: -1059.55337, mean: -0.60202
[32m[0906 20-57-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10668, current rewards: -1113.51838, mean: -0.61520
[32m[0906 20-57-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10665, current rewards: -1149.03793, mean: -0.61776
[32m[0906 20-57-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10658, current rewards: -1212.82545, mean: -0.63499
[32m[0906 20-57-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10655, current rewards: -1261.20372, mean: -0.64347
[32m[0906 20-57-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10658, current rewards: -1318.95943, mean: -0.65620
[32m[0906 20-57-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10710, current rewards: -1360.62279, mean: -0.66050
[32m[0906 20-57-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10756, current rewards: -1405.24586, mean: -0.66599
[32m[0906 20-57-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10794, current rewards: -1451.37048, mean: -0.67193
[32m[0906 20-57-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10840, current rewards: -1488.84243, mean: -0.67368
[32m[0906 20-58-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10905, current rewards: -1512.65639, mean: -0.66932
[32m[0906 20-58-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10952, current rewards: -1557.95288, mean: -0.67444
[32m[0906 20-58-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10963, current rewards: -1580.02816, mean: -0.66950
[32m[0906 20-58-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10959, current rewards: -1574.53495, mean: -0.65333
[32m[0906 20-58-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10956, current rewards: -1569.04497, mean: -0.63782
[32m[0906 20-58-33 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 20-58-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-58-33 @MBExp.py:227][0m Rewards obtained: [-1564.6506824801036], Lows: [878], Highs: [44], Total time: 19918.883
[32m[0906 21-01-25 @MBExp.py:144][0m ####################################################################
[32m[0906 21-01-25 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 21-01-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11506, current rewards: -6.53490, mean: -0.65349
[32m[0906 21-01-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10870, current rewards: 3.40634, mean: 0.05677
[32m[0906 21-01-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10807, current rewards: 13.06346, mean: 0.11876
[32m[0906 21-01-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10795, current rewards: 21.43881, mean: 0.13399
[32m[0906 21-01-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10771, current rewards: 29.97755, mean: 0.14275
[32m[0906 21-01-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10750, current rewards: 36.77184, mean: 0.14143
[32m[0906 21-01-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10743, current rewards: 43.59587, mean: 0.14063
[32m[0906 21-02-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10740, current rewards: 50.42811, mean: 0.14008
[32m[0906 21-02-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10741, current rewards: 57.25607, mean: 0.13965
[32m[0906 21-02-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10711, current rewards: 64.07915, mean: 0.13930
[32m[0906 21-02-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10683, current rewards: 57.70304, mean: 0.11314
[32m[0906 21-02-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10659, current rewards: 62.84340, mean: 0.11222
[32m[0906 21-02-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10641, current rewards: 67.91681, mean: 0.11134
[32m[0906 21-02-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10622, current rewards: 72.98965, mean: 0.11059
[32m[0906 21-02-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10609, current rewards: 78.06357, mean: 0.10995
[32m[0906 21-02-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10601, current rewards: 83.13666, mean: 0.10939
[32m[0906 21-02-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10592, current rewards: 88.20938, mean: 0.10890
[32m[0906 21-02-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10583, current rewards: 93.28235, mean: 0.10847
[32m[0906 21-03-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10579, current rewards: 98.82027, mean: 0.10859
[32m[0906 21-03-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10571, current rewards: 104.16743, mean: 0.10851
[32m[0906 21-03-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10557, current rewards: 103.97987, mean: 0.10295
[32m[0906 21-03-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10537, current rewards: 53.97987, mean: 0.05092
[32m[0906 21-03-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10518, current rewards: 3.97987, mean: 0.00359
[32m[0906 21-03-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10500, current rewards: -46.02013, mean: -0.03967
[32m[0906 21-03-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10484, current rewards: -96.02013, mean: -0.07936
[32m[0906 21-03-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10469, current rewards: -146.02013, mean: -0.11589
[32m[0906 21-03-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10455, current rewards: -196.02013, mean: -0.14963
[32m[0906 21-03-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10444, current rewards: -246.02013, mean: -0.18090
[32m[0906 21-03-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10431, current rewards: -296.02013, mean: -0.20994
[32m[0906 21-03-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10418, current rewards: -346.02013, mean: -0.23700
[32m[0906 21-04-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10409, current rewards: -396.02013, mean: -0.26226
[32m[0906 21-04-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10399, current rewards: -446.02013, mean: -0.28591
[32m[0906 21-04-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10388, current rewards: -496.02013, mean: -0.30809
[32m[0906 21-04-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10381, current rewards: -546.02013, mean: -0.32893
[32m[0906 21-04-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10375, current rewards: -596.02013, mean: -0.34855
[32m[0906 21-04-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10364, current rewards: -646.02013, mean: -0.36706
[32m[0906 21-04-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10356, current rewards: -696.02013, mean: -0.38454
[32m[0906 21-04-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10348, current rewards: -746.02013, mean: -0.40109
[32m[0906 21-04-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10341, current rewards: -796.02013, mean: -0.41676
[32m[0906 21-04-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10335, current rewards: -846.02013, mean: -0.43164
[32m[0906 21-04-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10329, current rewards: -896.02013, mean: -0.44578
[32m[0906 21-04-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10323, current rewards: -946.02013, mean: -0.45923
[32m[0906 21-05-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10323, current rewards: -996.02013, mean: -0.47205
[32m[0906 21-05-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10326, current rewards: -1046.02013, mean: -0.48427
[32m[0906 21-05-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10327, current rewards: -1096.02013, mean: -0.49594
[32m[0906 21-05-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10329, current rewards: -1146.02013, mean: -0.50709
[32m[0906 21-05-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10331, current rewards: -1196.02013, mean: -0.51776
[32m[0906 21-05-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10333, current rewards: -1246.02013, mean: -0.52797
[32m[0906 21-05-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10337, current rewards: -1296.02013, mean: -0.53777
[32m[0906 21-05-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10347, current rewards: -1346.02013, mean: -0.54716
[32m[0906 21-05-45 @Agent.py:117][0m Average action selection time: 0.1035
[32m[0906 21-05-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-05-45 @MBExp.py:227][0m Rewards obtained: [-1386.0201297354195], Lows: [7], Highs: [1500], Total time: 20178.53739
[32m[0906 21-08-38 @MBExp.py:144][0m ####################################################################
[32m[0906 21-08-38 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 21-08-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11254, current rewards: -12.92896, mean: -1.29290
[32m[0906 21-08-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10761, current rewards: -10.81431, mean: -0.18024
[32m[0906 21-08-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10741, current rewards: -6.65295, mean: -0.06048
[32m[0906 21-08-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10714, current rewards: -2.48974, mean: -0.01556
[32m[0906 21-09-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10704, current rewards: 1.67077, mean: 0.00796
[32m[0906 21-09-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10705, current rewards: 5.82999, mean: 0.02242
[32m[0906 21-09-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10685, current rewards: 9.98726, mean: 0.03222
[32m[0906 21-09-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10679, current rewards: 14.14245, mean: 0.03928
[32m[0906 21-09-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10683, current rewards: 18.29980, mean: 0.04463
[32m[0906 21-09-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10654, current rewards: 22.93135, mean: 0.04985
[32m[0906 21-09-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10623, current rewards: 15.81932, mean: 0.03102
[32m[0906 21-09-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10603, current rewards: 21.65051, mean: 0.03866
[32m[0906 21-09-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10579, current rewards: 26.90976, mean: 0.04411
[32m[0906 21-09-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10563, current rewards: 32.15929, mean: 0.04873
[32m[0906 21-09-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10549, current rewards: 37.42181, mean: 0.05271
[32m[0906 21-09-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10541, current rewards: 42.70388, mean: 0.05619
[32m[0906 21-10-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10529, current rewards: 47.97097, mean: 0.05922
[32m[0906 21-10-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10525, current rewards: 53.60115, mean: 0.06233
[32m[0906 21-10-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10514, current rewards: 59.16432, mean: 0.06502
[32m[0906 21-10-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10506, current rewards: 64.72747, mean: 0.06742
[32m[0906 21-10-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10497, current rewards: 70.29062, mean: 0.06959
[32m[0906 21-10-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10476, current rewards: 29.18072, mean: 0.02753
[32m[0906 21-10-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10456, current rewards: -20.81928, mean: -0.01876
[32m[0906 21-10-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10440, current rewards: -70.81928, mean: -0.06105
[32m[0906 21-10-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10424, current rewards: -120.81928, mean: -0.09985
[32m[0906 21-10-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10410, current rewards: -170.81928, mean: -0.13557
[32m[0906 21-10-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10398, current rewards: -220.81928, mean: -0.16856
[32m[0906 21-11-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10386, current rewards: -270.81928, mean: -0.19913
[32m[0906 21-11-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10375, current rewards: -320.81928, mean: -0.22753
[32m[0906 21-11-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10363, current rewards: -370.81928, mean: -0.25399
[32m[0906 21-11-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10356, current rewards: -420.81928, mean: -0.27869
[32m[0906 21-11-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10347, current rewards: -470.81928, mean: -0.30181
[32m[0906 21-11-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10338, current rewards: -520.81928, mean: -0.32349
[32m[0906 21-11-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10331, current rewards: -570.81928, mean: -0.34387
[32m[0906 21-11-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10323, current rewards: -620.81928, mean: -0.36305
[32m[0906 21-11-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10317, current rewards: -670.81928, mean: -0.38115
[32m[0906 21-11-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10311, current rewards: -720.81928, mean: -0.39824
[32m[0906 21-11-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10304, current rewards: -770.81928, mean: -0.41442
[32m[0906 21-11-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10297, current rewards: -820.81928, mean: -0.42975
[32m[0906 21-12-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10291, current rewards: -870.81928, mean: -0.44430
[32m[0906 21-12-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10285, current rewards: -920.81928, mean: -0.45812
[32m[0906 21-12-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10279, current rewards: -970.81928, mean: -0.47127
[32m[0906 21-12-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10275, current rewards: -1020.81928, mean: -0.48380
[32m[0906 21-12-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10276, current rewards: -1070.81928, mean: -0.49575
[32m[0906 21-12-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10278, current rewards: -1120.81928, mean: -0.50716
[32m[0906 21-12-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10281, current rewards: -1170.81928, mean: -0.51806
[32m[0906 21-12-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10283, current rewards: -1220.81928, mean: -0.52849
[32m[0906 21-12-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10283, current rewards: -1270.81928, mean: -0.53848
[32m[0906 21-12-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10285, current rewards: -1320.81928, mean: -0.54806
[32m[0906 21-12-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10292, current rewards: -1370.81928, mean: -0.55724
[32m[0906 21-12-56 @Agent.py:117][0m Average action selection time: 0.1030
[32m[0906 21-12-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-12-57 @MBExp.py:227][0m Rewards obtained: [-1410.8192804358655], Lows: [11], Highs: [1487], Total time: 20436.779217000003
[32m[0906 21-15-52 @MBExp.py:144][0m ####################################################################
[32m[0906 21-15-52 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 21-15-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10674, current rewards: 0.89347, mean: 0.08935
[32m[0906 21-15-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10730, current rewards: 7.85001, mean: 0.13083
[32m[0906 21-16-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10698, current rewards: 13.77606, mean: 0.12524
[32m[0906 21-16-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10692, current rewards: 19.70238, mean: 0.12314
[32m[0906 21-16-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10696, current rewards: 25.62850, mean: 0.12204
[32m[0906 21-16-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10689, current rewards: 31.55447, mean: 0.12136
[32m[0906 21-16-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10679, current rewards: 37.48031, mean: 0.12090
[32m[0906 21-16-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10685, current rewards: 43.40627, mean: 0.12057
[32m[0906 21-16-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10677, current rewards: 49.33244, mean: 0.12032
[32m[0906 21-16-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10660, current rewards: 54.46080, mean: 0.11839
[32m[0906 21-16-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10631, current rewards: 60.17853, mean: 0.11800
[32m[0906 21-16-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10608, current rewards: 28.10211, mean: 0.05018
[32m[0906 21-16-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10585, current rewards: -28.49500, mean: -0.04671
[32m[0906 21-17-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10566, current rewards: -84.35390, mean: -0.12781
[32m[0906 21-17-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10550, current rewards: -143.39804, mean: -0.20197
[32m[0906 21-17-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10542, current rewards: -198.08490, mean: -0.26064
[32m[0906 21-17-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10538, current rewards: -257.65276, mean: -0.31809
[32m[0906 21-17-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10524, current rewards: -314.04391, mean: -0.36517
[32m[0906 21-17-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10515, current rewards: -368.14386, mean: -0.40455
[32m[0906 21-17-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10508, current rewards: -428.23284, mean: -0.44608
[32m[0906 21-17-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10503, current rewards: -484.51110, mean: -0.47971
[32m[0906 21-17-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10483, current rewards: -544.67225, mean: -0.51384
[32m[0906 21-17-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10475, current rewards: -601.11121, mean: -0.54154
[32m[0906 21-17-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10456, current rewards: -661.94283, mean: -0.57064
[32m[0906 21-17-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10457, current rewards: -712.25488, mean: -0.58864
[32m[0906 21-18-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10442, current rewards: -767.38792, mean: -0.60904
[32m[0906 21-18-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10428, current rewards: -811.53104, mean: -0.61949
[32m[0906 21-18-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10414, current rewards: -804.65073, mean: -0.59165
[32m[0906 21-18-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10402, current rewards: -797.77382, mean: -0.56580
[32m[0906 21-18-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10389, current rewards: -790.89667, mean: -0.54171
[32m[0906 21-18-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10376, current rewards: -784.02138, mean: -0.51922
[32m[0906 21-18-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10366, current rewards: -777.14628, mean: -0.49817
[32m[0906 21-18-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10357, current rewards: -770.26222, mean: -0.47842
[32m[0906 21-18-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10348, current rewards: -763.39105, mean: -0.45987
[32m[0906 21-18-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10339, current rewards: -755.77146, mean: -0.44197
[32m[0906 21-18-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10331, current rewards: -748.71837, mean: -0.42541
[32m[0906 21-18-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10323, current rewards: -741.66410, mean: -0.40976
[32m[0906 21-19-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10315, current rewards: -734.60963, mean: -0.39495
[32m[0906 21-19-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10307, current rewards: -727.39047, mean: -0.38083
[32m[0906 21-19-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10302, current rewards: -720.79514, mean: -0.36775
[32m[0906 21-19-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10296, current rewards: -714.19340, mean: -0.35532
[32m[0906 21-19-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10290, current rewards: -707.59551, mean: -0.34349
[32m[0906 21-19-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10284, current rewards: -701.23955, mean: -0.33234
[32m[0906 21-19-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10279, current rewards: -694.65872, mean: -0.32160
[32m[0906 21-19-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10281, current rewards: -688.07051, mean: -0.31134
[32m[0906 21-19-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10283, current rewards: -681.48585, mean: -0.30154
[32m[0906 21-19-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10284, current rewards: -674.90155, mean: -0.29217
[32m[0906 21-19-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10285, current rewards: -668.31174, mean: -0.28318
[32m[0906 21-20-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10286, current rewards: -661.73782, mean: -0.27458
[32m[0906 21-20-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10290, current rewards: -655.14787, mean: -0.26632
[32m[0906 21-20-10 @Agent.py:117][0m Average action selection time: 0.1030
[32m[0906 21-20-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-20-10 @MBExp.py:227][0m Rewards obtained: [-652.5670064705145], Lows: [484], Highs: [8], Total time: 20695.009034000002
[32m[0906 21-23-07 @MBExp.py:144][0m ####################################################################
[32m[0906 21-23-07 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 21-23-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10527, current rewards: -14.00000, mean: -1.40000
[32m[0906 21-23-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11056, current rewards: -60.38731, mean: -1.00646
[32m[0906 21-23-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11037, current rewards: -70.36918, mean: -0.63972
[32m[0906 21-23-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10900, current rewards: -62.94519, mean: -0.39341
[32m[0906 21-23-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10843, current rewards: -55.52827, mean: -0.26442
[32m[0906 21-23-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10810, current rewards: -48.10010, mean: -0.18500
[32m[0906 21-23-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10774, current rewards: -40.67617, mean: -0.13121
[32m[0906 21-23-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10753, current rewards: -33.26128, mean: -0.09239
[32m[0906 21-23-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10746, current rewards: -25.82195, mean: -0.06298
[32m[0906 21-23-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10719, current rewards: -17.26546, mean: -0.03753
[32m[0906 21-24-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10680, current rewards: -9.42639, mean: -0.01848
[32m[0906 21-24-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10649, current rewards: -13.76367, mean: -0.02458
[32m[0906 21-24-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10623, current rewards: -8.78669, mean: -0.01440
[32m[0906 21-24-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10600, current rewards: -3.81016, mean: -0.00577
[32m[0906 21-24-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10580, current rewards: 1.16250, mean: 0.00164
[32m[0906 21-24-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10565, current rewards: 6.14278, mean: 0.00808
[32m[0906 21-24-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10547, current rewards: 11.11826, mean: 0.01373
[32m[0906 21-24-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10549, current rewards: -0.06199, mean: -0.00007
[32m[0906 21-24-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10578, current rewards: -21.53286, mean: -0.02366
[32m[0906 21-24-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10595, current rewards: -46.10523, mean: -0.04803
[32m[0906 21-24-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10610, current rewards: -75.19984, mean: -0.07446
[32m[0906 21-25-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10598, current rewards: -98.19090, mean: -0.09263
[32m[0906 21-25-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10593, current rewards: -111.42081, mean: -0.10038
[32m[0906 21-25-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10570, current rewards: -104.81377, mean: -0.09036
[32m[0906 21-25-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10547, current rewards: -98.22087, mean: -0.08117
[32m[0906 21-25-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10526, current rewards: -91.11031, mean: -0.07231
[32m[0906 21-25-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10507, current rewards: -84.76397, mean: -0.06471
[32m[0906 21-25-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10490, current rewards: -78.40449, mean: -0.05765
[32m[0906 21-25-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10473, current rewards: -72.05537, mean: -0.05110
[32m[0906 21-25-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10457, current rewards: -65.69700, mean: -0.04500
[32m[0906 21-25-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10459, current rewards: -84.90647, mean: -0.05623
[32m[0906 21-25-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10463, current rewards: -102.82459, mean: -0.06591
[32m[0906 21-25-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10451, current rewards: -94.14857, mean: -0.05848
[32m[0906 21-26-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10448, current rewards: -86.01590, mean: -0.05182
[32m[0906 21-26-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10466, current rewards: -76.54310, mean: -0.04476
[32m[0906 21-26-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10489, current rewards: -67.21575, mean: -0.03819
[32m[0906 21-26-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10502, current rewards: -57.88703, mean: -0.03198
[32m[0906 21-26-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10515, current rewards: -48.55836, mean: -0.02611
[32m[0906 21-26-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10533, current rewards: -39.23043, mean: -0.02054
[32m[0906 21-26-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10548, current rewards: -29.93318, mean: -0.01527
[32m[0906 21-26-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10568, current rewards: -20.61054, mean: -0.01025
[32m[0906 21-26-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10580, current rewards: -11.12100, mean: -0.00540
[32m[0906 21-26-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10581, current rewards: -1.80404, mean: -0.00085
[32m[0906 21-26-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10597, current rewards: 7.33360, mean: 0.00340
[32m[0906 21-27-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10593, current rewards: 3.32100, mean: 0.00150
[32m[0906 21-27-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10585, current rewards: 8.55847, mean: 0.00379
[32m[0906 21-27-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10579, current rewards: 13.79732, mean: 0.00597
[32m[0906 21-27-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10573, current rewards: 19.03222, mean: 0.00806
[32m[0906 21-27-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10568, current rewards: 24.26786, mean: 0.01007
[32m[0906 21-27-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10569, current rewards: 29.51112, mean: 0.01200
[32m[0906 21-27-32 @Agent.py:117][0m Average action selection time: 0.1057
[32m[0906 21-27-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-27-32 @MBExp.py:227][0m Rewards obtained: [33.936756325287156], Lows: [158], Highs: [10], Total time: 20960.102547000002
[32m[0906 21-30-31 @MBExp.py:144][0m ####################################################################
[32m[0906 21-30-31 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 21-30-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10473, current rewards: -10.78602, mean: -1.07860
[32m[0906 21-30-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10519, current rewards: -19.49346, mean: -0.32489
[32m[0906 21-30-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10538, current rewards: -12.27269, mean: -0.11157
[32m[0906 21-30-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10546, current rewards: -5.06133, mean: -0.03163
[32m[0906 21-30-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10541, current rewards: 2.15637, mean: 0.01027
[32m[0906 21-30-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10547, current rewards: 9.37719, mean: 0.03607
[32m[0906 21-31-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10540, current rewards: 16.58377, mean: 0.05350
[32m[0906 21-31-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10535, current rewards: 11.57803, mean: 0.03216
[32m[0906 21-31-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10523, current rewards: 17.78466, mean: 0.04338
[32m[0906 21-31-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10496, current rewards: 23.90128, mean: 0.05196
[32m[0906 21-31-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10472, current rewards: 30.01442, mean: 0.05885
[32m[0906 21-31-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10460, current rewards: 36.12380, mean: 0.06451
[32m[0906 21-31-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10444, current rewards: 21.24595, mean: 0.03483
[32m[0906 21-31-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10433, current rewards: 28.82182, mean: 0.04367
[32m[0906 21-31-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10431, current rewards: 35.74847, mean: 0.05035
[32m[0906 21-31-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10424, current rewards: 42.67513, mean: 0.05615
[32m[0906 21-31-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10417, current rewards: 47.11953, mean: 0.05817
[32m[0906 21-32-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10411, current rewards: 50.86206, mean: 0.05914
[32m[0906 21-32-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10405, current rewards: 34.18243, mean: 0.03756
[32m[0906 21-32-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10400, current rewards: -15.81757, mean: -0.01648
[32m[0906 21-32-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10381, current rewards: -65.81757, mean: -0.06517
[32m[0906 21-32-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10363, current rewards: -115.81757, mean: -0.10926
[32m[0906 21-32-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10346, current rewards: -165.81757, mean: -0.14939
[32m[0906 21-32-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10332, current rewards: -215.81757, mean: -0.18605
[32m[0906 21-32-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10318, current rewards: -265.81757, mean: -0.21968
[32m[0906 21-32-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10305, current rewards: -315.81757, mean: -0.25065
[32m[0906 21-32-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10294, current rewards: -365.81757, mean: -0.27925
[32m[0906 21-32-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10285, current rewards: -415.81757, mean: -0.30575
[32m[0906 21-32-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10276, current rewards: -465.81757, mean: -0.33037
[32m[0906 21-33-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10268, current rewards: -515.81757, mean: -0.35330
[32m[0906 21-33-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10262, current rewards: -565.81757, mean: -0.37471
[32m[0906 21-33-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10255, current rewards: -615.81757, mean: -0.39475
[32m[0906 21-33-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10249, current rewards: -665.81757, mean: -0.41355
[32m[0906 21-33-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10243, current rewards: -715.81757, mean: -0.43122
[32m[0906 21-33-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10236, current rewards: -765.81757, mean: -0.44785
[32m[0906 21-33-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10230, current rewards: -815.81757, mean: -0.46353
[32m[0906 21-33-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10226, current rewards: -865.81757, mean: -0.47835
[32m[0906 21-33-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10222, current rewards: -915.81757, mean: -0.49238
[32m[0906 21-33-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10218, current rewards: -965.81757, mean: -0.50566
[32m[0906 21-33-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10215, current rewards: -1015.81757, mean: -0.51827
[32m[0906 21-33-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10210, current rewards: -1065.81757, mean: -0.53026
[32m[0906 21-34-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10205, current rewards: -1115.81757, mean: -0.54166
[32m[0906 21-34-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10200, current rewards: -1165.81757, mean: -0.55252
[32m[0906 21-34-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10198, current rewards: -1215.81757, mean: -0.56288
[32m[0906 21-34-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10199, current rewards: -1265.81757, mean: -0.57277
[32m[0906 21-34-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10201, current rewards: -1315.81757, mean: -0.58222
[32m[0906 21-34-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10204, current rewards: -1365.81757, mean: -0.59126
[32m[0906 21-34-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10205, current rewards: -1415.81757, mean: -0.59992
[32m[0906 21-34-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10207, current rewards: -1465.81757, mean: -0.60822
[32m[0906 21-34-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10211, current rewards: -1515.81757, mean: -0.61619
[32m[0906 21-34-47 @Agent.py:117][0m Average action selection time: 0.1022
[32m[0906 21-34-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-34-47 @MBExp.py:227][0m Rewards obtained: [-1555.8175657145723], Lows: [27], Highs: [1614], Total time: 21216.303056
[32m[0906 21-37-48 @MBExp.py:144][0m ####################################################################
[32m[0906 21-37-48 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 21-37-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10537, current rewards: -6.64872, mean: -0.66487
[32m[0906 21-37-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10647, current rewards: 4.45569, mean: 0.07426
[32m[0906 21-37-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10590, current rewards: 12.19839, mean: 0.11089
[32m[0906 21-38-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10583, current rewards: 16.39292, mean: 0.10246
[32m[0906 21-38-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10577, current rewards: 20.58585, mean: 0.09803
[32m[0906 21-38-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10561, current rewards: 24.77997, mean: 0.09531
[32m[0906 21-38-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10558, current rewards: 28.97343, mean: 0.09346
[32m[0906 21-38-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10550, current rewards: 26.84628, mean: 0.07457
[32m[0906 21-38-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10541, current rewards: 31.66413, mean: 0.07723
[32m[0906 21-38-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10507, current rewards: 36.47821, mean: 0.07930
[32m[0906 21-38-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10484, current rewards: 41.29303, mean: 0.08097
[32m[0906 21-38-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10461, current rewards: 46.11330, mean: 0.08235
[32m[0906 21-38-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10444, current rewards: 50.93260, mean: 0.08350
[32m[0906 21-38-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10438, current rewards: 55.75082, mean: 0.08447
[32m[0906 21-39-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10436, current rewards: 60.56738, mean: 0.08531
[32m[0906 21-39-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10420, current rewards: 66.03004, mean: 0.08688
[32m[0906 21-39-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10390, current rewards: 71.41600, mean: 0.08817
[32m[0906 21-39-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10351, current rewards: 76.65657, mean: 0.08914
[32m[0906 21-39-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10315, current rewards: 81.89959, mean: 0.09000
[32m[0906 21-39-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10283, current rewards: 74.56575, mean: 0.07767
[32m[0906 21-39-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10241, current rewards: 79.09594, mean: 0.07831
[32m[0906 21-39-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10198, current rewards: 83.61186, mean: 0.07888
[32m[0906 21-39-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10161, current rewards: 88.13122, mean: 0.07940
[32m[0906 21-39-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10127, current rewards: 92.64910, mean: 0.07987
[32m[0906 21-39-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10097, current rewards: 96.46314, mean: 0.07972
[32m[0906 21-39-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10071, current rewards: 100.74445, mean: 0.07996
[32m[0906 21-40-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10046, current rewards: 76.80798, mean: 0.05863
[32m[0906 21-40-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10022, current rewards: 81.93696, mean: 0.06025
[32m[0906 21-40-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10000, current rewards: 87.01876, mean: 0.06172
[32m[0906 21-40-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09979, current rewards: 92.10218, mean: 0.06308
[32m[0906 21-40-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09961, current rewards: 97.18384, mean: 0.06436
[32m[0906 21-40-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09942, current rewards: 102.26774, mean: 0.06556
[32m[0906 21-40-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09926, current rewards: 107.67336, mean: 0.06688
[32m[0906 21-40-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09910, current rewards: 112.72154, mean: 0.06790
[32m[0906 21-40-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09894, current rewards: 117.76764, mean: 0.06887
[32m[0906 21-40-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09880, current rewards: 122.81248, mean: 0.06978
[32m[0906 21-40-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09866, current rewards: 127.85766, mean: 0.07064
[32m[0906 21-40-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09854, current rewards: 132.90067, mean: 0.07145
[32m[0906 21-40-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09842, current rewards: 131.33917, mean: 0.06876
[32m[0906 21-41-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09833, current rewards: 60.68263, mean: 0.03096
[32m[0906 21-41-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09824, current rewards: -5.29404, mean: -0.00263
[32m[0906 21-41-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09816, current rewards: -59.62668, mean: -0.02894
[32m[0906 21-41-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09814, current rewards: -128.80929, mean: -0.06105
[32m[0906 21-41-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09819, current rewards: -194.37489, mean: -0.08999
[32m[0906 21-41-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09816, current rewards: -256.60426, mean: -0.11611
[32m[0906 21-41-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09828, current rewards: -308.69014, mean: -0.13659
[32m[0906 21-41-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09838, current rewards: -374.66307, mean: -0.16219
[32m[0906 21-41-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09846, current rewards: -441.08705, mean: -0.18690
[32m[0906 21-41-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09850, current rewards: -504.36996, mean: -0.20928
[32m[0906 21-41-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09859, current rewards: -570.44387, mean: -0.23189
[32m[0906 21-41-55 @Agent.py:117][0m Average action selection time: 0.0986
[32m[0906 21-41-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-41-55 @MBExp.py:227][0m Rewards obtained: [-570.8664310601692], Lows: [401], Highs: [17], Total time: 21463.673731
[32m[0906 21-44-38 @MBExp.py:144][0m ####################################################################
[32m[0906 21-44-38 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 21-44-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08925, current rewards: -5.49254, mean: -0.54925
[32m[0906 21-44-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08908, current rewards: -18.38350, mean: -0.30639
[32m[0906 21-44-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08911, current rewards: -12.69513, mean: -0.11541
[32m[0906 21-44-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08924, current rewards: -7.01521, mean: -0.04385
[32m[0906 21-44-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08924, current rewards: -1.32963, mean: -0.00633
[32m[0906 21-45-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08924, current rewards: 4.36104, mean: 0.01677
[32m[0906 21-45-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08926, current rewards: 10.05013, mean: 0.03242
[32m[0906 21-45-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08927, current rewards: 16.79005, mean: 0.04664
[32m[0906 21-45-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08929, current rewards: 22.09255, mean: 0.05388
[32m[0906 21-45-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08901, current rewards: 27.35959, mean: 0.05948
[32m[0906 21-45-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08881, current rewards: 32.62685, mean: 0.06397
[32m[0906 21-45-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08884, current rewards: 20.92401, mean: 0.03736
[32m[0906 21-45-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08870, current rewards: 24.90670, mean: 0.04083
[32m[0906 21-45-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08864, current rewards: 29.07250, mean: 0.04405
[32m[0906 21-45-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08859, current rewards: 33.30612, mean: 0.04691
[32m[0906 21-45-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08845, current rewards: 20.20161, mean: 0.02658
[32m[0906 21-45-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08837, current rewards: 24.69276, mean: 0.03048
[32m[0906 21-45-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08831, current rewards: 29.77404, mean: 0.03462
[32m[0906 21-45-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08822, current rewards: 34.85356, mean: 0.03830
[32m[0906 21-46-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08819, current rewards: 39.93457, mean: 0.04160
[32m[0906 21-46-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08806, current rewards: 45.01346, mean: 0.04457
[32m[0906 21-46-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08790, current rewards: 50.09450, mean: 0.04726
[32m[0906 21-46-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08776, current rewards: 55.17779, mean: 0.04971
[32m[0906 21-46-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08761, current rewards: 60.25658, mean: 0.05195
[32m[0906 21-46-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08751, current rewards: 66.01724, mean: 0.05456
[32m[0906 21-46-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08740, current rewards: 72.74621, mean: 0.05774
[32m[0906 21-46-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08731, current rewards: 79.20503, mean: 0.06046
[32m[0906 21-46-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08721, current rewards: 85.66385, mean: 0.06299
[32m[0906 21-46-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08714, current rewards: 41.30974, mean: 0.02930
[32m[0906 21-46-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08705, current rewards: -8.69026, mean: -0.00595
[32m[0906 21-46-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08697, current rewards: -19.22121, mean: -0.01273
[32m[0906 21-46-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08690, current rewards: -14.54897, mean: -0.00933
[32m[0906 21-46-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08683, current rewards: -9.87966, mean: -0.00614
[32m[0906 21-47-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08676, current rewards: -5.66881, mean: -0.00341
[32m[0906 21-47-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08670, current rewards: -1.11135, mean: -0.00065
[32m[0906 21-47-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08665, current rewards: 3.44588, mean: 0.00196
[32m[0906 21-47-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08659, current rewards: 8.00092, mean: 0.00442
[32m[0906 21-47-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08654, current rewards: 10.89663, mean: 0.00586
[32m[0906 21-47-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08649, current rewards: 15.80322, mean: 0.00827
[32m[0906 21-47-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08645, current rewards: 20.70688, mean: 0.01056
[32m[0906 21-47-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08641, current rewards: 25.60909, mean: 0.01274
[32m[0906 21-47-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08637, current rewards: 30.47069, mean: 0.01479
[32m[0906 21-47-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08632, current rewards: 35.40902, mean: 0.01678
[32m[0906 21-47-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08632, current rewards: 40.36603, mean: 0.01869
[32m[0906 21-47-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08634, current rewards: 45.31037, mean: 0.02050
[32m[0906 21-47-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08636, current rewards: 37.53641, mean: 0.01661
[32m[0906 21-47-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08638, current rewards: 42.33187, mean: 0.01833
[32m[0906 21-48-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08639, current rewards: 47.12935, mean: 0.01997
[32m[0906 21-48-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08641, current rewards: 51.92567, mean: 0.02155
[32m[0906 21-48-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08647, current rewards: 56.75311, mean: 0.02307
[32m[0906 21-48-15 @Agent.py:117][0m Average action selection time: 0.0865
[32m[0906 21-48-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-48-15 @MBExp.py:227][0m Rewards obtained: [60.59533704957656], Lows: [37], Highs: [120], Total time: 21680.670009999998
[32m[0906 21-50-47 @MBExp.py:144][0m ####################################################################
[32m[0906 21-50-47 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 21-50-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08923, current rewards: 1.15853, mean: 0.11585
[32m[0906 21-50-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08970, current rewards: 6.63967, mean: 0.11066
[32m[0906 21-50-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08951, current rewards: 12.12927, mean: 0.11027
[32m[0906 21-51-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08955, current rewards: 17.61915, mean: 0.11012
[32m[0906 21-51-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08949, current rewards: 23.10820, mean: 0.11004
[32m[0906 21-51-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08948, current rewards: 28.59688, mean: 0.10999
[32m[0906 21-51-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08962, current rewards: 21.87513, mean: 0.07056
[32m[0906 21-51-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09035, current rewards: 0.21791, mean: 0.00061
[32m[0906 21-51-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09037, current rewards: 3.05762, mean: 0.00746
[32m[0906 21-51-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08999, current rewards: 10.90241, mean: 0.02370
[32m[0906 21-51-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08970, current rewards: 18.75841, mean: 0.03678
[32m[0906 21-51-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08944, current rewards: 26.56099, mean: 0.04743
[32m[0906 21-51-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08924, current rewards: 34.41013, mean: 0.05641
[32m[0906 21-51-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08921, current rewards: 32.06642, mean: 0.04859
[32m[0906 21-51-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08949, current rewards: 23.29395, mean: 0.03281
[32m[0906 21-51-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08992, current rewards: 2.20821, mean: 0.00291
[32m[0906 21-52-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09024, current rewards: -16.79547, mean: -0.02074
[32m[0906 21-52-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09060, current rewards: -43.90388, mean: -0.05105
[32m[0906 21-52-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09068, current rewards: -48.63229, mean: -0.05344
[32m[0906 21-52-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09050, current rewards: -44.03927, mean: -0.04587
[32m[0906 21-52-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09020, current rewards: -38.33985, mean: -0.03796
[32m[0906 21-52-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08995, current rewards: -32.62318, mean: -0.03078
[32m[0906 21-52-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08969, current rewards: -26.91143, mean: -0.02424
[32m[0906 21-52-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08948, current rewards: -21.19739, mean: -0.01827
[32m[0906 21-52-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08928, current rewards: -15.15576, mean: -0.01253
[32m[0906 21-52-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08909, current rewards: -18.65520, mean: -0.01481
[32m[0906 21-52-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08892, current rewards: -11.04857, mean: -0.00843
[32m[0906 21-52-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08875, current rewards: -3.43473, mean: -0.00253
[32m[0906 21-52-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08861, current rewards: 4.17049, mean: 0.00296
[32m[0906 21-52-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08847, current rewards: 11.78737, mean: 0.00807
[32m[0906 21-53-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08835, current rewards: 18.62472, mean: 0.01233
[32m[0906 21-53-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08823, current rewards: 24.12283, mean: 0.01546
[32m[0906 21-53-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08811, current rewards: 29.55911, mean: 0.01836
[32m[0906 21-53-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08799, current rewards: 35.04605, mean: 0.02111
[32m[0906 21-53-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08788, current rewards: 40.53416, mean: 0.02370
[32m[0906 21-53-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08779, current rewards: 33.69880, mean: 0.01915
[32m[0906 21-53-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08770, current rewards: 39.61667, mean: 0.02189
[32m[0906 21-53-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08762, current rewards: 45.53455, mean: 0.02448
[32m[0906 21-53-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08754, current rewards: 51.45242, mean: 0.02694
[32m[0906 21-53-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08747, current rewards: 57.37029, mean: 0.02927
[32m[0906 21-53-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08741, current rewards: 63.15233, mean: 0.03142
[32m[0906 21-53-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08734, current rewards: 68.10954, mean: 0.03306
[32m[0906 21-53-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08728, current rewards: 26.90269, mean: 0.01275
[32m[0906 21-53-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08725, current rewards: -23.09731, mean: -0.01069
[32m[0906 21-54-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08724, current rewards: -73.09731, mean: -0.03308
[32m[0906 21-54-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08725, current rewards: -123.09731, mean: -0.05447
[32m[0906 21-54-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08725, current rewards: -173.09731, mean: -0.07493
[32m[0906 21-54-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08724, current rewards: -223.09731, mean: -0.09453
[32m[0906 21-54-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08724, current rewards: -273.09731, mean: -0.11332
[32m[0906 21-54-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08729, current rewards: -323.09731, mean: -0.13134
[32m[0906 21-54-25 @Agent.py:117][0m Average action selection time: 0.0873
[32m[0906 21-54-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-54-26 @MBExp.py:227][0m Rewards obtained: [-363.09730526859], Lows: [86], Highs: [447], Total time: 21899.714483
[32m[0906 21-56-58 @MBExp.py:144][0m ####################################################################
[32m[0906 21-56-58 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 21-56-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08863, current rewards: -14.00000, mean: -1.40000
[32m[0906 21-57-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10242, current rewards: -57.61052, mean: -0.96018
[32m[0906 21-57-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10474, current rewards: -100.69056, mean: -0.91537
[32m[0906 21-57-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10506, current rewards: -142.44731, mean: -0.89030
[32m[0906 21-57-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10495, current rewards: -176.70317, mean: -0.84144
[32m[0906 21-57-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10422, current rewards: -239.45964, mean: -0.92100
[32m[0906 21-57-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10186, current rewards: -251.57229, mean: -0.81152
[32m[0906 21-57-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10016, current rewards: -242.82077, mean: -0.67450
[32m[0906 21-57-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09852, current rewards: -234.81360, mean: -0.57272
[32m[0906 21-57-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09728, current rewards: -226.80506, mean: -0.49305
[32m[0906 21-57-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09626, current rewards: -218.79592, mean: -0.42901
[32m[0906 21-57-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09542, current rewards: -210.78714, mean: -0.37641
[32m[0906 21-57-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09495, current rewards: -202.77793, mean: -0.33242
[32m[0906 21-58-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09435, current rewards: -194.76888, mean: -0.29510
[32m[0906 21-58-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09380, current rewards: -186.75991, mean: -0.26304
[32m[0906 21-58-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09351, current rewards: -218.08683, mean: -0.28696
[32m[0906 21-58-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09365, current rewards: -280.33580, mean: -0.34609
[32m[0906 21-58-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09359, current rewards: -338.51691, mean: -0.39362
[32m[0906 21-58-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09336, current rewards: -394.92490, mean: -0.43398
[32m[0906 21-58-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09309, current rewards: -450.41077, mean: -0.46918
[32m[0906 21-58-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09283, current rewards: -504.00557, mean: -0.49902
[32m[0906 21-58-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09265, current rewards: -562.13967, mean: -0.53032
[32m[0906 21-58-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09263, current rewards: -602.38434, mean: -0.54269
[32m[0906 21-58-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09239, current rewards: -664.25303, mean: -0.57263
[32m[0906 21-58-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09238, current rewards: -719.95884, mean: -0.59501
[32m[0906 21-58-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09215, current rewards: -775.76278, mean: -0.61568
[32m[0906 21-58-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09203, current rewards: -831.94036, mean: -0.63507
[32m[0906 21-59-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09193, current rewards: -872.81493, mean: -0.64178
[32m[0906 21-59-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09174, current rewards: -916.78116, mean: -0.65020
[32m[0906 21-59-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09157, current rewards: -973.23379, mean: -0.66660
[32m[0906 21-59-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09144, current rewards: -1000.09220, mean: -0.66231
[32m[0906 21-59-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09123, current rewards: -1044.97801, mean: -0.66986
[32m[0906 21-59-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09116, current rewards: -1101.70542, mean: -0.68429
[32m[0906 21-59-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09099, current rewards: -1152.64719, mean: -0.69437
[32m[0906 21-59-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09086, current rewards: -1196.05100, mean: -0.69945
[32m[0906 21-59-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09077, current rewards: -1252.40449, mean: -0.71159
[32m[0906 21-59-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09065, current rewards: -1308.57857, mean: -0.72297
[32m[0906 21-59-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09056, current rewards: -1347.84331, mean: -0.72465
[32m[0906 21-59-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09045, current rewards: -1400.81165, mean: -0.73341
[32m[0906 21-59-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09037, current rewards: -1438.45440, mean: -0.73391
[32m[0906 22-00-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09034, current rewards: -1463.38510, mean: -0.72805
[32m[0906 22-00-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09021, current rewards: -1457.94198, mean: -0.70774
[32m[0906 22-00-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09012, current rewards: -1451.42380, mean: -0.68788
[32m[0906 22-00-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09005, current rewards: -1444.95569, mean: -0.66896
[32m[0906 22-00-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08998, current rewards: -1438.42256, mean: -0.65087
[32m[0906 22-00-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08993, current rewards: -1431.91327, mean: -0.63359
[32m[0906 22-00-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08986, current rewards: -1425.40520, mean: -0.61706
[32m[0906 22-00-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08984, current rewards: -1418.91008, mean: -0.60123
[32m[0906 22-00-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08984, current rewards: -1410.26325, mean: -0.58517
[32m[0906 22-00-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08988, current rewards: -1456.58778, mean: -0.59211
[32m[0906 22-00-44 @Agent.py:117][0m Average action selection time: 0.0900
[32m[0906 22-00-44 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-00-44 @MBExp.py:227][0m Rewards obtained: [-1491.7954462624325], Lows: [634], Highs: [440], Total time: 22125.369822
[32m[0906 22-03-19 @MBExp.py:144][0m ####################################################################
[32m[0906 22-03-19 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 22-03-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09512, current rewards: -11.00000, mean: -1.10000
[32m[0906 22-03-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09062, current rewards: -8.96357, mean: -0.14939
[32m[0906 22-03-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09009, current rewards: -3.42368, mean: -0.03112
[32m[0906 22-03-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08998, current rewards: 2.10836, mean: 0.01318
[32m[0906 22-03-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08976, current rewards: 7.64438, mean: 0.03640
[32m[0906 22-03-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08970, current rewards: 13.17781, mean: 0.05068
[32m[0906 22-03-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08956, current rewards: 18.71236, mean: 0.06036
[32m[0906 22-03-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08917, current rewards: 24.57398, mean: 0.06826
[32m[0906 22-03-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08889, current rewards: 29.80097, mean: 0.07269
[32m[0906 22-03-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08864, current rewards: 35.03054, mean: 0.07615
[32m[0906 22-04-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08850, current rewards: 40.25747, mean: 0.07894
[32m[0906 22-04-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08849, current rewards: 40.11563, mean: 0.07164
[32m[0906 22-04-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08838, current rewards: 45.07280, mean: 0.07389
[32m[0906 22-04-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08826, current rewards: 50.02869, mean: 0.07580
[32m[0906 22-04-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08818, current rewards: 54.98948, mean: 0.07745
[32m[0906 22-04-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08809, current rewards: 59.64499, mean: 0.07848
[32m[0906 22-04-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08802, current rewards: 64.54406, mean: 0.07968
[32m[0906 22-04-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08797, current rewards: 72.33790, mean: 0.08411
[32m[0906 22-04-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08782, current rewards: 76.87219, mean: 0.08447
[32m[0906 22-04-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08766, current rewards: 81.40156, mean: 0.08479
[32m[0906 22-04-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08751, current rewards: 85.93371, mean: 0.08508
[32m[0906 22-04-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08736, current rewards: 90.46219, mean: 0.08534
[32m[0906 22-04-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08726, current rewards: 94.99247, mean: 0.08558
[32m[0906 22-05-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08716, current rewards: 99.99030, mean: 0.08620
[32m[0906 22-05-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08706, current rewards: 104.75923, mean: 0.08658
[32m[0906 22-05-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08697, current rewards: 109.32022, mean: 0.08676
[32m[0906 22-05-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08688, current rewards: 113.88224, mean: 0.08693
[32m[0906 22-05-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08681, current rewards: 109.02830, mean: 0.08017
[32m[0906 22-05-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08674, current rewards: 113.84397, mean: 0.08074
[32m[0906 22-05-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08668, current rewards: 118.66445, mean: 0.08128
[32m[0906 22-05-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08662, current rewards: 123.47443, mean: 0.08177
[32m[0906 22-05-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08656, current rewards: 128.28781, mean: 0.08224
[32m[0906 22-05-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08650, current rewards: 133.06929, mean: 0.08265
[32m[0906 22-05-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08645, current rewards: 128.00553, mean: 0.07711
[32m[0906 22-05-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08640, current rewards: 133.44115, mean: 0.07804
[32m[0906 22-05-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08635, current rewards: 138.87206, mean: 0.07890
[32m[0906 22-05-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08631, current rewards: 144.30236, mean: 0.07973
[32m[0906 22-05-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08626, current rewards: 149.73520, mean: 0.08050
[32m[0906 22-06-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08622, current rewards: 155.17235, mean: 0.08124
[32m[0906 22-06-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08619, current rewards: 160.60872, mean: 0.08194
[32m[0906 22-06-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08614, current rewards: 165.88658, mean: 0.08253
[32m[0906 22-06-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08610, current rewards: 158.85493, mean: 0.07711
[32m[0906 22-06-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08609, current rewards: 164.36773, mean: 0.07790
[32m[0906 22-06-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08611, current rewards: 169.88186, mean: 0.07865
[32m[0906 22-06-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08615, current rewards: 175.39546, mean: 0.07936
[32m[0906 22-06-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08617, current rewards: 180.91088, mean: 0.08005
[32m[0906 22-06-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08618, current rewards: 186.42598, mean: 0.08070
[32m[0906 22-06-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08622, current rewards: 191.93883, mean: 0.08133
[32m[0906 22-06-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08630, current rewards: 197.01869, mean: 0.08175
[32m[0906 22-06-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08637, current rewards: 202.46299, mean: 0.08230
[32m[0906 22-06-55 @Agent.py:117][0m Average action selection time: 0.0864
[32m[0906 22-06-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-06-55 @MBExp.py:227][0m Rewards obtained: [199.15947783137682], Lows: [15], Highs: [27], Total time: 22342.133741
[32m[0906 22-09-31 @MBExp.py:144][0m ####################################################################
[32m[0906 22-09-31 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 22-09-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09434, current rewards: -2.31759, mean: -0.23176
[32m[0906 22-09-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09093, current rewards: -27.74801, mean: -0.46247
[32m[0906 22-09-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09005, current rewards: -23.48897, mean: -0.21354
[32m[0906 22-09-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08990, current rewards: -19.36350, mean: -0.12102
[32m[0906 22-09-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08978, current rewards: -15.22782, mean: -0.07251
[32m[0906 22-09-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08969, current rewards: -11.07533, mean: -0.04260
[32m[0906 22-09-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08960, current rewards: -6.99407, mean: -0.02256
[32m[0906 22-10-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08921, current rewards: -1.15838, mean: -0.00322
[32m[0906 22-10-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08887, current rewards: 5.30045, mean: 0.01293
[32m[0906 22-10-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08862, current rewards: -19.85767, mean: -0.04317
[32m[0906 22-10-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08844, current rewards: -69.85767, mean: -0.13698
[32m[0906 22-10-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08830, current rewards: -119.85767, mean: -0.21403
[32m[0906 22-10-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08808, current rewards: -169.85767, mean: -0.27846
[32m[0906 22-10-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08801, current rewards: -219.85767, mean: -0.33312
[32m[0906 22-10-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08796, current rewards: -269.85767, mean: -0.38008
[32m[0906 22-10-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08790, current rewards: -319.85767, mean: -0.42087
[32m[0906 22-10-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08783, current rewards: -369.85767, mean: -0.45661
[32m[0906 22-10-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08777, current rewards: -419.85767, mean: -0.48821
[32m[0906 22-10-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08768, current rewards: -469.85767, mean: -0.51633
[32m[0906 22-10-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08751, current rewards: -519.85767, mean: -0.54152
[32m[0906 22-11-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08737, current rewards: -569.85767, mean: -0.56422
[32m[0906 22-11-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08724, current rewards: -619.85767, mean: -0.58477
[32m[0906 22-11-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08711, current rewards: -669.85767, mean: -0.60348
[32m[0906 22-11-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08703, current rewards: -719.85767, mean: -0.62057
[32m[0906 22-11-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08693, current rewards: -769.85767, mean: -0.63625
[32m[0906 22-11-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08684, current rewards: -819.85767, mean: -0.65068
[32m[0906 22-11-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08674, current rewards: -869.85767, mean: -0.66401
[32m[0906 22-11-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08665, current rewards: -919.85767, mean: -0.67637
[32m[0906 22-11-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08656, current rewards: -969.85767, mean: -0.68784
[32m[0906 22-11-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08650, current rewards: -1019.85767, mean: -0.69853
[32m[0906 22-11-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08643, current rewards: -1069.85767, mean: -0.70852
[32m[0906 22-11-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08635, current rewards: -1119.85767, mean: -0.71786
[32m[0906 22-11-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08630, current rewards: -1169.85767, mean: -0.72662
[32m[0906 22-11-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08624, current rewards: -1219.85767, mean: -0.73485
[32m[0906 22-11-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08620, current rewards: -1269.85767, mean: -0.74261
[32m[0906 22-12-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08615, current rewards: -1319.85767, mean: -0.74992
[32m[0906 22-12-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08610, current rewards: -1369.85767, mean: -0.75683
[32m[0906 22-12-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08606, current rewards: -1419.85767, mean: -0.76336
[32m[0906 22-12-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08603, current rewards: -1469.85767, mean: -0.76956
[32m[0906 22-12-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08599, current rewards: -1519.85767, mean: -0.77544
[32m[0906 22-12-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08597, current rewards: -1569.85767, mean: -0.78102
[32m[0906 22-12-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08593, current rewards: -1619.85767, mean: -0.78634
[32m[0906 22-12-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08590, current rewards: -1669.85767, mean: -0.79140
[32m[0906 22-12-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08591, current rewards: -1719.85767, mean: -0.79623
[32m[0906 22-12-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08594, current rewards: -1769.85767, mean: -0.80084
[32m[0906 22-12-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08597, current rewards: -1819.85767, mean: -0.80525
[32m[0906 22-12-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08599, current rewards: -1869.85767, mean: -0.80946
[32m[0906 22-12-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08601, current rewards: -1919.85767, mean: -0.81350
[32m[0906 22-12-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08606, current rewards: -1969.85767, mean: -0.81737
[32m[0906 22-13-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08613, current rewards: -2019.85767, mean: -0.82108
[32m[0906 22-13-07 @Agent.py:117][0m Average action selection time: 0.0862
[32m[0906 22-13-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-13-08 @MBExp.py:227][0m Rewards obtained: [-2059.8576705997402], Lows: [17], Highs: [2068], Total time: 22558.340681
[32m[0906 22-15-46 @MBExp.py:144][0m ####################################################################
[32m[0906 22-15-46 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 22-15-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08885, current rewards: -6.54548, mean: -0.65455
[32m[0906 22-15-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09237, current rewards: -9.77550, mean: -0.16292
[32m[0906 22-15-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09384, current rewards: -11.03999, mean: -0.10036
[32m[0906 22-16-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09245, current rewards: -22.82066, mean: -0.14263
[32m[0906 22-16-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09191, current rewards: -28.41128, mean: -0.13529
[32m[0906 22-16-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09188, current rewards: -23.76954, mean: -0.09142
[32m[0906 22-16-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09269, current rewards: -46.30773, mean: -0.14938
[32m[0906 22-16-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09236, current rewards: -59.24133, mean: -0.16456
[32m[0906 22-16-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09182, current rewards: -70.64863, mean: -0.17231
[32m[0906 22-16-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09138, current rewards: -74.32078, mean: -0.16157
[32m[0906 22-16-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09148, current rewards: -102.88415, mean: -0.20173
[32m[0906 22-16-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09125, current rewards: -146.72975, mean: -0.26202
[32m[0906 22-16-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09093, current rewards: -141.85870, mean: -0.23256
[32m[0906 22-16-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09062, current rewards: -149.81106, mean: -0.22699
[32m[0906 22-16-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09034, current rewards: -143.99939, mean: -0.20282
[32m[0906 22-16-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09009, current rewards: -137.16730, mean: -0.18048
[32m[0906 22-16-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08988, current rewards: -131.63280, mean: -0.16251
[32m[0906 22-17-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08970, current rewards: -126.20775, mean: -0.14675
[32m[0906 22-17-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08947, current rewards: -120.73837, mean: -0.13268
[32m[0906 22-17-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08921, current rewards: -115.28318, mean: -0.12009
[32m[0906 22-17-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08899, current rewards: -109.85034, mean: -0.10876
[32m[0906 22-17-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08880, current rewards: -104.38089, mean: -0.09847
[32m[0906 22-17-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08863, current rewards: -98.92494, mean: -0.08912
[32m[0906 22-17-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08847, current rewards: -106.73472, mean: -0.09201
[32m[0906 22-17-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08831, current rewards: -101.45164, mean: -0.08384
[32m[0906 22-17-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08816, current rewards: -96.09340, mean: -0.07626
[32m[0906 22-17-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08802, current rewards: -90.74384, mean: -0.06927
[32m[0906 22-17-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08790, current rewards: -85.38161, mean: -0.06278
[32m[0906 22-17-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08780, current rewards: -80.01734, mean: -0.05675
[32m[0906 22-17-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08770, current rewards: -74.65163, mean: -0.05113
[32m[0906 22-17-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08759, current rewards: -69.27935, mean: -0.04588
[32m[0906 22-18-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08749, current rewards: -63.91473, mean: -0.04097
[32m[0906 22-18-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08741, current rewards: -58.93510, mean: -0.03661
[32m[0906 22-18-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08732, current rewards: -54.57740, mean: -0.03288
[32m[0906 22-18-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08724, current rewards: -50.26644, mean: -0.02940
[32m[0906 22-18-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08717, current rewards: -45.97294, mean: -0.02612
[32m[0906 22-18-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08710, current rewards: -41.67245, mean: -0.02302
[32m[0906 22-18-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08704, current rewards: -37.39131, mean: -0.02010
[32m[0906 22-18-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08697, current rewards: -33.10772, mean: -0.01733
[32m[0906 22-18-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08691, current rewards: -28.81384, mean: -0.01470
[32m[0906 22-18-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08687, current rewards: -36.49454, mean: -0.01816
[32m[0906 22-18-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08681, current rewards: -31.14146, mean: -0.01512
[32m[0906 22-18-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08676, current rewards: -25.70862, mean: -0.01218
[32m[0906 22-18-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08670, current rewards: -20.27384, mean: -0.00939
[32m[0906 22-18-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08671, current rewards: -14.83805, mean: -0.00671
[32m[0906 22-19-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08672, current rewards: -9.40580, mean: -0.00416
[32m[0906 22-19-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08673, current rewards: -3.97097, mean: -0.00172
[32m[0906 22-19-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08673, current rewards: 1.46403, mean: 0.00062
[32m[0906 22-19-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08677, current rewards: -9.00607, mean: -0.00374
[32m[0906 22-19-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08684, current rewards: -34.39836, mean: -0.01398
[32m[0906 22-19-24 @Agent.py:117][0m Average action selection time: 0.0869
[32m[0906 22-19-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-19-24 @MBExp.py:227][0m Rewards obtained: [-46.18382225174069], Lows: [112], Highs: [74], Total time: 22776.357872
[32m[0906 22-22-04 @MBExp.py:144][0m ####################################################################
[32m[0906 22-22-04 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 22-22-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08848, current rewards: -9.83354, mean: -0.98335
[32m[0906 22-22-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08939, current rewards: -20.12193, mean: -0.33537
[32m[0906 22-22-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08940, current rewards: -14.52022, mean: -0.13200
[32m[0906 22-22-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08930, current rewards: -8.92075, mean: -0.05575
[32m[0906 22-22-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08943, current rewards: -3.32062, mean: -0.01581
[32m[0906 22-22-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08939, current rewards: 2.28087, mean: 0.00877
[32m[0906 22-22-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08939, current rewards: 7.72952, mean: 0.02493
[32m[0906 22-22-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08915, current rewards: 13.31808, mean: 0.03699
[32m[0906 22-22-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08888, current rewards: 6.26268, mean: 0.01527
[32m[0906 22-22-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08865, current rewards: 12.31399, mean: 0.02677
[32m[0906 22-22-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08846, current rewards: 18.37098, mean: 0.03602
[32m[0906 22-22-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08831, current rewards: 24.42645, mean: 0.04362
[32m[0906 22-22-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08805, current rewards: 30.48396, mean: 0.04997
[32m[0906 22-23-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08797, current rewards: 36.54077, mean: 0.05536
[32m[0906 22-23-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08789, current rewards: 42.59797, mean: 0.06000
[32m[0906 22-23-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08784, current rewards: 48.90957, mean: 0.06435
[32m[0906 22-23-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08780, current rewards: 54.96412, mean: 0.06786
[32m[0906 22-23-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08775, current rewards: 61.02300, mean: 0.07096
[32m[0906 22-23-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08766, current rewards: 67.07649, mean: 0.07371
[32m[0906 22-23-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08749, current rewards: 68.65303, mean: 0.07151
[32m[0906 22-23-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08735, current rewards: 64.48227, mean: 0.06384
[32m[0906 22-23-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08723, current rewards: 70.65872, mean: 0.06666
[32m[0906 22-23-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08712, current rewards: 76.84467, mean: 0.06923
[32m[0906 22-23-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08700, current rewards: 83.75899, mean: 0.07221
[32m[0906 22-23-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08690, current rewards: 89.73858, mean: 0.07416
[32m[0906 22-23-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08681, current rewards: 95.69989, mean: 0.07595
[32m[0906 22-23-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08670, current rewards: 101.67319, mean: 0.07761
[32m[0906 22-24-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08663, current rewards: 107.63686, mean: 0.07914
[32m[0906 22-24-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08657, current rewards: 113.60730, mean: 0.08057
[32m[0906 22-24-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08649, current rewards: 107.80844, mean: 0.07384
[32m[0906 22-24-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08643, current rewards: 113.56305, mean: 0.07521
[32m[0906 22-24-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08637, current rewards: 120.46951, mean: 0.07722
[32m[0906 22-24-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08630, current rewards: 129.00743, mean: 0.08013
[32m[0906 22-24-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08625, current rewards: 137.54535, mean: 0.08286
[32m[0906 22-24-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08621, current rewards: 133.20493, mean: 0.07790
[32m[0906 22-24-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08617, current rewards: 83.20493, mean: 0.04728
[32m[0906 22-24-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08613, current rewards: 33.20493, mean: 0.01835
[32m[0906 22-24-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08609, current rewards: -16.79507, mean: -0.00903
[32m[0906 22-24-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08605, current rewards: -66.79507, mean: -0.03497
[32m[0906 22-24-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08601, current rewards: -116.79507, mean: -0.05959
[32m[0906 22-24-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08597, current rewards: -166.79507, mean: -0.08298
[32m[0906 22-25-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08593, current rewards: -216.79507, mean: -0.10524
[32m[0906 22-25-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08589, current rewards: -266.79507, mean: -0.12644
[32m[0906 22-25-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08586, current rewards: -316.79507, mean: -0.14666
[32m[0906 22-25-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08586, current rewards: -366.79507, mean: -0.16597
[32m[0906 22-25-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08588, current rewards: -416.79507, mean: -0.18442
[32m[0906 22-25-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08590, current rewards: -466.79507, mean: -0.20208
[32m[0906 22-25-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08592, current rewards: -516.79507, mean: -0.21898
[32m[0906 22-25-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08595, current rewards: -566.79507, mean: -0.23518
[32m[0906 22-25-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08602, current rewards: -616.79507, mean: -0.25073
[32m[0906 22-25-40 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0906 22-25-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-25-40 @MBExp.py:227][0m Rewards obtained: [-656.7950694434825], Lows: [27], Highs: [812], Total time: 22992.308729
[32m[0906 22-28-30 @MBExp.py:144][0m ####################################################################
[32m[0906 22-28-30 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 22-28-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09840, current rewards: -11.65458, mean: -1.16546
[32m[0906 22-28-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09952, current rewards: -7.87485, mean: -0.13125
[32m[0906 22-28-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09973, current rewards: -2.08953, mean: -0.01900
[32m[0906 22-28-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09975, current rewards: 3.70990, mean: 0.02319
[32m[0906 22-28-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09973, current rewards: 9.50810, mean: 0.04528
[32m[0906 22-28-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09974, current rewards: 15.30867, mean: 0.05888
[32m[0906 22-29-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09979, current rewards: 22.45315, mean: 0.07243
[32m[0906 22-29-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09968, current rewards: 17.44692, mean: 0.04846
[32m[0906 22-29-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09935, current rewards: 25.74704, mean: 0.06280
[32m[0906 22-29-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09902, current rewards: 34.04716, mean: 0.07402
[32m[0906 22-29-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09878, current rewards: 42.34728, mean: 0.08303
[32m[0906 22-29-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09862, current rewards: 50.64740, mean: 0.09044
[32m[0906 22-29-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09836, current rewards: 58.94752, mean: 0.09664
[32m[0906 22-29-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09827, current rewards: 67.24764, mean: 0.10189
[32m[0906 22-29-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09819, current rewards: 75.26438, mean: 0.10601
[32m[0906 22-29-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09810, current rewards: 44.48771, mean: 0.05854
[32m[0906 22-29-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09804, current rewards: -5.51229, mean: -0.00681
[32m[0906 22-29-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09801, current rewards: -55.51229, mean: -0.06455
[32m[0906 22-30-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09796, current rewards: -105.51229, mean: -0.11595
[32m[0906 22-30-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09776, current rewards: -155.51229, mean: -0.16199
[32m[0906 22-30-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09756, current rewards: -205.51229, mean: -0.20348
[32m[0906 22-30-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09738, current rewards: -255.51229, mean: -0.24105
[32m[0906 22-30-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09723, current rewards: -305.51229, mean: -0.27524
[32m[0906 22-30-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09708, current rewards: -355.51229, mean: -0.30648
[32m[0906 22-30-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09694, current rewards: -405.51229, mean: -0.33513
[32m[0906 22-30-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09683, current rewards: -455.51229, mean: -0.36152
[32m[0906 22-30-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09670, current rewards: -505.51229, mean: -0.38589
[32m[0906 22-30-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09659, current rewards: -555.51229, mean: -0.40846
[32m[0906 22-30-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09649, current rewards: -605.51229, mean: -0.42944
[32m[0906 22-30-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09640, current rewards: -655.51229, mean: -0.44898
[32m[0906 22-30-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09631, current rewards: -705.51229, mean: -0.46723
[32m[0906 22-31-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09623, current rewards: -755.51229, mean: -0.48430
[32m[0906 22-31-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09616, current rewards: -805.51229, mean: -0.50032
[32m[0906 22-31-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09610, current rewards: -855.51229, mean: -0.51537
[32m[0906 22-31-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09601, current rewards: -905.51229, mean: -0.52954
[32m[0906 22-31-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09597, current rewards: -955.51229, mean: -0.54290
[32m[0906 22-31-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09592, current rewards: -1005.51229, mean: -0.55553
[32m[0906 22-31-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09585, current rewards: -1055.51229, mean: -0.56748
[32m[0906 22-31-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09580, current rewards: -1105.51229, mean: -0.57880
[32m[0906 22-31-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09576, current rewards: -1155.51229, mean: -0.58955
[32m[0906 22-31-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09572, current rewards: -1205.51229, mean: -0.59976
[32m[0906 22-31-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09567, current rewards: -1255.51229, mean: -0.60947
[32m[0906 22-31-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09562, current rewards: -1305.51229, mean: -0.61873
[32m[0906 22-31-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09558, current rewards: -1355.51229, mean: -0.62755
[32m[0906 22-32-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09553, current rewards: -1405.51229, mean: -0.63598
[32m[0906 22-32-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09556, current rewards: -1455.51229, mean: -0.64403
[32m[0906 22-32-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09560, current rewards: -1505.51229, mean: -0.65174
[32m[0906 22-32-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09563, current rewards: -1555.51229, mean: -0.65912
[32m[0906 22-32-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09566, current rewards: -1605.51229, mean: -0.66619
[32m[0906 22-32-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09572, current rewards: -1655.51229, mean: -0.67297
[32m[0906 22-32-30 @Agent.py:117][0m Average action selection time: 0.0958
[32m[0906 22-32-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-32-31 @MBExp.py:227][0m Rewards obtained: [-1695.5122932468632], Lows: [10], Highs: [1778], Total time: 23232.546163
[32m[0906 22-35-19 @MBExp.py:144][0m ####################################################################
[32m[0906 22-35-19 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 22-35-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08836, current rewards: -5.46040, mean: -0.54604
[32m[0906 22-35-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08935, current rewards: -16.63239, mean: -0.27721
[32m[0906 22-35-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08945, current rewards: -10.91068, mean: -0.09919
[32m[0906 22-35-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08943, current rewards: -5.18516, mean: -0.03241
[32m[0906 22-35-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08949, current rewards: 0.53532, mean: 0.00255
[32m[0906 22-35-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08948, current rewards: 6.25507, mean: 0.02406
[32m[0906 22-35-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08946, current rewards: 12.00464, mean: 0.03872
[32m[0906 22-35-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08943, current rewards: 17.69495, mean: 0.04915
[32m[0906 22-35-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08910, current rewards: 23.37935, mean: 0.05702
[32m[0906 22-36-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08884, current rewards: 29.06321, mean: 0.06318
[32m[0906 22-36-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08864, current rewards: 32.63834, mean: 0.06400
[32m[0906 22-36-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08850, current rewards: 30.42162, mean: 0.05432
[32m[0906 22-36-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08831, current rewards: 39.29347, mean: 0.06442
[32m[0906 22-36-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08821, current rewards: 48.16662, mean: 0.07298
[32m[0906 22-36-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08813, current rewards: 57.76471, mean: 0.08136
[32m[0906 22-36-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08803, current rewards: 59.30611, mean: 0.07803
[32m[0906 22-36-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08798, current rewards: 64.37178, mean: 0.07947
[32m[0906 22-36-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08792, current rewards: 69.43682, mean: 0.08074
[32m[0906 22-36-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08788, current rewards: 74.50442, mean: 0.08187
[32m[0906 22-36-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08773, current rewards: 79.57391, mean: 0.08289
[32m[0906 22-36-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08758, current rewards: 84.63867, mean: 0.08380
[32m[0906 22-36-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08744, current rewards: 89.70084, mean: 0.08462
[32m[0906 22-36-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08732, current rewards: 94.74950, mean: 0.08536
[32m[0906 22-37-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08720, current rewards: 99.35222, mean: 0.08565
[32m[0906 22-37-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08710, current rewards: 104.70890, mean: 0.08654
[32m[0906 22-37-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08698, current rewards: 110.00668, mean: 0.08731
[32m[0906 22-37-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08689, current rewards: 115.31112, mean: 0.08802
[32m[0906 22-37-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08679, current rewards: 120.61741, mean: 0.08869
[32m[0906 22-37-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08674, current rewards: 125.91214, mean: 0.08930
[32m[0906 22-37-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08668, current rewards: 131.21870, mean: 0.08988
[32m[0906 22-37-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08661, current rewards: 124.27639, mean: 0.08230
[32m[0906 22-37-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08655, current rewards: 130.42316, mean: 0.08360
[32m[0906 22-37-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08650, current rewards: 136.56406, mean: 0.08482
[32m[0906 22-37-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08648, current rewards: 142.70920, mean: 0.08597
[32m[0906 22-37-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08647, current rewards: 148.85039, mean: 0.08705
[32m[0906 22-37-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08642, current rewards: 154.99603, mean: 0.08807
[32m[0906 22-37-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08637, current rewards: 161.13720, mean: 0.08903
[32m[0906 22-38-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08632, current rewards: 167.28267, mean: 0.08994
[32m[0906 22-38-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08627, current rewards: 173.42715, mean: 0.09080
[32m[0906 22-38-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08623, current rewards: 180.10095, mean: 0.09189
[32m[0906 22-38-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08618, current rewards: 186.06862, mean: 0.09257
[32m[0906 22-38-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08615, current rewards: 192.03862, mean: 0.09322
[32m[0906 22-38-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08612, current rewards: 198.00480, mean: 0.09384
[32m[0906 22-38-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08611, current rewards: 184.84376, mean: 0.08558
[32m[0906 22-38-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08608, current rewards: 190.96533, mean: 0.08641
[32m[0906 22-38-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08606, current rewards: 197.05218, mean: 0.08719
[32m[0906 22-38-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08608, current rewards: 203.14034, mean: 0.08794
[32m[0906 22-38-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08610, current rewards: 209.10412, mean: 0.08860
[32m[0906 22-38-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08611, current rewards: 215.12661, mean: 0.08926
[32m[0906 22-38-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08612, current rewards: 221.14945, mean: 0.08990
[32m[0906 22-38-55 @Agent.py:117][0m Average action selection time: 0.0862
[32m[0906 22-38-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-38-56 @MBExp.py:227][0m Rewards obtained: [225.9661671968445], Lows: [30], Highs: [14], Total time: 23448.728924
[32m[0906 22-41-41 @MBExp.py:144][0m ####################################################################
[32m[0906 22-41-41 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 22-41-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08800, current rewards: -4.49735, mean: -0.44974
[32m[0906 22-41-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08909, current rewards: 1.23876, mean: 0.02065
[32m[0906 22-41-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08920, current rewards: 6.40606, mean: 0.05824
[32m[0906 22-41-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08932, current rewards: 11.57498, mean: 0.07234
[32m[0906 22-42-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08934, current rewards: 16.74429, mean: 0.07973
[32m[0906 22-42-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08934, current rewards: 21.90537, mean: 0.08425
[32m[0906 22-42-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08931, current rewards: 26.77226, mean: 0.08636
[32m[0906 22-42-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08931, current rewards: 31.82435, mean: 0.08840
[32m[0906 22-42-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08896, current rewards: 36.87435, mean: 0.08994
[32m[0906 22-42-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08870, current rewards: 41.92045, mean: 0.09113
[32m[0906 22-42-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08853, current rewards: 46.97277, mean: 0.09210
[32m[0906 22-42-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08834, current rewards: 52.02418, mean: 0.09290
[32m[0906 22-42-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08839, current rewards: 52.66870, mean: 0.08634
[32m[0906 22-42-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08847, current rewards: 56.84532, mean: 0.08613
[32m[0906 22-42-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08845, current rewards: 63.13335, mean: 0.08892
[32m[0906 22-42-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08835, current rewards: 68.55786, mean: 0.09021
[32m[0906 22-42-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08826, current rewards: 73.97386, mean: 0.09133
[32m[0906 22-42-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08817, current rewards: 72.85661, mean: 0.08472
[32m[0906 22-43-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08811, current rewards: 82.19005, mean: 0.09032
[32m[0906 22-43-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08798, current rewards: 91.52349, mean: 0.09534
[32m[0906 22-43-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08781, current rewards: 100.85693, mean: 0.09986
[32m[0906 22-43-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08767, current rewards: 110.19038, mean: 0.10395
[32m[0906 22-43-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08753, current rewards: 117.91096, mean: 0.10623
[32m[0906 22-43-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08739, current rewards: 75.28789, mean: 0.06490
[32m[0906 22-43-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08727, current rewards: 25.28789, mean: 0.02090
[32m[0906 22-43-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08716, current rewards: -24.71211, mean: -0.01961
[32m[0906 22-43-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08707, current rewards: -74.71211, mean: -0.05703
[32m[0906 22-43-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08698, current rewards: -124.71211, mean: -0.09170
[32m[0906 22-43-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08688, current rewards: -174.71211, mean: -0.12391
[32m[0906 22-43-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08679, current rewards: -224.71211, mean: -0.15391
[32m[0906 22-43-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08671, current rewards: -274.71211, mean: -0.18193
[32m[0906 22-43-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08664, current rewards: -324.71211, mean: -0.20815
[32m[0906 22-44-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08657, current rewards: -374.71211, mean: -0.23274
[32m[0906 22-44-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08651, current rewards: -424.71211, mean: -0.25585
[32m[0906 22-44-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08646, current rewards: -474.71211, mean: -0.27761
[32m[0906 22-44-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08640, current rewards: -524.71211, mean: -0.29813
[32m[0906 22-44-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08636, current rewards: -574.71211, mean: -0.31752
[32m[0906 22-44-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08631, current rewards: -624.71211, mean: -0.33587
[32m[0906 22-44-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08627, current rewards: -674.71211, mean: -0.35325
[32m[0906 22-44-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08623, current rewards: -724.71211, mean: -0.36975
[32m[0906 22-44-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08619, current rewards: -774.71211, mean: -0.38543
[32m[0906 22-44-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08614, current rewards: -824.71211, mean: -0.40035
[32m[0906 22-44-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08610, current rewards: -874.71211, mean: -0.41456
[32m[0906 22-44-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08607, current rewards: -924.71211, mean: -0.42811
[32m[0906 22-44-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08603, current rewards: -974.71211, mean: -0.44105
[32m[0906 22-44-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08600, current rewards: -1024.71211, mean: -0.45341
[32m[0906 22-45-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08600, current rewards: -1074.71211, mean: -0.46524
[32m[0906 22-45-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08602, current rewards: -1124.71211, mean: -0.47657
[32m[0906 22-45-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08605, current rewards: -1174.71211, mean: -0.48743
[32m[0906 22-45-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08607, current rewards: -1224.71211, mean: -0.49785
[32m[0906 22-45-17 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0906 22-45-17 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-45-17 @MBExp.py:227][0m Rewards obtained: [-1264.7121072052148], Lows: [5], Highs: [1393], Total time: 23664.655340999998
[32m[0906 22-48-04 @MBExp.py:144][0m ####################################################################
[32m[0906 22-48-04 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 22-48-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08880, current rewards: -10.80441, mean: -1.08044
[32m[0906 22-48-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09575, current rewards: -62.63178, mean: -1.04386
[32m[0906 22-48-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09287, current rewards: -118.76483, mean: -1.07968
[32m[0906 22-48-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09233, current rewards: -187.03902, mean: -1.16899
[32m[0906 22-48-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09251, current rewards: -248.67020, mean: -1.18414
[32m[0906 22-48-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09280, current rewards: -307.08142, mean: -1.18108
[32m[0906 22-48-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09269, current rewards: -375.09060, mean: -1.20997
[32m[0906 22-48-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09256, current rewards: -417.77705, mean: -1.16049
[32m[0906 22-48-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09188, current rewards: -469.12595, mean: -1.14421
[32m[0906 22-48-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09135, current rewards: -528.08374, mean: -1.14801
[32m[0906 22-48-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09127, current rewards: -589.95516, mean: -1.15677
[32m[0906 22-48-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09087, current rewards: -649.19607, mean: -1.15928
[32m[0906 22-48-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09076, current rewards: -716.24045, mean: -1.17416
[32m[0906 22-49-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09074, current rewards: -770.99458, mean: -1.16817
[32m[0906 22-49-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09053, current rewards: -822.56260, mean: -1.15854
[32m[0906 22-49-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09036, current rewards: -888.14292, mean: -1.16861
[32m[0906 22-49-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09037, current rewards: -926.26257, mean: -1.14353
[32m[0906 22-49-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09054, current rewards: -979.85373, mean: -1.13936
[32m[0906 22-49-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09034, current rewards: -1011.59051, mean: -1.11164
[32m[0906 22-49-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09008, current rewards: -1003.93542, mean: -1.04577
[32m[0906 22-49-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08981, current rewards: -996.28034, mean: -0.98642
[32m[0906 22-49-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08956, current rewards: -988.62525, mean: -0.93267
[32m[0906 22-49-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08933, current rewards: -981.16324, mean: -0.88393
[32m[0906 22-49-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08912, current rewards: -976.01359, mean: -0.84139
[32m[0906 22-49-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08894, current rewards: -969.92879, mean: -0.80159
[32m[0906 22-49-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08877, current rewards: -963.68520, mean: -0.76483
[32m[0906 22-50-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08861, current rewards: -965.31436, mean: -0.73688
[32m[0906 22-50-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08847, current rewards: -1048.78321, mean: -0.77116
[32m[0906 22-50-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08836, current rewards: -1132.34961, mean: -0.80308
[32m[0906 22-50-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08824, current rewards: -1223.61298, mean: -0.83809
[32m[0906 22-50-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08811, current rewards: -1312.17501, mean: -0.86899
[32m[0906 22-50-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08799, current rewards: -1392.29929, mean: -0.89250
[32m[0906 22-50-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08788, current rewards: -1469.45081, mean: -0.91270
[32m[0906 22-50-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08778, current rewards: -1547.98656, mean: -0.93252
[32m[0906 22-50-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08769, current rewards: -1630.28215, mean: -0.95338
[32m[0906 22-50-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08761, current rewards: -1717.07790, mean: -0.97561
[32m[0906 22-50-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08756, current rewards: -1794.66099, mean: -0.99153
[32m[0906 22-50-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08758, current rewards: -1844.91946, mean: -0.99189
[32m[0906 22-50-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08763, current rewards: -1903.02733, mean: -0.99635
[32m[0906 22-50-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08763, current rewards: -1945.12742, mean: -0.99241
[32m[0906 22-51-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08761, current rewards: -2001.22637, mean: -0.99564
[32m[0906 22-51-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08768, current rewards: -2053.86593, mean: -0.99702
[32m[0906 22-51-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08764, current rewards: -2110.48984, mean: -1.00023
[32m[0906 22-51-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08760, current rewards: -2172.85282, mean: -1.00595
[32m[0906 22-51-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08759, current rewards: -2228.40517, mean: -1.00833
[32m[0906 22-51-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08757, current rewards: -2274.58581, mean: -1.00645
[32m[0906 22-51-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08754, current rewards: -2296.98294, mean: -0.99436
[32m[0906 22-51-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08757, current rewards: -2322.71412, mean: -0.98420
[32m[0906 22-51-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08760, current rewards: -2355.25172, mean: -0.97728
[32m[0906 22-51-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08762, current rewards: -2386.64969, mean: -0.97018
[32m[0906 22-51-43 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0906 22-51-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-51-44 @MBExp.py:227][0m Rewards obtained: [-2409.8359992352757], Lows: [1253], Highs: [98], Total time: 23884.410313999997
[32m[0906 22-54-33 @MBExp.py:144][0m ####################################################################
[32m[0906 22-54-33 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 22-54-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08906, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-54-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08925, current rewards: -60.00000, mean: -1.00000
[32m[0906 22-54-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08919, current rewards: -110.00000, mean: -1.00000
[32m[0906 22-54-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08930, current rewards: -160.00000, mean: -1.00000
[32m[0906 22-54-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08931, current rewards: -210.00000, mean: -1.00000
[32m[0906 22-54-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08931, current rewards: -260.00000, mean: -1.00000
[32m[0906 22-55-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08931, current rewards: -310.00000, mean: -1.00000
[32m[0906 22-55-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08911, current rewards: -360.00000, mean: -1.00000
[32m[0906 22-55-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09067, current rewards: -407.46485, mean: -0.99382
[32m[0906 22-55-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09239, current rewards: -450.61788, mean: -0.97960
[32m[0906 22-55-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09390, current rewards: -497.34507, mean: -0.97519
[32m[0906 22-55-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09502, current rewards: -556.65747, mean: -0.99403
[32m[0906 22-55-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09634, current rewards: -595.72401, mean: -0.97660
[32m[0906 22-55-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09599, current rewards: -618.24536, mean: -0.93674
[32m[0906 22-55-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09564, current rewards: -611.38956, mean: -0.86111
[32m[0906 22-55-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09590, current rewards: -647.03085, mean: -0.85136
[32m[0906 22-55-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09585, current rewards: -665.01166, mean: -0.82100
[32m[0906 22-55-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09584, current rewards: -712.88404, mean: -0.82893
[32m[0906 22-56-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09555, current rewards: -766.90510, mean: -0.84275
[32m[0906 22-56-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09540, current rewards: -821.99549, mean: -0.85625
[32m[0906 22-56-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09512, current rewards: -832.77835, mean: -0.82453
[32m[0906 22-56-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09519, current rewards: -872.84616, mean: -0.82344
[32m[0906 22-56-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09510, current rewards: -911.49068, mean: -0.82116
[32m[0906 22-56-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09507, current rewards: -942.79109, mean: -0.81275
[32m[0906 22-56-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09505, current rewards: -973.19176, mean: -0.80429
[32m[0906 22-56-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09514, current rewards: -1010.60170, mean: -0.80206
[32m[0906 22-56-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09477, current rewards: -1006.00642, mean: -0.76794
[32m[0906 22-56-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09445, current rewards: -1000.04813, mean: -0.73533
[32m[0906 22-56-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09412, current rewards: -994.17085, mean: -0.70509
[32m[0906 22-56-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09383, current rewards: -988.25708, mean: -0.67689
[32m[0906 22-56-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09358, current rewards: -982.13269, mean: -0.65042
[32m[0906 22-56-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09366, current rewards: -989.49958, mean: -0.63429
[32m[0906 22-57-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09396, current rewards: -1046.39094, mean: -0.64993
[32m[0906 22-57-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09445, current rewards: -1104.72349, mean: -0.66550
[32m[0906 22-57-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09461, current rewards: -1166.77201, mean: -0.68232
[32m[0906 22-57-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09465, current rewards: -1236.34295, mean: -0.70247
[32m[0906 22-57-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09488, current rewards: -1305.02119, mean: -0.72101
[32m[0906 22-57-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09505, current rewards: -1378.31123, mean: -0.74103
[32m[0906 22-57-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09575, current rewards: -1420.18402, mean: -0.74355
[32m[0906 22-57-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09661, current rewards: -1468.02498, mean: -0.74899
[32m[0906 22-57-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09657, current rewards: -1483.01418, mean: -0.73782
[32m[0906 22-57-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09636, current rewards: -1478.76985, mean: -0.71785
[32m[0906 22-57-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09621, current rewards: -1474.77275, mean: -0.69894
[32m[0906 22-58-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09608, current rewards: -1470.72628, mean: -0.68089
[32m[0906 22-58-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09596, current rewards: -1466.71304, mean: -0.66367
[32m[0906 22-58-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09578, current rewards: -1462.71107, mean: -0.64722
[32m[0906 22-58-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09572, current rewards: -1458.94504, mean: -0.63158
[32m[0906 22-58-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09585, current rewards: -1525.44077, mean: -0.64637
[32m[0906 22-58-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09629, current rewards: -1584.59469, mean: -0.65751
[32m[0906 22-58-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09634, current rewards: -1646.90345, mean: -0.66947
[32m[0906 22-58-34 @Agent.py:117][0m Average action selection time: 0.0962
[32m[0906 22-58-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-58-34 @MBExp.py:227][0m Rewards obtained: [-1726.90344715368], Lows: [373], Highs: [1093], Total time: 24125.711831999997
[32m[0906 23-01-24 @MBExp.py:144][0m ####################################################################
[32m[0906 23-01-24 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 23-01-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08984, current rewards: -12.92482, mean: -1.29248
[32m[0906 23-01-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08960, current rewards: -95.97186, mean: -1.59953
[32m[0906 23-01-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08831, current rewards: -185.65824, mean: -1.68780
[32m[0906 23-01-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08783, current rewards: -275.71098, mean: -1.72319
[32m[0906 23-01-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08753, current rewards: -370.58872, mean: -1.76471
[32m[0906 23-01-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08737, current rewards: -452.98436, mean: -1.74225
[32m[0906 23-01-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08765, current rewards: -536.00123, mean: -1.72904
[32m[0906 23-01-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08874, current rewards: -602.09371, mean: -1.67248
[32m[0906 23-02-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08852, current rewards: -596.67902, mean: -1.45531
[32m[0906 23-02-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08833, current rewards: -591.66770, mean: -1.28623
[32m[0906 23-02-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08817, current rewards: -586.66069, mean: -1.15032
[32m[0906 23-02-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08806, current rewards: -581.65187, mean: -1.03866
[32m[0906 23-02-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08792, current rewards: -576.81826, mean: -0.94560
[32m[0906 23-02-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08774, current rewards: -571.81771, mean: -0.86639
[32m[0906 23-02-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08750, current rewards: -566.81363, mean: -0.79833
[32m[0906 23-02-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08730, current rewards: -561.81875, mean: -0.73924
[32m[0906 23-02-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08712, current rewards: -556.81280, mean: -0.68742
[32m[0906 23-02-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08696, current rewards: -551.80943, mean: -0.64164
[32m[0906 23-02-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08686, current rewards: -546.80900, mean: -0.60089
[32m[0906 23-02-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08673, current rewards: -541.80413, mean: -0.56438
[32m[0906 23-02-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08662, current rewards: -536.19812, mean: -0.53089
[32m[0906 23-02-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08651, current rewards: -547.92109, mean: -0.51691
[32m[0906 23-03-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08644, current rewards: -574.13919, mean: -0.51724
[32m[0906 23-03-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08634, current rewards: -569.70029, mean: -0.49112
[32m[0906 23-03-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08627, current rewards: -565.26138, mean: -0.46716
[32m[0906 23-03-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08620, current rewards: -560.82279, mean: -0.44510
[32m[0906 23-03-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08615, current rewards: -556.38336, mean: -0.42472
[32m[0906 23-03-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08609, current rewards: -551.94461, mean: -0.40584
[32m[0906 23-03-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08608, current rewards: -570.45679, mean: -0.40458
[32m[0906 23-03-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08602, current rewards: -589.58497, mean: -0.40383
[32m[0906 23-03-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08595, current rewards: -585.17969, mean: -0.38754
[32m[0906 23-03-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08590, current rewards: -580.78270, mean: -0.37230
[32m[0906 23-03-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08585, current rewards: -576.38727, mean: -0.35800
[32m[0906 23-03-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08580, current rewards: -571.99321, mean: -0.34457
[32m[0906 23-03-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08577, current rewards: -567.59832, mean: -0.33193
[32m[0906 23-03-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08573, current rewards: -568.64489, mean: -0.32309
[32m[0906 23-04-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08570, current rewards: -563.35142, mean: -0.31124
[32m[0906 23-04-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08567, current rewards: -557.75364, mean: -0.29987
[32m[0906 23-04-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08564, current rewards: -552.53684, mean: -0.28929
[32m[0906 23-04-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08561, current rewards: -547.31884, mean: -0.27924
[32m[0906 23-04-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08559, current rewards: -548.92470, mean: -0.27310
[32m[0906 23-04-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08559, current rewards: -544.77128, mean: -0.26445
[32m[0906 23-04-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08563, current rewards: -540.62887, mean: -0.25622
[32m[0906 23-04-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08566, current rewards: -536.48749, mean: -0.24837
[32m[0906 23-04-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08569, current rewards: -532.34907, mean: -0.24088
[32m[0906 23-04-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08571, current rewards: -528.20744, mean: -0.23372
[32m[0906 23-04-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08574, current rewards: -524.06785, mean: -0.22687
[32m[0906 23-04-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08578, current rewards: -519.92935, mean: -0.22031
[32m[0906 23-04-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08585, current rewards: -575.93480, mean: -0.23898
[32m[0906 23-04-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08592, current rewards: -654.02474, mean: -0.26586
[32m[0906 23-05-00 @Agent.py:117][0m Average action selection time: 0.0860
[32m[0906 23-05-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-05-00 @MBExp.py:227][0m Rewards obtained: [-726.6803458498034], Lows: [442], Highs: [58], Total time: 24341.414779999996
[32m[0906 23-07-52 @MBExp.py:144][0m ####################################################################
[32m[0906 23-07-52 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 23-07-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09728, current rewards: -14.00000, mean: -1.40000
[32m[0906 23-07-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09279, current rewards: -27.91171, mean: -0.46520
[32m[0906 23-08-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09057, current rewards: -23.62856, mean: -0.21481
[32m[0906 23-08-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08932, current rewards: -18.93760, mean: -0.11836
[32m[0906 23-08-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08876, current rewards: -15.14238, mean: -0.07211
[32m[0906 23-08-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08844, current rewards: -11.34547, mean: -0.04364
[32m[0906 23-08-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08814, current rewards: -7.55000, mean: -0.02435
[32m[0906 23-08-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08833, current rewards: -3.75095, mean: -0.01042
[32m[0906 23-08-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08821, current rewards: 0.04339, mean: 0.00011
[32m[0906 23-08-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08806, current rewards: 3.83738, mean: 0.00834
[32m[0906 23-08-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08792, current rewards: 7.63411, mean: 0.01497
[32m[0906 23-08-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08782, current rewards: 11.42059, mean: 0.02039
[32m[0906 23-08-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08772, current rewards: 10.50543, mean: 0.01722
[32m[0906 23-08-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08768, current rewards: 14.88052, mean: 0.02255
[32m[0906 23-08-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08742, current rewards: 19.27094, mean: 0.02714
[32m[0906 23-08-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08725, current rewards: 23.61761, mean: 0.03108
[32m[0906 23-09-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08708, current rewards: 27.98535, mean: 0.03455
[32m[0906 23-09-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08695, current rewards: 32.38231, mean: 0.03765
[32m[0906 23-09-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08682, current rewards: 36.75921, mean: 0.04039
[32m[0906 23-09-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08671, current rewards: 41.02856, mean: 0.04274
[32m[0906 23-09-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08660, current rewards: 45.84033, mean: 0.04539
[32m[0906 23-09-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08650, current rewards: 39.09551, mean: 0.03688
[32m[0906 23-09-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08641, current rewards: 42.31030, mean: 0.03812
[32m[0906 23-09-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08633, current rewards: 45.52698, mean: 0.03925
[32m[0906 23-09-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08625, current rewards: 48.74248, mean: 0.04028
[32m[0906 23-09-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08619, current rewards: 51.95757, mean: 0.04124
[32m[0906 23-09-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08613, current rewards: 55.17313, mean: 0.04212
[32m[0906 23-09-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08608, current rewards: 58.58286, mean: 0.04308
[32m[0906 23-09-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08602, current rewards: 65.62555, mean: 0.04654
[32m[0906 23-09-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08597, current rewards: 72.88404, mean: 0.04992
[32m[0906 23-10-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08593, current rewards: 80.14549, mean: 0.05308
[32m[0906 23-10-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08589, current rewards: 87.40659, mean: 0.05603
[32m[0906 23-10-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08585, current rewards: 94.65623, mean: 0.05879
[32m[0906 23-10-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08581, current rewards: 101.90999, mean: 0.06139
[32m[0906 23-10-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08577, current rewards: 109.14867, mean: 0.06383
[32m[0906 23-10-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08573, current rewards: 116.40572, mean: 0.06614
[32m[0906 23-10-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08571, current rewards: 100.34693, mean: 0.05544
[32m[0906 23-10-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08571, current rewards: 52.17469, mean: 0.02805
[32m[0906 23-10-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08567, current rewards: 10.57406, mean: 0.00554
[32m[0906 23-10-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08564, current rewards: -32.34263, mean: -0.01650
[32m[0906 23-10-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08566, current rewards: -78.88099, mean: -0.03924
[32m[0906 23-10-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08563, current rewards: -123.13300, mean: -0.05977
[32m[0906 23-10-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08563, current rewards: -172.98275, mean: -0.08198
[32m[0906 23-10-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08569, current rewards: -224.52496, mean: -0.10395
[32m[0906 23-11-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08573, current rewards: -258.69580, mean: -0.11706
[32m[0906 23-11-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08575, current rewards: -254.01085, mean: -0.11239
[32m[0906 23-11-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08577, current rewards: -249.27207, mean: -0.10791
[32m[0906 23-11-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08579, current rewards: -244.53315, mean: -0.10362
[32m[0906 23-11-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08586, current rewards: -239.79441, mean: -0.09950
[32m[0906 23-11-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08593, current rewards: -235.05798, mean: -0.09555
[32m[0906 23-11-28 @Agent.py:117][0m Average action selection time: 0.0860
[32m[0906 23-11-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-11-28 @MBExp.py:227][0m Rewards obtained: [-231.26633228966665], Lows: [226], Highs: [23], Total time: 24557.116717999994
[32m[0906 23-14-22 @MBExp.py:144][0m ####################################################################
[32m[0906 23-14-22 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 23-14-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09446, current rewards: -9.12863, mean: -0.91286
[32m[0906 23-14-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09114, current rewards: -28.44501, mean: -0.47408
[32m[0906 23-14-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09173, current rewards: -52.88365, mean: -0.48076
[32m[0906 23-14-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09015, current rewards: -69.34440, mean: -0.43340
[32m[0906 23-14-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08948, current rewards: -108.28386, mean: -0.51564
[32m[0906 23-14-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08931, current rewards: -125.64503, mean: -0.48325
[32m[0906 23-14-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08936, current rewards: -147.00984, mean: -0.47423
[32m[0906 23-14-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08953, current rewards: -168.75753, mean: -0.46877
[32m[0906 23-14-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08974, current rewards: -190.37985, mean: -0.46434
[32m[0906 23-15-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09006, current rewards: -215.44524, mean: -0.46836
[32m[0906 23-15-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09039, current rewards: -254.47287, mean: -0.49897
[32m[0906 23-15-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09058, current rewards: -274.52391, mean: -0.49022
[32m[0906 23-15-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09041, current rewards: -289.75623, mean: -0.47501
[32m[0906 23-15-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09031, current rewards: -345.28064, mean: -0.52315
[32m[0906 23-15-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08989, current rewards: -366.91724, mean: -0.51678
[32m[0906 23-15-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08956, current rewards: -389.31724, mean: -0.51226
[32m[0906 23-15-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08925, current rewards: -399.16535, mean: -0.49280
[32m[0906 23-15-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08899, current rewards: -425.28609, mean: -0.49452
[32m[0906 23-15-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08897, current rewards: -439.94419, mean: -0.48346
[32m[0906 23-15-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08889, current rewards: -459.84028, mean: -0.47900
[32m[0906 23-15-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08879, current rewards: -477.75182, mean: -0.47302
[32m[0906 23-15-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08863, current rewards: -496.52623, mean: -0.46842
[32m[0906 23-16-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08887, current rewards: -537.87351, mean: -0.48457
[32m[0906 23-16-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08888, current rewards: -554.46866, mean: -0.47799
[32m[0906 23-16-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08889, current rewards: -570.96860, mean: -0.47187
[32m[0906 23-16-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08872, current rewards: -573.69913, mean: -0.45532
[32m[0906 23-16-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08855, current rewards: -569.73080, mean: -0.43491
[32m[0906 23-16-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08841, current rewards: -565.76776, mean: -0.41601
[32m[0906 23-16-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08827, current rewards: -561.96587, mean: -0.39856
[32m[0906 23-16-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08815, current rewards: -559.45749, mean: -0.38319
[32m[0906 23-16-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08802, current rewards: -551.01522, mean: -0.36491
[32m[0906 23-16-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08791, current rewards: -541.99819, mean: -0.34743
[32m[0906 23-16-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08781, current rewards: -532.54365, mean: -0.33077
[32m[0906 23-16-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08772, current rewards: -522.81513, mean: -0.31495
[32m[0906 23-16-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08762, current rewards: -513.05917, mean: -0.30003
[32m[0906 23-16-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08753, current rewards: -501.70157, mean: -0.28506
[32m[0906 23-17-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08743, current rewards: -491.24579, mean: -0.27141
[32m[0906 23-17-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08735, current rewards: -482.11197, mean: -0.25920
[32m[0906 23-17-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08748, current rewards: -500.29667, mean: -0.26194
[32m[0906 23-17-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08764, current rewards: -513.28192, mean: -0.26188
[32m[0906 23-17-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08764, current rewards: -512.36726, mean: -0.25491
[32m[0906 23-17-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08759, current rewards: -518.61571, mean: -0.25176
[32m[0906 23-17-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08755, current rewards: -516.97762, mean: -0.24501
[32m[0906 23-17-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08754, current rewards: -508.35820, mean: -0.23535
[32m[0906 23-17-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08752, current rewards: -499.58706, mean: -0.22606
[32m[0906 23-17-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08750, current rewards: -490.69466, mean: -0.21712
[32m[0906 23-17-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08749, current rewards: -481.81097, mean: -0.20858
[32m[0906 23-17-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08749, current rewards: -472.91829, mean: -0.20039
[32m[0906 23-17-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08747, current rewards: -463.98962, mean: -0.19253
[32m[0906 23-17-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08747, current rewards: -459.43069, mean: -0.18676
[32m[0906 23-18-01 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0906 23-18-01 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-18-02 @MBExp.py:227][0m Rewards obtained: [-465.03227653668137], Lows: [121], Highs: [482], Total time: 24776.506789999992
[32m[0906 23-20-57 @MBExp.py:144][0m ####################################################################
[32m[0906 23-20-57 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 23-20-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08931, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-21-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08934, current rewards: -57.87379, mean: -0.96456
[32m[0906 23-21-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08838, current rewards: -105.75189, mean: -0.96138
[32m[0906 23-21-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08785, current rewards: -155.75189, mean: -0.97345
[32m[0906 23-21-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08764, current rewards: -205.75189, mean: -0.97977
[32m[0906 23-21-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08745, current rewards: -255.75189, mean: -0.98366
[32m[0906 23-21-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08776, current rewards: -305.75189, mean: -0.98630
[32m[0906 23-21-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08795, current rewards: -355.75189, mean: -0.98820
[32m[0906 23-21-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08813, current rewards: -404.70337, mean: -0.98708
[32m[0906 23-21-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08826, current rewards: -454.70337, mean: -0.98849
[32m[0906 23-21-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08840, current rewards: -504.70337, mean: -0.98961
[32m[0906 23-21-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08850, current rewards: -516.36293, mean: -0.92208
[32m[0906 23-21-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08846, current rewards: -513.51276, mean: -0.84182
[32m[0906 23-21-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08833, current rewards: -510.66258, mean: -0.77373
[32m[0906 23-22-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08809, current rewards: -507.81241, mean: -0.71523
[32m[0906 23-22-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08788, current rewards: -504.96224, mean: -0.66442
[32m[0906 23-22-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08768, current rewards: -549.67722, mean: -0.67861
[32m[0906 23-22-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08752, current rewards: -599.67722, mean: -0.69730
[32m[0906 23-22-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08735, current rewards: -649.67722, mean: -0.71393
[32m[0906 23-22-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08723, current rewards: -699.67722, mean: -0.72883
[32m[0906 23-22-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08710, current rewards: -749.67722, mean: -0.74225
[32m[0906 23-22-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08697, current rewards: -799.67722, mean: -0.75441
[32m[0906 23-22-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08685, current rewards: -849.67722, mean: -0.76547
[32m[0906 23-22-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08676, current rewards: -899.67722, mean: -0.77558
[32m[0906 23-22-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08667, current rewards: -949.67722, mean: -0.78486
[32m[0906 23-22-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08658, current rewards: -999.67722, mean: -0.79339
[32m[0906 23-22-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08649, current rewards: -1049.67722, mean: -0.80128
[32m[0906 23-22-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08642, current rewards: -1099.67722, mean: -0.80859
[32m[0906 23-22-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08635, current rewards: -1149.67722, mean: -0.81537
[32m[0906 23-23-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08630, current rewards: -1199.67722, mean: -0.82170
[32m[0906 23-23-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08624, current rewards: -1249.67722, mean: -0.82760
[32m[0906 23-23-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08618, current rewards: -1299.67722, mean: -0.83313
[32m[0906 23-23-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08613, current rewards: -1349.67722, mean: -0.83831
[32m[0906 23-23-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08608, current rewards: -1399.67722, mean: -0.84318
[32m[0906 23-23-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08602, current rewards: -1449.67722, mean: -0.84776
[32m[0906 23-23-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08598, current rewards: -1499.67722, mean: -0.85209
[32m[0906 23-23-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08594, current rewards: -1549.67722, mean: -0.85618
[32m[0906 23-23-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08590, current rewards: -1599.67722, mean: -0.86004
[32m[0906 23-23-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08587, current rewards: -1649.67722, mean: -0.86371
[32m[0906 23-23-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08584, current rewards: -1699.67722, mean: -0.86718
[32m[0906 23-23-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08580, current rewards: -1749.67722, mean: -0.87049
[32m[0906 23-23-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08578, current rewards: -1799.67722, mean: -0.87363
[32m[0906 23-23-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08576, current rewards: -1849.67722, mean: -0.87662
[32m[0906 23-24-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08580, current rewards: -1899.67722, mean: -0.87948
[32m[0906 23-24-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08582, current rewards: -1949.67722, mean: -0.88221
[32m[0906 23-24-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08585, current rewards: -1999.67722, mean: -0.88481
[32m[0906 23-24-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08587, current rewards: -2049.67722, mean: -0.88731
[32m[0906 23-24-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08589, current rewards: -2099.67722, mean: -0.88969
[32m[0906 23-24-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08592, current rewards: -2149.67722, mean: -0.89198
[32m[0906 23-24-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08594, current rewards: -2199.67722, mean: -0.89418
[32m[0906 23-24-32 @Agent.py:117][0m Average action selection time: 0.0860
[32m[0906 23-24-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-24-33 @MBExp.py:227][0m Rewards obtained: [-2239.677222655034], Lows: [5], Highs: [2244], Total time: 24992.122740999992
[32m[0906 23-27-30 @MBExp.py:144][0m ####################################################################
[32m[0906 23-27-30 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 23-27-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08838, current rewards: -12.95036, mean: -1.29504
[32m[0906 23-27-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08948, current rewards: -9.14020, mean: -0.15234
[32m[0906 23-27-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08821, current rewards: -3.11549, mean: -0.02832
[32m[0906 23-27-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08789, current rewards: 2.74091, mean: 0.01713
[32m[0906 23-27-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08774, current rewards: 8.60497, mean: 0.04098
[32m[0906 23-27-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08759, current rewards: 14.47243, mean: 0.05566
[32m[0906 23-27-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08794, current rewards: 20.32341, mean: 0.06556
[32m[0906 23-28-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08822, current rewards: 26.18810, mean: 0.07274
[32m[0906 23-28-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08840, current rewards: 32.04681, mean: 0.07816
[32m[0906 23-28-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08853, current rewards: 5.58300, mean: 0.01214
[32m[0906 23-28-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08861, current rewards: -7.27930, mean: -0.01427
[32m[0906 23-28-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08869, current rewards: -10.34928, mean: -0.01848
[32m[0906 23-28-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08876, current rewards: -12.18499, mean: -0.01998
[32m[0906 23-28-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08879, current rewards: -17.05922, mean: -0.02585
[32m[0906 23-28-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08875, current rewards: -25.04708, mean: -0.03528
[32m[0906 23-28-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08848, current rewards: -24.62550, mean: -0.03240
[32m[0906 23-28-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08825, current rewards: -43.18331, mean: -0.05331
[32m[0906 23-28-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08806, current rewards: -47.25964, mean: -0.05495
[32m[0906 23-28-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08788, current rewards: -39.55380, mean: -0.04347
[32m[0906 23-28-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08771, current rewards: -32.09360, mean: -0.03343
[32m[0906 23-28-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08755, current rewards: -24.63340, mean: -0.02439
[32m[0906 23-29-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08741, current rewards: -17.17321, mean: -0.01620
[32m[0906 23-29-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08728, current rewards: -43.03993, mean: -0.03877
[32m[0906 23-29-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08714, current rewards: -93.03993, mean: -0.08021
[32m[0906 23-29-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08703, current rewards: -143.03993, mean: -0.11821
[32m[0906 23-29-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08694, current rewards: -193.03993, mean: -0.15321
[32m[0906 23-29-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08684, current rewards: -243.03993, mean: -0.18553
[32m[0906 23-29-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08676, current rewards: -293.03993, mean: -0.21547
[32m[0906 23-29-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08667, current rewards: -343.03993, mean: -0.24329
[32m[0906 23-29-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08661, current rewards: -393.03993, mean: -0.26921
[32m[0906 23-29-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08655, current rewards: -443.03993, mean: -0.29340
[32m[0906 23-29-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08647, current rewards: -493.03993, mean: -0.31605
[32m[0906 23-29-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08642, current rewards: -543.03993, mean: -0.33729
[32m[0906 23-29-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08638, current rewards: -593.03993, mean: -0.35725
[32m[0906 23-29-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08632, current rewards: -643.03993, mean: -0.37605
[32m[0906 23-30-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08627, current rewards: -693.03993, mean: -0.39377
[32m[0906 23-30-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08623, current rewards: -743.03993, mean: -0.41052
[32m[0906 23-30-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08619, current rewards: -793.03993, mean: -0.42637
[32m[0906 23-30-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08614, current rewards: -843.03993, mean: -0.44138
[32m[0906 23-30-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08611, current rewards: -893.03993, mean: -0.45563
[32m[0906 23-30-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08608, current rewards: -943.03993, mean: -0.46917
[32m[0906 23-30-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08605, current rewards: -993.03993, mean: -0.48206
[32m[0906 23-30-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08601, current rewards: -1043.03993, mean: -0.49433
[32m[0906 23-30-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08601, current rewards: -1093.03993, mean: -0.50604
[32m[0906 23-30-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08603, current rewards: -1143.03993, mean: -0.51721
[32m[0906 23-30-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08604, current rewards: -1193.03993, mean: -0.52789
[32m[0906 23-30-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08606, current rewards: -1243.03993, mean: -0.53811
[32m[0906 23-30-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08608, current rewards: -1293.03993, mean: -0.54790
[32m[0906 23-30-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08610, current rewards: -1343.03993, mean: -0.55728
[32m[0906 23-31-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08612, current rewards: -1393.03993, mean: -0.56628
[32m[0906 23-31-05 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0906 23-31-05 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-31-06 @MBExp.py:227][0m Rewards obtained: [-1433.0399292484049], Lows: [82], Highs: [1428], Total time: 25208.194346999993
[32m[0906 23-34-05 @MBExp.py:144][0m ####################################################################
[32m[0906 23-34-05 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 23-34-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08887, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-34-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10032, current rewards: -45.69857, mean: -0.76164
[32m[0906 23-34-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10082, current rewards: -75.67325, mean: -0.68794
[32m[0906 23-34-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09926, current rewards: -99.69966, mean: -0.62312
[32m[0906 23-34-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09892, current rewards: -126.56931, mean: -0.60271
[32m[0906 23-34-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09873, current rewards: -155.61623, mean: -0.59852
[32m[0906 23-34-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10009, current rewards: -200.57146, mean: -0.64700
[32m[0906 23-34-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10103, current rewards: -223.63927, mean: -0.62122
[32m[0906 23-34-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09977, current rewards: -271.64592, mean: -0.66255
[32m[0906 23-34-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10040, current rewards: -306.66311, mean: -0.66666
[32m[0906 23-34-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10025, current rewards: -345.25754, mean: -0.67698
[32m[0906 23-35-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10048, current rewards: -373.71828, mean: -0.66735
[32m[0906 23-35-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09975, current rewards: -381.82260, mean: -0.62594
[32m[0906 23-35-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09889, current rewards: -375.72159, mean: -0.56928
[32m[0906 23-35-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09786, current rewards: -369.62591, mean: -0.52060
[32m[0906 23-35-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09698, current rewards: -363.53039, mean: -0.47833
[32m[0906 23-35-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09621, current rewards: -357.43225, mean: -0.44127
[32m[0906 23-35-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09550, current rewards: -351.30980, mean: -0.40850
[32m[0906 23-35-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09489, current rewards: -344.90537, mean: -0.37902
[32m[0906 23-35-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09436, current rewards: -338.82681, mean: -0.35294
[32m[0906 23-35-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09387, current rewards: -333.69899, mean: -0.33040
[32m[0906 23-35-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09344, current rewards: -328.16786, mean: -0.30959
[32m[0906 23-35-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09304, current rewards: -322.63884, mean: -0.29067
[32m[0906 23-35-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09265, current rewards: -331.17866, mean: -0.28550
[32m[0906 23-35-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09231, current rewards: -322.12552, mean: -0.26622
[32m[0906 23-36-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09200, current rewards: -312.19272, mean: -0.24777
[32m[0906 23-36-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09171, current rewards: -302.24487, mean: -0.23072
[32m[0906 23-36-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09145, current rewards: -292.29647, mean: -0.21492
[32m[0906 23-36-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09121, current rewards: -282.35901, mean: -0.20025
[32m[0906 23-36-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09099, current rewards: -272.41138, mean: -0.18658
[32m[0906 23-36-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09076, current rewards: -273.81488, mean: -0.18133
[32m[0906 23-36-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09055, current rewards: -268.60412, mean: -0.17218
[32m[0906 23-36-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09037, current rewards: -263.38999, mean: -0.16360
[32m[0906 23-36-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09018, current rewards: -258.18909, mean: -0.15554
[32m[0906 23-36-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09000, current rewards: -252.97686, mean: -0.14794
[32m[0906 23-36-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08985, current rewards: -247.95653, mean: -0.14088
[32m[0906 23-36-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08970, current rewards: -242.74499, mean: -0.13411
[32m[0906 23-36-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08957, current rewards: -237.53239, mean: -0.12771
[32m[0906 23-36-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08945, current rewards: -232.32801, mean: -0.12164
[32m[0906 23-37-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08932, current rewards: -227.12000, mean: -0.11588
[32m[0906 23-37-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08921, current rewards: -221.91089, mean: -0.11040
[32m[0906 23-37-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08911, current rewards: -216.70346, mean: -0.10520
[32m[0906 23-37-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08902, current rewards: -223.18342, mean: -0.10577
[32m[0906 23-37-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08897, current rewards: -214.51018, mean: -0.09931
[32m[0906 23-37-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08893, current rewards: -205.84614, mean: -0.09314
[32m[0906 23-37-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08888, current rewards: -197.16358, mean: -0.08724
[32m[0906 23-37-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08884, current rewards: -188.48582, mean: -0.08160
[32m[0906 23-37-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08879, current rewards: -179.80724, mean: -0.07619
[32m[0906 23-37-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08875, current rewards: -171.13900, mean: -0.07101
[32m[0906 23-37-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08872, current rewards: -162.46204, mean: -0.06604
[32m[0906 23-37-47 @Agent.py:117][0m Average action selection time: 0.0887
[32m[0906 23-37-47 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-37-47 @MBExp.py:227][0m Rewards obtained: [-150.26781126044483], Lows: [233], Highs: [29], Total time: 25430.657315999993
[32m[0906 23-40-48 @MBExp.py:144][0m ####################################################################
[32m[0906 23-40-48 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 23-40-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08807, current rewards: -12.94288, mean: -1.29429
[32m[0906 23-40-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08774, current rewards: -15.23447, mean: -0.25391
[32m[0906 23-40-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08741, current rewards: -6.98130, mean: -0.06347
[32m[0906 23-41-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08726, current rewards: 1.28835, mean: 0.00805
[32m[0906 23-41-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08733, current rewards: 9.52602, mean: 0.04536
[32m[0906 23-41-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08778, current rewards: 17.78036, mean: 0.06839
[32m[0906 23-41-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08802, current rewards: 26.03449, mean: 0.08398
[32m[0906 23-41-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08821, current rewards: 16.82973, mean: 0.04675
[32m[0906 23-41-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08835, current rewards: 25.15717, mean: 0.06136
[32m[0906 23-41-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08847, current rewards: 35.26816, mean: 0.07667
[32m[0906 23-41-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08857, current rewards: 44.17811, mean: 0.08662
[32m[0906 23-41-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08866, current rewards: 53.09896, mean: 0.09482
[32m[0906 23-41-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08871, current rewards: 62.04093, mean: 0.10171
[32m[0906 23-41-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08872, current rewards: 70.95580, mean: 0.10751
[32m[0906 23-41-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08867, current rewards: 79.86939, mean: 0.11249
[32m[0906 23-41-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08846, current rewards: 88.76877, mean: 0.11680
[32m[0906 23-42-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08820, current rewards: 97.67606, mean: 0.12059
[32m[0906 23-42-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08797, current rewards: 104.52076, mean: 0.12154
[32m[0906 23-42-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08777, current rewards: 112.20297, mean: 0.12330
[32m[0906 23-42-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08771, current rewards: 108.34335, mean: 0.11286
[32m[0906 23-42-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08755, current rewards: 117.42641, mean: 0.11626
[32m[0906 23-42-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08741, current rewards: 126.45902, mean: 0.11930
[32m[0906 23-42-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08727, current rewards: 135.49827, mean: 0.12207
[32m[0906 23-42-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08714, current rewards: 144.53256, mean: 0.12460
[32m[0906 23-42-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08702, current rewards: 153.57866, mean: 0.12692
[32m[0906 23-42-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08692, current rewards: 165.75637, mean: 0.13155
[32m[0906 23-42-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08683, current rewards: 174.85029, mean: 0.13347
[32m[0906 23-42-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08673, current rewards: 182.49898, mean: 0.13419
[32m[0906 23-42-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08665, current rewards: 184.60732, mean: 0.13093
[32m[0906 23-42-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08657, current rewards: 187.58661, mean: 0.12848
[32m[0906 23-42-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08650, current rewards: 187.94036, mean: 0.12446
[32m[0906 23-43-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08644, current rewards: 181.23864, mean: 0.11618
[32m[0906 23-43-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08637, current rewards: 185.47001, mean: 0.11520
[32m[0906 23-43-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08631, current rewards: 188.62253, mean: 0.11363
[32m[0906 23-43-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08625, current rewards: 195.14551, mean: 0.11412
[32m[0906 23-43-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08620, current rewards: 201.63789, mean: 0.11457
[32m[0906 23-43-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08615, current rewards: 208.09884, mean: 0.11497
[32m[0906 23-43-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08611, current rewards: 214.61842, mean: 0.11539
[32m[0906 23-43-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08607, current rewards: 221.11664, mean: 0.11577
[32m[0906 23-43-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08604, current rewards: 227.59221, mean: 0.11612
[32m[0906 23-43-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08600, current rewards: 234.13436, mean: 0.11648
[32m[0906 23-43-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08596, current rewards: 241.06135, mean: 0.11702
[32m[0906 23-43-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08593, current rewards: 247.44190, mean: 0.11727
[32m[0906 23-43-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08595, current rewards: 255.85923, mean: 0.11845
[32m[0906 23-43-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08598, current rewards: 264.20154, mean: 0.11955
[32m[0906 23-44-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08600, current rewards: 272.64488, mean: 0.12064
[32m[0906 23-44-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08602, current rewards: 280.98069, mean: 0.12164
[32m[0906 23-44-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08604, current rewards: 289.31377, mean: 0.12259
[32m[0906 23-44-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08606, current rewards: 297.72997, mean: 0.12354
[32m[0906 23-44-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08607, current rewards: 306.05096, mean: 0.12441
[32m[0906 23-44-24 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0906 23-44-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-44-24 @MBExp.py:227][0m Rewards obtained: [310.9502493418626], Lows: [60], Highs: [10], Total time: 25646.59159799999
[32m[0906 23-47-26 @MBExp.py:144][0m ####################################################################
[32m[0906 23-47-26 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 23-47-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09305, current rewards: -9.76397, mean: -0.97640
[32m[0906 23-47-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09089, current rewards: -42.84927, mean: -0.71415
[32m[0906 23-47-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08942, current rewards: -84.38814, mean: -0.76716
[32m[0906 23-47-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08854, current rewards: -122.12127, mean: -0.76326
[32m[0906 23-47-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08851, current rewards: -162.25161, mean: -0.77263
[32m[0906 23-47-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08888, current rewards: -198.46715, mean: -0.76334
[32m[0906 23-47-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08923, current rewards: -240.53257, mean: -0.77591
[32m[0906 23-47-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08922, current rewards: -277.14433, mean: -0.76985
[32m[0906 23-48-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08932, current rewards: -311.27123, mean: -0.75920
[32m[0906 23-48-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08941, current rewards: -363.20613, mean: -0.78958
[32m[0906 23-48-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08942, current rewards: -428.73846, mean: -0.84066
[32m[0906 23-48-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08945, current rewards: -492.12929, mean: -0.87880
[32m[0906 23-48-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08945, current rewards: -551.59015, mean: -0.90425
[32m[0906 23-48-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08946, current rewards: -620.05008, mean: -0.93947
[32m[0906 23-48-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08940, current rewards: -672.92705, mean: -0.94778
[32m[0906 23-48-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08915, current rewards: -740.13566, mean: -0.97386
[32m[0906 23-48-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08885, current rewards: -789.81341, mean: -0.97508
[32m[0906 23-48-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08863, current rewards: -846.56414, mean: -0.98438
[32m[0906 23-48-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08845, current rewards: -880.82632, mean: -0.96794
[32m[0906 23-48-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08834, current rewards: -933.82250, mean: -0.97273
[32m[0906 23-48-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08830, current rewards: -953.18445, mean: -0.94375
[32m[0906 23-49-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08817, current rewards: -960.36499, mean: -0.90600
[32m[0906 23-49-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08831, current rewards: -993.33383, mean: -0.89490
[32m[0906 23-49-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08825, current rewards: -1021.85501, mean: -0.88091
[32m[0906 23-49-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08810, current rewards: -1071.85501, mean: -0.88583
[32m[0906 23-49-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08809, current rewards: -1121.85501, mean: -0.89036
[32m[0906 23-49-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08807, current rewards: -1153.90626, mean: -0.88084
[32m[0906 23-49-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08808, current rewards: -1183.34126, mean: -0.87010
[32m[0906 23-49-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08807, current rewards: -1210.12887, mean: -0.85825
[32m[0906 23-49-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08805, current rewards: -1246.02716, mean: -0.85344
[32m[0906 23-49-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08814, current rewards: -1259.74132, mean: -0.83427
[32m[0906 23-49-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08820, current rewards: -1280.90505, mean: -0.82109
[32m[0906 23-49-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08810, current rewards: -1300.62850, mean: -0.80784
[32m[0906 23-49-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08811, current rewards: -1343.89608, mean: -0.80958
[32m[0906 23-49-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08807, current rewards: -1404.10455, mean: -0.82111
[32m[0906 23-50-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08811, current rewards: -1432.16991, mean: -0.81373
[32m[0906 23-50-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08816, current rewards: -1461.57197, mean: -0.80750
[32m[0906 23-50-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08816, current rewards: -1500.29166, mean: -0.80661
[32m[0906 23-50-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08822, current rewards: -1529.18166, mean: -0.80062
[32m[0906 23-50-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08828, current rewards: -1591.21637, mean: -0.81185
[32m[0906 23-50-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08832, current rewards: -1620.37077, mean: -0.80615
[32m[0906 23-50-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08833, current rewards: -1661.69278, mean: -0.80665
[32m[0906 23-50-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08837, current rewards: -1691.00602, mean: -0.80142
[32m[0906 23-50-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08835, current rewards: -1729.64283, mean: -0.80076
[32m[0906 23-50-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08833, current rewards: -1779.64283, mean: -0.80527
[32m[0906 23-50-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08829, current rewards: -1829.64283, mean: -0.80958
[32m[0906 23-50-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08827, current rewards: -1879.64283, mean: -0.81370
[32m[0906 23-50-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08824, current rewards: -1929.64283, mean: -0.81765
[32m[0906 23-50-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08820, current rewards: -1979.64283, mean: -0.82143
[32m[0906 23-51-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08818, current rewards: -2029.64283, mean: -0.82506
[32m[0906 23-51-07 @Agent.py:117][0m Average action selection time: 0.0882
[32m[0906 23-51-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-51-08 @MBExp.py:227][0m Rewards obtained: [-2052.726187518345], Lows: [799], Highs: [655], Total time: 25867.74372799999
[32m[0906 23-54-11 @MBExp.py:144][0m ####################################################################
[32m[0906 23-54-11 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 23-54-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08636, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-54-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08907, current rewards: -57.56618, mean: -0.95944
[32m[0906 23-54-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08788, current rewards: -110.51854, mean: -1.00471
[32m[0906 23-54-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09115, current rewards: -193.41870, mean: -1.20887
[32m[0906 23-54-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09104, current rewards: -231.70873, mean: -1.10337
[32m[0906 23-54-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09042, current rewards: -225.39331, mean: -0.86690
[32m[0906 23-54-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09026, current rewards: -219.07788, mean: -0.70670
[32m[0906 23-54-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09017, current rewards: -212.76246, mean: -0.59101
[32m[0906 23-54-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09012, current rewards: -206.45498, mean: -0.50355
[32m[0906 23-54-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09007, current rewards: -201.20393, mean: -0.43740
[32m[0906 23-54-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09001, current rewards: -195.95924, mean: -0.38423
[32m[0906 23-55-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08996, current rewards: -190.71455, mean: -0.34056
[32m[0906 23-55-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08990, current rewards: -228.56072, mean: -0.37469
[32m[0906 23-55-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08987, current rewards: -278.56072, mean: -0.42206
[32m[0906 23-55-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08958, current rewards: -328.56072, mean: -0.46276
[32m[0906 23-55-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08923, current rewards: -378.56072, mean: -0.49811
[32m[0906 23-55-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08893, current rewards: -428.56072, mean: -0.52909
[32m[0906 23-55-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08867, current rewards: -478.56072, mean: -0.55647
[32m[0906 23-55-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08846, current rewards: -528.56072, mean: -0.58084
[32m[0906 23-55-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08825, current rewards: -578.56072, mean: -0.60267
[32m[0906 23-55-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08809, current rewards: -628.56072, mean: -0.62234
[32m[0906 23-55-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08793, current rewards: -678.56072, mean: -0.64015
[32m[0906 23-55-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08777, current rewards: -728.56072, mean: -0.65636
[32m[0906 23-55-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08763, current rewards: -778.56072, mean: -0.67117
[32m[0906 23-55-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08752, current rewards: -828.56072, mean: -0.68476
[32m[0906 23-56-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08739, current rewards: -880.56072, mean: -0.69886
[32m[0906 23-56-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08756, current rewards: -946.45439, mean: -0.72248
[32m[0906 23-56-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08767, current rewards: -994.80330, mean: -0.73147
[32m[0906 23-56-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08765, current rewards: -1046.88467, mean: -0.74247
[32m[0906 23-56-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08755, current rewards: -1101.82911, mean: -0.75468
[32m[0906 23-56-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08749, current rewards: -1150.76813, mean: -0.76210
[32m[0906 23-56-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08755, current rewards: -1213.92919, mean: -0.77816
[32m[0906 23-56-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08754, current rewards: -1258.20241, mean: -0.78149
[32m[0906 23-56-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08744, current rewards: -1308.20241, mean: -0.78807
[32m[0906 23-56-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08735, current rewards: -1358.20241, mean: -0.79427
[32m[0906 23-56-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08728, current rewards: -1408.20241, mean: -0.80012
[32m[0906 23-56-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08721, current rewards: -1458.20241, mean: -0.80564
[32m[0906 23-56-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08714, current rewards: -1508.20241, mean: -0.81086
[32m[0906 23-56-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08706, current rewards: -1558.20241, mean: -0.81581
[32m[0906 23-57-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08700, current rewards: -1608.20241, mean: -0.82051
[32m[0906 23-57-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08694, current rewards: -1658.20241, mean: -0.82498
[32m[0906 23-57-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08689, current rewards: -1708.20241, mean: -0.82922
[32m[0906 23-57-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08688, current rewards: -1758.20241, mean: -0.83327
[32m[0906 23-57-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08688, current rewards: -1808.20241, mean: -0.83713
[32m[0906 23-57-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08688, current rewards: -1858.20241, mean: -0.84082
[32m[0906 23-57-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08687, current rewards: -1908.20241, mean: -0.84434
[32m[0906 23-57-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08688, current rewards: -1958.20241, mean: -0.84771
[32m[0906 23-57-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08688, current rewards: -2008.20241, mean: -0.85093
[32m[0906 23-57-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08688, current rewards: -2058.20241, mean: -0.85403
[32m[0906 23-57-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08687, current rewards: -2108.20241, mean: -0.85699
[32m[0906 23-57-49 @Agent.py:117][0m Average action selection time: 0.0869
[32m[0906 23-57-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-57-49 @MBExp.py:227][0m Rewards obtained: [-2148.202405058688], Lows: [125], Highs: [1950], Total time: 26085.67518999999
[32m[0907 00-00-55 @MBExp.py:144][0m ####################################################################
[32m[0907 00-00-55 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 00-00-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08853, current rewards: -0.04758, mean: -0.00476
[32m[0907 00-01-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08742, current rewards: 3.62497, mean: 0.06042
[32m[0907 00-01-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08709, current rewards: 6.16497, mean: 0.05605
[32m[0907 00-01-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08713, current rewards: 9.82833, mean: 0.06143
[32m[0907 00-01-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08706, current rewards: 14.26137, mean: 0.06791
[32m[0907 00-01-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08725, current rewards: 18.23489, mean: 0.07013
[32m[0907 00-01-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08785, current rewards: 10.06939, mean: 0.03248
[32m[0907 00-01-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08853, current rewards: 15.00528, mean: 0.04168
[32m[0907 00-01-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08889, current rewards: 10.33904, mean: 0.02522
[32m[0907 00-01-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08908, current rewards: 14.07994, mean: 0.03061
[32m[0907 00-01-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08911, current rewards: 18.58589, mean: 0.03644
[32m[0907 00-01-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08913, current rewards: 20.68615, mean: 0.03694
[32m[0907 00-01-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08915, current rewards: 28.72285, mean: 0.04709
[32m[0907 00-01-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08936, current rewards: 11.73579, mean: 0.01778
[32m[0907 00-01-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08928, current rewards: 3.13175, mean: 0.00441
[32m[0907 00-02-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08898, current rewards: -6.07321, mean: -0.00799
[32m[0907 00-02-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08871, current rewards: -21.80785, mean: -0.02692
[32m[0907 00-02-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08853, current rewards: -28.34815, mean: -0.03296
[32m[0907 00-02-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08831, current rewards: -38.82014, mean: -0.04266
[32m[0907 00-02-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08816, current rewards: -61.93914, mean: -0.06452
[32m[0907 00-02-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08808, current rewards: -75.49207, mean: -0.07474
[32m[0907 00-02-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08798, current rewards: -69.93339, mean: -0.06597
[32m[0907 00-02-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08792, current rewards: -86.70816, mean: -0.07812
[32m[0907 00-02-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08778, current rewards: -95.51889, mean: -0.08234
[32m[0907 00-02-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08765, current rewards: -90.73922, mean: -0.07499
[32m[0907 00-02-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08752, current rewards: -84.97365, mean: -0.06744
[32m[0907 00-02-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08741, current rewards: -78.93628, mean: -0.06026
[32m[0907 00-02-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08732, current rewards: -72.90286, mean: -0.05361
[32m[0907 00-02-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08722, current rewards: -66.86710, mean: -0.04742
[32m[0907 00-03-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08713, current rewards: -60.83201, mean: -0.04167
[32m[0907 00-03-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08705, current rewards: -54.79516, mean: -0.03629
[32m[0907 00-03-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08702, current rewards: -65.46115, mean: -0.04196
[32m[0907 00-03-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08694, current rewards: -56.14772, mean: -0.03487
[32m[0907 00-03-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08688, current rewards: -44.62503, mean: -0.02688
[32m[0907 00-03-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08681, current rewards: -37.17511, mean: -0.02174
[32m[0907 00-03-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08675, current rewards: -32.07707, mean: -0.01823
[32m[0907 00-03-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08673, current rewards: -33.70966, mean: -0.01862
[32m[0907 00-03-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08678, current rewards: -27.09167, mean: -0.01457
[32m[0907 00-03-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08681, current rewards: -20.57291, mean: -0.01077
[32m[0907 00-03-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08680, current rewards: -13.23994, mean: -0.00676
[32m[0907 00-03-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08679, current rewards: -5.56964, mean: -0.00277
[32m[0907 00-03-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08674, current rewards: -4.15771, mean: -0.00202
[32m[0907 00-03-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08668, current rewards: 0.29875, mean: 0.00014
[32m[0907 00-04-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08668, current rewards: -8.95384, mean: -0.00415
[32m[0907 00-04-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08671, current rewards: -21.25013, mean: -0.00962
[32m[0907 00-04-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08676, current rewards: -38.46051, mean: -0.01702
[32m[0907 00-04-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08679, current rewards: -50.02986, mean: -0.02166
[32m[0907 00-04-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08680, current rewards: -66.70298, mean: -0.02826
[32m[0907 00-04-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08679, current rewards: -92.52908, mean: -0.03839
[32m[0907 00-04-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08679, current rewards: -106.42938, mean: -0.04326
[32m[0907 00-04-33 @Agent.py:117][0m Average action selection time: 0.0868
[32m[0907 00-04-33 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-04-33 @MBExp.py:227][0m Rewards obtained: [-123.46239514833938], Lows: [229], Highs: [22], Total time: 26303.45307799999
[32m[0907 00-07-41 @MBExp.py:144][0m ####################################################################
[32m[0907 00-07-41 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 00-07-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09109, current rewards: -8.94546, mean: -0.89455
[32m[0907 00-07-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10289, current rewards: -54.77860, mean: -0.91298
[32m[0907 00-07-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09999, current rewards: -106.30900, mean: -0.96645
[32m[0907 00-07-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09732, current rewards: -164.74308, mean: -1.02964
[32m[0907 00-08-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09669, current rewards: -212.96248, mean: -1.01411
[32m[0907 00-08-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09690, current rewards: -280.19703, mean: -1.07768
[32m[0907 00-08-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09710, current rewards: -338.09052, mean: -1.09061
[32m[0907 00-08-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09746, current rewards: -379.43467, mean: -1.05399
[32m[0907 00-08-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09734, current rewards: -431.10232, mean: -1.05147
[32m[0907 00-08-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09651, current rewards: -481.10232, mean: -1.04587
[32m[0907 00-08-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09580, current rewards: -531.10232, mean: -1.04138
[32m[0907 00-08-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09524, current rewards: -581.10232, mean: -1.03768
[32m[0907 00-08-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09477, current rewards: -631.10232, mean: -1.03459
[32m[0907 00-08-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09422, current rewards: -681.10232, mean: -1.03197
[32m[0907 00-08-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09353, current rewards: -731.10232, mean: -1.02972
[32m[0907 00-08-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09294, current rewards: -781.10232, mean: -1.02777
[32m[0907 00-08-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09240, current rewards: -831.10232, mean: -1.02605
[32m[0907 00-09-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09195, current rewards: -881.10232, mean: -1.02454
[32m[0907 00-09-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09155, current rewards: -931.10232, mean: -1.02319
[32m[0907 00-09-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09118, current rewards: -981.10232, mean: -1.02198
[32m[0907 00-09-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09085, current rewards: -1031.10232, mean: -1.02089
[32m[0907 00-09-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09055, current rewards: -1081.10232, mean: -1.01991
[32m[0907 00-09-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09027, current rewards: -1131.10232, mean: -1.01901
[32m[0907 00-09-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09004, current rewards: -1181.10232, mean: -1.01819
[32m[0907 00-09-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08981, current rewards: -1231.10232, mean: -1.01744
[32m[0907 00-09-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08958, current rewards: -1281.10232, mean: -1.01675
[32m[0907 00-09-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08937, current rewards: -1331.10232, mean: -1.01611
[32m[0907 00-09-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08919, current rewards: -1381.10232, mean: -1.01552
[32m[0907 00-09-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08903, current rewards: -1431.10232, mean: -1.01497
[32m[0907 00-09-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08889, current rewards: -1481.10232, mean: -1.01445
[32m[0907 00-09-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08874, current rewards: -1531.10232, mean: -1.01398
[32m[0907 00-10-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08860, current rewards: -1581.10232, mean: -1.01353
[32m[0907 00-10-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08848, current rewards: -1631.10232, mean: -1.01311
[32m[0907 00-10-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08836, current rewards: -1681.10232, mean: -1.01271
[32m[0907 00-10-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08825, current rewards: -1731.10232, mean: -1.01234
[32m[0907 00-10-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08816, current rewards: -1781.10232, mean: -1.01199
[32m[0907 00-10-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08805, current rewards: -1831.10232, mean: -1.01166
[32m[0907 00-10-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08796, current rewards: -1855.27868, mean: -0.99746
[32m[0907 00-10-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08788, current rewards: -1851.47943, mean: -0.96936
[32m[0907 00-10-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08780, current rewards: -1847.68018, mean: -0.94269
[32m[0907 00-10-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08770, current rewards: -1843.88093, mean: -0.91735
[32m[0907 00-10-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08763, current rewards: -1845.66644, mean: -0.89595
[32m[0907 00-10-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08757, current rewards: -1895.66644, mean: -0.89842
[32m[0907 00-10-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08756, current rewards: -1945.66644, mean: -0.90077
[32m[0907 00-10-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08754, current rewards: -1995.66644, mean: -0.90302
[32m[0907 00-10-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08753, current rewards: -2045.66644, mean: -0.90516
[32m[0907 00-11-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08752, current rewards: -2095.66644, mean: -0.90721
[32m[0907 00-11-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08751, current rewards: -2145.66644, mean: -0.90918
[32m[0907 00-11-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08750, current rewards: -2195.66644, mean: -0.91106
[32m[0907 00-11-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08749, current rewards: -2245.66644, mean: -0.91287
[32m[0907 00-11-20 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0907 00-11-20 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-11-20 @MBExp.py:227][0m Rewards obtained: [-2285.666439522953], Lows: [125], Highs: [2066], Total time: 26522.90749299999
[32m[0907 00-14-30 @MBExp.py:144][0m ####################################################################
[32m[0907 00-14-30 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 00-14-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08612, current rewards: -12.54858, mean: -1.25486
[32m[0907 00-14-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09050, current rewards: -96.40388, mean: -1.60673
[32m[0907 00-14-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09251, current rewards: -177.94782, mean: -1.61771
[32m[0907 00-14-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09463, current rewards: -256.49357, mean: -1.60308
[32m[0907 00-14-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09615, current rewards: -337.60123, mean: -1.60762
[32m[0907 00-14-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09545, current rewards: -419.31021, mean: -1.61273
[32m[0907 00-15-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09508, current rewards: -504.82455, mean: -1.62847
[32m[0907 00-15-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09483, current rewards: -588.83725, mean: -1.63566
[32m[0907 00-15-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09498, current rewards: -677.59767, mean: -1.65268
[32m[0907 00-15-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09475, current rewards: -761.17254, mean: -1.65472
[32m[0907 00-15-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09553, current rewards: -835.16614, mean: -1.63758
[32m[0907 00-15-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09498, current rewards: -935.16614, mean: -1.66994
[32m[0907 00-15-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09452, current rewards: -1035.16614, mean: -1.69699
[32m[0907 00-15-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09377, current rewards: -1135.16614, mean: -1.71995
[32m[0907 00-15-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09311, current rewards: -1235.16614, mean: -1.73967
[32m[0907 00-15-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09254, current rewards: -1335.16614, mean: -1.75680
[32m[0907 00-15-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09204, current rewards: -1435.16614, mean: -1.77181
[32m[0907 00-15-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09160, current rewards: -1535.16614, mean: -1.78508
[32m[0907 00-15-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09121, current rewards: -1635.16614, mean: -1.79689
[32m[0907 00-15-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09086, current rewards: -1735.16614, mean: -1.80746
[32m[0907 00-16-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09054, current rewards: -1830.50740, mean: -1.81238
[32m[0907 00-16-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09026, current rewards: -1907.14958, mean: -1.79920
[32m[0907 00-16-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08999, current rewards: -1990.87285, mean: -1.79358
[32m[0907 00-16-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08978, current rewards: -2079.46948, mean: -1.79265
[32m[0907 00-16-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08962, current rewards: -2161.79706, mean: -1.78661
[32m[0907 00-16-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08950, current rewards: -2244.73175, mean: -1.78153
[32m[0907 00-16-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08953, current rewards: -2310.93197, mean: -1.76407
[32m[0907 00-16-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08947, current rewards: -2382.93687, mean: -1.75216
[32m[0907 00-16-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08944, current rewards: -2456.49298, mean: -1.74219
[32m[0907 00-16-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08936, current rewards: -2523.64626, mean: -1.72852
[32m[0907 00-16-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08919, current rewards: -2515.09098, mean: -1.66562
[32m[0907 00-16-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08905, current rewards: -2506.62300, mean: -1.60681
[32m[0907 00-16-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08890, current rewards: -2498.15089, mean: -1.55165
[32m[0907 00-16-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08878, current rewards: -2489.68066, mean: -1.49981
[32m[0907 00-17-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08866, current rewards: -2481.20903, mean: -1.45100
[32m[0907 00-17-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08854, current rewards: -2472.75102, mean: -1.40497
[32m[0907 00-17-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08844, current rewards: -2464.28232, mean: -1.36148
[32m[0907 00-17-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08833, current rewards: -2455.81184, mean: -1.32033
[32m[0907 00-17-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08824, current rewards: -2447.33418, mean: -1.28133
[32m[0907 00-17-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08813, current rewards: -2438.85615, mean: -1.24431
[32m[0907 00-17-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08804, current rewards: -2470.28995, mean: -1.22900
[32m[0907 00-17-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08795, current rewards: -2559.14918, mean: -1.24231
[32m[0907 00-17-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08788, current rewards: -2649.99955, mean: -1.25592
[32m[0907 00-17-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08785, current rewards: -2735.25030, mean: -1.26632
[32m[0907 00-17-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08783, current rewards: -2823.75188, mean: -1.27772
[32m[0907 00-17-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08782, current rewards: -2913.15114, mean: -1.28900
[32m[0907 00-17-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08780, current rewards: -2992.17745, mean: -1.29531
[32m[0907 00-17-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08779, current rewards: -3080.29720, mean: -1.30521
[32m[0907 00-18-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08778, current rewards: -3168.44854, mean: -1.31471
[32m[0907 00-18-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08776, current rewards: -3268.44854, mean: -1.32864
[32m[0907 00-18-10 @Agent.py:117][0m Average action selection time: 0.0877
[32m[0907 00-18-10 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-18-10 @MBExp.py:227][0m Rewards obtained: [-3348.448541961609], Lows: [1742], Highs: [19], Total time: 26743.01538399999
[32m[0907 00-21-22 @MBExp.py:144][0m ####################################################################
[32m[0907 00-21-22 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 00-21-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11995, current rewards: -5.41103, mean: -0.54110
[32m[0907 00-21-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09542, current rewards: -73.06506, mean: -1.21775
[32m[0907 00-21-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09876, current rewards: -132.77241, mean: -1.20702
[32m[0907 00-21-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09716, current rewards: -196.25367, mean: -1.22659
[32m[0907 00-21-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09695, current rewards: -268.79509, mean: -1.27998
[32m[0907 00-21-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09570, current rewards: -346.40072, mean: -1.33231
[32m[0907 00-21-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09677, current rewards: -410.73799, mean: -1.32496
[32m[0907 00-21-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09625, current rewards: -482.95741, mean: -1.34155
[32m[0907 00-22-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09613, current rewards: -550.33284, mean: -1.34228
[32m[0907 00-22-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09615, current rewards: -613.23017, mean: -1.33311
[32m[0907 00-22-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09606, current rewards: -675.83129, mean: -1.32516
[32m[0907 00-22-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09589, current rewards: -754.71031, mean: -1.34770
[32m[0907 00-22-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09580, current rewards: -810.64731, mean: -1.32893
[32m[0907 00-22-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09578, current rewards: -889.90334, mean: -1.34834
[32m[0907 00-22-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09575, current rewards: -966.96414, mean: -1.36192
[32m[0907 00-22-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09558, current rewards: -1038.86875, mean: -1.36693
[32m[0907 00-22-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09545, current rewards: -1106.64367, mean: -1.36623
[32m[0907 00-22-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09483, current rewards: -1206.64367, mean: -1.40307
[32m[0907 00-22-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09426, current rewards: -1306.64367, mean: -1.43587
[32m[0907 00-22-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09376, current rewards: -1406.64367, mean: -1.46525
[32m[0907 00-22-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09331, current rewards: -1506.64367, mean: -1.49173
[32m[0907 00-23-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09289, current rewards: -1606.64367, mean: -1.51570
[32m[0907 00-23-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09251, current rewards: -1706.64367, mean: -1.53752
[32m[0907 00-23-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09217, current rewards: -1806.64367, mean: -1.55745
[32m[0907 00-23-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09184, current rewards: -1906.64367, mean: -1.57574
[32m[0907 00-23-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09156, current rewards: -2006.64367, mean: -1.59257
[32m[0907 00-23-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09131, current rewards: -2106.64367, mean: -1.60812
[32m[0907 00-23-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09108, current rewards: -2206.64367, mean: -1.62253
[32m[0907 00-23-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09085, current rewards: -2306.64367, mean: -1.63592
[32m[0907 00-23-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09065, current rewards: -2406.64367, mean: -1.64839
[32m[0907 00-23-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09045, current rewards: -2506.64367, mean: -1.66003
[32m[0907 00-23-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09027, current rewards: -2606.64367, mean: -1.67093
[32m[0907 00-23-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09009, current rewards: -2706.64367, mean: -1.68115
[32m[0907 00-23-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08991, current rewards: -2806.64367, mean: -1.69075
[32m[0907 00-23-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08976, current rewards: -2906.64367, mean: -1.69979
[32m[0907 00-24-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08961, current rewards: -3006.64367, mean: -1.70832
[32m[0907 00-24-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08946, current rewards: -3106.64367, mean: -1.71638
[32m[0907 00-24-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08933, current rewards: -3206.64367, mean: -1.72400
[32m[0907 00-24-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08920, current rewards: -3306.64367, mean: -1.73123
[32m[0907 00-24-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08908, current rewards: -3406.64367, mean: -1.73808
[32m[0907 00-24-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08897, current rewards: -3506.64367, mean: -1.74460
[32m[0907 00-24-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08886, current rewards: -3606.64367, mean: -1.75080
[32m[0907 00-24-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08880, current rewards: -3706.64367, mean: -1.75670
[32m[0907 00-24-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08876, current rewards: -3806.64367, mean: -1.76234
[32m[0907 00-24-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08873, current rewards: -3906.64367, mean: -1.76771
[32m[0907 00-24-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08869, current rewards: -4006.64367, mean: -1.77285
[32m[0907 00-24-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08866, current rewards: -4106.64367, mean: -1.77777
[32m[0907 00-24-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08862, current rewards: -4206.64367, mean: -1.78248
[32m[0907 00-24-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08859, current rewards: -4306.64367, mean: -1.78699
[32m[0907 00-25-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08855, current rewards: -4406.64367, mean: -1.79132
[32m[0907 00-25-04 @Agent.py:117][0m Average action selection time: 0.0885
[32m[0907 00-25-04 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-25-04 @MBExp.py:227][0m Rewards obtained: [-4486.643671482155], Lows: [2212], Highs: [95], Total time: 26965.10549999999
[32m[0907 00-28-17 @MBExp.py:144][0m ####################################################################
[32m[0907 00-28-17 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 00-28-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10563, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-28-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09559, current rewards: -86.03917, mean: -1.43399
[32m[0907 00-28-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09425, current rewards: -163.62196, mean: -1.48747
[32m[0907 00-28-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09297, current rewards: -237.02638, mean: -1.48141
[32m[0907 00-28-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09272, current rewards: -308.16867, mean: -1.46747
[32m[0907 00-28-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09231, current rewards: -390.78965, mean: -1.50304
[32m[0907 00-28-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09336, current rewards: -454.92020, mean: -1.46748
[32m[0907 00-28-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09350, current rewards: -535.41018, mean: -1.48725
[32m[0907 00-28-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09379, current rewards: -606.46614, mean: -1.47919
[32m[0907 00-29-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09371, current rewards: -676.84667, mean: -1.47141
[32m[0907 00-29-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09404, current rewards: -739.55474, mean: -1.45011
[32m[0907 00-29-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09438, current rewards: -816.70736, mean: -1.45841
[32m[0907 00-29-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09387, current rewards: -886.13082, mean: -1.45267
[32m[0907 00-29-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09416, current rewards: -937.49457, mean: -1.42045
[32m[0907 00-29-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09425, current rewards: -998.84282, mean: -1.40682
[32m[0907 00-29-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09403, current rewards: -1073.61052, mean: -1.41265
[32m[0907 00-29-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09437, current rewards: -1136.91851, mean: -1.40360
[32m[0907 00-29-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09473, current rewards: -1208.59984, mean: -1.40535
[32m[0907 00-29-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09532, current rewards: -1269.92661, mean: -1.39552
[32m[0907 00-29-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09517, current rewards: -1345.47498, mean: -1.40154
[32m[0907 00-29-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09523, current rewards: -1414.89169, mean: -1.40088
[32m[0907 00-29-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09525, current rewards: -1473.28411, mean: -1.38989
[32m[0907 00-30-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09503, current rewards: -1542.25152, mean: -1.38942
[32m[0907 00-30-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09492, current rewards: -1601.14787, mean: -1.38030
[32m[0907 00-30-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09504, current rewards: -1672.67210, mean: -1.38237
[32m[0907 00-30-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09498, current rewards: -1733.93539, mean: -1.37614
[32m[0907 00-30-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09473, current rewards: -1804.08823, mean: -1.37717
[32m[0907 00-30-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09437, current rewards: -1879.02971, mean: -1.38164
[32m[0907 00-30-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09408, current rewards: -1949.67881, mean: -1.38275
[32m[0907 00-30-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09399, current rewards: -2020.22201, mean: -1.38371
[32m[0907 00-30-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09410, current rewards: -2091.49979, mean: -1.38510
[32m[0907 00-30-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09414, current rewards: -2154.85511, mean: -1.38132
[32m[0907 00-30-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09400, current rewards: -2233.03909, mean: -1.38698
[32m[0907 00-30-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09388, current rewards: -2313.83315, mean: -1.39388
[32m[0907 00-30-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09389, current rewards: -2381.65823, mean: -1.39278
[32m[0907 00-31-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09383, current rewards: -2432.22142, mean: -1.38194
[32m[0907 00-31-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09381, current rewards: -2496.97533, mean: -1.37954
[32m[0907 00-31-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09385, current rewards: -2577.47751, mean: -1.38574
[32m[0907 00-31-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09382, current rewards: -2648.95549, mean: -1.38689
[32m[0907 00-31-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09392, current rewards: -2713.62711, mean: -1.38450
[32m[0907 00-31-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09410, current rewards: -2783.71054, mean: -1.38493
[32m[0907 00-31-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09412, current rewards: -2871.30540, mean: -1.39384
[32m[0907 00-31-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09411, current rewards: -2951.77834, mean: -1.39895
[32m[0907 00-31-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09416, current rewards: -3030.23369, mean: -1.40289
[32m[0907 00-31-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09406, current rewards: -3074.45782, mean: -1.39116
[32m[0907 00-31-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09418, current rewards: -3120.50567, mean: -1.38075
[32m[0907 00-31-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09417, current rewards: -3169.49515, mean: -1.37208
[32m[0907 00-32-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09420, current rewards: -3226.60979, mean: -1.36721
[32m[0907 00-32-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09405, current rewards: -3220.41772, mean: -1.33627
[32m[0907 00-32-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09391, current rewards: -3213.22174, mean: -1.30619
[32m[0907 00-32-12 @Agent.py:117][0m Average action selection time: 0.0938
[32m[0907 00-32-12 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-32-12 @MBExp.py:227][0m Rewards obtained: [-3207.471588172828], Lows: [1481], Highs: [349], Total time: 27200.32104599999
[32m[0907 00-35-27 @MBExp.py:144][0m ####################################################################
[32m[0907 00-35-27 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 00-35-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08610, current rewards: -2.61405, mean: -0.26141
[32m[0907 00-35-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08776, current rewards: 4.01477, mean: 0.06691
[32m[0907 00-35-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08852, current rewards: 11.66985, mean: 0.10609
[32m[0907 00-35-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08881, current rewards: 19.32493, mean: 0.12078
[32m[0907 00-35-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08897, current rewards: 26.98001, mean: 0.12848
[32m[0907 00-35-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08913, current rewards: 34.63509, mean: 0.13321
[32m[0907 00-35-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08912, current rewards: 41.04637, mean: 0.13241
[32m[0907 00-36-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08920, current rewards: 46.49962, mean: 0.12917
[32m[0907 00-36-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08923, current rewards: 51.95287, mean: 0.12671
[32m[0907 00-36-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08915, current rewards: 24.13417, mean: 0.05247
[32m[0907 00-36-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08881, current rewards: -25.86583, mean: -0.05072
[32m[0907 00-36-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08842, current rewards: -75.86583, mean: -0.13547
[32m[0907 00-36-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08811, current rewards: -125.86583, mean: -0.20634
[32m[0907 00-36-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08780, current rewards: -175.86583, mean: -0.26646
[32m[0907 00-36-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08758, current rewards: -225.86583, mean: -0.31812
[32m[0907 00-36-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08738, current rewards: -275.86583, mean: -0.36298
[32m[0907 00-36-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08721, current rewards: -325.86583, mean: -0.40230
[32m[0907 00-36-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08705, current rewards: -375.86583, mean: -0.43705
[32m[0907 00-36-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08692, current rewards: -425.86583, mean: -0.46798
[32m[0907 00-36-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08677, current rewards: -475.86583, mean: -0.49569
[32m[0907 00-36-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08667, current rewards: -525.86583, mean: -0.52066
[32m[0907 00-36-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08659, current rewards: -575.86583, mean: -0.54327
[32m[0907 00-37-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08651, current rewards: -625.86583, mean: -0.56384
[32m[0907 00-37-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08644, current rewards: -675.86583, mean: -0.58264
[32m[0907 00-37-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08636, current rewards: -725.86583, mean: -0.59989
[32m[0907 00-37-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08630, current rewards: -775.86583, mean: -0.61577
[32m[0907 00-37-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08623, current rewards: -825.86583, mean: -0.63043
[32m[0907 00-37-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08617, current rewards: -875.86583, mean: -0.64402
[32m[0907 00-37-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08611, current rewards: -925.86583, mean: -0.65664
[32m[0907 00-37-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08605, current rewards: -975.86583, mean: -0.66840
[32m[0907 00-37-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08600, current rewards: -1025.86583, mean: -0.67938
[32m[0907 00-37-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08595, current rewards: -1075.86583, mean: -0.68966
[32m[0907 00-37-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08590, current rewards: -1125.86583, mean: -0.69930
[32m[0907 00-37-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08586, current rewards: -1175.86583, mean: -0.70835
[32m[0907 00-37-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08582, current rewards: -1225.86583, mean: -0.71688
[32m[0907 00-37-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08579, current rewards: -1275.86583, mean: -0.72492
[32m[0907 00-38-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08575, current rewards: -1325.86583, mean: -0.73252
[32m[0907 00-38-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08571, current rewards: -1375.86583, mean: -0.73971
[32m[0907 00-38-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08568, current rewards: -1425.86583, mean: -0.74653
[32m[0907 00-38-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08565, current rewards: -1475.86583, mean: -0.75299
[32m[0907 00-38-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08568, current rewards: -1525.86583, mean: -0.75914
[32m[0907 00-38-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08571, current rewards: -1575.86583, mean: -0.76498
[32m[0907 00-38-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08574, current rewards: -1625.86583, mean: -0.77055
[32m[0907 00-38-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08577, current rewards: -1675.86583, mean: -0.77586
[32m[0907 00-38-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08580, current rewards: -1725.86583, mean: -0.78093
[32m[0907 00-38-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08582, current rewards: -1775.86583, mean: -0.78578
[32m[0907 00-38-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08585, current rewards: -1825.86583, mean: -0.79042
[32m[0907 00-38-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08587, current rewards: -1875.86583, mean: -0.79486
[32m[0907 00-38-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08589, current rewards: -1925.86583, mean: -0.79911
[32m[0907 00-38-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08592, current rewards: -1975.86583, mean: -0.80320
[32m[0907 00-39-03 @Agent.py:117][0m Average action selection time: 0.0859
[32m[0907 00-39-03 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-39-03 @MBExp.py:227][0m Rewards obtained: [-2015.8658348174222], Lows: [0], Highs: [2073], Total time: 27415.90844499999
[32m[0907 00-42-20 @MBExp.py:144][0m ####################################################################
[32m[0907 00-42-20 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 00-42-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08509, current rewards: -6.71882, mean: -0.67188
[32m[0907 00-42-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08773, current rewards: -1.51939, mean: -0.02532
[32m[0907 00-42-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08850, current rewards: 3.72517, mean: 0.03387
[32m[0907 00-42-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08874, current rewards: 8.96697, mean: 0.05604
[32m[0907 00-42-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08898, current rewards: 14.20676, mean: 0.06765
[32m[0907 00-42-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08908, current rewards: 19.62922, mean: 0.07550
[32m[0907 00-42-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08930, current rewards: 11.67282, mean: 0.03765
[32m[0907 00-42-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08933, current rewards: 19.32790, mean: 0.05369
[32m[0907 00-42-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08934, current rewards: 26.98298, mean: 0.06581
[32m[0907 00-43-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08941, current rewards: 34.63806, mean: 0.07530
[32m[0907 00-43-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08904, current rewards: 42.29314, mean: 0.08293
[32m[0907 00-43-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08864, current rewards: 49.94822, mean: 0.08919
[32m[0907 00-43-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08832, current rewards: 57.60331, mean: 0.09443
[32m[0907 00-43-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08803, current rewards: 24.89983, mean: 0.03773
[32m[0907 00-43-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08781, current rewards: -25.10017, mean: -0.03535
[32m[0907 00-43-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08763, current rewards: -75.10017, mean: -0.09882
[32m[0907 00-43-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08745, current rewards: -125.10017, mean: -0.15444
[32m[0907 00-43-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08728, current rewards: -175.10017, mean: -0.20360
[32m[0907 00-43-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08713, current rewards: -225.10017, mean: -0.24736
[32m[0907 00-43-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08696, current rewards: -275.10017, mean: -0.28656
[32m[0907 00-43-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08683, current rewards: -325.10017, mean: -0.32188
[32m[0907 00-43-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08671, current rewards: -375.10017, mean: -0.35387
[32m[0907 00-43-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08662, current rewards: -425.10017, mean: -0.38297
[32m[0907 00-44-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08653, current rewards: -475.10017, mean: -0.40957
[32m[0907 00-44-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08645, current rewards: -525.10017, mean: -0.43397
[32m[0907 00-44-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08637, current rewards: -575.10017, mean: -0.45643
[32m[0907 00-44-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08631, current rewards: -625.10017, mean: -0.47718
[32m[0907 00-44-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08624, current rewards: -675.10017, mean: -0.49640
[32m[0907 00-44-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08616, current rewards: -725.10017, mean: -0.51426
[32m[0907 00-44-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08609, current rewards: -775.10017, mean: -0.53089
[32m[0907 00-44-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08603, current rewards: -825.10017, mean: -0.54642
[32m[0907 00-44-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08599, current rewards: -875.10017, mean: -0.56096
[32m[0907 00-44-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08595, current rewards: -925.10017, mean: -0.57460
[32m[0907 00-44-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08591, current rewards: -975.10017, mean: -0.58741
[32m[0907 00-44-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08586, current rewards: -1025.10017, mean: -0.59947
[32m[0907 00-44-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08583, current rewards: -1075.10017, mean: -0.61085
[32m[0907 00-44-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08580, current rewards: -1125.10017, mean: -0.62160
[32m[0907 00-45-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08577, current rewards: -1175.10017, mean: -0.63177
[32m[0907 00-45-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08572, current rewards: -1225.10017, mean: -0.64141
[32m[0907 00-45-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08569, current rewards: -1275.10017, mean: -0.65056
[32m[0907 00-45-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08568, current rewards: -1325.10017, mean: -0.65925
[32m[0907 00-45-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08570, current rewards: -1375.10017, mean: -0.66752
[32m[0907 00-45-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08573, current rewards: -1425.10017, mean: -0.67540
[32m[0907 00-45-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08576, current rewards: -1475.10017, mean: -0.68292
[32m[0907 00-45-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08578, current rewards: -1525.10017, mean: -0.69009
[32m[0907 00-45-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08580, current rewards: -1575.10017, mean: -0.69695
[32m[0907 00-45-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08581, current rewards: -1625.10017, mean: -0.70351
[32m[0907 00-45-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08583, current rewards: -1675.10017, mean: -0.70979
[32m[0907 00-45-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08585, current rewards: -1725.10017, mean: -0.71581
[32m[0907 00-45-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08586, current rewards: -1775.10017, mean: -0.72159
[32m[0907 00-45-55 @Agent.py:117][0m Average action selection time: 0.0859
[32m[0907 00-45-55 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-45-55 @MBExp.py:227][0m Rewards obtained: [-1815.1001702837543], Lows: [8], Highs: [1880], Total time: 27631.36541799999
[32m[0907 00-49-14 @MBExp.py:144][0m ####################################################################
[32m[0907 00-49-14 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 00-49-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08589, current rewards: -8.24866, mean: -0.82487
[32m[0907 00-49-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08767, current rewards: -22.50824, mean: -0.37514
[32m[0907 00-49-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08846, current rewards: -17.61086, mean: -0.16010
[32m[0907 00-49-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08877, current rewards: -12.71458, mean: -0.07947
[32m[0907 00-49-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08895, current rewards: -7.80742, mean: -0.03718
[32m[0907 00-49-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08901, current rewards: -2.33558, mean: -0.00898
[32m[0907 00-49-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08910, current rewards: 1.28156, mean: 0.00413
[32m[0907 00-49-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08915, current rewards: 4.86107, mean: 0.01350
[32m[0907 00-49-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08917, current rewards: -16.86268, mean: -0.04113
[32m[0907 00-49-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08922, current rewards: -34.99480, mean: -0.07608
[32m[0907 00-49-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08900, current rewards: -61.40634, mean: -0.12040
[32m[0907 00-50-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08860, current rewards: -81.59143, mean: -0.14570
[32m[0907 00-50-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08832, current rewards: -106.19244, mean: -0.17409
[32m[0907 00-50-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08804, current rewards: -132.70041, mean: -0.20106
[32m[0907 00-50-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08801, current rewards: -151.50886, mean: -0.21339
[32m[0907 00-50-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08785, current rewards: -162.88467, mean: -0.21432
[32m[0907 00-50-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08767, current rewards: -169.59438, mean: -0.20938
[32m[0907 00-50-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08757, current rewards: -169.58846, mean: -0.19720
[32m[0907 00-50-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08739, current rewards: -172.10930, mean: -0.18913
[32m[0907 00-50-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08724, current rewards: -174.63561, mean: -0.18191
[32m[0907 00-50-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08708, current rewards: -179.23481, mean: -0.17746
[32m[0907 00-50-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08696, current rewards: -186.59572, mean: -0.17603
[32m[0907 00-50-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08709, current rewards: -200.41528, mean: -0.18055
[32m[0907 00-50-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08724, current rewards: -222.80600, mean: -0.19207
[32m[0907 00-51-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08723, current rewards: -244.00218, mean: -0.20165
[32m[0907 00-51-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08723, current rewards: -256.16694, mean: -0.20331
[32m[0907 00-51-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08726, current rewards: -276.23985, mean: -0.21087
[32m[0907 00-51-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08720, current rewards: -293.57055, mean: -0.21586
[32m[0907 00-51-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08727, current rewards: -310.36821, mean: -0.22012
[32m[0907 00-51-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08728, current rewards: -337.09709, mean: -0.23089
[32m[0907 00-51-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08722, current rewards: -355.88227, mean: -0.23568
[32m[0907 00-51-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08725, current rewards: -366.03926, mean: -0.23464
[32m[0907 00-51-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08725, current rewards: -389.55484, mean: -0.24196
[32m[0907 00-51-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08723, current rewards: -422.91054, mean: -0.25477
[32m[0907 00-51-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08715, current rewards: -414.44555, mean: -0.24237
[32m[0907 00-51-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08709, current rewards: -406.92636, mean: -0.23121
[32m[0907 00-51-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08703, current rewards: -399.40340, mean: -0.22066
[32m[0907 00-51-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08696, current rewards: -391.88134, mean: -0.21069
[32m[0907 00-52-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08689, current rewards: -383.20043, mean: -0.20063
[32m[0907 00-52-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08683, current rewards: -376.65616, mean: -0.19217
[32m[0907 00-52-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08679, current rewards: -370.11672, mean: -0.18414
[32m[0907 00-52-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08685, current rewards: -382.26189, mean: -0.18556
[32m[0907 00-52-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08684, current rewards: -396.30146, mean: -0.18782
[32m[0907 00-52-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08684, current rewards: -409.02916, mean: -0.18937
[32m[0907 00-52-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08685, current rewards: -421.78558, mean: -0.19085
[32m[0907 00-52-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08685, current rewards: -436.61593, mean: -0.19319
[32m[0907 00-52-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08684, current rewards: -438.31353, mean: -0.18975
[32m[0907 00-52-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08685, current rewards: -431.80912, mean: -0.18297
[32m[0907 00-52-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08685, current rewards: -425.26851, mean: -0.17646
[32m[0907 00-52-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08684, current rewards: -418.73341, mean: -0.17022
[32m[0907 00-52-51 @Agent.py:117][0m Average action selection time: 0.0868
[32m[0907 00-52-51 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-52-52 @MBExp.py:227][0m Rewards obtained: [-413.5085648264097], Lows: [304], Highs: [83], Total time: 27849.23839099999
[32m[0907 00-56-12 @MBExp.py:144][0m ####################################################################
[32m[0907 00-56-12 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 00-56-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08707, current rewards: -14.00000, mean: -1.40000
[32m[0907 00-56-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08874, current rewards: -114.00000, mean: -1.90000
[32m[0907 00-56-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08908, current rewards: -214.00000, mean: -1.94545
[32m[0907 00-56-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08918, current rewards: -314.00000, mean: -1.96250
[32m[0907 00-56-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08921, current rewards: -414.00000, mean: -1.97143
[32m[0907 00-56-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08926, current rewards: -514.00000, mean: -1.97692
[32m[0907 00-56-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08945, current rewards: -614.00000, mean: -1.98065
[32m[0907 00-56-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08940, current rewards: -714.00000, mean: -1.98333
[32m[0907 00-56-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08939, current rewards: -814.00000, mean: -1.98537
[32m[0907 00-56-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08939, current rewards: -914.00000, mean: -1.98696
[32m[0907 00-56-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08911, current rewards: -1014.00000, mean: -1.98824
[32m[0907 00-57-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08893, current rewards: -1114.00000, mean: -1.98929
[32m[0907 00-57-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08865, current rewards: -1214.00000, mean: -1.99016
[32m[0907 00-57-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08830, current rewards: -1314.00000, mean: -1.99091
[32m[0907 00-57-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08804, current rewards: -1414.00000, mean: -1.99155
[32m[0907 00-57-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08780, current rewards: -1514.00000, mean: -1.99211
[32m[0907 00-57-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08764, current rewards: -1614.00000, mean: -1.99259
[32m[0907 00-57-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08745, current rewards: -1639.97473, mean: -1.90695
[32m[0907 00-57-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08733, current rewards: -1660.91220, mean: -1.82518
[32m[0907 00-57-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08717, current rewards: -1669.63713, mean: -1.73921
[32m[0907 00-57-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08705, current rewards: -1676.14570, mean: -1.65955
[32m[0907 00-57-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08692, current rewards: -1694.06899, mean: -1.59818
[32m[0907 00-57-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08679, current rewards: -1719.64649, mean: -1.54923
[32m[0907 00-57-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08669, current rewards: -1762.02876, mean: -1.51899
[32m[0907 00-57-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08659, current rewards: -1823.04434, mean: -1.50665
[32m[0907 00-58-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08652, current rewards: -1886.12103, mean: -1.49692
[32m[0907 00-58-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08645, current rewards: -1946.10430, mean: -1.48558
[32m[0907 00-58-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08638, current rewards: -2006.88686, mean: -1.47565
[32m[0907 00-58-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08636, current rewards: -2077.05222, mean: -1.47309
[32m[0907 00-58-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08633, current rewards: -2141.62061, mean: -1.46686
[32m[0907 00-58-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08627, current rewards: -2190.41957, mean: -1.45061
[32m[0907 00-58-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08621, current rewards: -2236.34264, mean: -1.43355
[32m[0907 00-58-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08616, current rewards: -2283.40796, mean: -1.41827
[32m[0907 00-58-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08611, current rewards: -2333.68253, mean: -1.40583
[32m[0907 00-58-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08606, current rewards: -2393.97158, mean: -1.39998
[32m[0907 00-58-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08604, current rewards: -2443.56196, mean: -1.38839
[32m[0907 00-58-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08600, current rewards: -2453.54542, mean: -1.35555
[32m[0907 00-58-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08596, current rewards: -2442.77934, mean: -1.31332
[32m[0907 00-58-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08592, current rewards: -2432.06378, mean: -1.27333
[32m[0907 00-59-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08589, current rewards: -2421.32427, mean: -1.23537
[32m[0907 00-59-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08585, current rewards: -2410.50963, mean: -1.19926
[32m[0907 00-59-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08586, current rewards: -2399.79843, mean: -1.16495
[32m[0907 00-59-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08588, current rewards: -2389.09909, mean: -1.13227
[32m[0907 00-59-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08590, current rewards: -2378.38512, mean: -1.10110
[32m[0907 00-59-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08592, current rewards: -2367.52298, mean: -1.07128
[32m[0907 00-59-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08594, current rewards: -2360.80717, mean: -1.04460
[32m[0907 00-59-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08599, current rewards: -2456.46331, mean: -1.06340
[32m[0907 00-59-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08601, current rewards: -2556.46331, mean: -1.08325
[32m[0907 00-59-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08603, current rewards: -2656.46331, mean: -1.10227
[32m[0907 00-59-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08605, current rewards: -2756.46331, mean: -1.12051
[32m[0907 00-59-48 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 00-59-48 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-59-48 @MBExp.py:227][0m Rewards obtained: [-2836.4633079821433], Lows: [1532], Highs: [19], Total time: 28065.138730999992
[32m[0907 01-03-11 @MBExp.py:144][0m ####################################################################
[32m[0907 01-03-11 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 01-03-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09129, current rewards: 0.81238, mean: 0.08124
[32m[0907 01-03-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08949, current rewards: 7.52593, mean: 0.12543
[32m[0907 01-03-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08955, current rewards: 16.64117, mean: 0.15128
[32m[0907 01-03-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08965, current rewards: 25.70942, mean: 0.16068
[32m[0907 01-03-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08966, current rewards: 32.50414, mean: 0.15478
[32m[0907 01-03-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08985, current rewards: 2.24468, mean: 0.00863
[32m[0907 01-03-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08999, current rewards: -15.48669, mean: -0.04996
[32m[0907 01-03-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09019, current rewards: -102.17782, mean: -0.28383
[32m[0907 01-03-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09018, current rewards: -176.53006, mean: -0.43056
[32m[0907 01-03-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09011, current rewards: -168.23139, mean: -0.36572
[32m[0907 01-03-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08983, current rewards: -159.97171, mean: -0.31367
[32m[0907 01-04-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08957, current rewards: -151.71834, mean: -0.27093
[32m[0907 01-04-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08934, current rewards: -142.45331, mean: -0.23353
[32m[0907 01-04-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08916, current rewards: -131.78698, mean: -0.19968
[32m[0907 01-04-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08896, current rewards: -121.65118, mean: -0.17134
[32m[0907 01-04-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08883, current rewards: -111.51062, mean: -0.14672
[32m[0907 01-04-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08871, current rewards: -101.36678, mean: -0.12514
[32m[0907 01-04-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08883, current rewards: -130.35005, mean: -0.15157
[32m[0907 01-04-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08867, current rewards: -165.01675, mean: -0.18134
[32m[0907 01-04-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08847, current rewards: -176.05408, mean: -0.18339
[32m[0907 01-04-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08827, current rewards: -171.76719, mean: -0.17007
[32m[0907 01-04-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08812, current rewards: -161.56415, mean: -0.15242
[32m[0907 01-04-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08797, current rewards: -176.40042, mean: -0.15892
[32m[0907 01-04-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08780, current rewards: -218.12723, mean: -0.18804
[32m[0907 01-04-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08765, current rewards: -260.78347, mean: -0.21552
[32m[0907 01-05-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08754, current rewards: -339.05759, mean: -0.26909
[32m[0907 01-05-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08742, current rewards: -439.05759, mean: -0.33516
[32m[0907 01-05-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08730, current rewards: -539.05759, mean: -0.39637
[32m[0907 01-05-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08721, current rewards: -639.05759, mean: -0.45323
[32m[0907 01-05-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08712, current rewards: -739.05759, mean: -0.50620
[32m[0907 01-05-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08703, current rewards: -839.05759, mean: -0.55567
[32m[0907 01-05-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08697, current rewards: -939.05759, mean: -0.60196
[32m[0907 01-05-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08691, current rewards: -1039.05759, mean: -0.64538
[32m[0907 01-05-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08684, current rewards: -1139.05759, mean: -0.68618
[32m[0907 01-05-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08678, current rewards: -1239.05759, mean: -0.72460
[32m[0907 01-05-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08674, current rewards: -1332.56427, mean: -0.75714
[32m[0907 01-05-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08671, current rewards: -1376.45023, mean: -0.76047
[32m[0907 01-05-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08685, current rewards: -1464.87461, mean: -0.78757
[32m[0907 01-05-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08693, current rewards: -1523.79776, mean: -0.79780
[32m[0907 01-06-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08695, current rewards: -1577.63752, mean: -0.80492
[32m[0907 01-06-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08703, current rewards: -1654.60812, mean: -0.82319
[32m[0907 01-06-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08703, current rewards: -1683.44032, mean: -0.81720
[32m[0907 01-06-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08703, current rewards: -1737.89823, mean: -0.82365
[32m[0907 01-06-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08703, current rewards: -1785.28455, mean: -0.82652
[32m[0907 01-06-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08706, current rewards: -1818.93821, mean: -0.82305
[32m[0907 01-06-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08707, current rewards: -1833.91668, mean: -0.81147
[32m[0907 01-06-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08707, current rewards: -1844.05918, mean: -0.79829
[32m[0907 01-06-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08707, current rewards: -1857.36211, mean: -0.78702
[32m[0907 01-06-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08708, current rewards: -1885.68650, mean: -0.78244
[32m[0907 01-06-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08711, current rewards: -1897.29068, mean: -0.77126
[32m[0907 01-06-49 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 01-06-49 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-06-49 @MBExp.py:227][0m Rewards obtained: [-1911.844659517967], Lows: [1019], Highs: [144], Total time: 28283.688200999994
[32m[0907 01-10-14 @MBExp.py:144][0m ####################################################################
[32m[0907 01-10-14 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 01-10-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08816, current rewards: -1.43076, mean: -0.14308
[32m[0907 01-10-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08951, current rewards: 2.21825, mean: 0.03697
[32m[0907 01-10-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08943, current rewards: 5.84335, mean: 0.05312
[32m[0907 01-10-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08946, current rewards: 9.46848, mean: 0.05918
[32m[0907 01-10-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08952, current rewards: 13.09371, mean: 0.06235
[32m[0907 01-10-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08952, current rewards: 16.71852, mean: 0.06430
[32m[0907 01-10-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08950, current rewards: 20.34317, mean: 0.06562
[32m[0907 01-10-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08954, current rewards: 23.96782, mean: 0.06658
[32m[0907 01-10-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08954, current rewards: 27.59261, mean: 0.06730
[32m[0907 01-10-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08953, current rewards: 31.21774, mean: 0.06786
[32m[0907 01-10-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08954, current rewards: 34.84240, mean: 0.06832
[32m[0907 01-11-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08953, current rewards: 3.90164, mean: 0.00697
[32m[0907 01-11-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08954, current rewards: -29.23629, mean: -0.04793
[32m[0907 01-11-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08942, current rewards: -41.73415, mean: -0.06323
[32m[0907 01-11-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08922, current rewards: -36.22635, mean: -0.05102
[32m[0907 01-11-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08908, current rewards: -30.71471, mean: -0.04041
[32m[0907 01-11-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08895, current rewards: -25.19951, mean: -0.03111
[32m[0907 01-11-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08884, current rewards: -19.69481, mean: -0.02290
[32m[0907 01-11-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08874, current rewards: -16.40379, mean: -0.01803
[32m[0907 01-11-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08853, current rewards: -16.42290, mean: -0.01711
[32m[0907 01-11-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08834, current rewards: -13.21390, mean: -0.01308
[32m[0907 01-11-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08817, current rewards: -9.96984, mean: -0.00941
[32m[0907 01-11-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08801, current rewards: -6.71041, mean: -0.00605
[32m[0907 01-11-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08786, current rewards: -3.44637, mean: -0.00297
[32m[0907 01-12-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08772, current rewards: -0.18800, mean: -0.00016
[32m[0907 01-12-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08761, current rewards: 3.07366, mean: 0.00244
[32m[0907 01-12-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08750, current rewards: 6.33898, mean: 0.00484
[32m[0907 01-12-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08740, current rewards: 9.60069, mean: 0.00706
[32m[0907 01-12-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08730, current rewards: 12.85613, mean: 0.00912
[32m[0907 01-12-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08720, current rewards: 6.04392, mean: 0.00414
[32m[0907 01-12-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08711, current rewards: 9.64691, mean: 0.00639
[32m[0907 01-12-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08703, current rewards: 13.24037, mean: 0.00849
[32m[0907 01-12-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08695, current rewards: 16.83292, mean: 0.01046
[32m[0907 01-12-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08688, current rewards: 20.42622, mean: 0.01230
[32m[0907 01-12-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08681, current rewards: 24.01855, mean: 0.01405
[32m[0907 01-12-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08674, current rewards: 20.99332, mean: 0.01193
[32m[0907 01-12-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08667, current rewards: 26.03807, mean: 0.01439
[32m[0907 01-12-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08661, current rewards: 31.08587, mean: 0.01671
[32m[0907 01-12-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08655, current rewards: 36.13370, mean: 0.01892
[32m[0907 01-13-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08650, current rewards: 41.18012, mean: 0.02101
[32m[0907 01-13-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08644, current rewards: 46.23108, mean: 0.02300
[32m[0907 01-13-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08640, current rewards: 40.33561, mean: 0.01958
[32m[0907 01-13-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08635, current rewards: 44.52235, mean: 0.02110
[32m[0907 01-13-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08635, current rewards: 48.70792, mean: 0.02255
[32m[0907 01-13-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08636, current rewards: 52.89395, mean: 0.02393
[32m[0907 01-13-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08637, current rewards: 57.59711, mean: 0.02549
[32m[0907 01-13-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08637, current rewards: 52.87701, mean: 0.02289
[32m[0907 01-13-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08638, current rewards: 58.44016, mean: 0.02476
[32m[0907 01-13-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08639, current rewards: 64.00330, mean: 0.02656
[32m[0907 01-13-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08640, current rewards: 69.56645, mean: 0.02828
[32m[0907 01-13-50 @Agent.py:117][0m Average action selection time: 0.0864
[32m[0907 01-13-50 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-13-50 @MBExp.py:227][0m Rewards obtained: [74.01697032700318], Lows: [63], Highs: [16], Total time: 28500.402044999995
[32m[0907 01-17-16 @MBExp.py:144][0m ####################################################################
[32m[0907 01-17-16 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 01-17-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08763, current rewards: -8.94252, mean: -0.89425
[32m[0907 01-17-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08930, current rewards: -16.29674, mean: -0.27161
[32m[0907 01-17-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08933, current rewards: -12.26754, mean: -0.11152
[32m[0907 01-17-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08928, current rewards: -8.34492, mean: -0.05216
[32m[0907 01-17-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08935, current rewards: -4.31120, mean: -0.02053
[32m[0907 01-17-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08936, current rewards: -0.27821, mean: -0.00107
[32m[0907 01-17-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08936, current rewards: -16.45619, mean: -0.05308
[32m[0907 01-17-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08934, current rewards: -66.45619, mean: -0.18460
[32m[0907 01-17-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08938, current rewards: -116.45619, mean: -0.28404
[32m[0907 01-17-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08938, current rewards: -166.45619, mean: -0.36186
[32m[0907 01-18-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08938, current rewards: -216.45619, mean: -0.42442
[32m[0907 01-18-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08941, current rewards: -266.45619, mean: -0.47581
[32m[0907 01-18-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08942, current rewards: -316.45619, mean: -0.51878
[32m[0907 01-18-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08942, current rewards: -366.45619, mean: -0.55524
[32m[0907 01-18-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08927, current rewards: -416.45619, mean: -0.58656
[32m[0907 01-18-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08909, current rewards: -466.45619, mean: -0.61376
[32m[0907 01-18-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08895, current rewards: -516.45619, mean: -0.63760
[32m[0907 01-18-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08880, current rewards: -566.45619, mean: -0.65867
[32m[0907 01-18-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08869, current rewards: -616.45619, mean: -0.67742
[32m[0907 01-18-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08850, current rewards: -666.45619, mean: -0.69423
[32m[0907 01-18-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08848, current rewards: -708.78945, mean: -0.70177
[32m[0907 01-18-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08854, current rewards: -753.50949, mean: -0.71086
[32m[0907 01-18-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08836, current rewards: -803.50949, mean: -0.72388
[32m[0907 01-18-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08817, current rewards: -853.50949, mean: -0.73578
[32m[0907 01-19-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08803, current rewards: -903.50949, mean: -0.74670
[32m[0907 01-19-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08789, current rewards: -953.50949, mean: -0.75675
[32m[0907 01-19-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08776, current rewards: -1003.50949, mean: -0.76604
[32m[0907 01-19-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08765, current rewards: -1053.50949, mean: -0.77464
[32m[0907 01-19-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08754, current rewards: -1103.50949, mean: -0.78263
[32m[0907 01-19-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08744, current rewards: -1153.50949, mean: -0.79007
[32m[0907 01-19-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08734, current rewards: -1172.17515, mean: -0.77627
[32m[0907 01-19-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08726, current rewards: -1181.66351, mean: -0.75748
[32m[0907 01-19-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08717, current rewards: -1190.05844, mean: -0.73917
[32m[0907 01-19-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08710, current rewards: -1196.33549, mean: -0.72068
[32m[0907 01-19-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08709, current rewards: -1210.18151, mean: -0.70771
[32m[0907 01-19-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08702, current rewards: -1223.98310, mean: -0.69544
[32m[0907 01-19-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08695, current rewards: -1230.22348, mean: -0.67968
[32m[0907 01-19-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08688, current rewards: -1237.50246, mean: -0.66532
[32m[0907 01-20-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08682, current rewards: -1260.64077, mean: -0.66002
[32m[0907 01-20-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08676, current rewards: -1310.64077, mean: -0.66869
[32m[0907 01-20-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08672, current rewards: -1360.64077, mean: -0.67694
[32m[0907 01-20-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08667, current rewards: -1410.64077, mean: -0.68478
[32m[0907 01-20-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08662, current rewards: -1460.64077, mean: -0.69225
[32m[0907 01-20-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08658, current rewards: -1510.64077, mean: -0.69937
[32m[0907 01-20-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08655, current rewards: -1560.64077, mean: -0.70617
[32m[0907 01-20-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08655, current rewards: -1614.59304, mean: -0.71442
[32m[0907 01-20-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08665, current rewards: -1658.29815, mean: -0.71788
[32m[0907 01-20-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08673, current rewards: -1703.05207, mean: -0.72163
[32m[0907 01-20-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08683, current rewards: -1747.80994, mean: -0.72523
[32m[0907 01-20-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08688, current rewards: -1792.56758, mean: -0.72869
[32m[0907 01-20-54 @Agent.py:117][0m Average action selection time: 0.0869
[32m[0907 01-20-54 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-20-54 @MBExp.py:227][0m Rewards obtained: [-1827.3253144506496], Lows: [13], Highs: [1847], Total time: 28718.434652999997
[32m[0907 01-24-22 @MBExp.py:144][0m ####################################################################
[32m[0907 01-24-22 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 01-24-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08903, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-24-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08908, current rewards: -115.00000, mean: -1.91667
[32m[0907 01-24-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08915, current rewards: -215.00000, mean: -1.95455
[32m[0907 01-24-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08928, current rewards: -315.00000, mean: -1.96875
[32m[0907 01-24-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08936, current rewards: -415.00000, mean: -1.97619
[32m[0907 01-24-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08932, current rewards: -515.00000, mean: -1.98077
[32m[0907 01-24-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08936, current rewards: -615.00000, mean: -1.98387
[32m[0907 01-24-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08935, current rewards: -715.00000, mean: -1.98611
[32m[0907 01-24-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08935, current rewards: -815.00000, mean: -1.98780
[32m[0907 01-25-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08938, current rewards: -915.00000, mean: -1.98913
[32m[0907 01-25-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08935, current rewards: -1015.00000, mean: -1.99020
[32m[0907 01-25-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08935, current rewards: -1115.00000, mean: -1.99107
[32m[0907 01-25-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08934, current rewards: -1215.00000, mean: -1.99180
[32m[0907 01-25-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08935, current rewards: -1315.00000, mean: -1.99242
[32m[0907 01-25-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08919, current rewards: -1415.00000, mean: -1.99296
[32m[0907 01-25-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08900, current rewards: -1515.00000, mean: -1.99342
[32m[0907 01-25-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08885, current rewards: -1615.00000, mean: -1.99383
[32m[0907 01-25-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08872, current rewards: -1715.00000, mean: -1.99419
[32m[0907 01-25-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08862, current rewards: -1815.00000, mean: -1.99451
[32m[0907 01-25-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08840, current rewards: -1915.00000, mean: -1.99479
[32m[0907 01-25-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08820, current rewards: -2015.00000, mean: -1.99505
[32m[0907 01-25-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08803, current rewards: -2115.00000, mean: -1.99528
[32m[0907 01-25-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08787, current rewards: -2215.00000, mean: -1.99550
[32m[0907 01-26-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08773, current rewards: -2315.00000, mean: -1.99569
[32m[0907 01-26-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08759, current rewards: -2415.00000, mean: -1.99587
[32m[0907 01-26-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08747, current rewards: -2515.00000, mean: -1.99603
[32m[0907 01-26-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08736, current rewards: -2615.00000, mean: -1.99618
[32m[0907 01-26-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08725, current rewards: -2715.00000, mean: -1.99632
[32m[0907 01-26-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08715, current rewards: -2815.00000, mean: -1.99645
[32m[0907 01-26-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08705, current rewards: -2915.00000, mean: -1.99658
[32m[0907 01-26-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08698, current rewards: -3015.00000, mean: -1.99669
[32m[0907 01-26-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08690, current rewards: -3115.00000, mean: -1.99679
[32m[0907 01-26-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08682, current rewards: -3215.00000, mean: -1.99689
[32m[0907 01-26-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08676, current rewards: -3315.00000, mean: -1.99699
[32m[0907 01-26-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08669, current rewards: -3415.00000, mean: -1.99708
[32m[0907 01-26-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08664, current rewards: -3515.00000, mean: -1.99716
[32m[0907 01-26-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08658, current rewards: -3615.00000, mean: -1.99724
[32m[0907 01-27-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08653, current rewards: -3715.00000, mean: -1.99731
[32m[0907 01-27-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08648, current rewards: -3815.00000, mean: -1.99738
[32m[0907 01-27-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08643, current rewards: -3915.00000, mean: -1.99745
[32m[0907 01-27-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08639, current rewards: -4015.00000, mean: -1.99751
[32m[0907 01-27-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08635, current rewards: -4115.00000, mean: -1.99757
[32m[0907 01-27-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08631, current rewards: -4215.00000, mean: -1.99763
[32m[0907 01-27-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08626, current rewards: -4315.00000, mean: -1.99769
[32m[0907 01-27-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08624, current rewards: -4415.00000, mean: -1.99774
[32m[0907 01-27-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08625, current rewards: -4515.00000, mean: -1.99779
[32m[0907 01-27-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08627, current rewards: -4615.00000, mean: -1.99784
[32m[0907 01-27-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08627, current rewards: -4715.00000, mean: -1.99788
[32m[0907 01-27-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08628, current rewards: -4815.00000, mean: -1.99793
[32m[0907 01-27-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08629, current rewards: -4915.00000, mean: -1.99797
[32m[0907 01-27-58 @Agent.py:117][0m Average action selection time: 0.0863
[32m[0907 01-27-58 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-27-58 @MBExp.py:227][0m Rewards obtained: [-4995], Lows: [2495], Highs: [5], Total time: 28934.841945999997
[32m[0907 01-31-27 @MBExp.py:144][0m ####################################################################
[32m[0907 01-31-27 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 01-31-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08887, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-31-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08952, current rewards: -105.93270, mean: -1.76554
[32m[0907 01-31-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08956, current rewards: -205.93270, mean: -1.87212
[32m[0907 01-31-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08962, current rewards: -305.93270, mean: -1.91208
[32m[0907 01-31-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08956, current rewards: -405.93270, mean: -1.93301
[32m[0907 01-31-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08954, current rewards: -505.93270, mean: -1.94589
[32m[0907 01-31-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08952, current rewards: -605.93270, mean: -1.95462
[32m[0907 01-31-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08953, current rewards: -705.93270, mean: -1.96092
[32m[0907 01-32-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08951, current rewards: -805.93270, mean: -1.96569
[32m[0907 01-32-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08997, current rewards: -883.36537, mean: -1.92036
[32m[0907 01-32-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09041, current rewards: -920.16201, mean: -1.80424
[32m[0907 01-32-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09052, current rewards: -948.24909, mean: -1.69330
[32m[0907 01-32-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09052, current rewards: -982.47497, mean: -1.61061
[32m[0907 01-32-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09057, current rewards: -1008.47632, mean: -1.52799
[32m[0907 01-32-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09068, current rewards: -1040.45116, mean: -1.46542
[32m[0907 01-32-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09068, current rewards: -1081.19019, mean: -1.42262
[32m[0907 01-32-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09050, current rewards: -1141.49663, mean: -1.40926
[32m[0907 01-32-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09029, current rewards: -1241.49663, mean: -1.44360
[32m[0907 01-32-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09011, current rewards: -1341.49663, mean: -1.47417
[32m[0907 01-32-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08982, current rewards: -1441.49663, mean: -1.50156
[32m[0907 01-32-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08956, current rewards: -1541.49663, mean: -1.52623
[32m[0907 01-33-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08935, current rewards: -1641.49663, mean: -1.54858
[32m[0907 01-33-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08913, current rewards: -1716.38690, mean: -1.54629
[32m[0907 01-33-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08894, current rewards: -1767.00654, mean: -1.52328
[32m[0907 01-33-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08876, current rewards: -1813.60139, mean: -1.49884
[32m[0907 01-33-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08860, current rewards: -1889.31119, mean: -1.49945
[32m[0907 01-33-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08842, current rewards: -1989.31119, mean: -1.51856
[32m[0907 01-33-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08829, current rewards: -2089.31119, mean: -1.53626
[32m[0907 01-33-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08817, current rewards: -2189.31119, mean: -1.55270
[32m[0907 01-33-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08805, current rewards: -2289.31119, mean: -1.56802
[32m[0907 01-33-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08793, current rewards: -2389.31119, mean: -1.58233
[32m[0907 01-33-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08784, current rewards: -2489.31119, mean: -1.59571
[32m[0907 01-33-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08774, current rewards: -2589.31119, mean: -1.60827
[32m[0907 01-33-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08765, current rewards: -2689.31119, mean: -1.62007
[32m[0907 01-33-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08756, current rewards: -2789.31119, mean: -1.63118
[32m[0907 01-34-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08748, current rewards: -2889.31119, mean: -1.64165
[32m[0907 01-34-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08740, current rewards: -2989.31119, mean: -1.65155
[32m[0907 01-34-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08732, current rewards: -3082.18777, mean: -1.65709
[32m[0907 01-34-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08725, current rewards: -3182.18777, mean: -1.66607
[32m[0907 01-34-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08718, current rewards: -3282.18777, mean: -1.67459
[32m[0907 01-34-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08712, current rewards: -3382.18777, mean: -1.68268
[32m[0907 01-34-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08705, current rewards: -3482.18777, mean: -1.69038
[32m[0907 01-34-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08699, current rewards: -3582.18777, mean: -1.69772
[32m[0907 01-34-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08692, current rewards: -3662.98150, mean: -1.69582
[32m[0907 01-34-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08689, current rewards: -3718.53450, mean: -1.68259
[32m[0907 01-34-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08689, current rewards: -3767.96673, mean: -1.66724
[32m[0907 01-34-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08689, current rewards: -3822.33083, mean: -1.65469
[32m[0907 01-34-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08689, current rewards: -3890.70428, mean: -1.64860
[32m[0907 01-34-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08688, current rewards: -3937.40148, mean: -1.63378
[32m[0907 01-35-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08689, current rewards: -3985.42250, mean: -1.62009
[32m[0907 01-35-05 @Agent.py:117][0m Average action selection time: 0.0868
[32m[0907 01-35-05 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-35-05 @MBExp.py:227][0m Rewards obtained: [-4020.394047825561], Lows: [2065], Highs: [22], Total time: 29152.686174
[32m[0907 01-38-36 @MBExp.py:144][0m ####################################################################
[32m[0907 01-38-36 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 01-38-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08897, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-38-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08920, current rewards: -115.00000, mean: -1.91667
[32m[0907 01-38-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08918, current rewards: -215.00000, mean: -1.95455
[32m[0907 01-38-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08922, current rewards: -315.00000, mean: -1.96875
[32m[0907 01-38-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08925, current rewards: -415.00000, mean: -1.97619
[32m[0907 01-38-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08927, current rewards: -515.00000, mean: -1.98077
[32m[0907 01-39-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08926, current rewards: -615.00000, mean: -1.98387
[32m[0907 01-39-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08925, current rewards: -715.00000, mean: -1.98611
[32m[0907 01-39-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08925, current rewards: -815.00000, mean: -1.98780
[32m[0907 01-39-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08923, current rewards: -915.00000, mean: -1.98913
[32m[0907 01-39-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08926, current rewards: -1015.00000, mean: -1.99020
[32m[0907 01-39-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08926, current rewards: -1115.00000, mean: -1.99107
[32m[0907 01-39-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08928, current rewards: -1215.00000, mean: -1.99180
[32m[0907 01-39-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08930, current rewards: -1315.00000, mean: -1.99242
[32m[0907 01-39-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08930, current rewards: -1415.00000, mean: -1.99296
[32m[0907 01-39-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08931, current rewards: -1515.00000, mean: -1.99342
[32m[0907 01-39-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08926, current rewards: -1615.00000, mean: -1.99383
[32m[0907 01-39-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08913, current rewards: -1715.00000, mean: -1.99419
[32m[0907 01-39-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08900, current rewards: -1815.00000, mean: -1.99451
[32m[0907 01-40-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08876, current rewards: -1915.00000, mean: -1.99479
[32m[0907 01-40-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08855, current rewards: -2015.00000, mean: -1.99505
[32m[0907 01-40-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08836, current rewards: -2115.00000, mean: -1.99528
[32m[0907 01-40-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08820, current rewards: -2215.00000, mean: -1.99550
[32m[0907 01-40-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08805, current rewards: -2315.00000, mean: -1.99569
[32m[0907 01-40-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08790, current rewards: -2415.00000, mean: -1.99587
[32m[0907 01-40-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08777, current rewards: -2515.00000, mean: -1.99603
[32m[0907 01-40-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08764, current rewards: -2615.00000, mean: -1.99618
[32m[0907 01-40-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08754, current rewards: -2715.00000, mean: -1.99632
[32m[0907 01-40-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08744, current rewards: -2815.00000, mean: -1.99645
[32m[0907 01-40-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08733, current rewards: -2915.00000, mean: -1.99658
[32m[0907 01-40-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08725, current rewards: -3015.00000, mean: -1.99669
[32m[0907 01-40-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08716, current rewards: -3115.00000, mean: -1.99679
[32m[0907 01-40-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08708, current rewards: -3215.00000, mean: -1.99689
[32m[0907 01-41-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08701, current rewards: -3315.00000, mean: -1.99699
[32m[0907 01-41-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08693, current rewards: -3415.00000, mean: -1.99708
[32m[0907 01-41-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08686, current rewards: -3515.00000, mean: -1.99716
[32m[0907 01-41-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08679, current rewards: -3615.00000, mean: -1.99724
[32m[0907 01-41-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08673, current rewards: -3715.00000, mean: -1.99731
[32m[0907 01-41-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08668, current rewards: -3815.00000, mean: -1.99738
[32m[0907 01-41-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08662, current rewards: -3915.00000, mean: -1.99745
[32m[0907 01-41-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08657, current rewards: -4015.00000, mean: -1.99751
[32m[0907 01-41-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08652, current rewards: -4115.00000, mean: -1.99757
[32m[0907 01-41-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08648, current rewards: -4215.00000, mean: -1.99763
[32m[0907 01-41-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08644, current rewards: -4315.00000, mean: -1.99769
[32m[0907 01-41-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08642, current rewards: -4415.00000, mean: -1.99774
[32m[0907 01-41-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08644, current rewards: -4515.00000, mean: -1.99779
[32m[0907 01-41-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08644, current rewards: -4615.00000, mean: -1.99784
[32m[0907 01-42-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08645, current rewards: -4715.00000, mean: -1.99788
[32m[0907 01-42-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08646, current rewards: -4815.00000, mean: -1.99793
[32m[0907 01-42-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08647, current rewards: -4915.00000, mean: -1.99797
[32m[0907 01-42-13 @Agent.py:117][0m Average action selection time: 0.0865
[32m[0907 01-42-13 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-42-13 @MBExp.py:227][0m Rewards obtained: [-4995], Lows: [2495], Highs: [5], Total time: 29369.64328
[32m[0907 01-45-46 @MBExp.py:144][0m ####################################################################
[32m[0907 01-45-46 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 01-45-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08829, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-45-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09076, current rewards: -75.28743, mean: -1.25479
[32m[0907 01-45-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09108, current rewards: -135.82994, mean: -1.23482
[32m[0907 01-46-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09059, current rewards: -224.10270, mean: -1.40064
[32m[0907 01-46-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09028, current rewards: -303.93431, mean: -1.44731
[32m[0907 01-46-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09015, current rewards: -372.97142, mean: -1.43451
[32m[0907 01-46-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09004, current rewards: -451.86414, mean: -1.45763
[32m[0907 01-46-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08997, current rewards: -531.10737, mean: -1.47530
[32m[0907 01-46-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08994, current rewards: -604.98938, mean: -1.47558
[32m[0907 01-46-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08993, current rewards: -687.15703, mean: -1.49382
[32m[0907 01-46-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08991, current rewards: -761.17101, mean: -1.49249
[32m[0907 01-46-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08986, current rewards: -835.70571, mean: -1.49233
[32m[0907 01-46-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08982, current rewards: -916.48230, mean: -1.50243
[32m[0907 01-46-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08992, current rewards: -1005.97185, mean: -1.52420
[32m[0907 01-46-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08989, current rewards: -1105.97185, mean: -1.55771
[32m[0907 01-46-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08986, current rewards: -1205.97185, mean: -1.58681
[32m[0907 01-46-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08985, current rewards: -1305.97185, mean: -1.61231
[32m[0907 01-47-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08967, current rewards: -1405.97185, mean: -1.63485
[32m[0907 01-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08952, current rewards: -1505.97185, mean: -1.65491
[32m[0907 01-47-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08938, current rewards: -1605.97185, mean: -1.67289
[32m[0907 01-47-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08910, current rewards: -1705.97185, mean: -1.68908
[32m[0907 01-47-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08890, current rewards: -1805.97185, mean: -1.70375
[32m[0907 01-47-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08870, current rewards: -1905.97185, mean: -1.71709
[32m[0907 01-47-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08855, current rewards: -1985.51837, mean: -1.71165
[32m[0907 01-47-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08837, current rewards: -2063.53797, mean: -1.70540
[32m[0907 01-47-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08839, current rewards: -2135.37050, mean: -1.69474
[32m[0907 01-47-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08831, current rewards: -2210.08717, mean: -1.68709
[32m[0907 01-47-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08819, current rewards: -2283.73091, mean: -1.67921
[32m[0907 01-47-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08821, current rewards: -2353.56838, mean: -1.66920
[32m[0907 01-47-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08807, current rewards: -2451.48846, mean: -1.67910
[32m[0907 01-47-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08796, current rewards: -2551.48846, mean: -1.68973
[32m[0907 01-48-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08785, current rewards: -2651.48846, mean: -1.69967
[32m[0907 01-48-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08775, current rewards: -2751.48846, mean: -1.70900
[32m[0907 01-48-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08766, current rewards: -2851.48846, mean: -1.71776
[32m[0907 01-48-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08757, current rewards: -2951.48846, mean: -1.72602
[32m[0907 01-48-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08749, current rewards: -3026.94312, mean: -1.71985
[32m[0907 01-48-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08742, current rewards: -3126.94312, mean: -1.72759
[32m[0907 01-48-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08735, current rewards: -3226.94312, mean: -1.73492
[32m[0907 01-48-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08729, current rewards: -3326.94312, mean: -1.74186
[32m[0907 01-48-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08721, current rewards: -3426.94312, mean: -1.74844
[32m[0907 01-48-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08715, current rewards: -3526.94312, mean: -1.75470
[32m[0907 01-48-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08708, current rewards: -3626.94312, mean: -1.76065
[32m[0907 01-48-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08702, current rewards: -3726.94312, mean: -1.76632
[32m[0907 01-48-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08697, current rewards: -3826.94312, mean: -1.77173
[32m[0907 01-48-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08690, current rewards: -3926.94312, mean: -1.77690
[32m[0907 01-49-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08685, current rewards: -4026.94312, mean: -1.78183
[32m[0907 01-49-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08680, current rewards: -4126.94312, mean: -1.78656
[32m[0907 01-49-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08674, current rewards: -4226.94312, mean: -1.79108
[32m[0907 01-49-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08670, current rewards: -4326.94312, mean: -1.79541
[32m[0907 01-49-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08665, current rewards: -4426.94312, mean: -1.79957
[32m[0907 01-49-23 @Agent.py:117][0m Average action selection time: 0.0866
[32m[0907 01-49-23 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-49-23 @MBExp.py:227][0m Rewards obtained: [-4506.94312221918], Lows: [2264], Highs: [26], Total time: 29586.939095
[32m[0907 01-52-58 @MBExp.py:144][0m ####################################################################
[32m[0907 01-52-58 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 01-52-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09204, current rewards: -8.86799, mean: -0.88680
[32m[0907 01-53-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09748, current rewards: -56.02622, mean: -0.93377
[32m[0907 01-53-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09556, current rewards: -103.75112, mean: -0.94319
[32m[0907 01-53-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09582, current rewards: -172.70584, mean: -1.07941
[32m[0907 01-53-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09658, current rewards: -232.28422, mean: -1.10612
[32m[0907 01-53-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09576, current rewards: -279.98665, mean: -1.07687
[32m[0907 01-53-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09489, current rewards: -327.78047, mean: -1.05736
[32m[0907 01-53-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09478, current rewards: -373.15762, mean: -1.03655
[32m[0907 01-53-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09464, current rewards: -426.81977, mean: -1.04102
[32m[0907 01-53-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09527, current rewards: -482.28794, mean: -1.04845
[32m[0907 01-53-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09577, current rewards: -543.16535, mean: -1.06503
[32m[0907 01-53-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09601, current rewards: -605.39162, mean: -1.08106
[32m[0907 01-53-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09586, current rewards: -662.34131, mean: -1.08581
[32m[0907 01-54-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09596, current rewards: -717.90954, mean: -1.08774
[32m[0907 01-54-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09637, current rewards: -765.32479, mean: -1.07792
[32m[0907 01-54-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09594, current rewards: -830.61759, mean: -1.09292
[32m[0907 01-54-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09565, current rewards: -892.11986, mean: -1.10138
[32m[0907 01-54-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09514, current rewards: -943.77399, mean: -1.09741
[32m[0907 01-54-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09474, current rewards: -1001.66527, mean: -1.10073
[32m[0907 01-54-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09425, current rewards: -1067.47937, mean: -1.11196
[32m[0907 01-54-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09377, current rewards: -1138.06038, mean: -1.12679
[32m[0907 01-54-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09337, current rewards: -1207.34154, mean: -1.13900
[32m[0907 01-54-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09304, current rewards: -1271.89169, mean: -1.14585
[32m[0907 01-54-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09274, current rewards: -1348.01398, mean: -1.16208
[32m[0907 01-54-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09250, current rewards: -1421.16032, mean: -1.17451
[32m[0907 01-54-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09260, current rewards: -1496.83256, mean: -1.18796
[32m[0907 01-55-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09268, current rewards: -1568.49496, mean: -1.19732
[32m[0907 01-55-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09263, current rewards: -1654.96314, mean: -1.21688
[32m[0907 01-55-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09266, current rewards: -1732.89315, mean: -1.22900
[32m[0907 01-55-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09267, current rewards: -1816.61656, mean: -1.24426
[32m[0907 01-55-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09273, current rewards: -1896.84349, mean: -1.25619
[32m[0907 01-55-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09304, current rewards: -1979.44281, mean: -1.26887
[32m[0907 01-55-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09303, current rewards: -2051.10294, mean: -1.27398
[32m[0907 01-55-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09289, current rewards: -2136.01366, mean: -1.28676
[32m[0907 01-55-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09268, current rewards: -2197.01461, mean: -1.28480
[32m[0907 01-55-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09245, current rewards: -2247.01461, mean: -1.27671
[32m[0907 01-55-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09223, current rewards: -2297.01461, mean: -1.26907
[32m[0907 01-55-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09203, current rewards: -2347.01461, mean: -1.26184
[32m[0907 01-55-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09183, current rewards: -2397.01461, mean: -1.25498
[32m[0907 01-55-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09164, current rewards: -2447.01461, mean: -1.24848
[32m[0907 01-56-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09147, current rewards: -2497.01461, mean: -1.24230
[32m[0907 01-56-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09130, current rewards: -2547.01461, mean: -1.23641
[32m[0907 01-56-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09114, current rewards: -2597.01461, mean: -1.23081
[32m[0907 01-56-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09099, current rewards: -2647.01461, mean: -1.22547
[32m[0907 01-56-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09084, current rewards: -2697.01461, mean: -1.22037
[32m[0907 01-56-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09071, current rewards: -2747.01461, mean: -1.21549
[32m[0907 01-56-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09057, current rewards: -2797.01461, mean: -1.21083
[32m[0907 01-56-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09044, current rewards: -2847.01461, mean: -1.20636
[32m[0907 01-56-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09029, current rewards: -2897.01461, mean: -1.20208
[32m[0907 01-56-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09015, current rewards: -2947.01461, mean: -1.19797
[32m[0907 01-56-44 @Agent.py:117][0m Average action selection time: 0.0901
[32m[0907 01-56-44 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-56-44 @MBExp.py:227][0m Rewards obtained: [-2987.0146056068343], Lows: [1064], Highs: [947], Total time: 29812.830560000002
[32m[0907 02-00-21 @MBExp.py:144][0m ####################################################################
[32m[0907 02-00-21 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 02-00-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09190, current rewards: -15.00000, mean: -1.50000
[32m[0907 02-00-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09288, current rewards: -99.56488, mean: -1.65941
[32m[0907 02-00-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09250, current rewards: -161.51322, mean: -1.46830
[32m[0907 02-00-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09160, current rewards: -247.75659, mean: -1.54848
[32m[0907 02-00-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09158, current rewards: -323.75659, mean: -1.54170
[32m[0907 02-00-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09123, current rewards: -423.75659, mean: -1.62983
[32m[0907 02-00-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09099, current rewards: -523.75659, mean: -1.68954
[32m[0907 02-00-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09076, current rewards: -623.75659, mean: -1.73266
[32m[0907 02-00-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09057, current rewards: -723.75659, mean: -1.76526
[32m[0907 02-01-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09045, current rewards: -823.75659, mean: -1.79078
[32m[0907 02-01-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09033, current rewards: -923.75659, mean: -1.81129
[32m[0907 02-01-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09023, current rewards: -1023.75659, mean: -1.82814
[32m[0907 02-01-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09015, current rewards: -1123.75659, mean: -1.84222
[32m[0907 02-01-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09006, current rewards: -1223.75659, mean: -1.85418
[32m[0907 02-01-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08999, current rewards: -1323.75659, mean: -1.86445
[32m[0907 02-01-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08994, current rewards: -1423.75659, mean: -1.87336
[32m[0907 02-01-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08986, current rewards: -1523.75659, mean: -1.88118
[32m[0907 02-01-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08963, current rewards: -1623.75659, mean: -1.88809
[32m[0907 02-01-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08936, current rewards: -1723.75659, mean: -1.89424
[32m[0907 02-01-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08909, current rewards: -1823.75659, mean: -1.89975
[32m[0907 02-01-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08886, current rewards: -1923.75659, mean: -1.90471
[32m[0907 02-01-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08866, current rewards: -2023.75659, mean: -1.90920
[32m[0907 02-01-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08847, current rewards: -2123.75659, mean: -1.91329
[32m[0907 02-02-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08830, current rewards: -2223.75659, mean: -1.91703
[32m[0907 02-02-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08816, current rewards: -2323.75659, mean: -1.92046
[32m[0907 02-02-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08801, current rewards: -2423.75659, mean: -1.92362
[32m[0907 02-02-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08789, current rewards: -2523.75659, mean: -1.92653
[32m[0907 02-02-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08777, current rewards: -2623.75659, mean: -1.92923
[32m[0907 02-02-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08765, current rewards: -2723.75659, mean: -1.93174
[32m[0907 02-02-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08755, current rewards: -2823.75659, mean: -1.93408
[32m[0907 02-02-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08747, current rewards: -2923.75659, mean: -1.93626
[32m[0907 02-02-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08737, current rewards: -3023.75659, mean: -1.93831
[32m[0907 02-02-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08728, current rewards: -3123.75659, mean: -1.94022
[32m[0907 02-02-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08720, current rewards: -3223.75659, mean: -1.94202
[32m[0907 02-02-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08713, current rewards: -3323.75659, mean: -1.94372
[32m[0907 02-02-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08707, current rewards: -3423.75659, mean: -1.94532
[32m[0907 02-02-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08701, current rewards: -3523.75659, mean: -1.94683
[32m[0907 02-03-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08693, current rewards: -3623.75659, mean: -1.94826
[32m[0907 02-03-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08687, current rewards: -3723.75659, mean: -1.94961
[32m[0907 02-03-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08681, current rewards: -3823.75659, mean: -1.95090
[32m[0907 02-03-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08675, current rewards: -3923.75659, mean: -1.95212
[32m[0907 02-03-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08670, current rewards: -4023.75659, mean: -1.95328
[32m[0907 02-03-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08664, current rewards: -4123.75659, mean: -1.95439
[32m[0907 02-03-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08658, current rewards: -4223.75659, mean: -1.95544
[32m[0907 02-03-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08654, current rewards: -4323.75659, mean: -1.95645
[32m[0907 02-03-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08650, current rewards: -4423.75659, mean: -1.95741
[32m[0907 02-03-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08647, current rewards: -4523.75659, mean: -1.95834
[32m[0907 02-03-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08643, current rewards: -4623.75659, mean: -1.95922
[32m[0907 02-03-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08637, current rewards: -4723.75659, mean: -1.96006
[32m[0907 02-03-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08631, current rewards: -4823.75659, mean: -1.96088
[32m[0907 02-03-57 @Agent.py:117][0m Average action selection time: 0.0863
[32m[0907 02-03-57 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-03-57 @MBExp.py:227][0m Rewards obtained: [-4903.756592938111], Lows: [2413], Highs: [79], Total time: 30029.248840000004
[32m[0907 02-07-36 @MBExp.py:144][0m ####################################################################
[32m[0907 02-07-36 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 02-07-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09173, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-07-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09223, current rewards: -60.00000, mean: -1.00000
[32m[0907 02-07-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09177, current rewards: -110.00000, mean: -1.00000
[32m[0907 02-07-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09106, current rewards: -160.00000, mean: -1.00000
[32m[0907 02-07-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09072, current rewards: -210.00000, mean: -1.00000
[32m[0907 02-08-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09046, current rewards: -260.00000, mean: -1.00000
[32m[0907 02-08-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09033, current rewards: -310.00000, mean: -1.00000
[32m[0907 02-08-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09012, current rewards: -360.00000, mean: -1.00000
[32m[0907 02-08-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09003, current rewards: -410.00000, mean: -1.00000
[32m[0907 02-08-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08997, current rewards: -460.00000, mean: -1.00000
[32m[0907 02-08-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08989, current rewards: -510.00000, mean: -1.00000
[32m[0907 02-08-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08982, current rewards: -560.00000, mean: -1.00000
[32m[0907 02-08-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08978, current rewards: -610.00000, mean: -1.00000
[32m[0907 02-08-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08979, current rewards: -660.00000, mean: -1.00000
[32m[0907 02-08-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08978, current rewards: -693.74815, mean: -0.97711
[32m[0907 02-08-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08974, current rewards: -689.57531, mean: -0.90734
[32m[0907 02-08-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08971, current rewards: -685.40248, mean: -0.84618
[32m[0907 02-08-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08953, current rewards: -681.22965, mean: -0.79213
[32m[0907 02-08-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08938, current rewards: -677.58909, mean: -0.74460
[32m[0907 02-09-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08926, current rewards: -674.51178, mean: -0.70262
[32m[0907 02-09-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08913, current rewards: -671.43447, mean: -0.66479
[32m[0907 02-09-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08902, current rewards: -668.35715, mean: -0.63053
[32m[0907 02-09-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08891, current rewards: -665.27984, mean: -0.59935
[32m[0907 02-09-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08872, current rewards: -662.20252, mean: -0.57086
[32m[0907 02-09-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08854, current rewards: -659.12521, mean: -0.54473
[32m[0907 02-09-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08839, current rewards: -691.07892, mean: -0.54848
[32m[0907 02-09-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08824, current rewards: -741.07892, mean: -0.56571
[32m[0907 02-09-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08809, current rewards: -791.07892, mean: -0.58168
[32m[0907 02-09-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08797, current rewards: -841.07892, mean: -0.59651
[32m[0907 02-09-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08785, current rewards: -891.07892, mean: -0.61033
[32m[0907 02-09-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08775, current rewards: -941.07892, mean: -0.62323
[32m[0907 02-09-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08765, current rewards: -991.07892, mean: -0.63531
[32m[0907 02-09-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08755, current rewards: -1041.07892, mean: -0.64663
[32m[0907 02-10-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08745, current rewards: -1091.07892, mean: -0.65728
[32m[0907 02-10-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08737, current rewards: -1141.07892, mean: -0.66730
[32m[0907 02-10-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08729, current rewards: -1191.07892, mean: -0.67675
[32m[0907 02-10-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08721, current rewards: -1241.07892, mean: -0.68568
[32m[0907 02-10-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08713, current rewards: -1291.07892, mean: -0.69413
[32m[0907 02-10-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08704, current rewards: -1341.07892, mean: -0.70214
[32m[0907 02-10-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08698, current rewards: -1391.07892, mean: -0.70973
[32m[0907 02-10-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08691, current rewards: -1441.07892, mean: -0.71695
[32m[0907 02-10-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08686, current rewards: -1491.07892, mean: -0.72382
[32m[0907 02-10-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08682, current rewards: -1541.07892, mean: -0.73037
[32m[0907 02-10-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08676, current rewards: -1591.07892, mean: -0.73661
[32m[0907 02-10-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08671, current rewards: -1641.07892, mean: -0.74257
[32m[0907 02-10-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08666, current rewards: -1691.07892, mean: -0.74827
[32m[0907 02-10-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08661, current rewards: -1741.07892, mean: -0.75371
[32m[0907 02-11-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08657, current rewards: -1791.07892, mean: -0.75893
[32m[0907 02-11-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08650, current rewards: -1841.07892, mean: -0.76393
[32m[0907 02-11-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08625, current rewards: -1891.07892, mean: -0.76873
[32m[0907 02-11-12 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 02-11-12 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-11-12 @MBExp.py:227][0m Rewards obtained: [-1931.0789208935146], Lows: [0], Highs: [1968], Total time: 30245.141236000003
