[32m[0906 13-41-24 @logger.py:99][0m Log file set to /app/logs/dats-delay-5/zinc-coating-v0_4/Tuesday_06_September_2022_01-41PM.log
[32m[0906 13-41-24 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -13.00000, mean: -1.30000
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -64.88066, mean: -1.08134
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -120.56517, mean: -1.09605
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -169.44096, mean: -1.05901
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -214.33640, mean: -1.02065
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -266.65747, mean: -1.02561
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -316.65967, mean: -1.02148
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -368.97104, mean: -1.02492
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -422.47024, mean: -1.03042
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -471.41449, mean: -1.02481
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -526.38934, mean: -1.03214
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -590.86731, mean: -1.05512
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -656.82522, mean: -1.07676
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -730.41613, mean: -1.10669
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -788.80703, mean: -1.11100
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -871.23731, mean: -1.14636
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -941.45253, mean: -1.16229
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1011.66250, mean: -1.17635
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1073.24091, mean: -1.17939
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1145.65676, mean: -1.19339
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1216.12570, mean: -1.20408
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1280.19116, mean: -1.20773
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1358.59402, mean: -1.22396
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1421.42336, mean: -1.22536
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1500.56562, mean: -1.24014
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1546.39278, mean: -1.22730
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1598.68115, mean: -1.22037
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1655.21666, mean: -1.21707
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1708.75291, mean: -1.21188
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1769.02026, mean: -1.21166
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1823.34084, mean: -1.20751
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1875.91085, mean: -1.20251
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1926.74671, mean: -1.19674
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1978.79077, mean: -1.19204
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2038.13415, mean: -1.19189
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2100.25818, mean: -1.19333
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2160.57013, mean: -1.19369
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2215.82673, mean: -1.19130
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2271.32065, mean: -1.18917
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2335.95823, mean: -1.19182
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2390.78831, mean: -1.18945
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2448.23880, mean: -1.18847
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2496.89413, mean: -1.18336
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2554.11501, mean: -1.18246
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2596.15464, mean: -1.17473
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2656.73593, mean: -1.17555
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2707.74891, mean: -1.17219
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2757.48546, mean: -1.16843
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2811.02459, mean: -1.16640
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2865.00635, mean: -1.16464
[32m[0906 13-41-24 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-41-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-41-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-27 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-41-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.13323, current rewards: -11.73498, mean: -1.17350
[32m[0906 13-41-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11659, current rewards: -111.73498, mean: -1.86225
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11534, current rewards: -211.73498, mean: -1.92486
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11475, current rewards: -311.73498, mean: -1.94834
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11443, current rewards: -411.73498, mean: -1.96064
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11422, current rewards: -511.73498, mean: -1.96821
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11411, current rewards: -611.73498, mean: -1.97334
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11415, current rewards: -711.73498, mean: -1.97704
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11405, current rewards: -805.96741, mean: -1.96577
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11395, current rewards: -905.96741, mean: -1.96949
[32m[0906 13-42-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11400, current rewards: -1005.96741, mean: -1.97249
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11392, current rewards: -1105.96741, mean: -1.97494
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11385, current rewards: -1205.96741, mean: -1.97700
[32m[0906 13-42-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11386, current rewards: -1305.96741, mean: -1.97874
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11380, current rewards: -1405.96741, mean: -1.98024
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11370, current rewards: -1505.96741, mean: -1.98154
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11367, current rewards: -1567.20576, mean: -1.93482
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11353, current rewards: -1611.47253, mean: -1.87381
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11358, current rewards: -1657.88293, mean: -1.82185
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11357, current rewards: -1704.28203, mean: -1.77529
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11355, current rewards: -1752.84796, mean: -1.73549
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11358, current rewards: -1799.26161, mean: -1.69742
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11357, current rewards: -1845.67920, mean: -1.66277
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11358, current rewards: -1889.94736, mean: -1.62926
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11355, current rewards: -1912.76061, mean: -1.58079
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11354, current rewards: -1889.50650, mean: -1.49961
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11351, current rewards: -1866.25688, mean: -1.42462
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11353, current rewards: -1843.01182, mean: -1.35516
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11351, current rewards: -1819.77695, mean: -1.29062
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11349, current rewards: -1796.57657, mean: -1.23053
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11343, current rewards: -1773.27089, mean: -1.17435
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11339, current rewards: -1749.93057, mean: -1.12175
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11341, current rewards: -1758.08916, mean: -1.09198
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11340, current rewards: -1803.62656, mean: -1.08652
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11339, current rewards: -1850.29240, mean: -1.08204
[32m[0906 13-44-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11333, current rewards: -1896.94883, mean: -1.07781
[32m[0906 13-44-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11330, current rewards: -1943.61949, mean: -1.07382
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11329, current rewards: -1985.86692, mean: -1.06767
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11328, current rewards: -2028.07901, mean: -1.06182
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11328, current rewards: -2070.29044, mean: -1.05627
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11322, current rewards: -2116.95548, mean: -1.05321
[32m[0906 13-45-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11320, current rewards: -2192.10995, mean: -1.06413
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11319, current rewards: -2292.10995, mean: -1.08631
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11319, current rewards: -2392.10995, mean: -1.10746
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11322, current rewards: -2492.10995, mean: -1.12765
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11321, current rewards: -2592.10995, mean: -1.14695
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11322, current rewards: -2692.10995, mean: -1.16542
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11320, current rewards: -2792.10995, mean: -1.18310
[32m[0906 13-46-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11319, current rewards: -2892.10995, mean: -1.20005
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11319, current rewards: -2982.59684, mean: -1.21244
[32m[0906 13-46-10 @Agent.py:117][0m Average action selection time: 0.1132
[32m[0906 13-46-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-46-11 @MBExp.py:227][0m Rewards obtained: [-3062.5968420815657], Lows: [1659], Highs: [17], Total time: 283.696625
[32m[0906 13-46-15 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-15 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11183, current rewards: -6.49253, mean: -0.64925
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11188, current rewards: 0.97547, mean: 0.01626
[32m[0906 13-46-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11180, current rewards: 8.30863, mean: 0.07553
[32m[0906 13-46-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11178, current rewards: 15.64921, mean: 0.09781
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11189, current rewards: 22.98799, mean: 0.10947
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11187, current rewards: 19.89854, mean: 0.07653
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11179, current rewards: 44.05799, mean: 0.14212
[32m[0906 13-46-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11179, current rewards: 60.29806, mean: 0.16749
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11173, current rewards: 69.84745, mean: 0.17036
[32m[0906 13-47-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11167, current rewards: 79.39996, mean: 0.17261
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11171, current rewards: 78.55445, mean: 0.15403
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11173, current rewards: 84.05138, mean: 0.15009
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11172, current rewards: 89.54831, mean: 0.14680
[32m[0906 13-47-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11183, current rewards: 95.04719, mean: 0.14401
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11187, current rewards: 100.55158, mean: 0.14162
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11191, current rewards: 106.12334, mean: 0.13964
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11170, current rewards: 111.79026, mean: 0.13801
[32m[0906 13-47-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11156, current rewards: 117.45993, mean: 0.13658
[32m[0906 13-47-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11156, current rewards: 119.79183, mean: 0.13164
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11153, current rewards: 128.10001, mean: 0.13344
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11150, current rewards: 139.34411, mean: 0.13796
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11154, current rewards: 150.61201, mean: 0.14209
[32m[0906 13-48-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11152, current rewards: 148.31165, mean: 0.13361
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11153, current rewards: 153.19788, mean: 0.13207
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11156, current rewards: 157.11860, mean: 0.12985
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11155, current rewards: 161.04334, mean: 0.12781
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11155, current rewards: 164.96764, mean: 0.12593
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11160, current rewards: 168.89207, mean: 0.12419
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11161, current rewards: 172.81541, mean: 0.12256
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11165, current rewards: 176.73905, mean: 0.12105
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11160, current rewards: 180.66475, mean: 0.11965
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11156, current rewards: 184.63304, mean: 0.11835
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11161, current rewards: 189.99490, mean: 0.11801
[32m[0906 13-49-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11163, current rewards: 195.21659, mean: 0.11760
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11165, current rewards: 200.43968, mean: 0.11722
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11161, current rewards: 199.14371, mean: 0.11315
[32m[0906 13-49-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11157, current rewards: 204.50169, mean: 0.11298
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11155, current rewards: 209.85559, mean: 0.11283
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11158, current rewards: 215.21932, mean: 0.11268
[32m[0906 13-49-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11158, current rewards: 220.58308, mean: 0.11254
[32m[0906 13-50-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11152, current rewards: 224.42415, mean: 0.11165
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11147, current rewards: 227.82071, mean: 0.11059
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11147, current rewards: 231.22011, mean: 0.10958
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11147, current rewards: 222.86775, mean: 0.10318
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11149, current rewards: 227.50610, mean: 0.10294
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11148, current rewards: 232.14466, mean: 0.10272
[32m[0906 13-50-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11148, current rewards: 236.78230, mean: 0.10250
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11149, current rewards: 241.42050, mean: 0.10230
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11149, current rewards: 246.05749, mean: 0.10210
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11148, current rewards: 250.69420, mean: 0.10191
[32m[0906 13-50-55 @Agent.py:117][0m Average action selection time: 0.1115
[32m[0906 13-50-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-50-55 @MBExp.py:227][0m Rewards obtained: [254.40189433729788], Lows: [18], Highs: [24], Total time: 563.1239929999999
[32m[0906 13-51-02 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-02 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11146, current rewards: -5.61577, mean: -0.56158
[32m[0906 13-51-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11207, current rewards: -1.06571, mean: -0.01776
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11193, current rewards: 3.48009, mean: 0.03164
[32m[0906 13-51-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11165, current rewards: 8.02915, mean: 0.05018
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11173, current rewards: 12.57849, mean: 0.05990
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11167, current rewards: 13.45198, mean: 0.05174
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11170, current rewards: 21.45117, mean: 0.06920
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11175, current rewards: 26.56558, mean: 0.07379
[32m[0906 13-51-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11170, current rewards: 31.67886, mean: 0.07727
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11164, current rewards: 36.79767, mean: 0.07999
[32m[0906 13-51-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11166, current rewards: 41.90733, mean: 0.08217
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11165, current rewards: 47.02366, mean: 0.08397
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11166, current rewards: 52.13948, mean: 0.08547
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11168, current rewards: 57.25502, mean: 0.08675
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11167, current rewards: 62.42736, mean: 0.08793
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11168, current rewards: 58.89897, mean: 0.07750
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11147, current rewards: 68.46127, mean: 0.08452
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11124, current rewards: 78.02113, mean: 0.09072
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11130, current rewards: 87.56893, mean: 0.09623
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11133, current rewards: 97.11416, mean: 0.10116
[32m[0906 13-52-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11133, current rewards: 100.35565, mean: 0.09936
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11138, current rewards: 106.85582, mean: 0.10081
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11138, current rewards: 113.35751, mean: 0.10212
[32m[0906 13-53-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11139, current rewards: 119.85021, mean: 0.10332
[32m[0906 13-53-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11142, current rewards: 126.34672, mean: 0.10442
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11142, current rewards: 132.85033, mean: 0.10544
[32m[0906 13-53-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11142, current rewards: 139.34310, mean: 0.10637
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11144, current rewards: 145.84672, mean: 0.10724
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11141, current rewards: 152.33616, mean: 0.10804
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11140, current rewards: 158.83565, mean: 0.10879
[32m[0906 13-53-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11134, current rewards: 152.61934, mean: 0.10107
[32m[0906 13-53-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11123, current rewards: 157.44698, mean: 0.10093
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11125, current rewards: 161.98006, mean: 0.10061
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11126, current rewards: 166.51058, mean: 0.10031
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11128, current rewards: 171.03965, mean: 0.10002
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11123, current rewards: 175.56912, mean: 0.09976
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11113, current rewards: 180.10184, mean: 0.09950
[32m[0906 13-54-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11114, current rewards: 184.63235, mean: 0.09926
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11117, current rewards: 189.16436, mean: 0.09904
[32m[0906 13-54-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11117, current rewards: 193.43741, mean: 0.09869
[32m[0906 13-54-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11114, current rewards: 197.56822, mean: 0.09829
[32m[0906 13-54-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11108, current rewards: 201.70292, mean: 0.09791
[32m[0906 13-54-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11110, current rewards: 205.83845, mean: 0.09755
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11111, current rewards: 209.97394, mean: 0.09721
[32m[0906 13-55-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11112, current rewards: 214.10717, mean: 0.09688
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11113, current rewards: 212.03753, mean: 0.09382
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11114, current rewards: 215.77823, mean: 0.09341
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11117, current rewards: 219.79350, mean: 0.09313
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11118, current rewards: 227.91669, mean: 0.09457
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11118, current rewards: 236.13779, mean: 0.09599
[32m[0906 13-55-41 @Agent.py:117][0m Average action selection time: 0.1112
[32m[0906 13-55-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-55-41 @MBExp.py:227][0m Rewards obtained: [242.72358118263247], Lows: [12], Highs: [22], Total time: 841.8162199999999
[32m[0906 13-55-50 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-50 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11211, current rewards: -11.87343, mean: -1.18734
[32m[0906 13-55-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11163, current rewards: -6.72667, mean: -0.11211
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11149, current rewards: -0.04990, mean: -0.00045
[32m[0906 13-56-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11141, current rewards: 6.61451, mean: 0.04134
[32m[0906 13-56-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 13.27631, mean: 0.06322
[32m[0906 13-56-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11140, current rewards: 19.93684, mean: 0.07668
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11145, current rewards: 26.52973, mean: 0.08558
[32m[0906 13-56-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11151, current rewards: 33.10378, mean: 0.09195
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11149, current rewards: 39.67802, mean: 0.09678
[32m[0906 13-56-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11148, current rewards: 46.25696, mean: 0.10056
[32m[0906 13-56-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11146, current rewards: 52.84368, mean: 0.10362
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11143, current rewards: 59.41634, mean: 0.10610
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11151, current rewards: 63.86692, mean: 0.10470
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11149, current rewards: 59.15126, mean: 0.08962
[32m[0906 13-57-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11150, current rewards: 63.85096, mean: 0.08993
[32m[0906 13-57-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11153, current rewards: 68.51390, mean: 0.09015
[32m[0906 13-57-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11133, current rewards: 73.17489, mean: 0.09034
[32m[0906 13-57-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11112, current rewards: 77.83742, mean: 0.09051
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11114, current rewards: 82.50232, mean: 0.09066
[32m[0906 13-57-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11118, current rewards: 87.16182, mean: 0.09079
[32m[0906 13-57-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11119, current rewards: 91.82630, mean: 0.09092
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11121, current rewards: 96.48419, mean: 0.09102
[32m[0906 13-57-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11122, current rewards: 101.71528, mean: 0.09164
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11123, current rewards: 101.92264, mean: 0.08786
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11125, current rewards: 107.07429, mean: 0.08849
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11123, current rewards: 112.22719, mean: 0.08907
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11125, current rewards: 117.37612, mean: 0.08960
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11124, current rewards: 112.79575, mean: 0.08294
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11126, current rewards: 119.74720, mean: 0.08493
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11134, current rewards: 126.67951, mean: 0.08677
[32m[0906 13-58-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11130, current rewards: 133.42119, mean: 0.08836
[32m[0906 13-58-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11124, current rewards: 139.46868, mean: 0.08940
[32m[0906 13-58-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11125, current rewards: 146.09442, mean: 0.09074
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11128, current rewards: 152.71683, mean: 0.09200
[32m[0906 13-59-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11128, current rewards: 159.34042, mean: 0.09318
[32m[0906 13-59-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11129, current rewards: 165.96256, mean: 0.09430
[32m[0906 13-59-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11121, current rewards: 172.58585, mean: 0.09535
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11119, current rewards: 178.07690, mean: 0.09574
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11124, current rewards: 180.22897, mean: 0.09436
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11127, current rewards: 184.87950, mean: 0.09433
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11122, current rewards: 189.57737, mean: 0.09432
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11117, current rewards: 194.27320, mean: 0.09431
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11114, current rewards: 198.96247, mean: 0.09430
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11116, current rewards: 203.65498, mean: 0.09428
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11118, current rewards: 208.35170, mean: 0.09428
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11119, current rewards: 213.04653, mean: 0.09427
[32m[0906 14-00-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11119, current rewards: 217.74563, mean: 0.09426
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11121, current rewards: 222.99387, mean: 0.09449
[32m[0906 14-00-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11121, current rewards: 228.15182, mean: 0.09467
[32m[0906 14-00-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11122, current rewards: 233.31371, mean: 0.09484
[32m[0906 14-00-29 @Agent.py:117][0m Average action selection time: 0.1112
[32m[0906 14-00-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-00-29 @MBExp.py:227][0m Rewards obtained: [237.44212557651028], Lows: [14], Highs: [17], Total time: 1120.551997
[32m[0906 14-00-41 @MBExp.py:144][0m ####################################################################
[32m[0906 14-00-41 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-00-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11030, current rewards: -5.57862, mean: -0.55786
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11144, current rewards: 0.22372, mean: 0.00373
[32m[0906 14-00-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11138, current rewards: 6.46239, mean: 0.05875
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11164, current rewards: 12.68833, mean: 0.07930
[32m[0906 14-01-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11150, current rewards: 18.90944, mean: 0.09004
[32m[0906 14-01-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11140, current rewards: 25.13987, mean: 0.09669
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11151, current rewards: 33.28807, mean: 0.10738
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11144, current rewards: 39.80228, mean: 0.11056
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11144, current rewards: 46.31242, mean: 0.11296
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11143, current rewards: 52.82399, mean: 0.11483
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11140, current rewards: 59.34025, mean: 0.11635
[32m[0906 14-01-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11143, current rewards: 65.85097, mean: 0.11759
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11140, current rewards: 71.88711, mean: 0.11785
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11137, current rewards: 77.90329, mean: 0.11804
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11140, current rewards: 83.33134, mean: 0.11737
[32m[0906 14-02-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11142, current rewards: 88.08039, mean: 0.11590
[32m[0906 14-02-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11119, current rewards: 92.99928, mean: 0.11481
[32m[0906 14-02-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11100, current rewards: 97.91529, mean: 0.11385
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11089, current rewards: 102.83151, mean: 0.11300
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11092, current rewards: 107.74337, mean: 0.11223
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11099, current rewards: 112.65887, mean: 0.11154
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11101, current rewards: 117.56870, mean: 0.11091
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11103, current rewards: 122.48571, mean: 0.11035
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11108, current rewards: 128.11462, mean: 0.11044
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11109, current rewards: 133.48523, mean: 0.11032
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11112, current rewards: 138.85731, mean: 0.11020
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11116, current rewards: 144.22681, mean: 0.11010
[32m[0906 14-03-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11118, current rewards: 138.83352, mean: 0.10208
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11119, current rewards: 144.71906, mean: 0.10264
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11120, current rewards: 150.61044, mean: 0.10316
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11111, current rewards: 156.49575, mean: 0.10364
[32m[0906 14-03-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11102, current rewards: 163.17509, mean: 0.10460
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11094, current rewards: 169.77919, mean: 0.10545
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11096, current rewards: 166.64588, mean: 0.10039
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11100, current rewards: 172.98857, mean: 0.10116
[32m[0906 14-03-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11095, current rewards: 179.32352, mean: 0.10189
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11086, current rewards: 185.65287, mean: 0.10257
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11081, current rewards: 191.98077, mean: 0.10322
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11083, current rewards: 188.18393, mean: 0.09853
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11085, current rewards: 194.32061, mean: 0.09914
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11082, current rewards: 201.31268, mean: 0.10016
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11076, current rewards: 208.35152, mean: 0.10114
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11072, current rewards: 215.39063, mean: 0.10208
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11076, current rewards: 222.41598, mean: 0.10297
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11078, current rewards: 229.44758, mean: 0.10382
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11082, current rewards: 236.47991, mean: 0.10464
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11085, current rewards: 243.51577, mean: 0.10542
[32m[0906 14-05-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11088, current rewards: 251.02260, mean: 0.10637
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11091, current rewards: 259.64862, mean: 0.10774
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11095, current rewards: 266.17877, mean: 0.10820
[32m[0906 14-05-19 @Agent.py:117][0m Average action selection time: 0.1110
[32m[0906 14-05-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-05-19 @MBExp.py:227][0m Rewards obtained: [271.40257366575787], Lows: [13], Highs: [12], Total time: 1398.656254
[32m[0906 14-05-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-33 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11162, current rewards: -4.95077, mean: -0.49508
[32m[0906 14-05-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11190, current rewards: 1.06336, mean: 0.01772
[32m[0906 14-05-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11224, current rewards: 6.77512, mean: 0.06159
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11196, current rewards: 12.48198, mean: 0.07801
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11187, current rewards: 18.19001, mean: 0.08662
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11190, current rewards: 23.90252, mean: 0.09193
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11180, current rewards: 29.56374, mean: 0.09537
[32m[0906 14-06-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11184, current rewards: 35.22940, mean: 0.09786
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11186, current rewards: 40.89549, mean: 0.09975
[32m[0906 14-06-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11179, current rewards: 46.56370, mean: 0.10123
[32m[0906 14-06-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11181, current rewards: 41.98286, mean: 0.08232
[32m[0906 14-06-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11171, current rewards: 47.66364, mean: 0.08511
[32m[0906 14-06-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11172, current rewards: 53.34813, mean: 0.08746
[32m[0906 14-06-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11170, current rewards: 59.02794, mean: 0.08944
[32m[0906 14-06-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11167, current rewards: 65.11320, mean: 0.09171
[32m[0906 14-06-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11165, current rewards: 71.05156, mean: 0.09349
[32m[0906 14-07-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11144, current rewards: 76.98942, mean: 0.09505
[32m[0906 14-07-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11122, current rewards: 82.92673, mean: 0.09643
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11101, current rewards: 88.86475, mean: 0.09765
[32m[0906 14-07-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11106, current rewards: 89.51961, mean: 0.09325
[32m[0906 14-07-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11108, current rewards: 96.57565, mean: 0.09562
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11115, current rewards: 103.62868, mean: 0.09776
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11118, current rewards: 99.42573, mean: 0.08957
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11117, current rewards: 104.31906, mean: 0.08993
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11115, current rewards: 109.19765, mean: 0.09025
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11119, current rewards: 114.08004, mean: 0.09054
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11117, current rewards: 118.96038, mean: 0.09081
[32m[0906 14-08-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11128, current rewards: 123.84177, mean: 0.09106
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11138, current rewards: 128.72070, mean: 0.09129
[32m[0906 14-08-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11147, current rewards: 133.60481, mean: 0.09151
[32m[0906 14-08-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11147, current rewards: 138.33510, mean: 0.09161
[32m[0906 14-08-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11135, current rewards: 143.28919, mean: 0.09185
[32m[0906 14-08-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11125, current rewards: 148.27409, mean: 0.09210
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11126, current rewards: 153.26073, mean: 0.09233
[32m[0906 14-08-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11127, current rewards: 143.88702, mean: 0.08414
[32m[0906 14-08-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11122, current rewards: 149.56340, mean: 0.08498
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11114, current rewards: 154.88952, mean: 0.08557
[32m[0906 14-09-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11105, current rewards: 160.21708, mean: 0.08614
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11102, current rewards: 165.57847, mean: 0.08669
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11103, current rewards: 171.29262, mean: 0.08739
[32m[0906 14-09-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11096, current rewards: 176.87852, mean: 0.08800
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11088, current rewards: 182.46725, mean: 0.08858
[32m[0906 14-09-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11082, current rewards: 188.05966, mean: 0.08913
[32m[0906 14-09-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11082, current rewards: 193.65165, mean: 0.08965
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11083, current rewards: 199.24280, mean: 0.09016
[32m[0906 14-09-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11086, current rewards: 194.48848, mean: 0.08606
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11089, current rewards: 199.99643, mean: 0.08658
[32m[0906 14-09-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11091, current rewards: 205.49991, mean: 0.08708
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11093, current rewards: 211.00015, mean: 0.08755
[32m[0906 14-10-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11094, current rewards: 216.50516, mean: 0.08801
[32m[0906 14-10-11 @Agent.py:117][0m Average action selection time: 0.1109
[32m[0906 14-10-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-10-11 @MBExp.py:227][0m Rewards obtained: [220.90376451314043], Lows: [20], Highs: [17], Total time: 1676.717114
[32m[0906 14-10-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-28 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11096, current rewards: -7.83026, mean: -0.78303
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11117, current rewards: -1.75578, mean: -0.02926
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11109, current rewards: 5.13491, mean: 0.04668
[32m[0906 14-10-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11139, current rewards: 12.02881, mean: 0.07518
[32m[0906 14-10-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11128, current rewards: 18.92538, mean: 0.09012
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11111, current rewards: 26.55624, mean: 0.10214
[32m[0906 14-11-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11121, current rewards: 33.54171, mean: 0.10820
[32m[0906 14-11-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11120, current rewards: 40.53230, mean: 0.11259
[32m[0906 14-11-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11115, current rewards: 47.53756, mean: 0.11595
[32m[0906 14-11-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11123, current rewards: 54.53416, mean: 0.11855
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11122, current rewards: 61.53083, mean: 0.12065
[32m[0906 14-11-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11124, current rewards: 68.52315, mean: 0.12236
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11126, current rewards: 75.76901, mean: 0.12421
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11122, current rewards: 82.24213, mean: 0.12461
[32m[0906 14-11-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11122, current rewards: 89.27130, mean: 0.12573
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11119, current rewards: 95.70803, mean: 0.12593
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11099, current rewards: 102.14218, mean: 0.12610
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11082, current rewards: 108.57150, mean: 0.12625
[32m[0906 14-12-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11062, current rewards: 115.01283, mean: 0.12639
[32m[0906 14-12-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11054, current rewards: 110.04072, mean: 0.11463
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11061, current rewards: 116.49955, mean: 0.11535
[32m[0906 14-12-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11062, current rewards: 122.95837, mean: 0.11600
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11064, current rewards: 105.72198, mean: 0.09525
[32m[0906 14-12-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11068, current rewards: 55.72198, mean: 0.04804
[32m[0906 14-12-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11069, current rewards: 5.72198, mean: 0.00473
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11073, current rewards: -44.27802, mean: -0.03514
[32m[0906 14-12-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11076, current rewards: -94.27802, mean: -0.07197
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11079, current rewards: -144.27802, mean: -0.10609
[32m[0906 14-13-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11079, current rewards: -194.27802, mean: -0.13779
[32m[0906 14-13-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11081, current rewards: -244.27802, mean: -0.16731
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11072, current rewards: -294.27802, mean: -0.19489
[32m[0906 14-13-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11061, current rewards: -344.27802, mean: -0.22069
[32m[0906 14-13-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11053, current rewards: -394.27802, mean: -0.24489
[32m[0906 14-13-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11051, current rewards: -444.27802, mean: -0.26764
[32m[0906 14-13-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11053, current rewards: -494.27802, mean: -0.28905
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11051, current rewards: -544.27802, mean: -0.30925
[32m[0906 14-13-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11043, current rewards: -594.27802, mean: -0.32833
[32m[0906 14-13-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11036, current rewards: -644.27802, mean: -0.34639
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11032, current rewards: -694.27802, mean: -0.36350
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11034, current rewards: -744.27802, mean: -0.37973
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11032, current rewards: -794.27802, mean: -0.39516
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11026, current rewards: -844.27802, mean: -0.40984
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11019, current rewards: -894.27802, mean: -0.42383
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11017, current rewards: -944.27802, mean: -0.43717
[32m[0906 14-14-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11019, current rewards: -994.27802, mean: -0.44990
[32m[0906 14-14-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11022, current rewards: -1044.27802, mean: -0.46207
[32m[0906 14-14-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11025, current rewards: -1094.27802, mean: -0.47371
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11027, current rewards: -1144.27802, mean: -0.48486
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11030, current rewards: -1194.27802, mean: -0.49555
[32m[0906 14-15-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11032, current rewards: -1244.27802, mean: -0.50580
[32m[0906 14-15-04 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-15-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-15-04 @MBExp.py:227][0m Rewards obtained: [-1284.2780238361818], Lows: [6], Highs: [1418], Total time: 1953.248336
[32m[0906 14-15-23 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-23 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-15-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11084, current rewards: -6.68104, mean: -0.66810
[32m[0906 14-15-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11200, current rewards: 5.17761, mean: 0.08629
[32m[0906 14-15-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11151, current rewards: 18.33578, mean: 0.16669
[32m[0906 14-15-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11146, current rewards: 31.47975, mean: 0.19675
[32m[0906 14-15-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 44.62141, mean: 0.21248
[32m[0906 14-15-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11136, current rewards: 46.45245, mean: 0.17866
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11129, current rewards: 59.18015, mean: 0.19090
[32m[0906 14-16-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11139, current rewards: 71.90418, mean: 0.19973
[32m[0906 14-16-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11138, current rewards: 84.64536, mean: 0.20645
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11138, current rewards: 95.75961, mean: 0.20817
[32m[0906 14-16-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11143, current rewards: 112.19936, mean: 0.22000
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11137, current rewards: 128.75875, mean: 0.22993
[32m[0906 14-16-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11137, current rewards: 145.28287, mean: 0.23817
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11139, current rewards: 147.11736, mean: 0.22291
[32m[0906 14-16-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11135, current rewards: 158.64510, mean: 0.22344
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11137, current rewards: 170.18612, mean: 0.22393
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11117, current rewards: 177.16194, mean: 0.21872
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11095, current rewards: 184.37768, mean: 0.21439
[32m[0906 14-17-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11076, current rewards: 191.59519, mean: 0.21054
[32m[0906 14-17-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11061, current rewards: 198.80619, mean: 0.20709
[32m[0906 14-17-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11062, current rewards: 206.03335, mean: 0.20399
[32m[0906 14-17-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11069, current rewards: 213.48000, mean: 0.20140
[32m[0906 14-17-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11071, current rewards: 220.29946, mean: 0.19847
[32m[0906 14-17-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11079, current rewards: 227.10251, mean: 0.19578
[32m[0906 14-17-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11084, current rewards: 233.91008, mean: 0.19331
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11086, current rewards: 240.70791, mean: 0.19104
[32m[0906 14-17-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11087, current rewards: 247.89989, mean: 0.18924
[32m[0906 14-17-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11092, current rewards: 256.59801, mean: 0.18868
[32m[0906 14-18-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11092, current rewards: 265.30945, mean: 0.18816
[32m[0906 14-18-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11092, current rewards: 273.25513, mean: 0.18716
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11085, current rewards: 282.07461, mean: 0.18680
[32m[0906 14-18-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11075, current rewards: 292.66887, mean: 0.18761
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11065, current rewards: 303.25001, mean: 0.18835
[32m[0906 14-18-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11056, current rewards: 313.84107, mean: 0.18906
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11059, current rewards: 324.42792, mean: 0.18972
[32m[0906 14-18-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11054, current rewards: 335.02308, mean: 0.19035
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11048, current rewards: 345.63104, mean: 0.19096
[32m[0906 14-18-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11041, current rewards: 346.22886, mean: 0.18614
[32m[0906 14-18-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11033, current rewards: 353.30482, mean: 0.18498
[32m[0906 14-19-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11034, current rewards: 360.10675, mean: 0.18373
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11027, current rewards: 366.90724, mean: 0.18254
[32m[0906 14-19-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11021, current rewards: 373.71325, mean: 0.18141
[32m[0906 14-19-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11017, current rewards: 380.51195, mean: 0.18034
[32m[0906 14-19-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11010, current rewards: 387.31600, mean: 0.17931
[32m[0906 14-19-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11013, current rewards: 394.11640, mean: 0.17833
[32m[0906 14-19-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11016, current rewards: 391.80824, mean: 0.17337
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11019, current rewards: 404.16477, mean: 0.17496
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11022, current rewards: 413.54180, mean: 0.17523
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11025, current rewards: 422.88072, mean: 0.17547
[32m[0906 14-19-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11027, current rewards: 432.25487, mean: 0.17571
[32m[0906 14-19-59 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-19-59 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-20-00 @MBExp.py:227][0m Rewards obtained: [439.7656821557772], Lows: [17], Highs: [12], Total time: 2229.693984
[32m[0906 14-20-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-21 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10990, current rewards: -5.59026, mean: -0.55903
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11095, current rewards: -0.45005, mean: -0.00750
[32m[0906 14-20-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11136, current rewards: 4.82294, mean: 0.04384
[32m[0906 14-20-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11122, current rewards: 10.09210, mean: 0.06308
[32m[0906 14-20-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11114, current rewards: 15.36584, mean: 0.07317
[32m[0906 14-20-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11122, current rewards: 20.99141, mean: 0.08074
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11114, current rewards: 26.30100, mean: 0.08484
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11113, current rewards: 31.60906, mean: 0.08780
[32m[0906 14-21-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11117, current rewards: 36.91810, mean: 0.09004
[32m[0906 14-21-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11118, current rewards: 42.23082, mean: 0.09181
[32m[0906 14-21-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11117, current rewards: 47.53876, mean: 0.09321
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11122, current rewards: 52.84965, mean: 0.09437
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11122, current rewards: 47.70489, mean: 0.07820
[32m[0906 14-21-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11122, current rewards: 53.22389, mean: 0.08064
[32m[0906 14-21-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11127, current rewards: 58.43256, mean: 0.08230
[32m[0906 14-21-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11127, current rewards: 63.64322, mean: 0.08374
[32m[0906 14-21-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11108, current rewards: 68.85699, mean: 0.08501
[32m[0906 14-21-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11089, current rewards: 64.12359, mean: 0.07456
[32m[0906 14-22-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11072, current rewards: 69.72990, mean: 0.07663
[32m[0906 14-22-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11063, current rewards: 75.06452, mean: 0.07819
[32m[0906 14-22-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11061, current rewards: 80.39825, mean: 0.07960
[32m[0906 14-22-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11063, current rewards: 85.25275, mean: 0.08043
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11069, current rewards: 90.62516, mean: 0.08164
[32m[0906 14-22-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11072, current rewards: 96.00246, mean: 0.08276
[32m[0906 14-22-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11074, current rewards: 101.37488, mean: 0.08378
[32m[0906 14-22-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11079, current rewards: 96.10000, mean: 0.07627
[32m[0906 14-22-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11081, current rewards: 101.19549, mean: 0.07725
[32m[0906 14-22-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11083, current rewards: 106.29292, mean: 0.07816
[32m[0906 14-22-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11086, current rewards: 111.39073, mean: 0.07900
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11087, current rewards: 116.27901, mean: 0.07964
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11076, current rewards: 121.23420, mean: 0.08029
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11067, current rewards: 126.27824, mean: 0.08095
[32m[0906 14-23-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11058, current rewards: 131.32797, mean: 0.08157
[32m[0906 14-23-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11049, current rewards: 136.37551, mean: 0.08215
[32m[0906 14-23-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11050, current rewards: 141.42162, mean: 0.08270
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11046, current rewards: 146.46951, mean: 0.08322
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11038, current rewards: 146.16836, mean: 0.08076
[32m[0906 14-23-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11034, current rewards: 151.59194, mean: 0.08150
[32m[0906 14-23-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11027, current rewards: 157.59004, mean: 0.08251
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11021, current rewards: 162.90417, mean: 0.08311
[32m[0906 14-24-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11018, current rewards: 168.22060, mean: 0.08369
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11012, current rewards: 173.53391, mean: 0.08424
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11007, current rewards: 178.85014, mean: 0.08476
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11003, current rewards: 184.16431, mean: 0.08526
[32m[0906 14-24-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11003, current rewards: 189.47792, mean: 0.08574
[32m[0906 14-24-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11009, current rewards: 188.98352, mean: 0.08362
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11012, current rewards: 193.49370, mean: 0.08376
[32m[0906 14-24-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11014, current rewards: 198.28773, mean: 0.08402
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11018, current rewards: 203.08533, mean: 0.08427
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11020, current rewards: 207.88012, mean: 0.08450
[32m[0906 14-24-57 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-24-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-24-57 @MBExp.py:227][0m Rewards obtained: [211.71615549024077], Lows: [15], Highs: [16], Total time: 2505.943866
[32m[0906 14-25-20 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-20 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-25-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11110, current rewards: -6.67695, mean: -0.66769
[32m[0906 14-25-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11096, current rewards: 1.00668, mean: 0.01678
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11095, current rewards: 8.70471, mean: 0.07913
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11117, current rewards: 16.40345, mean: 0.10252
[32m[0906 14-25-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11112, current rewards: 25.03950, mean: 0.11924
[32m[0906 14-25-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11127, current rewards: 32.12150, mean: 0.12354
[32m[0906 14-25-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11127, current rewards: 39.00824, mean: 0.12583
[32m[0906 14-26-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11130, current rewards: 45.89630, mean: 0.12749
[32m[0906 14-26-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11131, current rewards: 52.77390, mean: 0.12872
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11131, current rewards: 59.66662, mean: 0.12971
[32m[0906 14-26-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11126, current rewards: 55.18874, mean: 0.10821
[32m[0906 14-26-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11131, current rewards: 61.35338, mean: 0.10956
[32m[0906 14-26-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11130, current rewards: 67.52067, mean: 0.11069
[32m[0906 14-26-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11127, current rewards: 74.55093, mean: 0.11296
[32m[0906 14-26-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11128, current rewards: 80.53563, mean: 0.11343
[32m[0906 14-26-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11125, current rewards: 86.52473, mean: 0.11385
[32m[0906 14-26-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11101, current rewards: 92.52144, mean: 0.11422
[32m[0906 14-26-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11085, current rewards: 98.50971, mean: 0.11455
[32m[0906 14-27-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11062, current rewards: 104.50331, mean: 0.11484
[32m[0906 14-27-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11044, current rewards: 101.65186, mean: 0.10589
[32m[0906 14-27-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11034, current rewards: 107.37444, mean: 0.10631
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11040, current rewards: 113.98345, mean: 0.10753
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11044, current rewards: 120.91011, mean: 0.10893
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11054, current rewards: 127.83677, mean: 0.11020
[32m[0906 14-27-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11060, current rewards: 134.76343, mean: 0.11137
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11063, current rewards: 141.69009, mean: 0.11245
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11064, current rewards: 148.61675, mean: 0.11345
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11065, current rewards: 144.15807, mean: 0.10600
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11068, current rewards: 94.15807, mean: 0.06678
[32m[0906 14-28-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11069, current rewards: 44.15807, mean: 0.03025
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11058, current rewards: -5.84193, mean: -0.00387
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11048, current rewards: -55.84193, mean: -0.03580
[32m[0906 14-28-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11037, current rewards: -105.84193, mean: -0.06574
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11027, current rewards: -155.84193, mean: -0.09388
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11023, current rewards: -205.84193, mean: -0.12038
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11019, current rewards: -255.84193, mean: -0.14536
[32m[0906 14-28-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11012, current rewards: -305.84193, mean: -0.16897
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11007, current rewards: -355.84193, mean: -0.19131
[32m[0906 14-28-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11001, current rewards: -405.84193, mean: -0.21248
[32m[0906 14-28-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10995, current rewards: -455.84193, mean: -0.23257
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10990, current rewards: -505.84193, mean: -0.25166
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10984, current rewards: -555.84193, mean: -0.26983
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10978, current rewards: -605.84193, mean: -0.28713
[32m[0906 14-29-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10974, current rewards: -655.84193, mean: -0.30363
[32m[0906 14-29-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10970, current rewards: -705.84193, mean: -0.31939
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10973, current rewards: -755.84193, mean: -0.33444
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10978, current rewards: -805.84193, mean: -0.34885
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10982, current rewards: -855.84193, mean: -0.36264
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10985, current rewards: -905.84193, mean: -0.37587
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10989, current rewards: -955.84193, mean: -0.38855
[32m[0906 14-29-56 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-29-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-29-56 @MBExp.py:227][0m Rewards obtained: [-995.8419265561662], Lows: [10], Highs: [1157], Total time: 2781.431477
[32m[0906 14-30-22 @MBExp.py:144][0m ####################################################################
[32m[0906 14-30-22 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-30-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11129, current rewards: -4.28086, mean: -0.42809
[32m[0906 14-30-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11131, current rewards: 1.26095, mean: 0.02102
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11110, current rewards: 6.69733, mean: 0.06088
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11146, current rewards: 12.13716, mean: 0.07586
[32m[0906 14-30-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11122, current rewards: 17.02711, mean: 0.08108
[32m[0906 14-30-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11126, current rewards: 16.82009, mean: 0.06469
[32m[0906 14-30-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11132, current rewards: 21.83818, mean: 0.07045
[32m[0906 14-31-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11132, current rewards: 26.85508, mean: 0.07460
[32m[0906 14-31-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11137, current rewards: 31.86433, mean: 0.07772
[32m[0906 14-31-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11137, current rewards: 36.87615, mean: 0.08017
[32m[0906 14-31-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11133, current rewards: 41.89130, mean: 0.08214
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11139, current rewards: 46.90245, mean: 0.08375
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11134, current rewards: 52.25365, mean: 0.08566
[32m[0906 14-31-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11131, current rewards: 57.28998, mean: 0.08680
[32m[0906 14-31-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11130, current rewards: 62.32465, mean: 0.08778
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11127, current rewards: 67.35708, mean: 0.08863
[32m[0906 14-31-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11104, current rewards: 72.39064, mean: 0.08937
[32m[0906 14-31-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11086, current rewards: 72.47951, mean: 0.08428
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11066, current rewards: 78.39826, mean: 0.08615
[32m[0906 14-32-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11047, current rewards: 84.30780, mean: 0.08782
[32m[0906 14-32-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11035, current rewards: 90.23277, mean: 0.08934
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11035, current rewards: 96.14751, mean: 0.09071
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11039, current rewards: 102.05430, mean: 0.09194
[32m[0906 14-32-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11046, current rewards: 107.97513, mean: 0.09308
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11048, current rewards: 103.00325, mean: 0.08513
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11051, current rewards: 108.60026, mean: 0.08619
[32m[0906 14-32-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11056, current rewards: 114.19819, mean: 0.08717
[32m[0906 14-32-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11057, current rewards: 119.79457, mean: 0.08808
[32m[0906 14-32-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11061, current rewards: 125.70553, mean: 0.08915
[32m[0906 14-33-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11062, current rewards: 132.03522, mean: 0.09044
[32m[0906 14-33-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11051, current rewards: 137.94421, mean: 0.09135
[32m[0906 14-33-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11045, current rewards: 133.52596, mean: 0.08559
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11035, current rewards: 139.70427, mean: 0.08677
[32m[0906 14-33-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11026, current rewards: 145.86706, mean: 0.08787
[32m[0906 14-33-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11020, current rewards: 152.02376, mean: 0.08890
[32m[0906 14-33-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11016, current rewards: 158.18712, mean: 0.08988
[32m[0906 14-33-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11009, current rewards: 164.35063, mean: 0.09080
[32m[0906 14-33-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11004, current rewards: 169.71682, mean: 0.09125
[32m[0906 14-33-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10998, current rewards: 164.93575, mean: 0.08635
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10992, current rewards: 169.94359, mean: 0.08671
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10983, current rewards: 174.89368, mean: 0.08701
[32m[0906 14-34-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10977, current rewards: 179.84384, mean: 0.08730
[32m[0906 14-34-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10972, current rewards: 184.79260, mean: 0.08758
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10969, current rewards: 189.74203, mean: 0.08784
[32m[0906 14-34-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10964, current rewards: 194.69142, mean: 0.08810
[32m[0906 14-34-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10967, current rewards: 199.53598, mean: 0.08829
[32m[0906 14-34-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10973, current rewards: 204.36482, mean: 0.08847
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10977, current rewards: 209.19122, mean: 0.08864
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10982, current rewards: 214.01997, mean: 0.08880
[32m[0906 14-34-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10988, current rewards: 218.84845, mean: 0.08896
[32m[0906 14-34-57 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-34-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-34-57 @MBExp.py:227][0m Rewards obtained: [217.22924354910842], Lows: [15], Highs: [20], Total time: 3056.8878600000003
[32m[0906 14-35-25 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-25 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11195, current rewards: -4.36618, mean: -0.43662
[32m[0906 14-35-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11163, current rewards: 7.02797, mean: 0.11713
[32m[0906 14-35-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11181, current rewards: 18.75165, mean: 0.17047
[32m[0906 14-35-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11154, current rewards: 29.33008, mean: 0.18331
[32m[0906 14-35-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 39.74252, mean: 0.18925
[32m[0906 14-35-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11155, current rewards: 50.56141, mean: 0.19447
[32m[0906 14-36-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11150, current rewards: 61.39557, mean: 0.19805
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11151, current rewards: 72.24078, mean: 0.20067
[32m[0906 14-36-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11154, current rewards: 83.08390, mean: 0.20264
[32m[0906 14-36-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11150, current rewards: 93.90270, mean: 0.20414
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11151, current rewards: 104.74502, mean: 0.20538
[32m[0906 14-36-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11154, current rewards: 115.56297, mean: 0.20636
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11154, current rewards: 121.55682, mean: 0.19927
[32m[0906 14-36-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11153, current rewards: 130.60192, mean: 0.19788
[32m[0906 14-36-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11155, current rewards: 136.11739, mean: 0.19171
[32m[0906 14-36-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11155, current rewards: 141.63818, mean: 0.18637
[32m[0906 14-36-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11129, current rewards: 147.15922, mean: 0.18168
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11114, current rewards: 152.67765, mean: 0.17753
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11099, current rewards: 158.19676, mean: 0.17384
[32m[0906 14-37-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11084, current rewards: 163.71350, mean: 0.17053
[32m[0906 14-37-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11068, current rewards: 156.62326, mean: 0.15507
[32m[0906 14-37-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11062, current rewards: 162.37455, mean: 0.15318
[32m[0906 14-37-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11072, current rewards: 168.12674, mean: 0.15147
[32m[0906 14-37-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11080, current rewards: 173.87474, mean: 0.14989
[32m[0906 14-37-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11084, current rewards: 179.62229, mean: 0.14845
[32m[0906 14-37-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11089, current rewards: 185.37095, mean: 0.14712
[32m[0906 14-37-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11093, current rewards: 191.12230, mean: 0.14589
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11096, current rewards: 196.87242, mean: 0.14476
[32m[0906 14-38-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11101, current rewards: 203.46469, mean: 0.14430
[32m[0906 14-38-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11103, current rewards: 210.84839, mean: 0.14442
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11092, current rewards: 176.78785, mean: 0.11708
[32m[0906 14-38-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11084, current rewards: 126.78785, mean: 0.08127
[32m[0906 14-38-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11075, current rewards: 76.78785, mean: 0.04769
[32m[0906 14-38-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11067, current rewards: 26.78785, mean: 0.01614
[32m[0906 14-38-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11060, current rewards: -23.21215, mean: -0.01357
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11051, current rewards: -73.21215, mean: -0.04160
[32m[0906 14-38-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11044, current rewards: -123.21215, mean: -0.06807
[32m[0906 14-38-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11039, current rewards: -173.21215, mean: -0.09312
[32m[0906 14-38-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11033, current rewards: -223.21215, mean: -0.11687
[32m[0906 14-39-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11026, current rewards: -273.21215, mean: -0.13939
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11014, current rewards: -323.21215, mean: -0.16080
[32m[0906 14-39-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11007, current rewards: -373.21215, mean: -0.18117
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11001, current rewards: -423.21215, mean: -0.20057
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10998, current rewards: -473.21215, mean: -0.21908
[32m[0906 14-39-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10993, current rewards: -523.21215, mean: -0.23675
[32m[0906 14-39-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10992, current rewards: -573.21215, mean: -0.25363
[32m[0906 14-39-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10998, current rewards: -623.21215, mean: -0.26979
[32m[0906 14-39-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11001, current rewards: -673.21215, mean: -0.28526
[32m[0906 14-39-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11007, current rewards: -723.21215, mean: -0.30009
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11010, current rewards: -773.21215, mean: -0.31431
[32m[0906 14-40-01 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-40-01 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-40-01 @MBExp.py:227][0m Rewards obtained: [-813.2121503157581], Lows: [11], Highs: [1031], Total time: 3332.890733
[32m[0906 14-40-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-40-32 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-40-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11172, current rewards: -5.49000, mean: -0.54900
[32m[0906 14-40-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11179, current rewards: 0.60206, mean: 0.01003
[32m[0906 14-40-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11204, current rewards: 6.65087, mean: 0.06046
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11186, current rewards: 12.80837, mean: 0.08005
[32m[0906 14-40-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11197, current rewards: 19.76161, mean: 0.09410
[32m[0906 14-41-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11192, current rewards: 25.59572, mean: 0.09845
[32m[0906 14-41-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11181, current rewards: 31.42942, mean: 0.10139
[32m[0906 14-41-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11184, current rewards: 37.26383, mean: 0.10351
[32m[0906 14-41-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11184, current rewards: 43.09662, mean: 0.10511
[32m[0906 14-41-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11189, current rewards: 48.92830, mean: 0.10637
[32m[0906 14-41-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11199, current rewards: 54.76442, mean: 0.10738
[32m[0906 14-41-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11194, current rewards: 53.63222, mean: 0.09577
[32m[0906 14-41-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11192, current rewards: 58.74484, mean: 0.09630
[32m[0906 14-41-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11190, current rewards: 64.23898, mean: 0.09733
[32m[0906 14-41-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11186, current rewards: 69.73349, mean: 0.09822
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11186, current rewards: 75.23624, mean: 0.09900
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11165, current rewards: 80.73551, mean: 0.09967
[32m[0906 14-42-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11143, current rewards: 86.23521, mean: 0.10027
[32m[0906 14-42-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11125, current rewards: 91.72932, mean: 0.10080
[32m[0906 14-42-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11110, current rewards: 97.22308, mean: 0.10127
[32m[0906 14-42-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11097, current rewards: 103.40633, mean: 0.10238
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11082, current rewards: 109.17157, mean: 0.10299
[32m[0906 14-42-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11089, current rewards: 109.22308, mean: 0.09840
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11092, current rewards: 114.65746, mean: 0.09884
[32m[0906 14-42-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11095, current rewards: 119.95935, mean: 0.09914
[32m[0906 14-42-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11099, current rewards: 125.26261, mean: 0.09941
[32m[0906 14-42-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11103, current rewards: 130.57132, mean: 0.09967
[32m[0906 14-43-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11107, current rewards: 135.87626, mean: 0.09991
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11108, current rewards: 141.17989, mean: 0.10013
[32m[0906 14-43-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11110, current rewards: 136.13135, mean: 0.09324
[32m[0906 14-43-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11100, current rewards: 141.41808, mean: 0.09365
[32m[0906 14-43-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11090, current rewards: 146.71044, mean: 0.09405
[32m[0906 14-43-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11082, current rewards: 151.99963, mean: 0.09441
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11075, current rewards: 157.28456, mean: 0.09475
[32m[0906 14-43-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11067, current rewards: 157.17450, mean: 0.09191
[32m[0906 14-43-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11055, current rewards: 162.36647, mean: 0.09225
[32m[0906 14-43-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11051, current rewards: 167.52217, mean: 0.09255
[32m[0906 14-43-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11045, current rewards: 173.45545, mean: 0.09326
[32m[0906 14-44-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11038, current rewards: 178.77497, mean: 0.09360
[32m[0906 14-44-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11033, current rewards: 184.09675, mean: 0.09393
[32m[0906 14-44-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11019, current rewards: 189.41526, mean: 0.09424
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11008, current rewards: 194.73215, mean: 0.09453
[32m[0906 14-44-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11004, current rewards: 200.04712, mean: 0.09481
[32m[0906 14-44-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10999, current rewards: 205.36943, mean: 0.09508
[32m[0906 14-44-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10994, current rewards: 210.68544, mean: 0.09533
[32m[0906 14-44-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10991, current rewards: 210.68155, mean: 0.09322
[32m[0906 14-44-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10993, current rewards: 216.35922, mean: 0.09366
[32m[0906 14-44-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10997, current rewards: 222.04510, mean: 0.09409
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11001, current rewards: 227.72358, mean: 0.09449
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11004, current rewards: 233.40559, mean: 0.09488
[32m[0906 14-45-08 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-45-08 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-45-08 @MBExp.py:227][0m Rewards obtained: [237.9461205344291], Lows: [5], Highs: [27], Total time: 3608.7665260000003
[32m[0906 14-45-41 @MBExp.py:144][0m ####################################################################
[32m[0906 14-45-41 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11505, current rewards: -4.43419, mean: -0.44342
[32m[0906 14-45-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11174, current rewards: 1.33891, mean: 0.02232
[32m[0906 14-45-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11157, current rewards: 7.09791, mean: 0.06453
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11166, current rewards: 12.90174, mean: 0.08064
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11153, current rewards: 19.55587, mean: 0.09312
[32m[0906 14-46-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11149, current rewards: 25.67482, mean: 0.09875
[32m[0906 14-46-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11156, current rewards: 21.35673, mean: 0.06889
[32m[0906 14-46-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11151, current rewards: 28.59302, mean: 0.07943
[32m[0906 14-46-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11145, current rewards: 35.81422, mean: 0.08735
[32m[0906 14-46-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11154, current rewards: 43.04583, mean: 0.09358
[32m[0906 14-46-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11156, current rewards: 50.27743, mean: 0.09858
[32m[0906 14-46-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11159, current rewards: 57.50514, mean: 0.10269
[32m[0906 14-46-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11166, current rewards: 64.53620, mean: 0.10580
[32m[0906 14-46-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11162, current rewards: 71.61250, mean: 0.10850
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11160, current rewards: 78.69264, mean: 0.11083
[32m[0906 14-47-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11159, current rewards: 79.36944, mean: 0.10443
[32m[0906 14-47-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11136, current rewards: 85.38745, mean: 0.10542
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11117, current rewards: 91.40650, mean: 0.10629
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11100, current rewards: 97.42515, mean: 0.10706
[32m[0906 14-47-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11088, current rewards: 97.08514, mean: 0.10113
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11081, current rewards: 99.33677, mean: 0.09835
[32m[0906 14-47-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11068, current rewards: 105.70632, mean: 0.09972
[32m[0906 14-47-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11066, current rewards: 112.07649, mean: 0.10097
[32m[0906 14-47-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11071, current rewards: 118.44739, mean: 0.10211
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11076, current rewards: 124.81740, mean: 0.10315
[32m[0906 14-48-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11081, current rewards: 131.18887, mean: 0.10412
[32m[0906 14-48-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11087, current rewards: 134.17364, mean: 0.10242
[32m[0906 14-48-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11090, current rewards: 138.21868, mean: 0.10163
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11093, current rewards: 144.05814, mean: 0.10217
[32m[0906 14-48-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11097, current rewards: 150.16851, mean: 0.10286
[32m[0906 14-48-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11088, current rewards: 156.28057, mean: 0.10350
[32m[0906 14-48-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11077, current rewards: 162.38951, mean: 0.10410
[32m[0906 14-48-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11069, current rewards: 168.50214, mean: 0.10466
[32m[0906 14-48-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11061, current rewards: 174.61472, mean: 0.10519
[32m[0906 14-48-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11053, current rewards: 180.72312, mean: 0.10569
[32m[0906 14-48-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11044, current rewards: 175.14537, mean: 0.09951
[32m[0906 14-49-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11033, current rewards: 181.19095, mean: 0.10011
[32m[0906 14-49-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11026, current rewards: 187.28278, mean: 0.10069
[32m[0906 14-49-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11021, current rewards: 193.37153, mean: 0.10124
[32m[0906 14-49-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11016, current rewards: 199.46715, mean: 0.10177
[32m[0906 14-49-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11003, current rewards: 205.55526, mean: 0.10227
[32m[0906 14-49-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10992, current rewards: 211.64284, mean: 0.10274
[32m[0906 14-49-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10986, current rewards: 217.73195, mean: 0.10319
[32m[0906 14-49-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10983, current rewards: 223.82531, mean: 0.10362
[32m[0906 14-49-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10981, current rewards: 229.48943, mean: 0.10384
[32m[0906 14-49-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10977, current rewards: 235.28162, mean: 0.10411
[32m[0906 14-49-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10978, current rewards: 241.06446, mean: 0.10436
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10985, current rewards: 246.85247, mean: 0.10460
[32m[0906 14-50-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10988, current rewards: 252.63859, mean: 0.10483
[32m[0906 14-50-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10993, current rewards: 258.42333, mean: 0.10505
[32m[0906 14-50-16 @Agent.py:117][0m Average action selection time: 0.1100
[32m[0906 14-50-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-50-16 @MBExp.py:227][0m Rewards obtained: [263.04903602967], Lows: [17], Highs: [15], Total time: 3884.3494050000004
[32m[0906 14-50-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-50-52 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11218, current rewards: -4.43926, mean: -0.44393
[32m[0906 14-50-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11241, current rewards: 0.72130, mean: 0.01202
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11263, current rewards: 5.89581, mean: 0.05360
[32m[0906 14-51-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11265, current rewards: 11.29830, mean: 0.07061
[32m[0906 14-51-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11274, current rewards: 16.49636, mean: 0.07855
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11274, current rewards: 21.69701, mean: 0.08345
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11270, current rewards: 26.67929, mean: 0.08606
[32m[0906 14-51-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11279, current rewards: 31.77327, mean: 0.08826
[32m[0906 14-51-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11284, current rewards: 36.86686, mean: 0.08992
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11285, current rewards: 41.95668, mean: 0.09121
[32m[0906 14-51-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11292, current rewards: 47.04534, mean: 0.09225
[32m[0906 14-51-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11285, current rewards: 52.00881, mean: 0.09287
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11280, current rewards: 57.09621, mean: 0.09360
[32m[0906 14-52-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11276, current rewards: 62.18237, mean: 0.09422
[32m[0906 14-52-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11268, current rewards: 67.27372, mean: 0.09475
[32m[0906 14-52-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11259, current rewards: 72.36011, mean: 0.09521
[32m[0906 14-52-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11237, current rewards: 77.44862, mean: 0.09562
[32m[0906 14-52-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11211, current rewards: 72.05463, mean: 0.08378
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11190, current rewards: 77.40469, mean: 0.08506
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11175, current rewards: 83.44772, mean: 0.08692
[32m[0906 14-52-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11159, current rewards: 88.62927, mean: 0.08775
[32m[0906 14-52-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11145, current rewards: 93.80960, mean: 0.08850
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11137, current rewards: 93.52711, mean: 0.08426
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11143, current rewards: 98.59403, mean: 0.08499
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11150, current rewards: 103.65925, mean: 0.08567
[32m[0906 14-53-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11152, current rewards: 108.72259, mean: 0.08629
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11155, current rewards: 113.78702, mean: 0.08686
[32m[0906 14-53-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11159, current rewards: 118.94584, mean: 0.08746
[32m[0906 14-53-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11160, current rewards: 124.00636, mean: 0.08795
[32m[0906 14-53-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11159, current rewards: 129.06826, mean: 0.08840
[32m[0906 14-53-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11149, current rewards: 134.13258, mean: 0.08883
[32m[0906 14-53-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11138, current rewards: 139.19489, mean: 0.08923
[32m[0906 14-53-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11127, current rewards: 134.78965, mean: 0.08372
[32m[0906 14-53-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11118, current rewards: 139.93303, mean: 0.08430
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11110, current rewards: 145.07575, mean: 0.08484
[32m[0906 14-54-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11098, current rewards: 150.06879, mean: 0.08527
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11085, current rewards: 154.98104, mean: 0.08562
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11078, current rewards: 160.00238, mean: 0.08602
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11070, current rewards: 165.02715, mean: 0.08640
[32m[0906 14-54-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11066, current rewards: 170.05126, mean: 0.08676
[32m[0906 14-54-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11051, current rewards: 175.07677, mean: 0.08710
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11038, current rewards: 180.10233, mean: 0.08743
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11030, current rewards: 185.12504, mean: 0.08774
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11025, current rewards: 190.14985, mean: 0.08803
[32m[0906 14-54-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11022, current rewards: 177.44971, mean: 0.08029
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11019, current rewards: 182.56596, mean: 0.08078
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11015, current rewards: 187.68007, mean: 0.08125
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11019, current rewards: 192.79283, mean: 0.08169
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11024, current rewards: 197.90604, mean: 0.08212
[32m[0906 14-55-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11027, current rewards: 203.01865, mean: 0.08253
[32m[0906 14-55-28 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-55-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-55-28 @MBExp.py:227][0m Rewards obtained: [203.80146596148626], Lows: [10], Highs: [30], Total time: 4160.821825
[32m[0906 14-56-06 @MBExp.py:144][0m ####################################################################
[32m[0906 14-56-06 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11167, current rewards: -5.47234, mean: -0.54723
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11202, current rewards: -0.14344, mean: -0.00239
[32m[0906 14-56-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11202, current rewards: 4.74442, mean: 0.04313
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11204, current rewards: 9.82407, mean: 0.06140
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11200, current rewards: 14.96769, mean: 0.07127
[32m[0906 14-56-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11213, current rewards: 20.11092, mean: 0.07735
[32m[0906 14-56-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11202, current rewards: 25.25654, mean: 0.08147
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11204, current rewards: 30.40134, mean: 0.08445
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11207, current rewards: 35.54300, mean: 0.08669
[32m[0906 14-56-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11205, current rewards: 40.68558, mean: 0.08845
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11202, current rewards: 45.82803, mean: 0.08986
[32m[0906 14-57-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11203, current rewards: 52.06909, mean: 0.09298
[32m[0906 14-57-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11202, current rewards: 57.39781, mean: 0.09409
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11198, current rewards: 62.72909, mean: 0.09504
[32m[0906 14-57-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11198, current rewards: 62.59831, mean: 0.08817
[32m[0906 14-57-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11201, current rewards: 68.24189, mean: 0.08979
[32m[0906 14-57-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11180, current rewards: 73.89414, mean: 0.09123
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11160, current rewards: 79.54415, mean: 0.09249
[32m[0906 14-57-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11140, current rewards: 85.20332, mean: 0.09363
[32m[0906 14-57-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11123, current rewards: 91.74086, mean: 0.09556
[32m[0906 14-57-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11108, current rewards: 97.10849, mean: 0.09615
[32m[0906 14-58-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11093, current rewards: 102.47687, mean: 0.09668
[32m[0906 14-58-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11083, current rewards: 107.85036, mean: 0.09716
[32m[0906 14-58-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11085, current rewards: 113.21974, mean: 0.09760
[32m[0906 14-58-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11091, current rewards: 118.58434, mean: 0.09800
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11099, current rewards: 123.95902, mean: 0.09838
[32m[0906 14-58-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11102, current rewards: 129.32913, mean: 0.09872
[32m[0906 14-58-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11105, current rewards: 134.84154, mean: 0.09915
[32m[0906 14-58-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11112, current rewards: 130.22790, mean: 0.09236
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11112, current rewards: 135.68401, mean: 0.09293
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11102, current rewards: 141.14007, mean: 0.09347
[32m[0906 14-58-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11096, current rewards: 146.59430, mean: 0.09397
[32m[0906 14-59-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11088, current rewards: 152.04872, mean: 0.09444
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11080, current rewards: 157.50254, mean: 0.09488
[32m[0906 14-59-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11073, current rewards: 162.95729, mean: 0.09530
[32m[0906 14-59-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11061, current rewards: 161.86767, mean: 0.09197
[32m[0906 14-59-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11044, current rewards: 167.73591, mean: 0.09267
[32m[0906 14-59-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11039, current rewards: 173.15266, mean: 0.09309
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11035, current rewards: 178.56782, mean: 0.09349
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11029, current rewards: 183.98798, mean: 0.09387
[32m[0906 14-59-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11016, current rewards: 189.40436, mean: 0.09423
[32m[0906 14-59-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11004, current rewards: 194.79643, mean: 0.09456
[32m[0906 14-59-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10992, current rewards: 200.31546, mean: 0.09494
[32m[0906 15-00-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10989, current rewards: 205.83103, mean: 0.09529
[32m[0906 15-00-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10987, current rewards: 210.70023, mean: 0.09534
[32m[0906 15-00-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10984, current rewards: 216.16985, mean: 0.09565
[32m[0906 15-00-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10982, current rewards: 221.65368, mean: 0.09595
[32m[0906 15-00-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10984, current rewards: 227.13386, mean: 0.09624
[32m[0906 15-00-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10989, current rewards: 232.60607, mean: 0.09652
[32m[0906 15-00-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10996, current rewards: 238.08890, mean: 0.09678
[32m[0906 15-00-41 @Agent.py:117][0m Average action selection time: 0.1100
[32m[0906 15-00-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-00-41 @MBExp.py:227][0m Rewards obtained: [242.46506809427495], Lows: [5], Highs: [17], Total time: 4436.486448
[32m[0906 15-01-21 @MBExp.py:144][0m ####################################################################
[32m[0906 15-01-21 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11116, current rewards: -5.30961, mean: -0.53096
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11220, current rewards: -0.34490, mean: -0.00575
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11204, current rewards: 4.43417, mean: 0.04031
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11212, current rewards: 9.05292, mean: 0.05658
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11186, current rewards: 13.77594, mean: 0.06560
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11178, current rewards: 18.49848, mean: 0.07115
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11182, current rewards: 23.22231, mean: 0.07491
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11172, current rewards: 27.94559, mean: 0.07763
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11175, current rewards: 32.67278, mean: 0.07969
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11171, current rewards: 37.39917, mean: 0.08130
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11173, current rewards: 42.12319, mean: 0.08259
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11173, current rewards: 46.71778, mean: 0.08342
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11169, current rewards: 51.39117, mean: 0.08425
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11165, current rewards: 43.80758, mean: 0.06638
[32m[0906 15-02-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11166, current rewards: 49.53027, mean: 0.06976
[32m[0906 15-02-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11159, current rewards: 55.25505, mean: 0.07270
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11131, current rewards: 60.97862, mean: 0.07528
[32m[0906 15-02-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11113, current rewards: 66.70493, mean: 0.07756
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11091, current rewards: 72.43349, mean: 0.07960
[32m[0906 15-03-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11076, current rewards: 78.78898, mean: 0.08207
[32m[0906 15-03-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11063, current rewards: 84.28538, mean: 0.08345
[32m[0906 15-03-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11048, current rewards: 89.78461, mean: 0.08470
[32m[0906 15-03-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11034, current rewards: 95.27984, mean: 0.08584
[32m[0906 15-03-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11031, current rewards: 100.77443, mean: 0.08687
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11034, current rewards: 106.26939, mean: 0.08783
[32m[0906 15-03-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11038, current rewards: 105.04317, mean: 0.08337
[32m[0906 15-03-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11042, current rewards: 110.15638, mean: 0.08409
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11047, current rewards: 115.15907, mean: 0.08468
[32m[0906 15-03-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11051, current rewards: 120.27165, mean: 0.08530
[32m[0906 15-04-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11053, current rewards: 125.37845, mean: 0.08588
[32m[0906 15-04-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11043, current rewards: 130.48410, mean: 0.08641
[32m[0906 15-04-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11035, current rewards: 134.48941, mean: 0.08621
[32m[0906 15-04-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11028, current rewards: 135.79240, mean: 0.08434
[32m[0906 15-04-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11020, current rewards: 141.72134, mean: 0.08537
[32m[0906 15-04-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11015, current rewards: 147.65292, mean: 0.08635
[32m[0906 15-04-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11006, current rewards: 154.00271, mean: 0.08750
[32m[0906 15-04-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10994, current rewards: 160.39077, mean: 0.08861
[32m[0906 15-04-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10986, current rewards: 166.41140, mean: 0.08947
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10982, current rewards: 172.42055, mean: 0.09027
[32m[0906 15-04-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10978, current rewards: 178.42945, mean: 0.09104
[32m[0906 15-05-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10965, current rewards: 172.65200, mean: 0.08590
[32m[0906 15-05-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10953, current rewards: 178.64676, mean: 0.08672
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10940, current rewards: 183.87775, mean: 0.08715
[32m[0906 15-05-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10935, current rewards: 189.10520, mean: 0.08755
[32m[0906 15-05-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10932, current rewards: 193.79301, mean: 0.08769
[32m[0906 15-05-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10930, current rewards: 199.11108, mean: 0.08810
[32m[0906 15-05-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10927, current rewards: 204.42462, mean: 0.08850
[32m[0906 15-05-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10926, current rewards: 209.73945, mean: 0.08887
[32m[0906 15-05-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10931, current rewards: 215.05613, mean: 0.08923
[32m[0906 15-05-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10937, current rewards: 220.37530, mean: 0.08958
[32m[0906 15-05-56 @Agent.py:117][0m Average action selection time: 0.1094
[32m[0906 15-05-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-05-56 @MBExp.py:227][0m Rewards obtained: [224.62944764195473], Lows: [12], Highs: [17], Total time: 4710.7009849999995
[32m[0906 15-06-38 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-38 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11247, current rewards: -5.60253, mean: -0.56025
[32m[0906 15-06-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11173, current rewards: 0.86240, mean: 0.01437
[32m[0906 15-06-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11189, current rewards: 6.89939, mean: 0.06272
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11205, current rewards: 13.44695, mean: 0.08404
[32m[0906 15-07-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11208, current rewards: 20.05550, mean: 0.09550
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11211, current rewards: 26.67974, mean: 0.10261
[32m[0906 15-07-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11220, current rewards: 33.29682, mean: 0.10741
[32m[0906 15-07-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11216, current rewards: 29.28325, mean: 0.08134
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11218, current rewards: 34.87176, mean: 0.08505
[32m[0906 15-07-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11229, current rewards: 40.52789, mean: 0.08810
[32m[0906 15-07-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11232, current rewards: 46.19200, mean: 0.09057
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11231, current rewards: 52.00387, mean: 0.09286
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11225, current rewards: 57.71250, mean: 0.09461
[32m[0906 15-07-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11224, current rewards: 63.41881, mean: 0.09609
[32m[0906 15-07-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11222, current rewards: 69.12059, mean: 0.09735
[32m[0906 15-08-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11209, current rewards: 74.83003, mean: 0.09846
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11182, current rewards: 80.53991, mean: 0.09943
[32m[0906 15-08-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11162, current rewards: 86.24756, mean: 0.10029
[32m[0906 15-08-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11142, current rewards: 91.95686, mean: 0.10105
[32m[0906 15-08-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11124, current rewards: 97.04708, mean: 0.10109
[32m[0906 15-08-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11111, current rewards: 102.44959, mean: 0.10144
[32m[0906 15-08-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11097, current rewards: 107.84525, mean: 0.10174
[32m[0906 15-08-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11082, current rewards: 107.74492, mean: 0.09707
[32m[0906 15-08-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11072, current rewards: 113.07500, mean: 0.09748
[32m[0906 15-08-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11075, current rewards: 118.40070, mean: 0.09785
[32m[0906 15-08-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11080, current rewards: 123.73092, mean: 0.09820
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11083, current rewards: 129.05436, mean: 0.09851
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11085, current rewards: 135.66798, mean: 0.09976
[32m[0906 15-09-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11087, current rewards: 141.52914, mean: 0.10038
[32m[0906 15-09-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11088, current rewards: 147.09899, mean: 0.10075
[32m[0906 15-09-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11077, current rewards: 152.67072, mean: 0.10111
[32m[0906 15-09-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11070, current rewards: 158.24891, mean: 0.10144
[32m[0906 15-09-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11063, current rewards: 148.80987, mean: 0.09243
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11055, current rewards: 158.14331, mean: 0.09527
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11047, current rewards: 167.47675, mean: 0.09794
[32m[0906 15-09-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11037, current rewards: 176.81019, mean: 0.10046
[32m[0906 15-09-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11020, current rewards: 181.36781, mean: 0.10020
[32m[0906 15-10-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11006, current rewards: 165.44518, mean: 0.08895
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11002, current rewards: 115.44518, mean: 0.06044
[32m[0906 15-10-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10998, current rewards: 65.44518, mean: 0.03339
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10985, current rewards: 15.44518, mean: 0.00768
[32m[0906 15-10-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10973, current rewards: -34.55482, mean: -0.01677
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10961, current rewards: -84.55482, mean: -0.04007
[32m[0906 15-10-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10950, current rewards: -134.55482, mean: -0.06229
[32m[0906 15-10-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10949, current rewards: -184.55482, mean: -0.08351
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10946, current rewards: -234.55482, mean: -0.10379
[32m[0906 15-10-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10943, current rewards: -284.55482, mean: -0.12318
[32m[0906 15-10-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10941, current rewards: -334.55482, mean: -0.14176
[32m[0906 15-11-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10944, current rewards: -384.55482, mean: -0.15957
[32m[0906 15-11-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10950, current rewards: -434.55482, mean: -0.17665
[32m[0906 15-11-12 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-11-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-11-12 @MBExp.py:227][0m Rewards obtained: [-474.55482421609383], Lows: [13], Highs: [669], Total time: 4985.221876
[32m[0906 15-11-57 @MBExp.py:144][0m ####################################################################
[32m[0906 15-11-57 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11256, current rewards: -4.17437, mean: -0.41744
[32m[0906 15-12-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11228, current rewards: 1.52459, mean: 0.02541
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11204, current rewards: 7.10940, mean: 0.06463
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11223, current rewards: 12.30141, mean: 0.07688
[32m[0906 15-12-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11217, current rewards: 17.70793, mean: 0.08432
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11217, current rewards: 23.11247, mean: 0.08889
[32m[0906 15-12-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11227, current rewards: 28.51704, mean: 0.09199
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11222, current rewards: 33.92273, mean: 0.09423
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11218, current rewards: 39.32458, mean: 0.09591
[32m[0906 15-12-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11220, current rewards: 34.62739, mean: 0.07528
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11212, current rewards: 40.52485, mean: 0.07946
[32m[0906 15-13-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11212, current rewards: 47.11558, mean: 0.08413
[32m[0906 15-13-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11206, current rewards: 53.05739, mean: 0.08698
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11201, current rewards: 58.99854, mean: 0.08939
[32m[0906 15-13-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11203, current rewards: 64.94267, mean: 0.09147
[32m[0906 15-13-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11189, current rewards: 62.40745, mean: 0.08212
[32m[0906 15-13-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11160, current rewards: 66.35314, mean: 0.08192
[32m[0906 15-13-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11144, current rewards: 72.13930, mean: 0.08388
[32m[0906 15-13-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11125, current rewards: 77.92965, mean: 0.08564
[32m[0906 15-13-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11105, current rewards: 83.57711, mean: 0.08706
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11091, current rewards: 89.29820, mean: 0.08841
[32m[0906 15-13-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11079, current rewards: 95.01315, mean: 0.08964
[32m[0906 15-14-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11065, current rewards: 100.72399, mean: 0.09074
[32m[0906 15-14-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11054, current rewards: 106.43968, mean: 0.09176
[32m[0906 15-14-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11055, current rewards: 102.40360, mean: 0.08463
[32m[0906 15-14-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11060, current rewards: 108.78502, mean: 0.08634
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11066, current rewards: 115.16637, mean: 0.08791
[32m[0906 15-14-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11069, current rewards: 121.14522, mean: 0.08908
[32m[0906 15-14-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11073, current rewards: 126.79622, mean: 0.08993
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11075, current rewards: 132.82413, mean: 0.09098
[32m[0906 15-14-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11066, current rewards: 138.85122, mean: 0.09195
[32m[0906 15-14-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11056, current rewards: 144.87893, mean: 0.09287
[32m[0906 15-14-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11052, current rewards: 150.90769, mean: 0.09373
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11046, current rewards: 156.93355, mean: 0.09454
[32m[0906 15-15-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11039, current rewards: 162.96351, mean: 0.09530
[32m[0906 15-15-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11030, current rewards: 168.99045, mean: 0.09602
[32m[0906 15-15-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11013, current rewards: 170.15483, mean: 0.09401
[32m[0906 15-15-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10998, current rewards: 175.82134, mean: 0.09453
[32m[0906 15-15-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10991, current rewards: 181.50601, mean: 0.09503
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10987, current rewards: 187.18727, mean: 0.09550
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10974, current rewards: 192.86638, mean: 0.09595
[32m[0906 15-15-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10963, current rewards: 198.55107, mean: 0.09638
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10951, current rewards: 204.24034, mean: 0.09680
[32m[0906 15-15-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10941, current rewards: 209.92426, mean: 0.09719
[32m[0906 15-15-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10936, current rewards: 215.52585, mean: 0.09752
[32m[0906 15-16-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10934, current rewards: 215.67890, mean: 0.09543
[32m[0906 15-16-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10931, current rewards: 221.25940, mean: 0.09578
[32m[0906 15-16-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10929, current rewards: 226.84393, mean: 0.09612
[32m[0906 15-16-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10929, current rewards: 232.41723, mean: 0.09644
[32m[0906 15-16-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10936, current rewards: 237.99845, mean: 0.09675
[32m[0906 15-16-31 @Agent.py:117][0m Average action selection time: 0.1094
[32m[0906 15-16-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-16-31 @MBExp.py:227][0m Rewards obtained: [242.4637620087742], Lows: [15], Highs: [15], Total time: 5259.406021
[32m[0906 15-17-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-17-18 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 15-17-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11287, current rewards: -4.57083, mean: -0.45708
[32m[0906 15-17-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11168, current rewards: 1.50105, mean: 0.02502
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11242, current rewards: 7.41040, mean: 0.06737
[32m[0906 15-17-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11257, current rewards: 13.78537, mean: 0.08616
[32m[0906 15-17-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11231, current rewards: 19.73900, mean: 0.09400
[32m[0906 15-17-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11236, current rewards: 25.69199, mean: 0.09882
[32m[0906 15-17-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11220, current rewards: 31.64098, mean: 0.10207
[32m[0906 15-17-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11219, current rewards: 37.59293, mean: 0.10442
[32m[0906 15-18-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11210, current rewards: 43.54269, mean: 0.10620
[32m[0906 15-18-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11203, current rewards: 49.48827, mean: 0.10758
[32m[0906 15-18-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11198, current rewards: 44.38220, mean: 0.08702
[32m[0906 15-18-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11194, current rewards: 50.07640, mean: 0.08942
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11186, current rewards: 56.19243, mean: 0.09212
[32m[0906 15-18-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11180, current rewards: 62.31542, mean: 0.09442
[32m[0906 15-18-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11181, current rewards: 68.43789, mean: 0.09639
[32m[0906 15-18-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11164, current rewards: 74.55841, mean: 0.09810
[32m[0906 15-18-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11140, current rewards: 80.69081, mean: 0.09962
[32m[0906 15-18-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11121, current rewards: 76.45827, mean: 0.08890
[32m[0906 15-18-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11103, current rewards: 82.11651, mean: 0.09024
[32m[0906 15-19-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11089, current rewards: 87.89734, mean: 0.09156
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11074, current rewards: 93.56118, mean: 0.09263
[32m[0906 15-19-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11059, current rewards: 99.21882, mean: 0.09360
[32m[0906 15-19-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11049, current rewards: 104.87542, mean: 0.09448
[32m[0906 15-19-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11037, current rewards: 110.53125, mean: 0.09529
[32m[0906 15-19-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11031, current rewards: 116.18711, mean: 0.09602
[32m[0906 15-19-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11038, current rewards: 121.84565, mean: 0.09670
[32m[0906 15-19-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11043, current rewards: 127.50310, mean: 0.09733
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11049, current rewards: 126.76688, mean: 0.09321
[32m[0906 15-19-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11054, current rewards: 132.56957, mean: 0.09402
[32m[0906 15-20-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11052, current rewards: 138.38558, mean: 0.09478
[32m[0906 15-20-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11044, current rewards: 144.19109, mean: 0.09549
[32m[0906 15-20-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11039, current rewards: 150.00514, mean: 0.09616
[32m[0906 15-20-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11031, current rewards: 155.81547, mean: 0.09678
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11025, current rewards: 161.62672, mean: 0.09737
[32m[0906 15-20-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11019, current rewards: 167.43632, mean: 0.09792
[32m[0906 15-20-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11012, current rewards: 162.91705, mean: 0.09257
[32m[0906 15-20-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10996, current rewards: 168.34171, mean: 0.09301
[32m[0906 15-20-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10983, current rewards: 174.20133, mean: 0.09366
[32m[0906 15-20-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10973, current rewards: 180.06914, mean: 0.09428
[32m[0906 15-20-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10969, current rewards: 185.93623, mean: 0.09487
[32m[0906 15-20-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10959, current rewards: 191.79184, mean: 0.09542
[32m[0906 15-21-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10947, current rewards: 197.64877, mean: 0.09595
[32m[0906 15-21-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10935, current rewards: 203.51300, mean: 0.09645
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10925, current rewards: 209.37245, mean: 0.09693
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10917, current rewards: 215.09866, mean: 0.09733
[32m[0906 15-21-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10917, current rewards: 221.06560, mean: 0.09782
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10916, current rewards: 227.03377, mean: 0.09828
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10914, current rewards: 233.00117, mean: 0.09873
[32m[0906 15-21-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10912, current rewards: 228.18404, mean: 0.09468
[32m[0906 15-21-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10918, current rewards: 234.07283, mean: 0.09515
[32m[0906 15-21-52 @Agent.py:117][0m Average action selection time: 0.1092
[32m[0906 15-21-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-21-52 @MBExp.py:227][0m Rewards obtained: [238.78174137101345], Lows: [21], Highs: [12], Total time: 5533.170089
[32m[0906 15-22-41 @MBExp.py:144][0m ####################################################################
[32m[0906 15-22-41 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11005, current rewards: -5.60306, mean: -0.56031
[32m[0906 15-22-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11181, current rewards: 0.02402, mean: 0.00040
[32m[0906 15-22-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11166, current rewards: 5.89119, mean: 0.05356
[32m[0906 15-22-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11150, current rewards: 11.55571, mean: 0.07222
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11162, current rewards: 17.21924, mean: 0.08200
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11153, current rewards: 22.88500, mean: 0.08802
[32m[0906 15-23-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11150, current rewards: 23.21741, mean: 0.07489
[32m[0906 15-23-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11158, current rewards: 28.60342, mean: 0.07945
[32m[0906 15-23-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11154, current rewards: 33.99114, mean: 0.08291
[32m[0906 15-23-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11151, current rewards: 39.37419, mean: 0.08560
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11156, current rewards: 45.11235, mean: 0.08846
[32m[0906 15-23-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11153, current rewards: 50.51048, mean: 0.09020
[32m[0906 15-23-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11149, current rewards: 55.90940, mean: 0.09165
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11151, current rewards: 61.30511, mean: 0.09289
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11147, current rewards: 66.70639, mean: 0.09395
[32m[0906 15-24-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11130, current rewards: 60.19958, mean: 0.07921
[32m[0906 15-24-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11109, current rewards: 66.12147, mean: 0.08163
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11086, current rewards: 72.04270, mean: 0.08377
[32m[0906 15-24-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11067, current rewards: 77.96400, mean: 0.08567
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11055, current rewards: 83.88486, mean: 0.08738
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11038, current rewards: 81.88711, mean: 0.08108
[32m[0906 15-24-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11024, current rewards: 87.28524, mean: 0.08234
[32m[0906 15-24-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11015, current rewards: 92.72567, mean: 0.08354
[32m[0906 15-24-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11006, current rewards: 98.17540, mean: 0.08463
[32m[0906 15-24-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10999, current rewards: 103.61343, mean: 0.08563
[32m[0906 15-25-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11006, current rewards: 109.05646, mean: 0.08655
[32m[0906 15-25-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11012, current rewards: 117.57186, mean: 0.08975
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11019, current rewards: 122.97559, mean: 0.09042
[32m[0906 15-25-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11025, current rewards: 128.37889, mean: 0.09105
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11023, current rewards: 133.77556, mean: 0.09163
[32m[0906 15-25-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11019, current rewards: 139.17910, mean: 0.09217
[32m[0906 15-25-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11012, current rewards: 144.57607, mean: 0.09268
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11006, current rewards: 149.97461, mean: 0.09315
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11003, current rewards: 155.37530, mean: 0.09360
[32m[0906 15-25-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10997, current rewards: 150.36533, mean: 0.08793
[32m[0906 15-25-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10987, current rewards: 155.69402, mean: 0.08846
[32m[0906 15-26-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10974, current rewards: 161.17820, mean: 0.08905
[32m[0906 15-26-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10959, current rewards: 166.66061, mean: 0.08960
[32m[0906 15-26-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10947, current rewards: 172.14559, mean: 0.09013
[32m[0906 15-26-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10945, current rewards: 177.62867, mean: 0.09063
[32m[0906 15-26-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10933, current rewards: 183.11154, mean: 0.09110
[32m[0906 15-26-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10920, current rewards: 188.59677, mean: 0.09155
[32m[0906 15-26-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10910, current rewards: 194.08010, mean: 0.09198
[32m[0906 15-26-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10899, current rewards: 199.46122, mean: 0.09234
[32m[0906 15-26-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10888, current rewards: 204.92229, mean: 0.09273
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10884, current rewards: 210.37923, mean: 0.09309
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10882, current rewards: 215.83706, mean: 0.09344
[32m[0906 15-26-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10880, current rewards: 221.29246, mean: 0.09377
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10880, current rewards: 226.57906, mean: 0.09402
[32m[0906 15-27-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10883, current rewards: 231.90474, mean: 0.09427
[32m[0906 15-27-14 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 15-27-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-27-14 @MBExp.py:227][0m Rewards obtained: [236.1636800106155], Lows: [11], Highs: [18], Total time: 5806.053122
[32m[0906 15-28-05 @MBExp.py:144][0m ####################################################################
[32m[0906 15-28-05 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11096, current rewards: -4.58078, mean: -0.45808
[32m[0906 15-28-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11132, current rewards: 0.51424, mean: 0.00857
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11119, current rewards: 5.99521, mean: 0.05450
[32m[0906 15-28-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11156, current rewards: 11.26672, mean: 0.07042
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11149, current rewards: 16.53930, mean: 0.07876
[32m[0906 15-28-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11156, current rewards: 21.81391, mean: 0.08390
[32m[0906 15-28-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11172, current rewards: 27.08606, mean: 0.08737
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11173, current rewards: 32.36154, mean: 0.08989
[32m[0906 15-28-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11176, current rewards: 37.64063, mean: 0.09181
[32m[0906 15-28-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11186, current rewards: 32.45329, mean: 0.07055
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11186, current rewards: 38.31620, mean: 0.07513
[32m[0906 15-29-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11186, current rewards: 43.63059, mean: 0.07791
[32m[0906 15-29-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11192, current rewards: 48.94546, mean: 0.08024
[32m[0906 15-29-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11192, current rewards: 54.25581, mean: 0.08221
[32m[0906 15-29-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11196, current rewards: 59.56814, mean: 0.08390
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11177, current rewards: 64.88105, mean: 0.08537
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11154, current rewards: 70.19348, mean: 0.08666
[32m[0906 15-29-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11140, current rewards: 75.50620, mean: 0.08780
[32m[0906 15-29-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11118, current rewards: 65.52865, mean: 0.07201
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11099, current rewards: 46.69825, mean: 0.04864
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11085, current rewards: 52.15383, mean: 0.05164
[32m[0906 15-30-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11068, current rewards: 57.60459, mean: 0.05434
[32m[0906 15-30-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11054, current rewards: 63.05824, mean: 0.05681
[32m[0906 15-30-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11043, current rewards: 68.51098, mean: 0.05906
[32m[0906 15-30-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11032, current rewards: 73.96135, mean: 0.06113
[32m[0906 15-30-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11034, current rewards: 79.41696, mean: 0.06303
[32m[0906 15-30-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11041, current rewards: 84.87197, mean: 0.06479
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11044, current rewards: 85.59095, mean: 0.06293
[32m[0906 15-30-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11050, current rewards: 90.94382, mean: 0.06450
[32m[0906 15-30-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11047, current rewards: 96.29880, mean: 0.06596
[32m[0906 15-30-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11038, current rewards: 101.65569, mean: 0.06732
[32m[0906 15-30-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11029, current rewards: 107.01209, mean: 0.06860
[32m[0906 15-31-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11024, current rewards: 112.36851, mean: 0.06979
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11016, current rewards: 107.30071, mean: 0.06464
[32m[0906 15-31-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11009, current rewards: 112.76086, mean: 0.06594
[32m[0906 15-31-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11002, current rewards: 118.06039, mean: 0.06708
[32m[0906 15-31-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10986, current rewards: 123.46285, mean: 0.06821
[32m[0906 15-31-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10972, current rewards: 128.87431, mean: 0.06929
[32m[0906 15-31-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10960, current rewards: 134.28370, mean: 0.07031
[32m[0906 15-31-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10952, current rewards: 139.69413, mean: 0.07127
[32m[0906 15-31-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10940, current rewards: 145.10295, mean: 0.07219
[32m[0906 15-31-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10930, current rewards: 144.87112, mean: 0.07033
[32m[0906 15-31-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10918, current rewards: 150.14422, mean: 0.07116
[32m[0906 15-32-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10906, current rewards: 155.28438, mean: 0.07189
[32m[0906 15-32-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10897, current rewards: 160.51678, mean: 0.07263
[32m[0906 15-32-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10888, current rewards: 165.77229, mean: 0.07335
[32m[0906 15-32-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10887, current rewards: 171.02413, mean: 0.07404
[32m[0906 15-32-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10886, current rewards: 176.28642, mean: 0.07470
[32m[0906 15-32-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10884, current rewards: 181.54528, mean: 0.07533
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10883, current rewards: 174.24842, mean: 0.07083
[32m[0906 15-32-38 @Agent.py:117][0m Average action selection time: 0.1089
[32m[0906 15-32-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-32-38 @MBExp.py:227][0m Rewards obtained: [178.57897529561149], Lows: [22], Highs: [40], Total time: 6078.98938
[32m[0906 15-33-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-33-32 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 15-33-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11052, current rewards: -5.23752, mean: -0.52375
[32m[0906 15-33-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11203, current rewards: 0.82361, mean: 0.01373
[32m[0906 15-33-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11199, current rewards: 6.08405, mean: 0.05531
[32m[0906 15-33-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11186, current rewards: 11.52026, mean: 0.07200
[32m[0906 15-33-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11197, current rewards: 16.95691, mean: 0.08075
[32m[0906 15-34-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11190, current rewards: 22.39478, mean: 0.08613
[32m[0906 15-34-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11188, current rewards: 27.83111, mean: 0.08978
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11193, current rewards: 27.97754, mean: 0.07772
[32m[0906 15-34-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11188, current rewards: 33.44160, mean: 0.08156
[32m[0906 15-34-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11185, current rewards: 38.90620, mean: 0.08458
[32m[0906 15-34-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11190, current rewards: 44.22784, mean: 0.08672
[32m[0906 15-34-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11186, current rewards: 49.63235, mean: 0.08863
[32m[0906 15-34-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11181, current rewards: 55.04102, mean: 0.09023
[32m[0906 15-34-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11181, current rewards: 60.44925, mean: 0.09159
[32m[0906 15-34-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11180, current rewards: 65.85344, mean: 0.09275
[32m[0906 15-34-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11156, current rewards: 60.45958, mean: 0.07955
[32m[0906 15-35-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11137, current rewards: 65.75187, mean: 0.08118
[32m[0906 15-35-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11116, current rewards: 71.03806, mean: 0.08260
[32m[0906 15-35-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11099, current rewards: 76.48099, mean: 0.08405
[32m[0906 15-35-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11085, current rewards: 81.86302, mean: 0.08527
[32m[0906 15-35-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11067, current rewards: 87.24311, mean: 0.08638
[32m[0906 15-35-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11055, current rewards: 92.61902, mean: 0.08738
[32m[0906 15-35-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11046, current rewards: 97.99337, mean: 0.08828
[32m[0906 15-35-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11033, current rewards: 103.36936, mean: 0.08911
[32m[0906 15-35-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11021, current rewards: 108.74585, mean: 0.08987
[32m[0906 15-35-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11019, current rewards: 114.12213, mean: 0.09057
[32m[0906 15-35-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11025, current rewards: 119.46675, mean: 0.09120
[32m[0906 15-36-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11034, current rewards: 124.82182, mean: 0.09178
[32m[0906 15-36-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11037, current rewards: 124.74395, mean: 0.08847
[32m[0906 15-36-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11033, current rewards: 129.94795, mean: 0.08901
[32m[0906 15-36-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11027, current rewards: 135.14677, mean: 0.08950
[32m[0906 15-36-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11021, current rewards: 140.34454, mean: 0.08996
[32m[0906 15-36-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11015, current rewards: 145.54716, mean: 0.09040
[32m[0906 15-36-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11012, current rewards: 150.74410, mean: 0.09081
[32m[0906 15-36-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11008, current rewards: 156.09736, mean: 0.09129
[32m[0906 15-36-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10999, current rewards: 161.96675, mean: 0.09203
[32m[0906 15-36-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10985, current rewards: 154.75941, mean: 0.08550
[32m[0906 15-36-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10969, current rewards: 165.76346, mean: 0.08912
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10955, current rewards: 174.81689, mean: 0.09153
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10946, current rewards: 183.87033, mean: 0.09381
[32m[0906 15-37-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10934, current rewards: 192.92376, mean: 0.09598
[32m[0906 15-37-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10922, current rewards: 201.97719, mean: 0.09805
[32m[0906 15-37-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10912, current rewards: 195.67673, mean: 0.09274
[32m[0906 15-37-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10901, current rewards: 145.67673, mean: 0.06744
[32m[0906 15-37-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10893, current rewards: 95.67673, mean: 0.04329
[32m[0906 15-37-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10887, current rewards: 45.67673, mean: 0.02021
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10881, current rewards: -4.32327, mean: -0.00187
[32m[0906 15-37-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10879, current rewards: -54.32327, mean: -0.02302
[32m[0906 15-37-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10879, current rewards: -104.32327, mean: -0.04329
[32m[0906 15-38-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10876, current rewards: -154.32327, mean: -0.06273
[32m[0906 15-38-05 @Agent.py:117][0m Average action selection time: 0.1088
[32m[0906 15-38-05 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-38-05 @MBExp.py:227][0m Rewards obtained: [-194.32326786256655], Lows: [11], Highs: [419], Total time: 6351.647531
[32m[0906 15-39-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-39-01 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 15-39-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11177, current rewards: -4.45774, mean: -0.44577
[32m[0906 15-39-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11123, current rewards: 2.01205, mean: 0.03353
[32m[0906 15-39-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11135, current rewards: 8.48146, mean: 0.07710
[32m[0906 15-39-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11117, current rewards: 14.44719, mean: 0.09029
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11130, current rewards: 20.40962, mean: 0.09719
[32m[0906 15-39-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11139, current rewards: 26.37445, mean: 0.10144
[32m[0906 15-39-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11135, current rewards: 32.33697, mean: 0.10431
[32m[0906 15-39-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11129, current rewards: 27.86456, mean: 0.07740
[32m[0906 15-39-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11133, current rewards: 33.43186, mean: 0.08154
[32m[0906 15-39-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11132, current rewards: 38.99245, mean: 0.08477
[32m[0906 15-39-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11134, current rewards: 44.06837, mean: 0.08641
[32m[0906 15-40-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11135, current rewards: 49.69241, mean: 0.08874
[32m[0906 15-40-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11133, current rewards: 55.31883, mean: 0.09069
[32m[0906 15-40-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11127, current rewards: 60.94284, mean: 0.09234
[32m[0906 15-40-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11131, current rewards: 55.87081, mean: 0.07869
[32m[0906 15-40-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11110, current rewards: 61.81060, mean: 0.08133
[32m[0906 15-40-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11085, current rewards: 67.77221, mean: 0.08367
[32m[0906 15-40-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11066, current rewards: 73.73264, mean: 0.08574
[32m[0906 15-40-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11047, current rewards: 79.69458, mean: 0.08758
[32m[0906 15-40-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11028, current rewards: 85.58449, mean: 0.08915
[32m[0906 15-40-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11017, current rewards: 91.57734, mean: 0.09067
[32m[0906 15-40-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11003, current rewards: 97.56972, mean: 0.09205
[32m[0906 15-41-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10992, current rewards: 103.56762, mean: 0.09330
[32m[0906 15-41-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10984, current rewards: 109.55806, mean: 0.09445
[32m[0906 15-41-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10974, current rewards: 115.55408, mean: 0.09550
[32m[0906 15-41-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10964, current rewards: 121.54705, mean: 0.09647
[32m[0906 15-41-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10972, current rewards: 127.54482, mean: 0.09736
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10977, current rewards: 133.91228, mean: 0.09846
[32m[0906 15-41-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10984, current rewards: 139.83632, mean: 0.09917
[32m[0906 15-41-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10979, current rewards: 145.76284, mean: 0.09984
[32m[0906 15-41-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10971, current rewards: 151.68976, mean: 0.10046
[32m[0906 15-41-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10964, current rewards: 152.68457, mean: 0.09787
[32m[0906 15-41-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10958, current rewards: 159.24177, mean: 0.09891
[32m[0906 15-42-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10952, current rewards: 165.80420, mean: 0.09988
[32m[0906 15-42-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10948, current rewards: 172.36309, mean: 0.10080
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10943, current rewards: 179.22001, mean: 0.10183
[32m[0906 15-42-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10929, current rewards: 185.67823, mean: 0.10258
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10915, current rewards: 178.92841, mean: 0.09620
[32m[0906 15-42-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10902, current rewards: 184.58846, mean: 0.09664
[32m[0906 15-42-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10888, current rewards: 190.24701, mean: 0.09706
[32m[0906 15-42-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10878, current rewards: 195.90545, mean: 0.09747
[32m[0906 15-42-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10867, current rewards: 201.56708, mean: 0.09785
[32m[0906 15-42-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10856, current rewards: 207.22830, mean: 0.09821
[32m[0906 15-42-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10847, current rewards: 207.28835, mean: 0.09597
[32m[0906 15-43-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10839, current rewards: 212.96208, mean: 0.09636
[32m[0906 15-43-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10831, current rewards: 218.63866, mean: 0.09674
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10824, current rewards: 224.31171, mean: 0.09710
[32m[0906 15-43-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10825, current rewards: 229.98630, mean: 0.09745
[32m[0906 15-43-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10824, current rewards: 235.66057, mean: 0.09778
[32m[0906 15-43-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10826, current rewards: 241.33041, mean: 0.09810
[32m[0906 15-43-32 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 15-43-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-43-32 @MBExp.py:227][0m Rewards obtained: [245.86992298097763], Lows: [16], Highs: [16], Total time: 6623.006923
[32m[0906 15-44-31 @MBExp.py:144][0m ####################################################################
[32m[0906 15-44-31 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 15-44-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11346, current rewards: -5.67690, mean: -0.56769
[32m[0906 15-44-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11175, current rewards: -0.92877, mean: -0.01548
[32m[0906 15-44-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11146, current rewards: 4.21462, mean: 0.03831
[32m[0906 15-44-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11165, current rewards: 9.36291, mean: 0.05852
[32m[0906 15-44-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11156, current rewards: 14.51487, mean: 0.06912
[32m[0906 15-45-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11154, current rewards: 19.65974, mean: 0.07561
[32m[0906 15-45-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11157, current rewards: 24.80027, mean: 0.08000
[32m[0906 15-45-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11155, current rewards: 29.95729, mean: 0.08321
[32m[0906 15-45-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11147, current rewards: 35.10804, mean: 0.08563
[32m[0906 15-45-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11151, current rewards: 40.23879, mean: 0.08748
[32m[0906 15-45-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11145, current rewards: 34.79861, mean: 0.06823
[32m[0906 15-45-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11136, current rewards: 40.06360, mean: 0.07154
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11138, current rewards: 45.32867, mean: 0.07431
[32m[0906 15-45-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11139, current rewards: 50.59293, mean: 0.07666
[32m[0906 15-45-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11142, current rewards: 55.85676, mean: 0.07867
[32m[0906 15-45-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11119, current rewards: 61.11376, mean: 0.08041
[32m[0906 15-46-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11095, current rewards: 66.36326, mean: 0.08193
[32m[0906 15-46-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11077, current rewards: 71.56975, mean: 0.08322
[32m[0906 15-46-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11057, current rewards: 76.63156, mean: 0.08421
[32m[0906 15-46-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11043, current rewards: 81.86291, mean: 0.08527
[32m[0906 15-46-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11033, current rewards: 87.08919, mean: 0.08623
[32m[0906 15-46-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11021, current rewards: 92.32362, mean: 0.08710
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11010, current rewards: 97.55458, mean: 0.08789
[32m[0906 15-46-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11001, current rewards: 102.78123, mean: 0.08860
[32m[0906 15-46-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10990, current rewards: 108.01951, mean: 0.08927
[32m[0906 15-46-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10980, current rewards: 113.25164, mean: 0.08988
[32m[0906 15-46-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10984, current rewards: 118.47643, mean: 0.09044
[32m[0906 15-47-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10989, current rewards: 123.71252, mean: 0.09097
[32m[0906 15-47-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10994, current rewards: 118.30140, mean: 0.08390
[32m[0906 15-47-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10991, current rewards: 123.66150, mean: 0.08470
[32m[0906 15-47-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10983, current rewards: 129.02332, mean: 0.08545
[32m[0906 15-47-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10976, current rewards: 134.38568, mean: 0.08614
[32m[0906 15-47-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10974, current rewards: 139.74659, mean: 0.08680
[32m[0906 15-47-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10970, current rewards: 145.10565, mean: 0.08741
[32m[0906 15-47-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10963, current rewards: 151.17794, mean: 0.08841
[32m[0906 15-47-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10960, current rewards: 156.59410, mean: 0.08897
[32m[0906 15-47-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10948, current rewards: 162.01179, mean: 0.08951
[32m[0906 15-47-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10935, current rewards: 167.42988, mean: 0.09002
[32m[0906 15-48-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10925, current rewards: 167.46322, mean: 0.08768
[32m[0906 15-48-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10913, current rewards: 173.00318, mean: 0.08827
[32m[0906 15-48-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10896, current rewards: 178.54312, mean: 0.08883
[32m[0906 15-48-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10886, current rewards: 184.08645, mean: 0.08936
[32m[0906 15-48-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10874, current rewards: 189.31852, mean: 0.08972
[32m[0906 15-48-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10864, current rewards: 189.00008, mean: 0.08750
[32m[0906 15-48-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10856, current rewards: 193.96981, mean: 0.08777
[32m[0906 15-48-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10847, current rewards: 198.93740, mean: 0.08803
[32m[0906 15-48-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10838, current rewards: 203.90946, mean: 0.08827
[32m[0906 15-48-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10834, current rewards: 208.87668, mean: 0.08851
[32m[0906 15-48-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10832, current rewards: 213.84128, mean: 0.08873
[32m[0906 15-48-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10831, current rewards: 218.80911, mean: 0.08895
[32m[0906 15-49-02 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 15-49-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-49-02 @MBExp.py:227][0m Rewards obtained: [212.23518070151275], Lows: [15], Highs: [16], Total time: 6894.493737
[32m[0906 15-50-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-50-03 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 15-50-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11275, current rewards: -4.60486, mean: -0.46049
[32m[0906 15-50-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11239, current rewards: 0.79007, mean: 0.01317
[32m[0906 15-50-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11192, current rewards: 6.17110, mean: 0.05610
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11199, current rewards: 11.55618, mean: 0.07223
[32m[0906 15-50-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11181, current rewards: 16.94204, mean: 0.08068
[32m[0906 15-50-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11172, current rewards: 22.32555, mean: 0.08587
[32m[0906 15-50-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11189, current rewards: 17.36687, mean: 0.05602
[32m[0906 15-50-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11183, current rewards: 23.28870, mean: 0.06469
[32m[0906 15-50-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11183, current rewards: 29.10710, mean: 0.07099
[32m[0906 15-50-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11188, current rewards: 34.36330, mean: 0.07470
[32m[0906 15-51-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11192, current rewards: 40.12589, mean: 0.07868
[32m[0906 15-51-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11193, current rewards: 45.88519, mean: 0.08194
[32m[0906 15-51-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11196, current rewards: 51.64890, mean: 0.08467
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11194, current rewards: 57.40888, mean: 0.08698
[32m[0906 15-51-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11195, current rewards: 63.17355, mean: 0.08898
[32m[0906 15-51-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11174, current rewards: 68.93723, mean: 0.09071
[32m[0906 15-51-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11151, current rewards: 74.70440, mean: 0.09223
[32m[0906 15-51-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11131, current rewards: 82.12610, mean: 0.09550
[32m[0906 15-51-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11113, current rewards: 88.17160, mean: 0.09689
[32m[0906 15-51-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11095, current rewards: 72.33838, mean: 0.07535
[32m[0906 15-51-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11082, current rewards: 77.48881, mean: 0.07672
[32m[0906 15-52-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11068, current rewards: 82.63742, mean: 0.07796
[32m[0906 15-52-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11056, current rewards: 87.78111, mean: 0.07908
[32m[0906 15-52-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11045, current rewards: 92.93303, mean: 0.08011
[32m[0906 15-52-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11034, current rewards: 98.03398, mean: 0.08102
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11023, current rewards: 102.99862, mean: 0.08174
[32m[0906 15-52-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11019, current rewards: 107.76900, mean: 0.08227
[32m[0906 15-52-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11025, current rewards: 112.92100, mean: 0.08303
[32m[0906 15-52-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11031, current rewards: 118.07986, mean: 0.08374
[32m[0906 15-52-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11027, current rewards: 123.23407, mean: 0.08441
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11019, current rewards: 128.39358, mean: 0.08503
[32m[0906 15-52-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11013, current rewards: 133.54298, mean: 0.08560
[32m[0906 15-53-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11008, current rewards: 138.69811, mean: 0.08615
[32m[0906 15-53-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11001, current rewards: 143.85648, mean: 0.08666
[32m[0906 15-53-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10995, current rewards: 149.42249, mean: 0.08738
[32m[0906 15-53-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10990, current rewards: 154.61926, mean: 0.08785
[32m[0906 15-53-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10980, current rewards: 149.89025, mean: 0.08281
[32m[0906 15-53-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10965, current rewards: 155.32520, mean: 0.08351
[32m[0906 15-53-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10952, current rewards: 160.76033, mean: 0.08417
[32m[0906 15-53-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10940, current rewards: 166.19604, mean: 0.08479
[32m[0906 15-53-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10919, current rewards: 171.63061, mean: 0.08539
[32m[0906 15-53-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10909, current rewards: 177.06382, mean: 0.08595
[32m[0906 15-53-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10898, current rewards: 182.09842, mean: 0.08630
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10889, current rewards: 187.28415, mean: 0.08671
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10880, current rewards: 192.50501, mean: 0.08711
[32m[0906 15-54-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10871, current rewards: 197.72549, mean: 0.08749
[32m[0906 15-54-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10862, current rewards: 202.94298, mean: 0.08785
[32m[0906 15-54-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10855, current rewards: 202.60938, mean: 0.08585
[32m[0906 15-54-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10854, current rewards: 207.87887, mean: 0.08626
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10853, current rewards: 213.15369, mean: 0.08665
[32m[0906 15-54-35 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 15-54-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-54-35 @MBExp.py:227][0m Rewards obtained: [217.37578849911804], Lows: [10], Highs: [29], Total time: 7166.521425
[32m[0906 15-55-38 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-38 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 15-55-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11166, current rewards: -4.48442, mean: -0.44844
[32m[0906 15-55-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11182, current rewards: 1.28390, mean: 0.02140
[32m[0906 15-55-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11174, current rewards: 7.21966, mean: 0.06563
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11204, current rewards: 13.15282, mean: 0.08221
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11193, current rewards: 19.08159, mean: 0.09086
[32m[0906 15-56-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11186, current rewards: 25.00979, mean: 0.09619
[32m[0906 15-56-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11193, current rewards: 30.93908, mean: 0.09980
[32m[0906 15-56-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11187, current rewards: 36.87184, mean: 0.10242
[32m[0906 15-56-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11186, current rewards: 36.99976, mean: 0.09024
[32m[0906 15-56-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11195, current rewards: 42.22960, mean: 0.09180
[32m[0906 15-56-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11188, current rewards: 47.69576, mean: 0.09352
[32m[0906 15-56-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11184, current rewards: 53.15425, mean: 0.09492
[32m[0906 15-56-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11183, current rewards: 58.62312, mean: 0.09610
[32m[0906 15-56-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11178, current rewards: 64.08505, mean: 0.09710
[32m[0906 15-56-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11176, current rewards: 69.54481, mean: 0.09795
[32m[0906 15-57-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11151, current rewards: 75.00294, mean: 0.09869
[32m[0906 15-57-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11129, current rewards: 80.46177, mean: 0.09934
[32m[0906 15-57-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11112, current rewards: 86.21311, mean: 0.10025
[32m[0906 15-57-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11095, current rewards: 91.78504, mean: 0.10086
[32m[0906 15-57-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11079, current rewards: 97.36009, mean: 0.10142
[32m[0906 15-57-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11071, current rewards: 102.93767, mean: 0.10192
[32m[0906 15-57-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11064, current rewards: 95.84833, mean: 0.09042
[32m[0906 15-57-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11047, current rewards: 101.31047, mean: 0.09127
[32m[0906 15-57-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11034, current rewards: 106.76802, mean: 0.09204
[32m[0906 15-57-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11020, current rewards: 112.23239, mean: 0.09275
[32m[0906 15-57-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11009, current rewards: 117.67241, mean: 0.09339
[32m[0906 15-58-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11000, current rewards: 123.05332, mean: 0.09393
[32m[0906 15-58-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11002, current rewards: 128.62550, mean: 0.09458
[32m[0906 15-58-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11005, current rewards: 134.19804, mean: 0.09518
[32m[0906 15-58-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11001, current rewards: 139.76887, mean: 0.09573
[32m[0906 15-58-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10991, current rewards: 145.34234, mean: 0.09625
[32m[0906 15-58-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10983, current rewards: 150.91544, mean: 0.09674
[32m[0906 15-58-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10976, current rewards: 156.48712, mean: 0.09720
[32m[0906 15-58-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10968, current rewards: 162.06092, mean: 0.09763
[32m[0906 15-58-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10962, current rewards: 159.30460, mean: 0.09316
[32m[0906 15-58-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10956, current rewards: 109.30460, mean: 0.06210
[32m[0906 15-58-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10943, current rewards: 59.30460, mean: 0.03276
[32m[0906 15-59-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10927, current rewards: 9.30460, mean: 0.00500
[32m[0906 15-59-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10913, current rewards: -40.69540, mean: -0.02131
[32m[0906 15-59-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10900, current rewards: -90.69540, mean: -0.04627
[32m[0906 15-59-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10880, current rewards: -140.69540, mean: -0.07000
[32m[0906 15-59-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10867, current rewards: -190.69540, mean: -0.09257
[32m[0906 15-59-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10856, current rewards: -240.69540, mean: -0.11407
[32m[0906 15-59-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10845, current rewards: -290.69540, mean: -0.13458
[32m[0906 15-59-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10836, current rewards: -340.69540, mean: -0.15416
[32m[0906 15-59-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10826, current rewards: -390.69540, mean: -0.17287
[32m[0906 15-59-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10817, current rewards: -440.69540, mean: -0.19078
[32m[0906 15-59-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10809, current rewards: -490.69540, mean: -0.20792
[32m[0906 15-59-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10802, current rewards: -540.69540, mean: -0.22435
[32m[0906 16-00-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10800, current rewards: -590.69540, mean: -0.24012
[32m[0906 16-00-09 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 16-00-09 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-00-09 @MBExp.py:227][0m Rewards obtained: [-630.6954010850905], Lows: [6], Highs: [809], Total time: 7437.244143
[32m[0906 16-01-14 @MBExp.py:144][0m ####################################################################
[32m[0906 16-01-14 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 16-01-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11144, current rewards: -5.16829, mean: -0.51683
[32m[0906 16-01-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11095, current rewards: 0.45715, mean: 0.00762
[32m[0906 16-01-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11096, current rewards: 5.69526, mean: 0.05178
[32m[0906 16-01-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11113, current rewards: 10.93582, mean: 0.06835
[32m[0906 16-01-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11107, current rewards: 16.17306, mean: 0.07701
[32m[0906 16-01-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11102, current rewards: 21.40898, mean: 0.08234
[32m[0906 16-01-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11106, current rewards: 26.64476, mean: 0.08595
[32m[0906 16-01-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11104, current rewards: 20.32329, mean: 0.05645
[32m[0906 16-01-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11104, current rewards: 26.09481, mean: 0.06365
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11100, current rewards: 32.31898, mean: 0.07026
[32m[0906 16-02-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11098, current rewards: 39.41553, mean: 0.07729
[32m[0906 16-02-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11105, current rewards: 33.95084, mean: 0.06063
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11106, current rewards: -16.04916, mean: -0.02631
[32m[0906 16-02-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11102, current rewards: -66.04916, mean: -0.10007
[32m[0906 16-02-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11099, current rewards: -116.04916, mean: -0.16345
[32m[0906 16-02-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11072, current rewards: -166.04916, mean: -0.21849
[32m[0906 16-02-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11050, current rewards: -216.04916, mean: -0.26673
[32m[0906 16-02-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11035, current rewards: -266.04916, mean: -0.30936
[32m[0906 16-02-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11018, current rewards: -316.04916, mean: -0.34731
[32m[0906 16-03-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11004, current rewards: -366.04916, mean: -0.38130
[32m[0906 16-03-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10994, current rewards: -416.04916, mean: -0.41193
[32m[0906 16-03-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10980, current rewards: -466.04916, mean: -0.43967
[32m[0906 16-03-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10973, current rewards: -516.04916, mean: -0.46491
[32m[0906 16-03-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10966, current rewards: -566.04916, mean: -0.48797
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10956, current rewards: -616.04916, mean: -0.50913
[32m[0906 16-03-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10947, current rewards: -666.04916, mean: -0.52861
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10942, current rewards: -716.04916, mean: -0.54660
[32m[0906 16-03-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10947, current rewards: -766.04916, mean: -0.56327
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10952, current rewards: -816.04916, mean: -0.57876
[32m[0906 16-03-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10952, current rewards: -866.04916, mean: -0.59318
[32m[0906 16-03-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10946, current rewards: -916.04916, mean: -0.60666
[32m[0906 16-04-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10940, current rewards: -966.04916, mean: -0.61926
[32m[0906 16-04-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10935, current rewards: -1016.04916, mean: -0.63109
[32m[0906 16-04-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10929, current rewards: -1066.04916, mean: -0.64220
[32m[0906 16-04-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10923, current rewards: -1116.04916, mean: -0.65266
[32m[0906 16-04-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10919, current rewards: -1166.04916, mean: -0.66253
[32m[0906 16-04-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10911, current rewards: -1216.04916, mean: -0.67185
[32m[0906 16-04-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10896, current rewards: -1266.04916, mean: -0.68067
[32m[0906 16-04-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10885, current rewards: -1316.04916, mean: -0.68903
[32m[0906 16-04-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10872, current rewards: -1366.04916, mean: -0.69696
[32m[0906 16-04-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10854, current rewards: -1416.04916, mean: -0.70450
[32m[0906 16-04-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10838, current rewards: -1466.04916, mean: -0.71167
[32m[0906 16-05-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10828, current rewards: -1516.04916, mean: -0.71851
[32m[0906 16-05-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10819, current rewards: -1566.04916, mean: -0.72502
[32m[0906 16-05-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10811, current rewards: -1616.04916, mean: -0.73124
[32m[0906 16-05-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10802, current rewards: -1666.04916, mean: -0.73719
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10793, current rewards: -1716.04916, mean: -0.74288
[32m[0906 16-05-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10786, current rewards: -1766.04916, mean: -0.74833
[32m[0906 16-05-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10779, current rewards: -1816.04916, mean: -0.75355
[32m[0906 16-05-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10776, current rewards: -1866.04916, mean: -0.75856
[32m[0906 16-05-44 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 16-05-44 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-05-44 @MBExp.py:227][0m Rewards obtained: [-1906.0491622018365], Lows: [6], Highs: [1957], Total time: 7707.354947
[32m[0906 16-06-51 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-51 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 16-06-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11042, current rewards: 1.19336, mean: 0.11934
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11122, current rewards: 7.11124, mean: 0.11852
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11132, current rewards: 13.02912, mean: 0.11845
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11129, current rewards: 18.94699, mean: 0.11842
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11129, current rewards: 24.86486, mean: 0.11840
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11137, current rewards: 30.78274, mean: 0.11840
[32m[0906 16-07-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11123, current rewards: 36.70061, mean: 0.11839
[32m[0906 16-07-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11134, current rewards: 42.61849, mean: 0.11838
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11143, current rewards: 41.80566, mean: 0.10197
[32m[0906 16-07-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11136, current rewards: -8.19434, mean: -0.01781
[32m[0906 16-07-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11135, current rewards: -58.19434, mean: -0.11411
[32m[0906 16-07-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11137, current rewards: -108.19434, mean: -0.19320
[32m[0906 16-07-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11134, current rewards: -124.02723, mean: -0.20332
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11132, current rewards: -118.78022, mean: -0.17997
[32m[0906 16-08-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11119, current rewards: -113.53311, mean: -0.15991
[32m[0906 16-08-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11091, current rewards: -108.29068, mean: -0.14249
[32m[0906 16-08-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11069, current rewards: -108.45874, mean: -0.13390
[32m[0906 16-08-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11045, current rewards: -102.86876, mean: -0.11961
[32m[0906 16-08-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11026, current rewards: -97.44893, mean: -0.10709
[32m[0906 16-08-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11011, current rewards: -92.02942, mean: -0.09586
[32m[0906 16-08-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10996, current rewards: -86.61179, mean: -0.08575
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10983, current rewards: -81.19237, mean: -0.07660
[32m[0906 16-08-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10974, current rewards: -75.77636, mean: -0.06827
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10961, current rewards: -70.36348, mean: -0.06066
[32m[0906 16-09-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10952, current rewards: -64.94633, mean: -0.05367
[32m[0906 16-09-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10945, current rewards: -60.02690, mean: -0.04764
[32m[0906 16-09-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10937, current rewards: -55.01766, mean: -0.04200
[32m[0906 16-09-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10932, current rewards: -49.76380, mean: -0.03659
[32m[0906 16-09-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10940, current rewards: -44.52009, mean: -0.03157
[32m[0906 16-09-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10938, current rewards: -39.26882, mean: -0.02690
[32m[0906 16-09-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10931, current rewards: -34.01077, mean: -0.02252
[32m[0906 16-09-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10925, current rewards: -28.75736, mean: -0.01843
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10918, current rewards: -23.49940, mean: -0.01460
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10911, current rewards: -17.94409, mean: -0.01081
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10907, current rewards: -23.08115, mean: -0.01350
[32m[0906 16-10-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10902, current rewards: -17.53017, mean: -0.00996
[32m[0906 16-10-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10895, current rewards: -11.98326, mean: -0.00662
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10881, current rewards: -6.43588, mean: -0.00346
[32m[0906 16-10-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10869, current rewards: -0.89336, mean: -0.00047
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10857, current rewards: 4.64905, mean: 0.00237
[32m[0906 16-10-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10841, current rewards: 10.19548, mean: 0.00507
[32m[0906 16-10-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10822, current rewards: 15.89476, mean: 0.00772
[32m[0906 16-10-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10807, current rewards: 21.45817, mean: 0.01017
[32m[0906 16-10-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10799, current rewards: 27.01837, mean: 0.01251
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10789, current rewards: 22.01967, mean: 0.00996
[32m[0906 16-10-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10780, current rewards: 27.73838, mean: 0.01227
[32m[0906 16-11-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10772, current rewards: 33.30713, mean: 0.01442
[32m[0906 16-11-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10762, current rewards: 38.87336, mean: 0.01647
[32m[0906 16-11-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10755, current rewards: 44.44089, mean: 0.01844
[32m[0906 16-11-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10748, current rewards: 49.63046, mean: 0.02017
[32m[0906 16-11-21 @Agent.py:117][0m Average action selection time: 0.1075
[32m[0906 16-11-21 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-11-21 @MBExp.py:227][0m Rewards obtained: [53.88623965716268], Lows: [10], Highs: [180], Total time: 7976.752909
[32m[0906 16-12-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-12-30 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 16-12-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11019, current rewards: -5.15622, mean: -0.51562
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11140, current rewards: 0.21049, mean: 0.00351
[32m[0906 16-12-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11138, current rewards: 5.58505, mean: 0.05077
[32m[0906 16-12-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11121, current rewards: 10.96413, mean: 0.06853
[32m[0906 16-12-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 16.34081, mean: 0.07781
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11126, current rewards: 21.71642, mean: 0.08352
[32m[0906 16-13-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11125, current rewards: 27.09375, mean: 0.08740
[32m[0906 16-13-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11124, current rewards: 32.46096, mean: 0.09017
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11123, current rewards: 38.28801, mean: 0.09339
[32m[0906 16-13-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11120, current rewards: 43.67552, mean: 0.09495
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11123, current rewards: 49.06249, mean: 0.09620
[32m[0906 16-13-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11121, current rewards: 54.45165, mean: 0.09724
[32m[0906 16-13-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11125, current rewards: 49.51215, mean: 0.08117
[32m[0906 16-13-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11124, current rewards: 54.94546, mean: 0.08325
[32m[0906 16-13-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11116, current rewards: 60.37946, mean: 0.08504
[32m[0906 16-13-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11095, current rewards: 65.81338, mean: 0.08660
[32m[0906 16-14-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11074, current rewards: 70.79237, mean: 0.08740
[32m[0906 16-14-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11053, current rewards: 76.22864, mean: 0.08864
[32m[0906 16-14-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11041, current rewards: 81.66222, mean: 0.08974
[32m[0906 16-14-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11026, current rewards: 87.10214, mean: 0.09073
[32m[0906 16-14-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11012, current rewards: 92.53995, mean: 0.09162
[32m[0906 16-14-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11000, current rewards: 92.43456, mean: 0.08720
[32m[0906 16-14-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10987, current rewards: 97.74169, mean: 0.08806
[32m[0906 16-14-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10975, current rewards: 102.84724, mean: 0.08866
[32m[0906 16-14-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10968, current rewards: 108.13036, mean: 0.08936
[32m[0906 16-14-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10958, current rewards: 113.39291, mean: 0.08999
[32m[0906 16-14-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10950, current rewards: 118.54608, mean: 0.09049
[32m[0906 16-14-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10945, current rewards: 123.70108, mean: 0.09096
[32m[0906 16-15-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10951, current rewards: 128.85402, mean: 0.09139
[32m[0906 16-15-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10949, current rewards: 123.60577, mean: 0.08466
[32m[0906 16-15-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10944, current rewards: 129.05614, mean: 0.08547
[32m[0906 16-15-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10937, current rewards: 134.50380, mean: 0.08622
[32m[0906 16-15-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10932, current rewards: 139.94956, mean: 0.08693
[32m[0906 16-15-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10928, current rewards: 145.30654, mean: 0.08753
[32m[0906 16-15-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10924, current rewards: 150.76748, mean: 0.08817
[32m[0906 16-15-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10918, current rewards: 156.22674, mean: 0.08877
[32m[0906 16-15-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10916, current rewards: 161.68698, mean: 0.08933
[32m[0906 16-15-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10903, current rewards: 167.14608, mean: 0.08986
[32m[0906 16-15-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10890, current rewards: 172.60648, mean: 0.09037
[32m[0906 16-16-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10879, current rewards: 178.06592, mean: 0.09085
[32m[0906 16-16-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10863, current rewards: 183.52493, mean: 0.09131
[32m[0906 16-16-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10844, current rewards: 189.42984, mean: 0.09196
[32m[0906 16-16-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10830, current rewards: 188.30929, mean: 0.08925
[32m[0906 16-16-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10822, current rewards: 193.56495, mean: 0.08961
[32m[0906 16-16-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10814, current rewards: 198.83427, mean: 0.08997
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10807, current rewards: 204.10919, mean: 0.09031
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10798, current rewards: 209.38214, mean: 0.09064
[32m[0906 16-16-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10791, current rewards: 214.65070, mean: 0.09095
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10785, current rewards: 219.92413, mean: 0.09125
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10779, current rewards: 225.10759, mean: 0.09151
[32m[0906 16-17-00 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 16-17-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-17-00 @MBExp.py:227][0m Rewards obtained: [229.32519076228095], Lows: [10], Highs: [17], Total time: 8246.837234
[32m[0906 16-18-12 @MBExp.py:144][0m ####################################################################
[32m[0906 16-18-12 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 16-18-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11134, current rewards: -4.58092, mean: -0.45809
[32m[0906 16-18-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11106, current rewards: 0.81121, mean: 0.01352
[32m[0906 16-18-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11153, current rewards: 5.96587, mean: 0.05424
[32m[0906 16-18-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11137, current rewards: 11.12149, mean: 0.06951
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11123, current rewards: 16.27467, mean: 0.07750
[32m[0906 16-18-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11127, current rewards: 21.42622, mean: 0.08241
[32m[0906 16-18-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11128, current rewards: 24.37063, mean: 0.07861
[32m[0906 16-18-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11123, current rewards: 26.02523, mean: 0.07229
[32m[0906 16-18-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11133, current rewards: 31.21576, mean: 0.07614
[32m[0906 16-19-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11127, current rewards: 36.65706, mean: 0.07969
[32m[0906 16-19-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11123, current rewards: 42.09848, mean: 0.08255
[32m[0906 16-19-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11125, current rewards: 47.53968, mean: 0.08489
[32m[0906 16-19-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11123, current rewards: 52.98031, mean: 0.08685
[32m[0906 16-19-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11120, current rewards: 58.42180, mean: 0.08852
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11110, current rewards: 63.57965, mean: 0.08955
[32m[0906 16-19-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11085, current rewards: 68.78192, mean: 0.09050
[32m[0906 16-19-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11062, current rewards: 74.21940, mean: 0.09163
[32m[0906 16-19-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11046, current rewards: 79.36972, mean: 0.09229
[32m[0906 16-19-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11030, current rewards: 84.52569, mean: 0.09289
[32m[0906 16-19-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11014, current rewards: 89.67742, mean: 0.09341
[32m[0906 16-20-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11004, current rewards: 89.36245, mean: 0.08848
[32m[0906 16-20-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10992, current rewards: 94.36203, mean: 0.08902
[32m[0906 16-20-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10980, current rewards: 99.36117, mean: 0.08951
[32m[0906 16-20-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10972, current rewards: 104.36035, mean: 0.08997
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10962, current rewards: 109.28471, mean: 0.09032
[32m[0906 16-20-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10955, current rewards: 114.28731, mean: 0.09070
[32m[0906 16-20-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10947, current rewards: 119.28913, mean: 0.09106
[32m[0906 16-20-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10939, current rewards: 124.28933, mean: 0.09139
[32m[0906 16-20-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10943, current rewards: 129.28449, mean: 0.09169
[32m[0906 16-20-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10941, current rewards: 134.28736, mean: 0.09198
[32m[0906 16-20-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10935, current rewards: 139.28613, mean: 0.09224
[32m[0906 16-21-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10929, current rewards: 144.28607, mean: 0.09249
[32m[0906 16-21-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10924, current rewards: 149.64245, mean: 0.09295
[32m[0906 16-21-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10917, current rewards: 156.26472, mean: 0.09414
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10914, current rewards: 160.91663, mean: 0.09410
[32m[0906 16-21-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10909, current rewards: 165.57051, mean: 0.09407
[32m[0906 16-21-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10904, current rewards: 170.22579, mean: 0.09405
[32m[0906 16-21-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10893, current rewards: 174.87788, mean: 0.09402
[32m[0906 16-21-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10880, current rewards: 179.52855, mean: 0.09399
[32m[0906 16-21-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10869, current rewards: 174.33933, mean: 0.08895
[32m[0906 16-21-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10857, current rewards: 180.05341, mean: 0.08958
[32m[0906 16-21-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10838, current rewards: 185.97242, mean: 0.09028
[32m[0906 16-22-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10820, current rewards: 191.89030, mean: 0.09094
[32m[0906 16-22-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10811, current rewards: 197.80817, mean: 0.09158
[32m[0906 16-22-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10804, current rewards: 203.72605, mean: 0.09218
[32m[0906 16-22-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10796, current rewards: 201.81542, mean: 0.08930
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10789, current rewards: 151.81542, mean: 0.06572
[32m[0906 16-22-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10781, current rewards: 101.81542, mean: 0.04314
[32m[0906 16-22-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10773, current rewards: 51.81542, mean: 0.02150
[32m[0906 16-22-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10767, current rewards: 1.81542, mean: 0.00074
[32m[0906 16-22-42 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 16-22-42 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-22-42 @MBExp.py:227][0m Rewards obtained: [-38.18457988621924], Lows: [5], Highs: [262], Total time: 8516.582015
[32m[0906 16-23-56 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-56 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 16-23-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11372, current rewards: 1.25163, mean: 0.12516
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11115, current rewards: 5.79817, mean: 0.09664
[32m[0906 16-24-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11109, current rewards: 11.37032, mean: 0.10337
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11128, current rewards: 16.94043, mean: 0.10588
[32m[0906 16-24-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11118, current rewards: 22.51049, mean: 0.10719
[32m[0906 16-24-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11113, current rewards: 28.07743, mean: 0.10799
[32m[0906 16-24-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11126, current rewards: 33.64870, mean: 0.10854
[32m[0906 16-24-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11125, current rewards: 39.84789, mean: 0.11069
[32m[0906 16-24-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11117, current rewards: 39.36589, mean: 0.09601
[32m[0906 16-24-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11123, current rewards: 45.41839, mean: 0.09874
[32m[0906 16-24-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11123, current rewards: 51.46517, mean: 0.10091
[32m[0906 16-24-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11121, current rewards: 57.51155, mean: 0.10270
[32m[0906 16-25-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11126, current rewards: 63.56716, mean: 0.10421
[32m[0906 16-25-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11124, current rewards: 69.61978, mean: 0.10548
[32m[0906 16-25-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11107, current rewards: 75.67036, mean: 0.10658
[32m[0906 16-25-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11084, current rewards: 81.73038, mean: 0.10754
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11064, current rewards: 76.74895, mean: 0.09475
[32m[0906 16-25-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11044, current rewards: 82.23249, mean: 0.09562
[32m[0906 16-25-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11032, current rewards: 87.71582, mean: 0.09639
[32m[0906 16-25-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11015, current rewards: 93.20107, mean: 0.09708
[32m[0906 16-25-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11000, current rewards: 98.68534, mean: 0.09771
[32m[0906 16-25-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10991, current rewards: 104.16478, mean: 0.09827
[32m[0906 16-25-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10979, current rewards: 109.64919, mean: 0.09878
[32m[0906 16-26-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10966, current rewards: 115.13026, mean: 0.09925
[32m[0906 16-26-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10956, current rewards: 120.40376, mean: 0.09951
[32m[0906 16-26-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10945, current rewards: 125.85142, mean: 0.09988
[32m[0906 16-26-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10939, current rewards: 131.29111, mean: 0.10022
[32m[0906 16-26-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10932, current rewards: 136.73476, mean: 0.10054
[32m[0906 16-26-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10929, current rewards: 142.17292, mean: 0.10083
[32m[0906 16-26-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10928, current rewards: 137.04082, mean: 0.09386
[32m[0906 16-26-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10922, current rewards: 142.63405, mean: 0.09446
[32m[0906 16-26-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10916, current rewards: 148.22516, mean: 0.09502
[32m[0906 16-26-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10911, current rewards: 154.22498, mean: 0.09579
[32m[0906 16-26-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10906, current rewards: 159.83482, mean: 0.09629
[32m[0906 16-27-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10900, current rewards: 165.44387, mean: 0.09675
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10896, current rewards: 171.05853, mean: 0.09719
[32m[0906 16-27-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10891, current rewards: 176.66941, mean: 0.09761
[32m[0906 16-27-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10881, current rewards: 182.27963, mean: 0.09800
[32m[0906 16-27-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10869, current rewards: 187.88439, mean: 0.09837
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10860, current rewards: 193.49196, mean: 0.09872
[32m[0906 16-27-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10849, current rewards: 199.23174, mean: 0.09912
[32m[0906 16-27-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10831, current rewards: 204.84181, mean: 0.09944
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10813, current rewards: 204.92819, mean: 0.09712
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10798, current rewards: 210.43220, mean: 0.09742
[32m[0906 16-27-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10789, current rewards: 215.93527, mean: 0.09771
[32m[0906 16-28-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10781, current rewards: 221.44044, mean: 0.09798
[32m[0906 16-28-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10773, current rewards: 226.94955, mean: 0.09825
[32m[0906 16-28-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10765, current rewards: 232.45268, mean: 0.09850
[32m[0906 16-28-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10759, current rewards: 237.90230, mean: 0.09871
[32m[0906 16-28-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10751, current rewards: 243.39713, mean: 0.09894
[32m[0906 16-28-26 @Agent.py:117][0m Average action selection time: 0.1075
[32m[0906 16-28-26 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-28-26 @MBExp.py:227][0m Rewards obtained: [247.79384851011488], Lows: [10], Highs: [11], Total time: 8785.925728
[32m[0906 16-29-42 @MBExp.py:144][0m ####################################################################
[32m[0906 16-29-42 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 16-29-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11183, current rewards: 1.38714, mean: 0.13871
[32m[0906 16-29-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11200, current rewards: 6.70670, mean: 0.11178
[32m[0906 16-29-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11163, current rewards: 12.01013, mean: 0.10918
[32m[0906 16-30-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11147, current rewards: 17.31245, mean: 0.10820
[32m[0906 16-30-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11135, current rewards: 22.61574, mean: 0.10769
[32m[0906 16-30-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11121, current rewards: 20.48592, mean: 0.07879
[32m[0906 16-30-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11114, current rewards: 25.47435, mean: 0.08218
[32m[0906 16-30-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11117, current rewards: 30.52432, mean: 0.08479
[32m[0906 16-30-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11118, current rewards: 35.57176, mean: 0.08676
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11110, current rewards: 40.61412, mean: 0.08829
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11115, current rewards: 45.66446, mean: 0.08954
[32m[0906 16-30-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11110, current rewards: 50.71089, mean: 0.09056
[32m[0906 16-30-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11107, current rewards: 55.75721, mean: 0.09141
[32m[0906 16-30-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11107, current rewards: 60.79760, mean: 0.09212
[32m[0906 16-31-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11083, current rewards: 65.84712, mean: 0.09274
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11060, current rewards: 60.70292, mean: 0.07987
[32m[0906 16-31-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11038, current rewards: 66.29364, mean: 0.08184
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11018, current rewards: 71.87673, mean: 0.08358
[32m[0906 16-31-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11005, current rewards: 77.45277, mean: 0.08511
[32m[0906 16-31-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10991, current rewards: 83.03636, mean: 0.08650
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10980, current rewards: 88.61341, mean: 0.08774
[32m[0906 16-31-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10971, current rewards: 94.19373, mean: 0.08886
[32m[0906 16-31-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10961, current rewards: 100.02107, mean: 0.09011
[32m[0906 16-31-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10951, current rewards: 95.36440, mean: 0.08221
[32m[0906 16-31-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10946, current rewards: 101.07446, mean: 0.08353
[32m[0906 16-32-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10938, current rewards: 106.74348, mean: 0.08472
[32m[0906 16-32-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10930, current rewards: 112.40745, mean: 0.08581
[32m[0906 16-32-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10924, current rewards: 112.53301, mean: 0.08274
[32m[0906 16-32-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10917, current rewards: 117.94256, mean: 0.08365
[32m[0906 16-32-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10916, current rewards: 123.35186, mean: 0.08449
[32m[0906 16-32-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10913, current rewards: 128.75900, mean: 0.08527
[32m[0906 16-32-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10908, current rewards: 133.54678, mean: 0.08561
[32m[0906 16-32-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10904, current rewards: 138.99465, mean: 0.08633
[32m[0906 16-32-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10900, current rewards: 144.44638, mean: 0.08702
[32m[0906 16-32-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10897, current rewards: 149.89190, mean: 0.08766
[32m[0906 16-32-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10892, current rewards: 155.34710, mean: 0.08827
[32m[0906 16-33-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10888, current rewards: 155.37974, mean: 0.08585
[32m[0906 16-33-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10881, current rewards: 160.66068, mean: 0.08638
[32m[0906 16-33-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10868, current rewards: 165.93732, mean: 0.08688
[32m[0906 16-33-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10859, current rewards: 171.20862, mean: 0.08735
[32m[0906 16-33-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10847, current rewards: 176.48177, mean: 0.08780
[32m[0906 16-33-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10829, current rewards: 181.75602, mean: 0.08823
[32m[0906 16-33-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10814, current rewards: 187.03050, mean: 0.08864
[32m[0906 16-33-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10798, current rewards: 192.31155, mean: 0.08903
[32m[0906 16-33-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10788, current rewards: 197.59102, mean: 0.08941
[32m[0906 16-33-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10781, current rewards: 192.34274, mean: 0.08511
[32m[0906 16-33-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10773, current rewards: 197.79451, mean: 0.08563
[32m[0906 16-33-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10765, current rewards: 203.43014, mean: 0.08620
[32m[0906 16-34-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10760, current rewards: 208.83877, mean: 0.08666
[32m[0906 16-34-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10754, current rewards: 214.24982, mean: 0.08709
[32m[0906 16-34-12 @Agent.py:117][0m Average action selection time: 0.1075
[32m[0906 16-34-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-34-12 @MBExp.py:227][0m Rewards obtained: [218.58440562074932], Lows: [15], Highs: [17], Total time: 9055.355006
[32m[0906 16-35-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-35-30 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 16-35-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11100, current rewards: -5.39748, mean: -0.53975
[32m[0906 16-35-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11213, current rewards: 0.43656, mean: 0.00728
[32m[0906 16-35-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11166, current rewards: 6.01900, mean: 0.05472
[32m[0906 16-35-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11149, current rewards: 11.60156, mean: 0.07251
[32m[0906 16-35-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11159, current rewards: 17.18422, mean: 0.08183
[32m[0906 16-35-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11150, current rewards: 22.76698, mean: 0.08757
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11144, current rewards: 28.34943, mean: 0.09145
[32m[0906 16-36-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11152, current rewards: 27.43148, mean: 0.07620
[32m[0906 16-36-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11152, current rewards: 33.20859, mean: 0.08100
[32m[0906 16-36-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11148, current rewards: 38.98513, mean: 0.08475
[32m[0906 16-36-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11150, current rewards: 44.76395, mean: 0.08777
[32m[0906 16-36-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11148, current rewards: 50.54004, mean: 0.09025
[32m[0906 16-36-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11145, current rewards: 56.31765, mean: 0.09232
[32m[0906 16-36-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11147, current rewards: 62.00878, mean: 0.09395
[32m[0906 16-36-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11120, current rewards: 67.24470, mean: 0.09471
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11096, current rewards: 72.77650, mean: 0.09576
[32m[0906 16-37-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11077, current rewards: 78.31182, mean: 0.09668
[32m[0906 16-37-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11060, current rewards: 83.84763, mean: 0.09750
[32m[0906 16-37-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11045, current rewards: 87.15842, mean: 0.09578
[32m[0906 16-37-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11034, current rewards: 89.19107, mean: 0.09291
[32m[0906 16-37-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11020, current rewards: 94.35373, mean: 0.09342
[32m[0906 16-37-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11009, current rewards: 99.50752, mean: 0.09388
[32m[0906 16-37-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11004, current rewards: 105.09439, mean: 0.09468
[32m[0906 16-37-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10995, current rewards: 110.28613, mean: 0.09507
[32m[0906 16-37-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10984, current rewards: 115.47223, mean: 0.09543
[32m[0906 16-37-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10973, current rewards: 120.66088, mean: 0.09576
[32m[0906 16-37-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10963, current rewards: 125.84762, mean: 0.09607
[32m[0906 16-38-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10955, current rewards: 131.03734, mean: 0.09635
[32m[0906 16-38-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10946, current rewards: 138.67441, mean: 0.09835
[32m[0906 16-38-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10938, current rewards: 144.10213, mean: 0.09870
[32m[0906 16-38-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10933, current rewards: 149.13263, mean: 0.09876
[32m[0906 16-38-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10925, current rewards: 154.42292, mean: 0.09899
[32m[0906 16-38-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10920, current rewards: 159.71849, mean: 0.09920
[32m[0906 16-38-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10920, current rewards: 165.01031, mean: 0.09940
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10918, current rewards: 170.30417, mean: 0.09959
[32m[0906 16-38-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10917, current rewards: 175.59670, mean: 0.09977
[32m[0906 16-38-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10916, current rewards: 180.89175, mean: 0.09994
[32m[0906 16-38-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10913, current rewards: 186.18788, mean: 0.10010
[32m[0906 16-38-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10900, current rewards: 191.50540, mean: 0.10026
[32m[0906 16-39-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10889, current rewards: 197.35852, mean: 0.10069
[32m[0906 16-39-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10876, current rewards: 202.76843, mean: 0.10088
[32m[0906 16-39-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10857, current rewards: 208.17210, mean: 0.10105
[32m[0906 16-39-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10841, current rewards: 203.16303, mean: 0.09629
[32m[0906 16-39-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10824, current rewards: 208.61207, mean: 0.09658
[32m[0906 16-39-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10813, current rewards: 214.06015, mean: 0.09686
[32m[0906 16-39-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10807, current rewards: 219.51520, mean: 0.09713
[32m[0906 16-39-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10800, current rewards: 224.96618, mean: 0.09739
[32m[0906 16-39-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10793, current rewards: 230.06132, mean: 0.09748
[32m[0906 16-39-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10788, current rewards: 235.42400, mean: 0.09769
[32m[0906 16-39-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10782, current rewards: 240.78658, mean: 0.09788
[32m[0906 16-40-00 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 16-40-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-40-01 @MBExp.py:227][0m Rewards obtained: [245.08059315421113], Lows: [8], Highs: [11], Total time: 9325.502714
[32m[0906 16-41-21 @MBExp.py:144][0m ####################################################################
[32m[0906 16-41-21 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11067, current rewards: -5.50970, mean: -0.55097
[32m[0906 16-41-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11188, current rewards: 0.83606, mean: 0.01393
[32m[0906 16-41-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11153, current rewards: 6.78631, mean: 0.06169
[32m[0906 16-41-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11154, current rewards: 12.72885, mean: 0.07956
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11160, current rewards: 18.67602, mean: 0.08893
[32m[0906 16-41-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11155, current rewards: 24.61678, mean: 0.09468
[32m[0906 16-41-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11152, current rewards: 29.96668, mean: 0.09667
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11158, current rewards: 35.73333, mean: 0.09926
[32m[0906 16-42-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11162, current rewards: 41.50023, mean: 0.10122
[32m[0906 16-42-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11163, current rewards: 36.52166, mean: 0.07939
[32m[0906 16-42-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11163, current rewards: 42.08447, mean: 0.08252
[32m[0906 16-42-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11161, current rewards: 47.64136, mean: 0.08507
[32m[0906 16-42-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11163, current rewards: 53.20177, mean: 0.08722
[32m[0906 16-42-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11156, current rewards: 58.75087, mean: 0.08902
[32m[0906 16-42-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11129, current rewards: 64.03408, mean: 0.09019
[32m[0906 16-42-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11108, current rewards: 69.59560, mean: 0.09157
[32m[0906 16-42-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11083, current rewards: 75.14614, mean: 0.09277
[32m[0906 16-42-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11061, current rewards: 80.70291, mean: 0.09384
[32m[0906 16-43-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11045, current rewards: 86.25907, mean: 0.09479
[32m[0906 16-43-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11030, current rewards: 91.81641, mean: 0.09564
[32m[0906 16-43-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11014, current rewards: 97.36786, mean: 0.09640
[32m[0906 16-43-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11006, current rewards: 102.91710, mean: 0.09709
[32m[0906 16-43-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10992, current rewards: 108.90637, mean: 0.09811
[32m[0906 16-43-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10980, current rewards: 114.44140, mean: 0.09866
[32m[0906 16-43-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10971, current rewards: 109.46617, mean: 0.09047
[32m[0906 16-43-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10961, current rewards: 115.06914, mean: 0.09132
[32m[0906 16-43-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10952, current rewards: 120.67943, mean: 0.09212
[32m[0906 16-43-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10946, current rewards: 126.28779, mean: 0.09286
[32m[0906 16-43-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10937, current rewards: 131.89533, mean: 0.09354
[32m[0906 16-44-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10927, current rewards: 137.50199, mean: 0.09418
[32m[0906 16-44-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10923, current rewards: 143.01841, mean: 0.09471
[32m[0906 16-44-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10918, current rewards: 148.50855, mean: 0.09520
[32m[0906 16-44-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10914, current rewards: 154.09518, mean: 0.09571
[32m[0906 16-44-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10910, current rewards: 159.68428, mean: 0.09620
[32m[0906 16-44-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10904, current rewards: 159.79033, mean: 0.09344
[32m[0906 16-44-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10899, current rewards: 165.31728, mean: 0.09393
[32m[0906 16-44-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10896, current rewards: 170.83622, mean: 0.09438
[32m[0906 16-44-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10890, current rewards: 176.35797, mean: 0.09482
[32m[0906 16-44-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10877, current rewards: 181.88082, mean: 0.09523
[32m[0906 16-44-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10865, current rewards: 188.20103, mean: 0.09602
[32m[0906 16-45-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10853, current rewards: 193.71072, mean: 0.09637
[32m[0906 16-45-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10836, current rewards: 199.21843, mean: 0.09671
[32m[0906 16-45-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10820, current rewards: 194.25833, mean: 0.09207
[32m[0906 16-45-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10803, current rewards: 199.82201, mean: 0.09251
[32m[0906 16-45-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10786, current rewards: 205.37714, mean: 0.09293
[32m[0906 16-45-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10779, current rewards: 210.93496, mean: 0.09333
[32m[0906 16-45-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10770, current rewards: 216.48733, mean: 0.09372
[32m[0906 16-45-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10762, current rewards: 222.20128, mean: 0.09415
[32m[0906 16-45-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10756, current rewards: 227.77448, mean: 0.09451
[32m[0906 16-45-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10748, current rewards: 233.34899, mean: 0.09486
[32m[0906 16-45-51 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 16-45-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-45-51 @MBExp.py:227][0m Rewards obtained: [237.8131018901823], Lows: [15], Highs: [11], Total time: 9594.794574
[32m[0906 16-47-14 @MBExp.py:144][0m ####################################################################
[32m[0906 16-47-14 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 16-47-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11236, current rewards: -5.63415, mean: -0.56342
[32m[0906 16-47-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11136, current rewards: -0.34941, mean: -0.00582
[32m[0906 16-47-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11137, current rewards: 4.96841, mean: 0.04517
[32m[0906 16-47-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11181, current rewards: 10.28394, mean: 0.06427
[32m[0906 16-47-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11179, current rewards: 15.60101, mean: 0.07429
[32m[0906 16-47-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11163, current rewards: 16.15854, mean: 0.06215
[32m[0906 16-47-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11164, current rewards: 21.95334, mean: 0.07082
[32m[0906 16-47-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11158, current rewards: 27.72314, mean: 0.07701
[32m[0906 16-48-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11152, current rewards: 33.49797, mean: 0.08170
[32m[0906 16-48-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11149, current rewards: 39.26932, mean: 0.08537
[32m[0906 16-48-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11141, current rewards: 45.04452, mean: 0.08832
[32m[0906 16-48-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11139, current rewards: 50.81652, mean: 0.09074
[32m[0906 16-48-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11140, current rewards: 56.58537, mean: 0.09276
[32m[0906 16-48-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11133, current rewards: 62.36086, mean: 0.09449
[32m[0906 16-48-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11106, current rewards: 58.82644, mean: 0.08285
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11086, current rewards: 63.93357, mean: 0.08412
[32m[0906 16-48-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11063, current rewards: 69.03988, mean: 0.08523
[32m[0906 16-48-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11043, current rewards: 74.14608, mean: 0.08622
[32m[0906 16-48-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11027, current rewards: 79.25403, mean: 0.08709
[32m[0906 16-49-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11008, current rewards: 84.35761, mean: 0.08787
[32m[0906 16-49-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10993, current rewards: 89.46309, mean: 0.08858
[32m[0906 16-49-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10982, current rewards: 94.57195, mean: 0.08922
[32m[0906 16-49-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10971, current rewards: 99.00066, mean: 0.08919
[32m[0906 16-49-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10960, current rewards: 104.63270, mean: 0.09020
[32m[0906 16-49-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10954, current rewards: 99.73646, mean: 0.08243
[32m[0906 16-49-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10945, current rewards: 105.12811, mean: 0.08344
[32m[0906 16-49-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10938, current rewards: 110.51637, mean: 0.08436
[32m[0906 16-49-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10930, current rewards: 115.91141, mean: 0.08523
[32m[0906 16-49-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10922, current rewards: 121.30502, mean: 0.08603
[32m[0906 16-49-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10912, current rewards: 126.69263, mean: 0.08678
[32m[0906 16-49-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10906, current rewards: 132.17181, mean: 0.08753
[32m[0906 16-50-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10899, current rewards: 137.98981, mean: 0.08846
[32m[0906 16-50-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10897, current rewards: 143.25581, mean: 0.08898
[32m[0906 16-50-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10891, current rewards: 148.51495, mean: 0.08947
[32m[0906 16-50-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10887, current rewards: 153.77802, mean: 0.08993
[32m[0906 16-50-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10884, current rewards: 159.04081, mean: 0.09036
[32m[0906 16-50-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10880, current rewards: 164.30407, mean: 0.09078
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10875, current rewards: 169.56963, mean: 0.09117
[32m[0906 16-50-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10866, current rewards: 168.32740, mean: 0.08813
[32m[0906 16-50-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10854, current rewards: 174.27268, mean: 0.08891
[32m[0906 16-50-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10842, current rewards: 179.62741, mean: 0.08937
[32m[0906 16-50-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10829, current rewards: 184.98712, mean: 0.08980
[32m[0906 16-51-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10812, current rewards: 190.35231, mean: 0.09021
[32m[0906 16-51-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10795, current rewards: 195.72034, mean: 0.09061
[32m[0906 16-51-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10779, current rewards: 201.09139, mean: 0.09099
[32m[0906 16-51-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10770, current rewards: 196.07611, mean: 0.08676
[32m[0906 16-51-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10761, current rewards: 201.44697, mean: 0.08721
[32m[0906 16-51-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10753, current rewards: 206.77680, mean: 0.08762
[32m[0906 16-51-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10747, current rewards: 212.14594, mean: 0.08803
[32m[0906 16-51-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10740, current rewards: 217.51769, mean: 0.08842
[32m[0906 16-51-43 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 16-51-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-51-43 @MBExp.py:227][0m Rewards obtained: [221.8124492486789], Lows: [15], Highs: [17], Total time: 9863.898745
[32m[0906 16-53-08 @MBExp.py:144][0m ####################################################################
[32m[0906 16-53-08 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 16-53-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11110, current rewards: -5.69335, mean: -0.56933
[32m[0906 16-53-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11128, current rewards: -0.43353, mean: -0.00723
[32m[0906 16-53-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11132, current rewards: 5.07223, mean: 0.04611
[32m[0906 16-53-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11118, current rewards: 10.58056, mean: 0.06613
[32m[0906 16-53-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11111, current rewards: 16.08900, mean: 0.07661
[32m[0906 16-53-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11118, current rewards: 21.59181, mean: 0.08305
[32m[0906 16-53-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11116, current rewards: 27.98582, mean: 0.09028
[32m[0906 16-53-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11115, current rewards: 33.47713, mean: 0.09299
[32m[0906 16-53-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11122, current rewards: 38.96348, mean: 0.09503
[32m[0906 16-54-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11122, current rewards: 48.13439, mean: 0.10464
[32m[0906 16-54-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11120, current rewards: 53.89291, mean: 0.10567
[32m[0906 16-54-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11124, current rewards: 59.65193, mean: 0.10652
[32m[0906 16-54-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11124, current rewards: 65.40664, mean: 0.10722
[32m[0906 16-54-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11110, current rewards: 71.17059, mean: 0.10783
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11087, current rewards: 76.70414, mean: 0.10803
[32m[0906 16-54-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11066, current rewards: 82.38413, mean: 0.10840
[32m[0906 16-54-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11047, current rewards: 88.06834, mean: 0.10873
[32m[0906 16-54-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11032, current rewards: 93.75262, mean: 0.10901
[32m[0906 16-54-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11017, current rewards: 99.43881, mean: 0.10927
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11004, current rewards: 105.12186, mean: 0.10950
[32m[0906 16-55-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10994, current rewards: 110.80084, mean: 0.10970
[32m[0906 16-55-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10983, current rewards: 106.09266, mean: 0.10009
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10973, current rewards: 111.89193, mean: 0.10080
[32m[0906 16-55-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10967, current rewards: 117.51099, mean: 0.10130
[32m[0906 16-55-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10958, current rewards: 123.12997, mean: 0.10176
[32m[0906 16-55-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10953, current rewards: 128.74327, mean: 0.10218
[32m[0906 16-55-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10947, current rewards: 134.36216, mean: 0.10257
[32m[0906 16-55-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10940, current rewards: 139.97731, mean: 0.10292
[32m[0906 16-55-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10936, current rewards: 135.37011, mean: 0.09601
[32m[0906 16-55-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10923, current rewards: 140.99833, mean: 0.09657
[32m[0906 16-55-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10918, current rewards: 146.74542, mean: 0.09718
[32m[0906 16-55-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10914, current rewards: 152.37437, mean: 0.09768
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10911, current rewards: 158.00500, mean: 0.09814
[32m[0906 16-56-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10905, current rewards: 157.29897, mean: 0.09476
[32m[0906 16-56-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10902, current rewards: 160.59003, mean: 0.09391
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10898, current rewards: 167.86424, mean: 0.09538
[32m[0906 16-56-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10893, current rewards: 175.13845, mean: 0.09676
[32m[0906 16-56-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10892, current rewards: 182.41267, mean: 0.09807
[32m[0906 16-56-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10883, current rewards: 189.50922, mean: 0.09922
[32m[0906 16-56-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10870, current rewards: 157.65133, mean: 0.08043
[32m[0906 16-56-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10861, current rewards: 107.65133, mean: 0.05356
[32m[0906 16-56-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10847, current rewards: 57.65133, mean: 0.02799
[32m[0906 16-56-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10829, current rewards: 7.65133, mean: 0.00363
[32m[0906 16-57-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10815, current rewards: -42.34867, mean: -0.01961
[32m[0906 16-57-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10799, current rewards: -71.30333, mean: -0.03226
[32m[0906 16-57-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10784, current rewards: -65.82310, mean: -0.02913
[32m[0906 16-57-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10778, current rewards: -60.35150, mean: -0.02613
[32m[0906 16-57-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10770, current rewards: -54.01244, mean: -0.02289
[32m[0906 16-57-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10765, current rewards: -48.12168, mean: -0.01997
[32m[0906 16-57-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10761, current rewards: -42.51905, mean: -0.01728
[32m[0906 16-57-38 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 16-57-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-57-38 @MBExp.py:227][0m Rewards obtained: [-38.03135107100305], Lows: [16], Highs: [270], Total time: 10133.546204
[32m[0906 16-59-06 @MBExp.py:144][0m ####################################################################
[32m[0906 16-59-06 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 16-59-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11037, current rewards: -4.28863, mean: -0.42886
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11138, current rewards: 1.29059, mean: 0.02151
[32m[0906 16-59-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11114, current rewards: 6.84216, mean: 0.06220
[32m[0906 16-59-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11108, current rewards: 12.39720, mean: 0.07748
[32m[0906 16-59-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11115, current rewards: 17.95388, mean: 0.08549
[32m[0906 16-59-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11111, current rewards: 23.50407, mean: 0.09040
[32m[0906 16-59-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11106, current rewards: 28.46964, mean: 0.09184
[32m[0906 16-59-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11112, current rewards: 33.93955, mean: 0.09428
[32m[0906 16-59-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11105, current rewards: 33.92569, mean: 0.08275
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11112, current rewards: 39.33547, mean: 0.08551
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11112, current rewards: 44.74556, mean: 0.08774
[32m[0906 17-00-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11111, current rewards: 50.15526, mean: 0.08956
[32m[0906 17-00-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11109, current rewards: 55.56200, mean: 0.09109
[32m[0906 17-00-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11082, current rewards: 60.97595, mean: 0.09239
[32m[0906 17-00-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11056, current rewards: 66.84471, mean: 0.09415
[32m[0906 17-00-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11036, current rewards: 72.33940, mean: 0.09518
[32m[0906 17-00-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11015, current rewards: 77.83110, mean: 0.09609
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10997, current rewards: 83.32105, mean: 0.09688
[32m[0906 17-00-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10985, current rewards: 78.26555, mean: 0.08601
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10971, current rewards: 83.87468, mean: 0.08737
[32m[0906 17-00-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10960, current rewards: 89.48329, mean: 0.08860
[32m[0906 17-01-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10951, current rewards: 95.09297, mean: 0.08971
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10940, current rewards: 100.78744, mean: 0.09080
[32m[0906 17-01-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10929, current rewards: 106.40157, mean: 0.09173
[32m[0906 17-01-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10921, current rewards: 112.02593, mean: 0.09258
[32m[0906 17-01-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10914, current rewards: 117.64784, mean: 0.09337
[32m[0906 17-01-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10908, current rewards: 123.27201, mean: 0.09410
[32m[0906 17-01-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10904, current rewards: 128.89424, mean: 0.09478
[32m[0906 17-01-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10896, current rewards: 128.85496, mean: 0.09139
[32m[0906 17-01-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10878, current rewards: 134.24418, mean: 0.09195
[32m[0906 17-01-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10875, current rewards: 139.54327, mean: 0.09241
[32m[0906 17-01-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10868, current rewards: 144.46462, mean: 0.09261
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10863, current rewards: 149.77300, mean: 0.09303
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10860, current rewards: 155.08073, mean: 0.09342
[32m[0906 17-02-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10856, current rewards: 160.38780, mean: 0.09379
[32m[0906 17-02-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10853, current rewards: 165.69531, mean: 0.09415
[32m[0906 17-02-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10852, current rewards: 171.00529, mean: 0.09448
[32m[0906 17-02-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10848, current rewards: 176.31843, mean: 0.09479
[32m[0906 17-02-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10841, current rewards: 181.61825, mean: 0.09509
[32m[0906 17-02-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10831, current rewards: 187.87064, mean: 0.09585
[32m[0906 17-02-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10820, current rewards: 193.51112, mean: 0.09627
[32m[0906 17-02-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10806, current rewards: 188.62752, mean: 0.09157
[32m[0906 17-02-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10790, current rewards: 194.10603, mean: 0.09199
[32m[0906 17-02-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10773, current rewards: 199.58608, mean: 0.09240
[32m[0906 17-03-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10757, current rewards: 205.06185, mean: 0.09279
[32m[0906 17-03-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10742, current rewards: 210.54890, mean: 0.09316
[32m[0906 17-03-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10735, current rewards: 207.01095, mean: 0.08962
[32m[0906 17-03-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10728, current rewards: 216.06438, mean: 0.09155
[32m[0906 17-03-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10722, current rewards: 225.11782, mean: 0.09341
[32m[0906 17-03-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10715, current rewards: 229.44698, mean: 0.09327
[32m[0906 17-03-34 @Agent.py:117][0m Average action selection time: 0.1071
[32m[0906 17-03-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-03-34 @MBExp.py:227][0m Rewards obtained: [189.4469751958692], Lows: [15], Highs: [59], Total time: 10402.015004
[32m[0906 17-05-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-05-04 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 17-05-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11137, current rewards: -4.66064, mean: -0.46606
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11148, current rewards: 0.34074, mean: 0.00568
[32m[0906 17-05-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11194, current rewards: 5.90430, mean: 0.05368
[32m[0906 17-05-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11174, current rewards: 11.45304, mean: 0.07158
[32m[0906 17-05-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11165, current rewards: 17.02204, mean: 0.08106
[32m[0906 17-05-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11165, current rewards: 22.57822, mean: 0.08684
[32m[0906 17-05-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11164, current rewards: 28.38311, mean: 0.09156
[32m[0906 17-05-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11154, current rewards: 34.68679, mean: 0.09635
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11159, current rewards: 40.34060, mean: 0.09839
[32m[0906 17-05-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11156, current rewards: 47.26404, mean: 0.10275
[32m[0906 17-06-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11146, current rewards: 52.99238, mean: 0.10391
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11146, current rewards: 58.71606, mean: 0.10485
[32m[0906 17-06-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11139, current rewards: 64.43755, mean: 0.10564
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11108, current rewards: 70.15808, mean: 0.10630
[32m[0906 17-06-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11083, current rewards: 75.87608, mean: 0.10687
[32m[0906 17-06-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11061, current rewards: 81.57048, mean: 0.10733
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11043, current rewards: 87.28060, mean: 0.10775
[32m[0906 17-06-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11023, current rewards: 90.87299, mean: 0.10567
[32m[0906 17-06-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11005, current rewards: 88.21871, mean: 0.09694
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10994, current rewards: 93.94203, mean: 0.09786
[32m[0906 17-06-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10981, current rewards: 99.67115, mean: 0.09868
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10969, current rewards: 105.39952, mean: 0.09943
[32m[0906 17-07-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10960, current rewards: 111.12297, mean: 0.10011
[32m[0906 17-07-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10949, current rewards: 117.10180, mean: 0.10095
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10939, current rewards: 116.51552, mean: 0.09629
[32m[0906 17-07-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10933, current rewards: 119.94367, mean: 0.09519
[32m[0906 17-07-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10926, current rewards: 126.87032, mean: 0.09685
[32m[0906 17-07-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10923, current rewards: 133.79698, mean: 0.09838
[32m[0906 17-07-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10918, current rewards: 140.72364, mean: 0.09980
[32m[0906 17-07-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10899, current rewards: 147.65030, mean: 0.10113
[32m[0906 17-07-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10891, current rewards: 154.57696, mean: 0.10237
[32m[0906 17-07-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10887, current rewards: 160.29500, mean: 0.10275
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10884, current rewards: 164.03754, mean: 0.10189
[32m[0906 17-08-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10880, current rewards: 167.78007, mean: 0.10107
[32m[0906 17-08-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10877, current rewards: 139.27709, mean: 0.08145
[32m[0906 17-08-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10873, current rewards: 89.27709, mean: 0.05073
[32m[0906 17-08-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10869, current rewards: 39.27709, mean: 0.02170
[32m[0906 17-08-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10867, current rewards: -10.72291, mean: -0.00577
[32m[0906 17-08-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10861, current rewards: -60.72291, mean: -0.03179
[32m[0906 17-08-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10849, current rewards: -110.72291, mean: -0.05649
[32m[0906 17-08-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10840, current rewards: -160.72291, mean: -0.07996
[32m[0906 17-08-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10829, current rewards: -210.72291, mean: -0.10229
[32m[0906 17-08-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10810, current rewards: -260.72291, mean: -0.12357
[32m[0906 17-08-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10794, current rewards: -310.72291, mean: -0.14385
[32m[0906 17-09-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10778, current rewards: -360.72291, mean: -0.16322
[32m[0906 17-09-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10762, current rewards: -410.72291, mean: -0.18174
[32m[0906 17-09-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10753, current rewards: -460.72291, mean: -0.19945
[32m[0906 17-09-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10746, current rewards: -510.72291, mean: -0.21641
[32m[0906 17-09-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10738, current rewards: -560.72291, mean: -0.23267
[32m[0906 17-09-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10733, current rewards: -610.72291, mean: -0.24826
[32m[0906 17-09-33 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 17-09-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-09-33 @MBExp.py:227][0m Rewards obtained: [-650.7229139055183], Lows: [11], Highs: [825], Total time: 10670.964102
[32m[0906 17-11-05 @MBExp.py:144][0m ####################################################################
[32m[0906 17-11-05 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 17-11-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11049, current rewards: -4.49449, mean: -0.44945
[32m[0906 17-11-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11089, current rewards: 1.77395, mean: 0.02957
[32m[0906 17-11-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11090, current rewards: 7.43486, mean: 0.06759
[32m[0906 17-11-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11120, current rewards: 13.09458, mean: 0.08184
[32m[0906 17-11-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11116, current rewards: 18.75709, mean: 0.08932
[32m[0906 17-11-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11115, current rewards: 24.42068, mean: 0.09393
[32m[0906 17-11-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11129, current rewards: 30.08035, mean: 0.09703
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11128, current rewards: 35.74690, mean: 0.09930
[32m[0906 17-11-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11124, current rewards: 41.41286, mean: 0.10101
[32m[0906 17-11-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11126, current rewards: 47.07626, mean: 0.10234
[32m[0906 17-12-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11124, current rewards: 47.20400, mean: 0.09256
[32m[0906 17-12-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11130, current rewards: 52.74559, mean: 0.09419
[32m[0906 17-12-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11118, current rewards: 58.28527, mean: 0.09555
[32m[0906 17-12-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11089, current rewards: 63.81871, mean: 0.09670
[32m[0906 17-12-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11070, current rewards: 57.33372, mean: 0.08075
[32m[0906 17-12-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11050, current rewards: 63.25160, mean: 0.08323
[32m[0906 17-12-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11029, current rewards: 69.16947, mean: 0.08539
[32m[0906 17-12-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11013, current rewards: 75.08735, mean: 0.08731
[32m[0906 17-12-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10998, current rewards: 81.00522, mean: 0.08902
[32m[0906 17-12-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10984, current rewards: 86.92310, mean: 0.09054
[32m[0906 17-12-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10971, current rewards: 92.84097, mean: 0.09192
[32m[0906 17-13-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10958, current rewards: 98.75885, mean: 0.09317
[32m[0906 17-13-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10947, current rewards: 85.66464, mean: 0.07718
[32m[0906 17-13-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10940, current rewards: 35.66464, mean: 0.03075
[32m[0906 17-13-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10931, current rewards: -14.33536, mean: -0.01185
[32m[0906 17-13-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10921, current rewards: -64.33536, mean: -0.05106
[32m[0906 17-13-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10916, current rewards: -114.33536, mean: -0.08728
[32m[0906 17-13-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10911, current rewards: -164.33536, mean: -0.12083
[32m[0906 17-13-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10902, current rewards: -214.33536, mean: -0.15201
[32m[0906 17-13-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10888, current rewards: -264.33536, mean: -0.18105
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10879, current rewards: -314.33536, mean: -0.20817
[32m[0906 17-13-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10875, current rewards: -364.33536, mean: -0.23355
[32m[0906 17-14-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10871, current rewards: -414.33536, mean: -0.25735
[32m[0906 17-14-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10868, current rewards: -464.33536, mean: -0.27972
[32m[0906 17-14-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10864, current rewards: -514.33536, mean: -0.30078
[32m[0906 17-14-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10862, current rewards: -564.33536, mean: -0.32065
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10859, current rewards: -614.33536, mean: -0.33941
[32m[0906 17-14-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10855, current rewards: -664.33536, mean: -0.35717
[32m[0906 17-14-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10853, current rewards: -714.33536, mean: -0.37400
[32m[0906 17-14-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10842, current rewards: -764.33536, mean: -0.38997
[32m[0906 17-14-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10831, current rewards: -814.33536, mean: -0.40514
[32m[0906 17-14-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10822, current rewards: -864.33536, mean: -0.41958
[32m[0906 17-14-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10806, current rewards: -914.33536, mean: -0.43333
[32m[0906 17-14-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10789, current rewards: -964.33536, mean: -0.44645
[32m[0906 17-15-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10775, current rewards: -1014.33536, mean: -0.45898
[32m[0906 17-15-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10760, current rewards: -1064.33536, mean: -0.47094
[32m[0906 17-15-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10748, current rewards: -1114.33536, mean: -0.48240
[32m[0906 17-15-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10742, current rewards: -1164.33536, mean: -0.49336
[32m[0906 17-15-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10736, current rewards: -1214.33536, mean: -0.50387
[32m[0906 17-15-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10730, current rewards: -1264.33536, mean: -0.51396
[32m[0906 17-15-34 @Agent.py:117][0m Average action selection time: 0.1073
[32m[0906 17-15-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-15-34 @MBExp.py:227][0m Rewards obtained: [-1304.3353553482405], Lows: [6], Highs: [1417], Total time: 10939.87058
[32m[0906 17-17-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-17-09 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 17-17-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11283, current rewards: -4.57916, mean: -0.45792
[32m[0906 17-17-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11221, current rewards: 0.70248, mean: 0.01171
[32m[0906 17-17-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11167, current rewards: 5.93604, mean: 0.05396
[32m[0906 17-17-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11172, current rewards: 11.16905, mean: 0.06981
[32m[0906 17-17-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11194, current rewards: 16.40308, mean: 0.07811
[32m[0906 17-17-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11199, current rewards: 21.82034, mean: 0.08392
[32m[0906 17-17-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11204, current rewards: 27.11399, mean: 0.08746
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11188, current rewards: 32.41792, mean: 0.09005
[32m[0906 17-17-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11176, current rewards: 27.50914, mean: 0.06710
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11175, current rewards: 32.73047, mean: 0.07115
[32m[0906 17-18-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11162, current rewards: 37.94911, mean: 0.07441
[32m[0906 17-18-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11159, current rewards: 43.16933, mean: 0.07709
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11133, current rewards: 48.39197, mean: 0.07933
[32m[0906 17-18-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11099, current rewards: 53.47022, mean: 0.08102
[32m[0906 17-18-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11070, current rewards: 58.69245, mean: 0.08267
[32m[0906 17-18-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11049, current rewards: 63.91801, mean: 0.08410
[32m[0906 17-18-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11031, current rewards: 66.93314, mean: 0.08263
[32m[0906 17-18-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11009, current rewards: 69.33348, mean: 0.08062
[32m[0906 17-18-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10994, current rewards: 75.02585, mean: 0.08245
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10980, current rewards: 80.72322, mean: 0.08409
[32m[0906 17-19-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10965, current rewards: 86.43316, mean: 0.08558
[32m[0906 17-19-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10955, current rewards: 92.93962, mean: 0.08768
[32m[0906 17-19-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10944, current rewards: 93.36012, mean: 0.08411
[32m[0906 17-19-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10934, current rewards: 98.97285, mean: 0.08532
[32m[0906 17-19-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10924, current rewards: 104.58746, mean: 0.08644
[32m[0906 17-19-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10915, current rewards: 110.20033, mean: 0.08746
[32m[0906 17-19-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10911, current rewards: 115.81227, mean: 0.08841
[32m[0906 17-19-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10903, current rewards: 121.42221, mean: 0.08928
[32m[0906 17-19-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10890, current rewards: 127.04138, mean: 0.09010
[32m[0906 17-19-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10875, current rewards: 132.65433, mean: 0.09086
[32m[0906 17-19-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10866, current rewards: 138.23922, mean: 0.09155
[32m[0906 17-19-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10863, current rewards: 143.91758, mean: 0.09225
[32m[0906 17-20-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10860, current rewards: 149.59455, mean: 0.09292
[32m[0906 17-20-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10857, current rewards: 144.43201, mean: 0.08701
[32m[0906 17-20-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10853, current rewards: 149.47659, mean: 0.08741
[32m[0906 17-20-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10851, current rewards: 154.52182, mean: 0.08780
[32m[0906 17-20-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10848, current rewards: 154.09536, mean: 0.08514
[32m[0906 17-20-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10844, current rewards: 159.45527, mean: 0.08573
[32m[0906 17-20-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10842, current rewards: 164.40915, mean: 0.08608
[32m[0906 17-20-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10832, current rewards: 169.68437, mean: 0.08657
[32m[0906 17-20-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10820, current rewards: 174.96070, mean: 0.08705
[32m[0906 17-20-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10811, current rewards: 180.23584, mean: 0.08749
[32m[0906 17-20-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10795, current rewards: 174.96318, mean: 0.08292
[32m[0906 17-21-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10779, current rewards: 180.19962, mean: 0.08343
[32m[0906 17-21-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10763, current rewards: 185.43397, mean: 0.08391
[32m[0906 17-21-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10749, current rewards: 190.66727, mean: 0.08437
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10736, current rewards: 196.30201, mean: 0.08498
[32m[0906 17-21-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10729, current rewards: 201.53425, mean: 0.08540
[32m[0906 17-21-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10723, current rewards: 206.76412, mean: 0.08579
[32m[0906 17-21-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10716, current rewards: 211.99254, mean: 0.08618
[32m[0906 17-21-37 @Agent.py:117][0m Average action selection time: 0.1071
[32m[0906 17-21-37 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-21-37 @MBExp.py:227][0m Rewards obtained: [216.17809228256624], Lows: [15], Highs: [20], Total time: 11208.400932
[32m[0906 17-23-14 @MBExp.py:144][0m ####################################################################
[32m[0906 17-23-14 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 17-23-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11088, current rewards: -4.51161, mean: -0.45116
[32m[0906 17-23-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11123, current rewards: 1.12886, mean: 0.01881
[32m[0906 17-23-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11116, current rewards: 6.77412, mean: 0.06158
[32m[0906 17-23-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11135, current rewards: 12.41720, mean: 0.07761
[32m[0906 17-23-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11134, current rewards: 18.10646, mean: 0.08622
[32m[0906 17-23-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11131, current rewards: 23.90615, mean: 0.09195
[32m[0906 17-23-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11138, current rewards: 24.12021, mean: 0.07781
[32m[0906 17-23-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11132, current rewards: 29.71475, mean: 0.08254
[32m[0906 17-24-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11124, current rewards: 35.32359, mean: 0.08616
[32m[0906 17-24-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11128, current rewards: 40.93021, mean: 0.08898
[32m[0906 17-24-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11124, current rewards: 46.54199, mean: 0.09126
[32m[0906 17-24-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11115, current rewards: 52.14908, mean: 0.09312
[32m[0906 17-24-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11088, current rewards: 57.75964, mean: 0.09469
[32m[0906 17-24-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11057, current rewards: 62.83151, mean: 0.09520
[32m[0906 17-24-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11033, current rewards: 68.35746, mean: 0.09628
[32m[0906 17-24-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11016, current rewards: 73.88675, mean: 0.09722
[32m[0906 17-24-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10996, current rewards: 79.41910, mean: 0.09805
[32m[0906 17-24-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10981, current rewards: 84.94436, mean: 0.09877
[32m[0906 17-24-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10968, current rewards: 90.46828, mean: 0.09942
[32m[0906 17-24-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10955, current rewards: 96.06991, mean: 0.10007
[32m[0906 17-25-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10945, current rewards: 101.66390, mean: 0.10066
[32m[0906 17-25-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10936, current rewards: 107.41101, mean: 0.10133
[32m[0906 17-25-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10925, current rewards: 113.07126, mean: 0.10187
[32m[0906 17-25-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10920, current rewards: 118.72885, mean: 0.10235
[32m[0906 17-25-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10912, current rewards: 124.39079, mean: 0.10280
[32m[0906 17-25-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10903, current rewards: 130.05849, mean: 0.10322
[32m[0906 17-25-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10899, current rewards: 135.72126, mean: 0.10360
[32m[0906 17-25-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10895, current rewards: 141.39243, mean: 0.10397
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10879, current rewards: 147.05887, mean: 0.10430
[32m[0906 17-25-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10865, current rewards: 153.31385, mean: 0.10501
[32m[0906 17-25-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10855, current rewards: 146.93684, mean: 0.09731
[32m[0906 17-26-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10851, current rewards: 152.66557, mean: 0.09786
[32m[0906 17-26-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10848, current rewards: 158.39531, mean: 0.09838
[32m[0906 17-26-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10844, current rewards: 164.12448, mean: 0.09887
[32m[0906 17-26-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10839, current rewards: 169.85362, mean: 0.09933
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10837, current rewards: 175.58238, mean: 0.09976
[32m[0906 17-26-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10834, current rewards: 181.31151, mean: 0.10017
[32m[0906 17-26-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10831, current rewards: 187.00339, mean: 0.10054
[32m[0906 17-26-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10830, current rewards: 192.61576, mean: 0.10085
[32m[0906 17-26-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10822, current rewards: 191.61673, mean: 0.09776
[32m[0906 17-26-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10813, current rewards: 197.29672, mean: 0.09816
[32m[0906 17-26-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10804, current rewards: 202.97042, mean: 0.09853
[32m[0906 17-27-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10792, current rewards: 208.64773, mean: 0.09889
[32m[0906 17-27-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10776, current rewards: 214.32423, mean: 0.09922
[32m[0906 17-27-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10761, current rewards: 220.00023, mean: 0.09955
[32m[0906 17-27-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10747, current rewards: 217.21774, mean: 0.09611
[32m[0906 17-27-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10732, current rewards: 220.46107, mean: 0.09544
[32m[0906 17-27-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10728, current rewards: 226.06192, mean: 0.09579
[32m[0906 17-27-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10725, current rewards: 231.66376, mean: 0.09613
[32m[0906 17-27-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10721, current rewards: 237.26367, mean: 0.09645
[32m[0906 17-27-43 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 17-27-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-27-43 @MBExp.py:227][0m Rewards obtained: [241.7414412713037], Lows: [11], Highs: [16], Total time: 11477.060505000001
[32m[0906 17-29-22 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-22 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 17-29-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11036, current rewards: -5.32022, mean: -0.53202
[32m[0906 17-29-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11114, current rewards: 0.47956, mean: 0.00799
[32m[0906 17-29-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11118, current rewards: 6.05865, mean: 0.05508
[32m[0906 17-29-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11136, current rewards: 11.63650, mean: 0.07273
[32m[0906 17-29-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11143, current rewards: 16.76991, mean: 0.07986
[32m[0906 17-29-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11155, current rewards: 22.29667, mean: 0.08576
[32m[0906 17-29-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11155, current rewards: 27.82785, mean: 0.08977
[32m[0906 17-30-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11159, current rewards: 33.35561, mean: 0.09265
[32m[0906 17-30-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11162, current rewards: 38.88466, mean: 0.09484
[32m[0906 17-30-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11157, current rewards: 44.40607, mean: 0.09653
[32m[0906 17-30-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11151, current rewards: 49.92567, mean: 0.09789
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11139, current rewards: 44.94685, mean: 0.08026
[32m[0906 17-30-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11107, current rewards: 50.75933, mean: 0.08321
[32m[0906 17-30-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11082, current rewards: 56.75503, mean: 0.08599
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11061, current rewards: 62.30948, mean: 0.08776
[32m[0906 17-30-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11039, current rewards: 67.86359, mean: 0.08929
[32m[0906 17-30-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11020, current rewards: 73.41794, mean: 0.09064
[32m[0906 17-30-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11006, current rewards: 72.25599, mean: 0.08402
[32m[0906 17-31-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10991, current rewards: 77.79247, mean: 0.08549
[32m[0906 17-31-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10978, current rewards: 83.32597, mean: 0.08680
[32m[0906 17-31-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10969, current rewards: 88.85985, mean: 0.08798
[32m[0906 17-31-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10959, current rewards: 94.25966, mean: 0.08892
[32m[0906 17-31-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10946, current rewards: 99.79061, mean: 0.08990
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10941, current rewards: 105.32734, mean: 0.09080
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10935, current rewards: 110.86029, mean: 0.09162
[32m[0906 17-31-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10928, current rewards: 119.90219, mean: 0.09516
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10921, current rewards: 125.41046, mean: 0.09573
[32m[0906 17-31-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10915, current rewards: 130.90803, mean: 0.09626
[32m[0906 17-31-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10895, current rewards: 136.41294, mean: 0.09675
[32m[0906 17-32-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10881, current rewards: 142.24351, mean: 0.09743
[32m[0906 17-32-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10869, current rewards: 147.76985, mean: 0.09786
[32m[0906 17-32-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10867, current rewards: 153.29811, mean: 0.09827
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10867, current rewards: 158.83346, mean: 0.09865
[32m[0906 17-32-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10863, current rewards: 164.35729, mean: 0.09901
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10860, current rewards: 169.88681, mean: 0.09935
[32m[0906 17-32-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10857, current rewards: 164.89674, mean: 0.09369
[32m[0906 17-32-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10855, current rewards: 170.37446, mean: 0.09413
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10851, current rewards: 175.76216, mean: 0.09450
[32m[0906 17-32-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10849, current rewards: 181.23729, mean: 0.09489
[32m[0906 17-32-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10844, current rewards: 186.71514, mean: 0.09526
[32m[0906 17-33-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10833, current rewards: 192.19939, mean: 0.09562
[32m[0906 17-33-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10824, current rewards: 197.67572, mean: 0.09596
[32m[0906 17-33-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10815, current rewards: 203.15381, mean: 0.09628
[32m[0906 17-33-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10804, current rewards: 208.63489, mean: 0.09659
[32m[0906 17-33-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10797, current rewards: 203.60320, mean: 0.09213
[32m[0906 17-33-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10788, current rewards: 208.92434, mean: 0.09244
[32m[0906 17-33-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10780, current rewards: 214.46744, mean: 0.09284
[32m[0906 17-33-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10779, current rewards: 220.01071, mean: 0.09322
[32m[0906 17-33-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10771, current rewards: 225.55910, mean: 0.09359
[32m[0906 17-33-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10764, current rewards: 231.09919, mean: 0.09394
[32m[0906 17-33-52 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 17-33-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-33-52 @MBExp.py:227][0m Rewards obtained: [229.95412866917587], Lows: [15], Highs: [17], Total time: 11746.805000000002
[32m[0906 17-35-32 @MBExp.py:144][0m ####################################################################
[32m[0906 17-35-32 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11073, current rewards: -4.46258, mean: -0.44626
[32m[0906 17-35-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11071, current rewards: 0.47769, mean: 0.00796
[32m[0906 17-35-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11119, current rewards: 5.78517, mean: 0.05259
[32m[0906 17-35-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11132, current rewards: 11.09723, mean: 0.06936
[32m[0906 17-35-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11148, current rewards: 16.40488, mean: 0.07812
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11158, current rewards: 21.71206, mean: 0.08351
[32m[0906 17-36-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11159, current rewards: 27.01855, mean: 0.08716
[32m[0906 17-36-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11169, current rewards: 32.32701, mean: 0.08980
[32m[0906 17-36-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11168, current rewards: 37.63010, mean: 0.09178
[32m[0906 17-36-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11167, current rewards: 42.93576, mean: 0.09334
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11172, current rewards: 48.23873, mean: 0.09459
[32m[0906 17-36-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11138, current rewards: 53.54699, mean: 0.09562
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11110, current rewards: 59.67906, mean: 0.09783
[32m[0906 17-36-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11086, current rewards: 64.60775, mean: 0.09789
[32m[0906 17-36-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11068, current rewards: 69.58903, mean: 0.09801
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11045, current rewards: 74.57344, mean: 0.09812
[32m[0906 17-37-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11031, current rewards: 79.54477, mean: 0.09820
[32m[0906 17-37-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11017, current rewards: 74.58543, mean: 0.08673
[32m[0906 17-37-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11004, current rewards: 80.06191, mean: 0.08798
[32m[0906 17-37-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10995, current rewards: 85.53150, mean: 0.08910
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10983, current rewards: 91.00460, mean: 0.09010
[32m[0906 17-37-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10977, current rewards: 96.47284, mean: 0.09101
[32m[0906 17-37-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10976, current rewards: 101.94509, mean: 0.09184
[32m[0906 17-37-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10972, current rewards: 107.41732, mean: 0.09260
[32m[0906 17-37-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10962, current rewards: 112.88711, mean: 0.09330
[32m[0906 17-37-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10955, current rewards: 118.35866, mean: 0.09394
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10945, current rewards: 123.74378, mean: 0.09446
[32m[0906 17-38-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10932, current rewards: 129.25282, mean: 0.09504
[32m[0906 17-38-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10915, current rewards: 134.58809, mean: 0.09545
[32m[0906 17-38-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10897, current rewards: 139.62145, mean: 0.09563
[32m[0906 17-38-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10886, current rewards: 145.01615, mean: 0.09604
[32m[0906 17-38-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10883, current rewards: 141.98050, mean: 0.09101
[32m[0906 17-38-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10879, current rewards: 145.23504, mean: 0.09021
[32m[0906 17-38-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10873, current rewards: 150.68680, mean: 0.09078
[32m[0906 17-38-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10872, current rewards: 156.13928, mean: 0.09131
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10868, current rewards: 161.58986, mean: 0.09181
[32m[0906 17-38-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10863, current rewards: 167.04349, mean: 0.09229
[32m[0906 17-38-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10860, current rewards: 173.86458, mean: 0.09348
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10857, current rewards: 182.16471, mean: 0.09537
[32m[0906 17-39-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10852, current rewards: 190.46483, mean: 0.09718
[32m[0906 17-39-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10842, current rewards: 198.76495, mean: 0.09889
[32m[0906 17-39-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10831, current rewards: 207.06507, mean: 0.10052
[32m[0906 17-39-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10819, current rewards: 215.36519, mean: 0.10207
[32m[0906 17-39-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10810, current rewards: 194.51525, mean: 0.09005
[32m[0906 17-39-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10801, current rewards: 144.51525, mean: 0.06539
[32m[0906 17-39-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10791, current rewards: 94.51525, mean: 0.04182
[32m[0906 17-39-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10783, current rewards: 44.51525, mean: 0.01927
[32m[0906 17-39-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10779, current rewards: -5.48475, mean: -0.00232
[32m[0906 17-39-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10771, current rewards: -55.48475, mean: -0.02302
[32m[0906 17-39-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10766, current rewards: -105.48475, mean: -0.04288
[32m[0906 17-40-02 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 17-40-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-40-02 @MBExp.py:227][0m Rewards obtained: [-145.48475116075426], Lows: [10], Highs: [370], Total time: 12016.527496000002
[32m[0906 17-41-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-41-45 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 17-41-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11396, current rewards: -6.65920, mean: -0.66592
[32m[0906 17-41-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11170, current rewards: -1.64662, mean: -0.02744
[32m[0906 17-41-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11176, current rewards: 3.61711, mean: 0.03288
[32m[0906 17-42-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11190, current rewards: 8.88660, mean: 0.05554
[32m[0906 17-42-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11169, current rewards: 14.47404, mean: 0.06892
[32m[0906 17-42-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11155, current rewards: 19.80500, mean: 0.07617
[32m[0906 17-42-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11159, current rewards: 25.13590, mean: 0.08108
[32m[0906 17-42-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11153, current rewards: 30.46476, mean: 0.08462
[32m[0906 17-42-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11153, current rewards: 35.79947, mean: 0.08732
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11154, current rewards: 41.13802, mean: 0.08943
[32m[0906 17-42-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11135, current rewards: 46.46680, mean: 0.09111
[32m[0906 17-42-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11101, current rewards: 51.79469, mean: 0.09249
[32m[0906 17-42-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11079, current rewards: 57.50504, mean: 0.09427
[32m[0906 17-42-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11061, current rewards: 56.11043, mean: 0.08502
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11040, current rewards: 61.83492, mean: 0.08709
[32m[0906 17-43-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11028, current rewards: 67.55900, mean: 0.08889
[32m[0906 17-43-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11010, current rewards: 73.28247, mean: 0.09047
[32m[0906 17-43-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10994, current rewards: 79.00205, mean: 0.09186
[32m[0906 17-43-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10981, current rewards: 84.72593, mean: 0.09311
[32m[0906 17-43-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10971, current rewards: 90.45160, mean: 0.09422
[32m[0906 17-43-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10959, current rewards: 85.52493, mean: 0.08468
[32m[0906 17-43-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10949, current rewards: 90.48082, mean: 0.08536
[32m[0906 17-43-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10940, current rewards: 96.27185, mean: 0.08673
[32m[0906 17-43-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10931, current rewards: 102.06277, mean: 0.08799
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10925, current rewards: 107.84192, mean: 0.08913
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10921, current rewards: 113.63204, mean: 0.09018
[32m[0906 17-44-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10915, current rewards: 119.41899, mean: 0.09116
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10899, current rewards: 125.20831, mean: 0.09206
[32m[0906 17-44-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10880, current rewards: 130.99460, mean: 0.09290
[32m[0906 17-44-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10864, current rewards: 137.24374, mean: 0.09400
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10858, current rewards: 143.39972, mean: 0.09497
[32m[0906 17-44-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10856, current rewards: 148.97978, mean: 0.09550
[32m[0906 17-44-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10853, current rewards: 150.33117, mean: 0.09337
[32m[0906 17-44-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10851, current rewards: 150.62386, mean: 0.09074
[32m[0906 17-44-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10848, current rewards: 156.66913, mean: 0.09162
[32m[0906 17-44-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10847, current rewards: 162.71439, mean: 0.09245
[32m[0906 17-45-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10845, current rewards: 168.75966, mean: 0.09324
[32m[0906 17-45-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10842, current rewards: 174.80493, mean: 0.09398
[32m[0906 17-45-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10843, current rewards: 179.42019, mean: 0.09394
[32m[0906 17-45-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10838, current rewards: 185.05014, mean: 0.09441
[32m[0906 17-45-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10828, current rewards: 190.66821, mean: 0.09486
[32m[0906 17-45-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10820, current rewards: 196.30068, mean: 0.09529
[32m[0906 17-45-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10810, current rewards: 201.92623, mean: 0.09570
[32m[0906 17-45-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10800, current rewards: 207.55305, mean: 0.09609
[32m[0906 17-45-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10794, current rewards: 213.17763, mean: 0.09646
[32m[0906 17-45-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10786, current rewards: 218.80339, mean: 0.09682
[32m[0906 17-45-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10786, current rewards: 215.66489, mean: 0.09336
[32m[0906 17-46-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10785, current rewards: 213.25995, mean: 0.09036
[32m[0906 17-46-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10784, current rewards: 212.71571, mean: 0.08826
[32m[0906 17-46-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10780, current rewards: 214.03648, mean: 0.08701
[32m[0906 17-46-15 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 17-46-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-46-15 @MBExp.py:227][0m Rewards obtained: [210.70232324909819], Lows: [27], Highs: [15], Total time: 12286.749427000002
[32m[0906 17-48-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-48-01 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 17-48-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11139, current rewards: -4.49335, mean: -0.44933
[32m[0906 17-48-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11212, current rewards: 0.81658, mean: 0.01361
[32m[0906 17-48-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11183, current rewards: 6.33956, mean: 0.05763
[32m[0906 17-48-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11173, current rewards: 11.86329, mean: 0.07415
[32m[0906 17-48-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11191, current rewards: 17.39021, mean: 0.08281
[32m[0906 17-48-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11176, current rewards: 23.61318, mean: 0.09082
[32m[0906 17-48-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11174, current rewards: 29.65571, mean: 0.09566
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11176, current rewards: 29.64877, mean: 0.08236
[32m[0906 17-48-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11166, current rewards: 35.16556, mean: 0.08577
[32m[0906 17-48-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11170, current rewards: 40.68470, mean: 0.08845
[32m[0906 17-48-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11154, current rewards: 46.19922, mean: 0.09059
[32m[0906 17-49-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11120, current rewards: 51.71243, mean: 0.09234
[32m[0906 17-49-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11091, current rewards: 57.22804, mean: 0.09382
[32m[0906 17-49-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11070, current rewards: 62.73820, mean: 0.09506
[32m[0906 17-49-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11050, current rewards: 68.28468, mean: 0.09618
[32m[0906 17-49-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11031, current rewards: 73.33936, mean: 0.09650
[32m[0906 17-49-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11019, current rewards: 78.45733, mean: 0.09686
[32m[0906 17-49-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11003, current rewards: 83.58618, mean: 0.09719
[32m[0906 17-49-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10989, current rewards: 88.71644, mean: 0.09749
[32m[0906 17-49-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10979, current rewards: 93.84540, mean: 0.09776
[32m[0906 17-49-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10969, current rewards: 98.97041, mean: 0.09799
[32m[0906 17-49-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10958, current rewards: 104.10050, mean: 0.09821
[32m[0906 17-50-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10953, current rewards: 109.10601, mean: 0.09829
[32m[0906 17-50-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10945, current rewards: 110.05846, mean: 0.09488
[32m[0906 17-50-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10937, current rewards: 108.05801, mean: 0.08930
[32m[0906 17-50-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10932, current rewards: 113.71158, mean: 0.09025
[32m[0906 17-50-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10921, current rewards: 119.36401, mean: 0.09112
[32m[0906 17-50-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10902, current rewards: 125.01721, mean: 0.09192
[32m[0906 17-50-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10886, current rewards: 130.66898, mean: 0.09267
[32m[0906 17-50-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10870, current rewards: 136.32038, mean: 0.09337
[32m[0906 17-50-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10859, current rewards: 142.13209, mean: 0.09413
[32m[0906 17-50-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10857, current rewards: 147.81068, mean: 0.09475
[32m[0906 17-50-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10853, current rewards: 153.48928, mean: 0.09533
[32m[0906 17-51-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10853, current rewards: 150.19451, mean: 0.09048
[32m[0906 17-51-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10851, current rewards: 155.69766, mean: 0.09105
[32m[0906 17-51-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10849, current rewards: 161.19742, mean: 0.09159
[32m[0906 17-51-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10848, current rewards: 166.69316, mean: 0.09210
[32m[0906 17-51-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10847, current rewards: 172.19371, mean: 0.09258
[32m[0906 17-51-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10845, current rewards: 167.35317, mean: 0.08762
[32m[0906 17-51-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10841, current rewards: 172.96649, mean: 0.08825
[32m[0906 17-51-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10831, current rewards: 178.57296, mean: 0.08884
[32m[0906 17-51-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10822, current rewards: 184.18348, mean: 0.08941
[32m[0906 17-51-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10813, current rewards: 189.79465, mean: 0.08995
[32m[0906 17-51-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10805, current rewards: 195.40739, mean: 0.09047
[32m[0906 17-52-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10797, current rewards: 201.01825, mean: 0.09096
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10790, current rewards: 206.62689, mean: 0.09143
[32m[0906 17-52-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10782, current rewards: 201.59064, mean: 0.08727
[32m[0906 17-52-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10779, current rewards: 207.14773, mean: 0.08777
[32m[0906 17-52-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10773, current rewards: 212.69387, mean: 0.08825
[32m[0906 17-52-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10767, current rewards: 218.24433, mean: 0.08872
[32m[0906 17-52-31 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 17-52-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-52-31 @MBExp.py:227][0m Rewards obtained: [222.68185562132334], Lows: [16], Highs: [18], Total time: 12556.541252000003
[32m[0906 17-54-18 @MBExp.py:144][0m ####################################################################
[32m[0906 17-54-18 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 17-54-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11136, current rewards: -6.65819, mean: -0.66582
[32m[0906 17-54-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11159, current rewards: -1.54526, mean: -0.02575
[32m[0906 17-54-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11186, current rewards: 3.87464, mean: 0.03522
[32m[0906 17-54-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11187, current rewards: 9.30885, mean: 0.05818
[32m[0906 17-54-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11177, current rewards: 14.73814, mean: 0.07018
[32m[0906 17-54-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11191, current rewards: 20.46812, mean: 0.07872
[32m[0906 17-54-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11182, current rewards: 25.93393, mean: 0.08366
[32m[0906 17-54-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11180, current rewards: 31.40160, mean: 0.08723
[32m[0906 17-55-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11188, current rewards: 36.86696, mean: 0.08992
[32m[0906 17-55-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11185, current rewards: 42.33334, mean: 0.09203
[32m[0906 17-55-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11144, current rewards: 47.80234, mean: 0.09373
[32m[0906 17-55-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11117, current rewards: 53.26262, mean: 0.09511
[32m[0906 17-55-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11089, current rewards: 58.73148, mean: 0.09628
[32m[0906 17-55-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11071, current rewards: 64.30744, mean: 0.09744
[32m[0906 17-55-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11052, current rewards: 69.85612, mean: 0.09839
[32m[0906 17-55-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11033, current rewards: 75.42083, mean: 0.09924
[32m[0906 17-55-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11018, current rewards: 80.98419, mean: 0.09998
[32m[0906 17-55-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11001, current rewards: 86.54378, mean: 0.10063
[32m[0906 17-55-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10988, current rewards: 92.10522, mean: 0.10121
[32m[0906 17-56-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10979, current rewards: 97.66540, mean: 0.10173
[32m[0906 17-56-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10969, current rewards: 92.63532, mean: 0.09172
[32m[0906 17-56-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10958, current rewards: 97.73741, mean: 0.09221
[32m[0906 17-56-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10954, current rewards: 103.12221, mean: 0.09290
[32m[0906 17-56-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10947, current rewards: 108.50840, mean: 0.09354
[32m[0906 17-56-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10939, current rewards: 113.89915, mean: 0.09413
[32m[0906 17-56-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10936, current rewards: 119.28602, mean: 0.09467
[32m[0906 17-56-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10920, current rewards: 124.67149, mean: 0.09517
[32m[0906 17-56-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10902, current rewards: 130.05341, mean: 0.09563
[32m[0906 17-56-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10886, current rewards: 135.43768, mean: 0.09606
[32m[0906 17-56-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10871, current rewards: 141.46369, mean: 0.09689
[32m[0906 17-57-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10860, current rewards: 138.88018, mean: 0.09197
[32m[0906 17-57-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10859, current rewards: 146.95447, mean: 0.09420
[32m[0906 17-57-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10857, current rewards: 155.02876, mean: 0.09629
[32m[0906 17-57-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10853, current rewards: 131.74293, mean: 0.07936
[32m[0906 17-57-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10853, current rewards: 87.31522, mean: 0.05106
[32m[0906 17-57-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10853, current rewards: 92.80515, mean: 0.05273
[32m[0906 17-57-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10855, current rewards: 98.26541, mean: 0.05429
[32m[0906 17-57-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10855, current rewards: 103.73326, mean: 0.05577
[32m[0906 17-57-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10852, current rewards: 108.73756, mean: 0.05693
[32m[0906 17-57-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10845, current rewards: 114.16063, mean: 0.05825
[32m[0906 17-57-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10836, current rewards: 119.58529, mean: 0.05950
[32m[0906 17-58-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10825, current rewards: 125.01005, mean: 0.06068
[32m[0906 17-58-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10816, current rewards: 130.43694, mean: 0.06182
[32m[0906 17-58-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10808, current rewards: 125.36294, mean: 0.05804
[32m[0906 17-58-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10799, current rewards: 130.84115, mean: 0.05920
[32m[0906 17-58-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10790, current rewards: 136.31901, mean: 0.06032
[32m[0906 17-58-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10784, current rewards: 142.35940, mean: 0.06163
[32m[0906 17-58-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10780, current rewards: 147.85327, mean: 0.06265
[32m[0906 17-58-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10773, current rewards: 153.23909, mean: 0.06358
[32m[0906 17-58-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10766, current rewards: 158.62547, mean: 0.06448
[32m[0906 17-58-48 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 17-58-48 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-58-48 @MBExp.py:227][0m Rewards obtained: [162.93440523216594], Lows: [16], Highs: [77], Total time: 12826.294282000003
[32m[0906 18-00-38 @MBExp.py:144][0m ####################################################################
[32m[0906 18-00-38 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 18-00-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10946, current rewards: -6.68663, mean: -0.66866
[32m[0906 18-00-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11067, current rewards: -1.23976, mean: -0.02066
[32m[0906 18-00-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11142, current rewards: 4.22921, mean: 0.03845
[32m[0906 18-00-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11129, current rewards: 9.69720, mean: 0.06061
[32m[0906 18-01-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11131, current rewards: 15.16920, mean: 0.07223
[32m[0906 18-01-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11133, current rewards: 21.29545, mean: 0.08191
[32m[0906 18-01-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11128, current rewards: 26.74778, mean: 0.08628
[32m[0906 18-01-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11130, current rewards: 32.20170, mean: 0.08945
[32m[0906 18-01-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11133, current rewards: 37.64741, mean: 0.09182
[32m[0906 18-01-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11103, current rewards: 43.09928, mean: 0.09369
[32m[0906 18-01-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11067, current rewards: 40.11309, mean: 0.07865
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11041, current rewards: 43.62548, mean: 0.07790
[32m[0906 18-01-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11015, current rewards: 49.17229, mean: 0.08061
[32m[0906 18-01-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10995, current rewards: 54.26945, mean: 0.08223
[32m[0906 18-01-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10982, current rewards: 59.69072, mean: 0.08407
[32m[0906 18-02-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10965, current rewards: 54.78106, mean: 0.07208
[32m[0906 18-02-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10951, current rewards: 60.58574, mean: 0.07480
[32m[0906 18-02-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10944, current rewards: 66.39869, mean: 0.07721
[32m[0906 18-02-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10934, current rewards: 72.20521, mean: 0.07935
[32m[0906 18-02-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10924, current rewards: 78.01207, mean: 0.08126
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10919, current rewards: 83.82237, mean: 0.08299
[32m[0906 18-02-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10910, current rewards: 89.62640, mean: 0.08455
[32m[0906 18-02-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10906, current rewards: 95.72443, mean: 0.08624
[32m[0906 18-02-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10903, current rewards: 100.90203, mean: 0.08698
[32m[0906 18-02-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10897, current rewards: 96.12688, mean: 0.07944
[32m[0906 18-02-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10886, current rewards: 101.79010, mean: 0.08079
[32m[0906 18-03-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10870, current rewards: 107.45330, mean: 0.08203
[32m[0906 18-03-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10853, current rewards: 113.11778, mean: 0.08317
[32m[0906 18-03-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10837, current rewards: 118.78112, mean: 0.08424
[32m[0906 18-03-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10825, current rewards: 124.44386, mean: 0.08524
[32m[0906 18-03-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10817, current rewards: 131.31254, mean: 0.08696
[32m[0906 18-03-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10814, current rewards: 84.74899, mean: 0.05433
[32m[0906 18-03-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10817, current rewards: 34.74899, mean: 0.02158
[32m[0906 18-03-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10814, current rewards: -15.25101, mean: -0.00919
[32m[0906 18-03-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10811, current rewards: -65.25101, mean: -0.03816
[32m[0906 18-03-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10812, current rewards: -115.25101, mean: -0.06548
[32m[0906 18-03-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10809, current rewards: -165.25101, mean: -0.09130
[32m[0906 18-03-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10808, current rewards: -215.25101, mean: -0.11573
[32m[0906 18-04-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10809, current rewards: -232.25396, mean: -0.12160
[32m[0906 18-04-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10805, current rewards: -231.08187, mean: -0.11790
[32m[0906 18-04-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10796, current rewards: -225.67567, mean: -0.11228
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10789, current rewards: -220.26406, mean: -0.10692
[32m[0906 18-04-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10781, current rewards: -214.85171, mean: -0.10183
[32m[0906 18-04-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10774, current rewards: -209.44491, mean: -0.09697
[32m[0906 18-04-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10770, current rewards: -204.03332, mean: -0.09232
[32m[0906 18-04-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10763, current rewards: -198.62546, mean: -0.08789
[32m[0906 18-04-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10757, current rewards: -192.99596, mean: -0.08355
[32m[0906 18-04-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10755, current rewards: -187.53781, mean: -0.07947
[32m[0906 18-04-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10749, current rewards: -182.08990, mean: -0.07556
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10743, current rewards: -176.64162, mean: -0.07181
[32m[0906 18-05-07 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 18-05-07 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-05-07 @MBExp.py:227][0m Rewards obtained: [-182.83289528671932], Lows: [25], Highs: [368], Total time: 13095.558859000002
[32m[0906 18-07-00 @MBExp.py:144][0m ####################################################################
[32m[0906 18-07-00 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 18-07-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11077, current rewards: -6.72080, mean: -0.67208
[32m[0906 18-07-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11148, current rewards: -2.19468, mean: -0.03658
[32m[0906 18-07-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11170, current rewards: 2.64841, mean: 0.02408
[32m[0906 18-07-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11159, current rewards: 7.47801, mean: 0.04674
[32m[0906 18-07-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11158, current rewards: 12.31251, mean: 0.05863
[32m[0906 18-07-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11180, current rewards: 19.94767, mean: 0.07672
[32m[0906 18-07-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11185, current rewards: 31.46638, mean: 0.10150
[32m[0906 18-07-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11181, current rewards: 43.31894, mean: 0.12033
[32m[0906 18-07-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11174, current rewards: 30.57341, mean: 0.07457
[32m[0906 18-07-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11134, current rewards: 35.72774, mean: 0.07767
[32m[0906 18-07-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11099, current rewards: 40.88091, mean: 0.08016
[32m[0906 18-08-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11072, current rewards: 46.03417, mean: 0.08220
[32m[0906 18-08-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11051, current rewards: 51.18725, mean: 0.08391
[32m[0906 18-08-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11025, current rewards: 56.33489, mean: 0.08536
[32m[0906 18-08-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11006, current rewards: 61.03672, mean: 0.08597
[32m[0906 18-08-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10988, current rewards: 65.95629, mean: 0.08678
[32m[0906 18-08-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10977, current rewards: 70.87622, mean: 0.08750
[32m[0906 18-08-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10967, current rewards: 75.79563, mean: 0.08813
[32m[0906 18-08-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10956, current rewards: 80.71799, mean: 0.08870
[32m[0906 18-08-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10953, current rewards: 82.66375, mean: 0.08611
[32m[0906 18-08-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10946, current rewards: 92.33990, mean: 0.09143
[32m[0906 18-08-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10937, current rewards: 101.94449, mean: 0.09617
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10929, current rewards: 113.44876, mean: 0.10221
[32m[0906 18-09-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10924, current rewards: 121.51504, mean: 0.10475
[32m[0906 18-09-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10919, current rewards: 129.52708, mean: 0.10705
[32m[0906 18-09-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10901, current rewards: 127.36725, mean: 0.10109
[32m[0906 18-09-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10884, current rewards: 132.97751, mean: 0.10151
[32m[0906 18-09-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10868, current rewards: 138.26571, mean: 0.10167
[32m[0906 18-09-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10853, current rewards: 143.55155, mean: 0.10181
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10840, current rewards: 139.19483, mean: 0.09534
[32m[0906 18-09-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10832, current rewards: 144.47131, mean: 0.09568
[32m[0906 18-09-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10831, current rewards: 149.34374, mean: 0.09573
[32m[0906 18-09-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10831, current rewards: 154.58978, mean: 0.09602
[32m[0906 18-10-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10830, current rewards: 159.83556, mean: 0.09629
[32m[0906 18-10-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10830, current rewards: 165.08552, mean: 0.09654
[32m[0906 18-10-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10830, current rewards: 170.33479, mean: 0.09678
[32m[0906 18-10-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10829, current rewards: 175.58550, mean: 0.09701
[32m[0906 18-10-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10830, current rewards: 180.82847, mean: 0.09722
[32m[0906 18-10-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10829, current rewards: 180.31673, mean: 0.09441
[32m[0906 18-10-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10823, current rewards: 185.56879, mean: 0.09468
[32m[0906 18-10-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10815, current rewards: 190.65691, mean: 0.09485
[32m[0906 18-10-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10807, current rewards: 195.74548, mean: 0.09502
[32m[0906 18-10-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10799, current rewards: 197.53037, mean: 0.09362
[32m[0906 18-10-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10792, current rewards: 203.54287, mean: 0.09423
[32m[0906 18-10-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10785, current rewards: 212.33797, mean: 0.09608
[32m[0906 18-11-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10777, current rewards: 221.15799, mean: 0.09786
[32m[0906 18-11-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10772, current rewards: 229.97800, mean: 0.09956
[32m[0906 18-11-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10768, current rewards: 239.41879, mean: 0.10145
[32m[0906 18-11-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10762, current rewards: 247.55974, mean: 0.10272
[32m[0906 18-11-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10757, current rewards: 255.65747, mean: 0.10393
[32m[0906 18-11-29 @Agent.py:117][0m Average action selection time: 0.1075
[32m[0906 18-11-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-11-29 @MBExp.py:227][0m Rewards obtained: [262.15596030810843], Lows: [21], Highs: [21], Total time: 13365.149277000002
[32m[0906 18-13-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-13-24 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 18-13-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11087, current rewards: -4.53513, mean: -0.45351
[32m[0906 18-13-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11135, current rewards: 1.16725, mean: 0.01945
[32m[0906 18-13-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11174, current rewards: 6.88164, mean: 0.06256
[32m[0906 18-13-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11171, current rewards: 12.59637, mean: 0.07873
[32m[0906 18-13-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11171, current rewards: 18.30980, mean: 0.08719
[32m[0906 18-13-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11180, current rewards: 23.96714, mean: 0.09218
[32m[0906 18-13-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11179, current rewards: 29.66786, mean: 0.09570
[32m[0906 18-14-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11181, current rewards: 35.37367, mean: 0.09826
[32m[0906 18-14-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11147, current rewards: 41.08444, mean: 0.10021
[32m[0906 18-14-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11108, current rewards: 46.79756, mean: 0.10173
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11083, current rewards: 52.50188, mean: 0.10294
[32m[0906 18-14-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11058, current rewards: 47.76887, mean: 0.08530
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11035, current rewards: 53.37493, mean: 0.08750
[32m[0906 18-14-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11020, current rewards: 59.45874, mean: 0.09009
[32m[0906 18-14-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11002, current rewards: 65.09874, mean: 0.09169
[32m[0906 18-14-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10985, current rewards: 70.74544, mean: 0.09309
[32m[0906 18-14-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10976, current rewards: 76.39231, mean: 0.09431
[32m[0906 18-14-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10967, current rewards: 74.19829, mean: 0.08628
[32m[0906 18-15-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10956, current rewards: 80.00498, mean: 0.08792
[32m[0906 18-15-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10950, current rewards: 85.81314, mean: 0.08939
[32m[0906 18-15-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10941, current rewards: 91.62300, mean: 0.09072
[32m[0906 18-15-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10934, current rewards: 97.39505, mean: 0.09188
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10929, current rewards: 102.73497, mean: 0.09255
[32m[0906 18-15-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10923, current rewards: 108.53170, mean: 0.09356
[32m[0906 18-15-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10913, current rewards: 114.32158, mean: 0.09448
[32m[0906 18-15-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10897, current rewards: 120.11908, mean: 0.09533
[32m[0906 18-15-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10880, current rewards: 125.91216, mean: 0.09612
[32m[0906 18-15-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10864, current rewards: 131.70991, mean: 0.09685
[32m[0906 18-15-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10852, current rewards: 137.49792, mean: 0.09752
[32m[0906 18-16-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10838, current rewards: 138.45781, mean: 0.09483
[32m[0906 18-16-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10834, current rewards: 144.38822, mean: 0.09562
[32m[0906 18-16-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10835, current rewards: 150.03340, mean: 0.09618
[32m[0906 18-16-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10835, current rewards: 155.68142, mean: 0.09670
[32m[0906 18-16-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10834, current rewards: 162.69874, mean: 0.09801
[32m[0906 18-16-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10834, current rewards: 168.34445, mean: 0.09845
[32m[0906 18-16-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10832, current rewards: 173.97922, mean: 0.09885
[32m[0906 18-16-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10830, current rewards: 179.62599, mean: 0.09924
[32m[0906 18-16-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10831, current rewards: 185.27045, mean: 0.09961
[32m[0906 18-16-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10830, current rewards: 191.23621, mean: 0.10012
[32m[0906 18-16-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10826, current rewards: 196.93167, mean: 0.10048
[32m[0906 18-17-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10818, current rewards: 202.62064, mean: 0.10081
[32m[0906 18-17-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10810, current rewards: 208.31594, mean: 0.10112
[32m[0906 18-17-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10802, current rewards: 214.00272, mean: 0.10142
[32m[0906 18-17-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10795, current rewards: 209.40304, mean: 0.09695
[32m[0906 18-17-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10787, current rewards: 215.11023, mean: 0.09733
[32m[0906 18-17-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10781, current rewards: 220.80969, mean: 0.09770
[32m[0906 18-17-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10780, current rewards: 226.09718, mean: 0.09788
[32m[0906 18-17-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10776, current rewards: 231.83545, mean: 0.09824
[32m[0906 18-17-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10769, current rewards: 237.57869, mean: 0.09858
[32m[0906 18-17-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10762, current rewards: 237.95016, mean: 0.09673
[32m[0906 18-17-53 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-17-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-17-53 @MBExp.py:227][0m Rewards obtained: [242.43331403847037], Lows: [11], Highs: [22], Total time: 13634.825424000002
[32m[0906 18-19-50 @MBExp.py:144][0m ####################################################################
[32m[0906 18-19-50 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 18-19-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11062, current rewards: 1.23995, mean: 0.12399
[32m[0906 18-19-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11171, current rewards: 8.15531, mean: 0.13592
[32m[0906 18-20-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11166, current rewards: 13.78432, mean: 0.12531
[32m[0906 18-20-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11154, current rewards: 19.41314, mean: 0.12133
[32m[0906 18-20-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11164, current rewards: 18.42185, mean: 0.08772
[32m[0906 18-20-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11159, current rewards: 6.70499, mean: 0.02579
[32m[0906 18-20-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11156, current rewards: -10.04045, mean: -0.03239
[32m[0906 18-20-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11150, current rewards: -25.03754, mean: -0.06955
[32m[0906 18-20-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11102, current rewards: -35.84043, mean: -0.08742
[32m[0906 18-20-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11073, current rewards: -50.95381, mean: -0.11077
[32m[0906 18-20-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11052, current rewards: -63.82476, mean: -0.12515
[32m[0906 18-20-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11036, current rewards: -73.89016, mean: -0.13195
[32m[0906 18-20-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11024, current rewards: -68.15310, mean: -0.11173
[32m[0906 18-21-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11011, current rewards: -62.41921, mean: -0.09457
[32m[0906 18-21-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11001, current rewards: -56.68235, mean: -0.07983
[32m[0906 18-21-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10997, current rewards: -50.94442, mean: -0.06703
[32m[0906 18-21-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10989, current rewards: -45.20888, mean: -0.05581
[32m[0906 18-21-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10978, current rewards: -49.33043, mean: -0.05736
[32m[0906 18-21-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10974, current rewards: -43.00789, mean: -0.04726
[32m[0906 18-21-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10968, current rewards: -36.68567, mean: -0.03821
[32m[0906 18-21-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10960, current rewards: -30.38171, mean: -0.03008
[32m[0906 18-21-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10958, current rewards: -24.05817, mean: -0.02270
[32m[0906 18-21-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10950, current rewards: -17.81948, mean: -0.01605
[32m[0906 18-21-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10942, current rewards: -11.58851, mean: -0.00999
[32m[0906 18-22-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10926, current rewards: -5.33814, mean: -0.00441
[32m[0906 18-22-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10906, current rewards: 0.90492, mean: 0.00072
[32m[0906 18-22-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10887, current rewards: 1.79424, mean: 0.00137
[32m[0906 18-22-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10873, current rewards: 8.57206, mean: 0.00630
[32m[0906 18-22-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10858, current rewards: 15.34930, mean: 0.01089
[32m[0906 18-22-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10843, current rewards: 21.39098, mean: 0.01465
[32m[0906 18-22-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10839, current rewards: 27.46732, mean: 0.01819
[32m[0906 18-22-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10837, current rewards: 33.52360, mean: 0.02149
[32m[0906 18-22-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10834, current rewards: 39.59005, mean: 0.02459
[32m[0906 18-22-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10834, current rewards: 34.70300, mean: 0.02091
[32m[0906 18-22-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10832, current rewards: 40.20667, mean: 0.02351
[32m[0906 18-23-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10831, current rewards: 45.70877, mean: 0.02597
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10831, current rewards: 51.21099, mean: 0.02829
[32m[0906 18-23-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10830, current rewards: 56.40940, mean: 0.03033
[32m[0906 18-23-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10827, current rewards: 57.48111, mean: 0.03009
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10824, current rewards: 63.67977, mean: 0.03249
[32m[0906 18-23-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10815, current rewards: 70.96229, mean: 0.03530
[32m[0906 18-23-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10807, current rewards: 78.22310, mean: 0.03797
[32m[0906 18-23-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10800, current rewards: 85.49517, mean: 0.04052
[32m[0906 18-23-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10793, current rewards: 92.75240, mean: 0.04294
[32m[0906 18-23-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10785, current rewards: 100.02523, mean: 0.04526
[32m[0906 18-23-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10778, current rewards: 107.27985, mean: 0.04747
[32m[0906 18-24-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10776, current rewards: 113.81039, mean: 0.04927
[32m[0906 18-24-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10772, current rewards: 119.16431, mean: 0.05049
[32m[0906 18-24-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10768, current rewards: 124.51974, mean: 0.05167
[32m[0906 18-24-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10763, current rewards: 129.87852, mean: 0.05280
[32m[0906 18-24-20 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-24-20 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-24-20 @MBExp.py:227][0m Rewards obtained: [134.16152975107963], Lows: [81], Highs: [16], Total time: 13904.536756000003
[32m[0906 18-26-20 @MBExp.py:144][0m ####################################################################
[32m[0906 18-26-20 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 18-26-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11134, current rewards: -3.87973, mean: -0.38797
[32m[0906 18-26-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11184, current rewards: 1.92084, mean: 0.03201
[32m[0906 18-26-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11221, current rewards: 7.43805, mean: 0.06762
[32m[0906 18-26-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11227, current rewards: 12.95188, mean: 0.08095
[32m[0906 18-26-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11208, current rewards: 18.06745, mean: 0.08604
[32m[0906 18-26-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11210, current rewards: 23.80034, mean: 0.09154
[32m[0906 18-26-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11204, current rewards: 29.54030, mean: 0.09529
[32m[0906 18-27-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11158, current rewards: 35.27596, mean: 0.09799
[32m[0906 18-27-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11116, current rewards: 41.00872, mean: 0.10002
[32m[0906 18-27-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11080, current rewards: 46.74275, mean: 0.10161
[32m[0906 18-27-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11049, current rewards: 52.47974, mean: 0.10290
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11034, current rewards: 58.21750, mean: 0.10396
[32m[0906 18-27-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11016, current rewards: 59.50353, mean: 0.09755
[32m[0906 18-27-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11010, current rewards: 65.15924, mean: 0.09873
[32m[0906 18-27-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11003, current rewards: 70.82505, mean: 0.09975
[32m[0906 18-27-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10989, current rewards: 76.49191, mean: 0.10065
[32m[0906 18-27-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10975, current rewards: 82.15337, mean: 0.10142
[32m[0906 18-27-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10968, current rewards: 87.81825, mean: 0.10211
[32m[0906 18-27-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10959, current rewards: 83.13575, mean: 0.09136
[32m[0906 18-28-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10948, current rewards: 88.81701, mean: 0.09252
[32m[0906 18-28-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10941, current rewards: 94.33086, mean: 0.09340
[32m[0906 18-28-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10935, current rewards: 99.89637, mean: 0.09424
[32m[0906 18-28-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10929, current rewards: 105.57541, mean: 0.09511
[32m[0906 18-28-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10917, current rewards: 111.25354, mean: 0.09591
[32m[0906 18-28-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10898, current rewards: 116.93267, mean: 0.09664
[32m[0906 18-28-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10882, current rewards: 112.10743, mean: 0.08897
[32m[0906 18-28-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10868, current rewards: 117.63677, mean: 0.08980
[32m[0906 18-28-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10853, current rewards: 123.16659, mean: 0.09056
[32m[0906 18-28-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10839, current rewards: 128.69548, mean: 0.09127
[32m[0906 18-28-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10827, current rewards: 133.98862, mean: 0.09177
[32m[0906 18-29-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10827, current rewards: 139.57160, mean: 0.09243
[32m[0906 18-29-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10826, current rewards: 145.15183, mean: 0.09305
[32m[0906 18-29-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10827, current rewards: 150.73299, mean: 0.09362
[32m[0906 18-29-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10827, current rewards: 156.31201, mean: 0.09416
[32m[0906 18-29-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10826, current rewards: 161.89266, mean: 0.09467
[32m[0906 18-29-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10828, current rewards: 167.47745, mean: 0.09516
[32m[0906 18-29-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10827, current rewards: 173.06044, mean: 0.09561
[32m[0906 18-29-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10827, current rewards: 178.60519, mean: 0.09602
[32m[0906 18-29-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10829, current rewards: 178.14933, mean: 0.09327
[32m[0906 18-29-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10825, current rewards: 183.67855, mean: 0.09371
[32m[0906 18-29-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10816, current rewards: 189.20807, mean: 0.09413
[32m[0906 18-30-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10809, current rewards: 194.72989, mean: 0.09453
[32m[0906 18-30-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10800, current rewards: 200.25637, mean: 0.09491
[32m[0906 18-30-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10793, current rewards: 205.78623, mean: 0.09527
[32m[0906 18-30-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10786, current rewards: 211.31050, mean: 0.09562
[32m[0906 18-30-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10778, current rewards: 216.84129, mean: 0.09595
[32m[0906 18-30-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10776, current rewards: 222.36804, mean: 0.09626
[32m[0906 18-30-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10773, current rewards: 227.88769, mean: 0.09656
[32m[0906 18-30-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10766, current rewards: 233.41288, mean: 0.09685
[32m[0906 18-30-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10760, current rewards: 238.93783, mean: 0.09713
[32m[0906 18-30-49 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-30-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-30-49 @MBExp.py:227][0m Rewards obtained: [232.75693062365036], Lows: [16], Highs: [15], Total time: 14174.189406000003
[32m[0906 18-32-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-32-51 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 18-32-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11192, current rewards: -6.63211, mean: -0.66321
[32m[0906 18-32-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11246, current rewards: -1.53645, mean: -0.02561
[32m[0906 18-33-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11219, current rewards: 3.50978, mean: 0.03191
[32m[0906 18-33-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11234, current rewards: 8.14080, mean: 0.05088
[32m[0906 18-33-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11233, current rewards: 12.06431, mean: 0.05745
[32m[0906 18-33-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11230, current rewards: 16.06497, mean: 0.06179
[32m[0906 18-33-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11200, current rewards: 9.59169, mean: 0.03094
[32m[0906 18-33-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11147, current rewards: 15.03640, mean: 0.04177
[32m[0906 18-33-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11104, current rewards: 20.57663, mean: 0.05019
[32m[0906 18-33-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11079, current rewards: 26.11639, mean: 0.05677
[32m[0906 18-33-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11050, current rewards: 31.65522, mean: 0.06207
[32m[0906 18-33-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11029, current rewards: 37.19525, mean: 0.06642
[32m[0906 18-33-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11018, current rewards: 42.82050, mean: 0.07020
[32m[0906 18-34-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11006, current rewards: 48.36944, mean: 0.07329
[32m[0906 18-34-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10991, current rewards: 53.91735, mean: 0.07594
[32m[0906 18-34-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10985, current rewards: 59.46458, mean: 0.07824
[32m[0906 18-34-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10974, current rewards: 65.01566, mean: 0.08027
[32m[0906 18-34-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10964, current rewards: 70.56386, mean: 0.08205
[32m[0906 18-34-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10958, current rewards: 76.10996, mean: 0.08364
[32m[0906 18-34-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10951, current rewards: 81.65409, mean: 0.08506
[32m[0906 18-34-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10945, current rewards: 88.81252, mean: 0.08793
[32m[0906 18-34-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10942, current rewards: 94.40700, mean: 0.08906
[32m[0906 18-34-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10937, current rewards: 95.55578, mean: 0.08609
[32m[0906 18-34-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10915, current rewards: 100.05729, mean: 0.08626
[32m[0906 18-35-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10899, current rewards: 105.57815, mean: 0.08725
[32m[0906 18-35-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10881, current rewards: 111.09862, mean: 0.08817
[32m[0906 18-35-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10866, current rewards: 116.61849, mean: 0.08902
[32m[0906 18-35-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10853, current rewards: 122.14081, mean: 0.08981
[32m[0906 18-35-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10840, current rewards: 127.50253, mean: 0.09043
[32m[0906 18-35-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10829, current rewards: 132.65004, mean: 0.09086
[32m[0906 18-35-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10831, current rewards: 138.08761, mean: 0.09145
[32m[0906 18-35-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10831, current rewards: 143.53505, mean: 0.09201
[32m[0906 18-35-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10831, current rewards: 148.97355, mean: 0.09253
[32m[0906 18-35-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10831, current rewards: 154.14768, mean: 0.09286
[32m[0906 18-35-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10830, current rewards: 159.58002, mean: 0.09332
[32m[0906 18-36-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10828, current rewards: 165.01414, mean: 0.09376
[32m[0906 18-36-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10830, current rewards: 170.44975, mean: 0.09417
[32m[0906 18-36-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10829, current rewards: 175.96634, mean: 0.09461
[32m[0906 18-36-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10830, current rewards: 181.42564, mean: 0.09499
[32m[0906 18-36-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10828, current rewards: 186.88819, mean: 0.09535
[32m[0906 18-36-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10820, current rewards: 186.86039, mean: 0.09297
[32m[0906 18-36-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10812, current rewards: 191.85270, mean: 0.09313
[32m[0906 18-36-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10805, current rewards: 196.83802, mean: 0.09329
[32m[0906 18-36-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10796, current rewards: 201.83146, mean: 0.09344
[32m[0906 18-36-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10788, current rewards: 206.81906, mean: 0.09358
[32m[0906 18-36-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10783, current rewards: 212.38276, mean: 0.09397
[32m[0906 18-37-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10782, current rewards: 217.38562, mean: 0.09411
[32m[0906 18-37-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10778, current rewards: 222.39401, mean: 0.09423
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10774, current rewards: 227.40035, mean: 0.09436
[32m[0906 18-37-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10767, current rewards: 232.39992, mean: 0.09447
[32m[0906 18-37-21 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-37-21 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-37-21 @MBExp.py:227][0m Rewards obtained: [221.19389103624187], Lows: [13], Highs: [17], Total time: 14444.011208000004
[32m[0906 18-39-25 @MBExp.py:144][0m ####################################################################
[32m[0906 18-39-25 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 18-39-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11187, current rewards: -4.33286, mean: -0.43329
[32m[0906 18-39-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11276, current rewards: 3.45905, mean: 0.05765
[32m[0906 18-39-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11254, current rewards: 9.64902, mean: 0.08772
[32m[0906 18-39-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11256, current rewards: 15.83981, mean: 0.09900
[32m[0906 18-39-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11267, current rewards: 21.76971, mean: 0.10367
[32m[0906 18-39-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11243, current rewards: 28.02068, mean: 0.10777
[32m[0906 18-40-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11173, current rewards: 34.27366, mean: 0.11056
[32m[0906 18-40-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11131, current rewards: 40.52397, mean: 0.11257
[32m[0906 18-40-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11095, current rewards: 46.77427, mean: 0.11408
[32m[0906 18-40-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11067, current rewards: 47.26742, mean: 0.10276
[32m[0906 18-40-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11046, current rewards: 52.98449, mean: 0.10389
[32m[0906 18-40-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11024, current rewards: 58.69489, mean: 0.10481
[32m[0906 18-40-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11003, current rewards: 64.03014, mean: 0.10497
[32m[0906 18-40-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10991, current rewards: 69.72498, mean: 0.10564
[32m[0906 18-40-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10976, current rewards: 75.39191, mean: 0.10619
[32m[0906 18-40-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10963, current rewards: 81.05555, mean: 0.10665
[32m[0906 18-40-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10955, current rewards: 86.72122, mean: 0.10706
[32m[0906 18-41-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10945, current rewards: 92.38774, mean: 0.10743
[32m[0906 18-41-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10937, current rewards: 98.05011, mean: 0.10775
[32m[0906 18-41-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10934, current rewards: 103.71761, mean: 0.10804
[32m[0906 18-41-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10927, current rewards: 109.44451, mean: 0.10836
[32m[0906 18-41-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10920, current rewards: 106.21319, mean: 0.10020
[32m[0906 18-41-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10906, current rewards: 111.95636, mean: 0.10086
[32m[0906 18-41-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10887, current rewards: 117.70658, mean: 0.10147
[32m[0906 18-41-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10868, current rewards: 123.44914, mean: 0.10202
[32m[0906 18-41-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10854, current rewards: 129.18646, mean: 0.10253
[32m[0906 18-41-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10839, current rewards: 126.47202, mean: 0.09654
[32m[0906 18-41-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10826, current rewards: 134.59776, mean: 0.09897
[32m[0906 18-41-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10815, current rewards: 142.67205, mean: 0.10119
[32m[0906 18-42-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10808, current rewards: 145.40415, mean: 0.09959
[32m[0906 18-42-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10809, current rewards: 95.40415, mean: 0.06318
[32m[0906 18-42-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10810, current rewards: 45.40415, mean: 0.02911
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10810, current rewards: -4.59585, mean: -0.00285
[32m[0906 18-42-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10811, current rewards: -54.59585, mean: -0.03289
[32m[0906 18-42-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10813, current rewards: -104.59585, mean: -0.06117
[32m[0906 18-42-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10813, current rewards: -154.59585, mean: -0.08784
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10816, current rewards: -204.59585, mean: -0.11304
[32m[0906 18-42-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10817, current rewards: -254.59585, mean: -0.13688
[32m[0906 18-42-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10817, current rewards: -304.59585, mean: -0.15947
[32m[0906 18-42-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10815, current rewards: -354.59585, mean: -0.18092
[32m[0906 18-43-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10807, current rewards: -404.59585, mean: -0.20129
[32m[0906 18-43-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10800, current rewards: -454.59585, mean: -0.22068
[32m[0906 18-43-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10793, current rewards: -504.59585, mean: -0.23914
[32m[0906 18-43-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10786, current rewards: -554.59585, mean: -0.25676
[32m[0906 18-43-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10779, current rewards: -604.59585, mean: -0.27357
[32m[0906 18-43-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10775, current rewards: -654.59585, mean: -0.28964
[32m[0906 18-43-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10775, current rewards: -704.59585, mean: -0.30502
[32m[0906 18-43-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10771, current rewards: -754.59585, mean: -0.31974
[32m[0906 18-43-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10767, current rewards: -804.59585, mean: -0.33386
[32m[0906 18-43-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10762, current rewards: -854.59585, mean: -0.34740
[32m[0906 18-43-55 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-43-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-43-55 @MBExp.py:227][0m Rewards obtained: [-894.5958495955729], Lows: [10], Highs: [1053], Total time: 14713.747673000003
[32m[0906 18-46-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-46-02 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 18-46-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11343, current rewards: -5.45210, mean: -0.54521
[32m[0906 18-46-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11376, current rewards: 1.87878, mean: 0.03131
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11365, current rewards: 8.65653, mean: 0.07870
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11354, current rewards: 15.44079, mean: 0.09650
[32m[0906 18-46-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11362, current rewards: 22.22615, mean: 0.10584
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11296, current rewards: 28.44747, mean: 0.10941
[32m[0906 18-46-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11233, current rewards: 35.26032, mean: 0.11374
[32m[0906 18-46-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11196, current rewards: 42.05965, mean: 0.11683
[32m[0906 18-46-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11155, current rewards: 48.86732, mean: 0.11919
[32m[0906 18-46-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11123, current rewards: 55.66910, mean: 0.12102
[32m[0906 18-46-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11105, current rewards: 62.47468, mean: 0.12250
[32m[0906 18-47-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11083, current rewards: 69.27450, mean: 0.12370
[32m[0906 18-47-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11065, current rewards: 76.07264, mean: 0.12471
[32m[0906 18-47-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11054, current rewards: 83.62511, mean: 0.12670
[32m[0906 18-47-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11042, current rewards: 90.16304, mean: 0.12699
[32m[0906 18-47-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11036, current rewards: 96.63094, mean: 0.12715
[32m[0906 18-47-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11035, current rewards: 103.07309, mean: 0.12725
[32m[0906 18-47-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11037, current rewards: 109.51708, mean: 0.12735
[32m[0906 18-47-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11031, current rewards: 115.96017, mean: 0.12743
[32m[0906 18-47-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11029, current rewards: 122.40073, mean: 0.12750
[32m[0906 18-47-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11023, current rewards: 128.84345, mean: 0.12757
[32m[0906 18-47-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11013, current rewards: 124.80545, mean: 0.11774
[32m[0906 18-48-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10995, current rewards: 130.83363, mean: 0.11787
[32m[0906 18-48-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10977, current rewards: 136.64423, mean: 0.11780
[32m[0906 18-48-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10959, current rewards: 142.45797, mean: 0.11773
[32m[0906 18-48-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10944, current rewards: 148.26541, mean: 0.11767
[32m[0906 18-48-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10928, current rewards: 154.07638, mean: 0.11762
[32m[0906 18-48-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10913, current rewards: 159.88543, mean: 0.11756
[32m[0906 18-48-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10901, current rewards: 165.69947, mean: 0.11752
[32m[0906 18-48-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10895, current rewards: 171.51060, mean: 0.11747
[32m[0906 18-48-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10894, current rewards: 172.64050, mean: 0.11433
[32m[0906 18-48-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10896, current rewards: 183.41723, mean: 0.11758
[32m[0906 18-48-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10896, current rewards: 194.17195, mean: 0.12060
[32m[0906 18-49-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10897, current rewards: 204.95024, mean: 0.12346
[32m[0906 18-49-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10897, current rewards: 215.73519, mean: 0.12616
[32m[0906 18-49-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10894, current rewards: 226.50227, mean: 0.12869
[32m[0906 18-49-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10895, current rewards: 237.28013, mean: 0.13109
[32m[0906 18-49-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10894, current rewards: 235.34032, mean: 0.12653
[32m[0906 18-49-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10893, current rewards: 242.65265, mean: 0.12704
[32m[0906 18-49-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10889, current rewards: 249.96708, mean: 0.12753
[32m[0906 18-49-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10879, current rewards: 257.27918, mean: 0.12800
[32m[0906 18-49-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10870, current rewards: 264.59262, mean: 0.12844
[32m[0906 18-49-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10864, current rewards: 271.91559, mean: 0.12887
[32m[0906 18-49-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10857, current rewards: 279.22840, mean: 0.12927
[32m[0906 18-50-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10849, current rewards: 286.54297, mean: 0.12966
[32m[0906 18-50-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10843, current rewards: 293.86050, mean: 0.13003
[32m[0906 18-50-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10845, current rewards: 301.17081, mean: 0.13038
[32m[0906 18-50-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10838, current rewards: 308.48059, mean: 0.13071
[32m[0906 18-50-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10833, current rewards: 304.37897, mean: 0.12630
[32m[0906 18-50-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10826, current rewards: 310.66914, mean: 0.12629
[32m[0906 18-50-33 @Agent.py:117][0m Average action selection time: 0.1082
[32m[0906 18-50-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-50-33 @MBExp.py:227][0m Rewards obtained: [315.7024812234477], Lows: [16], Highs: [10], Total time: 14985.028976000003
[32m[0906 18-52-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-52-42 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 18-52-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11298, current rewards: -4.26615, mean: -0.42662
[32m[0906 18-52-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11371, current rewards: 1.89915, mean: 0.03165
[32m[0906 18-52-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11334, current rewards: 7.54534, mean: 0.06859
[32m[0906 18-53-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11333, current rewards: 13.18464, mean: 0.08240
[32m[0906 18-53-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11299, current rewards: 18.81727, mean: 0.08961
[32m[0906 18-53-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11224, current rewards: 23.79263, mean: 0.09151
[32m[0906 18-53-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11172, current rewards: 29.36780, mean: 0.09473
[32m[0906 18-53-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11134, current rewards: 34.94498, mean: 0.09707
[32m[0906 18-53-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11108, current rewards: 40.50998, mean: 0.09880
[32m[0906 18-53-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11084, current rewards: 46.52131, mean: 0.10113
[32m[0906 18-53-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11063, current rewards: 52.17354, mean: 0.10230
[32m[0906 18-53-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11046, current rewards: 57.82933, mean: 0.10327
[32m[0906 18-53-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11035, current rewards: 63.48348, mean: 0.10407
[32m[0906 18-53-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11020, current rewards: 69.51377, mean: 0.10532
[32m[0906 18-54-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11005, current rewards: 75.10667, mean: 0.10578
[32m[0906 18-54-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10997, current rewards: 68.22721, mean: 0.08977
[32m[0906 18-54-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10993, current rewards: 74.46322, mean: 0.09193
[32m[0906 18-54-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10982, current rewards: 80.69875, mean: 0.09384
[32m[0906 18-54-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10980, current rewards: 86.93525, mean: 0.09553
[32m[0906 18-54-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10976, current rewards: 93.16736, mean: 0.09705
[32m[0906 18-54-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10968, current rewards: 93.59134, mean: 0.09266
[32m[0906 18-54-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10948, current rewards: 99.54831, mean: 0.09391
[32m[0906 18-54-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10927, current rewards: 105.40643, mean: 0.09496
[32m[0906 18-54-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10908, current rewards: 111.08062, mean: 0.09576
[32m[0906 18-54-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10891, current rewards: 116.74847, mean: 0.09649
[32m[0906 18-55-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10875, current rewards: 122.41858, mean: 0.09716
[32m[0906 18-55-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10859, current rewards: 128.09278, mean: 0.09778
[32m[0906 18-55-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10849, current rewards: 133.76737, mean: 0.09836
[32m[0906 18-55-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10836, current rewards: 139.22264, mean: 0.09874
[32m[0906 18-55-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10831, current rewards: 144.89064, mean: 0.09924
[32m[0906 18-55-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10835, current rewards: 150.31993, mean: 0.09955
[32m[0906 18-55-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10837, current rewards: 156.00719, mean: 0.10000
[32m[0906 18-55-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10837, current rewards: 161.69199, mean: 0.10043
[32m[0906 18-55-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10840, current rewards: 167.36719, mean: 0.10082
[32m[0906 18-55-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10839, current rewards: 173.04677, mean: 0.10120
[32m[0906 18-55-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10839, current rewards: 178.72853, mean: 0.10155
[32m[0906 18-55-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10842, current rewards: 184.40822, mean: 0.10188
[32m[0906 18-56-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10843, current rewards: 190.09378, mean: 0.10220
[32m[0906 18-56-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10842, current rewards: 185.10619, mean: 0.09691
[32m[0906 18-56-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10840, current rewards: 190.76525, mean: 0.09733
[32m[0906 18-56-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10831, current rewards: 196.42511, mean: 0.09772
[32m[0906 18-56-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10823, current rewards: 202.08717, mean: 0.09810
[32m[0906 18-56-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10816, current rewards: 207.74790, mean: 0.09846
[32m[0906 18-56-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10808, current rewards: 213.41145, mean: 0.09880
[32m[0906 18-56-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10800, current rewards: 219.07508, mean: 0.09913
[32m[0906 18-56-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10797, current rewards: 224.73732, mean: 0.09944
[32m[0906 18-56-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10799, current rewards: 229.94477, mean: 0.09954
[32m[0906 18-56-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10793, current rewards: 230.07001, mean: 0.09749
[32m[0906 18-57-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10788, current rewards: 235.72214, mean: 0.09781
[32m[0906 18-57-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10783, current rewards: 241.37688, mean: 0.09812
[32m[0906 18-57-13 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-57-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-57-13 @MBExp.py:227][0m Rewards obtained: [245.8976399888416], Lows: [11], Highs: [15], Total time: 15255.255515000003
[32m[0906 18-59-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-24 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 18-59-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11196, current rewards: -5.59205, mean: -0.55920
[32m[0906 18-59-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11264, current rewards: 1.15889, mean: 0.01931
[32m[0906 18-59-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11246, current rewards: 7.98865, mean: 0.07262
[32m[0906 18-59-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11250, current rewards: 14.78017, mean: 0.09238
[32m[0906 18-59-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11148, current rewards: 21.88849, mean: 0.10423
[32m[0906 18-59-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11099, current rewards: 28.80790, mean: 0.11080
[32m[0906 18-59-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11077, current rewards: 35.66836, mean: 0.11506
[32m[0906 19-00-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11045, current rewards: 42.69466, mean: 0.11860
[32m[0906 19-00-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11026, current rewards: 49.62742, mean: 0.12104
[32m[0906 19-00-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11006, current rewards: 56.65926, mean: 0.12317
[32m[0906 19-00-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10989, current rewards: 63.68616, mean: 0.12487
[32m[0906 19-00-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10975, current rewards: 59.69357, mean: 0.10660
[32m[0906 19-00-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10972, current rewards: 65.16823, mean: 0.10683
[32m[0906 19-00-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10962, current rewards: 70.63785, mean: 0.10703
[32m[0906 19-00-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10950, current rewards: 76.10712, mean: 0.10719
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10945, current rewards: 81.57183, mean: 0.10733
[32m[0906 19-00-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10938, current rewards: 87.04228, mean: 0.10746
[32m[0906 19-00-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10933, current rewards: 92.51000, mean: 0.10757
[32m[0906 19-01-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10931, current rewards: 97.98025, mean: 0.10767
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10928, current rewards: 103.44897, mean: 0.10776
[32m[0906 19-01-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10926, current rewards: 108.91143, mean: 0.10783
[32m[0906 19-01-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10921, current rewards: 114.34278, mean: 0.10787
[32m[0906 19-01-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10904, current rewards: 119.81203, mean: 0.10794
[32m[0906 19-01-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10889, current rewards: 123.16474, mean: 0.10618
[32m[0906 19-01-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10876, current rewards: 120.64592, mean: 0.09971
[32m[0906 19-01-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10861, current rewards: 126.42042, mean: 0.10033
[32m[0906 19-01-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10846, current rewards: 132.18943, mean: 0.10091
[32m[0906 19-01-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10835, current rewards: 137.95995, mean: 0.10144
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10822, current rewards: 138.29965, mean: 0.09808
[32m[0906 19-02-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10823, current rewards: 144.42360, mean: 0.09892
[32m[0906 19-02-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10827, current rewards: 150.71824, mean: 0.09981
[32m[0906 19-02-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10828, current rewards: 156.99855, mean: 0.10064
[32m[0906 19-02-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10831, current rewards: 163.28854, mean: 0.10142
[32m[0906 19-02-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10830, current rewards: 169.57168, mean: 0.10215
[32m[0906 19-02-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10831, current rewards: 175.84074, mean: 0.10283
[32m[0906 19-02-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10834, current rewards: 182.12252, mean: 0.10348
[32m[0906 19-02-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10834, current rewards: 188.40191, mean: 0.10409
[32m[0906 19-02-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10835, current rewards: 194.72536, mean: 0.10469
[32m[0906 19-02-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10838, current rewards: 201.01137, mean: 0.10524
[32m[0906 19-02-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10833, current rewards: 207.29925, mean: 0.10576
[32m[0906 19-03-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10825, current rewards: 213.59374, mean: 0.10627
[32m[0906 19-03-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10817, current rewards: 219.88794, mean: 0.10674
[32m[0906 19-03-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10809, current rewards: 215.50595, mean: 0.10214
[32m[0906 19-03-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10802, current rewards: 221.02007, mean: 0.10232
[32m[0906 19-03-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10796, current rewards: 226.54068, mean: 0.10251
[32m[0906 19-03-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10790, current rewards: 231.99511, mean: 0.10265
[32m[0906 19-03-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10784, current rewards: 237.50062, mean: 0.10281
[32m[0906 19-03-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10779, current rewards: 243.00102, mean: 0.10297
[32m[0906 19-03-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10774, current rewards: 248.50406, mean: 0.10311
[32m[0906 19-03-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10770, current rewards: 254.00746, mean: 0.10326
[32m[0906 19-03-54 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 19-03-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-03-54 @MBExp.py:227][0m Rewards obtained: [258.41426394654417], Lows: [15], Highs: [11], Total time: 15525.234055000003
[32m[0906 19-06-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-06-08 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11289, current rewards: -5.55775, mean: -0.55578
[32m[0906 19-06-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11288, current rewards: -0.17454, mean: -0.00291
[32m[0906 19-06-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11318, current rewards: 5.05096, mean: 0.04592
[32m[0906 19-06-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11212, current rewards: 10.28494, mean: 0.06428
[32m[0906 19-06-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11132, current rewards: 15.50747, mean: 0.07385
[32m[0906 19-06-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11096, current rewards: 20.73977, mean: 0.07977
[32m[0906 19-06-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11063, current rewards: 25.96811, mean: 0.08377
[32m[0906 19-06-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11042, current rewards: 31.19636, mean: 0.08666
[32m[0906 19-06-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11030, current rewards: 36.42690, mean: 0.08885
[32m[0906 19-06-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11012, current rewards: 19.70876, mean: 0.04285
[32m[0906 19-07-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11002, current rewards: 26.94771, mean: 0.05284
[32m[0906 19-07-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10996, current rewards: 34.43755, mean: 0.06150
[32m[0906 19-07-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10989, current rewards: 41.71922, mean: 0.06839
[32m[0906 19-07-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10983, current rewards: 48.99995, mean: 0.07424
[32m[0906 19-07-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10978, current rewards: 56.27593, mean: 0.07926
[32m[0906 19-07-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10979, current rewards: 63.54813, mean: 0.08362
[32m[0906 19-07-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10983, current rewards: 63.01853, mean: 0.07780
[32m[0906 19-07-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10979, current rewards: 68.46898, mean: 0.07962
[32m[0906 19-07-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10975, current rewards: 73.92503, mean: 0.08124
[32m[0906 19-07-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10973, current rewards: 79.52951, mean: 0.08284
[32m[0906 19-08-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10971, current rewards: 85.03519, mean: 0.08419
[32m[0906 19-08-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10951, current rewards: 82.10094, mean: 0.07745
[32m[0906 19-08-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10935, current rewards: 86.15115, mean: 0.07761
[32m[0906 19-08-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10918, current rewards: 91.51120, mean: 0.07889
[32m[0906 19-08-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10902, current rewards: 96.87505, mean: 0.08006
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10890, current rewards: 102.23864, mean: 0.08114
[32m[0906 19-08-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10876, current rewards: 107.60366, mean: 0.08214
[32m[0906 19-08-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10863, current rewards: 112.76937, mean: 0.08292
[32m[0906 19-08-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10856, current rewards: 118.15379, mean: 0.08380
[32m[0906 19-08-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10858, current rewards: 123.53066, mean: 0.08461
[32m[0906 19-08-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10859, current rewards: 118.65737, mean: 0.07858
[32m[0906 19-08-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10863, current rewards: 124.06970, mean: 0.07953
[32m[0906 19-09-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10865, current rewards: 129.48042, mean: 0.08042
[32m[0906 19-09-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10866, current rewards: 134.88817, mean: 0.08126
[32m[0906 19-09-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10869, current rewards: 140.29516, mean: 0.08204
[32m[0906 19-09-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10870, current rewards: 145.59803, mean: 0.08273
[32m[0906 19-09-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10871, current rewards: 150.93609, mean: 0.08339
[32m[0906 19-09-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10874, current rewards: 156.31367, mean: 0.08404
[32m[0906 19-09-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10876, current rewards: 161.68936, mean: 0.08465
[32m[0906 19-09-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10872, current rewards: 167.06526, mean: 0.08524
[32m[0906 19-09-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10865, current rewards: 161.99662, mean: 0.08060
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10857, current rewards: 167.44152, mean: 0.08128
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10849, current rewards: 172.87953, mean: 0.08193
[32m[0906 19-10-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10843, current rewards: 178.31754, mean: 0.08255
[32m[0906 19-10-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10835, current rewards: 184.43982, mean: 0.08346
[32m[0906 19-10-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10828, current rewards: 190.03147, mean: 0.08408
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10824, current rewards: 195.62123, mean: 0.08468
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10820, current rewards: 201.21456, mean: 0.08526
[32m[0906 19-10-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10813, current rewards: 201.51431, mean: 0.08362
[32m[0906 19-10-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10808, current rewards: 206.96416, mean: 0.08413
[32m[0906 19-10-39 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 19-10-39 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-10-39 @MBExp.py:227][0m Rewards obtained: [211.32000351062362], Lows: [26], Highs: [17], Total time: 15796.088776000002
[32m[0906 19-12-55 @MBExp.py:144][0m ####################################################################
[32m[0906 19-12-55 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 19-12-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11463, current rewards: -5.66202, mean: -0.56620
[32m[0906 19-13-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11296, current rewards: -0.12113, mean: -0.00202
[32m[0906 19-13-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11199, current rewards: 6.13539, mean: 0.05578
[32m[0906 19-13-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11112, current rewards: 11.79545, mean: 0.07372
[32m[0906 19-13-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11053, current rewards: 17.45286, mean: 0.08311
[32m[0906 19-13-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11026, current rewards: 23.11066, mean: 0.08889
[32m[0906 19-13-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11013, current rewards: 26.65942, mean: 0.08600
[32m[0906 19-13-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10990, current rewards: 24.10401, mean: 0.06696
[32m[0906 19-13-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10974, current rewards: 29.71945, mean: 0.07249
[32m[0906 19-13-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10972, current rewards: 35.33380, mean: 0.07681
[32m[0906 19-13-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10964, current rewards: 40.70740, mean: 0.07982
[32m[0906 19-13-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10956, current rewards: 46.27190, mean: 0.08263
[32m[0906 19-14-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10956, current rewards: 51.82385, mean: 0.08496
[32m[0906 19-14-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10948, current rewards: 57.37659, mean: 0.08693
[32m[0906 19-14-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10940, current rewards: 62.93079, mean: 0.08863
[32m[0906 19-14-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10937, current rewards: 68.48830, mean: 0.09012
[32m[0906 19-14-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10931, current rewards: 67.13056, mean: 0.08288
[32m[0906 19-14-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10924, current rewards: 72.19151, mean: 0.08394
[32m[0906 19-14-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10922, current rewards: 77.33208, mean: 0.08498
[32m[0906 19-14-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10916, current rewards: 82.80706, mean: 0.08626
[32m[0906 19-14-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10900, current rewards: 87.83523, mean: 0.08697
[32m[0906 19-14-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10884, current rewards: 92.86725, mean: 0.08761
[32m[0906 19-14-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10865, current rewards: 97.89886, mean: 0.08820
[32m[0906 19-15-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10846, current rewards: 102.92360, mean: 0.08873
[32m[0906 19-15-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10833, current rewards: 97.45173, mean: 0.08054
[32m[0906 19-15-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10819, current rewards: 103.38800, mean: 0.08205
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10807, current rewards: 109.05046, mean: 0.08324
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10796, current rewards: 113.89106, mean: 0.08374
[32m[0906 19-15-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10791, current rewards: 119.42104, mean: 0.08470
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10793, current rewards: 124.94457, mean: 0.08558
[32m[0906 19-15-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10796, current rewards: 130.47067, mean: 0.08640
[32m[0906 19-15-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10797, current rewards: 135.99601, mean: 0.08718
[32m[0906 19-15-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10799, current rewards: 141.52037, mean: 0.08790
[32m[0906 19-15-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10803, current rewards: 147.04939, mean: 0.08858
[32m[0906 19-16-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10805, current rewards: 152.57142, mean: 0.08922
[32m[0906 19-16-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10806, current rewards: 158.28388, mean: 0.08993
[32m[0906 19-16-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10809, current rewards: 164.32364, mean: 0.09079
[32m[0906 19-16-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10811, current rewards: 169.65925, mean: 0.09121
[32m[0906 19-16-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10812, current rewards: 175.34211, mean: 0.09180
[32m[0906 19-16-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10809, current rewards: 181.01670, mean: 0.09236
[32m[0906 19-16-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10801, current rewards: 186.69541, mean: 0.09288
[32m[0906 19-16-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10793, current rewards: 192.37356, mean: 0.09339
[32m[0906 19-16-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10787, current rewards: 198.04940, mean: 0.09386
[32m[0906 19-16-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10779, current rewards: 203.72805, mean: 0.09432
[32m[0906 19-16-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10773, current rewards: 209.98237, mean: 0.09501
[32m[0906 19-16-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10767, current rewards: 215.68001, mean: 0.09543
[32m[0906 19-17-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10763, current rewards: 221.37521, mean: 0.09583
[32m[0906 19-17-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10757, current rewards: 227.06991, mean: 0.09622
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10753, current rewards: 232.45373, mean: 0.09645
[32m[0906 19-17-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10749, current rewards: 238.02393, mean: 0.09676
[32m[0906 19-17-24 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 19-17-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-17-24 @MBExp.py:227][0m Rewards obtained: [242.48434888803243], Lows: [10], Highs: [12], Total time: 16065.462241000003
[32m[0906 19-19-43 @MBExp.py:144][0m ####################################################################
[32m[0906 19-19-43 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11254, current rewards: -5.65048, mean: -0.56505
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11330, current rewards: -0.21885, mean: -0.00365
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11154, current rewards: 5.36297, mean: 0.04875
[32m[0906 19-20-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11075, current rewards: 10.81896, mean: 0.06762
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11049, current rewards: 16.27148, mean: 0.07748
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11020, current rewards: 21.71658, mean: 0.08353
[32m[0906 19-20-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10990, current rewards: 27.17426, mean: 0.08766
[32m[0906 19-20-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10979, current rewards: 32.62918, mean: 0.09064
[32m[0906 19-20-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10970, current rewards: 38.07850, mean: 0.09287
[32m[0906 19-20-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10960, current rewards: 43.52949, mean: 0.09463
[32m[0906 19-20-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10958, current rewards: 48.76563, mean: 0.09562
[32m[0906 19-20-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10946, current rewards: 43.79952, mean: 0.07821
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10941, current rewards: 49.30109, mean: 0.08082
[32m[0906 19-20-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10939, current rewards: 54.79058, mean: 0.08302
[32m[0906 19-21-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10935, current rewards: 60.29264, mean: 0.08492
[32m[0906 19-21-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10931, current rewards: 65.79793, mean: 0.08658
[32m[0906 19-21-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10931, current rewards: 71.29829, mean: 0.08802
[32m[0906 19-21-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10930, current rewards: 76.80408, mean: 0.08931
[32m[0906 19-21-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10930, current rewards: 82.30641, mean: 0.09045
[32m[0906 19-21-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10928, current rewards: 87.80473, mean: 0.09146
[32m[0906 19-21-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10910, current rewards: 93.30322, mean: 0.09238
[32m[0906 19-21-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10893, current rewards: 98.80422, mean: 0.09321
[32m[0906 19-21-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10878, current rewards: 98.78126, mean: 0.08899
[32m[0906 19-21-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10866, current rewards: 104.18883, mean: 0.08982
[32m[0906 19-21-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10853, current rewards: 109.59756, mean: 0.09058
[32m[0906 19-22-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10841, current rewards: 115.00630, mean: 0.09127
[32m[0906 19-22-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10829, current rewards: 120.40687, mean: 0.09191
[32m[0906 19-22-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10815, current rewards: 126.02691, mean: 0.09267
[32m[0906 19-22-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10817, current rewards: 131.44447, mean: 0.09322
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10820, current rewards: 136.85271, mean: 0.09373
[32m[0906 19-22-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10822, current rewards: 131.67669, mean: 0.08720
[32m[0906 19-22-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10825, current rewards: 137.46333, mean: 0.08812
[32m[0906 19-22-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10827, current rewards: 143.23249, mean: 0.08896
[32m[0906 19-22-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10828, current rewards: 149.00332, mean: 0.08976
[32m[0906 19-22-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10830, current rewards: 154.77415, mean: 0.09051
[32m[0906 19-22-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10831, current rewards: 160.22817, mean: 0.09104
[32m[0906 19-22-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10832, current rewards: 165.96927, mean: 0.09170
[32m[0906 19-23-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10834, current rewards: 171.70510, mean: 0.09231
[32m[0906 19-23-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10834, current rewards: 177.44142, mean: 0.09290
[32m[0906 19-23-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10830, current rewards: 183.18589, mean: 0.09346
[32m[0906 19-23-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10823, current rewards: 188.92221, mean: 0.09399
[32m[0906 19-23-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10814, current rewards: 184.46232, mean: 0.08954
[32m[0906 19-23-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10808, current rewards: 189.93603, mean: 0.09002
[32m[0906 19-23-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10804, current rewards: 195.40376, mean: 0.09046
[32m[0906 19-23-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10797, current rewards: 200.91284, mean: 0.09091
[32m[0906 19-23-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10790, current rewards: 206.42248, mean: 0.09134
[32m[0906 19-23-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10790, current rewards: 211.92781, mean: 0.09174
[32m[0906 19-23-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10785, current rewards: 217.43366, mean: 0.09213
[32m[0906 19-24-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10780, current rewards: 222.93796, mean: 0.09251
[32m[0906 19-24-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10776, current rewards: 223.69019, mean: 0.09093
[32m[0906 19-24-13 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 19-24-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-24-13 @MBExp.py:227][0m Rewards obtained: [227.963026497948], Lows: [15], Highs: [17], Total time: 16335.538407000004
[32m[0906 19-26-34 @MBExp.py:144][0m ####################################################################
[32m[0906 19-26-34 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 19-26-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11230, current rewards: -5.35007, mean: -0.53501
[32m[0906 19-26-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11003, current rewards: 2.77421, mean: 0.04624
[32m[0906 19-26-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10986, current rewards: 8.19408, mean: 0.07449
[32m[0906 19-26-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10959, current rewards: 14.30594, mean: 0.08941
[32m[0906 19-26-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10939, current rewards: 20.41606, mean: 0.09722
[32m[0906 19-27-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10940, current rewards: 26.52439, mean: 0.10202
[32m[0906 19-27-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10929, current rewards: 32.63559, mean: 0.10528
[32m[0906 19-27-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10930, current rewards: 38.74992, mean: 0.10764
[32m[0906 19-27-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10935, current rewards: 44.86015, mean: 0.10941
[32m[0906 19-27-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10928, current rewards: 44.22641, mean: 0.09614
[32m[0906 19-27-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10930, current rewards: 49.89665, mean: 0.09784
[32m[0906 19-27-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10942, current rewards: 55.87729, mean: 0.09978
[32m[0906 19-27-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10944, current rewards: 61.84907, mean: 0.10139
[32m[0906 19-27-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10938, current rewards: 67.81778, mean: 0.10275
[32m[0906 19-27-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10940, current rewards: 73.79000, mean: 0.10393
[32m[0906 19-27-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10940, current rewards: 80.37366, mean: 0.10575
[32m[0906 19-28-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10941, current rewards: 86.06423, mean: 0.10625
[32m[0906 19-28-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10938, current rewards: 91.74151, mean: 0.10668
[32m[0906 19-28-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10934, current rewards: 98.16284, mean: 0.10787
[32m[0906 19-28-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10911, current rewards: 103.75470, mean: 0.10808
[32m[0906 19-28-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10892, current rewards: 109.34585, mean: 0.10826
[32m[0906 19-28-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10875, current rewards: 114.93027, mean: 0.10842
[32m[0906 19-28-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10859, current rewards: 120.51377, mean: 0.10857
[32m[0906 19-28-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10845, current rewards: 115.79306, mean: 0.09982
[32m[0906 19-28-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10831, current rewards: 121.71946, mean: 0.10059
[32m[0906 19-28-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10820, current rewards: 127.65111, mean: 0.10131
[32m[0906 19-28-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10809, current rewards: 133.94659, mean: 0.10225
[32m[0906 19-29-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10800, current rewards: 139.92608, mean: 0.10289
[32m[0906 19-29-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10804, current rewards: 145.90690, mean: 0.10348
[32m[0906 19-29-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10806, current rewards: 151.88315, mean: 0.10403
[32m[0906 19-29-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10809, current rewards: 157.86596, mean: 0.10455
[32m[0906 19-29-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10815, current rewards: 163.84764, mean: 0.10503
[32m[0906 19-29-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10818, current rewards: 164.15925, mean: 0.10196
[32m[0906 19-29-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10820, current rewards: 169.72113, mean: 0.10224
[32m[0906 19-29-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10822, current rewards: 175.07691, mean: 0.10238
[32m[0906 19-29-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10824, current rewards: 180.76649, mean: 0.10271
[32m[0906 19-29-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10826, current rewards: 186.47756, mean: 0.10303
[32m[0906 19-29-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10829, current rewards: 192.18800, mean: 0.10333
[32m[0906 19-30-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10830, current rewards: 197.88636, mean: 0.10361
[32m[0906 19-30-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10827, current rewards: 203.58727, mean: 0.10387
[32m[0906 19-30-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10821, current rewards: 198.70175, mean: 0.09886
[32m[0906 19-30-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10814, current rewards: 204.71381, mean: 0.09938
[32m[0906 19-30-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10808, current rewards: 210.74418, mean: 0.09988
[32m[0906 19-30-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10803, current rewards: 216.87995, mean: 0.10041
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10795, current rewards: 222.87389, mean: 0.10085
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10791, current rewards: 228.87266, mean: 0.10127
[32m[0906 19-30-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10792, current rewards: 234.86579, mean: 0.10167
[32m[0906 19-30-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10787, current rewards: 240.86603, mean: 0.10206
[32m[0906 19-30-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10783, current rewards: 246.86101, mean: 0.10243
[32m[0906 19-31-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10779, current rewards: 252.86358, mean: 0.10279
[32m[0906 19-31-04 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 19-31-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-31-04 @MBExp.py:227][0m Rewards obtained: [257.66211160911496], Lows: [10], Highs: [17], Total time: 16605.709247000003
[32m[0906 19-33-27 @MBExp.py:144][0m ####################################################################
[32m[0906 19-33-27 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 19-33-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10943, current rewards: -4.74513, mean: -0.47451
[32m[0906 19-33-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10933, current rewards: 1.01759, mean: 0.01696
[32m[0906 19-33-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10977, current rewards: 6.72744, mean: 0.06116
[32m[0906 19-33-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10966, current rewards: 12.43621, mean: 0.07773
[32m[0906 19-33-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10967, current rewards: 18.14802, mean: 0.08642
[32m[0906 19-33-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10962, current rewards: 18.16635, mean: 0.06987
[32m[0906 19-34-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10959, current rewards: 23.81224, mean: 0.07681
[32m[0906 19-34-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10951, current rewards: 29.46085, mean: 0.08184
[32m[0906 19-34-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10946, current rewards: 35.11317, mean: 0.08564
[32m[0906 19-34-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10935, current rewards: 41.05548, mean: 0.08925
[32m[0906 19-34-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10930, current rewards: 46.71864, mean: 0.09161
[32m[0906 19-34-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10930, current rewards: 52.37823, mean: 0.09353
[32m[0906 19-34-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10922, current rewards: 58.03044, mean: 0.09513
[32m[0906 19-34-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10917, current rewards: 58.02464, mean: 0.08792
[32m[0906 19-34-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10918, current rewards: 63.64477, mean: 0.08964
[32m[0906 19-34-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10909, current rewards: 69.26625, mean: 0.09114
[32m[0906 19-34-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10902, current rewards: 74.88292, mean: 0.09245
[32m[0906 19-35-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10903, current rewards: 80.37948, mean: 0.09346
[32m[0906 19-35-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10882, current rewards: 85.98673, mean: 0.09449
[32m[0906 19-35-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10862, current rewards: 91.59670, mean: 0.09541
[32m[0906 19-35-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10848, current rewards: 97.20766, mean: 0.09625
[32m[0906 19-35-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10830, current rewards: 92.30287, mean: 0.08708
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10816, current rewards: 97.87191, mean: 0.08817
[32m[0906 19-35-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10807, current rewards: 103.43406, mean: 0.08917
[32m[0906 19-35-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10794, current rewards: 108.99531, mean: 0.09008
[32m[0906 19-35-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10784, current rewards: 114.32272, mean: 0.09073
[32m[0906 19-35-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10776, current rewards: 119.87250, mean: 0.09151
[32m[0906 19-35-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10771, current rewards: 125.41863, mean: 0.09222
[32m[0906 19-36-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10775, current rewards: 130.96447, mean: 0.09288
[32m[0906 19-36-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10783, current rewards: 136.51316, mean: 0.09350
[32m[0906 19-36-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10788, current rewards: 142.06156, mean: 0.09408
[32m[0906 19-36-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10792, current rewards: 147.61415, mean: 0.09462
[32m[0906 19-36-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10793, current rewards: 142.56344, mean: 0.08855
[32m[0906 19-36-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10796, current rewards: 147.85054, mean: 0.08907
[32m[0906 19-36-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10798, current rewards: 153.46086, mean: 0.08974
[32m[0906 19-36-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10799, current rewards: 159.07571, mean: 0.09038
[32m[0906 19-36-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10800, current rewards: 164.68610, mean: 0.09099
[32m[0906 19-36-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10802, current rewards: 170.29890, mean: 0.09156
[32m[0906 19-36-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10803, current rewards: 175.90927, mean: 0.09210
[32m[0906 19-36-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10799, current rewards: 181.51606, mean: 0.09261
[32m[0906 19-37-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10792, current rewards: 187.13058, mean: 0.09310
[32m[0906 19-37-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10785, current rewards: 193.09211, mean: 0.09373
[32m[0906 19-37-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10777, current rewards: 192.05969, mean: 0.09102
[32m[0906 19-37-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10771, current rewards: 197.65807, mean: 0.09151
[32m[0906 19-37-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10764, current rewards: 203.24464, mean: 0.09197
[32m[0906 19-37-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10762, current rewards: 208.84300, mean: 0.09241
[32m[0906 19-37-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10763, current rewards: 214.43177, mean: 0.09283
[32m[0906 19-37-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10759, current rewards: 220.02746, mean: 0.09323
[32m[0906 19-37-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10754, current rewards: 225.62285, mean: 0.09362
[32m[0906 19-37-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10752, current rewards: 231.21472, mean: 0.09399
[32m[0906 19-37-57 @Agent.py:117][0m Average action selection time: 0.1075
[32m[0906 19-37-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-37-57 @MBExp.py:227][0m Rewards obtained: [235.75241224840175], Lows: [10], Highs: [21], Total time: 16875.182081000003
[32m[0906 19-40-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-40-22 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 19-40-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10971, current rewards: -3.94993, mean: -0.39499
[32m[0906 19-40-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10950, current rewards: 1.85730, mean: 0.03095
[32m[0906 19-40-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10951, current rewards: 7.37297, mean: 0.06703
[32m[0906 19-40-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10928, current rewards: 12.89400, mean: 0.08059
[32m[0906 19-40-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10924, current rewards: 18.42650, mean: 0.08775
[32m[0906 19-40-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10935, current rewards: 23.95184, mean: 0.09212
[32m[0906 19-40-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10927, current rewards: 29.47018, mean: 0.09507
[32m[0906 19-41-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10923, current rewards: 34.99745, mean: 0.09722
[32m[0906 19-41-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10924, current rewards: 40.89421, mean: 0.09974
[32m[0906 19-41-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10919, current rewards: 46.40218, mean: 0.10087
[32m[0906 19-41-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10912, current rewards: 51.91255, mean: 0.10179
[32m[0906 19-41-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10915, current rewards: 57.43485, mean: 0.10256
[32m[0906 19-41-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10914, current rewards: 62.95605, mean: 0.10321
[32m[0906 19-41-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10914, current rewards: 68.47045, mean: 0.10374
[32m[0906 19-41-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10914, current rewards: 73.98169, mean: 0.10420
[32m[0906 19-41-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10913, current rewards: 79.49229, mean: 0.10460
[32m[0906 19-41-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10916, current rewards: 84.92469, mean: 0.10485
[32m[0906 19-41-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10907, current rewards: 79.80794, mean: 0.09280
[32m[0906 19-42-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10886, current rewards: 85.36423, mean: 0.09381
[32m[0906 19-42-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10868, current rewards: 90.91515, mean: 0.09470
[32m[0906 19-42-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10854, current rewards: 96.46663, mean: 0.09551
[32m[0906 19-42-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10840, current rewards: 102.01942, mean: 0.09624
[32m[0906 19-42-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10828, current rewards: 107.57605, mean: 0.09692
[32m[0906 19-42-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10816, current rewards: 113.12900, mean: 0.09753
[32m[0906 19-42-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10805, current rewards: 119.32503, mean: 0.09862
[32m[0906 19-42-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10795, current rewards: 124.85029, mean: 0.09909
[32m[0906 19-42-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10786, current rewards: 130.39363, mean: 0.09954
[32m[0906 19-42-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10787, current rewards: 135.93157, mean: 0.09995
[32m[0906 19-42-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10792, current rewards: 137.82410, mean: 0.09775
[32m[0906 19-43-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10795, current rewards: 143.38784, mean: 0.09821
[32m[0906 19-43-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10800, current rewards: 148.94401, mean: 0.09864
[32m[0906 19-43-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10804, current rewards: 154.50536, mean: 0.09904
[32m[0906 19-43-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10807, current rewards: 160.03681, mean: 0.09940
[32m[0906 19-43-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10809, current rewards: 165.11556, mean: 0.09947
[32m[0906 19-43-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10814, current rewards: 170.68502, mean: 0.09982
[32m[0906 19-43-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10817, current rewards: 176.25294, mean: 0.10014
[32m[0906 19-43-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10820, current rewards: 181.53529, mean: 0.10030
[32m[0906 19-43-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10823, current rewards: 181.52154, mean: 0.09759
[32m[0906 19-43-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10825, current rewards: 187.06738, mean: 0.09794
[32m[0906 19-43-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10823, current rewards: 192.60919, mean: 0.09827
[32m[0906 19-44-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10818, current rewards: 198.16396, mean: 0.09859
[32m[0906 19-44-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10813, current rewards: 203.70572, mean: 0.09889
[32m[0906 19-44-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10807, current rewards: 209.25516, mean: 0.09917
[32m[0906 19-44-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10804, current rewards: 214.80382, mean: 0.09945
[32m[0906 19-44-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10798, current rewards: 220.35132, mean: 0.09971
[32m[0906 19-44-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10799, current rewards: 225.90285, mean: 0.09996
[32m[0906 19-44-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10800, current rewards: 231.44859, mean: 0.10019
[32m[0906 19-44-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10796, current rewards: 237.00091, mean: 0.10042
[32m[0906 19-44-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10791, current rewards: 242.54824, mean: 0.10064
[32m[0906 19-44-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10788, current rewards: 248.16159, mean: 0.10088
[32m[0906 19-44-52 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 19-44-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-44-52 @MBExp.py:227][0m Rewards obtained: [252.60399086320385], Lows: [10], Highs: [5], Total time: 17145.590617
[32m[0906 19-47-21 @MBExp.py:144][0m ####################################################################
[32m[0906 19-47-21 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 19-47-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10825, current rewards: -4.58394, mean: -0.45839
[32m[0906 19-47-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10985, current rewards: 0.91637, mean: 0.01527
[32m[0906 19-47-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11041, current rewards: 6.45280, mean: 0.05866
[32m[0906 19-47-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11055, current rewards: 11.98428, mean: 0.07490
[32m[0906 19-47-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11040, current rewards: 17.51728, mean: 0.08342
[32m[0906 19-47-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11016, current rewards: 23.05221, mean: 0.08866
[32m[0906 19-47-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11003, current rewards: 28.58804, mean: 0.09222
[32m[0906 19-48-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11008, current rewards: 35.06753, mean: 0.09741
[32m[0906 19-48-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11002, current rewards: 40.59632, mean: 0.09902
[32m[0906 19-48-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10992, current rewards: 40.48892, mean: 0.08802
[32m[0906 19-48-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10991, current rewards: 46.12397, mean: 0.09044
[32m[0906 19-48-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10986, current rewards: 51.75765, mean: 0.09242
[32m[0906 19-48-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10983, current rewards: 57.38806, mean: 0.09408
[32m[0906 19-48-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10982, current rewards: 63.02218, mean: 0.09549
[32m[0906 19-48-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10978, current rewards: 68.65245, mean: 0.09669
[32m[0906 19-48-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10975, current rewards: 74.22595, mean: 0.09767
[32m[0906 19-48-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10966, current rewards: 79.47451, mean: 0.09812
[32m[0906 19-48-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10945, current rewards: 2.78335, mean: 0.00324
[32m[0906 19-49-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10924, current rewards: -97.21665, mean: -0.10683
[32m[0906 19-49-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10909, current rewards: -197.21665, mean: -0.20543
[32m[0906 19-49-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10892, current rewards: -297.21665, mean: -0.29427
[32m[0906 19-49-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10877, current rewards: -397.21665, mean: -0.37473
[32m[0906 19-49-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10868, current rewards: -497.21665, mean: -0.44794
[32m[0906 19-49-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10855, current rewards: -597.21665, mean: -0.51484
[32m[0906 19-49-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10844, current rewards: -697.21665, mean: -0.57621
[32m[0906 19-49-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10836, current rewards: -797.21665, mean: -0.63271
[32m[0906 19-49-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10827, current rewards: -897.21665, mean: -0.68490
[32m[0906 19-49-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10825, current rewards: -997.21665, mean: -0.73325
[32m[0906 19-49-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10833, current rewards: -1031.14582, mean: -0.73131
[32m[0906 19-49-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10838, current rewards: -1025.66079, mean: -0.70251
[32m[0906 19-50-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10844, current rewards: -1020.18080, mean: -0.67562
[32m[0906 19-50-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10848, current rewards: -1014.70013, mean: -0.65045
[32m[0906 19-50-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10851, current rewards: -1019.25412, mean: -0.63308
[32m[0906 19-50-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10856, current rewards: -1013.96046, mean: -0.61082
[32m[0906 19-50-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10859, current rewards: -1008.66682, mean: -0.58986
[32m[0906 19-50-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10863, current rewards: -1003.37473, mean: -0.57010
[32m[0906 19-50-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10868, current rewards: -998.08144, mean: -0.55143
[32m[0906 19-50-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10870, current rewards: -992.78243, mean: -0.53375
[32m[0906 19-50-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10873, current rewards: -987.49059, mean: -0.51701
[32m[0906 19-50-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10871, current rewards: -982.19887, mean: -0.50112
[32m[0906 19-51-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10864, current rewards: -976.76021, mean: -0.48595
[32m[0906 19-51-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10858, current rewards: -971.12093, mean: -0.47142
[32m[0906 19-51-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10853, current rewards: -975.90280, mean: -0.46251
[32m[0906 19-51-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10846, current rewards: -970.40552, mean: -0.44926
[32m[0906 19-51-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10842, current rewards: -964.90834, mean: -0.43661
[32m[0906 19-51-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10845, current rewards: -959.40601, mean: -0.42452
[32m[0906 19-51-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10843, current rewards: -953.90723, mean: -0.41295
[32m[0906 19-51-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10837, current rewards: -948.40858, mean: -0.40187
[32m[0906 19-51-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10834, current rewards: -942.91102, mean: -0.39125
[32m[0906 19-51-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10829, current rewards: -938.15054, mean: -0.38136
[32m[0906 19-51-52 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 19-51-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-51-52 @MBExp.py:227][0m Rewards obtained: [-933.7931343651612], Lows: [566], Highs: [15], Total time: 17417.021376
[32m[0906 19-54-23 @MBExp.py:144][0m ####################################################################
[32m[0906 19-54-23 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 19-54-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10870, current rewards: -5.59049, mean: -0.55905
[32m[0906 19-54-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10950, current rewards: 0.05038, mean: 0.00084
[32m[0906 19-54-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10951, current rewards: 5.67064, mean: 0.05155
[32m[0906 19-54-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10969, current rewards: 11.28848, mean: 0.07055
[32m[0906 19-54-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10958, current rewards: 17.20194, mean: 0.08191
[32m[0906 19-54-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10958, current rewards: 22.83514, mean: 0.08783
[32m[0906 19-54-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10963, current rewards: 28.46921, mean: 0.09184
[32m[0906 19-55-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10964, current rewards: 34.18376, mean: 0.09495
[32m[0906 19-55-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10961, current rewards: 39.81087, mean: 0.09710
[32m[0906 19-55-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10958, current rewards: 45.44827, mean: 0.09880
[32m[0906 19-55-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10954, current rewards: 51.07936, mean: 0.10016
[32m[0906 19-55-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10958, current rewards: 51.24939, mean: 0.09152
[32m[0906 19-55-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10954, current rewards: 56.80139, mean: 0.09312
[32m[0906 19-55-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10951, current rewards: 62.35394, mean: 0.09448
[32m[0906 19-55-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10952, current rewards: 67.89473, mean: 0.09563
[32m[0906 19-55-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10945, current rewards: 73.38054, mean: 0.09655
[32m[0906 19-55-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10921, current rewards: 78.54631, mean: 0.09697
[32m[0906 19-55-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10905, current rewards: 71.36917, mean: 0.08299
[32m[0906 19-56-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10887, current rewards: 77.06923, mean: 0.08469
[32m[0906 19-56-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10871, current rewards: 82.76925, mean: 0.08622
[32m[0906 19-56-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10859, current rewards: 88.46698, mean: 0.08759
[32m[0906 19-56-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10842, current rewards: 94.16202, mean: 0.08883
[32m[0906 19-56-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10828, current rewards: 94.16734, mean: 0.08484
[32m[0906 19-56-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10819, current rewards: 99.86738, mean: 0.08609
[32m[0906 19-56-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10808, current rewards: 105.53310, mean: 0.08722
[32m[0906 19-56-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10798, current rewards: 111.22712, mean: 0.08828
[32m[0906 19-56-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10790, current rewards: 116.91948, mean: 0.08925
[32m[0906 19-56-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10785, current rewards: 119.27558, mean: 0.08770
[32m[0906 19-56-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10790, current rewards: 122.80807, mean: 0.08710
[32m[0906 19-57-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10796, current rewards: 128.39254, mean: 0.08794
[32m[0906 19-57-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10799, current rewards: 133.98177, mean: 0.08873
[32m[0906 19-57-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10803, current rewards: 139.56560, mean: 0.08947
[32m[0906 19-57-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10808, current rewards: 145.25760, mean: 0.09022
[32m[0906 19-57-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10813, current rewards: 150.84515, mean: 0.09087
[32m[0906 19-57-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10816, current rewards: 156.43688, mean: 0.09148
[32m[0906 19-57-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10825, current rewards: 162.02077, mean: 0.09206
[32m[0906 19-57-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10828, current rewards: 167.61323, mean: 0.09260
[32m[0906 19-57-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10830, current rewards: 173.20584, mean: 0.09312
[32m[0906 19-57-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10833, current rewards: 178.80031, mean: 0.09361
[32m[0906 19-57-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10830, current rewards: 184.38955, mean: 0.09408
[32m[0906 19-58-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10824, current rewards: 190.50653, mean: 0.09478
[32m[0906 19-58-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10819, current rewards: 196.12103, mean: 0.09520
[32m[0906 19-58-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10813, current rewards: 201.73139, mean: 0.09561
[32m[0906 19-58-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10808, current rewards: 207.34657, mean: 0.09599
[32m[0906 19-58-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10808, current rewards: 202.37610, mean: 0.09157
[32m[0906 19-58-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10811, current rewards: 208.04160, mean: 0.09205
[32m[0906 19-58-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10809, current rewards: 213.73611, mean: 0.09253
[32m[0906 19-58-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10805, current rewards: 219.43149, mean: 0.09298
[32m[0906 19-58-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10801, current rewards: 224.74106, mean: 0.09325
[32m[0906 19-58-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10796, current rewards: 224.86028, mean: 0.09141
[32m[0906 19-58-53 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 19-58-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-58-53 @MBExp.py:227][0m Rewards obtained: [229.3758624940301], Lows: [11], Highs: [26], Total time: 17687.657079
[32m[0906 20-01-25 @MBExp.py:144][0m ####################################################################
[32m[0906 20-01-25 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 20-01-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10817, current rewards: -4.51833, mean: -0.45183
[32m[0906 20-01-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10970, current rewards: 0.95324, mean: 0.01589
[32m[0906 20-01-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10950, current rewards: 6.41828, mean: 0.05835
[32m[0906 20-01-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10954, current rewards: 11.89049, mean: 0.07432
[32m[0906 20-01-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10962, current rewards: 17.36806, mean: 0.08271
[32m[0906 20-01-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10956, current rewards: 22.84065, mean: 0.08785
[32m[0906 20-01-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10951, current rewards: 28.31992, mean: 0.09135
[32m[0906 20-02-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10950, current rewards: 33.79369, mean: 0.09387
[32m[0906 20-02-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10942, current rewards: 39.26843, mean: 0.09578
[32m[0906 20-02-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10945, current rewards: 44.74136, mean: 0.09726
[32m[0906 20-02-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10953, current rewards: 50.21907, mean: 0.09847
[32m[0906 20-02-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10951, current rewards: 55.69288, mean: 0.09945
[32m[0906 20-02-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10951, current rewards: 50.62870, mean: 0.08300
[32m[0906 20-02-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10953, current rewards: 56.43241, mean: 0.08550
[32m[0906 20-02-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10950, current rewards: 62.14855, mean: 0.08753
[32m[0906 20-02-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10946, current rewards: 67.86667, mean: 0.08930
[32m[0906 20-02-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10934, current rewards: 73.58233, mean: 0.09084
[32m[0906 20-02-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10910, current rewards: 79.30064, mean: 0.09221
[32m[0906 20-03-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10889, current rewards: 85.01341, mean: 0.09342
[32m[0906 20-03-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10874, current rewards: 84.39983, mean: 0.08792
[32m[0906 20-03-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10860, current rewards: 90.79577, mean: 0.08990
[32m[0906 20-03-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10845, current rewards: 97.20245, mean: 0.09170
[32m[0906 20-03-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10834, current rewards: 103.60389, mean: 0.09334
[32m[0906 20-03-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10824, current rewards: 111.03332, mean: 0.09572
[32m[0906 20-03-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10813, current rewards: 117.18215, mean: 0.09684
[32m[0906 20-03-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10807, current rewards: 123.33188, mean: 0.09788
[32m[0906 20-03-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10797, current rewards: 129.48206, mean: 0.09884
[32m[0906 20-03-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10795, current rewards: 126.14867, mean: 0.09276
[32m[0906 20-03-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10803, current rewards: 131.65829, mean: 0.09337
[32m[0906 20-04-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10808, current rewards: 137.16807, mean: 0.09395
[32m[0906 20-04-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10814, current rewards: 142.66988, mean: 0.09448
[32m[0906 20-04-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10820, current rewards: 147.66497, mean: 0.09466
[32m[0906 20-04-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10823, current rewards: 143.02296, mean: 0.08883
[32m[0906 20-04-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10828, current rewards: 148.60029, mean: 0.08952
[32m[0906 20-04-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10834, current rewards: 154.16781, mean: 0.09016
[32m[0906 20-04-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10837, current rewards: 159.74288, mean: 0.09076
[32m[0906 20-04-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10843, current rewards: 165.31083, mean: 0.09133
[32m[0906 20-04-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10845, current rewards: 170.87970, mean: 0.09187
[32m[0906 20-04-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10848, current rewards: 176.44865, mean: 0.09238
[32m[0906 20-04-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10847, current rewards: 182.02121, mean: 0.09287
[32m[0906 20-05-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10841, current rewards: 187.58249, mean: 0.09332
[32m[0906 20-05-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10835, current rewards: 193.15281, mean: 0.09376
[32m[0906 20-05-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10831, current rewards: 198.71416, mean: 0.09418
[32m[0906 20-05-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10827, current rewards: 204.27627, mean: 0.09457
[32m[0906 20-05-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10822, current rewards: 209.84911, mean: 0.09495
[32m[0906 20-05-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10823, current rewards: 215.41385, mean: 0.09532
[32m[0906 20-05-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10820, current rewards: 210.25909, mean: 0.09102
[32m[0906 20-05-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10815, current rewards: 215.81940, mean: 0.09145
[32m[0906 20-05-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10812, current rewards: 221.26917, mean: 0.09181
[32m[0906 20-05-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10807, current rewards: 226.92494, mean: 0.09225
[32m[0906 20-05-56 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 20-05-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-05-56 @MBExp.py:227][0m Rewards obtained: [231.45302909152093], Lows: [20], Highs: [11], Total time: 17958.546849000002
[32m[0906 20-08-31 @MBExp.py:144][0m ####################################################################
[32m[0906 20-08-31 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 20-08-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10736, current rewards: -4.20123, mean: -0.42012
[32m[0906 20-08-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10837, current rewards: 1.02519, mean: 0.01709
[32m[0906 20-08-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10900, current rewards: 6.48925, mean: 0.05899
[32m[0906 20-08-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10887, current rewards: 11.95178, mean: 0.07470
[32m[0906 20-08-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10894, current rewards: 17.41374, mean: 0.08292
[32m[0906 20-09-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10908, current rewards: 22.87627, mean: 0.08799
[32m[0906 20-09-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10897, current rewards: 28.94043, mean: 0.09336
[32m[0906 20-09-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10900, current rewards: 34.50280, mean: 0.09584
[32m[0906 20-09-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10906, current rewards: 40.06224, mean: 0.09771
[32m[0906 20-09-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10905, current rewards: 35.48548, mean: 0.07714
[32m[0906 20-09-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10902, current rewards: 42.58203, mean: 0.08349
[32m[0906 20-09-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10904, current rewards: 49.67859, mean: 0.08871
[32m[0906 20-09-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10903, current rewards: 56.77514, mean: 0.09307
[32m[0906 20-09-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10900, current rewards: 63.87169, mean: 0.09678
[32m[0906 20-09-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10900, current rewards: 70.74797, mean: 0.09965
[32m[0906 20-09-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10886, current rewards: 37.78165, mean: 0.04971
[32m[0906 20-09-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10860, current rewards: -12.21835, mean: -0.01508
[32m[0906 20-10-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10841, current rewards: -62.21835, mean: -0.07235
[32m[0906 20-10-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10821, current rewards: -112.21835, mean: -0.12332
[32m[0906 20-10-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10806, current rewards: -162.21835, mean: -0.16898
[32m[0906 20-10-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10791, current rewards: -212.21835, mean: -0.21012
[32m[0906 20-10-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10772, current rewards: -251.17169, mean: -0.23695
[32m[0906 20-10-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10759, current rewards: -245.67861, mean: -0.22133
[32m[0906 20-10-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10748, current rewards: -239.39746, mean: -0.20638
[32m[0906 20-10-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10738, current rewards: -233.75371, mean: -0.19318
[32m[0906 20-10-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10727, current rewards: -228.11308, mean: -0.18104
[32m[0906 20-10-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10720, current rewards: -227.96002, mean: -0.17402
[32m[0906 20-10-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10718, current rewards: -222.67738, mean: -0.16373
[32m[0906 20-11-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10722, current rewards: -217.39738, mean: -0.15418
[32m[0906 20-11-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10729, current rewards: -212.10929, mean: -0.14528
[32m[0906 20-11-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10733, current rewards: -206.82627, mean: -0.13697
[32m[0906 20-11-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10738, current rewards: -201.33125, mean: -0.12906
[32m[0906 20-11-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10743, current rewards: -196.04931, mean: -0.12177
[32m[0906 20-11-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10745, current rewards: -190.75521, mean: -0.11491
[32m[0906 20-11-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10750, current rewards: -185.45557, mean: -0.10845
[32m[0906 20-11-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10754, current rewards: -180.27038, mean: -0.10243
[32m[0906 20-11-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10755, current rewards: -174.96736, mean: -0.09667
[32m[0906 20-11-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10759, current rewards: -169.66637, mean: -0.09122
[32m[0906 20-11-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10762, current rewards: -164.36064, mean: -0.08605
[32m[0906 20-12-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10759, current rewards: -158.72493, mean: -0.08098
[32m[0906 20-12-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10755, current rewards: -153.49663, mean: -0.07637
[32m[0906 20-12-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10750, current rewards: -147.91961, mean: -0.07181
[32m[0906 20-12-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10744, current rewards: -142.33790, mean: -0.06746
[32m[0906 20-12-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10740, current rewards: -136.76869, mean: -0.06332
[32m[0906 20-12-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10736, current rewards: -131.19044, mean: -0.05936
[32m[0906 20-12-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10738, current rewards: -125.60737, mean: -0.05558
[32m[0906 20-12-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10736, current rewards: -120.02934, mean: -0.05196
[32m[0906 20-12-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10731, current rewards: -114.45380, mean: -0.04850
[32m[0906 20-12-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10727, current rewards: -108.87853, mean: -0.04518
[32m[0906 20-12-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10724, current rewards: -99.84972, mean: -0.04059
[32m[0906 20-13-00 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 20-13-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-13-00 @MBExp.py:227][0m Rewards obtained: [-95.66045450890347], Lows: [5], Highs: [334], Total time: 18227.380333
[32m[0906 20-15-36 @MBExp.py:144][0m ####################################################################
[32m[0906 20-15-36 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 20-15-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10841, current rewards: -5.55778, mean: -0.55578
[32m[0906 20-15-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10829, current rewards: 0.11919, mean: 0.00199
[32m[0906 20-15-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10828, current rewards: 5.70894, mean: 0.05190
[32m[0906 20-15-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10850, current rewards: 11.30271, mean: 0.07064
[32m[0906 20-15-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10838, current rewards: 16.89392, mean: 0.08045
[32m[0906 20-16-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10841, current rewards: 22.48786, mean: 0.08649
[32m[0906 20-16-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10846, current rewards: 27.51468, mean: 0.08876
[32m[0906 20-16-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10837, current rewards: 33.17425, mean: 0.09215
[32m[0906 20-16-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10833, current rewards: 38.83027, mean: 0.09471
[32m[0906 20-16-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10834, current rewards: 44.48650, mean: 0.09671
[32m[0906 20-16-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10831, current rewards: 50.13628, mean: 0.09831
[32m[0906 20-16-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10829, current rewards: 55.77889, mean: 0.09961
[32m[0906 20-16-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10830, current rewards: 61.43062, mean: 0.10071
[32m[0906 20-16-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10830, current rewards: 67.09664, mean: 0.10166
[32m[0906 20-16-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10823, current rewards: 72.78308, mean: 0.10251
[32m[0906 20-16-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10801, current rewards: 79.00459, mean: 0.10395
[32m[0906 20-17-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10778, current rewards: 84.63794, mean: 0.10449
[32m[0906 20-17-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10759, current rewards: 90.27465, mean: 0.10497
[32m[0906 20-17-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10743, current rewards: 95.91011, mean: 0.10540
[32m[0906 20-17-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10728, current rewards: 101.55034, mean: 0.10578
[32m[0906 20-17-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10713, current rewards: 107.18425, mean: 0.10612
[32m[0906 20-17-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10704, current rewards: 112.82141, mean: 0.10644
[32m[0906 20-17-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10697, current rewards: 118.45664, mean: 0.10672
[32m[0906 20-17-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10691, current rewards: 124.50321, mean: 0.10733
[32m[0906 20-17-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10685, current rewards: 119.28347, mean: 0.09858
[32m[0906 20-17-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10679, current rewards: 124.39657, mean: 0.09873
[32m[0906 20-17-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10670, current rewards: 129.50930, mean: 0.09886
[32m[0906 20-18-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10678, current rewards: 134.62525, mean: 0.09899
[32m[0906 20-18-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10683, current rewards: 139.73926, mean: 0.09911
[32m[0906 20-18-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10688, current rewards: 134.38426, mean: 0.09204
[32m[0906 20-18-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10693, current rewards: 140.09663, mean: 0.09278
[32m[0906 20-18-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10697, current rewards: 145.34076, mean: 0.09317
[32m[0906 20-18-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10703, current rewards: 150.91882, mean: 0.09374
[32m[0906 20-18-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10707, current rewards: 156.49902, mean: 0.09428
[32m[0906 20-18-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10710, current rewards: 156.32302, mean: 0.09142
[32m[0906 20-18-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10716, current rewards: 161.60016, mean: 0.09182
[32m[0906 20-18-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10719, current rewards: 166.86862, mean: 0.09219
[32m[0906 20-18-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10722, current rewards: 172.13817, mean: 0.09255
[32m[0906 20-19-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10726, current rewards: 177.41893, mean: 0.09289
[32m[0906 20-19-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10723, current rewards: 183.00037, mean: 0.09337
[32m[0906 20-19-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10717, current rewards: 188.50823, mean: 0.09379
[32m[0906 20-19-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10714, current rewards: 196.95555, mean: 0.09561
[32m[0906 20-19-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10708, current rewards: 202.61861, mean: 0.09603
[32m[0906 20-19-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10704, current rewards: 208.28265, mean: 0.09643
[32m[0906 20-19-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10702, current rewards: 213.95088, mean: 0.09681
[32m[0906 20-19-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10706, current rewards: 219.61829, mean: 0.09718
[32m[0906 20-19-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10702, current rewards: 225.28733, mean: 0.09753
[32m[0906 20-19-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10699, current rewards: 230.94633, mean: 0.09786
[32m[0906 20-19-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10695, current rewards: 236.12556, mean: 0.09798
[32m[0906 20-20-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10691, current rewards: 241.77839, mean: 0.09828
[32m[0906 20-20-04 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 20-20-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-20-04 @MBExp.py:227][0m Rewards obtained: [246.30269172806695], Lows: [10], Highs: [12], Total time: 18495.435415
[32m[0906 20-22-43 @MBExp.py:144][0m ####################################################################
[32m[0906 20-22-43 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 20-22-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10932, current rewards: -5.57699, mean: -0.55770
[32m[0906 20-22-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10874, current rewards: -0.06446, mean: -0.00107
[32m[0906 20-22-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10863, current rewards: 5.16442, mean: 0.04695
[32m[0906 20-23-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10872, current rewards: 10.39420, mean: 0.06496
[32m[0906 20-23-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10863, current rewards: 15.62688, mean: 0.07441
[32m[0906 20-23-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10860, current rewards: 20.85754, mean: 0.08022
[32m[0906 20-23-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10866, current rewards: 25.71208, mean: 0.08294
[32m[0906 20-23-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10868, current rewards: 31.03332, mean: 0.08620
[32m[0906 20-23-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10865, current rewards: 36.33833, mean: 0.08863
[32m[0906 20-23-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10879, current rewards: 41.64002, mean: 0.09052
[32m[0906 20-23-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10872, current rewards: 46.94014, mean: 0.09204
[32m[0906 20-23-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10871, current rewards: 43.19691, mean: 0.07714
[32m[0906 20-23-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10876, current rewards: 48.33473, mean: 0.07924
[32m[0906 20-23-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10876, current rewards: 53.46771, mean: 0.08101
[32m[0906 20-24-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10856, current rewards: 58.76963, mean: 0.08277
[32m[0906 20-24-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10835, current rewards: 64.98556, mean: 0.08551
[32m[0906 20-24-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10815, current rewards: 70.35999, mean: 0.08686
[32m[0906 20-24-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10797, current rewards: 75.73417, mean: 0.08806
[32m[0906 20-24-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10787, current rewards: 81.10910, mean: 0.08913
[32m[0906 20-24-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10769, current rewards: 86.48397, mean: 0.09009
[32m[0906 20-24-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10755, current rewards: 86.49262, mean: 0.08564
[32m[0906 20-24-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10750, current rewards: 91.93720, mean: 0.08673
[32m[0906 20-24-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10739, current rewards: 97.38614, mean: 0.08774
[32m[0906 20-24-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10730, current rewards: 102.32947, mean: 0.08822
[32m[0906 20-24-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10720, current rewards: 108.10669, mean: 0.08934
[32m[0906 20-24-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10711, current rewards: 113.88934, mean: 0.09039
[32m[0906 20-25-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10704, current rewards: 119.67132, mean: 0.09135
[32m[0906 20-25-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10711, current rewards: 115.02021, mean: 0.08457
[32m[0906 20-25-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10716, current rewards: 120.23077, mean: 0.08527
[32m[0906 20-25-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10720, current rewards: 125.33022, mean: 0.08584
[32m[0906 20-25-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10725, current rewards: 130.43522, mean: 0.08638
[32m[0906 20-25-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10728, current rewards: 135.72669, mean: 0.08700
[32m[0906 20-25-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10731, current rewards: 140.79777, mean: 0.08745
[32m[0906 20-25-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10736, current rewards: 145.85108, mean: 0.08786
[32m[0906 20-25-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10737, current rewards: 150.90045, mean: 0.08825
[32m[0906 20-25-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10738, current rewards: 155.94755, mean: 0.08861
[32m[0906 20-25-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10742, current rewards: 160.99587, mean: 0.08895
[32m[0906 20-26-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10745, current rewards: 166.04869, mean: 0.08927
[32m[0906 20-26-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10746, current rewards: 171.09879, mean: 0.08958
[32m[0906 20-26-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10743, current rewards: 176.18707, mean: 0.08989
[32m[0906 20-26-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10735, current rewards: 181.79216, mean: 0.09044
[32m[0906 20-26-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10727, current rewards: 169.19681, mean: 0.08213
[32m[0906 20-26-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10722, current rewards: 148.03191, mean: 0.07016
[32m[0906 20-26-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10717, current rewards: 136.32299, mean: 0.06311
[32m[0906 20-26-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10715, current rewards: 116.02710, mean: 0.05250
[32m[0906 20-26-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10718, current rewards: 90.49438, mean: 0.04004
[32m[0906 20-26-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10714, current rewards: 64.62774, mean: 0.02798
[32m[0906 20-26-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10708, current rewards: 72.14682, mean: 0.03057
[32m[0906 20-27-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10704, current rewards: 77.45270, mean: 0.03214
[32m[0906 20-27-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10700, current rewards: 83.10183, mean: 0.03378
[32m[0906 20-27-11 @Agent.py:117][0m Average action selection time: 0.1070
[32m[0906 20-27-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-27-11 @MBExp.py:227][0m Rewards obtained: [78.33159622854645], Lows: [102], Highs: [14], Total time: 18763.622135999998
[32m[0906 20-29-51 @MBExp.py:144][0m ####################################################################
[32m[0906 20-29-51 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 20-29-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10731, current rewards: -4.39774, mean: -0.43977
[32m[0906 20-29-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10853, current rewards: 3.90655, mean: 0.06511
[32m[0906 20-30-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10832, current rewards: 12.37582, mean: 0.11251
[32m[0906 20-30-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10817, current rewards: 20.84333, mean: 0.13027
[32m[0906 20-30-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10837, current rewards: 29.32202, mean: 0.13963
[32m[0906 20-30-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10833, current rewards: 37.80398, mean: 0.14540
[32m[0906 20-30-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10832, current rewards: 45.24791, mean: 0.14596
[32m[0906 20-30-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10823, current rewards: 53.83001, mean: 0.14953
[32m[0906 20-30-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10816, current rewards: 62.61006, mean: 0.15271
[32m[0906 20-30-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10819, current rewards: 71.39057, mean: 0.15520
[32m[0906 20-30-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10813, current rewards: 80.17933, mean: 0.15721
[32m[0906 20-30-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10813, current rewards: 88.97798, mean: 0.15889
[32m[0906 20-30-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10813, current rewards: 97.74649, mean: 0.16024
[32m[0906 20-31-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10795, current rewards: 100.43599, mean: 0.15218
[32m[0906 20-31-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10769, current rewards: 106.12929, mean: 0.14948
[32m[0906 20-31-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10754, current rewards: 112.34636, mean: 0.14782
[32m[0906 20-31-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10734, current rewards: 118.05851, mean: 0.14575
[32m[0906 20-31-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10718, current rewards: 123.77797, mean: 0.14393
[32m[0906 20-31-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10705, current rewards: 129.48813, mean: 0.14229
[32m[0906 20-31-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10693, current rewards: 128.82761, mean: 0.13420
[32m[0906 20-31-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10681, current rewards: 134.48883, mean: 0.13316
[32m[0906 20-31-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10672, current rewards: 140.13723, mean: 0.13220
[32m[0906 20-31-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10666, current rewards: 145.79595, mean: 0.13135
[32m[0906 20-31-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10657, current rewards: 152.34434, mean: 0.13133
[32m[0906 20-32-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10651, current rewards: 158.03786, mean: 0.13061
[32m[0906 20-32-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10645, current rewards: 163.73628, mean: 0.12995
[32m[0906 20-32-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10642, current rewards: 169.42602, mean: 0.12933
[32m[0906 20-32-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10651, current rewards: 175.11589, mean: 0.12876
[32m[0906 20-32-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10656, current rewards: 180.81165, mean: 0.12824
[32m[0906 20-32-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10661, current rewards: 168.17627, mean: 0.11519
[32m[0906 20-32-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10668, current rewards: 176.47639, mean: 0.11687
[32m[0906 20-32-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10674, current rewards: 183.51875, mean: 0.11764
[32m[0906 20-32-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10678, current rewards: 189.66156, mean: 0.11780
[32m[0906 20-32-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10683, current rewards: 196.41547, mean: 0.11832
[32m[0906 20-32-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10688, current rewards: 203.16336, mean: 0.11881
[32m[0906 20-33-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10692, current rewards: 209.90734, mean: 0.11927
[32m[0906 20-33-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10697, current rewards: 216.65712, mean: 0.11970
[32m[0906 20-33-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10701, current rewards: 223.40259, mean: 0.12011
[32m[0906 20-33-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10704, current rewards: 224.08638, mean: 0.11732
[32m[0906 20-33-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10704, current rewards: 229.87109, mean: 0.11728
[32m[0906 20-33-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10698, current rewards: 235.49950, mean: 0.11716
[32m[0906 20-33-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10694, current rewards: 241.24738, mean: 0.11711
[32m[0906 20-33-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10690, current rewards: 246.99176, mean: 0.11706
[32m[0906 20-33-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10686, current rewards: 252.74006, mean: 0.11701
[32m[0906 20-33-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10687, current rewards: 258.49148, mean: 0.11696
[32m[0906 20-33-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10691, current rewards: 264.23647, mean: 0.11692
[32m[0906 20-33-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10686, current rewards: 269.98539, mean: 0.11688
[32m[0906 20-34-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10680, current rewards: 275.73399, mean: 0.11684
[32m[0906 20-34-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10677, current rewards: 281.29790, mean: 0.11672
[32m[0906 20-34-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10674, current rewards: 286.99754, mean: 0.11667
[32m[0906 20-34-19 @Agent.py:117][0m Average action selection time: 0.1067
[32m[0906 20-34-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-34-19 @MBExp.py:227][0m Rewards obtained: [285.50575214892245], Lows: [12], Highs: [25], Total time: 19031.217603999998
[32m[0906 20-37-02 @MBExp.py:144][0m ####################################################################
[32m[0906 20-37-02 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 20-37-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10936, current rewards: -5.59054, mean: -0.55905
[32m[0906 20-37-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10863, current rewards: 0.05233, mean: 0.00087
[32m[0906 20-37-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10851, current rewards: 5.65202, mean: 0.05138
[32m[0906 20-37-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10851, current rewards: 11.24683, mean: 0.07029
[32m[0906 20-37-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10850, current rewards: 16.85783, mean: 0.08028
[32m[0906 20-37-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10843, current rewards: 22.46616, mean: 0.08641
[32m[0906 20-37-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10871, current rewards: 28.10521, mean: 0.09066
[32m[0906 20-37-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10867, current rewards: 33.70282, mean: 0.09362
[32m[0906 20-37-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10858, current rewards: 39.29717, mean: 0.09585
[32m[0906 20-37-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10865, current rewards: 44.90094, mean: 0.09761
[32m[0906 20-37-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10857, current rewards: 50.50093, mean: 0.09902
[32m[0906 20-38-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10854, current rewards: 56.10828, mean: 0.10019
[32m[0906 20-38-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10838, current rewards: 61.70445, mean: 0.10115
[32m[0906 20-38-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10809, current rewards: 67.31039, mean: 0.10199
[32m[0906 20-38-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10786, current rewards: 70.14226, mean: 0.09879
[32m[0906 20-38-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10770, current rewards: 75.69031, mean: 0.09959
[32m[0906 20-38-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10751, current rewards: 81.23727, mean: 0.10029
[32m[0906 20-38-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10733, current rewards: 86.78823, mean: 0.10092
[32m[0906 20-38-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10721, current rewards: 92.33690, mean: 0.10147
[32m[0906 20-38-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10707, current rewards: 97.87867, mean: 0.10196
[32m[0906 20-38-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10694, current rewards: 103.42472, mean: 0.10240
[32m[0906 20-38-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10685, current rewards: 108.97501, mean: 0.10281
[32m[0906 20-39-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10676, current rewards: 114.92441, mean: 0.10354
[32m[0906 20-39-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10667, current rewards: 120.63801, mean: 0.10400
[32m[0906 20-39-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10662, current rewards: 126.22613, mean: 0.10432
[32m[0906 20-39-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10654, current rewards: 121.90806, mean: 0.09675
[32m[0906 20-39-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10655, current rewards: 128.83472, mean: 0.09835
[32m[0906 20-39-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10665, current rewards: 135.76138, mean: 0.09982
[32m[0906 20-39-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10673, current rewards: 142.68804, mean: 0.10120
[32m[0906 20-39-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10679, current rewards: 149.61470, mean: 0.10248
[32m[0906 20-39-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10686, current rewards: 156.54136, mean: 0.10367
[32m[0906 20-39-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10690, current rewards: 161.99449, mean: 0.10384
[32m[0906 20-39-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10695, current rewards: 167.34165, mean: 0.10394
[32m[0906 20-40-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10702, current rewards: 172.68881, mean: 0.10403
[32m[0906 20-40-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10706, current rewards: 178.03597, mean: 0.10411
[32m[0906 20-40-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10710, current rewards: 147.96095, mean: 0.08407
[32m[0906 20-40-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10716, current rewards: 97.96095, mean: 0.05412
[32m[0906 20-40-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10719, current rewards: 47.96095, mean: 0.02579
[32m[0906 20-40-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10723, current rewards: -2.03905, mean: -0.00107
[32m[0906 20-40-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10721, current rewards: -52.03905, mean: -0.02655
[32m[0906 20-40-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10716, current rewards: -102.03905, mean: -0.05077
[32m[0906 20-40-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10711, current rewards: -152.03905, mean: -0.07381
[32m[0906 20-40-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10708, current rewards: -202.03905, mean: -0.09575
[32m[0906 20-40-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10705, current rewards: -252.03905, mean: -0.11668
[32m[0906 20-40-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10710, current rewards: -302.03905, mean: -0.13667
[32m[0906 20-41-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10712, current rewards: -352.03905, mean: -0.15577
[32m[0906 20-41-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10708, current rewards: -402.03905, mean: -0.17404
[32m[0906 20-41-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10703, current rewards: -452.03905, mean: -0.19154
[32m[0906 20-41-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10700, current rewards: -502.03905, mean: -0.20831
[32m[0906 20-41-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10696, current rewards: -552.03905, mean: -0.22441
[32m[0906 20-41-30 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 20-41-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-41-30 @MBExp.py:227][0m Rewards obtained: [-592.0390510940163], Lows: [6], Highs: [783], Total time: 19299.355003999997
[32m[0906 20-44-15 @MBExp.py:144][0m ####################################################################
[32m[0906 20-44-15 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 20-44-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10681, current rewards: -7.89423, mean: -0.78942
[32m[0906 20-44-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10755, current rewards: -3.11758, mean: -0.05196
[32m[0906 20-44-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10766, current rewards: 3.10165, mean: 0.02820
[32m[0906 20-44-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10784, current rewards: 9.32660, mean: 0.05829
[32m[0906 20-44-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10778, current rewards: 15.55765, mean: 0.07408
[32m[0906 20-44-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10781, current rewards: 21.24751, mean: 0.08172
[32m[0906 20-44-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10791, current rewards: 26.27835, mean: 0.08477
[32m[0906 20-44-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10786, current rewards: 29.52126, mean: 0.08200
[32m[0906 20-44-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10790, current rewards: 25.92748, mean: 0.06324
[32m[0906 20-45-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10789, current rewards: 32.13450, mean: 0.06986
[32m[0906 20-45-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10787, current rewards: 38.34108, mean: 0.07518
[32m[0906 20-45-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10781, current rewards: 44.54628, mean: 0.07955
[32m[0906 20-45-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10749, current rewards: 50.75405, mean: 0.08320
[32m[0906 20-45-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10726, current rewards: 56.96349, mean: 0.08631
[32m[0906 20-45-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10710, current rewards: 64.10240, mean: 0.09029
[32m[0906 20-45-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10693, current rewards: 69.77259, mean: 0.09181
[32m[0906 20-45-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10677, current rewards: 64.82443, mean: 0.08003
[32m[0906 20-45-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10669, current rewards: 69.87431, mean: 0.08125
[32m[0906 20-45-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10656, current rewards: 74.92418, mean: 0.08233
[32m[0906 20-45-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10645, current rewards: 79.97406, mean: 0.08331
[32m[0906 20-46-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10636, current rewards: 85.02393, mean: 0.08418
[32m[0906 20-46-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10628, current rewards: 90.07381, mean: 0.08498
[32m[0906 20-46-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10621, current rewards: 94.85057, mean: 0.08545
[32m[0906 20-46-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10612, current rewards: 51.17134, mean: 0.04411
[32m[0906 20-46-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10605, current rewards: 1.17134, mean: 0.00097
[32m[0906 20-46-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10599, current rewards: -48.82866, mean: -0.03875
[32m[0906 20-46-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10591, current rewards: -98.82866, mean: -0.07544
[32m[0906 20-46-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10588, current rewards: -148.82866, mean: -0.10943
[32m[0906 20-46-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10594, current rewards: -198.82866, mean: -0.14101
[32m[0906 20-46-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10600, current rewards: -248.82866, mean: -0.17043
[32m[0906 20-46-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10611, current rewards: -298.82866, mean: -0.19790
[32m[0906 20-47-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10618, current rewards: -348.82866, mean: -0.22361
[32m[0906 20-47-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10624, current rewards: -398.82866, mean: -0.24772
[32m[0906 20-47-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10628, current rewards: -448.82866, mean: -0.27038
[32m[0906 20-47-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10632, current rewards: -498.82866, mean: -0.29171
[32m[0906 20-47-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10638, current rewards: -548.82866, mean: -0.31183
[32m[0906 20-47-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10642, current rewards: -598.82866, mean: -0.33084
[32m[0906 20-47-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10648, current rewards: -648.82866, mean: -0.34883
[32m[0906 20-47-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10656, current rewards: -698.82866, mean: -0.36588
[32m[0906 20-47-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10653, current rewards: -748.82866, mean: -0.38206
[32m[0906 20-47-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10649, current rewards: -798.82866, mean: -0.39743
[32m[0906 20-47-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10646, current rewards: -848.82866, mean: -0.41205
[32m[0906 20-48-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10641, current rewards: -898.82866, mean: -0.42599
[32m[0906 20-48-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10641, current rewards: -948.82866, mean: -0.43927
[32m[0906 20-48-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10646, current rewards: -998.82866, mean: -0.45196
[32m[0906 20-48-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10647, current rewards: -1048.82866, mean: -0.46408
[32m[0906 20-48-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10642, current rewards: -1098.82866, mean: -0.47568
[32m[0906 20-48-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10640, current rewards: -1145.54182, mean: -0.48540
[32m[0906 20-48-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10636, current rewards: -1140.76121, mean: -0.47334
[32m[0906 20-48-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10632, current rewards: -1135.98060, mean: -0.46178
[32m[0906 20-48-41 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 20-48-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-48-41 @MBExp.py:227][0m Rewards obtained: [-1132.1561086121212], Lows: [10], Highs: [1251], Total time: 19565.881722
[32m[0906 20-51-29 @MBExp.py:144][0m ####################################################################
[32m[0906 20-51-29 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 20-51-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10723, current rewards: -0.87769, mean: -0.08777
[32m[0906 20-51-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10785, current rewards: 3.88191, mean: 0.06470
[32m[0906 20-51-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10846, current rewards: 9.36523, mean: 0.08514
[32m[0906 20-51-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10842, current rewards: 14.84181, mean: 0.09276
[32m[0906 20-51-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10837, current rewards: 20.31928, mean: 0.09676
[32m[0906 20-51-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10841, current rewards: 25.79675, mean: 0.09922
[32m[0906 20-52-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10842, current rewards: 31.48619, mean: 0.10157
[32m[0906 20-52-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10840, current rewards: 36.96239, mean: 0.10267
[32m[0906 20-52-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10842, current rewards: 42.44005, mean: 0.10351
[32m[0906 20-52-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10841, current rewards: 47.91865, mean: 0.10417
[32m[0906 20-52-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10832, current rewards: 53.39859, mean: 0.10470
[32m[0906 20-52-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10806, current rewards: 58.87341, mean: 0.10513
[32m[0906 20-52-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10778, current rewards: 59.21648, mean: 0.09708
[32m[0906 20-52-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10758, current rewards: 64.53567, mean: 0.09778
[32m[0906 20-52-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10741, current rewards: 69.75630, mean: 0.09825
[32m[0906 20-52-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10724, current rewards: 75.02699, mean: 0.09872
[32m[0906 20-52-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10708, current rewards: 80.30147, mean: 0.09914
[32m[0906 20-53-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10696, current rewards: 85.57252, mean: 0.09950
[32m[0906 20-53-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10685, current rewards: 90.84653, mean: 0.09983
[32m[0906 20-53-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10673, current rewards: 96.11810, mean: 0.10012
[32m[0906 20-53-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10667, current rewards: 101.38967, mean: 0.10039
[32m[0906 20-53-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10656, current rewards: 106.67124, mean: 0.10063
[32m[0906 20-53-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10646, current rewards: 112.10041, mean: 0.10099
[32m[0906 20-53-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10640, current rewards: 117.40924, mean: 0.10121
[32m[0906 20-53-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10633, current rewards: 122.72741, mean: 0.10143
[32m[0906 20-53-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10626, current rewards: 128.04610, mean: 0.10162
[32m[0906 20-53-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10624, current rewards: 136.42551, mean: 0.10414
[32m[0906 20-53-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10617, current rewards: 142.16784, mean: 0.10454
[32m[0906 20-53-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10612, current rewards: 147.90841, mean: 0.10490
[32m[0906 20-54-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10622, current rewards: 153.66194, mean: 0.10525
[32m[0906 20-54-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10628, current rewards: 159.44855, mean: 0.10560
[32m[0906 20-54-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10636, current rewards: 165.44835, mean: 0.10606
[32m[0906 20-54-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10644, current rewards: 171.20889, mean: 0.10634
[32m[0906 20-54-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10650, current rewards: 176.96829, mean: 0.10661
[32m[0906 20-54-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10656, current rewards: 182.72626, mean: 0.10686
[32m[0906 20-54-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10660, current rewards: 188.48536, mean: 0.10709
[32m[0906 20-54-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10664, current rewards: 194.24409, mean: 0.10732
[32m[0906 20-54-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10669, current rewards: 189.24574, mean: 0.10175
[32m[0906 20-54-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10672, current rewards: 194.84114, mean: 0.10201
[32m[0906 20-54-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10669, current rewards: 200.47747, mean: 0.10228
[32m[0906 20-55-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10664, current rewards: 206.07903, mean: 0.10253
[32m[0906 20-55-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10659, current rewards: 211.68036, mean: 0.10276
[32m[0906 20-55-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10656, current rewards: 217.28470, mean: 0.10298
[32m[0906 20-55-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10661, current rewards: 217.22293, mean: 0.10057
[32m[0906 20-55-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10665, current rewards: 222.57960, mean: 0.10071
[32m[0906 20-55-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10665, current rewards: 227.93415, mean: 0.10086
[32m[0906 20-55-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10662, current rewards: 233.28633, mean: 0.10099
[32m[0906 20-55-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10658, current rewards: 238.52676, mean: 0.10107
[32m[0906 20-55-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10653, current rewards: 243.85713, mean: 0.10119
[32m[0906 20-55-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10650, current rewards: 249.18746, mean: 0.10130
[32m[0906 20-55-55 @Agent.py:117][0m Average action selection time: 0.1065
[32m[0906 20-55-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-55-56 @MBExp.py:227][0m Rewards obtained: [253.4526349627808], Lows: [6], Highs: [11], Total time: 19832.867233999998
[32m[0906 20-58-45 @MBExp.py:144][0m ####################################################################
[32m[0906 20-58-45 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 20-58-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11052, current rewards: -5.75212, mean: -0.57521
[32m[0906 20-58-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10836, current rewards: 0.41748, mean: 0.00696
[32m[0906 20-58-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10803, current rewards: 5.91667, mean: 0.05379
[32m[0906 20-59-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10809, current rewards: 11.41524, mean: 0.07135
[32m[0906 20-59-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10803, current rewards: 16.91929, mean: 0.08057
[32m[0906 20-59-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10807, current rewards: 22.63570, mean: 0.08706
[32m[0906 20-59-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10817, current rewards: 28.14138, mean: 0.09078
[32m[0906 20-59-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10813, current rewards: 33.65080, mean: 0.09347
[32m[0906 20-59-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10816, current rewards: 39.15667, mean: 0.09550
[32m[0906 20-59-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10824, current rewards: 44.66218, mean: 0.09709
[32m[0906 20-59-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10824, current rewards: 50.17157, mean: 0.09838
[32m[0906 20-59-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10826, current rewards: 50.14273, mean: 0.08954
[32m[0906 20-59-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10813, current rewards: 55.66864, mean: 0.09126
[32m[0906 20-59-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10788, current rewards: 60.99525, mean: 0.09242
[32m[0906 21-00-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10766, current rewards: 66.00797, mean: 0.09297
[32m[0906 21-00-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10748, current rewards: 71.50745, mean: 0.09409
[32m[0906 21-00-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10729, current rewards: 77.01047, mean: 0.09507
[32m[0906 21-00-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10713, current rewards: 82.51388, mean: 0.09595
[32m[0906 21-00-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10704, current rewards: 88.00639, mean: 0.09671
[32m[0906 21-00-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10689, current rewards: 93.51210, mean: 0.09741
[32m[0906 21-00-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10675, current rewards: 99.01140, mean: 0.09803
[32m[0906 21-00-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10665, current rewards: 93.86403, mean: 0.08855
[32m[0906 21-00-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10654, current rewards: 99.64163, mean: 0.08977
[32m[0906 21-00-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10645, current rewards: 105.07388, mean: 0.09058
[32m[0906 21-00-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10637, current rewards: 110.50172, mean: 0.09132
[32m[0906 21-00-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10627, current rewards: 115.92969, mean: 0.09201
[32m[0906 21-01-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10619, current rewards: 121.35584, mean: 0.09264
[32m[0906 21-01-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10612, current rewards: 126.78513, mean: 0.09322
[32m[0906 21-01-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10606, current rewards: 132.21535, mean: 0.09377
[32m[0906 21-01-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10600, current rewards: 127.12874, mean: 0.08707
[32m[0906 21-01-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10597, current rewards: 132.32250, mean: 0.08763
[32m[0906 21-01-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10601, current rewards: 137.71846, mean: 0.08828
[32m[0906 21-01-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10606, current rewards: 143.11037, mean: 0.08889
[32m[0906 21-01-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10613, current rewards: 148.50302, mean: 0.08946
[32m[0906 21-01-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10617, current rewards: 153.89922, mean: 0.09000
[32m[0906 21-01-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10620, current rewards: 159.29496, mean: 0.09051
[32m[0906 21-01-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10624, current rewards: 164.69108, mean: 0.09099
[32m[0906 21-02-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10627, current rewards: 170.08599, mean: 0.09144
[32m[0906 21-02-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10631, current rewards: 175.82105, mean: 0.09205
[32m[0906 21-02-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10628, current rewards: 181.23283, mean: 0.09247
[32m[0906 21-02-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10622, current rewards: 186.65125, mean: 0.09286
[32m[0906 21-02-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10616, current rewards: 192.07436, mean: 0.09324
[32m[0906 21-02-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10614, current rewards: 197.49970, mean: 0.09360
[32m[0906 21-02-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10609, current rewards: 202.92444, mean: 0.09395
[32m[0906 21-02-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10605, current rewards: 208.34990, mean: 0.09428
[32m[0906 21-02-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10604, current rewards: 213.77416, mean: 0.09459
[32m[0906 21-02-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10600, current rewards: 202.30482, mean: 0.08758
[32m[0906 21-02-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10596, current rewards: 207.72235, mean: 0.08802
[32m[0906 21-03-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10593, current rewards: 213.13728, mean: 0.08844
[32m[0906 21-03-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10590, current rewards: 218.54800, mean: 0.08884
[32m[0906 21-03-10 @Agent.py:117][0m Average action selection time: 0.1059
[32m[0906 21-03-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-03-10 @MBExp.py:227][0m Rewards obtained: [222.87466360153516], Lows: [15], Highs: [17], Total time: 20098.381396999997
[32m[0906 21-06-01 @MBExp.py:144][0m ####################################################################
[32m[0906 21-06-01 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 21-06-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10640, current rewards: -4.54515, mean: -0.45451
[32m[0906 21-06-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10686, current rewards: 1.05084, mean: 0.01751
[32m[0906 21-06-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10712, current rewards: 6.55257, mean: 0.05957
[32m[0906 21-06-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10718, current rewards: 12.05167, mean: 0.07532
[32m[0906 21-06-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10713, current rewards: 17.55122, mean: 0.08358
[32m[0906 21-06-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10724, current rewards: 22.95298, mean: 0.08828
[32m[0906 21-06-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10719, current rewards: 28.44879, mean: 0.09177
[32m[0906 21-06-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10712, current rewards: 33.94150, mean: 0.09428
[32m[0906 21-06-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10713, current rewards: 29.03396, mean: 0.07081
[32m[0906 21-06-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10713, current rewards: 34.71069, mean: 0.07546
[32m[0906 21-06-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10706, current rewards: 40.38502, mean: 0.07919
[32m[0906 21-07-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10712, current rewards: 46.05968, mean: 0.08225
[32m[0906 21-07-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10679, current rewards: 51.73012, mean: 0.08480
[32m[0906 21-07-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10655, current rewards: 57.25209, mean: 0.08675
[32m[0906 21-07-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10637, current rewards: 62.89665, mean: 0.08859
[32m[0906 21-07-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10618, current rewards: 68.54298, mean: 0.09019
[32m[0906 21-07-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10600, current rewards: 74.18628, mean: 0.09159
[32m[0906 21-07-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10591, current rewards: 79.83059, mean: 0.09283
[32m[0906 21-07-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10581, current rewards: 85.47574, mean: 0.09393
[32m[0906 21-07-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10567, current rewards: 91.11895, mean: 0.09492
[32m[0906 21-07-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10560, current rewards: 96.76520, mean: 0.09581
[32m[0906 21-07-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10548, current rewards: 104.38916, mean: 0.09848
[32m[0906 21-07-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10540, current rewards: 107.49744, mean: 0.09684
[32m[0906 21-08-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10533, current rewards: 109.94514, mean: 0.09478
[32m[0906 21-08-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10524, current rewards: 112.39284, mean: 0.09289
[32m[0906 21-08-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10516, current rewards: 114.84055, mean: 0.09114
[32m[0906 21-08-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10511, current rewards: 99.45603, mean: 0.07592
[32m[0906 21-08-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10503, current rewards: 49.45603, mean: 0.03636
[32m[0906 21-08-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10497, current rewards: -0.54397, mean: -0.00039
[32m[0906 21-08-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10493, current rewards: -50.54397, mean: -0.03462
[32m[0906 21-08-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10490, current rewards: -100.54397, mean: -0.06659
[32m[0906 21-08-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10495, current rewards: -150.54397, mean: -0.09650
[32m[0906 21-08-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10503, current rewards: -200.54397, mean: -0.12456
[32m[0906 21-08-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10508, current rewards: -250.54397, mean: -0.15093
[32m[0906 21-09-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10513, current rewards: -300.54397, mean: -0.17576
[32m[0906 21-09-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10519, current rewards: -350.54397, mean: -0.19917
[32m[0906 21-09-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10522, current rewards: -400.54397, mean: -0.22130
[32m[0906 21-09-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10525, current rewards: -450.54397, mean: -0.24223
[32m[0906 21-09-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10530, current rewards: -500.54397, mean: -0.26206
[32m[0906 21-09-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10527, current rewards: -550.54397, mean: -0.28089
[32m[0906 21-09-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10520, current rewards: -600.54397, mean: -0.29878
[32m[0906 21-09-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10518, current rewards: -650.54397, mean: -0.31580
[32m[0906 21-09-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10513, current rewards: -700.54397, mean: -0.33201
[32m[0906 21-09-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10510, current rewards: -750.54397, mean: -0.34747
[32m[0906 21-09-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10508, current rewards: -800.54397, mean: -0.36224
[32m[0906 21-09-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10506, current rewards: -850.54397, mean: -0.37635
[32m[0906 21-10-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10502, current rewards: -900.54397, mean: -0.38985
[32m[0906 21-10-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10500, current rewards: -950.54397, mean: -0.40277
[32m[0906 21-10-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10498, current rewards: -1000.54397, mean: -0.41516
[32m[0906 21-10-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10496, current rewards: -1050.54397, mean: -0.42705
[32m[0906 21-10-24 @Agent.py:117][0m Average action selection time: 0.1049
[32m[0906 21-10-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-10-24 @MBExp.py:227][0m Rewards obtained: [-1090.543971266079], Lows: [5], Highs: [1212], Total time: 20361.520478
[32m[0906 21-13-17 @MBExp.py:144][0m ####################################################################
[32m[0906 21-13-17 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 21-13-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10814, current rewards: -4.05119, mean: -0.40512
[32m[0906 21-13-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10666, current rewards: 1.58828, mean: 0.02647
[32m[0906 21-13-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10659, current rewards: 6.92113, mean: 0.06292
[32m[0906 21-13-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10669, current rewards: 12.25452, mean: 0.07659
[32m[0906 21-13-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10665, current rewards: 17.59359, mean: 0.08378
[32m[0906 21-13-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10662, current rewards: 22.93216, mean: 0.08820
[32m[0906 21-13-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10672, current rewards: 26.41932, mean: 0.08522
[32m[0906 21-13-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10671, current rewards: 31.86024, mean: 0.08850
[32m[0906 21-14-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10671, current rewards: 37.30111, mean: 0.09098
[32m[0906 21-14-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10670, current rewards: 42.74752, mean: 0.09293
[32m[0906 21-14-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10662, current rewards: 35.38716, mean: 0.06939
[32m[0906 21-14-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10636, current rewards: 40.77036, mean: 0.07280
[32m[0906 21-14-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10613, current rewards: 46.27874, mean: 0.07587
[32m[0906 21-14-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10591, current rewards: 51.65553, mean: 0.07827
[32m[0906 21-14-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10573, current rewards: 57.03215, mean: 0.08033
[32m[0906 21-14-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10559, current rewards: 62.40827, mean: 0.08212
[32m[0906 21-14-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10542, current rewards: 67.78465, mean: 0.08368
[32m[0906 21-14-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10528, current rewards: 73.16135, mean: 0.08507
[32m[0906 21-14-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10518, current rewards: 70.79989, mean: 0.07780
[32m[0906 21-14-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10510, current rewards: 76.26957, mean: 0.07945
[32m[0906 21-15-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10501, current rewards: 81.46475, mean: 0.08066
[32m[0906 21-15-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10495, current rewards: 86.70705, mean: 0.08180
[32m[0906 21-15-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10490, current rewards: 92.14276, mean: 0.08301
[32m[0906 21-15-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10481, current rewards: 87.28876, mean: 0.07525
[32m[0906 21-15-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10475, current rewards: 92.56384, mean: 0.07650
[32m[0906 21-15-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10470, current rewards: 97.83822, mean: 0.07765
[32m[0906 21-15-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10465, current rewards: 103.11150, mean: 0.07871
[32m[0906 21-15-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10462, current rewards: 108.38536, mean: 0.07970
[32m[0906 21-15-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10461, current rewards: 113.65806, mean: 0.08061
[32m[0906 21-15-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10457, current rewards: 120.11230, mean: 0.08227
[32m[0906 21-15-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10460, current rewards: 125.47298, mean: 0.08309
[32m[0906 21-16-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10470, current rewards: 130.82650, mean: 0.08386
[32m[0906 21-16-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10476, current rewards: 136.18612, mean: 0.08459
[32m[0906 21-16-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10483, current rewards: 141.53970, mean: 0.08526
[32m[0906 21-16-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10489, current rewards: 141.27445, mean: 0.08262
[32m[0906 21-16-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10495, current rewards: 146.57652, mean: 0.08328
[32m[0906 21-16-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10501, current rewards: 151.87657, mean: 0.08391
[32m[0906 21-16-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10506, current rewards: 147.51482, mean: 0.07931
[32m[0906 21-16-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10510, current rewards: 152.86659, mean: 0.08003
[32m[0906 21-16-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10508, current rewards: 158.20205, mean: 0.08072
[32m[0906 21-16-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10505, current rewards: 163.53582, mean: 0.08136
[32m[0906 21-16-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10501, current rewards: 168.86953, mean: 0.08198
[32m[0906 21-16-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10496, current rewards: 174.20693, mean: 0.08256
[32m[0906 21-17-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10494, current rewards: 179.54101, mean: 0.08312
[32m[0906 21-17-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10494, current rewards: 184.87304, mean: 0.08365
[32m[0906 21-17-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10490, current rewards: 186.89096, mean: 0.08270
[32m[0906 21-17-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10488, current rewards: 191.13219, mean: 0.08274
[32m[0906 21-17-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10485, current rewards: 196.61448, mean: 0.08331
[32m[0906 21-17-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10482, current rewards: 202.09989, mean: 0.08386
[32m[0906 21-17-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10483, current rewards: 207.58428, mean: 0.08438
[32m[0906 21-17-39 @Agent.py:117][0m Average action selection time: 0.1048
[32m[0906 21-17-39 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-17-39 @MBExp.py:227][0m Rewards obtained: [211.9662744406631], Lows: [18], Highs: [22], Total time: 20624.338576
[32m[0906 21-20-34 @MBExp.py:144][0m ####################################################################
[32m[0906 21-20-34 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 21-20-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10531, current rewards: -4.61008, mean: -0.46101
[32m[0906 21-20-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10618, current rewards: 1.00134, mean: 0.01669
[32m[0906 21-20-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10657, current rewards: 6.60248, mean: 0.06002
[32m[0906 21-20-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10636, current rewards: 12.20806, mean: 0.07630
[32m[0906 21-20-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10620, current rewards: 17.73961, mean: 0.08447
[32m[0906 21-21-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10630, current rewards: 23.31994, mean: 0.08969
[32m[0906 21-21-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10634, current rewards: 28.90297, mean: 0.09324
[32m[0906 21-21-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10630, current rewards: 34.48367, mean: 0.09579
[32m[0906 21-21-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10636, current rewards: 40.06800, mean: 0.09773
[32m[0906 21-21-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10633, current rewards: 45.64923, mean: 0.09924
[32m[0906 21-21-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10627, current rewards: 51.23185, mean: 0.10045
[32m[0906 21-21-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10600, current rewards: 56.80687, mean: 0.10144
[32m[0906 21-21-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10578, current rewards: 62.38138, mean: 0.10226
[32m[0906 21-21-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10558, current rewards: 67.70327, mean: 0.10258
[32m[0906 21-21-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10547, current rewards: 73.09032, mean: 0.10294
[32m[0906 21-21-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10534, current rewards: 78.47640, mean: 0.10326
[32m[0906 21-21-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10519, current rewards: 83.86024, mean: 0.10353
[32m[0906 21-22-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10510, current rewards: 89.24762, mean: 0.10378
[32m[0906 21-22-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10499, current rewards: 94.63596, mean: 0.10400
[32m[0906 21-22-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10489, current rewards: 100.01741, mean: 0.10418
[32m[0906 21-22-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10484, current rewards: 105.19678, mean: 0.10416
[32m[0906 21-22-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10477, current rewards: 110.49714, mean: 0.10424
[32m[0906 21-22-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10471, current rewards: 115.79386, mean: 0.10432
[32m[0906 21-22-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10465, current rewards: 121.08616, mean: 0.10438
[32m[0906 21-22-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10460, current rewards: 126.38231, mean: 0.10445
[32m[0906 21-22-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10455, current rewards: 131.67352, mean: 0.10450
[32m[0906 21-22-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10453, current rewards: 136.97090, mean: 0.10456
[32m[0906 21-22-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10449, current rewards: 142.26785, mean: 0.10461
[32m[0906 21-23-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10445, current rewards: 137.93064, mean: 0.09782
[32m[0906 21-23-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10442, current rewards: 143.77789, mean: 0.09848
[32m[0906 21-23-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10446, current rewards: 149.44232, mean: 0.09897
[32m[0906 21-23-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10450, current rewards: 155.10589, mean: 0.09943
[32m[0906 21-23-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10458, current rewards: 160.77475, mean: 0.09986
[32m[0906 21-23-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10463, current rewards: 166.44148, mean: 0.10027
[32m[0906 21-23-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10468, current rewards: 172.10530, mean: 0.10065
[32m[0906 21-23-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10475, current rewards: 177.77206, mean: 0.10101
[32m[0906 21-23-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10478, current rewards: 183.43800, mean: 0.10135
[32m[0906 21-23-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10483, current rewards: 188.77099, mean: 0.10149
[32m[0906 21-23-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10488, current rewards: 194.39544, mean: 0.10178
[32m[0906 21-24-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10486, current rewards: 200.02028, mean: 0.10205
[32m[0906 21-24-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10483, current rewards: 204.53024, mean: 0.10176
[32m[0906 21-24-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10480, current rewards: 205.72571, mean: 0.09987
[32m[0906 21-24-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10477, current rewards: 211.27662, mean: 0.10013
[32m[0906 21-24-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10474, current rewards: 216.82928, mean: 0.10038
[32m[0906 21-24-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10473, current rewards: 222.38391, mean: 0.10063
[32m[0906 21-24-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10470, current rewards: 228.28100, mean: 0.10101
[32m[0906 21-24-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10466, current rewards: 233.82252, mean: 0.10122
[32m[0906 21-24-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10463, current rewards: 239.36872, mean: 0.10143
[32m[0906 21-24-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10461, current rewards: 244.90456, mean: 0.10162
[32m[0906 21-24-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10458, current rewards: 250.45658, mean: 0.10181
[32m[0906 21-24-56 @Agent.py:117][0m Average action selection time: 0.1046
[32m[0906 21-24-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-24-56 @MBExp.py:227][0m Rewards obtained: [254.89045192762325], Lows: [5], Highs: [10], Total time: 20886.530147999998
[32m[0906 21-27-52 @MBExp.py:144][0m ####################################################################
[32m[0906 21-27-52 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 21-27-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10401, current rewards: -5.60799, mean: -0.56080
[32m[0906 21-27-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10545, current rewards: -0.08792, mean: -0.00147
[32m[0906 21-28-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10567, current rewards: 5.44753, mean: 0.04952
[32m[0906 21-28-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10584, current rewards: 11.11918, mean: 0.06949
[32m[0906 21-28-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10578, current rewards: 16.66071, mean: 0.07934
[32m[0906 21-28-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10589, current rewards: 22.20092, mean: 0.08539
[32m[0906 21-28-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10589, current rewards: 27.74224, mean: 0.08949
[32m[0906 21-28-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10591, current rewards: 33.28507, mean: 0.09246
[32m[0906 21-28-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10587, current rewards: 38.83081, mean: 0.09471
[32m[0906 21-28-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10583, current rewards: 38.04004, mean: 0.08270
[32m[0906 21-28-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10545, current rewards: 40.51646, mean: 0.07944
[32m[0906 21-28-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10527, current rewards: 45.89653, mean: 0.08196
[32m[0906 21-28-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10508, current rewards: 51.37234, mean: 0.08422
[32m[0906 21-29-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10491, current rewards: 56.85083, mean: 0.08614
[32m[0906 21-29-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10479, current rewards: 62.32770, mean: 0.08779
[32m[0906 21-29-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10466, current rewards: 67.80465, mean: 0.08922
[32m[0906 21-29-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10454, current rewards: 63.49388, mean: 0.07839
[32m[0906 21-29-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10442, current rewards: 69.28911, mean: 0.08057
[32m[0906 21-29-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10436, current rewards: 75.08434, mean: 0.08251
[32m[0906 21-29-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10427, current rewards: 80.49005, mean: 0.08384
[32m[0906 21-29-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10420, current rewards: 72.05203, mean: 0.07134
[32m[0906 21-29-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10416, current rewards: 77.63423, mean: 0.07324
[32m[0906 21-29-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10410, current rewards: 83.22352, mean: 0.07498
[32m[0906 21-29-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10404, current rewards: 88.81065, mean: 0.07656
[32m[0906 21-29-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10398, current rewards: 94.40226, mean: 0.07802
[32m[0906 21-30-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10393, current rewards: 99.99333, mean: 0.07936
[32m[0906 21-30-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10389, current rewards: 105.58036, mean: 0.08060
[32m[0906 21-30-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10384, current rewards: 106.11337, mean: 0.07802
[32m[0906 21-30-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10380, current rewards: 112.12885, mean: 0.07952
[32m[0906 21-30-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10376, current rewards: 117.64173, mean: 0.08058
[32m[0906 21-30-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10373, current rewards: 123.15147, mean: 0.08156
[32m[0906 21-30-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10376, current rewards: 125.48552, mean: 0.08044
[32m[0906 21-30-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10381, current rewards: 120.80003, mean: 0.07503
[32m[0906 21-30-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10387, current rewards: 125.97690, mean: 0.07589
[32m[0906 21-30-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10392, current rewards: 131.15011, mean: 0.07670
[32m[0906 21-30-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10395, current rewards: 136.32492, mean: 0.07746
[32m[0906 21-31-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10402, current rewards: 141.68050, mean: 0.07828
[32m[0906 21-31-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10405, current rewards: 146.84927, mean: 0.07895
[32m[0906 21-31-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10409, current rewards: 142.13187, mean: 0.07441
[32m[0906 21-31-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10407, current rewards: 147.70149, mean: 0.07536
[32m[0906 21-31-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10405, current rewards: 153.27116, mean: 0.07625
[32m[0906 21-31-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10403, current rewards: 158.84734, mean: 0.07711
[32m[0906 21-31-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10401, current rewards: 164.41453, mean: 0.07792
[32m[0906 21-31-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10399, current rewards: 169.97947, mean: 0.07869
[32m[0906 21-31-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10400, current rewards: 175.61738, mean: 0.07946
[32m[0906 21-31-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10399, current rewards: 181.19033, mean: 0.08017
[32m[0906 21-31-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10396, current rewards: 186.76489, mean: 0.08085
[32m[0906 21-31-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10394, current rewards: 192.33993, mean: 0.08150
[32m[0906 21-32-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10393, current rewards: 197.91313, mean: 0.08212
[32m[0906 21-32-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10392, current rewards: 203.48712, mean: 0.08272
[32m[0906 21-32-13 @Agent.py:117][0m Average action selection time: 0.1039
[32m[0906 21-32-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-32-13 @MBExp.py:227][0m Rewards obtained: [202.43825677015025], Lows: [23], Highs: [28], Total time: 21147.093562
[32m[0906 21-35-11 @MBExp.py:144][0m ####################################################################
[32m[0906 21-35-11 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 21-35-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10520, current rewards: -14.00000, mean: -1.40000
[32m[0906 21-35-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10526, current rewards: -10.36732, mean: -0.17279
[32m[0906 21-35-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10536, current rewards: -4.58768, mean: -0.04171
[32m[0906 21-35-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10541, current rewards: 0.97256, mean: 0.00608
[32m[0906 21-35-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10534, current rewards: 6.55254, mean: 0.03120
[32m[0906 21-35-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10535, current rewards: 12.13592, mean: 0.04668
[32m[0906 21-35-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10541, current rewards: 17.71942, mean: 0.05716
[32m[0906 21-35-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10535, current rewards: 23.29497, mean: 0.06471
[32m[0906 21-35-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10533, current rewards: 28.85916, mean: 0.07039
[32m[0906 21-36-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10507, current rewards: 28.10646, mean: 0.06110
[32m[0906 21-36-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10480, current rewards: 29.65534, mean: 0.05815
[32m[0906 21-36-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10459, current rewards: 35.35841, mean: 0.06314
[32m[0906 21-36-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10448, current rewards: 40.91013, mean: 0.06707
[32m[0906 21-36-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10437, current rewards: 46.46554, mean: 0.07040
[32m[0906 21-36-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10426, current rewards: 52.01242, mean: 0.07326
[32m[0906 21-36-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10416, current rewards: 52.06519, mean: 0.06851
[32m[0906 21-36-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10404, current rewards: 57.74097, mean: 0.07129
[32m[0906 21-36-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10393, current rewards: 63.36325, mean: 0.07368
[32m[0906 21-36-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10389, current rewards: 68.98153, mean: 0.07580
[32m[0906 21-36-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10381, current rewards: 74.26023, mean: 0.07735
[32m[0906 21-36-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10373, current rewards: 67.30590, mean: 0.06664
[32m[0906 21-37-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10369, current rewards: 73.19120, mean: 0.06905
[32m[0906 21-37-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10365, current rewards: 79.07724, mean: 0.07124
[32m[0906 21-37-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10359, current rewards: 84.96411, mean: 0.07324
[32m[0906 21-37-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10353, current rewards: 90.85230, mean: 0.07508
[32m[0906 21-37-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10350, current rewards: 96.73544, mean: 0.07677
[32m[0906 21-37-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10347, current rewards: 102.62213, mean: 0.07834
[32m[0906 21-37-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10344, current rewards: 109.66410, mean: 0.08064
[32m[0906 21-37-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10343, current rewards: 115.99162, mean: 0.08226
[32m[0906 21-37-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10340, current rewards: 122.31934, mean: 0.08378
[32m[0906 21-37-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10337, current rewards: 128.64763, mean: 0.08520
[32m[0906 21-37-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10344, current rewards: 134.97611, mean: 0.08652
[32m[0906 21-37-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10350, current rewards: 133.95130, mean: 0.08320
[32m[0906 21-38-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10354, current rewards: 139.59712, mean: 0.08409
[32m[0906 21-38-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10361, current rewards: 145.24425, mean: 0.08494
[32m[0906 21-38-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10367, current rewards: 150.62036, mean: 0.08558
[32m[0906 21-38-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10370, current rewards: 156.30081, mean: 0.08635
[32m[0906 21-38-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10375, current rewards: 161.99773, mean: 0.08710
[32m[0906 21-38-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10379, current rewards: 167.70073, mean: 0.08780
[32m[0906 21-38-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10378, current rewards: 173.39618, mean: 0.08847
[32m[0906 21-38-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10376, current rewards: 179.09653, mean: 0.08910
[32m[0906 21-38-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10374, current rewards: 184.79723, mean: 0.08971
[32m[0906 21-38-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10372, current rewards: 190.49644, mean: 0.09028
[32m[0906 21-38-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10371, current rewards: 196.11675, mean: 0.09079
[32m[0906 21-39-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10374, current rewards: 202.07872, mean: 0.09144
[32m[0906 21-39-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10370, current rewards: 207.74390, mean: 0.09192
[32m[0906 21-39-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10363, current rewards: 213.41410, mean: 0.09239
[32m[0906 21-39-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10349, current rewards: 219.08096, mean: 0.09283
[32m[0906 21-39-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10337, current rewards: 224.74575, mean: 0.09326
[32m[0906 21-39-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10324, current rewards: 230.41553, mean: 0.09366
[32m[0906 21-39-30 @Agent.py:117][0m Average action selection time: 0.1031
[32m[0906 21-39-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-39-30 @MBExp.py:227][0m Rewards obtained: [234.9527339045517], Lows: [16], Highs: [17], Total time: 21406.196422999998
[32m[0906 21-42-13 @MBExp.py:144][0m ####################################################################
[32m[0906 21-42-13 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 21-42-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09872, current rewards: -6.81480, mean: -0.68148
[32m[0906 21-42-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09979, current rewards: -1.66966, mean: -0.02783
[32m[0906 21-42-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10000, current rewards: 3.53052, mean: 0.03210
[32m[0906 21-42-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09990, current rewards: 8.85691, mean: 0.05536
[32m[0906 21-42-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09993, current rewards: 14.18249, mean: 0.06754
[32m[0906 21-42-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09981, current rewards: 19.51019, mean: 0.07504
[32m[0906 21-42-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09984, current rewards: 19.34254, mean: 0.06240
[32m[0906 21-42-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09986, current rewards: 24.84930, mean: 0.06903
[32m[0906 21-42-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09986, current rewards: 30.34952, mean: 0.07402
[32m[0906 21-42-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09976, current rewards: 35.85165, mean: 0.07794
[32m[0906 21-43-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09947, current rewards: 41.32341, mean: 0.08103
[32m[0906 21-43-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09922, current rewards: 46.81807, mean: 0.08360
[32m[0906 21-43-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09903, current rewards: 52.33050, mean: 0.08579
[32m[0906 21-43-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09887, current rewards: 57.82900, mean: 0.08762
[32m[0906 21-43-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09871, current rewards: 52.38653, mean: 0.07378
[32m[0906 21-43-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09861, current rewards: 57.87605, mean: 0.07615
[32m[0906 21-43-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09851, current rewards: 63.36355, mean: 0.07823
[32m[0906 21-43-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09842, current rewards: 68.85822, mean: 0.08007
[32m[0906 21-43-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09835, current rewards: 74.41782, mean: 0.08178
[32m[0906 21-43-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09826, current rewards: 79.90652, mean: 0.08324
[32m[0906 21-43-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09820, current rewards: 85.41354, mean: 0.08457
[32m[0906 21-43-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09814, current rewards: 90.91090, mean: 0.08577
[32m[0906 21-44-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09809, current rewards: 96.40700, mean: 0.08685
[32m[0906 21-44-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09804, current rewards: 101.90824, mean: 0.08785
[32m[0906 21-44-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09799, current rewards: 107.40386, mean: 0.08876
[32m[0906 21-44-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09793, current rewards: 112.90481, mean: 0.08961
[32m[0906 21-44-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09753, current rewards: 118.08889, mean: 0.09014
[32m[0906 21-44-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09720, current rewards: 123.63803, mean: 0.09091
[32m[0906 21-44-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09683, current rewards: 129.19117, mean: 0.09162
[32m[0906 21-44-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09649, current rewards: 134.75438, mean: 0.09230
[32m[0906 21-44-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09617, current rewards: 140.30949, mean: 0.09292
[32m[0906 21-44-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09596, current rewards: 145.86043, mean: 0.09350
[32m[0906 21-44-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09576, current rewards: 140.95292, mean: 0.08755
[32m[0906 21-44-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09558, current rewards: 147.11443, mean: 0.08862
[32m[0906 21-44-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09540, current rewards: 153.02287, mean: 0.08949
[32m[0906 21-45-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09524, current rewards: 159.15022, mean: 0.09043
[32m[0906 21-45-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09508, current rewards: 165.28282, mean: 0.09132
[32m[0906 21-45-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09494, current rewards: 171.41149, mean: 0.09216
[32m[0906 21-45-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09479, current rewards: 177.53697, mean: 0.09295
[32m[0906 21-45-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09460, current rewards: 183.66523, mean: 0.09371
[32m[0906 21-45-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09443, current rewards: 189.79656, mean: 0.09443
[32m[0906 21-45-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09425, current rewards: 195.92558, mean: 0.09511
[32m[0906 21-45-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09407, current rewards: 203.17735, mean: 0.09629
[32m[0906 21-45-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09392, current rewards: 191.01354, mean: 0.08843
[32m[0906 21-45-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09381, current rewards: 143.12802, mean: 0.06476
[32m[0906 21-45-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09366, current rewards: 148.43507, mean: 0.06568
[32m[0906 21-45-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09351, current rewards: 153.88341, mean: 0.06662
[32m[0906 21-45-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09337, current rewards: 159.32984, mean: 0.06751
[32m[0906 21-45-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09324, current rewards: 164.78088, mean: 0.06837
[32m[0906 21-46-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09312, current rewards: 170.23971, mean: 0.06920
[32m[0906 21-46-06 @Agent.py:117][0m Average action selection time: 0.0930
[32m[0906 21-46-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-46-06 @MBExp.py:227][0m Rewards obtained: [174.60580871254487], Lows: [10], Highs: [78], Total time: 21639.462867
[32m[0906 21-48-34 @MBExp.py:144][0m ####################################################################
[32m[0906 21-48-34 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 21-48-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08866, current rewards: -0.40821, mean: -0.04082
[32m[0906 21-48-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08967, current rewards: 5.09594, mean: 0.08493
[32m[0906 21-48-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08968, current rewards: 13.17022, mean: 0.11973
[32m[0906 21-48-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08964, current rewards: 21.24451, mean: 0.13278
[32m[0906 21-48-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08962, current rewards: 29.31879, mean: 0.13961
[32m[0906 21-48-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08956, current rewards: 37.39308, mean: 0.14382
[32m[0906 21-49-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08958, current rewards: 32.69102, mean: 0.10545
[32m[0906 21-49-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08959, current rewards: -17.30898, mean: -0.04808
[32m[0906 21-49-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08953, current rewards: -67.30898, mean: -0.16417
[32m[0906 21-49-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08926, current rewards: -117.30898, mean: -0.25502
[32m[0906 21-49-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08900, current rewards: -167.30898, mean: -0.32806
[32m[0906 21-49-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08885, current rewards: -217.30898, mean: -0.38805
[32m[0906 21-49-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08869, current rewards: -267.30898, mean: -0.43821
[32m[0906 21-49-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08856, current rewards: -317.30898, mean: -0.48077
[32m[0906 21-49-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08844, current rewards: -367.30898, mean: -0.51734
[32m[0906 21-49-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08832, current rewards: -417.30898, mean: -0.54909
[32m[0906 21-49-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08825, current rewards: -467.30898, mean: -0.57692
[32m[0906 21-49-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08815, current rewards: -517.30898, mean: -0.60152
[32m[0906 21-49-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08810, current rewards: -567.30898, mean: -0.62342
[32m[0906 21-49-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08805, current rewards: -617.30898, mean: -0.64303
[32m[0906 21-50-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08800, current rewards: -667.30898, mean: -0.66070
[32m[0906 21-50-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08794, current rewards: -717.30898, mean: -0.67671
[32m[0906 21-50-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08789, current rewards: -767.30898, mean: -0.69127
[32m[0906 21-50-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08785, current rewards: -817.30898, mean: -0.70458
[32m[0906 21-50-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08782, current rewards: -867.30898, mean: -0.71678
[32m[0906 21-50-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08778, current rewards: -917.30898, mean: -0.72802
[32m[0906 21-50-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08775, current rewards: -967.30898, mean: -0.73840
[32m[0906 21-50-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08773, current rewards: -1017.30898, mean: -0.74802
[32m[0906 21-50-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08771, current rewards: -1067.30898, mean: -0.75696
[32m[0906 21-50-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08767, current rewards: -1117.30898, mean: -0.76528
[32m[0906 21-50-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08766, current rewards: -1167.30898, mean: -0.77305
[32m[0906 21-50-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08773, current rewards: -1217.30898, mean: -0.78033
[32m[0906 21-50-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08779, current rewards: -1267.30898, mean: -0.78715
[32m[0906 21-51-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08786, current rewards: -1317.30898, mean: -0.79356
[32m[0906 21-51-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08791, current rewards: -1367.30898, mean: -0.79960
[32m[0906 21-51-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08795, current rewards: -1417.30898, mean: -0.80529
[32m[0906 21-51-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08799, current rewards: -1467.30898, mean: -0.81067
[32m[0906 21-51-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08803, current rewards: -1517.30898, mean: -0.81576
[32m[0906 21-51-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08806, current rewards: -1567.30898, mean: -0.82058
[32m[0906 21-51-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08804, current rewards: -1617.30898, mean: -0.82516
[32m[0906 21-51-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08801, current rewards: -1667.30898, mean: -0.82951
[32m[0906 21-51-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08800, current rewards: -1717.30898, mean: -0.83365
[32m[0906 21-51-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08797, current rewards: -1767.30898, mean: -0.83759
[32m[0906 21-51-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08798, current rewards: -1817.30898, mean: -0.84135
[32m[0906 21-51-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08799, current rewards: -1867.30898, mean: -0.84494
[32m[0906 21-51-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08797, current rewards: -1917.30898, mean: -0.84837
[32m[0906 21-51-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08795, current rewards: -1967.30898, mean: -0.85165
[32m[0906 21-52-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08792, current rewards: -2017.30898, mean: -0.85479
[32m[0906 21-52-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08791, current rewards: -2067.30898, mean: -0.85780
[32m[0906 21-52-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08789, current rewards: -2117.30898, mean: -0.86069
[32m[0906 21-52-15 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0906 21-52-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-52-15 @MBExp.py:227][0m Rewards obtained: [-2157.308976127595], Lows: [1], Highs: [2203], Total time: 21859.856216999997
[32m[0906 21-54-45 @MBExp.py:144][0m ####################################################################
[32m[0906 21-54-45 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 21-54-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08776, current rewards: -12.92276, mean: -1.29228
[32m[0906 21-54-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08916, current rewards: -25.92458, mean: -0.43208
[32m[0906 21-54-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08924, current rewards: -18.90644, mean: -0.17188
[32m[0906 21-54-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08923, current rewards: -13.10253, mean: -0.08189
[32m[0906 21-55-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08925, current rewards: -7.30819, mean: -0.03480
[32m[0906 21-55-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08929, current rewards: -1.50892, mean: -0.00580
[32m[0906 21-55-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08930, current rewards: 4.29330, mean: 0.01385
[32m[0906 21-55-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08929, current rewards: -0.27817, mean: -0.00077
[32m[0906 21-55-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08909, current rewards: 5.30103, mean: 0.01293
[32m[0906 21-55-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08886, current rewards: 10.88929, mean: 0.02367
[32m[0906 21-55-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08865, current rewards: 16.39497, mean: 0.03215
[32m[0906 21-55-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08852, current rewards: 21.96644, mean: 0.03923
[32m[0906 21-55-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08839, current rewards: 27.53918, mean: 0.04515
[32m[0906 21-55-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08829, current rewards: 33.11059, mean: 0.05017
[32m[0906 21-55-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08820, current rewards: 38.68256, mean: 0.05448
[32m[0906 21-55-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08811, current rewards: 44.25234, mean: 0.05823
[32m[0906 21-55-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08802, current rewards: 49.77522, mean: 0.06145
[32m[0906 21-56-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08795, current rewards: 55.33892, mean: 0.06435
[32m[0906 21-56-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08789, current rewards: 60.74854, mean: 0.06676
[32m[0906 21-56-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08783, current rewards: 66.30996, mean: 0.06907
[32m[0906 21-56-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08779, current rewards: 59.39688, mean: 0.05881
[32m[0906 21-56-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08776, current rewards: 65.29435, mean: 0.06160
[32m[0906 21-56-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08771, current rewards: 70.97772, mean: 0.06394
[32m[0906 21-56-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08767, current rewards: 76.65975, mean: 0.06609
[32m[0906 21-56-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08764, current rewards: 82.34386, mean: 0.06805
[32m[0906 21-56-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08760, current rewards: 88.02430, mean: 0.06986
[32m[0906 21-56-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08759, current rewards: 94.44609, mean: 0.07210
[32m[0906 21-56-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08757, current rewards: 82.39887, mean: 0.06059
[32m[0906 21-56-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08756, current rewards: 87.92346, mean: 0.06236
[32m[0906 21-56-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08754, current rewards: 93.44230, mean: 0.06400
[32m[0906 21-56-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08752, current rewards: 98.96392, mean: 0.06554
[32m[0906 21-57-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08757, current rewards: 104.48185, mean: 0.06698
[32m[0906 21-57-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08763, current rewards: 110.00524, mean: 0.06833
[32m[0906 21-57-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08768, current rewards: 105.97880, mean: 0.06384
[32m[0906 21-57-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08773, current rewards: 111.65514, mean: 0.06530
[32m[0906 21-57-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08778, current rewards: 116.67241, mean: 0.06629
[32m[0906 21-57-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08783, current rewards: 122.34333, mean: 0.06759
[32m[0906 21-57-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08788, current rewards: 128.01077, mean: 0.06882
[32m[0906 21-57-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08792, current rewards: 133.68193, mean: 0.06999
[32m[0906 21-57-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08790, current rewards: 139.35212, mean: 0.07110
[32m[0906 21-57-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08788, current rewards: 145.02163, mean: 0.07215
[32m[0906 21-57-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08785, current rewards: 150.69575, mean: 0.07315
[32m[0906 21-57-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08783, current rewards: 155.25517, mean: 0.07358
[32m[0906 21-57-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08786, current rewards: 156.18570, mean: 0.07231
[32m[0906 21-58-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08786, current rewards: 161.76544, mean: 0.07320
[32m[0906 21-58-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08784, current rewards: 167.33948, mean: 0.07404
[32m[0906 21-58-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08782, current rewards: 172.90878, mean: 0.07485
[32m[0906 21-58-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08780, current rewards: 178.48320, mean: 0.07563
[32m[0906 21-58-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08778, current rewards: 184.06178, mean: 0.07637
[32m[0906 21-58-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08777, current rewards: 189.64501, mean: 0.07709
[32m[0906 21-58-25 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0906 21-58-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-58-25 @MBExp.py:227][0m Rewards obtained: [194.10146285627545], Lows: [29], Highs: [26], Total time: 22079.960982999997
[32m[0906 22-00-57 @MBExp.py:144][0m ####################################################################
[32m[0906 22-00-57 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 22-00-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08913, current rewards: -5.61665, mean: -0.56166
[32m[0906 22-01-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08955, current rewards: -0.16272, mean: -0.00271
[32m[0906 22-01-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08961, current rewards: 5.33266, mean: 0.04848
[32m[0906 22-01-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08964, current rewards: 10.82122, mean: 0.06763
[32m[0906 22-01-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08959, current rewards: 16.30965, mean: 0.07766
[32m[0906 22-01-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08960, current rewards: 11.39665, mean: 0.04383
[32m[0906 22-01-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08957, current rewards: 17.37413, mean: 0.05605
[32m[0906 22-01-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08952, current rewards: 23.33102, mean: 0.06481
[32m[0906 22-01-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08936, current rewards: 29.28084, mean: 0.07142
[32m[0906 22-01-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08908, current rewards: 35.23841, mean: 0.07661
[32m[0906 22-01-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08887, current rewards: 41.18930, mean: 0.08076
[32m[0906 22-01-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08869, current rewards: 41.25828, mean: 0.07368
[32m[0906 22-01-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08855, current rewards: 46.66428, mean: 0.07650
[32m[0906 22-01-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08844, current rewards: 52.06957, mean: 0.07889
[32m[0906 22-02-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08833, current rewards: 57.47643, mean: 0.08095
[32m[0906 22-02-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08822, current rewards: 62.88254, mean: 0.08274
[32m[0906 22-02-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08816, current rewards: 68.29075, mean: 0.08431
[32m[0906 22-02-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08810, current rewards: 73.59940, mean: 0.08558
[32m[0906 22-02-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08803, current rewards: 79.00897, mean: 0.08682
[32m[0906 22-02-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08797, current rewards: 84.41716, mean: 0.08793
[32m[0906 22-02-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08793, current rewards: 89.82154, mean: 0.08893
[32m[0906 22-02-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08789, current rewards: 98.27785, mean: 0.09271
[32m[0906 22-02-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08788, current rewards: 103.73517, mean: 0.09346
[32m[0906 22-02-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08785, current rewards: 109.18984, mean: 0.09413
[32m[0906 22-02-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08782, current rewards: 114.64416, mean: 0.09475
[32m[0906 22-02-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08779, current rewards: 120.04997, mean: 0.09528
[32m[0906 22-02-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08777, current rewards: 125.50795, mean: 0.09581
[32m[0906 22-02-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08773, current rewards: 130.96751, mean: 0.09630
[32m[0906 22-03-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08771, current rewards: 136.42639, mean: 0.09676
[32m[0906 22-03-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08767, current rewards: 141.88431, mean: 0.09718
[32m[0906 22-03-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08763, current rewards: 147.34339, mean: 0.09758
[32m[0906 22-03-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08762, current rewards: 152.79848, mean: 0.09795
[32m[0906 22-03-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08760, current rewards: 147.75280, mean: 0.09177
[32m[0906 22-03-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08767, current rewards: 153.26698, mean: 0.09233
[32m[0906 22-03-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08771, current rewards: 158.77746, mean: 0.09285
[32m[0906 22-03-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08776, current rewards: 164.29605, mean: 0.09335
[32m[0906 22-03-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08781, current rewards: 169.80495, mean: 0.09381
[32m[0906 22-03-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08786, current rewards: 175.32034, mean: 0.09426
[32m[0906 22-03-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08789, current rewards: 180.83449, mean: 0.09468
[32m[0906 22-03-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08786, current rewards: 186.35284, mean: 0.09508
[32m[0906 22-03-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08784, current rewards: 181.45428, mean: 0.09028
[32m[0906 22-03-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08781, current rewards: 186.60471, mean: 0.09058
[32m[0906 22-04-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08778, current rewards: 192.07665, mean: 0.09103
[32m[0906 22-04-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08778, current rewards: 197.76348, mean: 0.09156
[32m[0906 22-04-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08778, current rewards: 203.44841, mean: 0.09206
[32m[0906 22-04-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08777, current rewards: 209.13518, mean: 0.09254
[32m[0906 22-04-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08775, current rewards: 214.81909, mean: 0.09300
[32m[0906 22-04-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08774, current rewards: 220.50208, mean: 0.09343
[32m[0906 22-04-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08773, current rewards: 226.18127, mean: 0.09385
[32m[0906 22-04-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08772, current rewards: 231.86473, mean: 0.09425
[32m[0906 22-04-37 @Agent.py:117][0m Average action selection time: 0.0877
[32m[0906 22-04-37 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-04-37 @MBExp.py:227][0m Rewards obtained: [237.57862468430417], Lows: [15], Highs: [11], Total time: 22299.936873
[32m[0906 22-07-11 @MBExp.py:144][0m ####################################################################
[32m[0906 22-07-11 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 22-07-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08957, current rewards: -1.32915, mean: -0.13292
[32m[0906 22-07-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08969, current rewards: 4.02647, mean: 0.06711
[32m[0906 22-07-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08968, current rewards: 9.59440, mean: 0.08722
[32m[0906 22-07-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08961, current rewards: 15.16367, mean: 0.09477
[32m[0906 22-07-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08955, current rewards: 20.72982, mean: 0.09871
[32m[0906 22-07-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08953, current rewards: 26.30061, mean: 0.10116
[32m[0906 22-07-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08953, current rewards: 31.86880, mean: 0.10280
[32m[0906 22-07-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08952, current rewards: 29.99846, mean: 0.08333
[32m[0906 22-07-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08939, current rewards: 35.51595, mean: 0.08662
[32m[0906 22-07-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08912, current rewards: 41.67250, mean: 0.09059
[32m[0906 22-07-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08889, current rewards: 47.17645, mean: 0.09250
[32m[0906 22-08-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08871, current rewards: 52.68003, mean: 0.09407
[32m[0906 22-08-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08857, current rewards: 58.18112, mean: 0.09538
[32m[0906 22-08-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08842, current rewards: 63.68492, mean: 0.09649
[32m[0906 22-08-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08833, current rewards: 69.18756, mean: 0.09745
[32m[0906 22-08-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08825, current rewards: 74.69108, mean: 0.09828
[32m[0906 22-08-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08817, current rewards: 80.19146, mean: 0.09900
[32m[0906 22-08-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08809, current rewards: 78.99611, mean: 0.09186
[32m[0906 22-08-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08802, current rewards: 84.50770, mean: 0.09287
[32m[0906 22-08-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08794, current rewards: 90.01474, mean: 0.09377
[32m[0906 22-08-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08788, current rewards: 95.53070, mean: 0.09458
[32m[0906 22-08-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08783, current rewards: 101.03987, mean: 0.09532
[32m[0906 22-08-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08779, current rewards: 106.54813, mean: 0.09599
[32m[0906 22-08-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08774, current rewards: 112.05984, mean: 0.09660
[32m[0906 22-08-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08771, current rewards: 107.09194, mean: 0.08851
[32m[0906 22-09-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08768, current rewards: 112.26086, mean: 0.08910
[32m[0906 22-09-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08765, current rewards: 117.81183, mean: 0.08993
[32m[0906 22-09-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08763, current rewards: 123.35555, mean: 0.09070
[32m[0906 22-09-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08760, current rewards: 128.89491, mean: 0.09141
[32m[0906 22-09-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08758, current rewards: 134.43817, mean: 0.09208
[32m[0906 22-09-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08757, current rewards: 139.98011, mean: 0.09270
[32m[0906 22-09-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08755, current rewards: 145.51999, mean: 0.09328
[32m[0906 22-09-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08755, current rewards: 151.06734, mean: 0.09383
[32m[0906 22-09-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08762, current rewards: 157.06973, mean: 0.09462
[32m[0906 22-09-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08769, current rewards: 163.10598, mean: 0.09538
[32m[0906 22-09-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08774, current rewards: 168.64165, mean: 0.09582
[32m[0906 22-09-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08779, current rewards: 174.11072, mean: 0.09619
[32m[0906 22-09-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08783, current rewards: 177.58508, mean: 0.09548
[32m[0906 22-09-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08788, current rewards: 183.17964, mean: 0.09591
[32m[0906 22-10-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08785, current rewards: 188.77011, mean: 0.09631
[32m[0906 22-10-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08783, current rewards: 194.36587, mean: 0.09670
[32m[0906 22-10-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08781, current rewards: 199.95731, mean: 0.09707
[32m[0906 22-10-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08780, current rewards: 204.74164, mean: 0.09703
[32m[0906 22-10-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08778, current rewards: 210.35646, mean: 0.09739
[32m[0906 22-10-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08773, current rewards: 215.94449, mean: 0.09771
[32m[0906 22-10-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08772, current rewards: 221.53904, mean: 0.09803
[32m[0906 22-10-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08770, current rewards: 227.13533, mean: 0.09833
[32m[0906 22-10-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08770, current rewards: 232.73423, mean: 0.09862
[32m[0906 22-10-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08768, current rewards: 238.32908, mean: 0.09889
[32m[0906 22-10-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08767, current rewards: 233.16949, mean: 0.09478
[32m[0906 22-10-51 @Agent.py:117][0m Average action selection time: 0.0877
[32m[0906 22-10-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-10-51 @MBExp.py:227][0m Rewards obtained: [237.63066472424714], Lows: [14], Highs: [10], Total time: 22519.813303
[32m[0906 22-13-26 @MBExp.py:144][0m ####################################################################
[32m[0906 22-13-26 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 22-13-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08982, current rewards: -6.09851, mean: -0.60985
[32m[0906 22-13-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08964, current rewards: -2.52272, mean: -0.04205
[32m[0906 22-13-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08967, current rewards: 2.93507, mean: 0.02668
[32m[0906 22-13-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08960, current rewards: 8.39404, mean: 0.05246
[32m[0906 22-13-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08956, current rewards: 13.84901, mean: 0.06595
[32m[0906 22-13-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08953, current rewards: 19.31046, mean: 0.07427
[32m[0906 22-13-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08950, current rewards: 24.76671, mean: 0.07989
[32m[0906 22-13-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08950, current rewards: 30.22502, mean: 0.08396
[32m[0906 22-14-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08919, current rewards: 35.67901, mean: 0.08702
[32m[0906 22-14-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08894, current rewards: 41.13129, mean: 0.08942
[32m[0906 22-14-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08871, current rewards: 46.59000, mean: 0.09135
[32m[0906 22-14-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08855, current rewards: 52.04666, mean: 0.09294
[32m[0906 22-14-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08841, current rewards: 57.50789, mean: 0.09428
[32m[0906 22-14-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08828, current rewards: 52.78718, mean: 0.07998
[32m[0906 22-14-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08817, current rewards: 58.89895, mean: 0.08296
[32m[0906 22-14-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08805, current rewards: 65.00662, mean: 0.08554
[32m[0906 22-14-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08800, current rewards: 71.11405, mean: 0.08780
[32m[0906 22-14-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08794, current rewards: 77.16177, mean: 0.08972
[32m[0906 22-14-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08788, current rewards: 83.25999, mean: 0.09149
[32m[0906 22-14-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08783, current rewards: 79.63965, mean: 0.08296
[32m[0906 22-14-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08778, current rewards: 85.72466, mean: 0.08488
[32m[0906 22-15-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08775, current rewards: 91.81278, mean: 0.08662
[32m[0906 22-15-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08771, current rewards: 97.90011, mean: 0.08820
[32m[0906 22-15-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08768, current rewards: 103.98754, mean: 0.08964
[32m[0906 22-15-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08764, current rewards: 110.07729, mean: 0.09097
[32m[0906 22-15-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08761, current rewards: 116.48354, mean: 0.09245
[32m[0906 22-15-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08758, current rewards: 122.66232, mean: 0.09364
[32m[0906 22-15-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08754, current rewards: 128.83365, mean: 0.09473
[32m[0906 22-15-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08753, current rewards: 130.12701, mean: 0.09229
[32m[0906 22-15-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08749, current rewards: 138.06909, mean: 0.09457
[32m[0906 22-15-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08747, current rewards: 145.98784, mean: 0.09668
[32m[0906 22-15-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08746, current rewards: 153.92528, mean: 0.09867
[32m[0906 22-15-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08748, current rewards: 161.85075, mean: 0.10053
[32m[0906 22-15-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08754, current rewards: 169.64265, mean: 0.10219
[32m[0906 22-15-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08760, current rewards: 177.52810, mean: 0.10382
[32m[0906 22-16-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08764, current rewards: 185.41940, mean: 0.10535
[32m[0906 22-16-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08769, current rewards: 193.29817, mean: 0.10679
[32m[0906 22-16-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08774, current rewards: 188.38153, mean: 0.10128
[32m[0906 22-16-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08778, current rewards: 193.75881, mean: 0.10144
[32m[0906 22-16-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08779, current rewards: 199.13958, mean: 0.10160
[32m[0906 22-16-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08776, current rewards: 204.52405, mean: 0.10175
[32m[0906 22-16-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08774, current rewards: 210.13413, mean: 0.10201
[32m[0906 22-16-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08772, current rewards: 215.51658, mean: 0.10214
[32m[0906 22-16-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08770, current rewards: 220.89440, mean: 0.10227
[32m[0906 22-16-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08767, current rewards: 215.10877, mean: 0.09733
[32m[0906 22-16-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08765, current rewards: 221.08280, mean: 0.09782
[32m[0906 22-16-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08765, current rewards: 227.06255, mean: 0.09830
[32m[0906 22-16-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08763, current rewards: 233.04139, mean: 0.09875
[32m[0906 22-16-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08761, current rewards: 239.01941, mean: 0.09918
[32m[0906 22-17-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08759, current rewards: 245.31564, mean: 0.09972
[32m[0906 22-17-06 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0906 22-17-06 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-17-06 @MBExp.py:227][0m Rewards obtained: [250.10450073697572], Lows: [23], Highs: [10], Total time: 22739.476016
[32m[0906 22-19-43 @MBExp.py:144][0m ####################################################################
[32m[0906 22-19-43 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 22-19-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08958, current rewards: -9.37396, mean: -0.93740
[32m[0906 22-19-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09002, current rewards: -3.08583, mean: -0.05143
[32m[0906 22-19-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08994, current rewards: -9.46424, mean: -0.08604
[32m[0906 22-19-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08985, current rewards: -5.45756, mean: -0.03411
[32m[0906 22-20-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08971, current rewards: 2.09479, mean: 0.00998
[32m[0906 22-20-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08968, current rewards: -7.58763, mean: -0.02918
[32m[0906 22-20-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08966, current rewards: -2.81850, mean: -0.00909
[32m[0906 22-20-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08966, current rewards: -9.50539, mean: -0.02640
[32m[0906 22-20-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08935, current rewards: -6.57076, mean: -0.01603
[32m[0906 22-20-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08908, current rewards: 0.98436, mean: 0.00214
[32m[0906 22-20-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08887, current rewards: -7.52873, mean: -0.01476
[32m[0906 22-20-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08869, current rewards: -3.60091, mean: -0.00643
[32m[0906 22-20-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08858, current rewards: -7.81799, mean: -0.01282
[32m[0906 22-20-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08847, current rewards: -1.61091, mean: -0.00244
[32m[0906 22-20-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08840, current rewards: 4.34361, mean: 0.00612
[32m[0906 22-20-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08829, current rewards: 11.18968, mean: 0.01472
[32m[0906 22-20-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08822, current rewards: 17.72342, mean: 0.02188
[32m[0906 22-20-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08817, current rewards: 23.67801, mean: 0.02753
[32m[0906 22-21-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08810, current rewards: 29.62600, mean: 0.03256
[32m[0906 22-21-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08802, current rewards: 35.58857, mean: 0.03707
[32m[0906 22-21-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08795, current rewards: 41.53494, mean: 0.04112
[32m[0906 22-21-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08792, current rewards: 47.49638, mean: 0.04481
[32m[0906 22-21-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08788, current rewards: 53.44797, mean: 0.04815
[32m[0906 22-21-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08787, current rewards: 59.81857, mean: 0.05157
[32m[0906 22-21-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08783, current rewards: 65.16349, mean: 0.05385
[32m[0906 22-21-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08781, current rewards: 71.04952, mean: 0.05639
[32m[0906 22-21-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08778, current rewards: 76.94268, mean: 0.05873
[32m[0906 22-21-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08776, current rewards: 82.83404, mean: 0.06091
[32m[0906 22-21-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08774, current rewards: 88.71792, mean: 0.06292
[32m[0906 22-21-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08772, current rewards: 94.61081, mean: 0.06480
[32m[0906 22-21-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08769, current rewards: 100.50152, mean: 0.06656
[32m[0906 22-22-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08767, current rewards: 106.39132, mean: 0.06820
[32m[0906 22-22-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08767, current rewards: 97.56349, mean: 0.06060
[32m[0906 22-22-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08771, current rewards: 102.95935, mean: 0.06202
[32m[0906 22-22-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08777, current rewards: 108.36224, mean: 0.06337
[32m[0906 22-22-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08782, current rewards: 113.76096, mean: 0.06464
[32m[0906 22-22-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08787, current rewards: 119.15879, mean: 0.06583
[32m[0906 22-22-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08792, current rewards: 124.55833, mean: 0.06697
[32m[0906 22-22-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08796, current rewards: 125.35430, mean: 0.06563
[32m[0906 22-22-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08797, current rewards: 131.06313, mean: 0.06687
[32m[0906 22-22-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08795, current rewards: 136.96661, mean: 0.06814
[32m[0906 22-22-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08794, current rewards: 142.65571, mean: 0.06925
[32m[0906 22-22-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08791, current rewards: 148.34493, mean: 0.07031
[32m[0906 22-22-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08790, current rewards: 154.04389, mean: 0.07132
[32m[0906 22-22-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08784, current rewards: 159.74063, mean: 0.07228
[32m[0906 22-23-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08782, current rewards: 165.43455, mean: 0.07320
[32m[0906 22-23-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08781, current rewards: 171.13255, mean: 0.07408
[32m[0906 22-23-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08779, current rewards: 176.82585, mean: 0.07493
[32m[0906 22-23-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08778, current rewards: 182.82553, mean: 0.07586
[32m[0906 22-23-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08777, current rewards: 188.99382, mean: 0.07683
[32m[0906 22-23-23 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0906 22-23-23 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-23-23 @MBExp.py:227][0m Rewards obtained: [193.5364596428083], Lows: [108], Highs: [11], Total time: 22959.577626000002
[32m[0906 22-26-02 @MBExp.py:144][0m ####################################################################
[32m[0906 22-26-02 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 22-26-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08831, current rewards: -15.00000, mean: -1.50000
[32m[0906 22-26-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08928, current rewards: -115.00000, mean: -1.91667
[32m[0906 22-26-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08957, current rewards: -215.00000, mean: -1.95455
[32m[0906 22-26-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08951, current rewards: -315.00000, mean: -1.96875
[32m[0906 22-26-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08951, current rewards: -415.00000, mean: -1.97619
[32m[0906 22-26-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08957, current rewards: -515.00000, mean: -1.98077
[32m[0906 22-26-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08954, current rewards: -615.00000, mean: -1.98387
[32m[0906 22-26-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08931, current rewards: -715.00000, mean: -1.98611
[32m[0906 22-26-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08903, current rewards: -815.00000, mean: -1.98780
[32m[0906 22-26-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08880, current rewards: -915.00000, mean: -1.98913
[32m[0906 22-26-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08858, current rewards: -1015.00000, mean: -1.99020
[32m[0906 22-26-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08846, current rewards: -1115.00000, mean: -1.99107
[32m[0906 22-26-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08832, current rewards: -1215.00000, mean: -1.99180
[32m[0906 22-27-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08824, current rewards: -1315.00000, mean: -1.99242
[32m[0906 22-27-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08837, current rewards: -1415.00000, mean: -1.99296
[32m[0906 22-27-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08895, current rewards: -1515.00000, mean: -1.99342
[32m[0906 22-27-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08947, current rewards: -1615.00000, mean: -1.99383
[32m[0906 22-27-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08989, current rewards: -1715.00000, mean: -1.99419
[32m[0906 22-27-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09027, current rewards: -1815.00000, mean: -1.99451
[32m[0906 22-27-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09062, current rewards: -1915.00000, mean: -1.99479
[32m[0906 22-27-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09097, current rewards: -2015.00000, mean: -1.99505
[32m[0906 22-27-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09127, current rewards: -2115.00000, mean: -1.99528
[32m[0906 22-27-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09153, current rewards: -2215.00000, mean: -1.99550
[32m[0906 22-27-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09176, current rewards: -2315.00000, mean: -1.99569
[32m[0906 22-27-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09200, current rewards: -2415.00000, mean: -1.99587
[32m[0906 22-27-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09221, current rewards: -2515.00000, mean: -1.99603
[32m[0906 22-28-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09238, current rewards: -2615.00000, mean: -1.99618
[32m[0906 22-28-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09254, current rewards: -2715.00000, mean: -1.99632
[32m[0906 22-28-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09270, current rewards: -2815.00000, mean: -1.99645
[32m[0906 22-28-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09284, current rewards: -2915.00000, mean: -1.99658
[32m[0906 22-28-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09298, current rewards: -3015.00000, mean: -1.99669
[32m[0906 22-28-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09310, current rewards: -3115.00000, mean: -1.99679
[32m[0906 22-28-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09328, current rewards: -3215.00000, mean: -1.99689
[32m[0906 22-28-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09348, current rewards: -3315.00000, mean: -1.99699
[32m[0906 22-28-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09367, current rewards: -3415.00000, mean: -1.99708
[32m[0906 22-28-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09385, current rewards: -3515.00000, mean: -1.99716
[32m[0906 22-28-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09402, current rewards: -3615.00000, mean: -1.99724
[32m[0906 22-28-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09419, current rewards: -3715.00000, mean: -1.99731
[32m[0906 22-29-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09434, current rewards: -3815.00000, mean: -1.99738
[32m[0906 22-29-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09443, current rewards: -3915.00000, mean: -1.99745
[32m[0906 22-29-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09450, current rewards: -4015.00000, mean: -1.99751
[32m[0906 22-29-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09456, current rewards: -4115.00000, mean: -1.99757
[32m[0906 22-29-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09462, current rewards: -4215.00000, mean: -1.99763
[32m[0906 22-29-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09465, current rewards: -4315.00000, mean: -1.99769
[32m[0906 22-29-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09469, current rewards: -4415.00000, mean: -1.99774
[32m[0906 22-29-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09475, current rewards: -4515.00000, mean: -1.99779
[32m[0906 22-29-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09480, current rewards: -4615.00000, mean: -1.99784
[32m[0906 22-29-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09485, current rewards: -4715.00000, mean: -1.99788
[32m[0906 22-29-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09490, current rewards: -4815.00000, mean: -1.99793
[32m[0906 22-29-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09495, current rewards: -4915.00000, mean: -1.99797
[32m[0906 22-30-00 @Agent.py:117][0m Average action selection time: 0.0950
[32m[0906 22-30-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-30-01 @MBExp.py:227][0m Rewards obtained: [-4995], Lows: [2495], Highs: [5], Total time: 23197.824389
[32m[0906 22-32-59 @MBExp.py:144][0m ####################################################################
[32m[0906 22-32-59 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 22-33-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10620, current rewards: -6.83937, mean: -0.68394
[32m[0906 22-33-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10099, current rewards: -1.41880, mean: -0.02365
[32m[0906 22-33-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10039, current rewards: 4.13441, mean: 0.03759
[32m[0906 22-33-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10021, current rewards: 9.68939, mean: 0.06056
[32m[0906 22-33-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10010, current rewards: 15.24294, mean: 0.07259
[32m[0906 22-33-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10007, current rewards: 20.79657, mean: 0.07999
[32m[0906 22-33-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09821, current rewards: 26.35040, mean: 0.08500
[32m[0906 22-33-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09665, current rewards: 31.94370, mean: 0.08873
[32m[0906 22-33-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09549, current rewards: 37.49832, mean: 0.09146
[32m[0906 22-33-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09452, current rewards: 43.05511, mean: 0.09360
[32m[0906 22-33-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09390, current rewards: 36.21083, mean: 0.07100
[32m[0906 22-33-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09329, current rewards: 41.85220, mean: 0.07474
[32m[0906 22-33-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09277, current rewards: 47.49731, mean: 0.07786
[32m[0906 22-34-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09231, current rewards: 53.14332, mean: 0.08052
[32m[0906 22-34-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09194, current rewards: 58.78777, mean: 0.08280
[32m[0906 22-34-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09163, current rewards: 64.65278, mean: 0.08507
[32m[0906 22-34-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09133, current rewards: 70.31357, mean: 0.08681
[32m[0906 22-34-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09107, current rewards: 75.97427, mean: 0.08834
[32m[0906 22-34-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09085, current rewards: 81.63338, mean: 0.08971
[32m[0906 22-34-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09064, current rewards: 81.40286, mean: 0.08479
[32m[0906 22-34-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09047, current rewards: 86.93247, mean: 0.08607
[32m[0906 22-34-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09030, current rewards: 92.46043, mean: 0.08723
[32m[0906 22-34-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09014, current rewards: 97.98884, mean: 0.08828
[32m[0906 22-34-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09001, current rewards: 103.94711, mean: 0.08961
[32m[0906 22-34-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08989, current rewards: 109.43939, mean: 0.09045
[32m[0906 22-34-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08977, current rewards: 114.93782, mean: 0.09122
[32m[0906 22-34-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08967, current rewards: 120.44182, mean: 0.09194
[32m[0906 22-35-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08957, current rewards: 125.67836, mean: 0.09241
[32m[0906 22-35-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08947, current rewards: 131.21210, mean: 0.09306
[32m[0906 22-35-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08940, current rewards: 136.74949, mean: 0.09366
[32m[0906 22-35-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08933, current rewards: 142.28440, mean: 0.09423
[32m[0906 22-35-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08924, current rewards: 147.78497, mean: 0.09473
[32m[0906 22-35-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08923, current rewards: 153.30525, mean: 0.09522
[32m[0906 22-35-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08924, current rewards: 158.83102, mean: 0.09568
[32m[0906 22-35-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08926, current rewards: 164.62500, mean: 0.09627
[32m[0906 22-35-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08927, current rewards: 170.20629, mean: 0.09671
[32m[0906 22-35-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08927, current rewards: 175.79291, mean: 0.09712
[32m[0906 22-35-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08929, current rewards: 181.38426, mean: 0.09752
[32m[0906 22-35-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08930, current rewards: 186.96555, mean: 0.09789
[32m[0906 22-35-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08926, current rewards: 192.55896, mean: 0.09824
[32m[0906 22-35-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08920, current rewards: 198.58122, mean: 0.09880
[32m[0906 22-36-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08918, current rewards: 192.18784, mean: 0.09330
[32m[0906 22-36-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08913, current rewards: 197.57935, mean: 0.09364
[32m[0906 22-36-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08906, current rewards: 202.97779, mean: 0.09397
[32m[0906 22-36-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08901, current rewards: 208.36878, mean: 0.09428
[32m[0906 22-36-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08896, current rewards: 213.75900, mean: 0.09458
[32m[0906 22-36-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08892, current rewards: 219.15598, mean: 0.09487
[32m[0906 22-36-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08888, current rewards: 224.54568, mean: 0.09515
[32m[0906 22-36-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08884, current rewards: 223.72717, mean: 0.09283
[32m[0906 22-36-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08881, current rewards: 229.28468, mean: 0.09321
[32m[0906 22-36-41 @Agent.py:117][0m Average action selection time: 0.0888
[32m[0906 22-36-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-36-41 @MBExp.py:227][0m Rewards obtained: [233.69609862817248], Lows: [12], Highs: [17], Total time: 23420.506344
[32m[0906 22-39-24 @MBExp.py:144][0m ####################################################################
[32m[0906 22-39-24 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 22-39-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09410, current rewards: -5.66788, mean: -0.56679
[32m[0906 22-39-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09012, current rewards: -0.32935, mean: -0.00549
[32m[0906 22-39-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08987, current rewards: 5.16515, mean: 0.04696
[32m[0906 22-39-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08986, current rewards: 10.66652, mean: 0.06667
[32m[0906 22-39-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08986, current rewards: 16.16831, mean: 0.07699
[32m[0906 22-39-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08952, current rewards: 21.66341, mean: 0.08332
[32m[0906 22-39-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08909, current rewards: 27.15796, mean: 0.08761
[32m[0906 22-39-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08882, current rewards: 32.48486, mean: 0.09024
[32m[0906 22-40-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08858, current rewards: 37.97158, mean: 0.09261
[32m[0906 22-40-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08840, current rewards: 43.45121, mean: 0.09446
[32m[0906 22-40-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08824, current rewards: 48.93676, mean: 0.09595
[32m[0906 22-40-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08811, current rewards: 55.28764, mean: 0.09873
[32m[0906 22-40-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08801, current rewards: 60.88850, mean: 0.09982
[32m[0906 22-40-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08792, current rewards: 66.32942, mean: 0.10050
[32m[0906 22-40-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08785, current rewards: 71.78257, mean: 0.10110
[32m[0906 22-40-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08778, current rewards: 77.77852, mean: 0.10234
[32m[0906 22-40-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08773, current rewards: 83.27936, mean: 0.10281
[32m[0906 22-40-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08768, current rewards: 88.77619, mean: 0.10323
[32m[0906 22-40-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08763, current rewards: 94.27320, mean: 0.10360
[32m[0906 22-40-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08762, current rewards: 99.77090, mean: 0.10393
[32m[0906 22-40-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08757, current rewards: 105.26838, mean: 0.10423
[32m[0906 22-40-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08753, current rewards: 110.76080, mean: 0.10449
[32m[0906 22-41-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08752, current rewards: 116.74999, mean: 0.10518
[32m[0906 22-41-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08750, current rewards: 121.88192, mean: 0.10507
[32m[0906 22-41-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08747, current rewards: 127.28528, mean: 0.10519
[32m[0906 22-41-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08745, current rewards: 132.68043, mean: 0.10530
[32m[0906 22-41-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08743, current rewards: 138.07307, mean: 0.10540
[32m[0906 22-41-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08742, current rewards: 143.46531, mean: 0.10549
[32m[0906 22-41-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08740, current rewards: 148.85501, mean: 0.10557
[32m[0906 22-41-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08738, current rewards: 143.69064, mean: 0.09842
[32m[0906 22-41-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08736, current rewards: 149.15893, mean: 0.09878
[32m[0906 22-41-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08735, current rewards: 154.67141, mean: 0.09915
[32m[0906 22-41-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08741, current rewards: 160.65450, mean: 0.09979
[32m[0906 22-41-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08748, current rewards: 166.16361, mean: 0.10010
[32m[0906 22-41-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08753, current rewards: 171.66767, mean: 0.10039
[32m[0906 22-41-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08759, current rewards: 177.17317, mean: 0.10067
[32m[0906 22-42-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08765, current rewards: 182.68043, mean: 0.10093
[32m[0906 22-42-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08770, current rewards: 188.19354, mean: 0.10118
[32m[0906 22-42-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08775, current rewards: 193.70400, mean: 0.10142
[32m[0906 22-42-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08774, current rewards: 199.21756, mean: 0.10164
[32m[0906 22-42-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08772, current rewards: 194.35215, mean: 0.09669
[32m[0906 22-42-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08771, current rewards: 200.46913, mean: 0.09732
[32m[0906 22-42-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08769, current rewards: 206.58385, mean: 0.09791
[32m[0906 22-42-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08771, current rewards: 212.68854, mean: 0.09847
[32m[0906 22-42-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08776, current rewards: 218.80444, mean: 0.09901
[32m[0906 22-42-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08777, current rewards: 224.90834, mean: 0.09952
[32m[0906 22-42-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08775, current rewards: 231.02144, mean: 0.10001
[32m[0906 22-42-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08775, current rewards: 237.13049, mean: 0.10048
[32m[0906 22-42-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08773, current rewards: 230.22400, mean: 0.09553
[32m[0906 22-43-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08772, current rewards: 235.81937, mean: 0.09586
[32m[0906 22-43-04 @Agent.py:117][0m Average action selection time: 0.0877
[32m[0906 22-43-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-43-04 @MBExp.py:227][0m Rewards obtained: [240.29940662971902], Lows: [16], Highs: [6], Total time: 23640.507486000002
[32m[0906 22-45-48 @MBExp.py:144][0m ####################################################################
[32m[0906 22-45-48 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 22-45-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08891, current rewards: -8.38506, mean: -0.83851
[32m[0906 22-45-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08958, current rewards: -2.88771, mean: -0.04813
[32m[0906 22-45-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08961, current rewards: 2.55275, mean: 0.02321
[32m[0906 22-46-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08965, current rewards: 7.99926, mean: 0.05000
[32m[0906 22-46-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08964, current rewards: 13.44730, mean: 0.06403
[32m[0906 22-46-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08959, current rewards: 18.89931, mean: 0.07269
[32m[0906 22-46-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08912, current rewards: 24.15017, mean: 0.07790
[32m[0906 22-46-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08878, current rewards: 29.51218, mean: 0.08198
[32m[0906 22-46-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08856, current rewards: 34.95132, mean: 0.08525
[32m[0906 22-46-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08842, current rewards: 40.37995, mean: 0.08778
[32m[0906 22-46-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08828, current rewards: 35.42025, mean: 0.06945
[32m[0906 22-46-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08816, current rewards: 40.89073, mean: 0.07302
[32m[0906 22-46-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08804, current rewards: 46.36243, mean: 0.07600
[32m[0906 22-46-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08798, current rewards: 51.84189, mean: 0.07855
[32m[0906 22-46-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08791, current rewards: 57.31994, mean: 0.08073
[32m[0906 22-46-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08785, current rewards: 62.88964, mean: 0.08275
[32m[0906 22-46-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08782, current rewards: 68.36498, mean: 0.08440
[32m[0906 22-47-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08778, current rewards: 73.83672, mean: 0.08586
[32m[0906 22-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08773, current rewards: 79.30272, mean: 0.08715
[32m[0906 22-47-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08770, current rewards: 84.77829, mean: 0.08831
[32m[0906 22-47-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08769, current rewards: 90.24322, mean: 0.08935
[32m[0906 22-47-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08765, current rewards: 95.71944, mean: 0.09030
[32m[0906 22-47-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08763, current rewards: 90.54690, mean: 0.08157
[32m[0906 22-47-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08760, current rewards: 96.45765, mean: 0.08315
[32m[0906 22-47-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08757, current rewards: 101.94309, mean: 0.08425
[32m[0906 22-47-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08756, current rewards: 107.42529, mean: 0.08526
[32m[0906 22-47-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08755, current rewards: 112.90404, mean: 0.08619
[32m[0906 22-47-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08753, current rewards: 118.39449, mean: 0.08705
[32m[0906 22-47-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08751, current rewards: 123.87661, mean: 0.08786
[32m[0906 22-47-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08749, current rewards: 129.35933, mean: 0.08860
[32m[0906 22-48-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08749, current rewards: 117.59156, mean: 0.07788
[32m[0906 22-48-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08749, current rewards: 123.30369, mean: 0.07904
[32m[0906 22-48-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08756, current rewards: 128.88090, mean: 0.08005
[32m[0906 22-48-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08762, current rewards: 134.46007, mean: 0.08100
[32m[0906 22-48-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08768, current rewards: 140.03736, mean: 0.08189
[32m[0906 22-48-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08773, current rewards: 145.61354, mean: 0.08273
[32m[0906 22-48-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08779, current rewards: 151.19075, mean: 0.08353
[32m[0906 22-48-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08784, current rewards: 156.76853, mean: 0.08428
[32m[0906 22-48-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08788, current rewards: 162.34425, mean: 0.08500
[32m[0906 22-48-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08787, current rewards: 161.85846, mean: 0.08258
[32m[0906 22-48-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08785, current rewards: 166.72694, mean: 0.08295
[32m[0906 22-48-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08783, current rewards: 171.57437, mean: 0.08329
[32m[0906 22-48-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08781, current rewards: 176.42795, mean: 0.08362
[32m[0906 22-48-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08780, current rewards: 181.27683, mean: 0.08392
[32m[0906 22-49-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08783, current rewards: 186.12738, mean: 0.08422
[32m[0906 22-49-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08785, current rewards: 190.98350, mean: 0.08451
[32m[0906 22-49-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08784, current rewards: 186.57111, mean: 0.08077
[32m[0906 22-49-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08782, current rewards: 192.39430, mean: 0.08152
[32m[0906 22-49-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08781, current rewards: 198.01206, mean: 0.08216
[32m[0906 22-49-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08781, current rewards: 203.62328, mean: 0.08277
[32m[0906 22-49-28 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0906 22-49-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-49-28 @MBExp.py:227][0m Rewards obtained: [208.11288724009668], Lows: [26], Highs: [10], Total time: 23860.730254000002
[32m[0906 22-52-15 @MBExp.py:144][0m ####################################################################
[32m[0906 22-52-15 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 22-52-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08879, current rewards: -15.00000, mean: -1.50000
[32m[0906 22-52-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08967, current rewards: -115.00000, mean: -1.91667
[32m[0906 22-52-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08960, current rewards: -215.00000, mean: -1.95455
[32m[0906 22-52-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08954, current rewards: -315.00000, mean: -1.96875
[32m[0906 22-52-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08954, current rewards: -415.00000, mean: -1.97619
[32m[0906 22-52-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08937, current rewards: -515.00000, mean: -1.98077
[32m[0906 22-52-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08890, current rewards: -615.00000, mean: -1.98387
[32m[0906 22-52-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08862, current rewards: -715.00000, mean: -1.98611
[32m[0906 22-52-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08844, current rewards: -815.00000, mean: -1.98780
[32m[0906 22-52-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08828, current rewards: -915.00000, mean: -1.98913
[32m[0906 22-53-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08812, current rewards: -1015.00000, mean: -1.99020
[32m[0906 22-53-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08799, current rewards: -1115.00000, mean: -1.99107
[32m[0906 22-53-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08791, current rewards: -1215.00000, mean: -1.99180
[32m[0906 22-53-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08781, current rewards: -1315.00000, mean: -1.99242
[32m[0906 22-53-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08775, current rewards: -1415.00000, mean: -1.99296
[32m[0906 22-53-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08770, current rewards: -1515.00000, mean: -1.99342
[32m[0906 22-53-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08766, current rewards: -1615.00000, mean: -1.99383
[32m[0906 22-53-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08761, current rewards: -1715.00000, mean: -1.99419
[32m[0906 22-53-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08756, current rewards: -1815.00000, mean: -1.99451
[32m[0906 22-53-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08752, current rewards: -1915.00000, mean: -1.99479
[32m[0906 22-53-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08749, current rewards: -2008.79546, mean: -1.98891
[32m[0906 22-53-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08746, current rewards: -2108.79546, mean: -1.98943
[32m[0906 22-53-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08745, current rewards: -2208.79546, mean: -1.98991
[32m[0906 22-53-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08742, current rewards: -2308.79546, mean: -1.99034
[32m[0906 22-54-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08739, current rewards: -2408.79546, mean: -1.99074
[32m[0906 22-54-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08737, current rewards: -2508.79546, mean: -1.99111
[32m[0906 22-54-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08736, current rewards: -2608.79546, mean: -1.99145
[32m[0906 22-54-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08737, current rewards: -2708.79546, mean: -1.99176
[32m[0906 22-54-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08735, current rewards: -2808.79546, mean: -1.99205
[32m[0906 22-54-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08734, current rewards: -2908.79546, mean: -1.99233
[32m[0906 22-54-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08734, current rewards: -3008.79546, mean: -1.99258
[32m[0906 22-54-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08733, current rewards: -3108.79546, mean: -1.99282
[32m[0906 22-54-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08738, current rewards: -3208.79546, mean: -1.99304
[32m[0906 22-54-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08744, current rewards: -3306.65949, mean: -1.99196
[32m[0906 22-54-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08751, current rewards: -3393.12497, mean: -1.98428
[32m[0906 22-54-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08756, current rewards: -3493.12497, mean: -1.98473
[32m[0906 22-54-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08762, current rewards: -3593.12497, mean: -1.98515
[32m[0906 22-54-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08768, current rewards: -3693.12497, mean: -1.98555
[32m[0906 22-55-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08773, current rewards: -3793.12497, mean: -1.98593
[32m[0906 22-55-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08770, current rewards: -3893.12497, mean: -1.98629
[32m[0906 22-55-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08769, current rewards: -3993.12497, mean: -1.98663
[32m[0906 22-55-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08767, current rewards: -4093.12497, mean: -1.98695
[32m[0906 22-55-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08766, current rewards: -4193.12497, mean: -1.98726
[32m[0906 22-55-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08765, current rewards: -4293.12497, mean: -1.98756
[32m[0906 22-55-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08767, current rewards: -4393.12497, mean: -1.98784
[32m[0906 22-55-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08768, current rewards: -4493.12497, mean: -1.98811
[32m[0906 22-55-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08766, current rewards: -4593.12497, mean: -1.98837
[32m[0906 22-55-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08765, current rewards: -4693.12497, mean: -1.98861
[32m[0906 22-55-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08764, current rewards: -4793.12497, mean: -1.98885
[32m[0906 22-55-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08763, current rewards: -4893.12497, mean: -1.98908
[32m[0906 22-55-54 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0906 22-55-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-55-54 @MBExp.py:227][0m Rewards obtained: [-4973.124971900355], Lows: [2485], Highs: [5], Total time: 24080.497679
[32m[0906 22-58-42 @MBExp.py:144][0m ####################################################################
[32m[0906 22-58-42 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 22-58-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08910, current rewards: -8.94509, mean: -0.89451
[32m[0906 22-58-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08971, current rewards: -20.70038, mean: -0.34501
[32m[0906 22-58-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08965, current rewards: -17.20863, mean: -0.15644
[32m[0906 22-58-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08959, current rewards: -11.84028, mean: -0.07400
[32m[0906 22-59-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08957, current rewards: -6.47642, mean: -0.03084
[32m[0906 22-59-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08925, current rewards: -1.11997, mean: -0.00431
[32m[0906 22-59-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08886, current rewards: 4.24694, mean: 0.01370
[32m[0906 22-59-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08859, current rewards: 9.61084, mean: 0.02670
[32m[0906 22-59-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08839, current rewards: 14.97324, mean: 0.03652
[32m[0906 22-59-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08824, current rewards: 20.33437, mean: 0.04421
[32m[0906 22-59-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08813, current rewards: 25.69748, mean: 0.05039
[32m[0906 22-59-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08802, current rewards: 31.06388, mean: 0.05547
[32m[0906 22-59-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08794, current rewards: 36.43157, mean: 0.05972
[32m[0906 22-59-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08784, current rewards: 42.12787, mean: 0.06383
[32m[0906 22-59-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08780, current rewards: 47.49779, mean: 0.06690
[32m[0906 22-59-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08772, current rewards: 52.87476, mean: 0.06957
[32m[0906 22-59-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08768, current rewards: 58.24730, mean: 0.07191
[32m[0906 22-59-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08764, current rewards: 63.62710, mean: 0.07399
[32m[0906 23-00-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08760, current rewards: 69.00242, mean: 0.07583
[32m[0906 23-00-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08758, current rewards: 60.24379, mean: 0.06275
[32m[0906 23-00-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08755, current rewards: 65.78261, mean: 0.06513
[32m[0906 23-00-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08753, current rewards: 71.29699, mean: 0.06726
[32m[0906 23-00-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08750, current rewards: 76.81229, mean: 0.06920
[32m[0906 23-00-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08748, current rewards: 82.32835, mean: 0.07097
[32m[0906 23-00-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08746, current rewards: 87.84327, mean: 0.07260
[32m[0906 23-00-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08744, current rewards: 93.35766, mean: 0.07409
[32m[0906 23-00-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08744, current rewards: 98.87426, mean: 0.07548
[32m[0906 23-00-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08741, current rewards: 86.36761, mean: 0.06351
[32m[0906 23-00-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08740, current rewards: 75.47951, mean: 0.05353
[32m[0906 23-00-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08738, current rewards: 63.73109, mean: 0.04365
[32m[0906 23-00-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08738, current rewards: 30.79240, mean: 0.02039
[32m[0906 23-00-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08737, current rewards: 0.56473, mean: 0.00036
[32m[0906 23-01-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08736, current rewards: -25.84450, mean: -0.01605
[32m[0906 23-01-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08735, current rewards: -50.69649, mean: -0.03054
[32m[0906 23-01-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08733, current rewards: -74.37135, mean: -0.04349
[32m[0906 23-01-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08732, current rewards: -100.33458, mean: -0.05701
[32m[0906 23-01-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08731, current rewards: -126.40346, mean: -0.06984
[32m[0906 23-01-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08732, current rewards: -150.32131, mean: -0.08082
[32m[0906 23-01-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08739, current rewards: -180.15008, mean: -0.09432
[32m[0906 23-01-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08739, current rewards: -174.03567, mean: -0.08879
[32m[0906 23-01-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08738, current rewards: -168.59417, mean: -0.08388
[32m[0906 23-01-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08737, current rewards: -163.15197, mean: -0.07920
[32m[0906 23-01-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08736, current rewards: -157.71529, mean: -0.07475
[32m[0906 23-01-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08736, current rewards: -152.27654, mean: -0.07050
[32m[0906 23-01-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08740, current rewards: -146.83033, mean: -0.06644
[32m[0906 23-02-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08740, current rewards: -141.38812, mean: -0.06256
[32m[0906 23-02-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08738, current rewards: -136.45325, mean: -0.05907
[32m[0906 23-02-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08738, current rewards: -131.00267, mean: -0.05551
[32m[0906 23-02-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08737, current rewards: -125.55797, mean: -0.05210
[32m[0906 23-02-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08735, current rewards: -120.11165, mean: -0.04883
[32m[0906 23-02-21 @Agent.py:117][0m Average action selection time: 0.0873
[32m[0906 23-02-21 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-02-21 @MBExp.py:227][0m Rewards obtained: [-115.7537418801661], Lows: [198], Highs: [14], Total time: 24299.588888
[32m[0906 23-05-11 @MBExp.py:144][0m ####################################################################
[32m[0906 23-05-11 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 23-05-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09453, current rewards: -7.70320, mean: -0.77032
[32m[0906 23-05-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09049, current rewards: -1.00034, mean: -0.01667
[32m[0906 23-05-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09020, current rewards: 5.87325, mean: 0.05339
[32m[0906 23-05-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09010, current rewards: 12.75115, mean: 0.07969
[32m[0906 23-05-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08964, current rewards: 19.82641, mean: 0.09441
[32m[0906 23-05-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08912, current rewards: 26.79087, mean: 0.10304
[32m[0906 23-05-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08873, current rewards: 33.58875, mean: 0.10835
[32m[0906 23-05-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08848, current rewards: 40.38934, mean: 0.11219
[32m[0906 23-05-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08830, current rewards: 47.17919, mean: 0.11507
[32m[0906 23-05-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08820, current rewards: 53.98069, mean: 0.11735
[32m[0906 23-05-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08807, current rewards: 43.72469, mean: 0.08573
[32m[0906 23-06-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08797, current rewards: 49.55122, mean: 0.08848
[32m[0906 23-06-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08790, current rewards: 55.00461, mean: 0.09017
[32m[0906 23-06-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08782, current rewards: 61.11382, mean: 0.09260
[32m[0906 23-06-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08778, current rewards: 66.60801, mean: 0.09381
[32m[0906 23-06-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08775, current rewards: 72.10323, mean: 0.09487
[32m[0906 23-06-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08771, current rewards: 77.59793, mean: 0.09580
[32m[0906 23-06-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08767, current rewards: 83.09351, mean: 0.09662
[32m[0906 23-06-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08764, current rewards: 88.59071, mean: 0.09735
[32m[0906 23-06-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08761, current rewards: 94.08603, mean: 0.09801
[32m[0906 23-06-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08758, current rewards: 99.58209, mean: 0.09860
[32m[0906 23-06-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08755, current rewards: 105.07632, mean: 0.09913
[32m[0906 23-06-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08754, current rewards: 101.66141, mean: 0.09159
[32m[0906 23-06-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08753, current rewards: 107.21277, mean: 0.09242
[32m[0906 23-06-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08751, current rewards: 112.75514, mean: 0.09319
[32m[0906 23-07-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08750, current rewards: 118.29625, mean: 0.09389
[32m[0906 23-07-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08749, current rewards: 123.83454, mean: 0.09453
[32m[0906 23-07-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08747, current rewards: 129.33669, mean: 0.09510
[32m[0906 23-07-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08745, current rewards: 135.41708, mean: 0.09604
[32m[0906 23-07-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08742, current rewards: 141.27231, mean: 0.09676
[32m[0906 23-07-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08740, current rewards: 147.35011, mean: 0.09758
[32m[0906 23-07-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08738, current rewards: 153.43223, mean: 0.09835
[32m[0906 23-07-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08737, current rewards: 159.51333, mean: 0.09908
[32m[0906 23-07-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08736, current rewards: 165.59414, mean: 0.09976
[32m[0906 23-07-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08735, current rewards: 171.66897, mean: 0.10039
[32m[0906 23-07-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08735, current rewards: 164.90751, mean: 0.09370
[32m[0906 23-07-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08734, current rewards: 170.33887, mean: 0.09411
[32m[0906 23-07-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08735, current rewards: 176.96880, mean: 0.09514
[32m[0906 23-07-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08741, current rewards: 182.56968, mean: 0.09559
[32m[0906 23-08-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08741, current rewards: 188.07024, mean: 0.09595
[32m[0906 23-08-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08740, current rewards: 193.57635, mean: 0.09631
[32m[0906 23-08-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08739, current rewards: 199.08109, mean: 0.09664
[32m[0906 23-08-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08738, current rewards: 204.59040, mean: 0.09696
[32m[0906 23-08-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08737, current rewards: 202.58037, mean: 0.09379
[32m[0906 23-08-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08743, current rewards: 208.16510, mean: 0.09419
[32m[0906 23-08-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08742, current rewards: 213.75171, mean: 0.09458
[32m[0906 23-08-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08741, current rewards: 219.20121, mean: 0.09489
[32m[0906 23-08-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08740, current rewards: 224.81703, mean: 0.09526
[32m[0906 23-08-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08740, current rewards: 230.42688, mean: 0.09561
[32m[0906 23-08-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08738, current rewards: 236.04774, mean: 0.09595
[32m[0906 23-08-50 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0906 23-08-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-08-51 @MBExp.py:227][0m Rewards obtained: [240.5371028373476], Lows: [15], Highs: [21], Total time: 24518.785810999998
[32m[0906 23-11-42 @MBExp.py:144][0m ####################################################################
[32m[0906 23-11-42 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 23-11-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08900, current rewards: -14.00000, mean: -1.40000
[32m[0906 23-11-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08980, current rewards: -96.13678, mean: -1.60228
[32m[0906 23-11-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08974, current rewards: -178.48984, mean: -1.62263
[32m[0906 23-11-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08952, current rewards: -260.17917, mean: -1.62612
[32m[0906 23-12-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08896, current rewards: -351.58101, mean: -1.67420
[32m[0906 23-12-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08851, current rewards: -451.58101, mean: -1.73685
[32m[0906 23-12-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08828, current rewards: -551.58101, mean: -1.77929
[32m[0906 23-12-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08808, current rewards: -651.58101, mean: -1.80995
[32m[0906 23-12-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08797, current rewards: -751.58101, mean: -1.83312
[32m[0906 23-12-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08784, current rewards: -851.58101, mean: -1.85126
[32m[0906 23-12-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08777, current rewards: -951.58101, mean: -1.86585
[32m[0906 23-12-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08768, current rewards: -1051.58101, mean: -1.87782
[32m[0906 23-12-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08772, current rewards: -1146.29749, mean: -1.87918
[32m[0906 23-12-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08767, current rewards: -1246.29749, mean: -1.88833
[32m[0906 23-12-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08762, current rewards: -1346.29749, mean: -1.89619
[32m[0906 23-12-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08757, current rewards: -1446.29749, mean: -1.90302
[32m[0906 23-12-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08755, current rewards: -1546.29749, mean: -1.90901
[32m[0906 23-12-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08752, current rewards: -1641.29749, mean: -1.90849
[32m[0906 23-13-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08748, current rewards: -1741.29749, mean: -1.91351
[32m[0906 23-13-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08744, current rewards: -1841.29749, mean: -1.91802
[32m[0906 23-13-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08743, current rewards: -1941.29749, mean: -1.92208
[32m[0906 23-13-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08741, current rewards: -2041.29749, mean: -1.92575
[32m[0906 23-13-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08739, current rewards: -2141.29749, mean: -1.92910
[32m[0906 23-13-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08737, current rewards: -2241.29749, mean: -1.93215
[32m[0906 23-13-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08738, current rewards: -2315.13582, mean: -1.91334
[32m[0906 23-13-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08738, current rewards: -2370.27918, mean: -1.88117
[32m[0906 23-13-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08743, current rewards: -2419.89243, mean: -1.84725
[32m[0906 23-13-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08741, current rewards: -2479.75540, mean: -1.82335
[32m[0906 23-13-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08740, current rewards: -2544.62827, mean: -1.80470
[32m[0906 23-13-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08737, current rewards: -2616.01134, mean: -1.79179
[32m[0906 23-13-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08735, current rewards: -2695.98403, mean: -1.78542
[32m[0906 23-13-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08734, current rewards: -2778.18557, mean: -1.78089
[32m[0906 23-14-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08733, current rewards: -2860.38608, mean: -1.77664
[32m[0906 23-14-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08735, current rewards: -2938.33138, mean: -1.77008
[32m[0906 23-14-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08733, current rewards: -3031.78199, mean: -1.77297
[32m[0906 23-14-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08733, current rewards: -3131.78199, mean: -1.77942
[32m[0906 23-14-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08731, current rewards: -3231.78199, mean: -1.78551
[32m[0906 23-14-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08736, current rewards: -3331.78199, mean: -1.79128
[32m[0906 23-14-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08741, current rewards: -3420.99287, mean: -1.79110
[32m[0906 23-14-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08741, current rewards: -3498.00426, mean: -1.78470
[32m[0906 23-14-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08743, current rewards: -3575.16707, mean: -1.77869
[32m[0906 23-14-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08745, current rewards: -3647.56811, mean: -1.77066
[32m[0906 23-14-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08744, current rewards: -3721.45189, mean: -1.76372
[32m[0906 23-14-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08747, current rewards: -3821.45189, mean: -1.76919
[32m[0906 23-14-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08752, current rewards: -3921.45189, mean: -1.77441
[32m[0906 23-15-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08759, current rewards: -4003.63159, mean: -1.77152
[32m[0906 23-15-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08764, current rewards: -4103.63159, mean: -1.77646
[32m[0906 23-15-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08768, current rewards: -4203.63159, mean: -1.78120
[32m[0906 23-15-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08772, current rewards: -4303.63159, mean: -1.78574
[32m[0906 23-15-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08771, current rewards: -4403.63159, mean: -1.79009
[32m[0906 23-15-22 @Agent.py:117][0m Average action selection time: 0.0877
[32m[0906 23-15-22 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-15-22 @MBExp.py:227][0m Rewards obtained: [-4483.631588621944], Lows: [2270], Highs: [15], Total time: 24738.762715999997
[32m[0906 23-18-15 @MBExp.py:144][0m ####################################################################
[32m[0906 23-18-15 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 23-18-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08913, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-18-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08970, current rewards: -60.00000, mean: -1.00000
[32m[0906 23-18-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08919, current rewards: -110.00000, mean: -1.00000
[32m[0906 23-18-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08848, current rewards: -160.00000, mean: -1.00000
[32m[0906 23-18-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08822, current rewards: -187.34811, mean: -0.89213
[32m[0906 23-18-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08802, current rewards: -238.08012, mean: -0.91569
[32m[0906 23-18-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08790, current rewards: -288.05187, mean: -0.92920
[32m[0906 23-18-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08782, current rewards: -293.48807, mean: -0.81524
[32m[0906 23-18-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08776, current rewards: -288.00727, mean: -0.70246
[32m[0906 23-18-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08770, current rewards: -282.52180, mean: -0.61418
[32m[0906 23-19-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08762, current rewards: -277.03606, mean: -0.54321
[32m[0906 23-19-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08756, current rewards: -271.16746, mean: -0.48423
[32m[0906 23-19-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08752, current rewards: -265.45777, mean: -0.43518
[32m[0906 23-19-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08747, current rewards: -259.95620, mean: -0.39387
[32m[0906 23-19-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08745, current rewards: -276.53798, mean: -0.38949
[32m[0906 23-19-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08739, current rewards: -297.34623, mean: -0.39125
[32m[0906 23-19-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08734, current rewards: -291.74837, mean: -0.36018
[32m[0906 23-19-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08733, current rewards: -286.14994, mean: -0.33273
[32m[0906 23-19-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08730, current rewards: -280.55124, mean: -0.30830
[32m[0906 23-19-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08729, current rewards: -274.95320, mean: -0.28641
[32m[0906 23-19-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08727, current rewards: -269.35549, mean: -0.26669
[32m[0906 23-19-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08723, current rewards: -263.75673, mean: -0.24883
[32m[0906 23-19-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08722, current rewards: -258.15824, mean: -0.23257
[32m[0906 23-19-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08720, current rewards: -273.31071, mean: -0.23561
[32m[0906 23-20-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08718, current rewards: -266.93727, mean: -0.22061
[32m[0906 23-20-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08715, current rewards: -261.47497, mean: -0.20752
[32m[0906 23-20-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08714, current rewards: -256.00821, mean: -0.19543
[32m[0906 23-20-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08713, current rewards: -250.54114, mean: -0.18422
[32m[0906 23-20-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08713, current rewards: -245.51501, mean: -0.17412
[32m[0906 23-20-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08713, current rewards: -240.13760, mean: -0.16448
[32m[0906 23-20-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08711, current rewards: -234.75954, mean: -0.15547
[32m[0906 23-20-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08711, current rewards: -229.38953, mean: -0.14704
[32m[0906 23-20-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08711, current rewards: -234.55316, mean: -0.14569
[32m[0906 23-20-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08709, current rewards: -296.45821, mean: -0.17859
[32m[0906 23-20-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08709, current rewards: -363.17567, mean: -0.21238
[32m[0906 23-20-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08708, current rewards: -429.96956, mean: -0.24430
[32m[0906 23-20-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08713, current rewards: -492.35979, mean: -0.27202
[32m[0906 23-20-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08727, current rewards: -558.38127, mean: -0.30020
[32m[0906 23-21-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08745, current rewards: -624.52498, mean: -0.32698
[32m[0906 23-21-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08763, current rewards: -686.91838, mean: -0.35047
[32m[0906 23-21-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08773, current rewards: -752.74956, mean: -0.37450
[32m[0906 23-21-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08793, current rewards: -819.32020, mean: -0.39773
[32m[0906 23-21-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08809, current rewards: -881.67210, mean: -0.41785
[32m[0906 23-21-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08820, current rewards: -915.63112, mean: -0.42390
[32m[0906 23-21-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08823, current rewards: -910.01247, mean: -0.41177
[32m[0906 23-21-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08825, current rewards: -904.51157, mean: -0.40023
[32m[0906 23-21-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08829, current rewards: -899.00726, mean: -0.38918
[32m[0906 23-21-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08833, current rewards: -930.36419, mean: -0.39422
[32m[0906 23-21-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08834, current rewards: -934.95278, mean: -0.38795
[32m[0906 23-21-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08830, current rewards: -929.35774, mean: -0.37779
[32m[0906 23-21-57 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0906 23-21-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-21-57 @MBExp.py:227][0m Rewards obtained: [-924.8817397808356], Lows: [484], Highs: [176], Total time: 24960.199952
[32m[0906 23-24-52 @MBExp.py:144][0m ####################################################################
[32m[0906 23-24-52 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 23-24-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08917, current rewards: -8.62010, mean: -0.86201
[32m[0906 23-24-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08809, current rewards: -106.43430, mean: -1.77391
[32m[0906 23-25-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08756, current rewards: -206.43430, mean: -1.87668
[32m[0906 23-25-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08732, current rewards: -306.43430, mean: -1.91521
[32m[0906 23-25-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08722, current rewards: -406.43430, mean: -1.93540
[32m[0906 23-25-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08719, current rewards: -506.43430, mean: -1.94782
[32m[0906 23-25-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08711, current rewards: -606.43430, mean: -1.95624
[32m[0906 23-25-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08714, current rewards: -706.43430, mean: -1.96232
[32m[0906 23-25-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08710, current rewards: -806.43430, mean: -1.96691
[32m[0906 23-25-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08705, current rewards: -906.43430, mean: -1.97051
[32m[0906 23-25-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08703, current rewards: -1006.43430, mean: -1.97340
[32m[0906 23-25-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08702, current rewards: -1106.43430, mean: -1.97578
[32m[0906 23-25-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08712, current rewards: -1148.51346, mean: -1.88281
[32m[0906 23-25-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08732, current rewards: -1162.15403, mean: -1.76084
[32m[0906 23-25-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08734, current rewards: -1210.27384, mean: -1.70461
[32m[0906 23-25-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08737, current rewards: -1241.39198, mean: -1.63341
[32m[0906 23-26-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08734, current rewards: -1236.47419, mean: -1.52651
[32m[0906 23-26-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08730, current rewards: -1231.54534, mean: -1.43203
[32m[0906 23-26-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08730, current rewards: -1226.61550, mean: -1.34793
[32m[0906 23-26-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08729, current rewards: -1221.52038, mean: -1.27242
[32m[0906 23-26-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08732, current rewards: -1258.17636, mean: -1.24572
[32m[0906 23-26-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08729, current rewards: -1338.60692, mean: -1.26284
[32m[0906 23-26-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08727, current rewards: -1420.78056, mean: -1.27998
[32m[0906 23-26-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08726, current rewards: -1503.05221, mean: -1.29573
[32m[0906 23-26-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08726, current rewards: -1582.95280, mean: -1.30823
[32m[0906 23-26-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08723, current rewards: -1665.07739, mean: -1.32149
[32m[0906 23-26-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08722, current rewards: -1747.28328, mean: -1.33380
[32m[0906 23-26-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08721, current rewards: -1842.78557, mean: -1.35499
[32m[0906 23-26-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08720, current rewards: -1942.78557, mean: -1.37786
[32m[0906 23-26-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08719, current rewards: -2034.52797, mean: -1.39351
[32m[0906 23-27-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08718, current rewards: -2134.52797, mean: -1.41359
[32m[0906 23-27-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08717, current rewards: -2234.52797, mean: -1.43239
[32m[0906 23-27-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08717, current rewards: -2334.52797, mean: -1.45002
[32m[0906 23-27-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08716, current rewards: -2434.52797, mean: -1.46658
[32m[0906 23-27-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08715, current rewards: -2534.52797, mean: -1.48218
[32m[0906 23-27-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08715, current rewards: -2634.52797, mean: -1.49689
[32m[0906 23-27-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08720, current rewards: -2715.22800, mean: -1.50013
[32m[0906 23-27-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08726, current rewards: -2766.09757, mean: -1.48715
[32m[0906 23-27-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08726, current rewards: -2827.10502, mean: -1.48016
[32m[0906 23-27-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08739, current rewards: -2917.17232, mean: -1.48835
[32m[0906 23-27-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08739, current rewards: -3017.17232, mean: -1.50108
[32m[0906 23-27-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08738, current rewards: -3117.17232, mean: -1.51319
[32m[0906 23-27-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08743, current rewards: -3217.17232, mean: -1.52473
[32m[0906 23-28-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08749, current rewards: -3317.17232, mean: -1.53573
[32m[0906 23-28-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08755, current rewards: -3417.17232, mean: -1.54623
[32m[0906 23-28-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08760, current rewards: -3517.17232, mean: -1.55627
[32m[0906 23-28-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08783, current rewards: -3617.17232, mean: -1.56588
[32m[0906 23-28-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08801, current rewards: -3717.17232, mean: -1.57507
[32m[0906 23-28-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08824, current rewards: -3817.17232, mean: -1.58389
[32m[0906 23-28-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08846, current rewards: -3917.17232, mean: -1.59235
[32m[0906 23-28-34 @Agent.py:117][0m Average action selection time: 0.0885
[32m[0906 23-28-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-28-34 @MBExp.py:227][0m Rewards obtained: [-3980.1876930334142], Lows: [2025], Highs: [11], Total time: 25182.260254999997
[32m[0906 23-31-31 @MBExp.py:144][0m ####################################################################
[32m[0906 23-31-31 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 23-31-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08946, current rewards: -8.62707, mean: -0.86271
[32m[0906 23-31-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08751, current rewards: -0.31931, mean: -0.00532
[32m[0906 23-31-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08736, current rewards: 6.28892, mean: 0.05717
[32m[0906 23-31-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08715, current rewards: 10.99634, mean: 0.06873
[32m[0906 23-31-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08714, current rewards: 14.62967, mean: 0.06967
[32m[0906 23-31-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08710, current rewards: 18.26300, mean: 0.07024
[32m[0906 23-31-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08708, current rewards: 21.89633, mean: 0.07063
[32m[0906 23-32-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08705, current rewards: 25.52966, mean: 0.07092
[32m[0906 23-32-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08704, current rewards: 29.16299, mean: 0.07113
[32m[0906 23-32-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08703, current rewards: 18.85165, mean: 0.04098
[32m[0906 23-32-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08703, current rewards: -31.14835, mean: -0.06108
[32m[0906 23-32-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08702, current rewards: -81.14835, mean: -0.14491
[32m[0906 23-32-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08699, current rewards: -131.14835, mean: -0.21500
[32m[0906 23-32-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08697, current rewards: -181.14835, mean: -0.27447
[32m[0906 23-32-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08696, current rewards: -231.14835, mean: -0.32556
[32m[0906 23-32-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08696, current rewards: -281.14835, mean: -0.36993
[32m[0906 23-32-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08696, current rewards: -331.14835, mean: -0.40883
[32m[0906 23-32-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08694, current rewards: -381.14835, mean: -0.44320
[32m[0906 23-32-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08693, current rewards: -431.14835, mean: -0.47379
[32m[0906 23-32-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08691, current rewards: -481.14835, mean: -0.50120
[32m[0906 23-32-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08692, current rewards: -531.14835, mean: -0.52589
[32m[0906 23-33-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08692, current rewards: -581.14835, mean: -0.54825
[32m[0906 23-33-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08692, current rewards: -631.14835, mean: -0.56860
[32m[0906 23-33-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08692, current rewards: -681.14835, mean: -0.58720
[32m[0906 23-33-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08691, current rewards: -731.14835, mean: -0.60425
[32m[0906 23-33-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08690, current rewards: -781.14835, mean: -0.61996
[32m[0906 23-33-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08691, current rewards: -831.14835, mean: -0.63446
[32m[0906 23-33-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08691, current rewards: -881.14835, mean: -0.64790
[32m[0906 23-33-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08691, current rewards: -931.14835, mean: -0.66039
[32m[0906 23-33-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08691, current rewards: -981.14835, mean: -0.67202
[32m[0906 23-33-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08690, current rewards: -1031.14835, mean: -0.68288
[32m[0906 23-33-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08690, current rewards: -1081.14835, mean: -0.69304
[32m[0906 23-33-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08691, current rewards: -1131.14835, mean: -0.70258
[32m[0906 23-33-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08690, current rewards: -1181.14835, mean: -0.71154
[32m[0906 23-34-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08689, current rewards: -1231.14835, mean: -0.71997
[32m[0906 23-34-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08688, current rewards: -1281.14835, mean: -0.72793
[32m[0906 23-34-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08696, current rewards: -1331.14835, mean: -0.73544
[32m[0906 23-34-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08699, current rewards: -1381.14835, mean: -0.74255
[32m[0906 23-34-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08698, current rewards: -1431.14835, mean: -0.74929
[32m[0906 23-34-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08699, current rewards: -1481.14835, mean: -0.75569
[32m[0906 23-34-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08698, current rewards: -1531.14835, mean: -0.76177
[32m[0906 23-34-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08700, current rewards: -1581.14835, mean: -0.76755
[32m[0906 23-34-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08707, current rewards: -1631.14835, mean: -0.77306
[32m[0906 23-34-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08713, current rewards: -1681.14835, mean: -0.77831
[32m[0906 23-34-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08719, current rewards: -1731.14835, mean: -0.78333
[32m[0906 23-34-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08725, current rewards: -1781.14835, mean: -0.78812
[32m[0906 23-34-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08731, current rewards: -1831.14835, mean: -0.79270
[32m[0906 23-34-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08736, current rewards: -1881.14835, mean: -0.79710
[32m[0906 23-35-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08741, current rewards: -1931.14835, mean: -0.80131
[32m[0906 23-35-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08745, current rewards: -1981.14835, mean: -0.80534
[32m[0906 23-35-10 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0906 23-35-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-35-10 @MBExp.py:227][0m Rewards obtained: [-2021.1483487351788], Lows: [2], Highs: [2058], Total time: 25401.680761999996
[32m[0906 23-38-08 @MBExp.py:144][0m ####################################################################
[32m[0906 23-38-08 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 23-38-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08911, current rewards: -12.87308, mean: -1.28731
[32m[0906 23-38-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09081, current rewards: -10.64795, mean: -0.17747
[32m[0906 23-38-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08905, current rewards: -5.87664, mean: -0.05342
[32m[0906 23-38-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08841, current rewards: -0.85862, mean: -0.00537
[32m[0906 23-38-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08796, current rewards: 4.15836, mean: 0.01980
[32m[0906 23-38-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08775, current rewards: 9.17909, mean: 0.03530
[32m[0906 23-38-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08761, current rewards: 14.19964, mean: 0.04581
[32m[0906 23-38-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08752, current rewards: 19.21596, mean: 0.05338
[32m[0906 23-38-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08744, current rewards: 24.23469, mean: 0.05911
[32m[0906 23-38-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08740, current rewards: 29.25428, mean: 0.06360
[32m[0906 23-38-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08734, current rewards: 34.49134, mean: 0.06763
[32m[0906 23-38-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08731, current rewards: 39.62728, mean: 0.07076
[32m[0906 23-39-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08727, current rewards: 27.67454, mean: 0.04537
[32m[0906 23-39-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08726, current rewards: 33.43693, mean: 0.05066
[32m[0906 23-39-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08722, current rewards: 39.20206, mean: 0.05521
[32m[0906 23-39-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08721, current rewards: 44.96224, mean: 0.05916
[32m[0906 23-39-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08727, current rewards: 37.62394, mean: 0.04645
[32m[0906 23-39-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08727, current rewards: 42.92005, mean: 0.04991
[32m[0906 23-39-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08725, current rewards: 48.16190, mean: 0.05293
[32m[0906 23-39-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08724, current rewards: 53.11389, mean: 0.05533
[32m[0906 23-39-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08721, current rewards: 58.40192, mean: 0.05782
[32m[0906 23-39-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08721, current rewards: 63.69087, mean: 0.06009
[32m[0906 23-39-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08720, current rewards: 68.97757, mean: 0.06214
[32m[0906 23-39-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08721, current rewards: 74.26880, mean: 0.06402
[32m[0906 23-39-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08719, current rewards: 79.55502, mean: 0.06575
[32m[0906 23-39-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08718, current rewards: 84.84368, mean: 0.06734
[32m[0906 23-40-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08717, current rewards: 90.13061, mean: 0.06880
[32m[0906 23-40-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08717, current rewards: 82.46733, mean: 0.06064
[32m[0906 23-40-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08732, current rewards: 49.47667, mean: 0.03509
[32m[0906 23-40-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08741, current rewards: 11.25078, mean: 0.00771
[32m[0906 23-40-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08741, current rewards: 18.31520, mean: 0.01213
[32m[0906 23-40-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08738, current rewards: 25.50019, mean: 0.01635
[32m[0906 23-40-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08736, current rewards: 32.09892, mean: 0.01994
[32m[0906 23-40-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08735, current rewards: 39.28556, mean: 0.02367
[32m[0906 23-40-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08734, current rewards: 46.07025, mean: 0.02694
[32m[0906 23-40-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08732, current rewards: 52.96093, mean: 0.03009
[32m[0906 23-40-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08731, current rewards: 60.33338, mean: 0.03333
[32m[0906 23-40-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08731, current rewards: 68.01410, mean: 0.03657
[32m[0906 23-40-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08745, current rewards: 23.65071, mean: 0.01238
[32m[0906 23-41-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08755, current rewards: -24.05017, mean: -0.01227
[32m[0906 23-41-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08767, current rewards: -61.72834, mean: -0.03071
[32m[0906 23-41-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08783, current rewards: -98.92909, mean: -0.04802
[32m[0906 23-41-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08810, current rewards: -141.51176, mean: -0.06707
[32m[0906 23-41-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08815, current rewards: -166.11813, mean: -0.07691
[32m[0906 23-41-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08822, current rewards: -164.69125, mean: -0.07452
[32m[0906 23-41-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08824, current rewards: -157.23241, mean: -0.06957
[32m[0906 23-41-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08827, current rewards: -149.69304, mean: -0.06480
[32m[0906 23-41-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08829, current rewards: -142.37505, mean: -0.06033
[32m[0906 23-41-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08832, current rewards: -134.74543, mean: -0.05591
[32m[0906 23-41-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08834, current rewards: -127.42941, mean: -0.05180
[32m[0906 23-41-50 @Agent.py:117][0m Average action selection time: 0.0884
[32m[0906 23-41-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-41-50 @MBExp.py:227][0m Rewards obtained: [-121.41728734591364], Lows: [169], Highs: [64], Total time: 25623.326605999995
[32m[0906 23-44-51 @MBExp.py:144][0m ####################################################################
[32m[0906 23-44-51 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 23-44-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08406, current rewards: -14.00000, mean: -1.40000
[32m[0906 23-44-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08509, current rewards: -30.05209, mean: -0.50087
[32m[0906 23-45-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08585, current rewards: -23.89846, mean: -0.21726
[32m[0906 23-45-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08620, current rewards: -17.19021, mean: -0.10744
[32m[0906 23-45-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08636, current rewards: -10.49016, mean: -0.04995
[32m[0906 23-45-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08645, current rewards: -3.77392, mean: -0.01452
[32m[0906 23-45-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08653, current rewards: 2.93284, mean: 0.00946
[32m[0906 23-45-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08657, current rewards: 9.64153, mean: 0.02678
[32m[0906 23-45-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08658, current rewards: 5.22854, mean: 0.01275
[32m[0906 23-45-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08660, current rewards: 10.78831, mean: 0.02345
[32m[0906 23-45-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08660, current rewards: 16.74585, mean: 0.03283
[32m[0906 23-45-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08658, current rewards: 22.29852, mean: 0.03982
[32m[0906 23-45-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08659, current rewards: 27.85931, mean: 0.04567
[32m[0906 23-45-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08660, current rewards: 12.30371, mean: 0.01864
[32m[0906 23-45-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08662, current rewards: -68.57365, mean: -0.09658
[32m[0906 23-45-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08662, current rewards: -151.57636, mean: -0.19944
[32m[0906 23-46-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08661, current rewards: -234.58128, mean: -0.28961
[32m[0906 23-46-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08664, current rewards: -315.46557, mean: -0.36682
[32m[0906 23-46-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08666, current rewards: -393.36925, mean: -0.43227
[32m[0906 23-46-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08667, current rewards: -401.07582, mean: -0.41779
[32m[0906 23-46-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08668, current rewards: -411.72503, mean: -0.40765
[32m[0906 23-46-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08669, current rewards: -420.34456, mean: -0.39655
[32m[0906 23-46-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08669, current rewards: -455.00031, mean: -0.40991
[32m[0906 23-46-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08669, current rewards: -555.00031, mean: -0.47845
[32m[0906 23-46-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08670, current rewards: -655.00031, mean: -0.54132
[32m[0906 23-46-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08670, current rewards: -755.00031, mean: -0.59921
[32m[0906 23-46-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08671, current rewards: -855.00031, mean: -0.65267
[32m[0906 23-46-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08673, current rewards: -849.66645, mean: -0.62475
[32m[0906 23-46-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08673, current rewards: -844.07379, mean: -0.59863
[32m[0906 23-46-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08673, current rewards: -838.48237, mean: -0.57430
[32m[0906 23-47-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08673, current rewards: -832.88834, mean: -0.55158
[32m[0906 23-47-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08673, current rewards: -827.30005, mean: -0.53032
[32m[0906 23-47-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08676, current rewards: -821.70900, mean: -0.51038
[32m[0906 23-47-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08676, current rewards: -816.11079, mean: -0.49163
[32m[0906 23-47-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08677, current rewards: -810.51542, mean: -0.47399
[32m[0906 23-47-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08678, current rewards: -804.46846, mean: -0.45708
[32m[0906 23-47-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08679, current rewards: -798.85667, mean: -0.44136
[32m[0906 23-47-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08680, current rewards: -797.94022, mean: -0.42900
[32m[0906 23-47-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08681, current rewards: -792.41906, mean: -0.41488
[32m[0906 23-47-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08681, current rewards: -786.89838, mean: -0.40148
[32m[0906 23-47-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08681, current rewards: -781.37988, mean: -0.38875
[32m[0906 23-47-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08684, current rewards: -775.86034, mean: -0.37663
[32m[0906 23-47-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08691, current rewards: -802.23050, mean: -0.38020
[32m[0906 23-47-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08697, current rewards: -834.66682, mean: -0.38642
[32m[0906 23-48-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08705, current rewards: -849.34434, mean: -0.38432
[32m[0906 23-48-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08710, current rewards: -857.98339, mean: -0.37964
[32m[0906 23-48-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08716, current rewards: -868.86386, mean: -0.37613
[32m[0906 23-48-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08721, current rewards: -877.50951, mean: -0.37183
[32m[0906 23-48-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08726, current rewards: -886.12999, mean: -0.36769
[32m[0906 23-48-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08731, current rewards: -897.05014, mean: -0.36465
[32m[0906 23-48-29 @Agent.py:117][0m Average action selection time: 0.0873
[32m[0906 23-48-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-48-30 @MBExp.py:227][0m Rewards obtained: [-903.0187496219373], Lows: [576], Highs: [11], Total time: 25842.411573999994
[32m[0906 23-51-32 @MBExp.py:144][0m ####################################################################
[32m[0906 23-51-32 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 23-51-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08894, current rewards: -1.30734, mean: -0.13073
[32m[0906 23-51-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08725, current rewards: -5.93017, mean: -0.09884
[32m[0906 23-51-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08710, current rewards: 0.48473, mean: 0.00441
[32m[0906 23-51-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08700, current rewards: 7.07851, mean: 0.04424
[32m[0906 23-51-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08708, current rewards: 13.67047, mean: 0.06510
[32m[0906 23-51-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08703, current rewards: 20.26107, mean: 0.07793
[32m[0906 23-51-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08699, current rewards: 26.85810, mean: 0.08664
[32m[0906 23-52-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08701, current rewards: 33.45278, mean: 0.09292
[32m[0906 23-52-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08697, current rewards: 40.04784, mean: 0.09768
[32m[0906 23-52-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08697, current rewards: 46.63606, mean: 0.10138
[32m[0906 23-52-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08697, current rewards: 55.45735, mean: 0.10874
[32m[0906 23-52-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08695, current rewards: 62.08928, mean: 0.11087
[32m[0906 23-52-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08695, current rewards: 68.54811, mean: 0.11237
[32m[0906 23-52-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08695, current rewards: 46.77752, mean: 0.07088
[32m[0906 23-52-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08694, current rewards: -3.22248, mean: -0.00454
[32m[0906 23-52-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08693, current rewards: -53.22248, mean: -0.07003
[32m[0906 23-52-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08692, current rewards: -103.22248, mean: -0.12744
[32m[0906 23-52-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08691, current rewards: -153.22248, mean: -0.17817
[32m[0906 23-52-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08691, current rewards: -203.22248, mean: -0.22332
[32m[0906 23-52-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08693, current rewards: -253.22248, mean: -0.26377
[32m[0906 23-53-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08692, current rewards: -303.22248, mean: -0.30022
[32m[0906 23-53-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08692, current rewards: -298.71384, mean: -0.28181
[32m[0906 23-53-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08692, current rewards: -291.97253, mean: -0.26304
[32m[0906 23-53-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08692, current rewards: -285.30814, mean: -0.24596
[32m[0906 23-53-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08692, current rewards: -278.58335, mean: -0.23023
[32m[0906 23-53-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08691, current rewards: -280.42431, mean: -0.22256
[32m[0906 23-53-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08709, current rewards: -308.11586, mean: -0.23520
[32m[0906 23-53-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08713, current rewards: -330.11388, mean: -0.24273
[32m[0906 23-53-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08716, current rewards: -367.56282, mean: -0.26068
[32m[0906 23-53-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08725, current rewards: -399.17965, mean: -0.27341
[32m[0906 23-53-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08745, current rewards: -451.50801, mean: -0.29901
[32m[0906 23-53-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08766, current rewards: -471.81168, mean: -0.30244
[32m[0906 23-53-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08763, current rewards: -542.90608, mean: -0.33721
[32m[0906 23-53-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08773, current rewards: -579.54672, mean: -0.34912
[32m[0906 23-54-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08779, current rewards: -604.47690, mean: -0.35350
[32m[0906 23-54-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08776, current rewards: -597.50907, mean: -0.33949
[32m[0906 23-54-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08767, current rewards: -590.26709, mean: -0.32611
[32m[0906 23-54-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08764, current rewards: -582.98810, mean: -0.31343
[32m[0906 23-54-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08762, current rewards: -575.67505, mean: -0.30140
[32m[0906 23-54-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08760, current rewards: -568.41146, mean: -0.29001
[32m[0906 23-54-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08761, current rewards: -607.73583, mean: -0.30236
[32m[0906 23-54-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08759, current rewards: -603.38168, mean: -0.29290
[32m[0906 23-54-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08763, current rewards: -596.84074, mean: -0.28286
[32m[0906 23-54-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08768, current rewards: -590.57276, mean: -0.27341
[32m[0906 23-54-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08772, current rewards: -584.16563, mean: -0.26433
[32m[0906 23-54-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08776, current rewards: -577.88069, mean: -0.25570
[32m[0906 23-54-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08780, current rewards: -571.60688, mean: -0.24745
[32m[0906 23-54-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08783, current rewards: -565.37263, mean: -0.23956
[32m[0906 23-55-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08787, current rewards: -559.11993, mean: -0.23200
[32m[0906 23-55-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08791, current rewards: -552.79726, mean: -0.22471
[32m[0906 23-55-12 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0906 23-55-12 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-55-12 @MBExp.py:227][0m Rewards obtained: [-558.0837125086059], Lows: [183], Highs: [453], Total time: 26062.994355999996
[32m[0906 23-58-16 @MBExp.py:144][0m ####################################################################
[32m[0906 23-58-16 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 23-58-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08355, current rewards: -6.70490, mean: -0.67049
[32m[0906 23-58-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08625, current rewards: -4.65122, mean: -0.07752
[32m[0906 23-58-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08648, current rewards: 1.85401, mean: 0.01685
[32m[0906 23-58-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08661, current rewards: 7.64809, mean: 0.04780
[32m[0906 23-58-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08672, current rewards: 13.43803, mean: 0.06399
[32m[0906 23-58-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08676, current rewards: 19.22296, mean: 0.07393
[32m[0906 23-58-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08679, current rewards: 10.97151, mean: 0.03539
[32m[0906 23-58-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08679, current rewards: -86.92195, mean: -0.24145
[32m[0906 23-58-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08686, current rewards: -186.92195, mean: -0.45591
[32m[0906 23-58-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08689, current rewards: -286.92195, mean: -0.62374
[32m[0906 23-59-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08692, current rewards: -386.92195, mean: -0.75867
[32m[0906 23-59-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08690, current rewards: -486.92195, mean: -0.86950
[32m[0906 23-59-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08689, current rewards: -586.92195, mean: -0.96217
[32m[0906 23-59-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08691, current rewards: -654.80518, mean: -0.99213
[32m[0906 23-59-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08692, current rewards: -649.58524, mean: -0.91491
[32m[0906 23-59-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08691, current rewards: -644.40439, mean: -0.84790
[32m[0906 23-59-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08690, current rewards: -639.22720, mean: -0.78917
[32m[0906 23-59-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08689, current rewards: -634.04558, mean: -0.73726
[32m[0906 23-59-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08688, current rewards: -660.25236, mean: -0.72555
[32m[0906 23-59-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08687, current rewards: -710.25236, mean: -0.73985
[32m[0906 23-59-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08687, current rewards: -760.25236, mean: -0.75273
[32m[0906 23-59-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08687, current rewards: -810.25236, mean: -0.76439
[32m[0906 23-59-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08687, current rewards: -860.25236, mean: -0.77500
[32m[0906 23-59-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08686, current rewards: -910.25236, mean: -0.78470
[32m[0907 00-00-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08687, current rewards: -960.25236, mean: -0.79360
[32m[0907 00-00-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08686, current rewards: -1010.25236, mean: -0.80179
[32m[0907 00-00-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08686, current rewards: -1042.41192, mean: -0.79573
[32m[0907 00-00-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08688, current rewards: -1053.13751, mean: -0.77437
[32m[0907 00-00-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08688, current rewards: -1047.80843, mean: -0.74313
[32m[0907 00-00-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08687, current rewards: -1042.48081, mean: -0.71403
[32m[0907 00-00-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08686, current rewards: -1037.15255, mean: -0.68686
[32m[0907 00-00-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08685, current rewards: -1031.82496, mean: -0.66143
[32m[0907 00-00-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08685, current rewards: -1026.49721, mean: -0.63758
[32m[0907 00-00-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08684, current rewards: -1021.17167, mean: -0.61516
[32m[0907 00-00-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08684, current rewards: -1015.87028, mean: -0.59408
[32m[0907 00-00-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08683, current rewards: -1035.62201, mean: -0.58842
[32m[0907 00-00-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08681, current rewards: -1048.15279, mean: -0.57909
[32m[0907 00-00-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08678, current rewards: -1062.67473, mean: -0.57133
[32m[0907 00-01-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08680, current rewards: -1075.23045, mean: -0.56295
[32m[0907 00-01-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08681, current rewards: -1087.66077, mean: -0.55493
[32m[0907 00-01-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08681, current rewards: -1102.27049, mean: -0.54839
[32m[0907 00-01-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08681, current rewards: -1114.81037, mean: -0.54117
[32m[0907 00-01-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08693, current rewards: -1137.00170, mean: -0.53886
[32m[0907 00-01-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08702, current rewards: -1168.26170, mean: -0.54086
[32m[0907 00-01-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08711, current rewards: -1192.44690, mean: -0.53957
[32m[0907 00-01-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08718, current rewards: -1199.94796, mean: -0.53095
[32m[0907 00-01-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08722, current rewards: -1194.63928, mean: -0.51716
[32m[0907 00-01-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08728, current rewards: -1189.33479, mean: -0.50396
[32m[0907 00-01-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08733, current rewards: -1184.02270, mean: -0.49130
[32m[0907 00-01-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08737, current rewards: -1178.71181, mean: -0.47915
[32m[0907 00-01-55 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0907 00-01-55 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-01-56 @MBExp.py:227][0m Rewards obtained: [-1204.1194055433118], Lows: [482], Highs: [432], Total time: 26282.251252999995
[32m[0907 00-05-01 @MBExp.py:144][0m ####################################################################
[32m[0907 00-05-01 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 00-05-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11170, current rewards: -8.94529, mean: -0.89453
[32m[0907 00-05-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09361, current rewards: -58.40981, mean: -0.97350
[32m[0907 00-05-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09328, current rewards: -108.40981, mean: -0.98554
[32m[0907 00-05-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09238, current rewards: -156.27271, mean: -0.97670
[32m[0907 00-05-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09151, current rewards: -206.27271, mean: -0.98225
[32m[0907 00-05-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09160, current rewards: -256.27271, mean: -0.98566
[32m[0907 00-05-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09165, current rewards: -306.27271, mean: -0.98798
[32m[0907 00-05-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09145, current rewards: -356.27271, mean: -0.98965
[32m[0907 00-05-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09109, current rewards: -406.27271, mean: -0.99091
[32m[0907 00-05-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09077, current rewards: -456.27271, mean: -0.99190
[32m[0907 00-05-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09041, current rewards: -454.48894, mean: -0.89115
[32m[0907 00-05-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09011, current rewards: -449.68557, mean: -0.80301
[32m[0907 00-05-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08985, current rewards: -444.88142, mean: -0.72931
[32m[0907 00-06-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08963, current rewards: -440.07805, mean: -0.66678
[32m[0907 00-06-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08946, current rewards: -435.27364, mean: -0.61306
[32m[0907 00-06-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08930, current rewards: -430.47077, mean: -0.56641
[32m[0907 00-06-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08917, current rewards: -425.66867, mean: -0.52552
[32m[0907 00-06-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08905, current rewards: -420.40763, mean: -0.48885
[32m[0907 00-06-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08891, current rewards: -414.95438, mean: -0.45599
[32m[0907 00-06-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08880, current rewards: -409.50113, mean: -0.42656
[32m[0907 00-06-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08871, current rewards: -404.04788, mean: -0.40005
[32m[0907 00-06-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08868, current rewards: -448.50256, mean: -0.42312
[32m[0907 00-06-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08889, current rewards: -498.50256, mean: -0.44910
[32m[0907 00-06-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08909, current rewards: -548.50256, mean: -0.47285
[32m[0907 00-06-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08919, current rewards: -598.50256, mean: -0.49463
[32m[0907 00-06-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08935, current rewards: -648.50256, mean: -0.51468
[32m[0907 00-06-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08956, current rewards: -702.20524, mean: -0.53603
[32m[0907 00-07-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08946, current rewards: -802.20524, mean: -0.58986
[32m[0907 00-07-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08938, current rewards: -902.20524, mean: -0.63986
[32m[0907 00-07-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08930, current rewards: -1002.20524, mean: -0.68644
[32m[0907 00-07-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08921, current rewards: -1102.20524, mean: -0.72994
[32m[0907 00-07-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08914, current rewards: -1202.20524, mean: -0.77064
[32m[0907 00-07-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08907, current rewards: -1302.20524, mean: -0.80882
[32m[0907 00-07-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08900, current rewards: -1402.20524, mean: -0.84470
[32m[0907 00-07-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08894, current rewards: -1502.20524, mean: -0.87848
[32m[0907 00-07-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08886, current rewards: -1602.20524, mean: -0.91034
[32m[0907 00-07-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08876, current rewards: -1702.20524, mean: -0.94044
[32m[0907 00-07-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08871, current rewards: -1802.20524, mean: -0.96893
[32m[0907 00-07-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08867, current rewards: -1902.20524, mean: -0.99592
[32m[0907 00-07-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08862, current rewards: -2002.20524, mean: -1.02153
[32m[0907 00-07-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08858, current rewards: -2102.20524, mean: -1.04587
[32m[0907 00-08-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08854, current rewards: -2202.20524, mean: -1.06903
[32m[0907 00-08-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08850, current rewards: -2302.20524, mean: -1.09109
[32m[0907 00-08-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08849, current rewards: -2402.20524, mean: -1.11213
[32m[0907 00-08-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08851, current rewards: -2502.20524, mean: -1.13222
[32m[0907 00-08-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08853, current rewards: -2602.20524, mean: -1.15142
[32m[0907 00-08-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08856, current rewards: -2702.20524, mean: -1.16979
[32m[0907 00-08-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08858, current rewards: -2802.20524, mean: -1.18738
[32m[0907 00-08-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08860, current rewards: -2902.20524, mean: -1.20423
[32m[0907 00-08-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08863, current rewards: -3002.20524, mean: -1.22041
[32m[0907 00-08-43 @Agent.py:117][0m Average action selection time: 0.0886
[32m[0907 00-08-43 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-08-43 @MBExp.py:227][0m Rewards obtained: [-3082.2052422143524], Lows: [1209], Highs: [722], Total time: 26504.605443999993
[32m[0907 00-11-51 @MBExp.py:144][0m ####################################################################
[32m[0907 00-11-51 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 00-11-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08591, current rewards: -7.62803, mean: -0.76280
[32m[0907 00-11-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08703, current rewards: -4.35435, mean: -0.07257
[32m[0907 00-12-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08698, current rewards: 1.42014, mean: 0.01291
[32m[0907 00-12-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08692, current rewards: 7.19830, mean: 0.04499
[32m[0907 00-12-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08694, current rewards: 12.97124, mean: 0.06177
[32m[0907 00-12-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08692, current rewards: 18.74628, mean: 0.07210
[32m[0907 00-12-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08696, current rewards: 24.52963, mean: 0.07913
[32m[0907 00-12-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08691, current rewards: 30.30692, mean: 0.08419
[32m[0907 00-12-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08687, current rewards: 36.08386, mean: 0.08801
[32m[0907 00-12-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08687, current rewards: 42.40789, mean: 0.09219
[32m[0907 00-12-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08688, current rewards: 48.25680, mean: 0.09462
[32m[0907 00-12-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08687, current rewards: 54.10338, mean: 0.09661
[32m[0907 00-12-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08691, current rewards: 37.66787, mean: 0.06175
[32m[0907 00-12-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08690, current rewards: 43.22963, mean: 0.06550
[32m[0907 00-12-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08688, current rewards: 48.77711, mean: 0.06870
[32m[0907 00-12-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08687, current rewards: 54.32483, mean: 0.07148
[32m[0907 00-13-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08688, current rewards: 59.87219, mean: 0.07392
[32m[0907 00-13-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08688, current rewards: 54.13291, mean: 0.06295
[32m[0907 00-13-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08688, current rewards: 35.36289, mean: 0.03886
[32m[0907 00-13-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08686, current rewards: 16.56885, mean: 0.01726
[32m[0907 00-13-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08687, current rewards: -4.46359, mean: -0.00442
[32m[0907 00-13-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08687, current rewards: -15.93175, mean: -0.01503
[32m[0907 00-13-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08686, current rewards: -28.36337, mean: -0.02555
[32m[0907 00-13-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08687, current rewards: -46.79973, mean: -0.04034
[32m[0907 00-13-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08687, current rewards: -69.95215, mean: -0.05781
[32m[0907 00-13-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08688, current rewards: -86.59376, mean: -0.06873
[32m[0907 00-13-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08685, current rewards: -81.08113, mean: -0.06189
[32m[0907 00-13-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08686, current rewards: -75.56751, mean: -0.05556
[32m[0907 00-13-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08684, current rewards: -70.05397, mean: -0.04968
[32m[0907 00-13-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08685, current rewards: -64.54828, mean: -0.04421
[32m[0907 00-14-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08686, current rewards: -59.04285, mean: -0.03910
[32m[0907 00-14-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08688, current rewards: -53.53362, mean: -0.03432
[32m[0907 00-14-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08689, current rewards: -48.02171, mean: -0.02983
[32m[0907 00-14-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08689, current rewards: -42.51446, mean: -0.02561
[32m[0907 00-14-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08690, current rewards: -37.00811, mean: -0.02164
[32m[0907 00-14-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08690, current rewards: -31.49886, mean: -0.01790
[32m[0907 00-14-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08685, current rewards: -25.98199, mean: -0.01435
[32m[0907 00-14-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08683, current rewards: -20.47480, mean: -0.01101
[32m[0907 00-14-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08683, current rewards: -14.95662, mean: -0.00783
[32m[0907 00-14-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08684, current rewards: -9.44825, mean: -0.00482
[32m[0907 00-14-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08684, current rewards: -3.93887, mean: -0.00196
[32m[0907 00-14-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08685, current rewards: 2.01381, mean: 0.00098
[32m[0907 00-14-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08684, current rewards: -2.95299, mean: -0.00140
[32m[0907 00-14-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08684, current rewards: 2.71040, mean: 0.00125
[32m[0907 00-15-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08690, current rewards: 8.37127, mean: 0.00379
[32m[0907 00-15-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08695, current rewards: 14.03132, mean: 0.00621
[32m[0907 00-15-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08702, current rewards: 19.69634, mean: 0.00853
[32m[0907 00-15-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08707, current rewards: 25.35250, mean: 0.01074
[32m[0907 00-15-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08712, current rewards: 31.01171, mean: 0.01287
[32m[0907 00-15-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08717, current rewards: 36.68842, mean: 0.01491
[32m[0907 00-15-30 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0907 00-15-30 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-15-30 @MBExp.py:227][0m Rewards obtained: [41.250798483748625], Lows: [99], Highs: [79], Total time: 26723.298231999994
[32m[0907 00-18-39 @MBExp.py:144][0m ####################################################################
[32m[0907 00-18-39 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 00-18-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08570, current rewards: -0.89636, mean: -0.08964
[32m[0907 00-18-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08665, current rewards: 4.17613, mean: 0.06960
[32m[0907 00-18-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08661, current rewards: 10.48075, mean: 0.09528
[32m[0907 00-18-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08674, current rewards: 16.78727, mean: 0.10492
[32m[0907 00-18-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08681, current rewards: 23.09985, mean: 0.11000
[32m[0907 00-19-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08681, current rewards: 29.40979, mean: 0.11311
[32m[0907 00-19-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08683, current rewards: 35.72447, mean: 0.11524
[32m[0907 00-19-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08685, current rewards: 42.03702, mean: 0.11677
[32m[0907 00-19-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08683, current rewards: 48.34628, mean: 0.11792
[32m[0907 00-19-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08697, current rewards: 35.39565, mean: 0.07695
[32m[0907 00-19-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08718, current rewards: -13.31389, mean: -0.02611
[32m[0907 00-19-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08733, current rewards: -68.69477, mean: -0.12267
[32m[0907 00-19-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08770, current rewards: -137.05270, mean: -0.22468
[32m[0907 00-19-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08773, current rewards: -194.63703, mean: -0.29490
[32m[0907 00-19-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08780, current rewards: -261.79892, mean: -0.36873
[32m[0907 00-19-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08788, current rewards: -324.08771, mean: -0.42643
[32m[0907 00-19-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08793, current rewards: -387.84255, mean: -0.47882
[32m[0907 00-19-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08815, current rewards: -434.16721, mean: -0.50485
[32m[0907 00-20-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08827, current rewards: -489.25418, mean: -0.53764
[32m[0907 00-20-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08838, current rewards: -543.90871, mean: -0.56657
[32m[0907 00-20-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08834, current rewards: -600.09091, mean: -0.59415
[32m[0907 00-20-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08844, current rewards: -663.76357, mean: -0.62619
[32m[0907 00-20-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08845, current rewards: -728.92262, mean: -0.65669
[32m[0907 00-20-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08859, current rewards: -784.43752, mean: -0.67624
[32m[0907 00-20-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08851, current rewards: -868.30001, mean: -0.71760
[32m[0907 00-20-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08844, current rewards: -919.99813, mean: -0.73016
[32m[0907 00-20-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08860, current rewards: -968.38692, mean: -0.73923
[32m[0907 00-20-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08863, current rewards: -1037.44778, mean: -0.76283
[32m[0907 00-20-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08860, current rewards: -1094.07082, mean: -0.77594
[32m[0907 00-20-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08855, current rewards: -1089.33721, mean: -0.74612
[32m[0907 00-20-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08854, current rewards: -1121.45875, mean: -0.74269
[32m[0907 00-20-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08855, current rewards: -1141.87179, mean: -0.73197
[32m[0907 00-21-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08851, current rewards: -1136.30082, mean: -0.70578
[32m[0907 00-21-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08846, current rewards: -1130.59796, mean: -0.68108
[32m[0907 00-21-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08842, current rewards: -1125.00664, mean: -0.65790
[32m[0907 00-21-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08840, current rewards: -1139.22892, mean: -0.64729
[32m[0907 00-21-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08830, current rewards: -1150.46786, mean: -0.63562
[32m[0907 00-21-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08823, current rewards: -1144.86325, mean: -0.61552
[32m[0907 00-21-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08819, current rewards: -1139.26304, mean: -0.59647
[32m[0907 00-21-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08817, current rewards: -1133.66099, mean: -0.57840
[32m[0907 00-21-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08814, current rewards: -1128.06379, mean: -0.56123
[32m[0907 00-21-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08811, current rewards: -1122.99394, mean: -0.54514
[32m[0907 00-21-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08809, current rewards: -1117.39660, mean: -0.52957
[32m[0907 00-21-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08813, current rewards: -1111.79840, mean: -0.51472
[32m[0907 00-21-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08816, current rewards: -1106.20412, mean: -0.50054
[32m[0907 00-21-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08819, current rewards: -1100.60163, mean: -0.48699
[32m[0907 00-22-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08822, current rewards: -1095.01103, mean: -0.47403
[32m[0907 00-22-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08826, current rewards: -1115.53473, mean: -0.47268
[32m[0907 00-22-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08829, current rewards: -1119.23208, mean: -0.46441
[32m[0907 00-22-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08831, current rewards: -1112.97883, mean: -0.45243
[32m[0907 00-22-20 @Agent.py:117][0m Average action selection time: 0.0883
[32m[0907 00-22-20 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-22-21 @MBExp.py:227][0m Rewards obtained: [-1106.9537552294096], Lows: [590], Highs: [151], Total time: 26944.888349999994
[32m[0907 00-25-33 @MBExp.py:144][0m ####################################################################
[32m[0907 00-25-33 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 00-25-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08351, current rewards: -15.00000, mean: -1.50000
[32m[0907 00-25-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08426, current rewards: -15.76608, mean: -0.26277
[32m[0907 00-25-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08448, current rewards: -9.22622, mean: -0.08387
[32m[0907 00-25-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08525, current rewards: -2.67114, mean: -0.01669
[32m[0907 00-25-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08573, current rewards: 3.88084, mean: 0.01848
[32m[0907 00-25-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08598, current rewards: 10.41592, mean: 0.04006
[32m[0907 00-26-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08617, current rewards: 16.95790, mean: 0.05470
[32m[0907 00-26-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08624, current rewards: 23.47769, mean: 0.06522
[32m[0907 00-26-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08630, current rewards: 30.02502, mean: 0.07323
[32m[0907 00-26-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08636, current rewards: 26.03971, mean: 0.05661
[32m[0907 00-26-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08644, current rewards: 31.73000, mean: 0.06222
[32m[0907 00-26-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08648, current rewards: 37.41408, mean: 0.06681
[32m[0907 00-26-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08651, current rewards: 43.09553, mean: 0.07065
[32m[0907 00-26-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08654, current rewards: 48.78032, mean: 0.07391
[32m[0907 00-26-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08655, current rewards: 54.46232, mean: 0.07671
[32m[0907 00-26-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08657, current rewards: 60.15210, mean: 0.07915
[32m[0907 00-26-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08659, current rewards: 60.00081, mean: 0.07408
[32m[0907 00-26-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08660, current rewards: 58.16060, mean: 0.06763
[32m[0907 00-26-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08662, current rewards: 64.17194, mean: 0.07052
[32m[0907 00-26-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08665, current rewards: 70.18832, mean: 0.07311
[32m[0907 00-27-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08666, current rewards: 76.20301, mean: 0.07545
[32m[0907 00-27-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08667, current rewards: 82.22370, mean: 0.07757
[32m[0907 00-27-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08670, current rewards: 88.23363, mean: 0.07949
[32m[0907 00-27-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08672, current rewards: 94.24423, mean: 0.08125
[32m[0907 00-27-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08673, current rewards: 100.25636, mean: 0.08286
[32m[0907 00-27-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08674, current rewards: 106.26790, mean: 0.08434
[32m[0907 00-27-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08674, current rewards: 112.28815, mean: 0.08572
[32m[0907 00-27-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08676, current rewards: 118.30625, mean: 0.08699
[32m[0907 00-27-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08676, current rewards: 124.32125, mean: 0.08817
[32m[0907 00-27-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08677, current rewards: 130.32865, mean: 0.08927
[32m[0907 00-27-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08677, current rewards: 136.34525, mean: 0.09029
[32m[0907 00-27-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08677, current rewards: 135.99757, mean: 0.08718
[32m[0907 00-27-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08677, current rewards: 137.96562, mean: 0.08569
[32m[0907 00-27-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08677, current rewards: 143.46722, mean: 0.08643
[32m[0907 00-28-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08678, current rewards: 148.97208, mean: 0.08712
[32m[0907 00-28-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08678, current rewards: 154.46849, mean: 0.08777
[32m[0907 00-28-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08672, current rewards: 159.97261, mean: 0.08838
[32m[0907 00-28-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08665, current rewards: 165.47651, mean: 0.08897
[32m[0907 00-28-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08663, current rewards: 170.97659, mean: 0.08952
[32m[0907 00-28-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08664, current rewards: 176.47831, mean: 0.09004
[32m[0907 00-28-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08665, current rewards: 181.98073, mean: 0.09054
[32m[0907 00-28-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08666, current rewards: 187.52175, mean: 0.09103
[32m[0907 00-28-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08667, current rewards: 193.03435, mean: 0.09149
[32m[0907 00-28-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08669, current rewards: 198.54215, mean: 0.09192
[32m[0907 00-28-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08676, current rewards: 204.04613, mean: 0.09233
[32m[0907 00-28-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08682, current rewards: 198.98581, mean: 0.08805
[32m[0907 00-28-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08688, current rewards: 205.91632, mean: 0.08914
[32m[0907 00-28-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08694, current rewards: 212.91871, mean: 0.09022
[32m[0907 00-29-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08700, current rewards: 219.91890, mean: 0.09125
[32m[0907 00-29-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08706, current rewards: 228.07074, mean: 0.09271
[32m[0907 00-29-11 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 00-29-11 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-29-11 @MBExp.py:227][0m Rewards obtained: [233.6935541972213], Lows: [27], Highs: [11], Total time: 27163.413209999995
[32m[0907 00-32-25 @MBExp.py:144][0m ####################################################################
[32m[0907 00-32-25 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 00-32-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09281, current rewards: -7.55971, mean: -0.75597
[32m[0907 00-32-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08612, current rewards: -72.20611, mean: -1.20344
[32m[0907 00-32-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08575, current rewards: -131.47224, mean: -1.19520
[32m[0907 00-32-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08660, current rewards: -176.85873, mean: -1.10537
[32m[0907 00-32-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08694, current rewards: -222.44545, mean: -1.05926
[32m[0907 00-32-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08724, current rewards: -271.72830, mean: -1.04511
[32m[0907 00-32-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08716, current rewards: -319.40209, mean: -1.03033
[32m[0907 00-32-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08711, current rewards: -367.23158, mean: -1.02009
[32m[0907 00-33-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08736, current rewards: -419.11963, mean: -1.02224
[32m[0907 00-33-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08785, current rewards: -468.57831, mean: -1.01865
[32m[0907 00-33-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08818, current rewards: -533.26046, mean: -1.04561
[32m[0907 00-33-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08836, current rewards: -584.67609, mean: -1.04406
[32m[0907 00-33-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08834, current rewards: -642.85101, mean: -1.05385
[32m[0907 00-33-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08824, current rewards: -703.94168, mean: -1.06658
[32m[0907 00-33-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08821, current rewards: -766.36953, mean: -1.07939
[32m[0907 00-33-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08813, current rewards: -830.77964, mean: -1.09313
[32m[0907 00-33-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08827, current rewards: -896.84794, mean: -1.10722
[32m[0907 00-33-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08824, current rewards: -966.93251, mean: -1.12434
[32m[0907 00-33-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08822, current rewards: -1041.52602, mean: -1.14453
[32m[0907 00-33-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08817, current rewards: -1141.52602, mean: -1.18909
[32m[0907 00-33-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08813, current rewards: -1241.52602, mean: -1.22923
[32m[0907 00-33-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08809, current rewards: -1341.52602, mean: -1.26559
[32m[0907 00-34-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08804, current rewards: -1441.52602, mean: -1.29867
[32m[0907 00-34-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08801, current rewards: -1541.52602, mean: -1.32890
[32m[0907 00-34-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08796, current rewards: -1629.93720, mean: -1.34706
[32m[0907 00-34-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08792, current rewards: -1624.39175, mean: -1.28920
[32m[0907 00-34-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08788, current rewards: -1618.94315, mean: -1.23583
[32m[0907 00-34-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08785, current rewards: -1613.50003, mean: -1.18640
[32m[0907 00-34-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08782, current rewards: -1608.05081, mean: -1.14046
[32m[0907 00-34-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08779, current rewards: -1602.61363, mean: -1.09768
[32m[0907 00-34-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08776, current rewards: -1633.07068, mean: -1.08150
[32m[0907 00-34-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08774, current rewards: -1680.05842, mean: -1.07696
[32m[0907 00-34-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08772, current rewards: -1713.09889, mean: -1.06404
[32m[0907 00-34-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08779, current rewards: -1776.67998, mean: -1.07029
[32m[0907 00-34-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08792, current rewards: -1826.78234, mean: -1.06829
[32m[0907 00-35-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08794, current rewards: -1890.53466, mean: -1.07417
[32m[0907 00-35-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08801, current rewards: -1950.83134, mean: -1.07781
[32m[0907 00-35-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08804, current rewards: -2004.14243, mean: -1.07750
[32m[0907 00-35-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08801, current rewards: -2061.61686, mean: -1.07938
[32m[0907 00-35-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08799, current rewards: -2128.17072, mean: -1.08580
[32m[0907 00-35-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08795, current rewards: -2186.02924, mean: -1.08758
[32m[0907 00-35-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08801, current rewards: -2250.25190, mean: -1.09236
[32m[0907 00-35-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08810, current rewards: -2306.43085, mean: -1.09310
[32m[0907 00-35-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08823, current rewards: -2358.30073, mean: -1.09181
[32m[0907 00-35-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08834, current rewards: -2404.83377, mean: -1.08816
[32m[0907 00-35-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08853, current rewards: -2459.25409, mean: -1.08817
[32m[0907 00-35-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08865, current rewards: -2517.77732, mean: -1.08995
[32m[0907 00-35-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08877, current rewards: -2556.50444, mean: -1.08326
[32m[0907 00-35-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08880, current rewards: -2613.24769, mean: -1.08434
[32m[0907 00-36-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08900, current rewards: -2660.11647, mean: -1.08135
[32m[0907 00-36-08 @Agent.py:117][0m Average action selection time: 0.0891
[32m[0907 00-36-08 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-36-08 @MBExp.py:227][0m Rewards obtained: [-2708.6723285093003], Lows: [1444], Highs: [15], Total time: 27386.919953999994
[32m[0907 00-39-23 @MBExp.py:144][0m ####################################################################
[32m[0907 00-39-23 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 00-39-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08333, current rewards: -6.77605, mean: -0.67760
[32m[0907 00-39-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08481, current rewards: 3.40075, mean: 0.05668
[32m[0907 00-39-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08571, current rewards: 14.00687, mean: 0.12734
[32m[0907 00-39-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08613, current rewards: 24.60503, mean: 0.15378
[32m[0907 00-39-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08629, current rewards: 35.17703, mean: 0.16751
[32m[0907 00-39-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08642, current rewards: 45.78784, mean: 0.17611
[32m[0907 00-39-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08641, current rewards: 56.38763, mean: 0.18190
[32m[0907 00-39-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08647, current rewards: 66.97771, mean: 0.18605
[32m[0907 00-39-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08651, current rewards: 77.42216, mean: 0.18883
[32m[0907 00-40-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08673, current rewards: 1.84436, mean: 0.00401
[32m[0907 00-40-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08706, current rewards: -85.52718, mean: -0.16770
[32m[0907 00-40-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08704, current rewards: -185.52718, mean: -0.33130
[32m[0907 00-40-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08704, current rewards: -285.52718, mean: -0.46808
[32m[0907 00-40-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08702, current rewards: -385.52718, mean: -0.58413
[32m[0907 00-40-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08700, current rewards: -485.52718, mean: -0.68384
[32m[0907 00-40-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08697, current rewards: -585.52718, mean: -0.77043
[32m[0907 00-40-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08695, current rewards: -685.52718, mean: -0.84633
[32m[0907 00-40-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08695, current rewards: -785.52718, mean: -0.91340
[32m[0907 00-40-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08695, current rewards: -885.52718, mean: -0.97311
[32m[0907 00-40-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08694, current rewards: -985.52718, mean: -1.02659
[32m[0907 00-40-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08693, current rewards: -1085.52718, mean: -1.07478
[32m[0907 00-40-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08692, current rewards: -1185.52718, mean: -1.11842
[32m[0907 00-41-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08691, current rewards: -1285.52718, mean: -1.15813
[32m[0907 00-41-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08690, current rewards: -1385.52718, mean: -1.19442
[32m[0907 00-41-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08691, current rewards: -1485.52718, mean: -1.22771
[32m[0907 00-41-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08690, current rewards: -1585.52718, mean: -1.25835
[32m[0907 00-41-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08690, current rewards: -1685.52718, mean: -1.28666
[32m[0907 00-41-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08691, current rewards: -1785.52718, mean: -1.31289
[32m[0907 00-41-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08691, current rewards: -1885.52718, mean: -1.33725
[32m[0907 00-41-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08691, current rewards: -1985.52718, mean: -1.35995
[32m[0907 00-41-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08691, current rewards: -2085.52718, mean: -1.38114
[32m[0907 00-41-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08690, current rewards: -2185.52718, mean: -1.40098
[32m[0907 00-41-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08689, current rewards: -2285.52718, mean: -1.41958
[32m[0907 00-41-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08690, current rewards: -2385.52718, mean: -1.43706
[32m[0907 00-41-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08689, current rewards: -2485.52718, mean: -1.45352
[32m[0907 00-41-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08685, current rewards: -2585.52718, mean: -1.46905
[32m[0907 00-42-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08678, current rewards: -2685.52718, mean: -1.48372
[32m[0907 00-42-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08672, current rewards: -2785.52718, mean: -1.49760
[32m[0907 00-42-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08667, current rewards: -2885.52718, mean: -1.51075
[32m[0907 00-42-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08661, current rewards: -2985.52718, mean: -1.52323
[32m[0907 00-42-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08657, current rewards: -3085.52718, mean: -1.53509
[32m[0907 00-42-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08654, current rewards: -3185.52718, mean: -1.54637
[32m[0907 00-42-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08659, current rewards: -3285.52718, mean: -1.55712
[32m[0907 00-42-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08666, current rewards: -3385.52718, mean: -1.56737
[32m[0907 00-42-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08672, current rewards: -3485.52718, mean: -1.57716
[32m[0907 00-42-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08678, current rewards: -3585.52718, mean: -1.58652
[32m[0907 00-42-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08685, current rewards: -3685.52718, mean: -1.59547
[32m[0907 00-42-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08690, current rewards: -3785.52718, mean: -1.60404
[32m[0907 00-42-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08696, current rewards: -3885.52718, mean: -1.61225
[32m[0907 00-42-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08701, current rewards: -3985.52718, mean: -1.62013
[32m[0907 00-43-01 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 00-43-01 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-43-02 @MBExp.py:227][0m Rewards obtained: [-4065.5271797878613], Lows: [2073], Highs: [7], Total time: 27605.308480999993
[32m[0907 00-46-18 @MBExp.py:144][0m ####################################################################
[32m[0907 00-46-18 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 00-46-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08901, current rewards: -8.49338, mean: -0.84934
[32m[0907 00-46-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08612, current rewards: -5.27423, mean: -0.08790
[32m[0907 00-46-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08660, current rewards: 0.17293, mean: 0.00157
[32m[0907 00-46-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08676, current rewards: 5.62294, mean: 0.03514
[32m[0907 00-46-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08679, current rewards: 11.07109, mean: 0.05272
[32m[0907 00-46-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08678, current rewards: 16.52013, mean: 0.06354
[32m[0907 00-46-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08682, current rewards: 21.96599, mean: 0.07086
[32m[0907 00-46-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08683, current rewards: 27.41292, mean: 0.07615
[32m[0907 00-46-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08683, current rewards: 33.09444, mean: 0.08072
[32m[0907 00-46-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08684, current rewards: 38.54221, mean: 0.08379
[32m[0907 00-47-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08697, current rewards: 31.41640, mean: 0.06160
[32m[0907 00-47-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08696, current rewards: 36.95265, mean: 0.06599
[32m[0907 00-47-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08697, current rewards: 42.49756, mean: 0.06967
[32m[0907 00-47-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08693, current rewards: 48.04038, mean: 0.07279
[32m[0907 00-47-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08694, current rewards: 53.57955, mean: 0.07546
[32m[0907 00-47-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08693, current rewards: 59.12326, mean: 0.07779
[32m[0907 00-47-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08690, current rewards: 64.38282, mean: 0.07948
[32m[0907 00-47-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08689, current rewards: 69.91528, mean: 0.08130
[32m[0907 00-47-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08690, current rewards: 75.45434, mean: 0.08292
[32m[0907 00-47-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08690, current rewards: 80.98769, mean: 0.08436
[32m[0907 00-47-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08691, current rewards: 86.52110, mean: 0.08566
[32m[0907 00-47-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08691, current rewards: 92.06261, mean: 0.08685
[32m[0907 00-47-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08690, current rewards: 97.60279, mean: 0.08793
[32m[0907 00-47-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08689, current rewards: 103.13619, mean: 0.08891
[32m[0907 00-48-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08693, current rewards: 96.50564, mean: 0.07976
[32m[0907 00-48-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08692, current rewards: 101.93498, mean: 0.08090
[32m[0907 00-48-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08692, current rewards: 107.30855, mean: 0.08191
[32m[0907 00-48-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08691, current rewards: 112.68402, mean: 0.08286
[32m[0907 00-48-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08690, current rewards: 118.06087, mean: 0.08373
[32m[0907 00-48-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08691, current rewards: 123.43721, mean: 0.08455
[32m[0907 00-48-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08691, current rewards: 128.81676, mean: 0.08531
[32m[0907 00-48-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08692, current rewards: 134.19339, mean: 0.08602
[32m[0907 00-48-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08691, current rewards: 135.07565, mean: 0.08390
[32m[0907 00-48-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08691, current rewards: 145.16603, mean: 0.08745
[32m[0907 00-48-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08691, current rewards: 152.12056, mean: 0.08896
[32m[0907 00-48-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08686, current rewards: 159.08815, mean: 0.09039
[32m[0907 00-48-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08680, current rewards: 166.03554, mean: 0.09173
[32m[0907 00-49-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08674, current rewards: 173.00014, mean: 0.09301
[32m[0907 00-49-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08671, current rewards: 162.17903, mean: 0.08491
[32m[0907 00-49-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08666, current rewards: 167.64909, mean: 0.08554
[32m[0907 00-49-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08661, current rewards: 173.11716, mean: 0.08613
[32m[0907 00-49-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08661, current rewards: 168.33699, mean: 0.08172
[32m[0907 00-49-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08667, current rewards: 173.87338, mean: 0.08240
[32m[0907 00-49-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08673, current rewards: 179.40787, mean: 0.08306
[32m[0907 00-49-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08679, current rewards: 184.94391, mean: 0.08369
[32m[0907 00-49-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08686, current rewards: 190.47182, mean: 0.08428
[32m[0907 00-49-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08693, current rewards: 178.73361, mean: 0.07737
[32m[0907 00-49-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08698, current rewards: 184.21319, mean: 0.07806
[32m[0907 00-49-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08703, current rewards: 189.68931, mean: 0.07871
[32m[0907 00-49-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08709, current rewards: 194.80638, mean: 0.07919
[32m[0907 00-49-56 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 00-49-56 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-49-57 @MBExp.py:227][0m Rewards obtained: [199.15689528923406], Lows: [32], Highs: [21], Total time: 27823.904341999994
[32m[0907 00-53-16 @MBExp.py:144][0m ####################################################################
[32m[0907 00-53-16 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 00-53-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08790, current rewards: -12.88124, mean: -1.28812
[32m[0907 00-53-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08744, current rewards: -112.88124, mean: -1.88135
[32m[0907 00-53-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08728, current rewards: -212.88124, mean: -1.93528
[32m[0907 00-53-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08727, current rewards: -312.88124, mean: -1.95551
[32m[0907 00-53-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08711, current rewards: -412.88124, mean: -1.96610
[32m[0907 00-53-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08703, current rewards: -512.88124, mean: -1.97262
[32m[0907 00-53-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08708, current rewards: -612.88124, mean: -1.97704
[32m[0907 00-53-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08705, current rewards: -712.88124, mean: -1.98023
[32m[0907 00-53-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08705, current rewards: -812.88124, mean: -1.98264
[32m[0907 00-53-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08703, current rewards: -912.88124, mean: -1.98452
[32m[0907 00-54-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08700, current rewards: -1012.88124, mean: -1.98604
[32m[0907 00-54-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08701, current rewards: -1112.88124, mean: -1.98729
[32m[0907 00-54-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08701, current rewards: -1212.88124, mean: -1.98833
[32m[0907 00-54-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08698, current rewards: -1312.88124, mean: -1.98921
[32m[0907 00-54-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08696, current rewards: -1412.88124, mean: -1.98997
[32m[0907 00-54-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08697, current rewards: -1512.88124, mean: -1.99063
[32m[0907 00-54-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08698, current rewards: -1612.88124, mean: -1.99121
[32m[0907 00-54-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08697, current rewards: -1712.88124, mean: -1.99172
[32m[0907 00-54-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08698, current rewards: -1812.88124, mean: -1.99218
[32m[0907 00-54-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08698, current rewards: -1912.88124, mean: -1.99258
[32m[0907 00-54-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08699, current rewards: -2012.88124, mean: -1.99295
[32m[0907 00-54-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08698, current rewards: -2112.88124, mean: -1.99328
[32m[0907 00-54-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08698, current rewards: -2212.88124, mean: -1.99359
[32m[0907 00-54-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08698, current rewards: -2312.88124, mean: -1.99386
[32m[0907 00-55-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08698, current rewards: -2412.88124, mean: -1.99412
[32m[0907 00-55-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08699, current rewards: -2512.88124, mean: -1.99435
[32m[0907 00-55-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08698, current rewards: -2612.88124, mean: -1.99457
[32m[0907 00-55-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08698, current rewards: -2712.88124, mean: -1.99477
[32m[0907 00-55-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08698, current rewards: -2812.88124, mean: -1.99495
[32m[0907 00-55-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08697, current rewards: -2912.88124, mean: -1.99512
[32m[0907 00-55-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08698, current rewards: -3012.88124, mean: -1.99529
[32m[0907 00-55-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08697, current rewards: -3112.88124, mean: -1.99544
[32m[0907 00-55-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08695, current rewards: -3212.88124, mean: -1.99558
[32m[0907 00-55-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08694, current rewards: -3312.88124, mean: -1.99571
[32m[0907 00-55-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08695, current rewards: -3412.88124, mean: -1.99584
[32m[0907 00-55-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08689, current rewards: -3512.88124, mean: -1.99596
[32m[0907 00-55-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08683, current rewards: -3612.88124, mean: -1.99607
[32m[0907 00-55-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08678, current rewards: -3712.88124, mean: -1.99617
[32m[0907 00-56-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08671, current rewards: -3812.88124, mean: -1.99627
[32m[0907 00-56-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08666, current rewards: -3912.88124, mean: -1.99637
[32m[0907 00-56-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08661, current rewards: -4012.88124, mean: -1.99646
[32m[0907 00-56-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08661, current rewards: -4112.88124, mean: -1.99654
[32m[0907 00-56-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08668, current rewards: -4212.88124, mean: -1.99663
[32m[0907 00-56-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08675, current rewards: -4312.88124, mean: -1.99670
[32m[0907 00-56-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08680, current rewards: -4412.88124, mean: -1.99678
[32m[0907 00-56-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08686, current rewards: -4512.88124, mean: -1.99685
[32m[0907 00-56-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08692, current rewards: -4612.88124, mean: -1.99692
[32m[0907 00-56-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08698, current rewards: -4712.88124, mean: -1.99698
[32m[0907 00-56-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08703, current rewards: -4812.88124, mean: -1.99705
[32m[0907 00-56-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08709, current rewards: -4912.88124, mean: -1.99711
[32m[0907 00-56-54 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0907 00-56-54 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-56-54 @MBExp.py:227][0m Rewards obtained: [-4992.881237801737], Lows: [2494], Highs: [5], Total time: 28042.484155999995
[32m[0907 01-00-14 @MBExp.py:144][0m ####################################################################
[32m[0907 01-00-14 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 01-00-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08905, current rewards: -14.00000, mean: -1.40000
[32m[0907 01-00-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08559, current rewards: -34.75011, mean: -0.57917
[32m[0907 01-00-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08523, current rewards: -29.32610, mean: -0.26660
[32m[0907 01-00-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08550, current rewards: -23.90704, mean: -0.14942
[32m[0907 01-00-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08577, current rewards: -18.48097, mean: -0.08800
[32m[0907 01-00-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08600, current rewards: -13.06255, mean: -0.05024
[32m[0907 01-00-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08617, current rewards: -7.64449, mean: -0.02466
[32m[0907 01-00-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08624, current rewards: -2.40074, mean: -0.00667
[32m[0907 01-00-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08632, current rewards: 3.00824, mean: 0.00734
[32m[0907 01-00-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08640, current rewards: 8.41315, mean: 0.01829
[32m[0907 01-00-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08644, current rewards: 13.82516, mean: 0.02711
[32m[0907 01-01-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08646, current rewards: -21.64638, mean: -0.03865
[32m[0907 01-01-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08651, current rewards: -49.37384, mean: -0.08094
[32m[0907 01-01-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08655, current rewards: -79.25798, mean: -0.12009
[32m[0907 01-01-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08659, current rewards: -109.08404, mean: -0.15364
[32m[0907 01-01-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08662, current rewards: -136.36563, mean: -0.17943
[32m[0907 01-01-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08664, current rewards: -162.83608, mean: -0.20103
[32m[0907 01-01-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08664, current rewards: -190.38913, mean: -0.22138
[32m[0907 01-01-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08664, current rewards: -215.84633, mean: -0.23719
[32m[0907 01-01-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08667, current rewards: -243.55479, mean: -0.25370
[32m[0907 01-01-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08669, current rewards: -279.70296, mean: -0.27693
[32m[0907 01-01-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08671, current rewards: -307.98923, mean: -0.29056
[32m[0907 01-01-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08671, current rewards: -338.38500, mean: -0.30485
[32m[0907 01-01-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08671, current rewards: -368.77911, mean: -0.31791
[32m[0907 01-02-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08672, current rewards: -397.19841, mean: -0.32826
[32m[0907 01-02-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08673, current rewards: -427.70937, mean: -0.33945
[32m[0907 01-02-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08673, current rewards: -458.21831, mean: -0.34978
[32m[0907 01-02-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08674, current rewards: -486.62477, mean: -0.35781
[32m[0907 01-02-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08676, current rewards: -519.23894, mean: -0.36825
[32m[0907 01-02-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08676, current rewards: -532.85825, mean: -0.36497
[32m[0907 01-02-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08677, current rewards: -527.12869, mean: -0.34909
[32m[0907 01-02-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08678, current rewards: -521.39802, mean: -0.33423
[32m[0907 01-02-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08677, current rewards: -515.70943, mean: -0.32032
[32m[0907 01-02-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08678, current rewards: -509.97963, mean: -0.30722
[32m[0907 01-02-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08679, current rewards: -504.24835, mean: -0.29488
[32m[0907 01-02-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08680, current rewards: -498.51858, mean: -0.28325
[32m[0907 01-02-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08675, current rewards: -511.06826, mean: -0.28236
[32m[0907 01-02-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08687, current rewards: -542.91317, mean: -0.29189
[32m[0907 01-03-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08682, current rewards: -553.45608, mean: -0.28977
[32m[0907 01-03-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08677, current rewards: -561.53577, mean: -0.28650
[32m[0907 01-03-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08672, current rewards: -569.67436, mean: -0.28342
[32m[0907 01-03-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08672, current rewards: -585.21309, mean: -0.28408
[32m[0907 01-03-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08680, current rewards: -607.88098, mean: -0.28810
[32m[0907 01-03-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08688, current rewards: -631.45647, mean: -0.29234
[32m[0907 01-03-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08703, current rewards: -679.38665, mean: -0.30741
[32m[0907 01-03-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08708, current rewards: -673.96608, mean: -0.29822
[32m[0907 01-03-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08714, current rewards: -668.44216, mean: -0.28937
[32m[0907 01-03-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08720, current rewards: -662.91522, mean: -0.28090
[32m[0907 01-03-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08726, current rewards: -657.22238, mean: -0.27271
[32m[0907 01-03-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08732, current rewards: -651.69802, mean: -0.26492
[32m[0907 01-03-53 @Agent.py:117][0m Average action selection time: 0.0874
[32m[0907 01-03-53 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-03-53 @MBExp.py:227][0m Rewards obtained: [-647.2809411040126], Lows: [451], Highs: [16], Total time: 28261.626338999995
[32m[0907 01-07-16 @MBExp.py:144][0m ####################################################################
[32m[0907 01-07-16 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 01-07-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09787, current rewards: -11.60322, mean: -1.16032
[32m[0907 01-07-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09329, current rewards: -98.86796, mean: -1.64780
[32m[0907 01-07-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09284, current rewards: -182.36928, mean: -1.65790
[32m[0907 01-07-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09398, current rewards: -255.80364, mean: -1.59877
[32m[0907 01-07-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09524, current rewards: -292.26508, mean: -1.39174
[32m[0907 01-07-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09497, current rewards: -377.12402, mean: -1.45048
[32m[0907 01-07-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09539, current rewards: -456.17594, mean: -1.47154
[32m[0907 01-07-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09586, current rewards: -534.16725, mean: -1.48380
[32m[0907 01-07-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09573, current rewards: -596.91396, mean: -1.45589
[32m[0907 01-08-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09673, current rewards: -673.01878, mean: -1.46308
[32m[0907 01-08-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09645, current rewards: -743.27483, mean: -1.45740
[32m[0907 01-08-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09665, current rewards: -815.68684, mean: -1.45658
[32m[0907 01-08-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09669, current rewards: -886.75224, mean: -1.45369
[32m[0907 01-08-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09696, current rewards: -951.81613, mean: -1.44215
[32m[0907 01-08-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09686, current rewards: -989.02834, mean: -1.39300
[32m[0907 01-08-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09703, current rewards: -1024.09088, mean: -1.34749
[32m[0907 01-08-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09707, current rewards: -1063.40236, mean: -1.31284
[32m[0907 01-08-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09701, current rewards: -1101.48417, mean: -1.28080
[32m[0907 01-08-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09747, current rewards: -1149.71441, mean: -1.26342
[32m[0907 01-08-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09737, current rewards: -1219.02005, mean: -1.26981
[32m[0907 01-08-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09712, current rewards: -1287.69501, mean: -1.27495
[32m[0907 01-08-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09673, current rewards: -1375.86229, mean: -1.29798
[32m[0907 01-09-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09648, current rewards: -1454.45983, mean: -1.31032
[32m[0907 01-09-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09608, current rewards: -1545.88029, mean: -1.33266
[32m[0907 01-09-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09571, current rewards: -1641.43624, mean: -1.35656
[32m[0907 01-09-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09536, current rewards: -1735.19656, mean: -1.37714
[32m[0907 01-09-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09515, current rewards: -1823.14472, mean: -1.39171
[32m[0907 01-09-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09498, current rewards: -1907.57787, mean: -1.40263
[32m[0907 01-09-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09480, current rewards: -1997.76662, mean: -1.41686
[32m[0907 01-09-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09453, current rewards: -2085.17705, mean: -1.42820
[32m[0907 01-09-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09429, current rewards: -2182.40984, mean: -1.44530
[32m[0907 01-09-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09427, current rewards: -2261.12581, mean: -1.44944
[32m[0907 01-09-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09427, current rewards: -2343.26374, mean: -1.45544
[32m[0907 01-09-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09417, current rewards: -2404.01076, mean: -1.44820
[32m[0907 01-09-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09406, current rewards: -2445.50916, mean: -1.43012
[32m[0907 01-10-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09394, current rewards: -2525.76290, mean: -1.43509
[32m[0907 01-10-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09392, current rewards: -2612.31058, mean: -1.44327
[32m[0907 01-10-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09397, current rewards: -2675.72266, mean: -1.43856
[32m[0907 01-10-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09421, current rewards: -2744.72357, mean: -1.43703
[32m[0907 01-10-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09457, current rewards: -2794.73564, mean: -1.42589
[32m[0907 01-10-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09463, current rewards: -2857.60223, mean: -1.42169
[32m[0907 01-10-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09450, current rewards: -2857.97049, mean: -1.38736
[32m[0907 01-10-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09439, current rewards: -2850.31541, mean: -1.35086
[32m[0907 01-10-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09428, current rewards: -2842.66033, mean: -1.31605
[32m[0907 01-10-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09418, current rewards: -2835.00524, mean: -1.28281
[32m[0907 01-10-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09408, current rewards: -2827.35016, mean: -1.25104
[32m[0907 01-10-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09399, current rewards: -2819.69508, mean: -1.22065
[32m[0907 01-10-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09390, current rewards: -2817.86869, mean: -1.19401
[32m[0907 01-11-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09381, current rewards: -2867.86869, mean: -1.18999
[32m[0907 01-11-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09372, current rewards: -2917.86869, mean: -1.18613
[32m[0907 01-11-11 @Agent.py:117][0m Average action selection time: 0.0937
[32m[0907 01-11-11 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-11-11 @MBExp.py:227][0m Rewards obtained: [-2957.8686870647502], Lows: [1219], Highs: [622], Total time: 28496.516847999996
[32m[0907 01-14-35 @MBExp.py:144][0m ####################################################################
[32m[0907 01-14-35 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 01-14-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08891, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-14-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08735, current rewards: -115.00000, mean: -1.91667
[32m[0907 01-14-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08761, current rewards: -215.00000, mean: -1.95455
[32m[0907 01-14-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08681, current rewards: -315.00000, mean: -1.96875
[32m[0907 01-14-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08648, current rewards: -415.00000, mean: -1.97619
[32m[0907 01-14-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08678, current rewards: -515.00000, mean: -1.98077
[32m[0907 01-15-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08699, current rewards: -615.00000, mean: -1.98387
[32m[0907 01-15-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08713, current rewards: -715.00000, mean: -1.98611
[32m[0907 01-15-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08719, current rewards: -815.00000, mean: -1.98780
[32m[0907 01-15-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08720, current rewards: -915.00000, mean: -1.98913
[32m[0907 01-15-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08736, current rewards: -992.18001, mean: -1.94545
[32m[0907 01-15-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08767, current rewards: -1063.38508, mean: -1.89890
[32m[0907 01-15-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08780, current rewards: -1111.50526, mean: -1.82214
[32m[0907 01-15-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08793, current rewards: -1193.11548, mean: -1.80775
[32m[0907 01-15-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08795, current rewards: -1293.11548, mean: -1.82129
[32m[0907 01-15-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08794, current rewards: -1393.11548, mean: -1.83305
[32m[0907 01-15-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08803, current rewards: -1493.11548, mean: -1.84335
[32m[0907 01-15-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08812, current rewards: -1593.11548, mean: -1.85246
[32m[0907 01-15-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08820, current rewards: -1693.11548, mean: -1.86057
[32m[0907 01-16-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08816, current rewards: -1793.11548, mean: -1.86783
[32m[0907 01-16-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08808, current rewards: -1893.11548, mean: -1.87437
[32m[0907 01-16-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08802, current rewards: -1993.11548, mean: -1.88030
[32m[0907 01-16-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08798, current rewards: -2093.11548, mean: -1.88569
[32m[0907 01-16-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08793, current rewards: -2193.11548, mean: -1.89062
[32m[0907 01-16-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08790, current rewards: -2293.11548, mean: -1.89514
[32m[0907 01-16-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08786, current rewards: -2393.11548, mean: -1.89930
[32m[0907 01-16-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08783, current rewards: -2493.11548, mean: -1.90314
[32m[0907 01-16-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08778, current rewards: -2593.11548, mean: -1.90670
[32m[0907 01-16-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08776, current rewards: -2693.11548, mean: -1.91001
[32m[0907 01-16-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08774, current rewards: -2793.11548, mean: -1.91309
[32m[0907 01-16-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08771, current rewards: -2893.11548, mean: -1.91597
[32m[0907 01-16-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08769, current rewards: -2990.64344, mean: -1.91708
[32m[0907 01-16-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08767, current rewards: -3090.64344, mean: -1.91965
[32m[0907 01-17-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08761, current rewards: -3190.64344, mean: -1.92207
[32m[0907 01-17-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08752, current rewards: -3290.64344, mean: -1.92435
[32m[0907 01-17-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08744, current rewards: -3390.64344, mean: -1.92650
[32m[0907 01-17-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08736, current rewards: -3490.64344, mean: -1.92853
[32m[0907 01-17-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08737, current rewards: -3590.64344, mean: -1.93045
[32m[0907 01-17-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08743, current rewards: -3690.64344, mean: -1.93227
[32m[0907 01-17-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08748, current rewards: -3790.64344, mean: -1.93400
[32m[0907 01-17-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08753, current rewards: -3890.64344, mean: -1.93564
[32m[0907 01-17-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08758, current rewards: -3990.64344, mean: -1.93721
[32m[0907 01-17-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08764, current rewards: -4090.64344, mean: -1.93869
[32m[0907 01-17-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08768, current rewards: -4190.64344, mean: -1.94011
[32m[0907 01-17-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08773, current rewards: -4286.31691, mean: -1.93951
[32m[0907 01-17-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08779, current rewards: -4386.31691, mean: -1.94085
[32m[0907 01-17-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08787, current rewards: -4486.31691, mean: -1.94213
[32m[0907 01-18-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08796, current rewards: -4586.31691, mean: -1.94335
[32m[0907 01-18-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08807, current rewards: -4686.31691, mean: -1.94453
[32m[0907 01-18-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08814, current rewards: -4786.31691, mean: -1.94566
[32m[0907 01-18-16 @Agent.py:117][0m Average action selection time: 0.0882
[32m[0907 01-18-16 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-18-16 @MBExp.py:227][0m Rewards obtained: [-4866.316910503159], Lows: [2436], Highs: [9], Total time: 28717.738182999994
[32m[0907 01-21-43 @MBExp.py:144][0m ####################################################################
[32m[0907 01-21-43 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 01-21-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12302, current rewards: -12.34945, mean: -1.23495
[32m[0907 01-21-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09116, current rewards: -6.47136, mean: -0.10786
[32m[0907 01-21-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08808, current rewards: -1.01344, mean: -0.00921
[32m[0907 01-21-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08688, current rewards: 4.44363, mean: 0.02777
[32m[0907 01-22-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08628, current rewards: 9.90678, mean: 0.04718
[32m[0907 01-22-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08598, current rewards: 15.34876, mean: 0.05903
[32m[0907 01-22-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08617, current rewards: 20.82713, mean: 0.06718
[32m[0907 01-22-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08629, current rewards: 26.30541, mean: 0.07307
[32m[0907 01-22-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08636, current rewards: 31.78488, mean: 0.07752
[32m[0907 01-22-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08673, current rewards: 16.39474, mean: 0.03564
[32m[0907 01-22-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08673, current rewards: 10.27621, mean: 0.02015
[32m[0907 01-22-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08674, current rewards: 4.21320, mean: 0.00752
[32m[0907 01-22-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08676, current rewards: -3.03494, mean: -0.00498
[32m[0907 01-22-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08679, current rewards: -9.54911, mean: -0.01447
[32m[0907 01-22-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08680, current rewards: -15.81126, mean: -0.02227
[32m[0907 01-22-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08681, current rewards: -24.17952, mean: -0.03182
[32m[0907 01-22-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08681, current rewards: -30.25013, mean: -0.03735
[32m[0907 01-22-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08680, current rewards: -36.35569, mean: -0.04227
[32m[0907 01-23-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08680, current rewards: -37.61515, mean: -0.04134
[32m[0907 01-23-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08682, current rewards: -32.12352, mean: -0.03346
[32m[0907 01-23-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08681, current rewards: -26.62952, mean: -0.02637
[32m[0907 01-23-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08682, current rewards: -21.11148, mean: -0.01992
[32m[0907 01-23-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08682, current rewards: -15.61790, mean: -0.01407
[32m[0907 01-23-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08683, current rewards: -10.12353, mean: -0.00873
[32m[0907 01-23-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08685, current rewards: -4.63102, mean: -0.00383
[32m[0907 01-23-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08685, current rewards: 0.85744, mean: 0.00068
[32m[0907 01-23-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08685, current rewards: 6.35254, mean: 0.00485
[32m[0907 01-23-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08684, current rewards: 11.84228, mean: 0.00871
[32m[0907 01-23-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08689, current rewards: 2.47913, mean: 0.00176
[32m[0907 01-23-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08689, current rewards: 7.26347, mean: 0.00497
[32m[0907 01-23-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08690, current rewards: 12.19625, mean: 0.00808
[32m[0907 01-23-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08690, current rewards: 17.13187, mean: 0.01098
[32m[0907 01-24-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08688, current rewards: 22.06709, mean: 0.01371
[32m[0907 01-24-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08683, current rewards: 27.00060, mean: 0.01627
[32m[0907 01-24-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08678, current rewards: 31.93312, mean: 0.01867
[32m[0907 01-24-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08671, current rewards: 30.92437, mean: 0.01757
[32m[0907 01-24-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08668, current rewards: 36.68839, mean: 0.02027
[32m[0907 01-24-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08673, current rewards: 42.46200, mean: 0.02283
[32m[0907 01-24-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08680, current rewards: 48.23854, mean: 0.02526
[32m[0907 01-24-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08689, current rewards: 54.01194, mean: 0.02756
[32m[0907 01-24-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08696, current rewards: 59.78815, mean: 0.02975
[32m[0907 01-24-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08703, current rewards: 65.56234, mean: 0.03183
[32m[0907 01-24-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08709, current rewards: 71.33193, mean: 0.03381
[32m[0907 01-24-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08717, current rewards: 65.26655, mean: 0.03022
[32m[0907 01-24-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08723, current rewards: 69.73325, mean: 0.03155
[32m[0907 01-25-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08728, current rewards: 74.11989, mean: 0.03280
[32m[0907 01-25-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08733, current rewards: 78.59006, mean: 0.03402
[32m[0907 01-25-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08738, current rewards: 83.05940, mean: 0.03519
[32m[0907 01-25-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08742, current rewards: 87.52217, mean: 0.03632
[32m[0907 01-25-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08746, current rewards: 91.99030, mean: 0.03739
[32m[0907 01-25-22 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0907 01-25-22 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-25-22 @MBExp.py:227][0m Rewards obtained: [95.56654952294284], Lows: [56], Highs: [58], Total time: 28937.230655999992
[32m[0907 01-28-49 @MBExp.py:144][0m ####################################################################
[32m[0907 01-28-49 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 01-28-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08629, current rewards: -5.69684, mean: -0.56968
[32m[0907 01-28-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09823, current rewards: -18.16204, mean: -0.30270
[32m[0907 01-29-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09429, current rewards: -29.09391, mean: -0.26449
[32m[0907 01-29-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09667, current rewards: -27.14702, mean: -0.16967
[32m[0907 01-29-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09616, current rewards: -33.08859, mean: -0.15756
[32m[0907 01-29-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09643, current rewards: -59.99912, mean: -0.23077
[32m[0907 01-29-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09701, current rewards: -76.11285, mean: -0.24553
[32m[0907 01-29-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09746, current rewards: -96.37476, mean: -0.26771
[32m[0907 01-29-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09761, current rewards: -117.19152, mean: -0.28583
[32m[0907 01-29-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09736, current rewards: -134.11375, mean: -0.29155
[32m[0907 01-29-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09741, current rewards: -150.37673, mean: -0.29486
[32m[0907 01-29-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09812, current rewards: -158.57452, mean: -0.28317
[32m[0907 01-29-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09762, current rewards: -165.02632, mean: -0.27053
[32m[0907 01-29-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09730, current rewards: -172.39241, mean: -0.26120
[32m[0907 01-29-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09696, current rewards: -194.09747, mean: -0.27338
[32m[0907 01-30-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09698, current rewards: -209.37219, mean: -0.27549
[32m[0907 01-30-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09704, current rewards: -222.62909, mean: -0.27485
[32m[0907 01-30-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09684, current rewards: -225.29430, mean: -0.26197
[32m[0907 01-30-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09630, current rewards: -220.19287, mean: -0.24197
[32m[0907 01-30-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09583, current rewards: -214.76347, mean: -0.22371
[32m[0907 01-30-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09540, current rewards: -209.48481, mean: -0.20741
[32m[0907 01-30-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09501, current rewards: -204.22518, mean: -0.19267
[32m[0907 01-30-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09466, current rewards: -198.95519, mean: -0.17924
[32m[0907 01-30-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09433, current rewards: -193.69667, mean: -0.16698
[32m[0907 01-30-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09403, current rewards: -195.37020, mean: -0.16146
[32m[0907 01-30-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09375, current rewards: -186.84026, mean: -0.14829
[32m[0907 01-30-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09349, current rewards: -179.19635, mean: -0.13679
[32m[0907 01-30-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09325, current rewards: -171.71851, mean: -0.12626
[32m[0907 01-31-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09302, current rewards: -164.05699, mean: -0.11635
[32m[0907 01-31-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09282, current rewards: -156.41875, mean: -0.10714
[32m[0907 01-31-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09255, current rewards: -148.78968, mean: -0.09854
[32m[0907 01-31-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09230, current rewards: -141.15055, mean: -0.09048
[32m[0907 01-31-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09206, current rewards: -133.51673, mean: -0.08293
[32m[0907 01-31-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09183, current rewards: -125.87653, mean: -0.07583
[32m[0907 01-31-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09168, current rewards: -132.30493, mean: -0.07737
[32m[0907 01-31-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09163, current rewards: -190.35204, mean: -0.10815
[32m[0907 01-31-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09163, current rewards: -213.66591, mean: -0.11805
[32m[0907 01-31-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09168, current rewards: -236.69904, mean: -0.12726
[32m[0907 01-31-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09169, current rewards: -258.60073, mean: -0.13539
[32m[0907 01-31-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09166, current rewards: -279.52537, mean: -0.14261
[32m[0907 01-31-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09180, current rewards: -300.91023, mean: -0.14971
[32m[0907 01-31-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09178, current rewards: -295.03983, mean: -0.14322
[32m[0907 01-32-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09173, current rewards: -288.81133, mean: -0.13688
[32m[0907 01-32-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09169, current rewards: -282.59817, mean: -0.13083
[32m[0907 01-32-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09165, current rewards: -276.79923, mean: -0.12525
[32m[0907 01-32-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09161, current rewards: -270.41342, mean: -0.11965
[32m[0907 01-32-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09156, current rewards: -264.02172, mean: -0.11430
[32m[0907 01-32-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09152, current rewards: -257.64469, mean: -0.10917
[32m[0907 01-32-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09148, current rewards: -251.25387, mean: -0.10425
[32m[0907 01-32-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09147, current rewards: -257.63807, mean: -0.10473
[32m[0907 01-32-39 @Agent.py:117][0m Average action selection time: 0.0915
[32m[0907 01-32-39 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-32-39 @MBExp.py:227][0m Rewards obtained: [-258.57079870986183], Lows: [167], Highs: [224], Total time: 29166.63884899999
[32m[0907 01-36-09 @MBExp.py:144][0m ####################################################################
[32m[0907 01-36-09 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 01-36-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08984, current rewards: -14.00000, mean: -1.40000
[32m[0907 01-36-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08559, current rewards: -6.98170, mean: -0.11636
[32m[0907 01-36-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08533, current rewards: 2.17760, mean: 0.01980
[32m[0907 01-36-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08570, current rewards: 11.22378, mean: 0.07015
[32m[0907 01-36-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08595, current rewards: 20.26289, mean: 0.09649
[32m[0907 01-36-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08617, current rewards: 29.26546, mean: 0.11256
[32m[0907 01-36-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08633, current rewards: 38.30444, mean: 0.12356
[32m[0907 01-36-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08644, current rewards: 47.33659, mean: 0.13149
[32m[0907 01-36-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08652, current rewards: 56.35336, mean: 0.13745
[32m[0907 01-36-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08669, current rewards: 44.81054, mean: 0.09741
[32m[0907 01-36-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08666, current rewards: 50.44805, mean: 0.09892
[32m[0907 01-36-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08668, current rewards: 56.12005, mean: 0.10021
[32m[0907 01-37-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08670, current rewards: 61.79341, mean: 0.10130
[32m[0907 01-37-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08674, current rewards: 67.46689, mean: 0.10222
[32m[0907 01-37-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08672, current rewards: 67.47510, mean: 0.09504
[32m[0907 01-37-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08673, current rewards: 74.89636, mean: 0.09855
[32m[0907 01-37-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08675, current rewards: 82.30975, mean: 0.10162
[32m[0907 01-37-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08676, current rewards: 89.71413, mean: 0.10432
[32m[0907 01-37-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08678, current rewards: 97.31168, mean: 0.10694
[32m[0907 01-37-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08678, current rewards: 104.85645, mean: 0.10923
[32m[0907 01-37-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08679, current rewards: 112.25654, mean: 0.11115
[32m[0907 01-37-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08681, current rewards: 119.66057, mean: 0.11289
[32m[0907 01-37-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08682, current rewards: 127.05927, mean: 0.11447
[32m[0907 01-37-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08683, current rewards: 134.45589, mean: 0.11591
[32m[0907 01-37-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08682, current rewards: 131.52786, mean: 0.10870
[32m[0907 01-37-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08682, current rewards: 137.10219, mean: 0.10881
[32m[0907 01-38-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08682, current rewards: 142.66675, mean: 0.10891
[32m[0907 01-38-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08682, current rewards: 147.84629, mean: 0.10871
[32m[0907 01-38-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08682, current rewards: 153.37646, mean: 0.10878
[32m[0907 01-38-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08675, current rewards: 158.91697, mean: 0.10885
[32m[0907 01-38-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08668, current rewards: 138.41163, mean: 0.09166
[32m[0907 01-38-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08667, current rewards: 131.81994, mean: 0.08450
[32m[0907 01-38-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08660, current rewards: 137.55779, mean: 0.08544
[32m[0907 01-38-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08655, current rewards: 143.29121, mean: 0.08632
[32m[0907 01-38-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08657, current rewards: 149.03014, mean: 0.08715
[32m[0907 01-38-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08666, current rewards: 155.64689, mean: 0.08844
[32m[0907 01-38-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08675, current rewards: 161.41474, mean: 0.08918
[32m[0907 01-38-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08683, current rewards: 167.17488, mean: 0.08988
[32m[0907 01-38-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08690, current rewards: 172.94101, mean: 0.09055
[32m[0907 01-39-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08696, current rewards: 166.19683, mean: 0.08479
[32m[0907 01-39-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08703, current rewards: 170.13415, mean: 0.08464
[32m[0907 01-39-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08709, current rewards: 184.97266, mean: 0.08979
[32m[0907 01-39-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08715, current rewards: 199.93295, mean: 0.09475
[32m[0907 01-39-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08720, current rewards: 200.62922, mean: 0.09288
[32m[0907 01-39-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08725, current rewards: 206.21928, mean: 0.09331
[32m[0907 01-39-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08730, current rewards: 211.80349, mean: 0.09372
[32m[0907 01-39-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08734, current rewards: 208.95086, mean: 0.09045
[32m[0907 01-39-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08739, current rewards: 215.53186, mean: 0.09133
[32m[0907 01-39-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08742, current rewards: 224.15845, mean: 0.09301
[32m[0907 01-39-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08746, current rewards: 232.81647, mean: 0.09464
[32m[0907 01-39-48 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0907 01-39-48 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-39-48 @MBExp.py:227][0m Rewards obtained: [239.71897617089076], Lows: [49], Highs: [25], Total time: 29386.14438199999
[32m[0907 01-43-19 @MBExp.py:144][0m ####################################################################
[32m[0907 01-43-19 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 01-43-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08573, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-43-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08554, current rewards: -79.78904, mean: -1.32982
[32m[0907 01-43-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08610, current rewards: -135.66364, mean: -1.23331
[32m[0907 01-43-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08709, current rewards: -189.20740, mean: -1.18255
[32m[0907 01-43-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08764, current rewards: -245.17914, mean: -1.16752
[32m[0907 01-43-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08741, current rewards: -294.09387, mean: -1.13113
[32m[0907 01-43-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08741, current rewards: -344.09387, mean: -1.10998
[32m[0907 01-43-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08737, current rewards: -394.09387, mean: -1.09471
[32m[0907 01-43-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08727, current rewards: -444.09387, mean: -1.08316
[32m[0907 01-43-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08725, current rewards: -494.09387, mean: -1.07412
[32m[0907 01-44-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08724, current rewards: -496.90944, mean: -0.97433
[32m[0907 01-44-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08721, current rewards: -494.52179, mean: -0.88307
[32m[0907 01-44-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08719, current rewards: -492.13413, mean: -0.80678
[32m[0907 01-44-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08719, current rewards: -489.74647, mean: -0.74204
[32m[0907 01-44-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08719, current rewards: -487.35882, mean: -0.68642
[32m[0907 01-44-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08714, current rewards: -484.97116, mean: -0.63812
[32m[0907 01-44-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08712, current rewards: -521.35037, mean: -0.64364
[32m[0907 01-44-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08711, current rewards: -571.35037, mean: -0.66436
[32m[0907 01-44-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08711, current rewards: -621.35037, mean: -0.68280
[32m[0907 01-44-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08711, current rewards: -671.35037, mean: -0.69932
[32m[0907 01-44-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08709, current rewards: -721.35037, mean: -0.71421
[32m[0907 01-44-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08707, current rewards: -771.35037, mean: -0.72769
[32m[0907 01-44-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08705, current rewards: -821.35037, mean: -0.73996
[32m[0907 01-45-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08706, current rewards: -871.35037, mean: -0.75116
[32m[0907 01-45-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08704, current rewards: -921.35037, mean: -0.76145
[32m[0907 01-45-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08702, current rewards: -971.35037, mean: -0.77091
[32m[0907 01-45-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08702, current rewards: -1021.35037, mean: -0.77966
[32m[0907 01-45-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08700, current rewards: -1071.35037, mean: -0.78776
[32m[0907 01-45-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08700, current rewards: -1121.35037, mean: -0.79528
[32m[0907 01-45-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08699, current rewards: -1171.35037, mean: -0.80229
[32m[0907 01-45-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08698, current rewards: -1221.35037, mean: -0.80884
[32m[0907 01-45-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08699, current rewards: -1271.35037, mean: -0.81497
[32m[0907 01-45-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08699, current rewards: -1321.35037, mean: -0.82071
[32m[0907 01-45-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08698, current rewards: -1371.35037, mean: -0.82611
[32m[0907 01-45-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08701, current rewards: -1421.35037, mean: -0.83120
[32m[0907 01-45-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08716, current rewards: -1471.35037, mean: -0.83599
[32m[0907 01-45-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08725, current rewards: -1521.35037, mean: -0.84053
[32m[0907 01-46-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08733, current rewards: -1571.35037, mean: -0.84481
[32m[0907 01-46-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08739, current rewards: -1621.35037, mean: -0.84887
[32m[0907 01-46-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08745, current rewards: -1671.35037, mean: -0.85273
[32m[0907 01-46-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08750, current rewards: -1721.35037, mean: -0.85639
[32m[0907 01-46-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08755, current rewards: -1771.35037, mean: -0.85988
[32m[0907 01-46-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08759, current rewards: -1821.35037, mean: -0.86320
[32m[0907 01-46-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08764, current rewards: -1871.35037, mean: -0.86637
[32m[0907 01-46-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08768, current rewards: -1921.35037, mean: -0.86939
[32m[0907 01-46-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08772, current rewards: -1971.35037, mean: -0.87228
[32m[0907 01-46-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08775, current rewards: -2021.35037, mean: -0.87504
[32m[0907 01-46-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08778, current rewards: -2071.35037, mean: -0.87769
[32m[0907 01-46-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08782, current rewards: -2121.35037, mean: -0.88023
[32m[0907 01-46-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08786, current rewards: -2171.35037, mean: -0.88266
[32m[0907 01-46-59 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0907 01-46-59 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-47-00 @MBExp.py:227][0m Rewards obtained: [-2211.3503707916248], Lows: [52], Highs: [2125], Total time: 29606.61049699999
[32m[0907 01-50-32 @MBExp.py:144][0m ####################################################################
[32m[0907 01-50-32 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 01-50-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08990, current rewards: -8.55772, mean: -0.85577
[32m[0907 01-50-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09027, current rewards: -63.48091, mean: -1.05802
[32m[0907 01-50-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09148, current rewards: -122.49244, mean: -1.11357
[32m[0907 01-50-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09331, current rewards: -173.58241, mean: -1.08489
[32m[0907 01-50-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09171, current rewards: -166.88339, mean: -0.79468
[32m[0907 01-50-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09086, current rewards: -160.14672, mean: -0.61595
[32m[0907 01-51-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09029, current rewards: -153.40398, mean: -0.49485
[32m[0907 01-51-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08983, current rewards: -146.66773, mean: -0.40741
[32m[0907 01-51-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08951, current rewards: -139.93105, mean: -0.34130
[32m[0907 01-51-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08923, current rewards: -132.61145, mean: -0.28829
[32m[0907 01-51-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08905, current rewards: -179.85317, mean: -0.35265
[32m[0907 01-51-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08905, current rewards: -228.25404, mean: -0.40760
[32m[0907 01-51-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08886, current rewards: -254.91938, mean: -0.41790
[32m[0907 01-51-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08890, current rewards: -313.05830, mean: -0.47433
[32m[0907 01-51-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08893, current rewards: -375.55695, mean: -0.52895
[32m[0907 01-51-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08879, current rewards: -456.69876, mean: -0.60092
[32m[0907 01-51-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08866, current rewards: -535.86590, mean: -0.66156
[32m[0907 01-51-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08860, current rewards: -606.04640, mean: -0.70471
[32m[0907 01-51-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08852, current rewards: -667.93627, mean: -0.73400
[32m[0907 01-51-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08844, current rewards: -729.76952, mean: -0.76018
[32m[0907 01-52-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08835, current rewards: -793.86003, mean: -0.78600
[32m[0907 01-52-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08829, current rewards: -855.75646, mean: -0.80732
[32m[0907 01-52-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08823, current rewards: -917.57331, mean: -0.82664
[32m[0907 01-52-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08818, current rewards: -981.66920, mean: -0.84627
[32m[0907 01-52-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08810, current rewards: -1043.58879, mean: -0.86247
[32m[0907 01-52-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08805, current rewards: -1105.38877, mean: -0.87729
[32m[0907 01-52-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08801, current rewards: -1170.50774, mean: -0.89352
[32m[0907 01-52-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08806, current rewards: -1231.12037, mean: -0.90524
[32m[0907 01-52-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08801, current rewards: -1313.95331, mean: -0.93188
[32m[0907 01-52-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08797, current rewards: -1391.87049, mean: -0.95334
[32m[0907 01-52-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08793, current rewards: -1472.58385, mean: -0.97522
[32m[0907 01-52-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08791, current rewards: -1550.28228, mean: -0.99377
[32m[0907 01-52-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08791, current rewards: -1630.14072, mean: -1.01251
[32m[0907 01-52-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08788, current rewards: -1684.24558, mean: -1.01461
[32m[0907 01-53-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08799, current rewards: -1727.57251, mean: -1.01028
[32m[0907 01-53-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08804, current rewards: -1797.32555, mean: -1.02121
[32m[0907 01-53-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08809, current rewards: -1874.39747, mean: -1.03558
[32m[0907 01-53-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08812, current rewards: -1954.11034, mean: -1.05060
[32m[0907 01-53-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08815, current rewards: -2033.75947, mean: -1.06480
[32m[0907 01-53-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08819, current rewards: -2110.95356, mean: -1.07702
[32m[0907 01-53-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08822, current rewards: -2190.66468, mean: -1.08988
[32m[0907 01-53-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08825, current rewards: -2273.02459, mean: -1.10341
[32m[0907 01-53-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08829, current rewards: -2373.02459, mean: -1.12466
[32m[0907 01-53-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08832, current rewards: -2473.02459, mean: -1.14492
[32m[0907 01-53-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08835, current rewards: -2573.02459, mean: -1.16426
[32m[0907 01-53-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08852, current rewards: -2648.73097, mean: -1.17200
[32m[0907 01-53-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08882, current rewards: -2719.55356, mean: -1.17730
[32m[0907 01-54-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08914, current rewards: -2792.42137, mean: -1.18323
[32m[0907 01-54-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08948, current rewards: -2861.78233, mean: -1.18746
[32m[0907 01-54-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08976, current rewards: -2935.56223, mean: -1.19332
[32m[0907 01-54-17 @Agent.py:117][0m Average action selection time: 0.0898
[32m[0907 01-54-17 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-54-18 @MBExp.py:227][0m Rewards obtained: [-3002.1385675715082], Lows: [1593], Highs: [17], Total time: 29831.95287899999
[32m[0907 01-57-52 @MBExp.py:144][0m ####################################################################
[32m[0907 01-57-52 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 01-57-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10580, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-57-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08791, current rewards: -115.00000, mean: -1.91667
[32m[0907 01-58-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08716, current rewards: -215.00000, mean: -1.95455
[32m[0907 01-58-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08704, current rewards: -315.00000, mean: -1.96875
[32m[0907 01-58-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08701, current rewards: -415.00000, mean: -1.97619
[32m[0907 01-58-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08699, current rewards: -515.00000, mean: -1.98077
[32m[0907 01-58-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08698, current rewards: -615.00000, mean: -1.98387
[32m[0907 01-58-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08693, current rewards: -715.00000, mean: -1.98611
[32m[0907 01-58-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08691, current rewards: -794.92095, mean: -1.93883
[32m[0907 01-58-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08690, current rewards: -789.73281, mean: -1.71681
[32m[0907 01-58-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08692, current rewards: -784.25352, mean: -1.53775
[32m[0907 01-58-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08692, current rewards: -778.78096, mean: -1.39068
[32m[0907 01-58-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08691, current rewards: -774.41149, mean: -1.26953
[32m[0907 01-58-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08703, current rewards: -855.46294, mean: -1.29616
[32m[0907 01-58-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08701, current rewards: -912.29897, mean: -1.28493
[32m[0907 01-58-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08702, current rewards: -973.65120, mean: -1.28112
[32m[0907 01-59-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08701, current rewards: -1037.94977, mean: -1.28142
[32m[0907 01-59-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08704, current rewards: -1116.77989, mean: -1.29858
[32m[0907 01-59-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08705, current rewards: -1216.77989, mean: -1.33712
[32m[0907 01-59-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08705, current rewards: -1316.77989, mean: -1.37165
[32m[0907 01-59-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08704, current rewards: -1416.77989, mean: -1.40275
[32m[0907 01-59-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08705, current rewards: -1516.77989, mean: -1.43092
[32m[0907 01-59-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08704, current rewards: -1616.77989, mean: -1.45656
[32m[0907 01-59-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08703, current rewards: -1716.77989, mean: -1.47998
[32m[0907 01-59-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08701, current rewards: -1816.77989, mean: -1.50147
[32m[0907 01-59-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08701, current rewards: -1916.77989, mean: -1.52125
[32m[0907 01-59-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08701, current rewards: -2016.77989, mean: -1.53953
[32m[0907 01-59-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08700, current rewards: -2116.77989, mean: -1.55646
[32m[0907 01-59-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08699, current rewards: -2216.77989, mean: -1.57218
[32m[0907 01-59-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08697, current rewards: -2316.77989, mean: -1.58684
[32m[0907 02-00-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08697, current rewards: -2416.77989, mean: -1.60052
[32m[0907 02-00-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08696, current rewards: -2516.77989, mean: -1.61332
[32m[0907 02-00-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08697, current rewards: -2616.77989, mean: -1.62533
[32m[0907 02-00-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08716, current rewards: -2650.09722, mean: -1.59644
[32m[0907 02-00-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08725, current rewards: -2661.10625, mean: -1.55620
[32m[0907 02-00-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08739, current rewards: -2673.80519, mean: -1.51921
[32m[0907 02-00-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08750, current rewards: -2684.31983, mean: -1.48305
[32m[0907 02-00-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08754, current rewards: -2694.84856, mean: -1.44884
[32m[0907 02-00-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08760, current rewards: -2707.54075, mean: -1.41756
[32m[0907 02-00-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08765, current rewards: -2718.06014, mean: -1.38677
[32m[0907 02-00-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08770, current rewards: -2728.59423, mean: -1.35751
[32m[0907 02-00-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08783, current rewards: -2788.71397, mean: -1.35374
[32m[0907 02-00-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08791, current rewards: -2838.96721, mean: -1.34548
[32m[0907 02-01-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08797, current rewards: -2892.87896, mean: -1.33930
[32m[0907 02-01-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08800, current rewards: -2938.15011, mean: -1.32948
[32m[0907 02-01-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08809, current rewards: -2944.63697, mean: -1.30294
[32m[0907 02-01-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08812, current rewards: -2939.07735, mean: -1.27233
[32m[0907 02-01-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08815, current rewards: -2933.51487, mean: -1.24301
[32m[0907 02-01-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08817, current rewards: -2927.95426, mean: -1.21492
[32m[0907 02-01-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08820, current rewards: -2922.39418, mean: -1.18797
[32m[0907 02-01-33 @Agent.py:117][0m Average action selection time: 0.0882
[32m[0907 02-01-33 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-01-33 @MBExp.py:227][0m Rewards obtained: [-2917.8650448591275], Lows: [1522], Highs: [15], Total time: 30053.28737899999
[32m[0907 02-05-09 @MBExp.py:144][0m ####################################################################
[32m[0907 02-05-09 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 02-05-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08325, current rewards: 1.79133, mean: 0.17913
[32m[0907 02-05-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08516, current rewards: 8.83300, mean: 0.14722
[32m[0907 02-05-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08591, current rewards: 15.14843, mean: 0.13771
[32m[0907 02-05-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08624, current rewards: 21.46385, mean: 0.13415
[32m[0907 02-05-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08630, current rewards: 7.50572, mean: 0.03574
[32m[0907 02-05-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08644, current rewards: -42.49428, mean: -0.16344
[32m[0907 02-05-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08653, current rewards: -92.49428, mean: -0.29837
[32m[0907 02-05-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08662, current rewards: -142.49428, mean: -0.39582
[32m[0907 02-05-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08670, current rewards: -192.49428, mean: -0.46950
[32m[0907 02-05-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08674, current rewards: -242.49428, mean: -0.52716
[32m[0907 02-05-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08679, current rewards: -292.49428, mean: -0.57352
[32m[0907 02-05-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08681, current rewards: -342.49428, mean: -0.61160
[32m[0907 02-06-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08681, current rewards: -392.49428, mean: -0.64343
[32m[0907 02-06-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08682, current rewards: -442.49428, mean: -0.67045
[32m[0907 02-06-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08680, current rewards: -492.49428, mean: -0.69365
[32m[0907 02-06-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08680, current rewards: -542.49428, mean: -0.71381
[32m[0907 02-06-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08680, current rewards: -592.49428, mean: -0.73147
[32m[0907 02-06-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08682, current rewards: -642.49428, mean: -0.74709
[32m[0907 02-06-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08684, current rewards: -692.49428, mean: -0.76098
[32m[0907 02-06-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08686, current rewards: -742.49428, mean: -0.77343
[32m[0907 02-06-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08686, current rewards: -792.49428, mean: -0.78465
[32m[0907 02-06-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08687, current rewards: -842.49428, mean: -0.79481
[32m[0907 02-06-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08686, current rewards: -892.49428, mean: -0.80405
[32m[0907 02-06-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08686, current rewards: -942.49428, mean: -0.81250
[32m[0907 02-06-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08685, current rewards: -992.49428, mean: -0.82024
[32m[0907 02-06-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08686, current rewards: -1042.49428, mean: -0.82738
[32m[0907 02-07-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08686, current rewards: -1092.49428, mean: -0.83397
[32m[0907 02-07-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08688, current rewards: -1142.49428, mean: -0.84007
[32m[0907 02-07-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08689, current rewards: -1192.49428, mean: -0.84574
[32m[0907 02-07-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08688, current rewards: -1242.49428, mean: -0.85102
[32m[0907 02-07-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08689, current rewards: -1292.49428, mean: -0.85596
[32m[0907 02-07-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08689, current rewards: -1342.49428, mean: -0.86057
[32m[0907 02-07-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08694, current rewards: -1392.49428, mean: -0.86490
[32m[0907 02-07-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08702, current rewards: -1442.49428, mean: -0.86897
[32m[0907 02-07-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08714, current rewards: -1492.49428, mean: -0.87280
[32m[0907 02-07-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08729, current rewards: -1542.49428, mean: -0.87642
[32m[0907 02-07-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08737, current rewards: -1592.49428, mean: -0.87983
[32m[0907 02-07-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08743, current rewards: -1642.49428, mean: -0.88306
[32m[0907 02-07-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08749, current rewards: -1692.49428, mean: -0.88612
[32m[0907 02-08-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08754, current rewards: -1742.49428, mean: -0.88903
[32m[0907 02-08-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08758, current rewards: -1792.49428, mean: -0.89179
[32m[0907 02-08-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08763, current rewards: -1842.49428, mean: -0.89441
[32m[0907 02-08-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08767, current rewards: -1892.49428, mean: -0.89692
[32m[0907 02-08-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08771, current rewards: -1942.49428, mean: -0.89930
[32m[0907 02-08-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08775, current rewards: -1992.49428, mean: -0.90158
[32m[0907 02-08-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08779, current rewards: -2042.49428, mean: -0.90376
[32m[0907 02-08-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08783, current rewards: -2092.49428, mean: -0.90584
[32m[0907 02-08-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08786, current rewards: -2142.49428, mean: -0.90784
[32m[0907 02-08-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08790, current rewards: -2192.49428, mean: -0.90975
[32m[0907 02-08-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08793, current rewards: -2242.49428, mean: -0.91158
[32m[0907 02-08-50 @Agent.py:117][0m Average action selection time: 0.0880
[32m[0907 02-08-50 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-08-50 @MBExp.py:227][0m Rewards obtained: [-2282.4942776122903], Lows: [0], Highs: [2308], Total time: 30273.97496499999
[32m[0907 02-12-11 @MBExp.py:144][0m ####################################################################
[32m[0907 02-12-11 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 02-12-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08685, current rewards: -8.56821, mean: -0.85682
[32m[0907 02-12-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.07109, current rewards: -106.23483, mean: -1.77058
[32m[0907 02-12-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.06979, current rewards: -206.23483, mean: -1.87486
[32m[0907 02-12-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.06927, current rewards: -306.23483, mean: -1.91397
[32m[0907 02-12-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.06901, current rewards: -406.23483, mean: -1.93445
[32m[0907 02-12-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.06886, current rewards: -506.23483, mean: -1.94706
[32m[0907 02-12-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.06889, current rewards: -606.23483, mean: -1.95560
[32m[0907 02-12-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.06932, current rewards: -706.23483, mean: -1.96176
[32m[0907 02-12-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.06964, current rewards: -806.23483, mean: -1.96643
[32m[0907 02-12-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.06990, current rewards: -906.23483, mean: -1.97008
[32m[0907 02-12-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.07009, current rewards: -1006.23483, mean: -1.97301
[32m[0907 02-12-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.07025, current rewards: -1106.23483, mean: -1.97542
[32m[0907 02-12-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.07038, current rewards: -1206.23483, mean: -1.97743
[32m[0907 02-12-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.07049, current rewards: -1306.23483, mean: -1.97914
[32m[0907 02-13-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.07058, current rewards: -1406.23483, mean: -1.98061
[32m[0907 02-13-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.07067, current rewards: -1506.23483, mean: -1.98189
[32m[0907 02-13-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.07076, current rewards: -1606.23483, mean: -1.98301
[32m[0907 02-13-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.07082, current rewards: -1706.23483, mean: -1.98399
[32m[0907 02-13-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.07087, current rewards: -1806.23483, mean: -1.98487
[32m[0907 02-13-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.07091, current rewards: -1906.23483, mean: -1.98566
[32m[0907 02-13-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.07095, current rewards: -2006.23483, mean: -1.98637
[32m[0907 02-13-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.07099, current rewards: -2106.23483, mean: -1.98701
[32m[0907 02-13-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.07102, current rewards: -2206.23483, mean: -1.98760
[32m[0907 02-13-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.07105, current rewards: -2306.23483, mean: -1.98813
[32m[0907 02-13-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.07108, current rewards: -2406.23483, mean: -1.98862
[32m[0907 02-13-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.07110, current rewards: -2506.23483, mean: -1.98908
[32m[0907 02-13-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.07112, current rewards: -2606.23483, mean: -1.98949
[32m[0907 02-13-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.07115, current rewards: -2706.23483, mean: -1.98988
[32m[0907 02-13-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.07118, current rewards: -2806.23483, mean: -1.99024
[32m[0907 02-13-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.07121, current rewards: -2906.23483, mean: -1.99057
[32m[0907 02-13-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.07123, current rewards: -3006.23483, mean: -1.99088
[32m[0907 02-14-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.07126, current rewards: -3106.23483, mean: -1.99118
[32m[0907 02-14-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.07128, current rewards: -3206.23483, mean: -1.99145
[32m[0907 02-14-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.07129, current rewards: -3306.23483, mean: -1.99171
[32m[0907 02-14-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.07131, current rewards: -3406.23483, mean: -1.99195
[32m[0907 02-14-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.07133, current rewards: -3506.23483, mean: -1.99218
[32m[0907 02-14-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.07118, current rewards: -3606.23483, mean: -1.99239
[32m[0907 02-14-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.07091, current rewards: -3706.23483, mean: -1.99260
[32m[0907 02-14-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.07067, current rewards: -3806.23483, mean: -1.99279
[32m[0907 02-14-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.07044, current rewards: -3906.23483, mean: -1.99298
[32m[0907 02-14-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.07023, current rewards: -4006.23483, mean: -1.99315
[32m[0907 02-14-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.07002, current rewards: -4106.23483, mean: -1.99332
[32m[0907 02-14-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.06984, current rewards: -4206.23483, mean: -1.99348
[32m[0907 02-14-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.06965, current rewards: -4306.23483, mean: -1.99363
[32m[0907 02-14-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.06946, current rewards: -4406.23483, mean: -1.99377
[32m[0907 02-14-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.06928, current rewards: -4506.23483, mean: -1.99391
[32m[0907 02-14-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.06913, current rewards: -4606.23483, mean: -1.99404
[32m[0907 02-14-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.06896, current rewards: -4706.23483, mean: -1.99417
[32m[0907 02-14-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.06880, current rewards: -4806.23483, mean: -1.99429
[32m[0907 02-15-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.06865, current rewards: -4906.23483, mean: -1.99440
[32m[0907 02-15-03 @Agent.py:117][0m Average action selection time: 0.0685
[32m[0907 02-15-03 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-15-03 @MBExp.py:227][0m Rewards obtained: [-4986.234831880781], Lows: [2491], Highs: [5], Total time: 30445.966802999992
