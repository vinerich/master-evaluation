[32m[0906 13-40-11 @logger.py:99][0m Log file set to /app/logs/dats-delay-5/zinc-coating-v0_2/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-11 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -5.12990, mean: -0.51299
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -76.51632, mean: -1.27527
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -140.56387, mean: -1.27785
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -199.61825, mean: -1.24761
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -269.54896, mean: -1.28357
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -335.57898, mean: -1.29069
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -399.66132, mean: -1.28923
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -466.77317, mean: -1.29659
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -523.80969, mean: -1.27758
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -584.27522, mean: -1.27016
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -670.54977, mean: -1.31480
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -735.92411, mean: -1.31415
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -789.10314, mean: -1.29361
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -842.80620, mean: -1.27698
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -897.88993, mean: -1.26463
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -952.61193, mean: -1.25344
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -1004.33054, mean: -1.23991
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1059.48342, mean: -1.23196
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1113.81175, mean: -1.22397
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1160.36699, mean: -1.20872
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1215.16297, mean: -1.20313
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1277.82060, mean: -1.20549
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1330.81579, mean: -1.19893
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1389.89504, mean: -1.19819
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1456.01504, mean: -1.20332
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1518.38567, mean: -1.20507
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1578.58877, mean: -1.20503
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1645.07126, mean: -1.20961
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1718.62979, mean: -1.21889
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1786.04453, mean: -1.22332
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1857.08659, mean: -1.22986
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1914.24299, mean: -1.22708
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1990.42836, mean: -1.23629
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -2045.80486, mean: -1.23241
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2093.34050, mean: -1.22418
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2151.39722, mean: -1.22238
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2212.60600, mean: -1.22243
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2268.95513, mean: -1.21987
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2336.51779, mean: -1.22331
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2394.88258, mean: -1.22188
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2445.72035, mean: -1.21678
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2496.04925, mean: -1.21167
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2553.77724, mean: -1.21032
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2601.00426, mean: -1.20417
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2654.11244, mean: -1.20096
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2711.54821, mean: -1.19980
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2766.23708, mean: -1.19751
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2813.86110, mean: -1.19231
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2864.83681, mean: -1.18873
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2915.34088, mean: -1.18510
[32m[0906 13-40-11 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-40-13 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-13 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09988, current rewards: -5.57325, mean: -0.55732
[32m[0906 13-40-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08828, current rewards: -43.69428, mean: -0.72824
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08715, current rewards: -84.55936, mean: -0.76872
[32m[0906 13-40-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08699, current rewards: -125.41306, mean: -0.78383
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08698, current rewards: -166.19638, mean: -0.79141
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08815, current rewards: -211.58377, mean: -0.81378
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08987, current rewards: -256.94654, mean: -0.82886
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09113, current rewards: -302.32200, mean: -0.83978
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09217, current rewards: -343.15234, mean: -0.83696
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09288, current rewards: -433.94667, mean: -0.94336
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09351, current rewards: -533.94667, mean: -1.04695
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09399, current rewards: -554.62426, mean: -0.99040
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09443, current rewards: -536.32107, mean: -0.87921
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09481, current rewards: -518.03024, mean: -0.78489
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09532, current rewards: -499.75464, mean: -0.70388
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09587, current rewards: -481.43144, mean: -0.63346
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09688, current rewards: -463.11178, mean: -0.57174
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09788, current rewards: -448.88464, mean: -0.52196
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09871, current rewards: -442.58907, mean: -0.48636
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09948, current rewards: -460.30231, mean: -0.47948
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10018, current rewards: -501.09245, mean: -0.49613
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10079, current rewards: -541.90283, mean: -0.51123
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10137, current rewards: -584.96717, mean: -0.52700
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10188, current rewards: -630.30748, mean: -0.54337
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10234, current rewards: -675.65252, mean: -0.55839
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10280, current rewards: -710.42436, mean: -0.56383
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10320, current rewards: -700.70604, mean: -0.53489
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10358, current rewards: -690.96654, mean: -0.50806
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10394, current rewards: -681.25909, mean: -0.48316
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10425, current rewards: -671.53433, mean: -0.45996
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10454, current rewards: -661.81319, mean: -0.43829
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10484, current rewards: -652.10162, mean: -0.41801
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10499, current rewards: -642.36037, mean: -0.39898
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10522, current rewards: -632.62491, mean: -0.38110
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10545, current rewards: -650.49072, mean: -0.38040
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10564, current rewards: -695.44141, mean: -0.39514
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10585, current rewards: -738.14639, mean: -0.40782
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10605, current rewards: -778.49931, mean: -0.41855
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10622, current rewards: -818.84854, mean: -0.42872
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10641, current rewards: -868.58748, mean: -0.44316
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10657, current rewards: -901.54414, mean: -0.44853
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10670, current rewards: -937.12032, mean: -0.45491
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10688, current rewards: -993.11727, mean: -0.47067
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10703, current rewards: -1093.11727, mean: -0.50607
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10715, current rewards: -1193.11727, mean: -0.53987
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10730, current rewards: -1289.11727, mean: -0.57041
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10737, current rewards: -1279.48528, mean: -0.55389
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10749, current rewards: -1257.01831, mean: -0.53263
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10761, current rewards: -1234.50740, mean: -0.51224
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10771, current rewards: -1211.94329, mean: -0.49266
[32m[0906 13-44-43 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 13-44-43 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-44-44 @MBExp.py:227][0m Rewards obtained: [-1193.9196118695406], Lows: [841], Highs: [18], Total time: 270.217184
[32m[0906 13-44-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-48 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11263, current rewards: -5.66639, mean: -0.56664
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11149, current rewards: -2.35840, mean: -0.03931
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11165, current rewards: 0.92270, mean: 0.00839
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11170, current rewards: 4.20432, mean: 0.02628
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11166, current rewards: 7.48676, mean: 0.03565
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11120, current rewards: 10.76895, mean: 0.04142
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11118, current rewards: 14.05382, mean: 0.04533
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11128, current rewards: 17.33408, mean: 0.04815
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11134, current rewards: 15.28272, mean: 0.03727
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11138, current rewards: 19.74221, mean: 0.04292
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11135, current rewards: 24.48878, mean: 0.04802
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11146, current rewards: 29.23008, mean: 0.05220
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11149, current rewards: 33.96908, mean: 0.05569
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11151, current rewards: 38.71123, mean: 0.05865
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11155, current rewards: 43.03574, mean: 0.06061
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11143, current rewards: 46.47885, mean: 0.06116
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11138, current rewards: 49.92429, mean: 0.06163
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11141, current rewards: 53.55258, mean: 0.06227
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11141, current rewards: 57.47121, mean: 0.06316
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11143, current rewards: 61.38887, mean: 0.06395
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11148, current rewards: 65.30191, mean: 0.06466
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11150, current rewards: 69.21672, mean: 0.06530
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11152, current rewards: 73.13524, mean: 0.06589
[32m[0906 13-46-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11153, current rewards: 64.86758, mean: 0.05592
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11152, current rewards: 70.55810, mean: 0.05831
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11152, current rewards: 76.22590, mean: 0.06050
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11153, current rewards: 83.21542, mean: 0.06352
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11152, current rewards: 89.91476, mean: 0.06611
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11157, current rewards: 96.61039, mean: 0.06852
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11162, current rewards: 103.30610, mean: 0.07076
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11168, current rewards: 109.99901, mean: 0.07285
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11166, current rewards: 110.29032, mean: 0.07070
[32m[0906 13-47-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11154, current rewards: 113.07081, mean: 0.07023
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11152, current rewards: 122.24428, mean: 0.07364
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11154, current rewards: 127.24384, mean: 0.07441
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11153, current rewards: 131.32154, mean: 0.07461
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11152, current rewards: 135.40219, mean: 0.07481
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11152, current rewards: 139.48165, mean: 0.07499
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11152, current rewards: 143.55934, mean: 0.07516
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11153, current rewards: 147.63864, mean: 0.07533
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11154, current rewards: 151.71782, mean: 0.07548
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11154, current rewards: 155.79613, mean: 0.07563
[32m[0906 13-48-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11157, current rewards: 160.20644, mean: 0.07593
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11158, current rewards: 165.26465, mean: 0.07651
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11159, current rewards: 170.24220, mean: 0.07703
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11161, current rewards: 168.61586, mean: 0.07461
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11155, current rewards: 173.07611, mean: 0.07492
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11156, current rewards: 177.51434, mean: 0.07522
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11160, current rewards: 181.95514, mean: 0.07550
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11162, current rewards: 186.39899, mean: 0.07577
[32m[0906 13-49-28 @Agent.py:117][0m Average action selection time: 0.1116
[32m[0906 13-49-28 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-49-28 @MBExp.py:227][0m Rewards obtained: [189.95070111037964], Lows: [12], Highs: [17], Total time: 549.974625
[32m[0906 13-49-36 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-36 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11304, current rewards: -4.96284, mean: -0.49628
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11194, current rewards: 3.15213, mean: 0.05254
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11212, current rewards: 11.55710, mean: 0.10506
[32m[0906 13-49-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11194, current rewards: 19.95553, mean: 0.12472
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11152, current rewards: 28.34367, mean: 0.13497
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11108, current rewards: 36.74176, mean: 0.14131
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11111, current rewards: 45.14081, mean: 0.14562
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11118, current rewards: 53.54438, mean: 0.14873
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11130, current rewards: 61.94121, mean: 0.15108
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11129, current rewards: 23.06821, mean: 0.05015
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11130, current rewards: -9.95994, mean: -0.01953
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11139, current rewards: -42.95137, mean: -0.07670
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11139, current rewards: -75.91864, mean: -0.12446
[32m[0906 13-50-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11139, current rewards: -114.07545, mean: -0.17284
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11145, current rewards: -152.32590, mean: -0.21454
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11120, current rewards: -190.40618, mean: -0.25053
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11115, current rewards: -223.37967, mean: -0.27578
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11121, current rewards: -245.38697, mean: -0.28533
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11122, current rewards: -287.40780, mean: -0.31583
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11125, current rewards: -331.18175, mean: -0.34498
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11130, current rewards: -374.85264, mean: -0.37114
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11132, current rewards: -416.26408, mean: -0.39270
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11138, current rewards: -455.28620, mean: -0.41017
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11138, current rewards: -494.37466, mean: -0.42619
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11137, current rewards: -535.80815, mean: -0.44282
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11143, current rewards: -579.50597, mean: -0.45993
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11145, current rewards: -647.85672, mean: -0.49455
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11146, current rewards: -698.16111, mean: -0.51335
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11149, current rewards: -735.80317, mean: -0.52185
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11149, current rewards: -721.40469, mean: -0.49411
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11151, current rewards: -707.00321, mean: -0.46821
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11150, current rewards: -692.62230, mean: -0.44399
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11140, current rewards: -678.22569, mean: -0.42126
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11137, current rewards: -663.80566, mean: -0.39988
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11141, current rewards: -665.74313, mean: -0.38932
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11142, current rewards: -656.50498, mean: -0.37301
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11143, current rewards: -647.21013, mean: -0.35757
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11145, current rewards: -637.91111, mean: -0.34296
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11144, current rewards: -628.61687, mean: -0.32912
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11146, current rewards: -619.30932, mean: -0.31597
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11146, current rewards: -610.01734, mean: -0.30349
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11146, current rewards: -600.71510, mean: -0.29161
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11147, current rewards: -590.97344, mean: -0.28008
[32m[0906 13-53-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11146, current rewards: -578.56907, mean: -0.26786
[32m[0906 13-53-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11147, current rewards: -567.26165, mean: -0.25668
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11145, current rewards: -555.95184, mean: -0.24600
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11138, current rewards: -544.62743, mean: -0.23577
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11135, current rewards: -542.30412, mean: -0.22979
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11137, current rewards: -531.38110, mean: -0.22049
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11139, current rewards: -520.45762, mean: -0.21157
[32m[0906 13-54-15 @Agent.py:117][0m Average action selection time: 0.1114
[32m[0906 13-54-15 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-54-15 @MBExp.py:227][0m Rewards obtained: [-511.7495174503452], Lows: [520], Highs: [12], Total time: 829.1377699999999
[32m[0906 13-54-24 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-24 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11172, current rewards: -4.80706, mean: -0.48071
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11146, current rewards: 1.00735, mean: 0.01679
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11190, current rewards: 6.38513, mean: 0.05805
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11176, current rewards: 11.75967, mean: 0.07350
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11085, current rewards: 17.13439, mean: 0.08159
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11057, current rewards: 22.50880, mean: 0.08657
[32m[0906 13-54-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11069, current rewards: 27.88394, mean: 0.08995
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11084, current rewards: 33.26019, mean: 0.09239
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11098, current rewards: 38.63545, mean: 0.09423
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11099, current rewards: 43.52592, mean: 0.09462
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11105, current rewards: 48.46085, mean: 0.09502
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11112, current rewards: 49.02854, mean: 0.08755
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11118, current rewards: 53.52929, mean: 0.08775
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11120, current rewards: 57.99372, mean: 0.08787
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11109, current rewards: 62.45791, mean: 0.08797
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11085, current rewards: 66.92172, mean: 0.08805
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11089, current rewards: 71.38858, mean: 0.08813
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11093, current rewards: 72.36974, mean: 0.08415
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11095, current rewards: 71.61230, mean: 0.07869
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11098, current rewards: 77.01100, mean: 0.08022
[32m[0906 13-56-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11100, current rewards: 82.41168, mean: 0.08160
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11103, current rewards: 87.80530, mean: 0.08284
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11107, current rewards: 83.28964, mean: 0.07504
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11110, current rewards: 89.47418, mean: 0.07713
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11111, current rewards: 95.65646, mean: 0.07905
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11115, current rewards: 101.69419, mean: 0.08071
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11118, current rewards: 106.78598, mean: 0.08152
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11119, current rewards: 112.12813, mean: 0.08245
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11121, current rewards: 117.47241, mean: 0.08331
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11122, current rewards: 122.81199, mean: 0.08412
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11123, current rewards: 113.31907, mean: 0.07505
[32m[0906 13-57-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11120, current rewards: 118.69320, mean: 0.07609
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11111, current rewards: 124.06628, mean: 0.07706
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11107, current rewards: 129.43706, mean: 0.07797
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11110, current rewards: 135.05947, mean: 0.07898
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11112, current rewards: 140.62840, mean: 0.07990
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11114, current rewards: 146.19675, mean: 0.08077
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11115, current rewards: 151.76088, mean: 0.08159
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11117, current rewards: 157.33696, mean: 0.08238
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11119, current rewards: 162.90308, mean: 0.08311
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11118, current rewards: 167.55691, mean: 0.08336
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11118, current rewards: 171.61097, mean: 0.08331
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11120, current rewards: 175.17195, mean: 0.08302
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11120, current rewards: 178.66139, mean: 0.08271
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11123, current rewards: 182.15011, mean: 0.08242
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11127, current rewards: 185.63700, mean: 0.08214
[32m[0906 13-58-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11122, current rewards: 189.12411, mean: 0.08187
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11119, current rewards: 192.61238, mean: 0.08162
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11125, current rewards: 196.10384, mean: 0.08137
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11126, current rewards: 199.59060, mean: 0.08113
[32m[0906 13-59-03 @Agent.py:117][0m Average action selection time: 0.1113
[32m[0906 13-59-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 13-59-03 @MBExp.py:227][0m Rewards obtained: [202.6444616583124], Lows: [14], Highs: [17], Total time: 1108.0358339999998
[32m[0906 13-59-15 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-15 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11272, current rewards: -11.92903, mean: -1.19290
[32m[0906 13-59-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11223, current rewards: -12.13919, mean: -0.20232
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11211, current rewards: -8.43850, mean: -0.07671
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11153, current rewards: -4.73898, mean: -0.02962
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11093, current rewards: -1.03755, mean: -0.00494
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11060, current rewards: 2.66191, mean: 0.01024
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11081, current rewards: 6.36249, mean: 0.02052
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11099, current rewards: 10.06006, mean: 0.02794
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11106, current rewards: 2.01621, mean: 0.00492
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11106, current rewards: 9.39079, mean: 0.02041
[32m[0906 14-00-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11115, current rewards: 15.06786, mean: 0.02954
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11114, current rewards: 20.74492, mean: 0.03704
[32m[0906 14-00-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11119, current rewards: 26.42199, mean: 0.04331
[32m[0906 14-00-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11127, current rewards: 32.09906, mean: 0.04863
[32m[0906 14-00-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11104, current rewards: 37.77612, mean: 0.05321
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11085, current rewards: 43.45319, mean: 0.05718
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11084, current rewards: 49.13025, mean: 0.06065
[32m[0906 14-00-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11086, current rewards: 54.80732, mean: 0.06373
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11092, current rewards: 48.23543, mean: 0.05301
[32m[0906 14-01-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11094, current rewards: -1.76457, mean: -0.00184
[32m[0906 14-01-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11096, current rewards: -51.76457, mean: -0.05125
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11101, current rewards: -101.76457, mean: -0.09600
[32m[0906 14-01-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11102, current rewards: -151.76457, mean: -0.13672
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11102, current rewards: -201.76457, mean: -0.17393
[32m[0906 14-01-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11105, current rewards: -251.76457, mean: -0.20807
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11106, current rewards: -301.76457, mean: -0.23950
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11104, current rewards: -351.76457, mean: -0.26852
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11107, current rewards: -401.76457, mean: -0.29542
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11111, current rewards: -451.76457, mean: -0.32040
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11111, current rewards: -501.76457, mean: -0.34367
[32m[0906 14-02-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11113, current rewards: -551.76457, mean: -0.36541
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11108, current rewards: -601.76457, mean: -0.38575
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11098, current rewards: -651.76457, mean: -0.40482
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11090, current rewards: -701.76457, mean: -0.42275
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11090, current rewards: -751.76457, mean: -0.43963
[32m[0906 14-02-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11094, current rewards: -801.76457, mean: -0.45555
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11097, current rewards: -851.76457, mean: -0.47059
[32m[0906 14-02-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11099, current rewards: -901.76457, mean: -0.48482
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11102, current rewards: -951.76457, mean: -0.49831
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11104, current rewards: -1001.76457, mean: -0.51110
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11106, current rewards: -1051.76457, mean: -0.52327
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11108, current rewards: -1101.76457, mean: -0.53484
[32m[0906 14-03-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11110, current rewards: -1151.76457, mean: -0.54586
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11111, current rewards: -1201.76457, mean: -0.55637
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11113, current rewards: -1251.76457, mean: -0.56641
[32m[0906 14-03-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11110, current rewards: -1301.76457, mean: -0.57600
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11104, current rewards: -1351.76457, mean: -0.58518
[32m[0906 14-03-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11097, current rewards: -1401.76457, mean: -0.59397
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11097, current rewards: -1451.76457, mean: -0.60239
[32m[0906 14-03-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11098, current rewards: -1501.76457, mean: -0.61047
[32m[0906 14-03-53 @Agent.py:117][0m Average action selection time: 0.1110
[32m[0906 14-03-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-03-53 @MBExp.py:227][0m Rewards obtained: [-1541.7645681004985], Lows: [11], Highs: [1607], Total time: 1386.2294009999998
[32m[0906 14-04-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-07 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11199, current rewards: -7.85724, mean: -0.78572
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11157, current rewards: -3.83576, mean: -0.06393
[32m[0906 14-04-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11165, current rewards: 0.45876, mean: 0.00417
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.11077, current rewards: 4.75235, mean: 0.02970
[32m[0906 14-04-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.11013, current rewards: 9.04533, mean: 0.04307
[32m[0906 14-04-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.11003, current rewards: 13.33904, mean: 0.05130
[32m[0906 14-04-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.11041, current rewards: 17.63138, mean: 0.05688
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11058, current rewards: 21.92200, mean: 0.06089
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11074, current rewards: 26.21478, mean: 0.06394
[32m[0906 14-04-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11090, current rewards: 30.79213, mean: 0.06694
[32m[0906 14-05-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11101, current rewards: 35.28891, mean: 0.06919
[32m[0906 14-05-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11113, current rewards: 39.79035, mean: 0.07105
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11123, current rewards: 44.28936, mean: 0.07261
[32m[0906 14-05-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11114, current rewards: 48.78800, mean: 0.07392
[32m[0906 14-05-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11097, current rewards: 53.28464, mean: 0.07505
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11080, current rewards: 46.85924, mean: 0.06166
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11082, current rewards: 50.21148, mean: 0.06199
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11091, current rewards: 53.89188, mean: 0.06266
[32m[0906 14-05-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11096, current rewards: 57.64891, mean: 0.06335
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11101, current rewards: 61.33120, mean: 0.06389
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11108, current rewards: 65.01184, mean: 0.06437
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11110, current rewards: 68.69402, mean: 0.06481
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11113, current rewards: 72.37629, mean: 0.06520
[32m[0906 14-06-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11116, current rewards: 76.05658, mean: 0.06557
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11117, current rewards: 79.73811, mean: 0.06590
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11118, current rewards: 78.77807, mean: 0.06252
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11122, current rewards: 82.09319, mean: 0.06267
[32m[0906 14-06-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11122, current rewards: 85.54743, mean: 0.06290
[32m[0906 14-06-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11123, current rewards: 88.99983, mean: 0.06312
[32m[0906 14-06-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11125, current rewards: 92.45372, mean: 0.06332
[32m[0906 14-06-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11125, current rewards: 85.31800, mean: 0.05650
[32m[0906 14-07-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11121, current rewards: 88.43111, mean: 0.05669
[32m[0906 14-07-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11112, current rewards: 91.54240, mean: 0.05686
[32m[0906 14-07-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11104, current rewards: 94.65503, mean: 0.05702
[32m[0906 14-07-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11100, current rewards: 98.07235, mean: 0.05735
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11103, current rewards: 101.34037, mean: 0.05758
[32m[0906 14-07-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11105, current rewards: 104.60709, mean: 0.05779
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11111, current rewards: 107.87387, mean: 0.05800
[32m[0906 14-07-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11111, current rewards: 111.14157, mean: 0.05819
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11110, current rewards: 110.14720, mean: 0.05620
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11112, current rewards: 109.97655, mean: 0.05471
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11112, current rewards: 113.60521, mean: 0.05515
[32m[0906 14-08-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11114, current rewards: 117.37493, mean: 0.05563
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11122, current rewards: 121.03989, mean: 0.05604
[32m[0906 14-08-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11128, current rewards: 124.70261, mean: 0.05643
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11132, current rewards: 128.36867, mean: 0.05680
[32m[0906 14-08-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11128, current rewards: 132.03214, mean: 0.05716
[32m[0906 14-08-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11122, current rewards: 135.69620, mean: 0.05750
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11118, current rewards: 139.36001, mean: 0.05783
[32m[0906 14-08-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11120, current rewards: 124.22784, mean: 0.05050
[32m[0906 14-08-46 @Agent.py:117][0m Average action selection time: 0.1112
[32m[0906 14-08-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-08-46 @MBExp.py:227][0m Rewards obtained: [129.06405050296084], Lows: [22], Highs: [18], Total time: 1664.9492939999998
[32m[0906 14-09-03 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-03 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11330, current rewards: 1.25937, mean: 0.12594
[32m[0906 14-09-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11246, current rewards: 7.95296, mean: 0.13255
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11097, current rewards: 14.58345, mean: 0.13258
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10981, current rewards: 21.21458, mean: 0.13259
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10944, current rewards: 27.84211, mean: 0.13258
[32m[0906 14-09-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10946, current rewards: 34.47023, mean: 0.13258
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10977, current rewards: 41.10384, mean: 0.13259
[32m[0906 14-09-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.11012, current rewards: 30.13814, mean: 0.08372
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.11033, current rewards: 34.52910, mean: 0.08422
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11045, current rewards: 39.03333, mean: 0.08486
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11057, current rewards: 43.43785, mean: 0.08517
[32m[0906 14-10-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11063, current rewards: 47.83762, mean: 0.08542
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11071, current rewards: 42.51659, mean: 0.06970
[32m[0906 14-10-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11053, current rewards: 47.25797, mean: 0.07160
[32m[0906 14-10-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11033, current rewards: 52.00372, mean: 0.07324
[32m[0906 14-10-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.11012, current rewards: 56.74576, mean: 0.07467
[32m[0906 14-10-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.11017, current rewards: 56.90967, mean: 0.07026
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.11020, current rewards: 61.55680, mean: 0.07158
[32m[0906 14-10-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11027, current rewards: 66.26973, mean: 0.07282
[32m[0906 14-10-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11039, current rewards: 71.01120, mean: 0.07397
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11043, current rewards: 75.75912, mean: 0.07501
[32m[0906 14-11-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11050, current rewards: 80.49775, mean: 0.07594
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11053, current rewards: 85.23918, mean: 0.07679
[32m[0906 14-11-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11056, current rewards: 89.97832, mean: 0.07757
[32m[0906 14-11-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11059, current rewards: 94.71983, mean: 0.07828
[32m[0906 14-11-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11063, current rewards: 99.46125, mean: 0.07894
[32m[0906 14-11-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11065, current rewards: 104.64681, mean: 0.07988
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11070, current rewards: 109.55384, mean: 0.08055
[32m[0906 14-11-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11072, current rewards: 103.85725, mean: 0.07366
[32m[0906 14-11-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11073, current rewards: 108.62254, mean: 0.07440
[32m[0906 14-11-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11075, current rewards: 113.39097, mean: 0.07509
[32m[0906 14-11-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11069, current rewards: 118.15851, mean: 0.07574
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11060, current rewards: 122.92325, mean: 0.07635
[32m[0906 14-12-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11052, current rewards: 127.69080, mean: 0.07692
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11044, current rewards: 132.91813, mean: 0.07773
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11047, current rewards: 137.82936, mean: 0.07831
[32m[0906 14-12-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11052, current rewards: 142.74056, mean: 0.07886
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11054, current rewards: 147.64783, mean: 0.07938
[32m[0906 14-12-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11057, current rewards: 149.07947, mean: 0.07805
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11059, current rewards: 153.72020, mean: 0.07843
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11061, current rewards: 158.35917, mean: 0.07879
[32m[0906 14-12-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11063, current rewards: 162.99690, mean: 0.07912
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11064, current rewards: 167.38244, mean: 0.07933
[32m[0906 14-13-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11066, current rewards: 171.75526, mean: 0.07952
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11069, current rewards: 176.13532, mean: 0.07970
[32m[0906 14-13-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11066, current rewards: 180.51148, mean: 0.07987
[32m[0906 14-13-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11060, current rewards: 184.88631, mean: 0.08004
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11055, current rewards: 189.26232, mean: 0.08020
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11050, current rewards: 193.64056, mean: 0.08035
[32m[0906 14-13-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11052, current rewards: 187.95582, mean: 0.07640
[32m[0906 14-13-40 @Agent.py:117][0m Average action selection time: 0.1105
[32m[0906 14-13-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-13-40 @MBExp.py:227][0m Rewards obtained: [191.7829235861264], Lows: [20], Highs: [16], Total time: 1941.9975329999997
[32m[0906 14-13-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-58 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11248, current rewards: -5.59145, mean: -0.55915
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.11176, current rewards: 0.52909, mean: 0.00882
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.11025, current rewards: 6.66235, mean: 0.06057
[32m[0906 14-14-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10950, current rewards: 12.79703, mean: 0.07998
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10903, current rewards: 18.93561, mean: 0.09017
[32m[0906 14-14-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10924, current rewards: 25.07920, mean: 0.09646
[32m[0906 14-14-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10956, current rewards: 31.22183, mean: 0.10072
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10978, current rewards: 37.35386, mean: 0.10376
[32m[0906 14-14-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10999, current rewards: 33.55870, mean: 0.08185
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11016, current rewards: 40.54440, mean: 0.08814
[32m[0906 14-14-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11024, current rewards: 47.53646, mean: 0.09321
[32m[0906 14-15-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11034, current rewards: 54.52884, mean: 0.09737
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11031, current rewards: 61.52069, mean: 0.10085
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11006, current rewards: 68.51007, mean: 0.10380
[32m[0906 14-15-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10993, current rewards: 75.50096, mean: 0.10634
[32m[0906 14-15-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10976, current rewards: 82.49313, mean: 0.10854
[32m[0906 14-15-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10982, current rewards: 90.29305, mean: 0.11147
[32m[0906 14-15-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10994, current rewards: 88.22208, mean: 0.10258
[32m[0906 14-15-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.11002, current rewards: 94.91662, mean: 0.10430
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11007, current rewards: 101.52485, mean: 0.10576
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11017, current rewards: 108.13309, mean: 0.10706
[32m[0906 14-15-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11021, current rewards: 114.74132, mean: 0.10825
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11028, current rewards: 121.34956, mean: 0.10932
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11032, current rewards: 127.95779, mean: 0.11031
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11035, current rewards: 83.61861, mean: 0.06911
[32m[0906 14-16-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11040, current rewards: 56.96433, mean: 0.04521
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11043, current rewards: 64.30785, mean: 0.04909
[32m[0906 14-16-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11046, current rewards: 71.65355, mean: 0.05269
[32m[0906 14-16-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11051, current rewards: 78.98192, mean: 0.05602
[32m[0906 14-16-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11053, current rewards: 81.59368, mean: 0.05589
[32m[0906 14-16-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11056, current rewards: 88.08371, mean: 0.05833
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11053, current rewards: 94.57947, mean: 0.06063
[32m[0906 14-16-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11044, current rewards: 101.07653, mean: 0.06278
[32m[0906 14-17-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11035, current rewards: 107.48740, mean: 0.06475
[32m[0906 14-17-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11028, current rewards: 114.20348, mean: 0.06679
[32m[0906 14-17-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11027, current rewards: 104.39746, mean: 0.05932
[32m[0906 14-17-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11028, current rewards: 110.55961, mean: 0.06108
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11033, current rewards: 116.76493, mean: 0.06278
[32m[0906 14-17-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11038, current rewards: 122.96773, mean: 0.06438
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11042, current rewards: 129.17901, mean: 0.06591
[32m[0906 14-17-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11045, current rewards: 135.38925, mean: 0.06736
[32m[0906 14-17-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11046, current rewards: 141.83595, mean: 0.06885
[32m[0906 14-17-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11048, current rewards: 147.71543, mean: 0.07001
[32m[0906 14-17-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11051, current rewards: 153.58616, mean: 0.07110
[32m[0906 14-18-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11053, current rewards: 150.55492, mean: 0.06812
[32m[0906 14-18-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11053, current rewards: 157.85655, mean: 0.06985
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11047, current rewards: 165.15615, mean: 0.07150
[32m[0906 14-18-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11041, current rewards: 172.45278, mean: 0.07307
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11036, current rewards: 178.72878, mean: 0.07416
[32m[0906 14-18-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11037, current rewards: 184.76744, mean: 0.07511
[32m[0906 14-18-35 @Agent.py:117][0m Average action selection time: 0.1104
[32m[0906 14-18-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-18-35 @MBExp.py:227][0m Rewards obtained: [191.13698559724622], Lows: [20], Highs: [91], Total time: 2218.6351859999995
[32m[0906 14-18-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-56 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-18-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11168, current rewards: -7.83829, mean: -0.78383
[32m[0906 14-19-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10991, current rewards: -1.50134, mean: -0.02502
[32m[0906 14-19-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10892, current rewards: 4.93692, mean: 0.04488
[32m[0906 14-19-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10880, current rewards: 11.37653, mean: 0.07110
[32m[0906 14-19-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10859, current rewards: 17.81841, mean: 0.08485
[32m[0906 14-19-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10870, current rewards: 24.25873, mean: 0.09330
[32m[0906 14-19-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10921, current rewards: 30.69498, mean: 0.09902
[32m[0906 14-19-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10948, current rewards: 37.11909, mean: 0.10311
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10971, current rewards: 43.79415, mean: 0.10682
[32m[0906 14-19-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10992, current rewards: 50.21083, mean: 0.10915
[32m[0906 14-19-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11001, current rewards: 56.63359, mean: 0.11105
[32m[0906 14-19-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11012, current rewards: 63.06530, mean: 0.11262
[32m[0906 14-20-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10999, current rewards: 69.48187, mean: 0.11390
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10980, current rewards: 70.26280, mean: 0.10646
[32m[0906 14-20-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10965, current rewards: 76.81872, mean: 0.10820
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10955, current rewards: 83.36837, mean: 0.10970
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10965, current rewards: 90.30346, mean: 0.11149
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10978, current rewards: 96.92093, mean: 0.11270
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10988, current rewards: 103.54327, mean: 0.11378
[32m[0906 14-20-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10995, current rewards: 110.15855, mean: 0.11475
[32m[0906 14-20-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11002, current rewards: 116.77113, mean: 0.11561
[32m[0906 14-20-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11005, current rewards: 123.40200, mean: 0.11642
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11010, current rewards: 119.21561, mean: 0.10740
[32m[0906 14-21-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11017, current rewards: 125.70428, mean: 0.10837
[32m[0906 14-21-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11020, current rewards: 131.87976, mean: 0.10899
[32m[0906 14-21-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11026, current rewards: 138.26586, mean: 0.10973
[32m[0906 14-21-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11029, current rewards: 144.65072, mean: 0.11042
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11033, current rewards: 151.03827, mean: 0.11106
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11036, current rewards: 157.42197, mean: 0.11165
[32m[0906 14-21-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11042, current rewards: 158.21361, mean: 0.10837
[32m[0906 14-21-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11046, current rewards: 164.60734, mean: 0.10901
[32m[0906 14-21-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11040, current rewards: 170.99110, mean: 0.10961
[32m[0906 14-21-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11032, current rewards: 177.13450, mean: 0.11002
[32m[0906 14-22-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11026, current rewards: 183.42850, mean: 0.11050
[32m[0906 14-22-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11018, current rewards: 189.71855, mean: 0.11095
[32m[0906 14-22-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11015, current rewards: 196.00857, mean: 0.11137
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11019, current rewards: 202.30160, mean: 0.11177
[32m[0906 14-22-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11022, current rewards: 208.59257, mean: 0.11215
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11026, current rewards: 214.88425, mean: 0.11250
[32m[0906 14-22-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11029, current rewards: 221.17140, mean: 0.11284
[32m[0906 14-22-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11032, current rewards: 227.64363, mean: 0.11326
[32m[0906 14-22-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11036, current rewards: 233.98725, mean: 0.11359
[32m[0906 14-22-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11038, current rewards: 240.33470, mean: 0.11390
[32m[0906 14-22-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11041, current rewards: 235.61513, mean: 0.10908
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11044, current rewards: 240.53873, mean: 0.10884
[32m[0906 14-23-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11041, current rewards: 245.46468, mean: 0.10861
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11035, current rewards: 250.39268, mean: 0.10840
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11030, current rewards: 255.32144, mean: 0.10819
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11026, current rewards: 260.82150, mean: 0.10822
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11023, current rewards: 266.23176, mean: 0.10822
[32m[0906 14-23-33 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-23-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-23-33 @MBExp.py:227][0m Rewards obtained: [270.54285611319], Lows: [10], Highs: [18], Total time: 2494.9377279999994
[32m[0906 14-23-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-56 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11159, current rewards: -4.83599, mean: -0.48360
[32m[0906 14-24-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10959, current rewards: 0.86887, mean: 0.01448
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10881, current rewards: 6.49209, mean: 0.05902
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10874, current rewards: 12.11633, mean: 0.07573
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10865, current rewards: 17.73919, mean: 0.08447
[32m[0906 14-24-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10889, current rewards: 23.36145, mean: 0.08985
[32m[0906 14-24-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10946, current rewards: 28.98322, mean: 0.09349
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10975, current rewards: 34.61303, mean: 0.09615
[32m[0906 14-24-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10987, current rewards: 40.23849, mean: 0.09814
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11015, current rewards: 45.86858, mean: 0.09971
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11025, current rewards: 39.34583, mean: 0.07715
[32m[0906 14-24-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11030, current rewards: 45.68502, mean: 0.08158
[32m[0906 14-25-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11014, current rewards: 52.03004, mean: 0.08530
[32m[0906 14-25-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10993, current rewards: 58.36982, mean: 0.08844
[32m[0906 14-25-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10976, current rewards: 64.71096, mean: 0.09114
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10967, current rewards: 71.05481, mean: 0.09349
[32m[0906 14-25-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10976, current rewards: 77.39947, mean: 0.09555
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10986, current rewards: 83.74071, mean: 0.09737
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10997, current rewards: 90.08206, mean: 0.09899
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.11003, current rewards: 96.42525, mean: 0.10044
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11011, current rewards: 99.38389, mean: 0.09840
[32m[0906 14-25-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11018, current rewards: 102.21808, mean: 0.09643
[32m[0906 14-25-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11021, current rewards: 107.37325, mean: 0.09673
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11024, current rewards: 115.87628, mean: 0.09989
[32m[0906 14-26-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11029, current rewards: 124.22229, mean: 0.10266
[32m[0906 14-26-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11032, current rewards: 132.56136, mean: 0.10521
[32m[0906 14-26-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11039, current rewards: 140.89794, mean: 0.10756
[32m[0906 14-26-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11041, current rewards: 140.58203, mean: 0.10337
[32m[0906 14-26-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11042, current rewards: 148.52041, mean: 0.10533
[32m[0906 14-26-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11046, current rewards: 156.45991, mean: 0.10716
[32m[0906 14-26-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11049, current rewards: 164.38568, mean: 0.10886
[32m[0906 14-26-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11042, current rewards: 172.32692, mean: 0.11047
[32m[0906 14-26-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11035, current rewards: 180.25369, mean: 0.11196
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11026, current rewards: 176.93022, mean: 0.10658
[32m[0906 14-27-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11018, current rewards: 184.18263, mean: 0.10771
[32m[0906 14-27-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11013, current rewards: 191.43282, mean: 0.10877
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11016, current rewards: 198.67667, mean: 0.10977
[32m[0906 14-27-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11018, current rewards: 205.92474, mean: 0.11071
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11023, current rewards: 213.16715, mean: 0.11161
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11029, current rewards: 219.34413, mean: 0.11191
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11031, current rewards: 225.70427, mean: 0.11229
[32m[0906 14-27-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11035, current rewards: 227.77205, mean: 0.11057
[32m[0906 14-27-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11038, current rewards: 231.83948, mean: 0.10988
[32m[0906 14-27-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11039, current rewards: 238.20433, mean: 0.11028
[32m[0906 14-28-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11043, current rewards: 244.57176, mean: 0.11067
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11040, current rewards: 250.93929, mean: 0.11104
[32m[0906 14-28-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11034, current rewards: 257.30591, mean: 0.11139
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11031, current rewards: 263.67545, mean: 0.11173
[32m[0906 14-28-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11025, current rewards: 270.04017, mean: 0.11205
[32m[0906 14-28-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11021, current rewards: 276.40724, mean: 0.11236
[32m[0906 14-28-32 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-28-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-28-32 @MBExp.py:227][0m Rewards obtained: [281.49405766285236], Lows: [11], Highs: [24], Total time: 2771.2175149999994
[32m[0906 14-28-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-28-58 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-28-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10731, current rewards: -5.71786, mean: -0.57179
[32m[0906 14-29-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10804, current rewards: -0.34498, mean: -0.00575
[32m[0906 14-29-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10786, current rewards: 5.36845, mean: 0.04880
[32m[0906 14-29-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10788, current rewards: 11.07571, mean: 0.06922
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10784, current rewards: 16.79147, mean: 0.07996
[32m[0906 14-29-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10824, current rewards: 22.49685, mean: 0.08653
[32m[0906 14-29-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10885, current rewards: 27.96087, mean: 0.09020
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10918, current rewards: 33.63340, mean: 0.09343
[32m[0906 14-29-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10950, current rewards: 39.15641, mean: 0.09550
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10975, current rewards: 45.02507, mean: 0.09788
[32m[0906 14-29-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10986, current rewards: 50.88352, mean: 0.09977
[32m[0906 14-30-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10975, current rewards: 56.75634, mean: 0.10135
[32m[0906 14-30-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10960, current rewards: 62.61966, mean: 0.10266
[32m[0906 14-30-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10941, current rewards: 68.48682, mean: 0.10377
[32m[0906 14-30-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10926, current rewards: 74.72075, mean: 0.10524
[32m[0906 14-30-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10918, current rewards: 80.58836, mean: 0.10604
[32m[0906 14-30-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10930, current rewards: 86.46974, mean: 0.10675
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10938, current rewards: 92.35057, mean: 0.10738
[32m[0906 14-30-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10953, current rewards: 97.77665, mean: 0.10745
[32m[0906 14-30-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10963, current rewards: 103.34492, mean: 0.10765
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10972, current rewards: 108.90854, mean: 0.10783
[32m[0906 14-30-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10984, current rewards: 114.47547, mean: 0.10800
[32m[0906 14-31-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10989, current rewards: 120.14075, mean: 0.10823
[32m[0906 14-31-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10996, current rewards: 126.16610, mean: 0.10876
[32m[0906 14-31-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11004, current rewards: 131.44951, mean: 0.10864
[32m[0906 14-31-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11008, current rewards: 126.93230, mean: 0.10074
[32m[0906 14-31-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11012, current rewards: 132.24679, mean: 0.10095
[32m[0906 14-31-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11016, current rewards: 137.54402, mean: 0.10114
[32m[0906 14-31-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11018, current rewards: 142.84222, mean: 0.10131
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11024, current rewards: 148.14157, mean: 0.10147
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11027, current rewards: 153.44501, mean: 0.10162
[32m[0906 14-31-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11019, current rewards: 148.83025, mean: 0.09540
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11014, current rewards: 156.29044, mean: 0.09707
[32m[0906 14-32-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11006, current rewards: 163.75063, mean: 0.09864
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10998, current rewards: 171.21082, mean: 0.10012
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10992, current rewards: 148.79171, mean: 0.08454
[32m[0906 14-32-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10992, current rewards: 98.79171, mean: 0.05458
[32m[0906 14-32-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10995, current rewards: 48.79171, mean: 0.02623
[32m[0906 14-32-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11000, current rewards: -1.20829, mean: -0.00063
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11002, current rewards: -51.20829, mean: -0.02613
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11005, current rewards: -101.20829, mean: -0.05035
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11009, current rewards: -151.20829, mean: -0.07340
[32m[0906 14-32-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11011, current rewards: -201.20829, mean: -0.09536
[32m[0906 14-32-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11013, current rewards: -251.20829, mean: -0.11630
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11017, current rewards: -301.20829, mean: -0.13629
[32m[0906 14-33-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11013, current rewards: -351.20829, mean: -0.15540
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11007, current rewards: -370.13146, mean: -0.16023
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11004, current rewards: -366.02086, mean: -0.15509
[32m[0906 14-33-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10998, current rewards: -359.97560, mean: -0.14937
[32m[0906 14-33-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10993, current rewards: -353.93033, mean: -0.14387
[32m[0906 14-33-34 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 14-33-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-33-34 @MBExp.py:227][0m Rewards obtained: [-386.083994445786], Lows: [11], Highs: [586], Total time: 3046.7293819999995
[32m[0906 14-34-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-02 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10769, current rewards: 0.71795, mean: 0.07179
[32m[0906 14-34-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10788, current rewards: 6.69708, mean: 0.11162
[32m[0906 14-34-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10781, current rewards: 12.81857, mean: 0.11653
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10797, current rewards: 18.93950, mean: 0.11837
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10802, current rewards: 25.06134, mean: 0.11934
[32m[0906 14-34-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10839, current rewards: 31.18021, mean: 0.11992
[32m[0906 14-34-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10900, current rewards: 37.15984, mean: 0.11987
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10936, current rewards: 43.28947, mean: 0.12025
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10970, current rewards: 49.41719, mean: 0.12053
[32m[0906 14-34-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10999, current rewards: 55.54424, mean: 0.12075
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.11013, current rewards: 61.67460, mean: 0.12093
[32m[0906 14-35-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10995, current rewards: 67.80769, mean: 0.12109
[32m[0906 14-35-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10984, current rewards: 73.94172, mean: 0.12122
[32m[0906 14-35-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10969, current rewards: 80.07262, mean: 0.12132
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10954, current rewards: 86.19700, mean: 0.12140
[32m[0906 14-35-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10947, current rewards: 92.32530, mean: 0.12148
[32m[0906 14-35-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10959, current rewards: 98.45724, mean: 0.12155
[32m[0906 14-35-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10971, current rewards: 98.77228, mean: 0.11485
[32m[0906 14-35-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10983, current rewards: 103.63828, mean: 0.11389
[32m[0906 14-35-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10993, current rewards: 108.50593, mean: 0.11303
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11005, current rewards: 113.37297, mean: 0.11225
[32m[0906 14-35-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11011, current rewards: 118.24378, mean: 0.11155
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11016, current rewards: 123.36742, mean: 0.11114
[32m[0906 14-36-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11024, current rewards: 128.18354, mean: 0.11050
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11029, current rewards: 127.77929, mean: 0.10560
[32m[0906 14-36-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11035, current rewards: 132.90988, mean: 0.10548
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11042, current rewards: 138.04030, mean: 0.10537
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11044, current rewards: 143.17417, mean: 0.10528
[32m[0906 14-36-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11048, current rewards: 148.30991, mean: 0.10518
[32m[0906 14-36-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11055, current rewards: 153.44039, mean: 0.10510
[32m[0906 14-36-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11058, current rewards: 158.24333, mean: 0.10480
[32m[0906 14-36-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11051, current rewards: 163.26878, mean: 0.10466
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11046, current rewards: 168.29087, mean: 0.10453
[32m[0906 14-37-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11039, current rewards: 173.31727, mean: 0.10441
[32m[0906 14-37-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11033, current rewards: 178.34729, mean: 0.10430
[32m[0906 14-37-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11028, current rewards: 183.37399, mean: 0.10419
[32m[0906 14-37-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11023, current rewards: 188.40045, mean: 0.10409
[32m[0906 14-37-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11027, current rewards: 193.41959, mean: 0.10399
[32m[0906 14-37-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11035, current rewards: 199.22828, mean: 0.10431
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11039, current rewards: 204.97972, mean: 0.10458
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11043, current rewards: 204.94782, mean: 0.10196
[32m[0906 14-37-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11047, current rewards: 210.41883, mean: 0.10215
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11050, current rewards: 215.88482, mean: 0.10232
[32m[0906 14-38-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11054, current rewards: 221.35247, mean: 0.10248
[32m[0906 14-38-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11055, current rewards: 226.82693, mean: 0.10264
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11051, current rewards: 232.29782, mean: 0.10279
[32m[0906 14-38-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11047, current rewards: 237.76484, mean: 0.10293
[32m[0906 14-38-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11042, current rewards: 232.68777, mean: 0.09860
[32m[0906 14-38-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11038, current rewards: 238.89518, mean: 0.09913
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11035, current rewards: 245.20566, mean: 0.09968
[32m[0906 14-38-38 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-38-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-38-38 @MBExp.py:227][0m Rewards obtained: [250.2538748440537], Lows: [5], Highs: [15], Total time: 3323.2002939999993
[32m[0906 14-39-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-08 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-39-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10871, current rewards: -6.64022, mean: -0.66402
[32m[0906 14-39-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10808, current rewards: -1.33495, mean: -0.02225
[32m[0906 14-39-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10823, current rewards: 4.25806, mean: 0.03871
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10811, current rewards: 9.85348, mean: 0.06158
[32m[0906 14-39-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10813, current rewards: 15.45444, mean: 0.07359
[32m[0906 14-39-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10865, current rewards: 21.71601, mean: 0.08352
[32m[0906 14-39-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10919, current rewards: 27.25517, mean: 0.08792
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10957, current rewards: 32.79325, mean: 0.09109
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10990, current rewards: 38.32995, mean: 0.09349
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.11007, current rewards: 43.86364, mean: 0.09536
[32m[0906 14-40-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10998, current rewards: 49.40030, mean: 0.09686
[32m[0906 14-40-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10988, current rewards: 44.80481, mean: 0.08001
[32m[0906 14-40-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10973, current rewards: 50.89687, mean: 0.08344
[32m[0906 14-40-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10962, current rewards: 56.69054, mean: 0.08589
[32m[0906 14-40-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10955, current rewards: 61.76154, mean: 0.08699
[32m[0906 14-40-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10944, current rewards: 67.17084, mean: 0.08838
[32m[0906 14-40-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10958, current rewards: 72.58198, mean: 0.08961
[32m[0906 14-40-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10975, current rewards: 77.99242, mean: 0.09069
[32m[0906 14-40-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10986, current rewards: 83.40804, mean: 0.09166
[32m[0906 14-40-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10998, current rewards: 88.82239, mean: 0.09252
[32m[0906 14-41-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11010, current rewards: 94.23321, mean: 0.09330
[32m[0906 14-41-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11018, current rewards: 99.64445, mean: 0.09400
[32m[0906 14-41-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11028, current rewards: 105.05618, mean: 0.09465
[32m[0906 14-41-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11036, current rewards: 110.47390, mean: 0.09524
[32m[0906 14-41-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11045, current rewards: 115.88582, mean: 0.09577
[32m[0906 14-41-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11057, current rewards: 116.07197, mean: 0.09212
[32m[0906 14-41-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11060, current rewards: 121.71779, mean: 0.09291
[32m[0906 14-41-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11063, current rewards: 127.36611, mean: 0.09365
[32m[0906 14-41-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11068, current rewards: 133.00435, mean: 0.09433
[32m[0906 14-41-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11071, current rewards: 138.65326, mean: 0.09497
[32m[0906 14-41-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11074, current rewards: 144.08566, mean: 0.09542
[32m[0906 14-42-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11069, current rewards: 149.63084, mean: 0.09592
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11060, current rewards: 155.18098, mean: 0.09639
[32m[0906 14-42-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11053, current rewards: 160.72953, mean: 0.09683
[32m[0906 14-42-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11046, current rewards: 166.04745, mean: 0.09710
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11041, current rewards: 171.11232, mean: 0.09722
[32m[0906 14-42-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11033, current rewards: 176.10862, mean: 0.09730
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11036, current rewards: 181.11245, mean: 0.09737
[32m[0906 14-42-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11040, current rewards: 186.72429, mean: 0.09776
[32m[0906 14-42-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11043, current rewards: 191.69121, mean: 0.09780
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11047, current rewards: 196.65453, mean: 0.09784
[32m[0906 14-42-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11050, current rewards: 201.61437, mean: 0.09787
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11053, current rewards: 206.79696, mean: 0.09801
[32m[0906 14-43-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11057, current rewards: 212.27632, mean: 0.09828
[32m[0906 14-43-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11059, current rewards: 217.75671, mean: 0.09853
[32m[0906 14-43-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11056, current rewards: 223.24125, mean: 0.09878
[32m[0906 14-43-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11051, current rewards: 228.80703, mean: 0.09905
[32m[0906 14-43-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11046, current rewards: 222.70246, mean: 0.09437
[32m[0906 14-43-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11042, current rewards: 228.63244, mean: 0.09487
[32m[0906 14-43-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11037, current rewards: 234.56213, mean: 0.09535
[32m[0906 14-43-45 @Agent.py:117][0m Average action selection time: 0.1103
[32m[0906 14-43-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-43-45 @MBExp.py:227][0m Rewards obtained: [239.3056041493901], Lows: [11], Highs: [12], Total time: 3599.7259519999993
[32m[0906 14-44-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-18 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10820, current rewards: -4.58765, mean: -0.45876
[32m[0906 14-44-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10824, current rewards: 0.64855, mean: 0.01081
[32m[0906 14-44-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10818, current rewards: 6.11173, mean: 0.05556
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10795, current rewards: 11.57277, mean: 0.07233
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10804, current rewards: 17.02658, mean: 0.08108
[32m[0906 14-44-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10855, current rewards: 22.48710, mean: 0.08649
[32m[0906 14-44-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10905, current rewards: 27.94800, mean: 0.09015
[32m[0906 14-44-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10941, current rewards: 33.41193, mean: 0.09281
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10962, current rewards: 38.87455, mean: 0.09482
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10977, current rewards: 33.27508, mean: 0.07234
[32m[0906 14-45-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10964, current rewards: 37.63727, mean: 0.07380
[32m[0906 14-45-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10949, current rewards: 41.99863, mean: 0.07500
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10934, current rewards: 46.36107, mean: 0.07600
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10927, current rewards: 50.69424, mean: 0.07681
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10916, current rewards: 55.22626, mean: 0.07778
[32m[0906 14-45-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10907, current rewards: 59.76330, mean: 0.07864
[32m[0906 14-45-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10925, current rewards: 64.29689, mean: 0.07938
[32m[0906 14-45-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10939, current rewards: 68.83413, mean: 0.08004
[32m[0906 14-45-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10951, current rewards: 73.36937, mean: 0.08063
[32m[0906 14-46-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10962, current rewards: 77.90425, mean: 0.08115
[32m[0906 14-46-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10970, current rewards: 82.43728, mean: 0.08162
[32m[0906 14-46-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10984, current rewards: 88.10499, mean: 0.08312
[32m[0906 14-46-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10992, current rewards: 95.03165, mean: 0.08561
[32m[0906 14-46-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11000, current rewards: 101.95831, mean: 0.08790
[32m[0906 14-46-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11009, current rewards: 95.22257, mean: 0.07870
[32m[0906 14-46-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11015, current rewards: 84.78503, mean: 0.06729
[32m[0906 14-46-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11021, current rewards: 89.78257, mean: 0.06854
[32m[0906 14-46-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11028, current rewards: 94.77794, mean: 0.06969
[32m[0906 14-46-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11032, current rewards: 99.77656, mean: 0.07076
[32m[0906 14-46-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11036, current rewards: 104.77277, mean: 0.07176
[32m[0906 14-47-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11041, current rewards: 109.60545, mean: 0.07259
[32m[0906 14-47-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11036, current rewards: 109.23985, mean: 0.07003
[32m[0906 14-47-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11029, current rewards: 113.94867, mean: 0.07078
[32m[0906 14-47-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11024, current rewards: 118.66076, mean: 0.07148
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11018, current rewards: 123.37041, mean: 0.07215
[32m[0906 14-47-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11015, current rewards: 117.61877, mean: 0.06683
[32m[0906 14-47-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11013, current rewards: 123.38420, mean: 0.06817
[32m[0906 14-47-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11011, current rewards: 129.17511, mean: 0.06945
[32m[0906 14-47-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11015, current rewards: 135.20100, mean: 0.07079
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11018, current rewards: 140.98038, mean: 0.07193
[32m[0906 14-48-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11022, current rewards: 146.76042, mean: 0.07302
[32m[0906 14-48-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11026, current rewards: 152.53748, mean: 0.07405
[32m[0906 14-48-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11029, current rewards: 158.31962, mean: 0.07503
[32m[0906 14-48-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11031, current rewards: 153.52270, mean: 0.07108
[32m[0906 14-48-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11036, current rewards: 159.11362, mean: 0.07200
[32m[0906 14-48-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11031, current rewards: 164.70627, mean: 0.07288
[32m[0906 14-48-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11027, current rewards: 170.29986, mean: 0.07372
[32m[0906 14-48-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11022, current rewards: 170.54741, mean: 0.07227
[32m[0906 14-48-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11016, current rewards: 175.23892, mean: 0.07271
[32m[0906 14-48-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11012, current rewards: 179.93486, mean: 0.07314
[32m[0906 14-48-53 @Agent.py:117][0m Average action selection time: 0.1101
[32m[0906 14-48-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-48-53 @MBExp.py:227][0m Rewards obtained: [183.68761430308624], Lows: [15], Highs: [41], Total time: 3875.6741659999993
[32m[0906 14-49-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-28 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-49-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10813, current rewards: -4.32418, mean: -0.43242
[32m[0906 14-49-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10826, current rewards: 1.59349, mean: 0.02656
[32m[0906 14-49-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10834, current rewards: 7.53503, mean: 0.06850
[32m[0906 14-49-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10827, current rewards: 13.48309, mean: 0.08427
[32m[0906 14-49-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10814, current rewards: 19.73125, mean: 0.09396
[32m[0906 14-49-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10877, current rewards: 25.64281, mean: 0.09863
[32m[0906 14-50-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10925, current rewards: 31.55218, mean: 0.10178
[32m[0906 14-50-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10949, current rewards: 37.45900, mean: 0.10405
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10982, current rewards: 43.36435, mean: 0.10577
[32m[0906 14-50-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10983, current rewards: 49.27246, mean: 0.10711
[32m[0906 14-50-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10965, current rewards: 49.68873, mean: 0.09743
[32m[0906 14-50-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10959, current rewards: 55.24308, mean: 0.09865
[32m[0906 14-50-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10947, current rewards: 60.47049, mean: 0.09913
[32m[0906 14-50-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10939, current rewards: 65.77970, mean: 0.09967
[32m[0906 14-50-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10934, current rewards: 71.08279, mean: 0.10012
[32m[0906 14-50-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10928, current rewards: 76.38678, mean: 0.10051
[32m[0906 14-50-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10945, current rewards: 81.69232, mean: 0.10085
[32m[0906 14-51-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10968, current rewards: 86.99319, mean: 0.10115
[32m[0906 14-51-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10982, current rewards: 85.98036, mean: 0.09448
[32m[0906 14-51-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10993, current rewards: 87.04914, mean: 0.09068
[32m[0906 14-51-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.11013, current rewards: 92.25687, mean: 0.09134
[32m[0906 14-51-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11027, current rewards: 97.55008, mean: 0.09203
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11042, current rewards: 102.84627, mean: 0.09265
[32m[0906 14-51-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11054, current rewards: 108.14289, mean: 0.09323
[32m[0906 14-51-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11063, current rewards: 113.43813, mean: 0.09375
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11076, current rewards: 118.73513, mean: 0.09423
[32m[0906 14-51-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11083, current rewards: 124.02703, mean: 0.09468
[32m[0906 14-51-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11089, current rewards: 129.32253, mean: 0.09509
[32m[0906 14-52-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11097, current rewards: 134.45632, mean: 0.09536
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11101, current rewards: 139.72681, mean: 0.09570
[32m[0906 14-52-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11103, current rewards: 145.13660, mean: 0.09612
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11097, current rewards: 140.00345, mean: 0.08975
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11087, current rewards: 146.39347, mean: 0.09093
[32m[0906 14-52-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11079, current rewards: 152.84821, mean: 0.09208
[32m[0906 14-52-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11073, current rewards: 159.30429, mean: 0.09316
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11065, current rewards: 165.75335, mean: 0.09418
[32m[0906 14-52-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11059, current rewards: 172.20219, mean: 0.09514
[32m[0906 14-52-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11055, current rewards: 178.88168, mean: 0.09617
[32m[0906 14-53-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11060, current rewards: 185.29210, mean: 0.09701
[32m[0906 14-53-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11065, current rewards: 191.70384, mean: 0.09781
[32m[0906 14-53-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11070, current rewards: 198.11226, mean: 0.09856
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11074, current rewards: 204.52540, mean: 0.09928
[32m[0906 14-53-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11078, current rewards: 210.94550, mean: 0.09997
[32m[0906 14-53-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11081, current rewards: 217.36254, mean: 0.10063
[32m[0906 14-53-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11084, current rewards: 223.77599, mean: 0.10126
[32m[0906 14-53-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11080, current rewards: 230.18775, mean: 0.10185
[32m[0906 14-53-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11074, current rewards: 236.59953, mean: 0.10242
[32m[0906 14-53-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11069, current rewards: 232.49870, mean: 0.09852
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11065, current rewards: 240.11666, mean: 0.09963
[32m[0906 14-54-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11060, current rewards: 248.78251, mean: 0.10113
[32m[0906 14-54-05 @Agent.py:117][0m Average action selection time: 0.1106
[32m[0906 14-54-05 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-54-05 @MBExp.py:227][0m Rewards obtained: [255.7099858260013], Lows: [16], Highs: [10], Total time: 4152.764577999999
[32m[0906 14-54-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-42 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-54-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10887, current rewards: -4.02387, mean: -0.40239
[32m[0906 14-54-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10833, current rewards: 1.05890, mean: 0.01765
[32m[0906 14-54-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10819, current rewards: 5.93538, mean: 0.05396
[32m[0906 14-55-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10834, current rewards: 10.97824, mean: 0.06861
[32m[0906 14-55-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10827, current rewards: 15.80336, mean: 0.07525
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10878, current rewards: 20.63253, mean: 0.07936
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10931, current rewards: 25.46095, mean: 0.08213
[32m[0906 14-55-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10968, current rewards: 30.28812, mean: 0.08413
[32m[0906 14-55-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10994, current rewards: 25.10271, mean: 0.06123
[32m[0906 14-55-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10986, current rewards: 30.62925, mean: 0.06659
[32m[0906 14-55-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10968, current rewards: 36.16064, mean: 0.07090
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10951, current rewards: 41.51186, mean: 0.07413
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10942, current rewards: 47.05463, mean: 0.07714
[32m[0906 14-55-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10936, current rewards: 52.59016, mean: 0.07968
[32m[0906 14-56-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10927, current rewards: 47.53334, mean: 0.06695
[32m[0906 14-56-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10921, current rewards: 52.97798, mean: 0.06971
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10938, current rewards: 58.41180, mean: 0.07211
[32m[0906 14-56-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10955, current rewards: 63.84189, mean: 0.07423
[32m[0906 14-56-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10973, current rewards: 69.27811, mean: 0.07613
[32m[0906 14-56-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10984, current rewards: 75.30957, mean: 0.07845
[32m[0906 14-56-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10995, current rewards: 80.85899, mean: 0.08006
[32m[0906 14-56-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11003, current rewards: 81.02559, mean: 0.07644
[32m[0906 14-56-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11011, current rewards: 86.36623, mean: 0.07781
[32m[0906 14-56-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11021, current rewards: 91.70630, mean: 0.07906
[32m[0906 14-56-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11027, current rewards: 97.04469, mean: 0.08020
[32m[0906 14-57-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11034, current rewards: 102.39060, mean: 0.08126
[32m[0906 14-57-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11039, current rewards: 107.73101, mean: 0.08224
[32m[0906 14-57-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11042, current rewards: 113.04703, mean: 0.08312
[32m[0906 14-57-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11048, current rewards: 118.28579, mean: 0.08389
[32m[0906 14-57-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11055, current rewards: 123.60163, mean: 0.08466
[32m[0906 14-57-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11062, current rewards: 118.58062, mean: 0.07853
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11055, current rewards: 124.05225, mean: 0.07952
[32m[0906 14-57-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11049, current rewards: 129.52103, mean: 0.08045
[32m[0906 14-57-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11041, current rewards: 134.98880, mean: 0.08132
[32m[0906 14-57-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11035, current rewards: 140.46060, mean: 0.08214
[32m[0906 14-57-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11030, current rewards: 133.58788, mean: 0.07590
[32m[0906 14-58-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11024, current rewards: 138.67344, mean: 0.07662
[32m[0906 14-58-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11018, current rewards: 144.08935, mean: 0.07747
[32m[0906 14-58-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.11020, current rewards: 149.50259, mean: 0.07827
[32m[0906 14-58-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11025, current rewards: 154.91840, mean: 0.07904
[32m[0906 14-58-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11031, current rewards: 160.33201, mean: 0.07977
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11036, current rewards: 165.74915, mean: 0.08046
[32m[0906 14-58-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11040, current rewards: 171.16617, mean: 0.08112
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11044, current rewards: 176.58429, mean: 0.08175
[32m[0906 14-58-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11046, current rewards: 181.86013, mean: 0.08229
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11042, current rewards: 181.78161, mean: 0.08043
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11039, current rewards: 187.26601, mean: 0.08107
[32m[0906 14-59-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11034, current rewards: 192.72856, mean: 0.08166
[32m[0906 14-59-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11029, current rewards: 198.19775, mean: 0.08224
[32m[0906 14-59-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11025, current rewards: 203.66324, mean: 0.08279
[32m[0906 14-59-19 @Agent.py:117][0m Average action selection time: 0.1102
[32m[0906 14-59-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 14-59-19 @MBExp.py:227][0m Rewards obtained: [208.03498686870304], Lows: [21], Highs: [15], Total time: 4429.018236999999
[32m[0906 14-59-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-58 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-59-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10817, current rewards: 3.28807, mean: 0.32881
[32m[0906 15-00-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10852, current rewards: 10.65256, mean: 0.17754
[32m[0906 15-00-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10829, current rewards: 16.42024, mean: 0.14927
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10836, current rewards: 23.15263, mean: 0.14470
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10848, current rewards: 29.89624, mean: 0.14236
[32m[0906 15-00-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10908, current rewards: 36.63879, mean: 0.14092
[32m[0906 15-00-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10966, current rewards: 43.38666, mean: 0.13996
[32m[0906 15-00-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10993, current rewards: 50.12529, mean: 0.13924
[32m[0906 15-00-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10993, current rewards: 56.87025, mean: 0.13871
[32m[0906 15-00-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10979, current rewards: 63.60954, mean: 0.13828
[32m[0906 15-00-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10961, current rewards: 70.38813, mean: 0.13802
[32m[0906 15-01-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10949, current rewards: 72.37307, mean: 0.12924
[32m[0906 15-01-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10944, current rewards: 78.85367, mean: 0.12927
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10937, current rewards: 85.33237, mean: 0.12929
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10928, current rewards: 91.81721, mean: 0.12932
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10926, current rewards: 98.29003, mean: 0.12933
[32m[0906 15-01-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10947, current rewards: 104.76886, mean: 0.12934
[32m[0906 15-01-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10964, current rewards: 111.24325, mean: 0.12935
[32m[0906 15-01-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10977, current rewards: 117.72306, mean: 0.12937
[32m[0906 15-01-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10984, current rewards: 123.44901, mean: 0.12859
[32m[0906 15-01-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10992, current rewards: 129.43985, mean: 0.12816
[32m[0906 15-01-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.11003, current rewards: 135.42660, mean: 0.12776
[32m[0906 15-02-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.11008, current rewards: 141.41760, mean: 0.12740
[32m[0906 15-02-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.11014, current rewards: 147.40620, mean: 0.12707
[32m[0906 15-02-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11022, current rewards: 153.39543, mean: 0.12677
[32m[0906 15-02-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11026, current rewards: 159.38147, mean: 0.12649
[32m[0906 15-02-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11030, current rewards: 155.26948, mean: 0.11853
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11035, current rewards: 162.97531, mean: 0.11983
[32m[0906 15-02-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11038, current rewards: 170.62783, mean: 0.12101
[32m[0906 15-02-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11043, current rewards: 177.84507, mean: 0.12181
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11046, current rewards: 185.06337, mean: 0.12256
[32m[0906 15-02-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11034, current rewards: 192.27835, mean: 0.12326
[32m[0906 15-02-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11028, current rewards: 199.48718, mean: 0.12391
[32m[0906 15-03-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11019, current rewards: 206.71140, mean: 0.12452
[32m[0906 15-03-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11011, current rewards: 213.92282, mean: 0.12510
[32m[0906 15-03-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11005, current rewards: 221.13648, mean: 0.12565
[32m[0906 15-03-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10998, current rewards: 229.11819, mean: 0.12658
[32m[0906 15-03-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10992, current rewards: 226.11301, mean: 0.12157
[32m[0906 15-03-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10990, current rewards: 233.37157, mean: 0.12218
[32m[0906 15-03-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10993, current rewards: 240.61851, mean: 0.12276
[32m[0906 15-03-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10995, current rewards: 247.86701, mean: 0.12332
[32m[0906 15-03-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11000, current rewards: 255.11763, mean: 0.12384
[32m[0906 15-03-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11003, current rewards: 262.37182, mean: 0.12435
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11006, current rewards: 268.98690, mean: 0.12453
[32m[0906 15-04-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11010, current rewards: 276.39677, mean: 0.12507
[32m[0906 15-04-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11005, current rewards: 283.59362, mean: 0.12548
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11000, current rewards: 290.79274, mean: 0.12588
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10996, current rewards: 293.33383, mean: 0.12429
[32m[0906 15-04-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10991, current rewards: 300.53504, mean: 0.12470
[32m[0906 15-04-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10986, current rewards: 307.72882, mean: 0.12509
[32m[0906 15-04-33 @Agent.py:117][0m Average action selection time: 0.1098
[32m[0906 15-04-33 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-04-33 @MBExp.py:227][0m Rewards obtained: [313.4840998717511], Lows: [10], Highs: [11], Total time: 4704.335934999999
[32m[0906 15-05-15 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-15 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-05-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10706, current rewards: -3.94486, mean: -0.39449
[32m[0906 15-05-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10807, current rewards: 1.31491, mean: 0.02192
[32m[0906 15-05-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10820, current rewards: 5.92345, mean: 0.05385
[32m[0906 15-05-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10809, current rewards: 10.99940, mean: 0.06875
[32m[0906 15-05-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10816, current rewards: 16.24759, mean: 0.07737
[32m[0906 15-05-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10864, current rewards: 21.49014, mean: 0.08265
[32m[0906 15-05-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10904, current rewards: 26.73244, mean: 0.08623
[32m[0906 15-05-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10947, current rewards: 31.97412, mean: 0.08882
[32m[0906 15-06-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10934, current rewards: 37.21680, mean: 0.09077
[32m[0906 15-06-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10921, current rewards: 42.45806, mean: 0.09230
[32m[0906 15-06-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10912, current rewards: 47.70084, mean: 0.09353
[32m[0906 15-06-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10902, current rewards: 52.95166, mean: 0.09456
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10894, current rewards: 58.19663, mean: 0.09540
[32m[0906 15-06-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10886, current rewards: 63.43737, mean: 0.09612
[32m[0906 15-06-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10877, current rewards: 68.68236, mean: 0.09674
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10874, current rewards: 73.92870, mean: 0.09727
[32m[0906 15-06-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10893, current rewards: 79.17847, mean: 0.09775
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10910, current rewards: 66.23006, mean: 0.07701
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10926, current rewards: 71.72713, mean: 0.07882
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10942, current rewards: 77.21995, mean: 0.08044
[32m[0906 15-07-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10958, current rewards: 82.70411, mean: 0.08189
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10976, current rewards: 88.19045, mean: 0.08320
[32m[0906 15-07-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10985, current rewards: 93.67636, mean: 0.08439
[32m[0906 15-07-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10994, current rewards: 99.17567, mean: 0.08550
[32m[0906 15-07-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11008, current rewards: 104.66193, mean: 0.08650
[32m[0906 15-07-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11019, current rewards: 110.15830, mean: 0.08743
[32m[0906 15-07-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11025, current rewards: 111.42655, mean: 0.08506
[32m[0906 15-07-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11033, current rewards: 109.43685, mean: 0.08047
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11037, current rewards: 114.98468, mean: 0.08155
[32m[0906 15-07-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11041, current rewards: 120.53181, mean: 0.08256
[32m[0906 15-08-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11045, current rewards: 126.07848, mean: 0.08350
[32m[0906 15-08-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11036, current rewards: 131.62581, mean: 0.08438
[32m[0906 15-08-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11031, current rewards: 137.17487, mean: 0.08520
[32m[0906 15-08-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11025, current rewards: 142.72401, mean: 0.08598
[32m[0906 15-08-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11018, current rewards: 148.27275, mean: 0.08671
[32m[0906 15-08-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11012, current rewards: 153.64906, mean: 0.08730
[32m[0906 15-08-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.11007, current rewards: 159.14810, mean: 0.08793
[32m[0906 15-08-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.11002, current rewards: 164.64664, mean: 0.08852
[32m[0906 15-08-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10999, current rewards: 164.69107, mean: 0.08623
[32m[0906 15-08-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.11003, current rewards: 169.91593, mean: 0.08669
[32m[0906 15-08-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.11007, current rewards: 175.13759, mean: 0.08713
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.11012, current rewards: 180.35917, mean: 0.08755
[32m[0906 15-09-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.11015, current rewards: 185.57786, mean: 0.08795
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11019, current rewards: 190.40555, mean: 0.08815
[32m[0906 15-09-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11024, current rewards: 195.67769, mean: 0.08854
[32m[0906 15-09-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11018, current rewards: 200.93400, mean: 0.08891
[32m[0906 15-09-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.11014, current rewards: 206.19107, mean: 0.08926
[32m[0906 15-09-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.11011, current rewards: 211.12524, mean: 0.08946
[32m[0906 15-09-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.11008, current rewards: 216.28909, mean: 0.08975
[32m[0906 15-09-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.11004, current rewards: 221.45187, mean: 0.09002
[32m[0906 15-09-51 @Agent.py:117][0m Average action selection time: 0.1100
[32m[0906 15-09-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-09-51 @MBExp.py:227][0m Rewards obtained: [225.587415891841], Lows: [12], Highs: [15], Total time: 4980.109159
[32m[0906 15-10-35 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-35 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 15-10-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11025, current rewards: -5.07204, mean: -0.50720
[32m[0906 15-10-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10869, current rewards: 5.89936, mean: 0.09832
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10835, current rewards: 15.81126, mean: 0.14374
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10828, current rewards: 25.80025, mean: 0.16125
[32m[0906 15-10-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10803, current rewards: 35.80688, mean: 0.17051
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10864, current rewards: 45.80437, mean: 0.17617
[32m[0906 15-11-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10921, current rewards: 55.81839, mean: 0.18006
[32m[0906 15-11-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10932, current rewards: 65.81817, mean: 0.18283
[32m[0906 15-11-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10916, current rewards: 75.81600, mean: 0.18492
[32m[0906 15-11-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10907, current rewards: 77.07582, mean: 0.16756
[32m[0906 15-11-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10898, current rewards: 84.07623, mean: 0.16486
[32m[0906 15-11-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10888, current rewards: 91.16978, mean: 0.16280
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10888, current rewards: 98.27474, mean: 0.16111
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10881, current rewards: 105.36935, mean: 0.15965
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10877, current rewards: 112.46595, mean: 0.15840
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10878, current rewards: 119.56672, mean: 0.15732
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10901, current rewards: 126.66488, mean: 0.15638
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10919, current rewards: 133.76319, mean: 0.15554
[32m[0906 15-12-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10937, current rewards: 141.36155, mean: 0.15534
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10950, current rewards: 138.48490, mean: 0.14426
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10961, current rewards: 147.08063, mean: 0.14562
[32m[0906 15-12-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10974, current rewards: 155.69839, mean: 0.14689
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10983, current rewards: 164.28986, mean: 0.14801
[32m[0906 15-12-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10991, current rewards: 162.09803, mean: 0.13974
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.11001, current rewards: 170.20283, mean: 0.14066
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11006, current rewards: 178.30541, mean: 0.14151
[32m[0906 15-12-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11014, current rewards: 184.05795, mean: 0.14050
[32m[0906 15-13-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11019, current rewards: 190.70639, mean: 0.14023
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11023, current rewards: 197.33398, mean: 0.13995
[32m[0906 15-13-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11029, current rewards: 203.96823, mean: 0.13970
[32m[0906 15-13-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11030, current rewards: 210.60015, mean: 0.13947
[32m[0906 15-13-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11023, current rewards: 217.22761, mean: 0.13925
[32m[0906 15-13-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11016, current rewards: 223.85497, mean: 0.13904
[32m[0906 15-13-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11011, current rewards: 230.49026, mean: 0.13885
[32m[0906 15-13-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11005, current rewards: 237.18943, mean: 0.13871
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.11001, current rewards: 243.66612, mean: 0.13845
[32m[0906 15-13-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10996, current rewards: 245.50818, mean: 0.13564
[32m[0906 15-13-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10990, current rewards: 252.04923, mean: 0.13551
[32m[0906 15-14-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10986, current rewards: 259.08912, mean: 0.13565
[32m[0906 15-14-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10987, current rewards: 266.12256, mean: 0.13578
[32m[0906 15-14-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10990, current rewards: 273.15357, mean: 0.13590
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10995, current rewards: 280.18546, mean: 0.13601
[32m[0906 15-14-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10998, current rewards: 287.21688, mean: 0.13612
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.11003, current rewards: 295.95634, mean: 0.13702
[32m[0906 15-14-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.11007, current rewards: 292.58275, mean: 0.13239
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.11002, current rewards: 301.01670, mean: 0.13319
[32m[0906 15-14-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10998, current rewards: 309.43583, mean: 0.13395
[32m[0906 15-14-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10996, current rewards: 317.86321, mean: 0.13469
[32m[0906 15-15-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10991, current rewards: 326.28175, mean: 0.13539
[32m[0906 15-15-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10988, current rewards: 334.72724, mean: 0.13607
[32m[0906 15-15-10 @Agent.py:117][0m Average action selection time: 0.1099
[32m[0906 15-15-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-15-10 @MBExp.py:227][0m Rewards obtained: [341.4699228115342], Lows: [16], Highs: [16], Total time: 5255.467815
[32m[0906 15-15-56 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-56 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 15-15-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10732, current rewards: -5.21685, mean: -0.52169
[32m[0906 15-16-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10810, current rewards: 0.44395, mean: 0.00740
[32m[0906 15-16-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10802, current rewards: 6.54124, mean: 0.05947
[32m[0906 15-16-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10810, current rewards: 12.63219, mean: 0.07895
[32m[0906 15-16-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10801, current rewards: 18.72676, mean: 0.08918
[32m[0906 15-16-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10873, current rewards: 24.81900, mean: 0.09546
[32m[0906 15-16-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10936, current rewards: 30.91092, mean: 0.09971
[32m[0906 15-16-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10930, current rewards: 37.00128, mean: 0.10278
[32m[0906 15-16-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10913, current rewards: 29.99538, mean: 0.07316
[32m[0906 15-16-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10905, current rewards: 37.57126, mean: 0.08168
[32m[0906 15-16-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10897, current rewards: 44.97555, mean: 0.08819
[32m[0906 15-16-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10888, current rewards: 52.40439, mean: 0.09358
[32m[0906 15-17-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10887, current rewards: 59.83655, mean: 0.09809
[32m[0906 15-17-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10879, current rewards: 67.26178, mean: 0.10191
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10874, current rewards: 74.69659, mean: 0.10521
[32m[0906 15-17-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10877, current rewards: 82.12875, mean: 0.10806
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10896, current rewards: 75.75357, mean: 0.09352
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10921, current rewards: 81.26341, mean: 0.09449
[32m[0906 15-17-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10941, current rewards: 86.74334, mean: 0.09532
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10953, current rewards: 92.17687, mean: 0.09602
[32m[0906 15-17-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10966, current rewards: 97.60802, mean: 0.09664
[32m[0906 15-17-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10977, current rewards: 103.04073, mean: 0.09721
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10988, current rewards: 108.47140, mean: 0.09772
[32m[0906 15-18-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10995, current rewards: 113.90421, mean: 0.09819
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10999, current rewards: 119.33561, mean: 0.09862
[32m[0906 15-18-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.11006, current rewards: 124.76817, mean: 0.09902
[32m[0906 15-18-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.11013, current rewards: 129.86352, mean: 0.09913
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11016, current rewards: 135.20494, mean: 0.09942
[32m[0906 15-18-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11021, current rewards: 134.82534, mean: 0.09562
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11027, current rewards: 139.75739, mean: 0.09572
[32m[0906 15-18-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11026, current rewards: 144.69026, mean: 0.09582
[32m[0906 15-18-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11018, current rewards: 149.62720, mean: 0.09591
[32m[0906 15-18-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11013, current rewards: 154.55940, mean: 0.09600
[32m[0906 15-18-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.11008, current rewards: 159.48871, mean: 0.09608
[32m[0906 15-19-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.11003, current rewards: 164.36254, mean: 0.09612
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10997, current rewards: 169.34079, mean: 0.09622
[32m[0906 15-19-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10991, current rewards: 171.46686, mean: 0.09473
[32m[0906 15-19-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10988, current rewards: 177.93937, mean: 0.09567
[32m[0906 15-19-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10982, current rewards: 184.40359, mean: 0.09655
[32m[0906 15-19-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10980, current rewards: 190.86552, mean: 0.09738
[32m[0906 15-19-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10986, current rewards: 197.32800, mean: 0.09817
[32m[0906 15-19-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10990, current rewards: 203.78817, mean: 0.09893
[32m[0906 15-19-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10994, current rewards: 210.76763, mean: 0.09989
[32m[0906 15-19-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10999, current rewards: 217.31423, mean: 0.10061
[32m[0906 15-20-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10999, current rewards: 223.84669, mean: 0.10129
[32m[0906 15-20-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10995, current rewards: 230.40038, mean: 0.10195
[32m[0906 15-20-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10992, current rewards: 236.94676, mean: 0.10257
[32m[0906 15-20-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10989, current rewards: 232.67934, mean: 0.09859
[32m[0906 15-20-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10986, current rewards: 238.83992, mean: 0.09910
[32m[0906 15-20-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10983, current rewards: 244.99778, mean: 0.09959
[32m[0906 15-20-31 @Agent.py:117][0m Average action selection time: 0.1098
[32m[0906 15-20-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-20-31 @MBExp.py:227][0m Rewards obtained: [250.32620478034082], Lows: [15], Highs: [21], Total time: 5530.677552
[32m[0906 15-21-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-21-19 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10742, current rewards: -14.00000, mean: -1.40000
[32m[0906 15-21-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10787, current rewards: -11.03130, mean: -0.18385
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10806, current rewards: -3.74773, mean: -0.03407
[32m[0906 15-21-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10803, current rewards: 3.53350, mean: 0.02208
[32m[0906 15-21-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10807, current rewards: 10.82129, mean: 0.05153
[32m[0906 15-21-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10889, current rewards: 18.10369, mean: 0.06963
[32m[0906 15-21-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10907, current rewards: 25.39005, mean: 0.08190
[32m[0906 15-21-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10890, current rewards: 32.67720, mean: 0.09077
[32m[0906 15-22-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10879, current rewards: 40.41056, mean: 0.09856
[32m[0906 15-22-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10867, current rewards: 48.06048, mean: 0.10448
[32m[0906 15-22-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10856, current rewards: 32.42977, mean: 0.06359
[32m[0906 15-22-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10856, current rewards: 42.01159, mean: 0.07502
[32m[0906 15-22-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10849, current rewards: 50.80025, mean: 0.08328
[32m[0906 15-22-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10843, current rewards: 59.58892, mean: 0.09029
[32m[0906 15-22-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10841, current rewards: 68.37758, mean: 0.09631
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10841, current rewards: 77.16624, mean: 0.10153
[32m[0906 15-22-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10865, current rewards: 85.95490, mean: 0.10612
[32m[0906 15-22-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10882, current rewards: 90.21223, mean: 0.10490
[32m[0906 15-22-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10898, current rewards: 75.14124, mean: 0.08257
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10914, current rewards: 25.14124, mean: 0.02619
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10927, current rewards: -24.85876, mean: -0.02461
[32m[0906 15-23-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10937, current rewards: -74.85876, mean: -0.07062
[32m[0906 15-23-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10947, current rewards: -124.85876, mean: -0.11249
[32m[0906 15-23-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10953, current rewards: -174.85876, mean: -0.15074
[32m[0906 15-23-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10962, current rewards: -224.85876, mean: -0.18583
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10973, current rewards: -274.85876, mean: -0.21814
[32m[0906 15-23-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10979, current rewards: -324.85876, mean: -0.24798
[32m[0906 15-23-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10984, current rewards: -374.85876, mean: -0.27563
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10991, current rewards: -424.85876, mean: -0.30132
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10994, current rewards: -474.85876, mean: -0.32525
[32m[0906 15-24-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10991, current rewards: -524.85876, mean: -0.34759
[32m[0906 15-24-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10985, current rewards: -574.85876, mean: -0.36850
[32m[0906 15-24-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10976, current rewards: -624.85876, mean: -0.38811
[32m[0906 15-24-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10970, current rewards: -674.85876, mean: -0.40654
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10965, current rewards: -724.85876, mean: -0.42389
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10960, current rewards: -774.85876, mean: -0.44026
[32m[0906 15-24-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10956, current rewards: -824.85876, mean: -0.45572
[32m[0906 15-24-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10952, current rewards: -874.85876, mean: -0.47035
[32m[0906 15-24-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10947, current rewards: -924.85876, mean: -0.48422
[32m[0906 15-24-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10945, current rewards: -974.85876, mean: -0.49738
[32m[0906 15-25-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10952, current rewards: -1024.85876, mean: -0.50988
[32m[0906 15-25-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10957, current rewards: -1074.85876, mean: -0.52178
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10964, current rewards: -1124.85876, mean: -0.53311
[32m[0906 15-25-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10969, current rewards: -1174.85876, mean: -0.54392
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10969, current rewards: -1224.85876, mean: -0.55423
[32m[0906 15-25-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10968, current rewards: -1274.85876, mean: -0.56410
[32m[0906 15-25-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10964, current rewards: -1324.85876, mean: -0.57353
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10961, current rewards: -1374.85876, mean: -0.58257
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10959, current rewards: -1424.85876, mean: -0.59123
[32m[0906 15-25-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10955, current rewards: -1474.85876, mean: -0.59954
[32m[0906 15-25-54 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-25-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-25-54 @MBExp.py:227][0m Rewards obtained: [-1514.8587581942427], Lows: [17], Highs: [1613], Total time: 5805.199892000001
[32m[0906 15-26-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-44 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 15-26-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10812, current rewards: -4.20791, mean: -0.42079
[32m[0906 15-26-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10799, current rewards: 1.27880, mean: 0.02131
[32m[0906 15-26-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10780, current rewards: 6.75116, mean: 0.06137
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10791, current rewards: 12.23003, mean: 0.07644
[32m[0906 15-27-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10802, current rewards: 13.48356, mean: 0.06421
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10859, current rewards: 11.27250, mean: 0.04336
[32m[0906 15-27-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10867, current rewards: 16.70478, mean: 0.05389
[32m[0906 15-27-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10853, current rewards: 22.13764, mean: 0.06149
[32m[0906 15-27-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10854, current rewards: 27.28693, mean: 0.06655
[32m[0906 15-27-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10860, current rewards: 32.73639, mean: 0.07117
[32m[0906 15-27-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10849, current rewards: 38.18985, mean: 0.07488
[32m[0906 15-27-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10841, current rewards: 43.64270, mean: 0.07793
[32m[0906 15-27-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10841, current rewards: 42.29345, mean: 0.06933
[32m[0906 15-27-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10835, current rewards: 47.46025, mean: 0.07191
[32m[0906 15-28-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10828, current rewards: 52.62467, mean: 0.07412
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10837, current rewards: 57.79126, mean: 0.07604
[32m[0906 15-28-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10857, current rewards: 62.96037, mean: 0.07773
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10874, current rewards: 68.12550, mean: 0.07922
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10892, current rewards: 73.29387, mean: 0.08054
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10906, current rewards: 78.45748, mean: 0.08173
[32m[0906 15-28-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10921, current rewards: 83.62204, mean: 0.08279
[32m[0906 15-28-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10937, current rewards: 88.79313, mean: 0.08377
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10950, current rewards: 93.95446, mean: 0.08464
[32m[0906 15-28-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10959, current rewards: 99.12656, mean: 0.08545
[32m[0906 15-28-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10973, current rewards: 104.41765, mean: 0.08630
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10981, current rewards: 109.53392, mean: 0.08693
[32m[0906 15-29-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10992, current rewards: 114.62056, mean: 0.08750
[32m[0906 15-29-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.11001, current rewards: 119.70346, mean: 0.08802
[32m[0906 15-29-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11007, current rewards: 124.79178, mean: 0.08850
[32m[0906 15-29-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11014, current rewards: 129.88475, mean: 0.08896
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.11012, current rewards: 134.87689, mean: 0.08932
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.11007, current rewards: 140.19884, mean: 0.08987
[32m[0906 15-29-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.11003, current rewards: 145.52121, mean: 0.09039
[32m[0906 15-29-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10995, current rewards: 150.99733, mean: 0.09096
[32m[0906 15-29-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10988, current rewards: 156.31402, mean: 0.09141
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10984, current rewards: 161.62988, mean: 0.09184
[32m[0906 15-30-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10978, current rewards: 157.83986, mean: 0.08720
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10971, current rewards: 163.08526, mean: 0.08768
[32m[0906 15-30-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10966, current rewards: 168.33542, mean: 0.08813
[32m[0906 15-30-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10962, current rewards: 173.58499, mean: 0.08856
[32m[0906 15-30-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10964, current rewards: 178.82981, mean: 0.08897
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10970, current rewards: 183.79059, mean: 0.08922
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10973, current rewards: 189.03355, mean: 0.08959
[32m[0906 15-30-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10976, current rewards: 184.69188, mean: 0.08551
[32m[0906 15-30-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10976, current rewards: 190.14883, mean: 0.08604
[32m[0906 15-30-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10972, current rewards: 195.60656, mean: 0.08655
[32m[0906 15-30-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10967, current rewards: 201.06377, mean: 0.08704
[32m[0906 15-31-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10964, current rewards: 206.51834, mean: 0.08751
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10960, current rewards: 211.97497, mean: 0.08796
[32m[0906 15-31-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10956, current rewards: 217.43023, mean: 0.08839
[32m[0906 15-31-19 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-31-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-31-19 @MBExp.py:227][0m Rewards obtained: [221.79510271467646], Lows: [16], Highs: [11], Total time: 6079.7914040000005
[32m[0906 15-32-11 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-11 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 15-32-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10741, current rewards: -5.31839, mean: -0.53184
[32m[0906 15-32-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10792, current rewards: 0.76670, mean: 0.01278
[32m[0906 15-32-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10823, current rewards: 6.70961, mean: 0.06100
[32m[0906 15-32-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10815, current rewards: 12.65109, mean: 0.07907
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10816, current rewards: 18.60118, mean: 0.08858
[32m[0906 15-32-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10861, current rewards: 24.54304, mean: 0.09440
[32m[0906 15-32-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10856, current rewards: 30.48164, mean: 0.09833
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10845, current rewards: 36.25622, mean: 0.10071
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10849, current rewards: 42.18287, mean: 0.10289
[32m[0906 15-33-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10840, current rewards: 48.10296, mean: 0.10457
[32m[0906 15-33-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10834, current rewards: 54.02687, mean: 0.10594
[32m[0906 15-33-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10829, current rewards: 59.94594, mean: 0.10705
[32m[0906 15-33-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10827, current rewards: 60.27346, mean: 0.09881
[32m[0906 15-33-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10826, current rewards: 61.23674, mean: 0.09278
[32m[0906 15-33-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10825, current rewards: 65.34399, mean: 0.09203
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10832, current rewards: 69.67738, mean: 0.09168
[32m[0906 15-33-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10855, current rewards: 74.00905, mean: 0.09137
[32m[0906 15-33-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10874, current rewards: 78.33694, mean: 0.09109
[32m[0906 15-33-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10892, current rewards: 82.66624, mean: 0.09084
[32m[0906 15-33-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10910, current rewards: 86.99423, mean: 0.09062
[32m[0906 15-34-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10925, current rewards: 91.31937, mean: 0.09042
[32m[0906 15-34-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10936, current rewards: 95.64531, mean: 0.09023
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10949, current rewards: 99.97126, mean: 0.09006
[32m[0906 15-34-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10959, current rewards: 104.43526, mean: 0.09003
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10968, current rewards: 108.92582, mean: 0.09002
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10978, current rewards: 113.40917, mean: 0.09001
[32m[0906 15-34-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10986, current rewards: 117.89515, mean: 0.09000
[32m[0906 15-34-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10991, current rewards: 122.37941, mean: 0.08998
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.11000, current rewards: 114.46406, mean: 0.08118
[32m[0906 15-34-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.11004, current rewards: 120.59374, mean: 0.08260
[32m[0906 15-34-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10997, current rewards: 126.71158, mean: 0.08391
[32m[0906 15-35-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10993, current rewards: 133.34278, mean: 0.08548
[32m[0906 15-35-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10988, current rewards: 141.01609, mean: 0.08759
[32m[0906 15-35-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10982, current rewards: 147.78012, mean: 0.08902
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10977, current rewards: 154.54416, mean: 0.09038
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10971, current rewards: 161.30820, mean: 0.09165
[32m[0906 15-35-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10967, current rewards: 168.07224, mean: 0.09286
[32m[0906 15-35-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10963, current rewards: 118.07224, mean: 0.06348
[32m[0906 15-35-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10959, current rewards: 68.07224, mean: 0.03564
[32m[0906 15-35-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10955, current rewards: 18.07224, mean: 0.00922
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10958, current rewards: -31.92776, mean: -0.01588
[32m[0906 15-35-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10963, current rewards: -81.92776, mean: -0.03977
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10969, current rewards: -131.92776, mean: -0.06253
[32m[0906 15-36-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10974, current rewards: -181.92776, mean: -0.08423
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10972, current rewards: -231.92776, mean: -0.10494
[32m[0906 15-36-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10970, current rewards: -281.92776, mean: -0.12475
[32m[0906 15-36-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10967, current rewards: -331.92776, mean: -0.14369
[32m[0906 15-36-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10964, current rewards: -381.92776, mean: -0.16183
[32m[0906 15-36-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10961, current rewards: -431.92776, mean: -0.17922
[32m[0906 15-36-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10957, current rewards: -481.92776, mean: -0.19591
[32m[0906 15-36-46 @Agent.py:117][0m Average action selection time: 0.1095
[32m[0906 15-36-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-36-46 @MBExp.py:227][0m Rewards obtained: [-521.9277621074923], Lows: [8], Highs: [701], Total time: 6354.368975
[32m[0906 15-37-41 @MBExp.py:144][0m ####################################################################
[32m[0906 15-37-41 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 15-37-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10673, current rewards: -7.73158, mean: -0.77316
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10722, current rewards: -1.76389, mean: -0.02940
[32m[0906 15-37-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10753, current rewards: 3.96597, mean: 0.03605
[32m[0906 15-37-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10759, current rewards: 9.68553, mean: 0.06053
[32m[0906 15-38-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10774, current rewards: 15.40563, mean: 0.07336
[32m[0906 15-38-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10792, current rewards: 21.12720, mean: 0.08126
[32m[0906 15-38-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10788, current rewards: 26.62032, mean: 0.08587
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10790, current rewards: 21.64275, mean: 0.06012
[32m[0906 15-38-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10791, current rewards: 27.47511, mean: 0.06701
[32m[0906 15-38-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10789, current rewards: 33.31021, mean: 0.07241
[32m[0906 15-38-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10785, current rewards: 39.14441, mean: 0.07675
[32m[0906 15-38-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10786, current rewards: 44.98309, mean: 0.08033
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10781, current rewards: 50.82079, mean: 0.08331
[32m[0906 15-38-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10779, current rewards: 56.65199, mean: 0.08584
[32m[0906 15-38-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10780, current rewards: 62.77813, mean: 0.08842
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10786, current rewards: 69.46226, mean: 0.09140
[32m[0906 15-39-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10807, current rewards: 75.29405, mean: 0.09296
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10828, current rewards: 81.12479, mean: 0.09433
[32m[0906 15-39-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10845, current rewards: 81.21734, mean: 0.08925
[32m[0906 15-39-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10861, current rewards: 86.95073, mean: 0.09057
[32m[0906 15-39-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10878, current rewards: 92.68354, mean: 0.09177
[32m[0906 15-39-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10888, current rewards: 93.95248, mean: 0.08863
[32m[0906 15-39-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10897, current rewards: 98.44900, mean: 0.08869
[32m[0906 15-39-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10908, current rewards: 104.23147, mean: 0.08985
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10917, current rewards: 109.70063, mean: 0.09066
[32m[0906 15-39-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10925, current rewards: 93.37025, mean: 0.07410
[32m[0906 15-40-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10934, current rewards: 102.15891, mean: 0.07798
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10942, current rewards: 110.94757, mean: 0.08158
[32m[0906 15-40-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10947, current rewards: 119.73623, mean: 0.08492
[32m[0906 15-40-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10954, current rewards: 128.52490, mean: 0.08803
[32m[0906 15-40-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10947, current rewards: 137.31356, mean: 0.09094
[32m[0906 15-40-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10941, current rewards: 143.88731, mean: 0.09224
[32m[0906 15-40-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10936, current rewards: 139.16366, mean: 0.08644
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10929, current rewards: 138.92075, mean: 0.08369
[32m[0906 15-40-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10923, current rewards: 144.55042, mean: 0.08453
[32m[0906 15-40-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10919, current rewards: 150.19986, mean: 0.08534
[32m[0906 15-40-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10913, current rewards: 155.85048, mean: 0.08611
[32m[0906 15-41-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10912, current rewards: 161.49565, mean: 0.08683
[32m[0906 15-41-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10907, current rewards: 167.14671, mean: 0.08751
[32m[0906 15-41-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10903, current rewards: 167.28877, mean: 0.08535
[32m[0906 15-41-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10902, current rewards: 173.70755, mean: 0.08642
[32m[0906 15-41-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10906, current rewards: 179.41930, mean: 0.08710
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10911, current rewards: 185.13263, mean: 0.08774
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10917, current rewards: 190.85220, mean: 0.08836
[32m[0906 15-41-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10912, current rewards: 196.57316, mean: 0.08895
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10909, current rewards: 202.28811, mean: 0.08951
[32m[0906 15-41-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10907, current rewards: 208.00698, mean: 0.09005
[32m[0906 15-41-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10904, current rewards: 213.72561, mean: 0.09056
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10900, current rewards: 218.63846, mean: 0.09072
[32m[0906 15-42-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10899, current rewards: 224.20527, mean: 0.09114
[32m[0906 15-42-14 @Agent.py:117][0m Average action selection time: 0.1090
[32m[0906 15-42-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-42-14 @MBExp.py:227][0m Rewards obtained: [228.66154281099531], Lows: [18], Highs: [34], Total time: 6627.498005
[32m[0906 15-43-11 @MBExp.py:144][0m ####################################################################
[32m[0906 15-43-11 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 15-43-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10951, current rewards: -4.53393, mean: -0.45339
[32m[0906 15-43-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10857, current rewards: 1.58734, mean: 0.02646
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10841, current rewards: 7.55952, mean: 0.06872
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10851, current rewards: 13.53404, mean: 0.08459
[32m[0906 15-43-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10846, current rewards: 19.50980, mean: 0.09290
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10847, current rewards: 25.48770, mean: 0.09803
[32m[0906 15-43-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10846, current rewards: 31.67158, mean: 0.10217
[32m[0906 15-43-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10843, current rewards: 37.85704, mean: 0.10516
[32m[0906 15-43-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10833, current rewards: 37.82003, mean: 0.09224
[32m[0906 15-44-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10832, current rewards: 43.12868, mean: 0.09376
[32m[0906 15-44-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10827, current rewards: 48.43901, mean: 0.09498
[32m[0906 15-44-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10817, current rewards: 53.75373, mean: 0.09599
[32m[0906 15-44-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10816, current rewards: 59.05771, mean: 0.09682
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10813, current rewards: 64.37029, mean: 0.09753
[32m[0906 15-44-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10808, current rewards: 69.68024, mean: 0.09814
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10822, current rewards: 75.40876, mean: 0.09922
[32m[0906 15-44-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10840, current rewards: 80.66924, mean: 0.09959
[32m[0906 15-44-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10857, current rewards: 85.73874, mean: 0.09970
[32m[0906 15-44-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10877, current rewards: 91.41442, mean: 0.10046
[32m[0906 15-44-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10891, current rewards: 97.08504, mean: 0.10113
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10902, current rewards: 102.76421, mean: 0.10175
[32m[0906 15-45-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10916, current rewards: 108.43998, mean: 0.10230
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10925, current rewards: 114.12204, mean: 0.10281
[32m[0906 15-45-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10935, current rewards: 119.69579, mean: 0.10319
[32m[0906 15-45-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10941, current rewards: 125.36373, mean: 0.10361
[32m[0906 15-45-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10949, current rewards: 131.04078, mean: 0.10400
[32m[0906 15-45-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10956, current rewards: 126.28595, mean: 0.09640
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10962, current rewards: 131.91124, mean: 0.09699
[32m[0906 15-45-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10969, current rewards: 137.54062, mean: 0.09755
[32m[0906 15-45-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10973, current rewards: 143.16396, mean: 0.09806
[32m[0906 15-45-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10966, current rewards: 148.79224, mean: 0.09854
[32m[0906 15-46-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10958, current rewards: 153.85083, mean: 0.09862
[32m[0906 15-46-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10955, current rewards: 159.47795, mean: 0.09905
[32m[0906 15-46-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10949, current rewards: 154.51684, mean: 0.09308
[32m[0906 15-46-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10945, current rewards: 160.04737, mean: 0.09359
[32m[0906 15-46-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10942, current rewards: 165.57663, mean: 0.09408
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10938, current rewards: 171.10606, mean: 0.09453
[32m[0906 15-46-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10933, current rewards: 176.62948, mean: 0.09496
[32m[0906 15-46-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10929, current rewards: 182.15615, mean: 0.09537
[32m[0906 15-46-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10925, current rewards: 187.96275, mean: 0.09590
[32m[0906 15-46-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10921, current rewards: 193.69905, mean: 0.09637
[32m[0906 15-46-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10928, current rewards: 199.26360, mean: 0.09673
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10934, current rewards: 204.83476, mean: 0.09708
[32m[0906 15-47-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10939, current rewards: 210.40228, mean: 0.09741
[32m[0906 15-47-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10936, current rewards: 215.97032, mean: 0.09772
[32m[0906 15-47-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10933, current rewards: 221.53782, mean: 0.09803
[32m[0906 15-47-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10929, current rewards: 227.10817, mean: 0.09832
[32m[0906 15-47-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10929, current rewards: 232.67579, mean: 0.09859
[32m[0906 15-47-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10927, current rewards: 232.41084, mean: 0.09644
[32m[0906 15-47-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10924, current rewards: 236.61686, mean: 0.09619
[32m[0906 15-47-45 @Agent.py:117][0m Average action selection time: 0.1092
[32m[0906 15-47-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-47-45 @MBExp.py:227][0m Rewards obtained: [239.9846176593982], Lows: [10], Highs: [15], Total time: 6901.299342
[32m[0906 15-48-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-48-44 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 15-48-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10965, current rewards: -5.48073, mean: -0.54807
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10784, current rewards: 0.15438, mean: 0.00257
[32m[0906 15-48-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10763, current rewards: 5.53015, mean: 0.05027
[32m[0906 15-49-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10780, current rewards: 10.91058, mean: 0.06819
[32m[0906 15-49-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10736, current rewards: 16.28434, mean: 0.07754
[32m[0906 15-49-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10746, current rewards: 21.66236, mean: 0.08332
[32m[0906 15-49-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10759, current rewards: 16.09515, mean: 0.05192
[32m[0906 15-49-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10767, current rewards: 21.46474, mean: 0.05962
[32m[0906 15-49-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10771, current rewards: 26.94665, mean: 0.06572
[32m[0906 15-49-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10777, current rewards: 32.42276, mean: 0.07048
[32m[0906 15-49-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10775, current rewards: 37.90332, mean: 0.07432
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10774, current rewards: 43.37954, mean: 0.07746
[32m[0906 15-49-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10779, current rewards: 48.85460, mean: 0.08009
[32m[0906 15-49-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10779, current rewards: 54.33300, mean: 0.08232
[32m[0906 15-50-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10785, current rewards: 59.81251, mean: 0.08424
[32m[0906 15-50-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10807, current rewards: 65.49087, mean: 0.08617
[32m[0906 15-50-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10830, current rewards: 70.99466, mean: 0.08765
[32m[0906 15-50-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10850, current rewards: 72.26913, mean: 0.08403
[32m[0906 15-50-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10874, current rewards: 72.30116, mean: 0.07945
[32m[0906 15-50-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10888, current rewards: 78.63568, mean: 0.08191
[32m[0906 15-50-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10901, current rewards: 84.97183, mean: 0.08413
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10915, current rewards: 91.30045, mean: 0.08613
[32m[0906 15-50-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10927, current rewards: 97.63692, mean: 0.08796
[32m[0906 15-50-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10939, current rewards: 104.01151, mean: 0.08967
[32m[0906 15-50-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10951, current rewards: 110.34616, mean: 0.09120
[32m[0906 15-51-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10963, current rewards: 116.68559, mean: 0.09261
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10974, current rewards: 123.02555, mean: 0.09391
[32m[0906 15-51-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10982, current rewards: 118.40332, mean: 0.08706
[32m[0906 15-51-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10989, current rewards: 124.32648, mean: 0.08817
[32m[0906 15-51-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10991, current rewards: 130.24001, mean: 0.08921
[32m[0906 15-51-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10984, current rewards: 136.16112, mean: 0.09017
[32m[0906 15-51-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10978, current rewards: 143.45536, mean: 0.09196
[32m[0906 15-51-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10974, current rewards: 149.29109, mean: 0.09273
[32m[0906 15-51-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10967, current rewards: 155.12847, mean: 0.09345
[32m[0906 15-51-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10961, current rewards: 160.96291, mean: 0.09413
[32m[0906 15-51-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10959, current rewards: 156.42724, mean: 0.08888
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10954, current rewards: 162.40739, mean: 0.08973
[32m[0906 15-52-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10949, current rewards: 168.28846, mean: 0.09048
[32m[0906 15-52-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10947, current rewards: 174.16998, mean: 0.09119
[32m[0906 15-52-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10942, current rewards: 173.07777, mean: 0.08830
[32m[0906 15-52-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10936, current rewards: 178.29726, mean: 0.08871
[32m[0906 15-52-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10942, current rewards: 182.79122, mean: 0.08873
[32m[0906 15-52-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10948, current rewards: 187.28953, mean: 0.08876
[32m[0906 15-52-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10950, current rewards: 191.78703, mean: 0.08879
[32m[0906 15-52-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10947, current rewards: 196.28547, mean: 0.08882
[32m[0906 15-52-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10944, current rewards: 200.78327, mean: 0.08884
[32m[0906 15-52-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10940, current rewards: 205.27934, mean: 0.08887
[32m[0906 15-53-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10939, current rewards: 209.73771, mean: 0.08887
[32m[0906 15-53-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10936, current rewards: 214.22227, mean: 0.08889
[32m[0906 15-53-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10934, current rewards: 218.70721, mean: 0.08891
[32m[0906 15-53-18 @Agent.py:117][0m Average action selection time: 0.1093
[32m[0906 15-53-18 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-53-18 @MBExp.py:227][0m Rewards obtained: [222.29617910865034], Lows: [20], Highs: [12], Total time: 7175.3393160000005
[32m[0906 15-54-20 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-20 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 15-54-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10683, current rewards: -4.46139, mean: -0.44614
[32m[0906 15-54-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10777, current rewards: 1.09404, mean: 0.01823
[32m[0906 15-54-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10782, current rewards: 6.63777, mean: 0.06034
[32m[0906 15-54-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10741, current rewards: 12.17513, mean: 0.07609
[32m[0906 15-54-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10711, current rewards: 17.71375, mean: 0.08435
[32m[0906 15-54-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10720, current rewards: 23.24618, mean: 0.08941
[32m[0906 15-54-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10743, current rewards: 28.25447, mean: 0.09114
[32m[0906 15-54-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10748, current rewards: 33.65810, mean: 0.09349
[32m[0906 15-55-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10753, current rewards: 39.05301, mean: 0.09525
[32m[0906 15-55-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10762, current rewards: 44.45215, mean: 0.09664
[32m[0906 15-55-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10760, current rewards: 49.84968, mean: 0.09774
[32m[0906 15-55-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10764, current rewards: 44.93440, mean: 0.08024
[32m[0906 15-55-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10774, current rewards: 50.54986, mean: 0.08287
[32m[0906 15-55-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10773, current rewards: 56.16616, mean: 0.08510
[32m[0906 15-55-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10774, current rewards: 61.78288, mean: 0.08702
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10799, current rewards: 67.39826, mean: 0.08868
[32m[0906 15-55-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10824, current rewards: 73.01111, mean: 0.09014
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10844, current rewards: 78.62415, mean: 0.09142
[32m[0906 15-55-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10864, current rewards: 84.24059, mean: 0.09257
[32m[0906 15-56-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10881, current rewards: 89.85805, mean: 0.09360
[32m[0906 15-56-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10898, current rewards: 95.47573, mean: 0.09453
[32m[0906 15-56-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10909, current rewards: 101.09290, mean: 0.09537
[32m[0906 15-56-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10922, current rewards: 106.61708, mean: 0.09605
[32m[0906 15-56-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10933, current rewards: 112.19946, mean: 0.09672
[32m[0906 15-56-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10945, current rewards: 117.77946, mean: 0.09734
[32m[0906 15-56-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10953, current rewards: 123.36028, mean: 0.09790
[32m[0906 15-56-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10963, current rewards: 128.94107, mean: 0.09843
[32m[0906 15-56-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10969, current rewards: 134.52277, mean: 0.09891
[32m[0906 15-56-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10975, current rewards: 135.35502, mean: 0.09600
[32m[0906 15-57-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10973, current rewards: 140.98225, mean: 0.09656
[32m[0906 15-57-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10969, current rewards: 147.23615, mean: 0.09751
[32m[0906 15-57-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10963, current rewards: 152.89609, mean: 0.09801
[32m[0906 15-57-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10960, current rewards: 158.55718, mean: 0.09848
[32m[0906 15-57-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10955, current rewards: 164.21712, mean: 0.09893
[32m[0906 15-57-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10953, current rewards: 169.87759, mean: 0.09934
[32m[0906 15-57-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10954, current rewards: 175.54319, mean: 0.09974
[32m[0906 15-57-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10951, current rewards: 181.20917, mean: 0.10012
[32m[0906 15-57-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10944, current rewards: 186.87461, mean: 0.10047
[32m[0906 15-57-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10941, current rewards: 192.67756, mean: 0.10088
[32m[0906 15-57-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10936, current rewards: 198.35190, mean: 0.10120
[32m[0906 15-58-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10931, current rewards: 204.02080, mean: 0.10150
[32m[0906 15-58-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10934, current rewards: 199.08611, mean: 0.09664
[32m[0906 15-58-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10938, current rewards: 204.66600, mean: 0.09700
[32m[0906 15-58-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10939, current rewards: 210.24856, mean: 0.09734
[32m[0906 15-58-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10934, current rewards: 215.82879, mean: 0.09766
[32m[0906 15-58-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10931, current rewards: 221.40969, mean: 0.09797
[32m[0906 15-58-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10928, current rewards: 227.36190, mean: 0.09843
[32m[0906 15-58-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10924, current rewards: 233.06477, mean: 0.09876
[32m[0906 15-58-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10920, current rewards: 238.70914, mean: 0.09905
[32m[0906 15-58-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10917, current rewards: 244.35476, mean: 0.09933
[32m[0906 15-58-54 @Agent.py:117][0m Average action selection time: 0.1091
[32m[0906 15-58-54 @Agent.py:118][0m Rollout length: 2505
[32m[0906 15-58-54 @MBExp.py:227][0m Rewards obtained: [244.41918258076936], Lows: [10], Highs: [14], Total time: 7448.913535000001
[32m[0906 15-59-58 @MBExp.py:144][0m ####################################################################
[32m[0906 15-59-58 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 15-59-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10799, current rewards: -4.59894, mean: -0.45989
[32m[0906 16-00-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10732, current rewards: 3.13844, mean: 0.05231
[32m[0906 16-00-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10733, current rewards: 9.81355, mean: 0.08921
[32m[0906 16-00-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10628, current rewards: 16.49336, mean: 0.10308
[32m[0906 16-00-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10623, current rewards: 23.17896, mean: 0.11038
[32m[0906 16-00-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10666, current rewards: 29.40506, mean: 0.11310
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10682, current rewards: 36.57923, mean: 0.11800
[32m[0906 16-00-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10688, current rewards: 43.76380, mean: 0.12157
[32m[0906 16-00-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10704, current rewards: 50.94679, mean: 0.12426
[32m[0906 16-00-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10703, current rewards: 58.12961, mean: 0.12637
[32m[0906 16-00-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10713, current rewards: 65.30694, mean: 0.12805
[32m[0906 16-00-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10723, current rewards: 72.48741, mean: 0.12944
[32m[0906 16-01-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10722, current rewards: 79.67777, mean: 0.13062
[32m[0906 16-01-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10722, current rewards: 87.14257, mean: 0.13203
[32m[0906 16-01-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10730, current rewards: 94.53348, mean: 0.13315
[32m[0906 16-01-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10755, current rewards: 101.94785, mean: 0.13414
[32m[0906 16-01-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10776, current rewards: 109.35109, mean: 0.13500
[32m[0906 16-01-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10798, current rewards: 106.29981, mean: 0.12360
[32m[0906 16-01-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10813, current rewards: 113.17425, mean: 0.12437
[32m[0906 16-01-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10829, current rewards: 120.04242, mean: 0.12504
[32m[0906 16-01-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10845, current rewards: 126.91244, mean: 0.12566
[32m[0906 16-01-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10856, current rewards: 122.86778, mean: 0.11591
[32m[0906 16-01-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10870, current rewards: 123.56558, mean: 0.11132
[32m[0906 16-02-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10885, current rewards: 130.12454, mean: 0.11218
[32m[0906 16-02-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10892, current rewards: 136.67448, mean: 0.11295
[32m[0906 16-02-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10903, current rewards: 143.22746, mean: 0.11367
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10911, current rewards: 149.78147, mean: 0.11434
[32m[0906 16-02-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10917, current rewards: 156.34265, mean: 0.11496
[32m[0906 16-02-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10925, current rewards: 162.89971, mean: 0.11553
[32m[0906 16-02-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10918, current rewards: 169.45549, mean: 0.11607
[32m[0906 16-02-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10910, current rewards: 175.60429, mean: 0.11629
[32m[0906 16-02-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10905, current rewards: 182.04579, mean: 0.11670
[32m[0906 16-02-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10899, current rewards: 188.47703, mean: 0.11707
[32m[0906 16-02-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10895, current rewards: 194.91937, mean: 0.11742
[32m[0906 16-03-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10893, current rewards: 201.35483, mean: 0.11775
[32m[0906 16-03-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10890, current rewards: 197.02936, mean: 0.11195
[32m[0906 16-03-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10887, current rewards: 203.29811, mean: 0.11232
[32m[0906 16-03-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10885, current rewards: 209.76006, mean: 0.11277
[32m[0906 16-03-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10882, current rewards: 217.86429, mean: 0.11407
[32m[0906 16-03-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10879, current rewards: 224.02922, mean: 0.11430
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10879, current rewards: 230.20379, mean: 0.11453
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10882, current rewards: 236.38401, mean: 0.11475
[32m[0906 16-03-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10889, current rewards: 242.56679, mean: 0.11496
[32m[0906 16-03-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10891, current rewards: 248.74755, mean: 0.11516
[32m[0906 16-03-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10889, current rewards: 254.92089, mean: 0.11535
[32m[0906 16-04-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10887, current rewards: 261.10342, mean: 0.11553
[32m[0906 16-04-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10886, current rewards: 267.32652, mean: 0.11573
[32m[0906 16-04-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10884, current rewards: 268.38002, mean: 0.11372
[32m[0906 16-04-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10881, current rewards: 275.58624, mean: 0.11435
[32m[0906 16-04-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10879, current rewards: 282.78827, mean: 0.11495
[32m[0906 16-04-30 @Agent.py:117][0m Average action selection time: 0.1088
[32m[0906 16-04-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-04-30 @MBExp.py:227][0m Rewards obtained: [288.53530737512926], Lows: [17], Highs: [14], Total time: 7721.5439830000005
[32m[0906 16-05-36 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-36 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 16-05-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10734, current rewards: -3.38965, mean: -0.33897
[32m[0906 16-05-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10800, current rewards: 2.55203, mean: 0.04253
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10663, current rewards: 8.28322, mean: 0.07530
[32m[0906 16-05-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10567, current rewards: 14.01285, mean: 0.08758
[32m[0906 16-05-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10601, current rewards: 19.87409, mean: 0.09464
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10643, current rewards: 26.32367, mean: 0.10124
[32m[0906 16-06-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10666, current rewards: 32.16826, mean: 0.10377
[32m[0906 16-06-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10684, current rewards: 38.01213, mean: 0.10559
[32m[0906 16-06-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10695, current rewards: 43.85760, mean: 0.10697
[32m[0906 16-06-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10702, current rewards: 46.35193, mean: 0.10077
[32m[0906 16-06-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10712, current rewards: 47.96813, mean: 0.09406
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10716, current rewards: 53.37678, mean: 0.09532
[32m[0906 16-06-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10717, current rewards: 58.79366, mean: 0.09638
[32m[0906 16-06-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10724, current rewards: 63.71530, mean: 0.09654
[32m[0906 16-06-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10731, current rewards: 69.05589, mean: 0.09726
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10756, current rewards: 74.38342, mean: 0.09787
[32m[0906 16-07-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10779, current rewards: 70.10992, mean: 0.08656
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10796, current rewards: 75.66199, mean: 0.08798
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10811, current rewards: 81.21370, mean: 0.08925
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10831, current rewards: 86.76529, mean: 0.09038
[32m[0906 16-07-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10847, current rewards: 92.31855, mean: 0.09140
[32m[0906 16-07-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10865, current rewards: 98.01653, mean: 0.09247
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10883, current rewards: 103.76690, mean: 0.09348
[32m[0906 16-07-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10893, current rewards: 109.33414, mean: 0.09425
[32m[0906 16-07-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10902, current rewards: 109.73798, mean: 0.09069
[32m[0906 16-07-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10912, current rewards: 115.43101, mean: 0.09161
[32m[0906 16-08-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10919, current rewards: 121.12768, mean: 0.09246
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10927, current rewards: 126.82413, mean: 0.09325
[32m[0906 16-08-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10929, current rewards: 132.52077, mean: 0.09399
[32m[0906 16-08-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10922, current rewards: 138.21686, mean: 0.09467
[32m[0906 16-08-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10918, current rewards: 144.42490, mean: 0.09565
[32m[0906 16-08-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10913, current rewards: 149.95726, mean: 0.09613
[32m[0906 16-08-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10907, current rewards: 155.48714, mean: 0.09658
[32m[0906 16-08-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10903, current rewards: 161.01760, mean: 0.09700
[32m[0906 16-08-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10898, current rewards: 161.25607, mean: 0.09430
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10893, current rewards: 167.39734, mean: 0.09511
[32m[0906 16-08-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10889, current rewards: 173.53996, mean: 0.09588
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10884, current rewards: 179.68312, mean: 0.09660
[32m[0906 16-09-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10879, current rewards: 185.87339, mean: 0.09732
[32m[0906 16-09-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10877, current rewards: 192.02936, mean: 0.09797
[32m[0906 16-09-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10873, current rewards: 198.18836, mean: 0.09860
[32m[0906 16-09-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10873, current rewards: 204.34281, mean: 0.09920
[32m[0906 16-09-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10880, current rewards: 210.49722, mean: 0.09976
[32m[0906 16-09-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10879, current rewards: 216.65451, mean: 0.10030
[32m[0906 16-09-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10876, current rewards: 222.80948, mean: 0.10082
[32m[0906 16-09-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10874, current rewards: 223.24118, mean: 0.09878
[32m[0906 16-09-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10871, current rewards: 229.03085, mean: 0.09915
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10868, current rewards: 234.60901, mean: 0.09941
[32m[0906 16-09-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10866, current rewards: 240.18842, mean: 0.09966
[32m[0906 16-10-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10864, current rewards: 245.77202, mean: 0.09991
[32m[0906 16-10-08 @Agent.py:117][0m Average action selection time: 0.1086
[32m[0906 16-10-08 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-10-08 @MBExp.py:227][0m Rewards obtained: [250.23591936639605], Lows: [6], Highs: [26], Total time: 7993.794024000001
[32m[0906 16-11-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-11-17 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 16-11-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10920, current rewards: -5.60750, mean: -0.56075
[32m[0906 16-11-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10627, current rewards: 0.03731, mean: 0.00062
[32m[0906 16-11-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10535, current rewards: 5.68341, mean: 0.05167
[32m[0906 16-11-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10519, current rewards: 11.33647, mean: 0.07085
[32m[0906 16-11-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10554, current rewards: 16.75129, mean: 0.07977
[32m[0906 16-11-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10591, current rewards: 22.38090, mean: 0.08608
[32m[0906 16-11-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10628, current rewards: 28.01384, mean: 0.09037
[32m[0906 16-11-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10648, current rewards: 33.64457, mean: 0.09346
[32m[0906 16-12-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10661, current rewards: 39.28098, mean: 0.09581
[32m[0906 16-12-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10675, current rewards: 44.91503, mean: 0.09764
[32m[0906 16-12-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10680, current rewards: 50.54209, mean: 0.09910
[32m[0906 16-12-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10685, current rewards: 56.17575, mean: 0.10031
[32m[0906 16-12-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10695, current rewards: 62.55399, mean: 0.10255
[32m[0906 16-12-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10696, current rewards: 68.50073, mean: 0.10379
[32m[0906 16-12-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10708, current rewards: 65.00264, mean: 0.09155
[32m[0906 16-12-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10737, current rewards: 70.94828, mean: 0.09335
[32m[0906 16-12-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10760, current rewards: 76.86615, mean: 0.09490
[32m[0906 16-12-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10781, current rewards: 82.78403, mean: 0.09626
[32m[0906 16-12-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10805, current rewards: 48.44103, mean: 0.05323
[32m[0906 16-13-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10822, current rewards: -1.55897, mean: -0.00162
[32m[0906 16-13-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10838, current rewards: -51.55897, mean: -0.05105
[32m[0906 16-13-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10850, current rewards: -101.55897, mean: -0.09581
[32m[0906 16-13-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10863, current rewards: -151.55897, mean: -0.13654
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10877, current rewards: -201.55897, mean: -0.17376
[32m[0906 16-13-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10886, current rewards: -251.55897, mean: -0.20790
[32m[0906 16-13-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10894, current rewards: -301.55897, mean: -0.23933
[32m[0906 16-13-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10905, current rewards: -351.55897, mean: -0.26837
[32m[0906 16-13-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10916, current rewards: -401.55897, mean: -0.29526
[32m[0906 16-13-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10916, current rewards: -451.55897, mean: -0.32025
[32m[0906 16-13-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10913, current rewards: -501.55897, mean: -0.34353
[32m[0906 16-14-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10907, current rewards: -551.55897, mean: -0.36527
[32m[0906 16-14-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10902, current rewards: -601.55897, mean: -0.38561
[32m[0906 16-14-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10899, current rewards: -651.55897, mean: -0.40470
[32m[0906 16-14-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10894, current rewards: -701.55897, mean: -0.42263
[32m[0906 16-14-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10890, current rewards: -751.55897, mean: -0.43951
[32m[0906 16-14-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10888, current rewards: -801.55897, mean: -0.45543
[32m[0906 16-14-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10884, current rewards: -851.55897, mean: -0.47047
[32m[0906 16-14-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10881, current rewards: -901.55897, mean: -0.48471
[32m[0906 16-14-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10879, current rewards: -951.55897, mean: -0.49820
[32m[0906 16-14-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10876, current rewards: -1001.55897, mean: -0.51100
[32m[0906 16-14-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10874, current rewards: -1051.55897, mean: -0.52316
[32m[0906 16-15-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10875, current rewards: -1101.55897, mean: -0.53474
[32m[0906 16-15-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10881, current rewards: -1151.55897, mean: -0.54576
[32m[0906 16-15-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10879, current rewards: -1201.55897, mean: -0.55628
[32m[0906 16-15-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10877, current rewards: -1251.55897, mean: -0.56632
[32m[0906 16-15-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10874, current rewards: -1301.55897, mean: -0.57591
[32m[0906 16-15-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10871, current rewards: -1351.55897, mean: -0.58509
[32m[0906 16-15-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10870, current rewards: -1401.55897, mean: -0.59388
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10868, current rewards: -1451.55897, mean: -0.60231
[32m[0906 16-15-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10866, current rewards: -1501.55897, mean: -0.61039
[32m[0906 16-15-49 @Agent.py:117][0m Average action selection time: 0.1087
[32m[0906 16-15-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-15-49 @MBExp.py:227][0m Rewards obtained: [-1541.5589676604977], Lows: [5], Highs: [1632], Total time: 8266.147329000001
[32m[0906 16-17-00 @MBExp.py:144][0m ####################################################################
[32m[0906 16-17-00 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 16-17-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10544, current rewards: 0.06238, mean: 0.00624
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10488, current rewards: 5.56410, mean: 0.09273
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10491, current rewards: 10.81051, mean: 0.09828
[32m[0906 16-17-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10487, current rewards: 16.05820, mean: 0.10036
[32m[0906 16-17-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10570, current rewards: 21.74805, mean: 0.10356
[32m[0906 16-17-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10625, current rewards: 27.03813, mean: 0.10399
[32m[0906 16-17-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10670, current rewards: 32.32206, mean: 0.10426
[32m[0906 16-17-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10705, current rewards: 32.97404, mean: 0.09159
[32m[0906 16-17-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10710, current rewards: 38.55874, mean: 0.09405
[32m[0906 16-17-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10717, current rewards: 44.13960, mean: 0.09596
[32m[0906 16-17-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10724, current rewards: 49.72036, mean: 0.09749
[32m[0906 16-18-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10731, current rewards: 55.30429, mean: 0.09876
[32m[0906 16-18-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10730, current rewards: 61.12550, mean: 0.10021
[32m[0906 16-18-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10739, current rewards: 66.72910, mean: 0.10110
[32m[0906 16-18-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10758, current rewards: 66.95395, mean: 0.09430
[32m[0906 16-18-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10783, current rewards: 72.42770, mean: 0.09530
[32m[0906 16-18-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10807, current rewards: 77.89856, mean: 0.09617
[32m[0906 16-18-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10826, current rewards: 83.36942, mean: 0.09694
[32m[0906 16-18-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10841, current rewards: 88.83994, mean: 0.09763
[32m[0906 16-18-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10860, current rewards: 94.31014, mean: 0.09824
[32m[0906 16-18-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10874, current rewards: 99.77611, mean: 0.09879
[32m[0906 16-18-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10884, current rewards: 94.99096, mean: 0.08961
[32m[0906 16-19-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10897, current rewards: 100.39373, mean: 0.09044
[32m[0906 16-19-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10904, current rewards: 105.79530, mean: 0.09120
[32m[0906 16-19-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10915, current rewards: 111.19666, mean: 0.09190
[32m[0906 16-19-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10923, current rewards: 116.60054, mean: 0.09254
[32m[0906 16-19-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10926, current rewards: 122.00662, mean: 0.09313
[32m[0906 16-19-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10935, current rewards: 127.41036, mean: 0.09368
[32m[0906 16-19-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10929, current rewards: 132.81602, mean: 0.09420
[32m[0906 16-19-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10925, current rewards: 133.38691, mean: 0.09136
[32m[0906 16-19-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10922, current rewards: 138.39878, mean: 0.09165
[32m[0906 16-19-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10917, current rewards: 143.41398, mean: 0.09193
[32m[0906 16-19-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10911, current rewards: 148.42299, mean: 0.09219
[32m[0906 16-20-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10908, current rewards: 153.43734, mean: 0.09243
[32m[0906 16-20-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10903, current rewards: 158.45029, mean: 0.09266
[32m[0906 16-20-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10898, current rewards: 163.46507, mean: 0.09288
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10895, current rewards: 168.47908, mean: 0.09308
[32m[0906 16-20-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10891, current rewards: 173.76717, mean: 0.09342
[32m[0906 16-20-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10888, current rewards: 178.70409, mean: 0.09356
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10887, current rewards: 183.65259, mean: 0.09370
[32m[0906 16-20-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10883, current rewards: 188.58870, mean: 0.09383
[32m[0906 16-20-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10882, current rewards: 193.53392, mean: 0.09395
[32m[0906 16-20-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10889, current rewards: 200.35192, mean: 0.09495
[32m[0906 16-20-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10885, current rewards: 205.48312, mean: 0.09513
[32m[0906 16-21-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10882, current rewards: 210.61389, mean: 0.09530
[32m[0906 16-21-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10882, current rewards: 215.75185, mean: 0.09547
[32m[0906 16-21-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10878, current rewards: 220.88035, mean: 0.09562
[32m[0906 16-21-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10875, current rewards: 226.01234, mean: 0.09577
[32m[0906 16-21-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10874, current rewards: 231.13953, mean: 0.09591
[32m[0906 16-21-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10871, current rewards: 236.26612, mean: 0.09604
[32m[0906 16-21-32 @Agent.py:117][0m Average action selection time: 0.1087
[32m[0906 16-21-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-21-32 @MBExp.py:227][0m Rewards obtained: [240.3694635271359], Lows: [5], Highs: [15], Total time: 8538.604341000002
[32m[0906 16-22-45 @MBExp.py:144][0m ####################################################################
[32m[0906 16-22-45 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 16-22-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10355, current rewards: -4.34726, mean: -0.43473
[32m[0906 16-22-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10448, current rewards: 1.34376, mean: 0.02240
[32m[0906 16-22-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10466, current rewards: 7.05431, mean: 0.06413
[32m[0906 16-23-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10457, current rewards: 12.47168, mean: 0.07795
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10508, current rewards: 17.69904, mean: 0.08428
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10561, current rewards: 23.43512, mean: 0.09014
[32m[0906 16-23-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10583, current rewards: 29.17151, mean: 0.09410
[32m[0906 16-23-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10599, current rewards: 34.91366, mean: 0.09698
[32m[0906 16-23-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10622, current rewards: 40.64760, mean: 0.09914
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10632, current rewards: 35.88804, mean: 0.07802
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10643, current rewards: 41.95172, mean: 0.08226
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10659, current rewards: 48.00729, mean: 0.08573
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10662, current rewards: 54.03965, mean: 0.08859
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10668, current rewards: 60.12397, mean: 0.09110
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10700, current rewards: 66.20733, mean: 0.09325
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10727, current rewards: 72.28576, mean: 0.09511
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10751, current rewards: 78.36888, mean: 0.09675
[32m[0906 16-24-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10776, current rewards: 84.44380, mean: 0.09819
[32m[0906 16-24-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10794, current rewards: 90.52180, mean: 0.09947
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10815, current rewards: 96.60768, mean: 0.10063
[32m[0906 16-24-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10832, current rewards: 98.48985, mean: 0.09751
[32m[0906 16-24-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10847, current rewards: 104.72063, mean: 0.09879
[32m[0906 16-24-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10862, current rewards: 110.58013, mean: 0.09962
[32m[0906 16-24-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10874, current rewards: 116.44678, mean: 0.10039
[32m[0906 16-24-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10884, current rewards: 122.30418, mean: 0.10108
[32m[0906 16-25-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10897, current rewards: 128.16514, mean: 0.10172
[32m[0906 16-25-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10906, current rewards: 133.76044, mean: 0.10211
[32m[0906 16-25-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10911, current rewards: 140.34022, mean: 0.10319
[32m[0906 16-25-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10907, current rewards: 146.90339, mean: 0.10419
[32m[0906 16-25-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10902, current rewards: 153.47692, mean: 0.10512
[32m[0906 16-25-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10897, current rewards: 159.53829, mean: 0.10565
[32m[0906 16-25-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10893, current rewards: 165.30503, mean: 0.10596
[32m[0906 16-25-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10888, current rewards: 171.06767, mean: 0.10625
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10884, current rewards: 176.83224, mean: 0.10653
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10880, current rewards: 182.60863, mean: 0.10679
[32m[0906 16-25-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10876, current rewards: 188.37466, mean: 0.10703
[32m[0906 16-26-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10872, current rewards: 194.14148, mean: 0.10726
[32m[0906 16-26-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10870, current rewards: 189.34008, mean: 0.10180
[32m[0906 16-26-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10867, current rewards: 194.44835, mean: 0.10181
[32m[0906 16-26-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10864, current rewards: 199.50906, mean: 0.10179
[32m[0906 16-26-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10863, current rewards: 204.57206, mean: 0.10178
[32m[0906 16-26-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10860, current rewards: 209.63479, mean: 0.10176
[32m[0906 16-26-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10863, current rewards: 214.69651, mean: 0.10175
[32m[0906 16-26-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10862, current rewards: 219.75140, mean: 0.10174
[32m[0906 16-26-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10859, current rewards: 224.81380, mean: 0.10173
[32m[0906 16-26-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10857, current rewards: 230.17638, mean: 0.10185
[32m[0906 16-26-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10856, current rewards: 235.95112, mean: 0.10214
[32m[0906 16-27-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10853, current rewards: 242.01986, mean: 0.10255
[32m[0906 16-27-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10851, current rewards: 242.58633, mean: 0.10066
[32m[0906 16-27-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10849, current rewards: 248.43193, mean: 0.10099
[32m[0906 16-27-17 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 16-27-17 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-27-17 @MBExp.py:227][0m Rewards obtained: [253.1074410482161], Lows: [10], Highs: [15], Total time: 8810.503456000002
[32m[0906 16-28-32 @MBExp.py:144][0m ####################################################################
[32m[0906 16-28-32 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 16-28-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10279, current rewards: -5.68582, mean: -0.56858
[32m[0906 16-28-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10394, current rewards: -0.61722, mean: -0.01029
[32m[0906 16-28-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10414, current rewards: 4.83512, mean: 0.04396
[32m[0906 16-28-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10416, current rewards: 10.28590, mean: 0.06429
[32m[0906 16-28-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10491, current rewards: 16.31613, mean: 0.07770
[32m[0906 16-28-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10557, current rewards: 21.74921, mean: 0.08365
[32m[0906 16-29-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10580, current rewards: 27.17883, mean: 0.08767
[32m[0906 16-29-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10607, current rewards: 32.61449, mean: 0.09060
[32m[0906 16-29-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10630, current rewards: 38.04252, mean: 0.09279
[32m[0906 16-29-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10642, current rewards: 43.47692, mean: 0.09452
[32m[0906 16-29-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10648, current rewards: 48.91378, mean: 0.09591
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10666, current rewards: 54.34668, mean: 0.09705
[32m[0906 16-29-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10676, current rewards: 49.45682, mean: 0.08108
[32m[0906 16-29-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10682, current rewards: 55.07286, mean: 0.08344
[32m[0906 16-29-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10716, current rewards: 60.69076, mean: 0.08548
[32m[0906 16-29-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10743, current rewards: 66.30646, mean: 0.08725
[32m[0906 16-29-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10767, current rewards: 71.92423, mean: 0.08880
[32m[0906 16-30-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10790, current rewards: 77.54235, mean: 0.09017
[32m[0906 16-30-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10808, current rewards: 83.15550, mean: 0.09138
[32m[0906 16-30-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10822, current rewards: 88.77016, mean: 0.09247
[32m[0906 16-30-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10839, current rewards: 88.84372, mean: 0.08796
[32m[0906 16-30-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10852, current rewards: 94.28491, mean: 0.08895
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10865, current rewards: 99.72810, mean: 0.08985
[32m[0906 16-30-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10879, current rewards: 105.17725, mean: 0.09067
[32m[0906 16-30-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10889, current rewards: 100.36584, mean: 0.08295
[32m[0906 16-30-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10898, current rewards: 106.13955, mean: 0.08424
[32m[0906 16-30-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10909, current rewards: 111.91663, mean: 0.08543
[32m[0906 16-31-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10907, current rewards: 117.69314, mean: 0.08654
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10901, current rewards: 123.46688, mean: 0.08757
[32m[0906 16-31-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10897, current rewards: 129.24605, mean: 0.08852
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10891, current rewards: 135.01944, mean: 0.08942
[32m[0906 16-31-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10887, current rewards: 140.80023, mean: 0.09026
[32m[0906 16-31-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10885, current rewards: 146.57668, mean: 0.09104
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10880, current rewards: 152.35462, mean: 0.09178
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10877, current rewards: 152.59715, mean: 0.08924
[32m[0906 16-31-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10874, current rewards: 158.19380, mean: 0.08988
[32m[0906 16-31-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10871, current rewards: 163.95536, mean: 0.09058
[32m[0906 16-31-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10870, current rewards: 169.63284, mean: 0.09120
[32m[0906 16-32-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10867, current rewards: 175.20926, mean: 0.09173
[32m[0906 16-32-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10864, current rewards: 170.75684, mean: 0.08712
[32m[0906 16-32-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10862, current rewards: 178.61638, mean: 0.08886
[32m[0906 16-32-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10858, current rewards: 186.47592, mean: 0.09052
[32m[0906 16-32-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10860, current rewards: 194.33546, mean: 0.09210
[32m[0906 16-32-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10858, current rewards: 170.95085, mean: 0.07914
[32m[0906 16-32-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10856, current rewards: 120.95085, mean: 0.05473
[32m[0906 16-32-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10854, current rewards: 70.95085, mean: 0.03139
[32m[0906 16-32-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10852, current rewards: 20.95085, mean: 0.00907
[32m[0906 16-32-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10850, current rewards: -29.04915, mean: -0.01231
[32m[0906 16-32-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10848, current rewards: -79.04915, mean: -0.03280
[32m[0906 16-32-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10847, current rewards: -129.04915, mean: -0.05246
[32m[0906 16-33-04 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-33-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-33-04 @MBExp.py:227][0m Rewards obtained: [-169.04915386494685], Lows: [16], Highs: [383], Total time: 9082.355863000003
[32m[0906 16-34-21 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-21 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 16-34-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10387, current rewards: -4.40797, mean: -0.44080
[32m[0906 16-34-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10415, current rewards: 0.34110, mean: 0.00569
[32m[0906 16-34-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10446, current rewards: 5.08994, mean: 0.04627
[32m[0906 16-34-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10447, current rewards: 9.83791, mean: 0.06149
[32m[0906 16-34-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10525, current rewards: 14.58726, mean: 0.06946
[32m[0906 16-34-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10587, current rewards: 19.33509, mean: 0.07437
[32m[0906 16-34-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10616, current rewards: 24.08546, mean: 0.07770
[32m[0906 16-34-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10636, current rewards: 28.83292, mean: 0.08009
[32m[0906 16-35-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10662, current rewards: 33.58120, mean: 0.08191
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10668, current rewards: 38.32697, mean: 0.08332
[32m[0906 16-35-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10677, current rewards: 43.07715, mean: 0.08446
[32m[0906 16-35-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10691, current rewards: 48.05424, mean: 0.08581
[32m[0906 16-35-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10695, current rewards: 53.00189, mean: 0.08689
[32m[0906 16-35-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10710, current rewards: 48.41372, mean: 0.07335
[32m[0906 16-35-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10743, current rewards: 54.54741, mean: 0.07683
[32m[0906 16-35-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10768, current rewards: 60.68017, mean: 0.07984
[32m[0906 16-35-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10791, current rewards: 66.81424, mean: 0.08249
[32m[0906 16-35-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10810, current rewards: 72.94407, mean: 0.08482
[32m[0906 16-36-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10829, current rewards: 79.07803, mean: 0.08690
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10842, current rewards: 85.21362, mean: 0.08876
[32m[0906 16-36-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10859, current rewards: 91.02035, mean: 0.09012
[32m[0906 16-36-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10873, current rewards: 97.11516, mean: 0.09162
[32m[0906 16-36-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10885, current rewards: 103.20631, mean: 0.09298
[32m[0906 16-36-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10898, current rewards: 109.30579, mean: 0.09423
[32m[0906 16-36-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10909, current rewards: 109.77736, mean: 0.09073
[32m[0906 16-36-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10919, current rewards: 115.16943, mean: 0.09140
[32m[0906 16-36-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10928, current rewards: 120.45012, mean: 0.09195
[32m[0906 16-36-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10923, current rewards: 125.72859, mean: 0.09245
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10919, current rewards: 131.75437, mean: 0.09344
[32m[0906 16-37-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10916, current rewards: 137.05613, mean: 0.09387
[32m[0906 16-37-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10912, current rewards: 142.35338, mean: 0.09427
[32m[0906 16-37-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10908, current rewards: 147.65539, mean: 0.09465
[32m[0906 16-37-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10903, current rewards: 152.95561, mean: 0.09500
[32m[0906 16-37-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10900, current rewards: 158.01152, mean: 0.09519
[32m[0906 16-37-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10898, current rewards: 163.10084, mean: 0.09538
[32m[0906 16-37-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10898, current rewards: 168.18798, mean: 0.09556
[32m[0906 16-37-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10894, current rewards: 173.30199, mean: 0.09575
[32m[0906 16-37-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10891, current rewards: 178.30772, mean: 0.09586
[32m[0906 16-37-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10886, current rewards: 183.54618, mean: 0.09610
[32m[0906 16-37-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10882, current rewards: 188.78570, mean: 0.09632
[32m[0906 16-38-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10880, current rewards: 194.02470, mean: 0.09653
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10877, current rewards: 199.26775, mean: 0.09673
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10875, current rewards: 193.58352, mean: 0.09175
[32m[0906 16-38-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10873, current rewards: 199.37875, mean: 0.09230
[32m[0906 16-38-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10869, current rewards: 206.01258, mean: 0.09322
[32m[0906 16-38-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10867, current rewards: 214.31269, mean: 0.09483
[32m[0906 16-38-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10869, current rewards: 222.61281, mean: 0.09637
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10868, current rewards: 230.91293, mean: 0.09784
[32m[0906 16-38-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10868, current rewards: 239.21305, mean: 0.09926
[32m[0906 16-38-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10868, current rewards: 247.51317, mean: 0.10062
[32m[0906 16-38-53 @Agent.py:117][0m Average action selection time: 0.1087
[32m[0906 16-38-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-38-54 @MBExp.py:227][0m Rewards obtained: [254.1532696718343], Lows: [11], Highs: [10], Total time: 9354.780781000003
[32m[0906 16-40-13 @MBExp.py:144][0m ####################################################################
[32m[0906 16-40-13 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 16-40-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10419, current rewards: -4.47630, mean: -0.44763
[32m[0906 16-40-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10417, current rewards: 0.88249, mean: 0.01471
[32m[0906 16-40-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10428, current rewards: 6.12309, mean: 0.05566
[32m[0906 16-40-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10425, current rewards: 11.03519, mean: 0.06897
[32m[0906 16-40-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10502, current rewards: 16.29836, mean: 0.07761
[32m[0906 16-40-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10558, current rewards: 21.56211, mean: 0.08293
[32m[0906 16-40-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10581, current rewards: 26.82134, mean: 0.08652
[32m[0906 16-40-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10599, current rewards: 32.08604, mean: 0.08913
[32m[0906 16-40-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10624, current rewards: 37.34815, mean: 0.09109
[32m[0906 16-41-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10637, current rewards: 42.61684, mean: 0.09265
[32m[0906 16-41-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10646, current rewards: 47.88744, mean: 0.09390
[32m[0906 16-41-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10660, current rewards: 53.15251, mean: 0.09492
[32m[0906 16-41-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10668, current rewards: 58.42396, mean: 0.09578
[32m[0906 16-41-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10687, current rewards: 63.68934, mean: 0.09650
[32m[0906 16-41-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10720, current rewards: 68.95485, mean: 0.09712
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10746, current rewards: 62.78724, mean: 0.08261
[32m[0906 16-41-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10771, current rewards: 68.26179, mean: 0.08427
[32m[0906 16-41-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10795, current rewards: 73.73950, mean: 0.08574
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10815, current rewards: 79.21445, mean: 0.08705
[32m[0906 16-41-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10835, current rewards: 85.54773, mean: 0.08911
[32m[0906 16-42-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10851, current rewards: 91.06134, mean: 0.09016
[32m[0906 16-42-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10865, current rewards: 96.56930, mean: 0.09110
[32m[0906 16-42-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10882, current rewards: 102.08206, mean: 0.09197
[32m[0906 16-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10894, current rewards: 107.59363, mean: 0.09275
[32m[0906 16-42-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10903, current rewards: 112.91056, mean: 0.09331
[32m[0906 16-42-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10914, current rewards: 118.40194, mean: 0.09397
[32m[0906 16-42-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10918, current rewards: 123.89228, mean: 0.09457
[32m[0906 16-42-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10912, current rewards: 129.55566, mean: 0.09526
[32m[0906 16-42-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10907, current rewards: 135.06738, mean: 0.09579
[32m[0906 16-42-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10900, current rewards: 140.58712, mean: 0.09629
[32m[0906 16-42-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10895, current rewards: 146.10421, mean: 0.09676
[32m[0906 16-43-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10893, current rewards: 141.34697, mean: 0.09061
[32m[0906 16-43-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10887, current rewards: 147.20951, mean: 0.09143
[32m[0906 16-43-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10883, current rewards: 153.07033, mean: 0.09221
[32m[0906 16-43-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10880, current rewards: 158.93247, mean: 0.09294
[32m[0906 16-43-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10876, current rewards: 154.04664, mean: 0.08753
[32m[0906 16-43-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10873, current rewards: 159.06512, mean: 0.08788
[32m[0906 16-43-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10871, current rewards: 164.51746, mean: 0.08845
[32m[0906 16-43-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10868, current rewards: 169.96757, mean: 0.08899
[32m[0906 16-43-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10865, current rewards: 175.42422, mean: 0.08950
[32m[0906 16-43-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10864, current rewards: 174.55229, mean: 0.08684
[32m[0906 16-43-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10861, current rewards: 175.74554, mean: 0.08531
[32m[0906 16-44-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10857, current rewards: 181.21703, mean: 0.08588
[32m[0906 16-44-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10855, current rewards: 186.68425, mean: 0.08643
[32m[0906 16-44-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10853, current rewards: 191.88670, mean: 0.08683
[32m[0906 16-44-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10849, current rewards: 197.29856, mean: 0.08730
[32m[0906 16-44-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10848, current rewards: 202.70897, mean: 0.08775
[32m[0906 16-44-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10845, current rewards: 208.11895, mean: 0.08819
[32m[0906 16-44-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10843, current rewards: 213.53127, mean: 0.08860
[32m[0906 16-44-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10842, current rewards: 213.47852, mean: 0.08678
[32m[0906 16-44-45 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-44-45 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-44-45 @MBExp.py:227][0m Rewards obtained: [217.8220703185882], Lows: [20], Highs: [11], Total time: 9626.524965000002
[32m[0906 16-46-07 @MBExp.py:144][0m ####################################################################
[32m[0906 16-46-07 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 16-46-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10394, current rewards: -5.21971, mean: -0.52197
[32m[0906 16-46-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10430, current rewards: 1.40187, mean: 0.02336
[32m[0906 16-46-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10394, current rewards: 7.14555, mean: 0.06496
[32m[0906 16-46-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10389, current rewards: 12.57687, mean: 0.07861
[32m[0906 16-46-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10481, current rewards: 18.38582, mean: 0.08755
[32m[0906 16-46-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10527, current rewards: 24.19665, mean: 0.09306
[32m[0906 16-46-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10563, current rewards: 30.00580, mean: 0.09679
[32m[0906 16-46-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10599, current rewards: 35.81684, mean: 0.09949
[32m[0906 16-46-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10621, current rewards: 31.03174, mean: 0.07569
[32m[0906 16-46-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10632, current rewards: 37.13042, mean: 0.08072
[32m[0906 16-47-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10649, current rewards: 43.22951, mean: 0.08476
[32m[0906 16-47-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10653, current rewards: 49.37661, mean: 0.08817
[32m[0906 16-47-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10657, current rewards: 55.46764, mean: 0.09093
[32m[0906 16-47-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10688, current rewards: 61.56165, mean: 0.09328
[32m[0906 16-47-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10722, current rewards: 67.65329, mean: 0.09529
[32m[0906 16-47-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10750, current rewards: 73.74894, mean: 0.09704
[32m[0906 16-47-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10780, current rewards: 79.84505, mean: 0.09857
[32m[0906 16-47-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10801, current rewards: 85.93603, mean: 0.09993
[32m[0906 16-47-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10818, current rewards: 92.02063, mean: 0.10112
[32m[0906 16-47-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10835, current rewards: 99.03682, mean: 0.10316
[32m[0906 16-47-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10850, current rewards: 100.56654, mean: 0.09957
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10865, current rewards: 105.39231, mean: 0.09943
[32m[0906 16-48-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10876, current rewards: 110.75076, mean: 0.09978
[32m[0906 16-48-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10886, current rewards: 116.11052, mean: 0.10010
[32m[0906 16-48-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10897, current rewards: 121.46399, mean: 0.10038
[32m[0906 16-48-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10906, current rewards: 126.82223, mean: 0.10065
[32m[0906 16-48-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10903, current rewards: 132.18271, mean: 0.10090
[32m[0906 16-48-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10900, current rewards: 137.35597, mean: 0.10100
[32m[0906 16-48-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10897, current rewards: 142.74049, mean: 0.10123
[32m[0906 16-48-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10891, current rewards: 148.12387, mean: 0.10145
[32m[0906 16-48-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10886, current rewards: 153.50429, mean: 0.10166
[32m[0906 16-48-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10882, current rewards: 148.50871, mean: 0.09520
[32m[0906 16-49-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10877, current rewards: 154.29412, mean: 0.09583
[32m[0906 16-49-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10875, current rewards: 160.07456, mean: 0.09643
[32m[0906 16-49-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10871, current rewards: 165.85550, mean: 0.09699
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10868, current rewards: 171.41344, mean: 0.09739
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10867, current rewards: 177.08904, mean: 0.09784
[32m[0906 16-49-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10863, current rewards: 182.91574, mean: 0.09834
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10859, current rewards: 188.75636, mean: 0.09883
[32m[0906 16-49-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10857, current rewards: 194.58169, mean: 0.09928
[32m[0906 16-49-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10854, current rewards: 200.41645, mean: 0.09971
[32m[0906 16-49-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10849, current rewards: 206.24972, mean: 0.10012
[32m[0906 16-49-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10846, current rewards: 212.08444, mean: 0.10051
[32m[0906 16-50-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10843, current rewards: 217.92362, mean: 0.10089
[32m[0906 16-50-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10842, current rewards: 223.86067, mean: 0.10129
[32m[0906 16-50-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10843, current rewards: 229.56138, mean: 0.10158
[32m[0906 16-50-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10841, current rewards: 235.28530, mean: 0.10186
[32m[0906 16-50-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10839, current rewards: 241.01120, mean: 0.10212
[32m[0906 16-50-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10839, current rewards: 246.73378, mean: 0.10238
[32m[0906 16-50-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10837, current rewards: 252.45032, mean: 0.10262
[32m[0906 16-50-38 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 16-50-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-50-38 @MBExp.py:227][0m Rewards obtained: [257.0232557167919], Lows: [10], Highs: [11], Total time: 9898.125981000003
[32m[0906 16-52-02 @MBExp.py:144][0m ####################################################################
[32m[0906 16-52-02 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 16-52-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10268, current rewards: -5.69647, mean: -0.56965
[32m[0906 16-52-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10384, current rewards: 0.04563, mean: 0.00076
[32m[0906 16-52-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10393, current rewards: 5.90894, mean: 0.05372
[32m[0906 16-52-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10415, current rewards: 11.49850, mean: 0.07187
[32m[0906 16-52-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10497, current rewards: 17.08084, mean: 0.08134
[32m[0906 16-52-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10543, current rewards: 22.66343, mean: 0.08717
[32m[0906 16-52-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10586, current rewards: 28.24578, mean: 0.09112
[32m[0906 16-52-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10608, current rewards: 33.83264, mean: 0.09398
[32m[0906 16-52-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10628, current rewards: 39.42005, mean: 0.09615
[32m[0906 16-52-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10647, current rewards: 45.01098, mean: 0.09785
[32m[0906 16-52-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10654, current rewards: 51.56955, mean: 0.10112
[32m[0906 16-53-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10662, current rewards: 51.67731, mean: 0.09228
[32m[0906 16-53-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10675, current rewards: 57.09767, mean: 0.09360
[32m[0906 16-53-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10707, current rewards: 62.51875, mean: 0.09473
[32m[0906 16-53-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10737, current rewards: 67.94782, mean: 0.09570
[32m[0906 16-53-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10767, current rewards: 73.36282, mean: 0.09653
[32m[0906 16-53-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10791, current rewards: 78.78366, mean: 0.09726
[32m[0906 16-53-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10811, current rewards: 84.20068, mean: 0.09791
[32m[0906 16-53-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10829, current rewards: 89.61941, mean: 0.09848
[32m[0906 16-53-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10844, current rewards: 98.20786, mean: 0.10230
[32m[0906 16-53-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10861, current rewards: 103.83319, mean: 0.10281
[32m[0906 16-53-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10872, current rewards: 109.46592, mean: 0.10327
[32m[0906 16-54-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10885, current rewards: 115.08953, mean: 0.10368
[32m[0906 16-54-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10897, current rewards: 120.71201, mean: 0.10406
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10907, current rewards: 126.33907, mean: 0.10441
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10912, current rewards: 131.96793, mean: 0.10474
[32m[0906 16-54-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10908, current rewards: 127.20971, mean: 0.09711
[32m[0906 16-54-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10904, current rewards: 132.67422, mean: 0.09755
[32m[0906 16-54-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10900, current rewards: 138.36034, mean: 0.09813
[32m[0906 16-54-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10898, current rewards: 144.04923, mean: 0.09866
[32m[0906 16-54-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10895, current rewards: 149.73895, mean: 0.09916
[32m[0906 16-54-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10891, current rewards: 155.43174, mean: 0.09964
[32m[0906 16-54-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10889, current rewards: 161.12277, mean: 0.10008
[32m[0906 16-55-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10886, current rewards: 166.81229, mean: 0.10049
[32m[0906 16-55-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10883, current rewards: 172.50155, mean: 0.10088
[32m[0906 16-55-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10881, current rewards: 178.18595, mean: 0.10124
[32m[0906 16-55-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10879, current rewards: 183.87849, mean: 0.10159
[32m[0906 16-55-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10877, current rewards: 179.21207, mean: 0.09635
[32m[0906 16-55-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10876, current rewards: 184.65984, mean: 0.09668
[32m[0906 16-55-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10874, current rewards: 190.10708, mean: 0.09699
[32m[0906 16-55-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10872, current rewards: 195.55302, mean: 0.09729
[32m[0906 16-55-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10866, current rewards: 200.99825, mean: 0.09757
[32m[0906 16-55-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10862, current rewards: 206.44807, mean: 0.09784
[32m[0906 16-55-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10859, current rewards: 212.64259, mean: 0.09845
[32m[0906 16-56-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10858, current rewards: 218.27523, mean: 0.09877
[32m[0906 16-56-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10856, current rewards: 223.90775, mean: 0.09907
[32m[0906 16-56-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10854, current rewards: 223.02211, mean: 0.09655
[32m[0906 16-56-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10853, current rewards: 228.91540, mean: 0.09700
[32m[0906 16-56-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10851, current rewards: 234.80511, mean: 0.09743
[32m[0906 16-56-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10850, current rewards: 240.69768, mean: 0.09784
[32m[0906 16-56-34 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 16-56-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 16-56-34 @MBExp.py:227][0m Rewards obtained: [245.41110141568478], Lows: [10], Highs: [17], Total time: 10170.108171000003
[32m[0906 16-58-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-58-01 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 16-58-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10312, current rewards: -5.45870, mean: -0.54587
[32m[0906 16-58-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10458, current rewards: 0.19095, mean: 0.00318
[32m[0906 16-58-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10414, current rewards: 5.61489, mean: 0.05104
[32m[0906 16-58-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10416, current rewards: 11.03815, mean: 0.06899
[32m[0906 16-58-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10502, current rewards: 16.46392, mean: 0.07840
[32m[0906 16-58-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10551, current rewards: 21.88635, mean: 0.08418
[32m[0906 16-58-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10587, current rewards: 27.30954, mean: 0.08810
[32m[0906 16-58-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10613, current rewards: 32.95457, mean: 0.09154
[32m[0906 16-58-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10631, current rewards: 38.27048, mean: 0.09334
[32m[0906 16-58-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10642, current rewards: 43.79817, mean: 0.09521
[32m[0906 16-58-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10656, current rewards: 49.13363, mean: 0.09634
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10664, current rewards: 54.46127, mean: 0.09725
[32m[0906 16-59-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10673, current rewards: 59.78688, mean: 0.09801
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10711, current rewards: 65.12058, mean: 0.09867
[32m[0906 16-59-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10740, current rewards: 70.44875, mean: 0.09922
[32m[0906 16-59-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10760, current rewards: 75.77610, mean: 0.09971
[32m[0906 16-59-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10787, current rewards: 71.57969, mean: 0.08837
[32m[0906 16-59-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10806, current rewards: 77.01092, mean: 0.08955
[32m[0906 16-59-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10824, current rewards: 82.71667, mean: 0.09090
[32m[0906 16-59-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10841, current rewards: 88.39538, mean: 0.09208
[32m[0906 16-59-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10855, current rewards: 94.07033, mean: 0.09314
[32m[0906 16-59-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10866, current rewards: 99.74886, mean: 0.09410
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10880, current rewards: 105.42965, mean: 0.09498
[32m[0906 17-00-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10889, current rewards: 111.11287, mean: 0.09579
[32m[0906 17-00-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10899, current rewards: 116.79349, mean: 0.09652
[32m[0906 17-00-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10897, current rewards: 122.38888, mean: 0.09713
[32m[0906 17-00-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10890, current rewards: 128.06417, mean: 0.09776
[32m[0906 17-00-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10886, current rewards: 133.75737, mean: 0.09835
[32m[0906 17-00-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10880, current rewards: 127.09348, mean: 0.09014
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10874, current rewards: 133.04255, mean: 0.09113
[32m[0906 17-00-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10873, current rewards: 138.99117, mean: 0.09205
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10868, current rewards: 144.93775, mean: 0.09291
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10862, current rewards: 150.88466, mean: 0.09372
[32m[0906 17-01-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10858, current rewards: 156.84456, mean: 0.09448
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10854, current rewards: 163.40091, mean: 0.09556
[32m[0906 17-01-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10850, current rewards: 169.43176, mean: 0.09627
[32m[0906 17-01-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10848, current rewards: 175.46181, mean: 0.09694
[32m[0906 17-01-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10846, current rewards: 181.49357, mean: 0.09758
[32m[0906 17-01-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10842, current rewards: 187.52468, mean: 0.09818
[32m[0906 17-01-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10843, current rewards: 193.55575, mean: 0.09875
[32m[0906 17-01-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10839, current rewards: 187.01220, mean: 0.09304
[32m[0906 17-01-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10830, current rewards: 192.59649, mean: 0.09349
[32m[0906 17-01-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10828, current rewards: 198.01554, mean: 0.09385
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10825, current rewards: 203.60611, mean: 0.09426
[32m[0906 17-02-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10824, current rewards: 198.68890, mean: 0.08990
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10823, current rewards: 204.15064, mean: 0.09033
[32m[0906 17-02-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10822, current rewards: 209.50586, mean: 0.09070
[32m[0906 17-02-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10821, current rewards: 214.85721, mean: 0.09104
[32m[0906 17-02-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10820, current rewards: 220.21312, mean: 0.09137
[32m[0906 17-02-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10818, current rewards: 225.56399, mean: 0.09169
[32m[0906 17-02-32 @Agent.py:117][0m Average action selection time: 0.1082
[32m[0906 17-02-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-02-32 @MBExp.py:227][0m Rewards obtained: [230.4878525342703], Lows: [19], Highs: [12], Total time: 10441.258373000004
[32m[0906 17-04-00 @MBExp.py:144][0m ####################################################################
[32m[0906 17-04-00 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10266, current rewards: -6.42810, mean: -0.64281
[32m[0906 17-04-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10356, current rewards: -0.23141, mean: -0.00386
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10392, current rewards: 5.46869, mean: 0.04972
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10411, current rewards: 11.17011, mean: 0.06981
[32m[0906 17-04-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10501, current rewards: 6.80720, mean: 0.03242
[32m[0906 17-04-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10554, current rewards: 13.15000, mean: 0.05058
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10588, current rewards: 19.43416, mean: 0.06269
[32m[0906 17-04-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10615, current rewards: 25.71368, mean: 0.07143
[32m[0906 17-04-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10637, current rewards: 31.81537, mean: 0.07760
[32m[0906 17-04-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10650, current rewards: 37.81341, mean: 0.08220
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10660, current rewards: 44.38161, mean: 0.08702
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10678, current rewards: 45.19580, mean: 0.08071
[32m[0906 17-05-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10696, current rewards: 50.83343, mean: 0.08333
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10733, current rewards: 56.48349, mean: 0.08558
[32m[0906 17-05-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10769, current rewards: 62.13109, mean: 0.08751
[32m[0906 17-05-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10797, current rewards: 67.77169, mean: 0.08917
[32m[0906 17-05-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10823, current rewards: 73.41834, mean: 0.09064
[32m[0906 17-05-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10845, current rewards: 74.83044, mean: 0.08701
[32m[0906 17-05-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10862, current rewards: 80.74012, mean: 0.08873
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10874, current rewards: 86.41279, mean: 0.09001
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10890, current rewards: 92.08730, mean: 0.09118
[32m[0906 17-05-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10900, current rewards: 97.75693, mean: 0.09222
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10911, current rewards: 103.43014, mean: 0.09318
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10921, current rewards: 109.10291, mean: 0.09405
[32m[0906 17-06-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10928, current rewards: 114.78194, mean: 0.09486
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10923, current rewards: 120.09262, mean: 0.09531
[32m[0906 17-06-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10917, current rewards: 125.81322, mean: 0.09604
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10910, current rewards: 129.40935, mean: 0.09515
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10905, current rewards: 136.20662, mean: 0.09660
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10898, current rewards: 142.88271, mean: 0.09786
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10892, current rewards: 149.54767, mean: 0.09904
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10890, current rewards: 156.22344, mean: 0.10014
[32m[0906 17-06-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10886, current rewards: 162.89902, mean: 0.10118
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10881, current rewards: 170.16551, mean: 0.10251
[32m[0906 17-07-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10879, current rewards: 176.96689, mean: 0.10349
[32m[0906 17-07-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10875, current rewards: 183.70253, mean: 0.10438
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10872, current rewards: 190.44903, mean: 0.10522
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10871, current rewards: 186.47680, mean: 0.10026
[32m[0906 17-07-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10868, current rewards: 192.07469, mean: 0.10056
[32m[0906 17-07-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10867, current rewards: 197.62702, mean: 0.10083
[32m[0906 17-07-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10864, current rewards: 203.17681, mean: 0.10108
[32m[0906 17-07-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10854, current rewards: 208.72340, mean: 0.10132
[32m[0906 17-07-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10852, current rewards: 213.99392, mean: 0.10142
[32m[0906 17-07-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10851, current rewards: 219.49860, mean: 0.10162
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10850, current rewards: 225.00522, mean: 0.10181
[32m[0906 17-08-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10847, current rewards: 230.51692, mean: 0.10200
[32m[0906 17-08-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10845, current rewards: 236.02665, mean: 0.10218
[32m[0906 17-08-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10843, current rewards: 231.39882, mean: 0.09805
[32m[0906 17-08-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10840, current rewards: 238.09912, mean: 0.09880
[32m[0906 17-08-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10839, current rewards: 244.79382, mean: 0.09951
[32m[0906 17-08-32 @Agent.py:117][0m Average action selection time: 0.1084
[32m[0906 17-08-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-08-32 @MBExp.py:227][0m Rewards obtained: [251.21164253872078], Lows: [16], Highs: [21], Total time: 10712.927352000004
[32m[0906 17-10-02 @MBExp.py:144][0m ####################################################################
[32m[0906 17-10-02 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10273, current rewards: 1.95434, mean: 0.19543
[32m[0906 17-10-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10374, current rewards: 8.02191, mean: 0.13370
[32m[0906 17-10-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10390, current rewards: 14.00609, mean: 0.12733
[32m[0906 17-10-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10442, current rewards: 19.99182, mean: 0.12495
[32m[0906 17-10-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10523, current rewards: 25.97641, mean: 0.12370
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10577, current rewards: 31.96160, mean: 0.12293
[32m[0906 17-10-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10612, current rewards: 37.94795, mean: 0.12241
[32m[0906 17-10-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10626, current rewards: 43.93351, mean: 0.12204
[32m[0906 17-10-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10636, current rewards: 50.45874, mean: 0.12307
[32m[0906 17-10-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10654, current rewards: 58.75886, mean: 0.12774
[32m[0906 17-10-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10661, current rewards: 26.24890, mean: 0.05147
[32m[0906 17-11-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10666, current rewards: -23.75110, mean: -0.04241
[32m[0906 17-11-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10693, current rewards: -73.75110, mean: -0.12090
[32m[0906 17-11-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10723, current rewards: -123.75110, mean: -0.18750
[32m[0906 17-11-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10751, current rewards: -137.36527, mean: -0.19347
[32m[0906 17-11-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10781, current rewards: -132.00949, mean: -0.17370
[32m[0906 17-11-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10800, current rewards: -126.70240, mean: -0.15642
[32m[0906 17-11-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10822, current rewards: -121.45401, mean: -0.14123
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10841, current rewards: -116.03866, mean: -0.12752
[32m[0906 17-11-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10855, current rewards: -110.62070, mean: -0.11523
[32m[0906 17-11-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10871, current rewards: -105.20538, mean: -0.10416
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10885, current rewards: -99.78782, mean: -0.09414
[32m[0906 17-12-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10897, current rewards: -99.65359, mean: -0.08978
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10910, current rewards: -94.06711, mean: -0.08109
[32m[0906 17-12-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10907, current rewards: -88.47587, mean: -0.07312
[32m[0906 17-12-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10901, current rewards: -83.48267, mean: -0.06626
[32m[0906 17-12-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10898, current rewards: -77.89934, mean: -0.05947
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10893, current rewards: -72.31683, mean: -0.05317
[32m[0906 17-12-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10888, current rewards: -66.73274, mean: -0.04733
[32m[0906 17-12-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10886, current rewards: -61.14844, mean: -0.04188
[32m[0906 17-12-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10882, current rewards: -55.56214, mean: -0.03680
[32m[0906 17-12-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10878, current rewards: -49.98048, mean: -0.03204
[32m[0906 17-12-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10876, current rewards: -44.39217, mean: -0.02757
[32m[0906 17-13-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10871, current rewards: -38.12227, mean: -0.02297
[32m[0906 17-13-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10869, current rewards: -31.82591, mean: -0.01861
[32m[0906 17-13-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10867, current rewards: -26.23721, mean: -0.01491
[32m[0906 17-13-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10863, current rewards: -30.81825, mean: -0.01703
[32m[0906 17-13-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10859, current rewards: -25.25854, mean: -0.01358
[32m[0906 17-13-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10859, current rewards: -19.70142, mean: -0.01031
[32m[0906 17-13-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10857, current rewards: -14.14834, mean: -0.00722
[32m[0906 17-13-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10849, current rewards: -18.56291, mean: -0.00924
[32m[0906 17-13-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10840, current rewards: -12.90175, mean: -0.00626
[32m[0906 17-13-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10839, current rewards: -7.38176, mean: -0.00350
[32m[0906 17-13-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10838, current rewards: -1.75948, mean: -0.00081
[32m[0906 17-14-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10838, current rewards: 3.86311, mean: 0.00175
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10836, current rewards: 9.48673, mean: 0.00420
[32m[0906 17-14-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10835, current rewards: 15.11349, mean: 0.00654
[32m[0906 17-14-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10834, current rewards: 20.73882, mean: 0.00879
[32m[0906 17-14-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10833, current rewards: 26.35810, mean: 0.01094
[32m[0906 17-14-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10832, current rewards: 31.98046, mean: 0.01300
[32m[0906 17-14-34 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 17-14-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-14-34 @MBExp.py:227][0m Rewards obtained: [36.28093814439336], Lows: [10], Highs: [207], Total time: 10984.474266000005
[32m[0906 17-16-07 @MBExp.py:144][0m ####################################################################
[32m[0906 17-16-07 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10347, current rewards: -5.55042, mean: -0.55504
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10436, current rewards: 0.10703, mean: 0.00178
[32m[0906 17-16-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10425, current rewards: 5.78671, mean: 0.05261
[32m[0906 17-16-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10470, current rewards: 11.46951, mean: 0.07168
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10538, current rewards: 17.15064, mean: 0.08167
[32m[0906 17-16-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10589, current rewards: 22.82889, mean: 0.08780
[32m[0906 17-16-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10634, current rewards: 28.50541, mean: 0.09195
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10654, current rewards: 34.18691, mean: 0.09496
[32m[0906 17-16-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10670, current rewards: 30.67494, mean: 0.07482
[32m[0906 17-16-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10689, current rewards: 36.17590, mean: 0.07864
[32m[0906 17-17-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10695, current rewards: 41.62882, mean: 0.08163
[32m[0906 17-17-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10706, current rewards: 47.08165, mean: 0.08407
[32m[0906 17-17-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10737, current rewards: 52.53483, mean: 0.08612
[32m[0906 17-17-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10768, current rewards: 57.98757, mean: 0.08786
[32m[0906 17-17-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10792, current rewards: 63.43958, mean: 0.08935
[32m[0906 17-17-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10825, current rewards: 67.78284, mean: 0.08919
[32m[0906 17-17-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10850, current rewards: 67.69618, mean: 0.08358
[32m[0906 17-17-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10875, current rewards: 73.29133, mean: 0.08522
[32m[0906 17-17-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10889, current rewards: 78.91289, mean: 0.08672
[32m[0906 17-17-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10900, current rewards: 84.54250, mean: 0.08807
[32m[0906 17-17-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10911, current rewards: 90.17020, mean: 0.08928
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10920, current rewards: 95.79290, mean: 0.09037
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10927, current rewards: 101.41721, mean: 0.09137
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10933, current rewards: 107.04557, mean: 0.09228
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10924, current rewards: 112.67984, mean: 0.09312
[32m[0906 17-18-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10917, current rewards: 119.02191, mean: 0.09446
[32m[0906 17-18-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10912, current rewards: 124.68413, mean: 0.09518
[32m[0906 17-18-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10904, current rewards: 130.34497, mean: 0.09584
[32m[0906 17-18-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10897, current rewards: 127.55334, mean: 0.09046
[32m[0906 17-18-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10892, current rewards: 131.12533, mean: 0.08981
[32m[0906 17-18-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10887, current rewards: 136.74088, mean: 0.09056
[32m[0906 17-18-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10881, current rewards: 142.35932, mean: 0.09126
[32m[0906 17-19-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10877, current rewards: 147.97685, mean: 0.09191
[32m[0906 17-19-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10872, current rewards: 153.00124, mean: 0.09217
[32m[0906 17-19-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10868, current rewards: 158.67119, mean: 0.09279
[32m[0906 17-19-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10865, current rewards: 164.34371, mean: 0.09338
[32m[0906 17-19-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10861, current rewards: 170.01945, mean: 0.09393
[32m[0906 17-19-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10857, current rewards: 175.69755, mean: 0.09446
[32m[0906 17-19-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10855, current rewards: 181.37103, mean: 0.09496
[32m[0906 17-19-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10851, current rewards: 165.02976, mean: 0.08420
[32m[0906 17-19-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10840, current rewards: 170.72318, mean: 0.08494
[32m[0906 17-19-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10833, current rewards: 176.41736, mean: 0.08564
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10830, current rewards: 182.10860, mean: 0.08631
[32m[0906 17-20-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10828, current rewards: 187.79820, mean: 0.08694
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10828, current rewards: 193.49369, mean: 0.08755
[32m[0906 17-20-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10826, current rewards: 199.18480, mean: 0.08813
[32m[0906 17-20-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10824, current rewards: 204.87056, mean: 0.08869
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10824, current rewards: 208.69639, mean: 0.08843
[32m[0906 17-20-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10823, current rewards: 214.29473, mean: 0.08892
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10820, current rewards: 220.15018, mean: 0.08949
[32m[0906 17-20-38 @Agent.py:117][0m Average action selection time: 0.1082
[32m[0906 17-20-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-20-38 @MBExp.py:227][0m Rewards obtained: [224.9233100064465], Lows: [19], Highs: [20], Total time: 11255.714458000004
[32m[0906 17-22-13 @MBExp.py:144][0m ####################################################################
[32m[0906 17-22-13 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 17-22-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10293, current rewards: -6.46345, mean: -0.64634
[32m[0906 17-22-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10390, current rewards: -0.09788, mean: -0.00163
[32m[0906 17-22-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10401, current rewards: 5.60356, mean: 0.05094
[32m[0906 17-22-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10462, current rewards: 11.29964, mean: 0.07062
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10530, current rewards: 17.00478, mean: 0.08098
[32m[0906 17-22-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10574, current rewards: 22.70645, mean: 0.08733
[32m[0906 17-22-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10606, current rewards: 28.41264, mean: 0.09165
[32m[0906 17-22-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10629, current rewards: 34.11444, mean: 0.09476
[32m[0906 17-22-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10649, current rewards: 40.19492, mean: 0.09804
[32m[0906 17-23-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10666, current rewards: 45.90307, mean: 0.09979
[32m[0906 17-23-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10675, current rewards: 51.60833, mean: 0.10119
[32m[0906 17-23-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10683, current rewards: 57.31317, mean: 0.10234
[32m[0906 17-23-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10722, current rewards: 57.39178, mean: 0.09408
[32m[0906 17-23-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10755, current rewards: 62.98380, mean: 0.09543
[32m[0906 17-23-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10785, current rewards: 68.57540, mean: 0.09659
[32m[0906 17-23-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10809, current rewards: 74.17383, mean: 0.09760
[32m[0906 17-23-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10829, current rewards: 79.65740, mean: 0.09834
[32m[0906 17-23-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10851, current rewards: 85.22801, mean: 0.09910
[32m[0906 17-23-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10865, current rewards: 90.80211, mean: 0.09978
[32m[0906 17-23-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10877, current rewards: 96.37042, mean: 0.10039
[32m[0906 17-24-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10891, current rewards: 101.93871, mean: 0.10093
[32m[0906 17-24-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10904, current rewards: 107.49084, mean: 0.10141
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10911, current rewards: 113.19963, mean: 0.10198
[32m[0906 17-24-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10912, current rewards: 118.90608, mean: 0.10251
[32m[0906 17-24-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10905, current rewards: 125.37960, mean: 0.10362
[32m[0906 17-24-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10897, current rewards: 131.28676, mean: 0.10420
[32m[0906 17-24-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10895, current rewards: 137.00539, mean: 0.10458
[32m[0906 17-24-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10887, current rewards: 142.72855, mean: 0.10495
[32m[0906 17-24-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10881, current rewards: 148.45178, mean: 0.10528
[32m[0906 17-24-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10879, current rewards: 149.94779, mean: 0.10270
[32m[0906 17-24-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10873, current rewards: 151.32696, mean: 0.10022
[32m[0906 17-25-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10868, current rewards: 158.98204, mean: 0.10191
[32m[0906 17-25-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10867, current rewards: 166.63712, mean: 0.10350
[32m[0906 17-25-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10864, current rewards: 128.16814, mean: 0.07721
[32m[0906 17-25-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10860, current rewards: 78.16814, mean: 0.04571
[32m[0906 17-25-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10859, current rewards: 28.16814, mean: 0.01600
[32m[0906 17-25-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10855, current rewards: -21.83186, mean: -0.01206
[32m[0906 17-25-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10851, current rewards: -71.83186, mean: -0.03862
[32m[0906 17-25-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10849, current rewards: -121.83186, mean: -0.06379
[32m[0906 17-25-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10842, current rewards: -171.83186, mean: -0.08767
[32m[0906 17-25-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10831, current rewards: -221.83186, mean: -0.11036
[32m[0906 17-25-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10824, current rewards: -271.83186, mean: -0.13196
[32m[0906 17-26-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10822, current rewards: -321.83186, mean: -0.15253
[32m[0906 17-26-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10819, current rewards: -371.83186, mean: -0.17214
[32m[0906 17-26-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10818, current rewards: -421.83186, mean: -0.19087
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10816, current rewards: -471.83186, mean: -0.20878
[32m[0906 17-26-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10813, current rewards: -521.83186, mean: -0.22590
[32m[0906 17-26-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10813, current rewards: -571.83186, mean: -0.24230
[32m[0906 17-26-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10811, current rewards: -621.83186, mean: -0.25802
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10810, current rewards: -671.83186, mean: -0.27310
[32m[0906 17-26-44 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 17-26-44 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-26-44 @MBExp.py:227][0m Rewards obtained: [-711.8318648278894], Lows: [6], Highs: [892], Total time: 11526.711284000005
[32m[0906 17-28-22 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-22 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10303, current rewards: -7.06788, mean: -0.70679
[32m[0906 17-28-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10398, current rewards: -1.79969, mean: -0.02999
[32m[0906 17-28-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10426, current rewards: 3.10002, mean: 0.02818
[32m[0906 17-28-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10461, current rewards: 7.99891, mean: 0.04999
[32m[0906 17-28-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10541, current rewards: 12.89874, mean: 0.06142
[32m[0906 17-28-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10595, current rewards: 11.60240, mean: 0.04462
[32m[0906 17-28-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10630, current rewards: 16.95746, mean: 0.05470
[32m[0906 17-29-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10648, current rewards: 22.31817, mean: 0.06199
[32m[0906 17-29-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10671, current rewards: 27.86813, mean: 0.06797
[32m[0906 17-29-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10678, current rewards: 33.25426, mean: 0.07229
[32m[0906 17-29-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10687, current rewards: 38.64138, mean: 0.07577
[32m[0906 17-29-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10696, current rewards: 44.02822, mean: 0.07862
[32m[0906 17-29-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10734, current rewards: 49.42243, mean: 0.08102
[32m[0906 17-29-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10764, current rewards: 54.81055, mean: 0.08305
[32m[0906 17-29-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10793, current rewards: 49.59967, mean: 0.06986
[32m[0906 17-29-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10815, current rewards: 55.05724, mean: 0.07244
[32m[0906 17-29-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10833, current rewards: 61.02440, mean: 0.07534
[32m[0906 17-29-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10853, current rewards: 66.55837, mean: 0.07739
[32m[0906 17-30-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10869, current rewards: 66.49766, mean: 0.07307
[32m[0906 17-30-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10887, current rewards: 72.32808, mean: 0.07534
[32m[0906 17-30-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10899, current rewards: 78.15415, mean: 0.07738
[32m[0906 17-30-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10911, current rewards: 83.98368, mean: 0.07923
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10917, current rewards: 84.06874, mean: 0.07574
[32m[0906 17-30-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10913, current rewards: 89.46685, mean: 0.07713
[32m[0906 17-30-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10906, current rewards: 94.66293, mean: 0.07823
[32m[0906 17-30-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10903, current rewards: 100.05131, mean: 0.07941
[32m[0906 17-30-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10898, current rewards: 105.42588, mean: 0.08048
[32m[0906 17-30-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10893, current rewards: 110.66069, mean: 0.08137
[32m[0906 17-30-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10892, current rewards: 115.99863, mean: 0.08227
[32m[0906 17-31-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10886, current rewards: 121.32398, mean: 0.08310
[32m[0906 17-31-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10883, current rewards: 126.66257, mean: 0.08388
[32m[0906 17-31-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10880, current rewards: 131.99866, mean: 0.08461
[32m[0906 17-31-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10877, current rewards: 137.31414, mean: 0.08529
[32m[0906 17-31-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10871, current rewards: 142.64569, mean: 0.08593
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10870, current rewards: 147.97486, mean: 0.08654
[32m[0906 17-31-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10868, current rewards: 153.30987, mean: 0.08711
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10865, current rewards: 158.63718, mean: 0.08764
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10863, current rewards: 153.45907, mean: 0.08250
[32m[0906 17-31-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10861, current rewards: 158.93008, mean: 0.08321
[32m[0906 17-31-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10849, current rewards: 164.40147, mean: 0.08388
[32m[0906 17-32-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10839, current rewards: 169.83641, mean: 0.08450
[32m[0906 17-32-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10833, current rewards: 164.45913, mean: 0.07983
[32m[0906 17-32-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10832, current rewards: 169.35296, mean: 0.08026
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10832, current rewards: 174.24708, mean: 0.08067
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10831, current rewards: 179.14114, mean: 0.08106
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10829, current rewards: 184.03660, mean: 0.08143
[32m[0906 17-32-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10829, current rewards: 188.92941, mean: 0.08179
[32m[0906 17-32-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10829, current rewards: 193.82388, mean: 0.08213
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10827, current rewards: 198.71842, mean: 0.08246
[32m[0906 17-32-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10827, current rewards: 203.61415, mean: 0.08277
[32m[0906 17-32-53 @Agent.py:117][0m Average action selection time: 0.1083
[32m[0906 17-32-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-32-54 @MBExp.py:227][0m Rewards obtained: [207.52840524415748], Lows: [17], Highs: [20], Total time: 11798.129714000004
[32m[0906 17-34-34 @MBExp.py:144][0m ####################################################################
[32m[0906 17-34-34 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 17-34-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10301, current rewards: -3.97445, mean: -0.39745
[32m[0906 17-34-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10425, current rewards: 1.90520, mean: 0.03175
[32m[0906 17-34-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10413, current rewards: 7.49527, mean: 0.06814
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10421, current rewards: 13.08847, mean: 0.08180
[32m[0906 17-34-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10427, current rewards: 18.68125, mean: 0.08896
[32m[0906 17-35-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10421, current rewards: 24.26719, mean: 0.09334
[32m[0906 17-35-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10429, current rewards: 29.85720, mean: 0.09631
[32m[0906 17-35-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10441, current rewards: 24.98397, mean: 0.06940
[32m[0906 17-35-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10446, current rewards: 30.66891, mean: 0.07480
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10481, current rewards: 36.35630, mean: 0.07904
[32m[0906 17-35-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10513, current rewards: 42.04527, mean: 0.08244
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10539, current rewards: 47.73021, mean: 0.08523
[32m[0906 17-35-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10590, current rewards: 53.41535, mean: 0.08757
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10636, current rewards: 59.10403, mean: 0.08955
[32m[0906 17-35-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10676, current rewards: 64.78764, mean: 0.09125
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10708, current rewards: 71.05695, mean: 0.09350
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10741, current rewards: 76.70685, mean: 0.09470
[32m[0906 17-36-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10765, current rewards: 82.36387, mean: 0.09577
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10790, current rewards: 82.50585, mean: 0.09067
[32m[0906 17-36-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10811, current rewards: 87.84670, mean: 0.09151
[32m[0906 17-36-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10827, current rewards: 93.19280, mean: 0.09227
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10844, current rewards: 98.54114, mean: 0.09296
[32m[0906 17-36-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10842, current rewards: 93.49744, mean: 0.08423
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10839, current rewards: 99.36742, mean: 0.08566
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10841, current rewards: 105.38682, mean: 0.08710
[32m[0906 17-36-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10839, current rewards: 111.14865, mean: 0.08821
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10838, current rewards: 116.91289, mean: 0.08925
[32m[0906 17-37-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10838, current rewards: 122.67397, mean: 0.09020
[32m[0906 17-37-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10836, current rewards: 123.06199, mean: 0.08728
[32m[0906 17-37-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10835, current rewards: 128.72867, mean: 0.08817
[32m[0906 17-37-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10837, current rewards: 134.39777, mean: 0.08901
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10836, current rewards: 140.05764, mean: 0.08978
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10835, current rewards: 145.07416, mean: 0.09011
[32m[0906 17-37-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10840, current rewards: 150.70287, mean: 0.09078
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10840, current rewards: 156.33022, mean: 0.09142
[32m[0906 17-37-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10837, current rewards: 161.97286, mean: 0.09203
[32m[0906 17-37-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10836, current rewards: 167.60866, mean: 0.09260
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10835, current rewards: 173.24505, mean: 0.09314
[32m[0906 17-38-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10830, current rewards: 168.93464, mean: 0.08845
[32m[0906 17-38-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10822, current rewards: 174.46472, mean: 0.08901
[32m[0906 17-38-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10812, current rewards: 180.47841, mean: 0.08979
[32m[0906 17-38-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10806, current rewards: 185.96472, mean: 0.09027
[32m[0906 17-38-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10806, current rewards: 191.40283, mean: 0.09071
[32m[0906 17-38-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10805, current rewards: 196.83790, mean: 0.09113
[32m[0906 17-38-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10804, current rewards: 202.27216, mean: 0.09153
[32m[0906 17-38-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10803, current rewards: 207.70852, mean: 0.09191
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10802, current rewards: 213.14352, mean: 0.09227
[32m[0906 17-38-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10800, current rewards: 218.58089, mean: 0.09262
[32m[0906 17-38-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10799, current rewards: 224.02076, mean: 0.09295
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10797, current rewards: 229.41064, mean: 0.09326
[32m[0906 17-39-04 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 17-39-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-39-04 @MBExp.py:227][0m Rewards obtained: [233.77107570626953], Lows: [15], Highs: [15], Total time: 12068.778103000004
[32m[0906 17-40-46 @MBExp.py:144][0m ####################################################################
[32m[0906 17-40-46 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 17-40-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10329, current rewards: -4.60948, mean: -0.46095
[32m[0906 17-40-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10372, current rewards: 0.63134, mean: 0.01052
[32m[0906 17-40-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10404, current rewards: 5.99791, mean: 0.05453
[32m[0906 17-41-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10408, current rewards: 11.36176, mean: 0.07101
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10402, current rewards: 16.72673, mean: 0.07965
[32m[0906 17-41-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10402, current rewards: 22.09360, mean: 0.08498
[32m[0906 17-41-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10408, current rewards: 27.45926, mean: 0.08858
[32m[0906 17-41-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10405, current rewards: 33.13243, mean: 0.09203
[32m[0906 17-41-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10419, current rewards: 38.50058, mean: 0.09390
[32m[0906 17-41-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10463, current rewards: 43.86173, mean: 0.09535
[32m[0906 17-41-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10496, current rewards: 49.22683, mean: 0.09652
[32m[0906 17-41-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10528, current rewards: 54.59241, mean: 0.09749
[32m[0906 17-41-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10579, current rewards: 59.95794, mean: 0.09829
[32m[0906 17-41-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10620, current rewards: 47.21246, mean: 0.07153
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10662, current rewards: 52.80122, mean: 0.07437
[32m[0906 17-42-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10692, current rewards: 58.61194, mean: 0.07712
[32m[0906 17-42-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10720, current rewards: 64.23916, mean: 0.07931
[32m[0906 17-42-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10750, current rewards: 69.86773, mean: 0.08124
[32m[0906 17-42-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10770, current rewards: 75.50297, mean: 0.08297
[32m[0906 17-42-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10789, current rewards: 81.13074, mean: 0.08451
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10809, current rewards: 86.75971, mean: 0.08590
[32m[0906 17-42-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10818, current rewards: 92.39326, mean: 0.08716
[32m[0906 17-42-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10817, current rewards: 98.02770, mean: 0.08831
[32m[0906 17-42-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10815, current rewards: 103.65756, mean: 0.08936
[32m[0906 17-42-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10812, current rewards: 109.28864, mean: 0.09032
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10810, current rewards: 114.91157, mean: 0.09120
[32m[0906 17-43-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10811, current rewards: 120.54123, mean: 0.09202
[32m[0906 17-43-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10810, current rewards: 115.32267, mean: 0.08480
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10806, current rewards: 120.73109, mean: 0.08562
[32m[0906 17-43-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10807, current rewards: 126.12720, mean: 0.08639
[32m[0906 17-43-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10806, current rewards: 131.52541, mean: 0.08710
[32m[0906 17-43-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10805, current rewards: 136.92565, mean: 0.08777
[32m[0906 17-43-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10805, current rewards: 142.32714, mean: 0.08840
[32m[0906 17-43-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10803, current rewards: 147.73037, mean: 0.08899
[32m[0906 17-43-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10801, current rewards: 153.13314, mean: 0.08955
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10801, current rewards: 158.53322, mean: 0.09008
[32m[0906 17-44-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10800, current rewards: 163.93461, mean: 0.09057
[32m[0906 17-44-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10798, current rewards: 158.86107, mean: 0.08541
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10793, current rewards: 164.24871, mean: 0.08599
[32m[0906 17-44-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10783, current rewards: 169.56094, mean: 0.08651
[32m[0906 17-44-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10773, current rewards: 174.92720, mean: 0.08703
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10770, current rewards: 180.29700, mean: 0.08752
[32m[0906 17-44-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10770, current rewards: 185.66459, mean: 0.08799
[32m[0906 17-44-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10770, current rewards: 191.02987, mean: 0.08844
[32m[0906 17-44-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10771, current rewards: 196.39824, mean: 0.08887
[32m[0906 17-44-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10770, current rewards: 201.76700, mean: 0.08928
[32m[0906 17-44-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10770, current rewards: 207.13399, mean: 0.08967
[32m[0906 17-45-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10771, current rewards: 212.50299, mean: 0.09004
[32m[0906 17-45-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10771, current rewards: 217.86975, mean: 0.09040
[32m[0906 17-45-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10771, current rewards: 223.23548, mean: 0.09075
[32m[0906 17-45-16 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 17-45-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-45-16 @MBExp.py:227][0m Rewards obtained: [227.52859145818505], Lows: [16], Highs: [10], Total time: 12338.824269000004
[32m[0906 17-47-02 @MBExp.py:144][0m ####################################################################
[32m[0906 17-47-02 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 17-47-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10376, current rewards: 0.65190, mean: 0.06519
[32m[0906 17-47-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10465, current rewards: 6.61725, mean: 0.11029
[32m[0906 17-47-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10455, current rewards: 12.67200, mean: 0.11520
[32m[0906 17-47-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10447, current rewards: 18.72104, mean: 0.11701
[32m[0906 17-47-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10457, current rewards: 24.77178, mean: 0.11796
[32m[0906 17-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10472, current rewards: 31.16778, mean: 0.11988
[32m[0906 17-47-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10476, current rewards: 38.01257, mean: 0.12262
[32m[0906 17-47-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10489, current rewards: 43.75833, mean: 0.12155
[32m[0906 17-47-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10496, current rewards: 49.50424, mean: 0.12074
[32m[0906 17-47-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10526, current rewards: 55.24992, mean: 0.12011
[32m[0906 17-47-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10558, current rewards: 60.99591, mean: 0.11960
[32m[0906 17-48-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10575, current rewards: 58.91467, mean: 0.10520
[32m[0906 17-48-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10631, current rewards: 64.69827, mean: 0.10606
[32m[0906 17-48-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10676, current rewards: 70.48285, mean: 0.10679
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10709, current rewards: 75.70661, mean: 0.10663
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10741, current rewards: 81.45119, mean: 0.10717
[32m[0906 17-48-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10767, current rewards: 87.19107, mean: 0.10764
[32m[0906 17-48-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10789, current rewards: 92.93254, mean: 0.10806
[32m[0906 17-48-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10812, current rewards: 98.67182, mean: 0.10843
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10829, current rewards: 104.41672, mean: 0.10877
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10843, current rewards: 110.16010, mean: 0.10907
[32m[0906 17-48-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10855, current rewards: 115.90424, mean: 0.10934
[32m[0906 17-49-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10851, current rewards: 122.17048, mean: 0.11006
[32m[0906 17-49-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10847, current rewards: 122.90356, mean: 0.10595
[32m[0906 17-49-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10845, current rewards: 128.36625, mean: 0.10609
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10844, current rewards: 133.82608, mean: 0.10621
[32m[0906 17-49-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10841, current rewards: 139.28711, mean: 0.10633
[32m[0906 17-49-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10841, current rewards: 144.75162, mean: 0.10644
[32m[0906 17-49-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10838, current rewards: 140.02877, mean: 0.09931
[32m[0906 17-49-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10836, current rewards: 145.89632, mean: 0.09993
[32m[0906 17-49-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10835, current rewards: 151.75964, mean: 0.10050
[32m[0906 17-49-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10835, current rewards: 157.62742, mean: 0.10104
[32m[0906 17-49-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10832, current rewards: 163.49367, mean: 0.10155
[32m[0906 17-50-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10832, current rewards: 169.36177, mean: 0.10203
[32m[0906 17-50-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10831, current rewards: 175.22200, mean: 0.10247
[32m[0906 17-50-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10829, current rewards: 181.08208, mean: 0.10289
[32m[0906 17-50-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10829, current rewards: 186.94163, mean: 0.10328
[32m[0906 17-50-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10826, current rewards: 188.55830, mean: 0.10138
[32m[0906 17-50-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10816, current rewards: 194.02776, mean: 0.10159
[32m[0906 17-50-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10808, current rewards: 199.49450, mean: 0.10178
[32m[0906 17-50-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10799, current rewards: 204.96805, mean: 0.10197
[32m[0906 17-50-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10790, current rewards: 210.43591, mean: 0.10215
[32m[0906 17-50-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10792, current rewards: 215.91385, mean: 0.10233
[32m[0906 17-50-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10792, current rewards: 221.38993, mean: 0.10250
[32m[0906 17-51-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10792, current rewards: 226.86761, mean: 0.10266
[32m[0906 17-51-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10793, current rewards: 232.34538, mean: 0.10281
[32m[0906 17-51-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10792, current rewards: 237.81220, mean: 0.10295
[32m[0906 17-51-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10792, current rewards: 232.41948, mean: 0.09848
[32m[0906 17-51-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10793, current rewards: 238.19941, mean: 0.09884
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10792, current rewards: 243.98702, mean: 0.09918
[32m[0906 17-51-32 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 17-51-32 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-51-32 @MBExp.py:227][0m Rewards obtained: [248.61550856579962], Lows: [10], Highs: [17], Total time: 12609.374063000005
[32m[0906 17-53-19 @MBExp.py:144][0m ####################################################################
[32m[0906 17-53-19 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 17-53-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10220, current rewards: -12.93869, mean: -1.29387
[32m[0906 17-53-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10434, current rewards: -17.34860, mean: -0.28914
[32m[0906 17-53-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10421, current rewards: -11.17193, mean: -0.10156
[32m[0906 17-53-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10420, current rewards: -5.00086, mean: -0.03126
[32m[0906 17-53-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10439, current rewards: 1.17379, mean: 0.00559
[32m[0906 17-53-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10435, current rewards: 7.97168, mean: 0.03066
[32m[0906 17-53-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10436, current rewards: 14.94321, mean: 0.04820
[32m[0906 17-53-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10448, current rewards: 21.11758, mean: 0.05866
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10460, current rewards: 25.16522, mean: 0.06138
[32m[0906 17-54-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10498, current rewards: 23.52969, mean: 0.05115
[32m[0906 17-54-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10530, current rewards: 29.15439, mean: 0.05717
[32m[0906 17-54-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10553, current rewards: 34.77612, mean: 0.06210
[32m[0906 17-54-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10604, current rewards: 30.70329, mean: 0.05033
[32m[0906 17-54-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10651, current rewards: 36.27840, mean: 0.05497
[32m[0906 17-54-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10689, current rewards: 41.72228, mean: 0.05876
[32m[0906 17-54-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10721, current rewards: 47.28266, mean: 0.06221
[32m[0906 17-54-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10753, current rewards: 52.84199, mean: 0.06524
[32m[0906 17-54-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10777, current rewards: 58.40059, mean: 0.06791
[32m[0906 17-54-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10799, current rewards: 54.99534, mean: 0.06043
[32m[0906 17-55-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10821, current rewards: 61.45417, mean: 0.06401
[32m[0906 17-55-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10839, current rewards: 67.91299, mean: 0.06724
[32m[0906 17-55-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10838, current rewards: 74.37182, mean: 0.07016
[32m[0906 17-55-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10839, current rewards: 78.98271, mean: 0.07116
[32m[0906 17-55-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10839, current rewards: 85.18855, mean: 0.07344
[32m[0906 17-55-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10837, current rewards: 89.13541, mean: 0.07367
[32m[0906 17-55-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10837, current rewards: 81.70237, mean: 0.06484
[32m[0906 17-55-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10833, current rewards: 88.06808, mean: 0.06723
[32m[0906 17-55-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10829, current rewards: 94.43897, mean: 0.06944
[32m[0906 17-55-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10829, current rewards: 100.80478, mean: 0.07149
[32m[0906 17-55-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10828, current rewards: 107.16867, mean: 0.07340
[32m[0906 17-56-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10825, current rewards: 113.76376, mean: 0.07534
[32m[0906 17-56-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10826, current rewards: 120.91417, mean: 0.07751
[32m[0906 17-56-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10824, current rewards: 116.37172, mean: 0.07228
[32m[0906 17-56-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10823, current rewards: 122.07888, mean: 0.07354
[32m[0906 17-56-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10825, current rewards: 127.79404, mean: 0.07473
[32m[0906 17-56-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10824, current rewards: 133.50544, mean: 0.07586
[32m[0906 17-56-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10824, current rewards: 139.21570, mean: 0.07691
[32m[0906 17-56-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10818, current rewards: 144.92720, mean: 0.07792
[32m[0906 17-56-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10807, current rewards: 150.63633, mean: 0.07887
[32m[0906 17-56-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10800, current rewards: 156.35101, mean: 0.07977
[32m[0906 17-56-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10793, current rewards: 162.05614, mean: 0.08062
[32m[0906 17-57-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10785, current rewards: 157.59842, mean: 0.07650
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10788, current rewards: 163.26193, mean: 0.07738
[32m[0906 17-57-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10789, current rewards: 168.93181, mean: 0.07821
[32m[0906 17-57-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10788, current rewards: 174.60215, mean: 0.07901
[32m[0906 17-57-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10790, current rewards: 180.26453, mean: 0.07976
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10792, current rewards: 185.93161, mean: 0.08049
[32m[0906 17-57-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10795, current rewards: 191.54846, mean: 0.08116
[32m[0906 17-57-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10797, current rewards: 197.21709, mean: 0.08183
[32m[0906 17-57-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10795, current rewards: 202.88949, mean: 0.08248
[32m[0906 17-57-50 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 17-57-50 @Agent.py:118][0m Rollout length: 2505
[32m[0906 17-57-50 @MBExp.py:227][0m Rewards obtained: [207.42543482986844], Lows: [39], Highs: [10], Total time: 12879.987025000004
[32m[0906 17-59-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-59-39 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 17-59-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10423, current rewards: 0.86130, mean: 0.08613
[32m[0906 17-59-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10411, current rewards: 6.51906, mean: 0.10865
[32m[0906 17-59-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10451, current rewards: 12.10799, mean: 0.11007
[32m[0906 17-59-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10431, current rewards: 17.69518, mean: 0.11059
[32m[0906 18-00-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10425, current rewards: 23.28258, mean: 0.11087
[32m[0906 18-00-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10428, current rewards: 28.47654, mean: 0.10953
[32m[0906 18-00-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10428, current rewards: 34.08792, mean: 0.10996
[32m[0906 18-00-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10419, current rewards: 39.69546, mean: 0.11027
[32m[0906 18-00-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10442, current rewards: 45.30373, mean: 0.11050
[32m[0906 18-00-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10471, current rewards: 50.90925, mean: 0.11067
[32m[0906 18-00-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10497, current rewards: 56.51234, mean: 0.11081
[32m[0906 18-00-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10518, current rewards: 57.80423, mean: 0.10322
[32m[0906 18-00-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10567, current rewards: 63.73975, mean: 0.10449
[32m[0906 18-00-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10609, current rewards: 69.79459, mean: 0.10575
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10646, current rewards: 75.73651, mean: 0.10667
[32m[0906 18-01-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10677, current rewards: 81.62168, mean: 0.10740
[32m[0906 18-01-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10705, current rewards: 87.51732, mean: 0.10805
[32m[0906 18-01-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10731, current rewards: 93.42460, mean: 0.10863
[32m[0906 18-01-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10753, current rewards: 99.32149, mean: 0.10914
[32m[0906 18-01-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10775, current rewards: 94.22391, mean: 0.09815
[32m[0906 18-01-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10784, current rewards: 99.87473, mean: 0.09889
[32m[0906 18-01-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10784, current rewards: 105.88629, mean: 0.09989
[32m[0906 18-01-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10788, current rewards: 111.53621, mean: 0.10048
[32m[0906 18-01-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10787, current rewards: 117.20145, mean: 0.10104
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10786, current rewards: 122.86661, mean: 0.10154
[32m[0906 18-01-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10787, current rewards: 128.53345, mean: 0.10201
[32m[0906 18-02-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10787, current rewards: 128.74149, mean: 0.09828
[32m[0906 18-02-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10786, current rewards: 134.50264, mean: 0.09890
[32m[0906 18-02-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10789, current rewards: 140.26199, mean: 0.09948
[32m[0906 18-02-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10788, current rewards: 146.02737, mean: 0.10002
[32m[0906 18-02-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10787, current rewards: 151.78759, mean: 0.10052
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10788, current rewards: 157.54743, mean: 0.10099
[32m[0906 18-02-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10788, current rewards: 163.30796, mean: 0.10143
[32m[0906 18-02-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10788, current rewards: 169.06567, mean: 0.10185
[32m[0906 18-02-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10790, current rewards: 174.82771, mean: 0.10224
[32m[0906 18-02-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10789, current rewards: 180.58637, mean: 0.10261
[32m[0906 18-02-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10787, current rewards: 175.75623, mean: 0.09710
[32m[0906 18-03-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10779, current rewards: 181.61378, mean: 0.09764
[32m[0906 18-03-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10771, current rewards: 187.56307, mean: 0.09820
[32m[0906 18-03-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10761, current rewards: 193.28981, mean: 0.09862
[32m[0906 18-03-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10756, current rewards: 199.02580, mean: 0.09902
[32m[0906 18-03-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10752, current rewards: 204.75658, mean: 0.09940
[32m[0906 18-03-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10753, current rewards: 210.49413, mean: 0.09976
[32m[0906 18-03-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10757, current rewards: 216.22475, mean: 0.10010
[32m[0906 18-03-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10757, current rewards: 221.96194, mean: 0.10044
[32m[0906 18-03-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10756, current rewards: 227.69436, mean: 0.10075
[32m[0906 18-03-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10758, current rewards: 229.48684, mean: 0.09934
[32m[0906 18-03-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10758, current rewards: 235.50523, mean: 0.09979
[32m[0906 18-03-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10759, current rewards: 241.52832, mean: 0.10022
[32m[0906 18-04-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10761, current rewards: 247.54225, mean: 0.10063
[32m[0906 18-04-09 @Agent.py:117][0m Average action selection time: 0.1076
[32m[0906 18-04-09 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-04-09 @MBExp.py:227][0m Rewards obtained: [252.3569898491136], Lows: [10], Highs: [15], Total time: 13149.768777000005
[32m[0906 18-06-00 @MBExp.py:144][0m ####################################################################
[32m[0906 18-06-00 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 18-06-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10344, current rewards: -9.36048, mean: -0.93605
[32m[0906 18-06-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10422, current rewards: -4.94623, mean: -0.08244
[32m[0906 18-06-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10488, current rewards: 0.71612, mean: 0.00651
[32m[0906 18-06-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10459, current rewards: 6.37616, mean: 0.03985
[32m[0906 18-06-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10449, current rewards: 12.54711, mean: 0.05975
[32m[0906 18-06-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10458, current rewards: 18.38843, mean: 0.07072
[32m[0906 18-06-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10454, current rewards: 24.22811, mean: 0.07816
[32m[0906 18-06-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10460, current rewards: 30.07118, mean: 0.08353
[32m[0906 18-06-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10480, current rewards: 35.91028, mean: 0.08759
[32m[0906 18-06-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10509, current rewards: 41.75290, mean: 0.09077
[32m[0906 18-06-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10531, current rewards: 47.59249, mean: 0.09332
[32m[0906 18-07-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10562, current rewards: 43.09828, mean: 0.07696
[32m[0906 18-07-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10611, current rewards: 48.44686, mean: 0.07942
[32m[0906 18-07-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10654, current rewards: 53.93323, mean: 0.08172
[32m[0906 18-07-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10693, current rewards: 59.41225, mean: 0.08368
[32m[0906 18-07-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10724, current rewards: 64.89792, mean: 0.08539
[32m[0906 18-07-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10756, current rewards: 70.38217, mean: 0.08689
[32m[0906 18-07-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10788, current rewards: 75.86915, mean: 0.08822
[32m[0906 18-07-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10812, current rewards: 81.35079, mean: 0.08940
[32m[0906 18-07-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10834, current rewards: 86.83558, mean: 0.09045
[32m[0906 18-07-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10829, current rewards: 92.50630, mean: 0.09159
[32m[0906 18-07-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10827, current rewards: 98.01966, mean: 0.09247
[32m[0906 18-08-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10829, current rewards: 103.52018, mean: 0.09326
[32m[0906 18-08-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10827, current rewards: 103.61120, mean: 0.08932
[32m[0906 18-08-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10823, current rewards: 109.19033, mean: 0.09024
[32m[0906 18-08-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10823, current rewards: 114.76562, mean: 0.09108
[32m[0906 18-08-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10821, current rewards: 120.33565, mean: 0.09186
[32m[0906 18-08-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10819, current rewards: 125.89734, mean: 0.09257
[32m[0906 18-08-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10819, current rewards: 131.72569, mean: 0.09342
[32m[0906 18-08-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10818, current rewards: 137.29771, mean: 0.09404
[32m[0906 18-08-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10816, current rewards: 142.87868, mean: 0.09462
[32m[0906 18-08-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10815, current rewards: 148.46886, mean: 0.09517
[32m[0906 18-08-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10814, current rewards: 143.94142, mean: 0.08940
[32m[0906 18-09-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10813, current rewards: 149.73956, mean: 0.09020
[32m[0906 18-09-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10813, current rewards: 155.53735, mean: 0.09096
[32m[0906 18-09-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10813, current rewards: 161.33861, mean: 0.09167
[32m[0906 18-09-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10805, current rewards: 167.10928, mean: 0.09233
[32m[0906 18-09-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10797, current rewards: 172.89489, mean: 0.09295
[32m[0906 18-09-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10787, current rewards: 178.70854, mean: 0.09356
[32m[0906 18-09-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10779, current rewards: 184.52224, mean: 0.09414
[32m[0906 18-09-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10772, current rewards: 190.33587, mean: 0.09469
[32m[0906 18-09-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10768, current rewards: 196.15032, mean: 0.09522
[32m[0906 18-09-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10769, current rewards: 191.59797, mean: 0.09080
[32m[0906 18-09-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10771, current rewards: 197.79330, mean: 0.09157
[32m[0906 18-09-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10773, current rewards: 203.66927, mean: 0.09216
[32m[0906 18-10-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10774, current rewards: 209.50061, mean: 0.09270
[32m[0906 18-10-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10776, current rewards: 215.35813, mean: 0.09323
[32m[0906 18-10-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10776, current rewards: 221.21290, mean: 0.09373
[32m[0906 18-10-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10777, current rewards: 227.07228, mean: 0.09422
[32m[0906 18-10-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10779, current rewards: 232.93169, mean: 0.09469
[32m[0906 18-10-30 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-10-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-10-31 @MBExp.py:227][0m Rewards obtained: [237.61831762557233], Lows: [18], Highs: [11], Total time: 13419.997033000005
[32m[0906 18-12-25 @MBExp.py:144][0m ####################################################################
[32m[0906 18-12-25 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 18-12-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10291, current rewards: -4.54473, mean: -0.45447
[32m[0906 18-12-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10473, current rewards: 1.26170, mean: 0.02103
[32m[0906 18-12-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10454, current rewards: 7.34547, mean: 0.06678
[32m[0906 18-12-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10442, current rewards: 13.84435, mean: 0.08653
[32m[0906 18-12-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10463, current rewards: 19.91159, mean: 0.09482
[32m[0906 18-12-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10462, current rewards: 25.97748, mean: 0.09991
[32m[0906 18-12-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10462, current rewards: 32.03785, mean: 0.10335
[32m[0906 18-13-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10468, current rewards: 38.10464, mean: 0.10585
[32m[0906 18-13-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10482, current rewards: 44.16706, mean: 0.10772
[32m[0906 18-13-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10515, current rewards: 50.22872, mean: 0.10919
[32m[0906 18-13-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10553, current rewards: 56.29290, mean: 0.11038
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10576, current rewards: 62.16557, mean: 0.11101
[32m[0906 18-13-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10626, current rewards: 68.24563, mean: 0.11188
[32m[0906 18-13-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10672, current rewards: 74.34141, mean: 0.11264
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10711, current rewards: 80.43047, mean: 0.11328
[32m[0906 18-13-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10742, current rewards: 68.57030, mean: 0.09022
[32m[0906 18-13-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10776, current rewards: 75.34101, mean: 0.09301
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10802, current rewards: 81.35698, mean: 0.09460
[32m[0906 18-14-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10822, current rewards: 87.37746, mean: 0.09602
[32m[0906 18-14-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10835, current rewards: 93.31667, mean: 0.09720
[32m[0906 18-14-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10833, current rewards: 99.37996, mean: 0.09840
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10835, current rewards: 105.43210, mean: 0.09946
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10833, current rewards: 111.49526, mean: 0.10045
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10833, current rewards: 117.54094, mean: 0.10133
[32m[0906 18-14-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10833, current rewards: 123.59296, mean: 0.10214
[32m[0906 18-14-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10833, current rewards: 129.64763, mean: 0.10289
[32m[0906 18-14-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10832, current rewards: 135.70261, mean: 0.10359
[32m[0906 18-14-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10835, current rewards: 142.06600, mean: 0.10446
[32m[0906 18-14-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10833, current rewards: 148.35819, mean: 0.10522
[32m[0906 18-15-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10832, current rewards: 144.32898, mean: 0.09886
[32m[0906 18-15-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10834, current rewards: 150.00222, mean: 0.09934
[32m[0906 18-15-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10831, current rewards: 155.67480, mean: 0.09979
[32m[0906 18-15-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10830, current rewards: 161.34686, mean: 0.10022
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10831, current rewards: 167.02101, mean: 0.10062
[32m[0906 18-15-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10831, current rewards: 167.55412, mean: 0.09798
[32m[0906 18-15-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10829, current rewards: 173.26712, mean: 0.09845
[32m[0906 18-15-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10820, current rewards: 178.94676, mean: 0.09887
[32m[0906 18-15-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10812, current rewards: 184.66275, mean: 0.09928
[32m[0906 18-15-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10805, current rewards: 190.37614, mean: 0.09967
[32m[0906 18-15-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10799, current rewards: 196.09034, mean: 0.10005
[32m[0906 18-16-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10791, current rewards: 201.80326, mean: 0.10040
[32m[0906 18-16-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10788, current rewards: 207.51805, mean: 0.10074
[32m[0906 18-16-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10791, current rewards: 213.23149, mean: 0.10106
[32m[0906 18-16-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10792, current rewards: 218.94285, mean: 0.10136
[32m[0906 18-16-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10793, current rewards: 224.65101, mean: 0.10165
[32m[0906 18-16-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10796, current rewards: 230.36330, mean: 0.10193
[32m[0906 18-16-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10796, current rewards: 225.93595, mean: 0.09781
[32m[0906 18-16-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10796, current rewards: 231.72080, mean: 0.09819
[32m[0906 18-16-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10797, current rewards: 237.49870, mean: 0.09855
[32m[0906 18-16-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10797, current rewards: 243.28232, mean: 0.09890
[32m[0906 18-16-55 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 18-16-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-16-55 @MBExp.py:227][0m Rewards obtained: [247.91349048073468], Lows: [14], Highs: [20], Total time: 13690.697933000005
[32m[0906 18-18-52 @MBExp.py:144][0m ####################################################################
[32m[0906 18-18-52 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10313, current rewards: -8.11308, mean: -0.81131
[32m[0906 18-18-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10413, current rewards: -2.57559, mean: -0.04293
[32m[0906 18-19-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10427, current rewards: 3.98177, mean: 0.03620
[32m[0906 18-19-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10456, current rewards: 9.88760, mean: 0.06180
[32m[0906 18-19-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10451, current rewards: 15.79916, mean: 0.07523
[32m[0906 18-19-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10439, current rewards: 21.70863, mean: 0.08349
[32m[0906 18-19-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10447, current rewards: 27.62064, mean: 0.08910
[32m[0906 18-19-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10444, current rewards: 33.53201, mean: 0.09314
[32m[0906 18-19-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10459, current rewards: 39.43908, mean: 0.09619
[32m[0906 18-19-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10502, current rewards: 45.35574, mean: 0.09860
[32m[0906 18-19-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10524, current rewards: 41.50242, mean: 0.08138
[32m[0906 18-19-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10548, current rewards: 47.72073, mean: 0.08522
[32m[0906 18-19-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10603, current rewards: 53.94323, mean: 0.08843
[32m[0906 18-20-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10646, current rewards: 50.90356, mean: 0.07713
[32m[0906 18-20-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10681, current rewards: 58.82231, mean: 0.08285
[32m[0906 18-20-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10719, current rewards: 66.74811, mean: 0.08783
[32m[0906 18-20-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10749, current rewards: 74.67432, mean: 0.09219
[32m[0906 18-20-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10772, current rewards: 82.60166, mean: 0.09605
[32m[0906 18-20-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10797, current rewards: 90.37528, mean: 0.09931
[32m[0906 18-20-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10797, current rewards: 96.61881, mean: 0.10064
[32m[0906 18-20-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10799, current rewards: 103.56579, mean: 0.10254
[32m[0906 18-20-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10803, current rewards: 110.51654, mean: 0.10426
[32m[0906 18-20-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10806, current rewards: 117.46152, mean: 0.10582
[32m[0906 18-20-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10810, current rewards: 124.40411, mean: 0.10724
[32m[0906 18-21-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10813, current rewards: 131.34444, mean: 0.10855
[32m[0906 18-21-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10815, current rewards: 128.10046, mean: 0.10167
[32m[0906 18-21-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10819, current rewards: 133.76842, mean: 0.10211
[32m[0906 18-21-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10821, current rewards: 139.59255, mean: 0.10264
[32m[0906 18-21-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10822, current rewards: 145.26574, mean: 0.10303
[32m[0906 18-21-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10826, current rewards: 150.94470, mean: 0.10339
[32m[0906 18-21-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10825, current rewards: 156.61609, mean: 0.10372
[32m[0906 18-21-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10823, current rewards: 162.28704, mean: 0.10403
[32m[0906 18-21-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10827, current rewards: 167.96128, mean: 0.10432
[32m[0906 18-21-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10825, current rewards: 173.63820, mean: 0.10460
[32m[0906 18-21-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10826, current rewards: 179.31629, mean: 0.10486
[32m[0906 18-22-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10818, current rewards: 184.99956, mean: 0.10511
[32m[0906 18-22-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10808, current rewards: 175.10162, mean: 0.09674
[32m[0906 18-22-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10799, current rewards: 180.58110, mean: 0.09709
[32m[0906 18-22-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10792, current rewards: 185.94125, mean: 0.09735
[32m[0906 18-22-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10783, current rewards: 191.30780, mean: 0.09761
[32m[0906 18-22-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10776, current rewards: 196.66678, mean: 0.09784
[32m[0906 18-22-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10775, current rewards: 202.02718, mean: 0.09807
[32m[0906 18-22-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10776, current rewards: 207.38497, mean: 0.09829
[32m[0906 18-22-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10776, current rewards: 213.55613, mean: 0.09887
[32m[0906 18-22-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10777, current rewards: 219.13642, mean: 0.09916
[32m[0906 18-22-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10778, current rewards: 224.73144, mean: 0.09944
[32m[0906 18-23-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10779, current rewards: 230.31968, mean: 0.09971
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10781, current rewards: 235.91446, mean: 0.09996
[32m[0906 18-23-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10782, current rewards: 241.50978, mean: 0.10021
[32m[0906 18-23-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10782, current rewards: 247.09992, mean: 0.10045
[32m[0906 18-23-22 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-23-22 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-23-22 @MBExp.py:227][0m Rewards obtained: [251.57485493180488], Lows: [19], Highs: [15], Total time: 13961.041172000005
[32m[0906 18-25-20 @MBExp.py:144][0m ####################################################################
[32m[0906 18-25-20 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 18-25-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10262, current rewards: -11.76850, mean: -1.17685
[32m[0906 18-25-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10403, current rewards: -6.47914, mean: -0.10799
[32m[0906 18-25-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10447, current rewards: -1.02582, mean: -0.00933
[32m[0906 18-25-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10451, current rewards: 4.45378, mean: 0.02784
[32m[0906 18-25-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10449, current rewards: 9.92985, mean: 0.04728
[32m[0906 18-25-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10453, current rewards: 15.40724, mean: 0.05926
[32m[0906 18-25-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10446, current rewards: 20.88369, mean: 0.06737
[32m[0906 18-25-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10440, current rewards: 26.36508, mean: 0.07324
[32m[0906 18-26-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10466, current rewards: 31.84711, mean: 0.07768
[32m[0906 18-26-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10501, current rewards: 37.32041, mean: 0.08113
[32m[0906 18-26-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10531, current rewards: 43.03261, mean: 0.08438
[32m[0906 18-26-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10561, current rewards: 48.47332, mean: 0.08656
[32m[0906 18-26-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10610, current rewards: 53.91623, mean: 0.08839
[32m[0906 18-26-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10658, current rewards: 59.14839, mean: 0.08962
[32m[0906 18-26-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10698, current rewards: 65.11180, mean: 0.09171
[32m[0906 18-26-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10729, current rewards: 70.64920, mean: 0.09296
[32m[0906 18-26-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10761, current rewards: 76.18564, mean: 0.09406
[32m[0906 18-26-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10787, current rewards: 81.71911, mean: 0.09502
[32m[0906 18-26-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10795, current rewards: 87.46560, mean: 0.09612
[32m[0906 18-27-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10798, current rewards: 92.96146, mean: 0.09683
[32m[0906 18-27-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10800, current rewards: 98.46062, mean: 0.09749
[32m[0906 18-27-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10800, current rewards: 103.95321, mean: 0.09807
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10802, current rewards: 107.34179, mean: 0.09670
[32m[0906 18-27-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10804, current rewards: 104.40501, mean: 0.09000
[32m[0906 18-27-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10809, current rewards: 109.93490, mean: 0.09086
[32m[0906 18-27-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10814, current rewards: 115.46418, mean: 0.09164
[32m[0906 18-27-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10814, current rewards: 120.83249, mean: 0.09224
[32m[0906 18-27-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10813, current rewards: 126.39887, mean: 0.09294
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10815, current rewards: 121.76502, mean: 0.08636
[32m[0906 18-27-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10816, current rewards: 131.00803, mean: 0.08973
[32m[0906 18-28-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10815, current rewards: 140.13593, mean: 0.09281
[32m[0906 18-28-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10815, current rewards: 149.26792, mean: 0.09568
[32m[0906 18-28-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10815, current rewards: 158.40605, mean: 0.09839
[32m[0906 18-28-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10815, current rewards: 167.53548, mean: 0.10092
[32m[0906 18-28-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10812, current rewards: 177.81667, mean: 0.10399
[32m[0906 18-28-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10803, current rewards: 187.98013, mean: 0.10681
[32m[0906 18-28-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10794, current rewards: 198.10289, mean: 0.10945
[32m[0906 18-28-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10786, current rewards: 208.23687, mean: 0.11196
[32m[0906 18-28-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10778, current rewards: 218.37152, mean: 0.11433
[32m[0906 18-28-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10770, current rewards: 228.49937, mean: 0.11658
[32m[0906 18-28-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10763, current rewards: 238.64566, mean: 0.11873
[32m[0906 18-29-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10763, current rewards: 248.77038, mean: 0.12076
[32m[0906 18-29-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10765, current rewards: 253.72714, mean: 0.12025
[32m[0906 18-29-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10767, current rewards: 259.29808, mean: 0.12005
[32m[0906 18-29-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10768, current rewards: 264.86864, mean: 0.11985
[32m[0906 18-29-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10771, current rewards: 270.44251, mean: 0.11966
[32m[0906 18-29-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10773, current rewards: 276.01416, mean: 0.11949
[32m[0906 18-29-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10774, current rewards: 281.58398, mean: 0.11932
[32m[0906 18-29-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10775, current rewards: 287.15526, mean: 0.11915
[32m[0906 18-29-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10777, current rewards: 292.72520, mean: 0.11899
[32m[0906 18-29-51 @Agent.py:117][0m Average action selection time: 0.1078
[32m[0906 18-29-51 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-29-51 @MBExp.py:227][0m Rewards obtained: [297.18098759620693], Lows: [13], Highs: [6], Total time: 14231.253956000004
[32m[0906 18-31-52 @MBExp.py:144][0m ####################################################################
[32m[0906 18-31-52 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 18-31-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10479, current rewards: -5.61291, mean: -0.56129
[32m[0906 18-31-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10494, current rewards: -0.39350, mean: -0.00656
[32m[0906 18-32-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10506, current rewards: 4.94607, mean: 0.04496
[32m[0906 18-32-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10535, current rewards: 10.28797, mean: 0.06430
[32m[0906 18-32-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10522, current rewards: 15.63199, mean: 0.07444
[32m[0906 18-32-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10517, current rewards: 20.97274, mean: 0.08066
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10523, current rewards: 26.31198, mean: 0.08488
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10520, current rewards: 31.65302, mean: 0.08793
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10536, current rewards: 36.99786, mean: 0.09024
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10578, current rewards: 42.11119, mean: 0.09155
[32m[0906 18-32-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10603, current rewards: 47.46873, mean: 0.09308
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10623, current rewards: 52.82253, mean: 0.09433
[32m[0906 18-32-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10675, current rewards: 58.17369, mean: 0.09537
[32m[0906 18-33-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10716, current rewards: 58.56738, mean: 0.08874
[32m[0906 18-33-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10756, current rewards: 63.91071, mean: 0.09002
[32m[0906 18-33-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10793, current rewards: 69.26928, mean: 0.09114
[32m[0906 18-33-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10820, current rewards: 74.62926, mean: 0.09213
[32m[0906 18-33-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10838, current rewards: 80.21784, mean: 0.09328
[32m[0906 18-33-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10840, current rewards: 85.58489, mean: 0.09405
[32m[0906 18-33-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10840, current rewards: 90.95315, mean: 0.09474
[32m[0906 18-33-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10847, current rewards: 96.31784, mean: 0.09536
[32m[0906 18-33-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10844, current rewards: 101.68695, mean: 0.09593
[32m[0906 18-33-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10846, current rewards: 107.05369, mean: 0.09644
[32m[0906 18-33-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10848, current rewards: 101.84077, mean: 0.08779
[32m[0906 18-34-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10847, current rewards: 107.36529, mean: 0.08873
[32m[0906 18-34-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10848, current rewards: 113.28705, mean: 0.08991
[32m[0906 18-34-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10849, current rewards: 119.01872, mean: 0.09085
[32m[0906 18-34-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10848, current rewards: 124.74176, mean: 0.09172
[32m[0906 18-34-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10846, current rewards: 130.46636, mean: 0.09253
[32m[0906 18-34-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10848, current rewards: 136.18908, mean: 0.09328
[32m[0906 18-34-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10847, current rewards: 141.91477, mean: 0.09398
[32m[0906 18-34-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10847, current rewards: 147.64219, mean: 0.09464
[32m[0906 18-34-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10848, current rewards: 153.13889, mean: 0.09512
[32m[0906 18-34-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10847, current rewards: 158.95066, mean: 0.09575
[32m[0906 18-34-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10838, current rewards: 164.43493, mean: 0.09616
[32m[0906 18-35-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10830, current rewards: 169.86446, mean: 0.09651
[32m[0906 18-35-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10820, current rewards: 175.29524, mean: 0.09685
[32m[0906 18-35-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10812, current rewards: 180.71999, mean: 0.09716
[32m[0906 18-35-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10804, current rewards: 185.04177, mean: 0.09688
[32m[0906 18-35-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10797, current rewards: 186.37255, mean: 0.09509
[32m[0906 18-35-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10789, current rewards: 191.81641, mean: 0.09543
[32m[0906 18-35-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10792, current rewards: 197.26175, mean: 0.09576
[32m[0906 18-35-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10793, current rewards: 202.18717, mean: 0.09582
[32m[0906 18-35-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10793, current rewards: 207.65385, mean: 0.09614
[32m[0906 18-35-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10795, current rewards: 213.11721, mean: 0.09643
[32m[0906 18-35-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10795, current rewards: 218.57891, mean: 0.09672
[32m[0906 18-36-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10795, current rewards: 224.03783, mean: 0.09699
[32m[0906 18-36-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10797, current rewards: 229.50402, mean: 0.09725
[32m[0906 18-36-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10798, current rewards: 225.12939, mean: 0.09341
[32m[0906 18-36-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10798, current rewards: 230.48832, mean: 0.09369
[32m[0906 18-36-22 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 18-36-22 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-36-22 @MBExp.py:227][0m Rewards obtained: [235.3009965278457], Lows: [10], Highs: [16], Total time: 14502.037028000004
[32m[0906 18-38-26 @MBExp.py:144][0m ####################################################################
[32m[0906 18-38-26 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 18-38-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10692, current rewards: -4.59580, mean: -0.45958
[32m[0906 18-38-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10486, current rewards: 0.95547, mean: 0.01592
[32m[0906 18-38-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10491, current rewards: 6.73627, mean: 0.06124
[32m[0906 18-38-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10485, current rewards: 12.51830, mean: 0.07824
[32m[0906 18-38-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10476, current rewards: 18.29647, mean: 0.08713
[32m[0906 18-38-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10465, current rewards: 24.07830, mean: 0.09261
[32m[0906 18-38-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10465, current rewards: 29.86080, mean: 0.09633
[32m[0906 18-39-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10473, current rewards: 35.63814, mean: 0.09899
[32m[0906 18-39-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10493, current rewards: 30.84589, mean: 0.07523
[32m[0906 18-39-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10537, current rewards: 36.53237, mean: 0.07942
[32m[0906 18-39-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10562, current rewards: 42.22341, mean: 0.08279
[32m[0906 18-39-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10583, current rewards: 47.91475, mean: 0.08556
[32m[0906 18-39-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10642, current rewards: 53.60311, mean: 0.08787
[32m[0906 18-39-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10684, current rewards: 59.29363, mean: 0.08984
[32m[0906 18-39-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10722, current rewards: 64.98368, mean: 0.09153
[32m[0906 18-39-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10760, current rewards: 60.06884, mean: 0.07904
[32m[0906 18-39-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10787, current rewards: 65.72372, mean: 0.08114
[32m[0906 18-39-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10791, current rewards: 71.92513, mean: 0.08363
[32m[0906 18-40-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10796, current rewards: 77.60207, mean: 0.08528
[32m[0906 18-40-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10798, current rewards: 79.93384, mean: 0.08326
[32m[0906 18-40-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10801, current rewards: 84.12128, mean: 0.08329
[32m[0906 18-40-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10805, current rewards: 90.43732, mean: 0.08532
[32m[0906 18-40-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10805, current rewards: 96.76102, mean: 0.08717
[32m[0906 18-40-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10804, current rewards: 103.06612, mean: 0.08885
[32m[0906 18-40-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10807, current rewards: 109.37951, mean: 0.09040
[32m[0906 18-40-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10806, current rewards: 116.53644, mean: 0.09249
[32m[0906 18-40-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10806, current rewards: 122.82948, mean: 0.09376
[32m[0906 18-40-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10809, current rewards: 129.10757, mean: 0.09493
[32m[0906 18-40-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10809, current rewards: 125.52656, mean: 0.08903
[32m[0906 18-41-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10809, current rewards: 131.27698, mean: 0.08992
[32m[0906 18-41-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10809, current rewards: 137.02918, mean: 0.09075
[32m[0906 18-41-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10809, current rewards: 132.64868, mean: 0.08503
[32m[0906 18-41-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10809, current rewards: 141.18675, mean: 0.08769
[32m[0906 18-41-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10805, current rewards: 148.62835, mean: 0.08954
[32m[0906 18-41-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10796, current rewards: 150.32195, mean: 0.08791
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10785, current rewards: 156.20475, mean: 0.08875
[32m[0906 18-41-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10778, current rewards: 162.08450, mean: 0.08955
[32m[0906 18-41-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10769, current rewards: 167.96788, mean: 0.09031
[32m[0906 18-41-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10761, current rewards: 173.85256, mean: 0.09102
[32m[0906 18-41-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10755, current rewards: 179.73270, mean: 0.09170
[32m[0906 18-42-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10750, current rewards: 185.61667, mean: 0.09235
[32m[0906 18-42-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10752, current rewards: 191.50335, mean: 0.09296
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10755, current rewards: 197.82708, mean: 0.09376
[32m[0906 18-42-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10757, current rewards: 203.77935, mean: 0.09434
[32m[0906 18-42-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10758, current rewards: 203.99164, mean: 0.09230
[32m[0906 18-42-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10762, current rewards: 209.65103, mean: 0.09277
[32m[0906 18-42-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10763, current rewards: 215.31323, mean: 0.09321
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10764, current rewards: 220.97332, mean: 0.09363
[32m[0906 18-42-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10766, current rewards: 226.63406, mean: 0.09404
[32m[0906 18-42-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10768, current rewards: 232.28899, mean: 0.09443
[32m[0906 18-42-56 @Agent.py:117][0m Average action selection time: 0.1077
[32m[0906 18-42-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-42-56 @MBExp.py:227][0m Rewards obtained: [236.81752480833214], Lows: [21], Highs: [18], Total time: 14772.016527000003
[32m[0906 18-45-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-45-02 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 18-45-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10408, current rewards: -4.61459, mean: -0.46146
[32m[0906 18-45-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10521, current rewards: 1.85340, mean: 0.03089
[32m[0906 18-45-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10493, current rewards: 8.39781, mean: 0.07634
[32m[0906 18-45-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10484, current rewards: 14.95257, mean: 0.09345
[32m[0906 18-45-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10502, current rewards: 21.50345, mean: 0.10240
[32m[0906 18-45-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10499, current rewards: 28.05668, mean: 0.10791
[32m[0906 18-45-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10504, current rewards: 34.61057, mean: 0.11165
[32m[0906 18-45-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10515, current rewards: 41.16140, mean: 0.11434
[32m[0906 18-45-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10549, current rewards: 48.30027, mean: 0.11781
[32m[0906 18-45-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10587, current rewards: 54.67879, mean: 0.11887
[32m[0906 18-45-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10625, current rewards: 55.30538, mean: 0.10844
[32m[0906 18-46-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10659, current rewards: 61.05292, mean: 0.10902
[32m[0906 18-46-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10715, current rewards: 66.79834, mean: 0.10951
[32m[0906 18-46-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10764, current rewards: 72.54038, mean: 0.10991
[32m[0906 18-46-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10804, current rewards: 78.28111, mean: 0.11026
[32m[0906 18-46-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10843, current rewards: 84.02325, mean: 0.11056
[32m[0906 18-46-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10859, current rewards: 89.78093, mean: 0.11084
[32m[0906 18-46-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10865, current rewards: 95.79443, mean: 0.11139
[32m[0906 18-46-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10871, current rewards: 101.12535, mean: 0.11113
[32m[0906 18-46-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10872, current rewards: 106.62049, mean: 0.11106
[32m[0906 18-46-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10873, current rewards: 112.11582, mean: 0.11101
[32m[0906 18-46-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10873, current rewards: 106.91258, mean: 0.10086
[32m[0906 18-47-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10872, current rewards: 112.20229, mean: 0.10108
[32m[0906 18-47-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10872, current rewards: 117.49366, mean: 0.10129
[32m[0906 18-47-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10875, current rewards: 122.78475, mean: 0.10147
[32m[0906 18-47-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10877, current rewards: 127.98395, mean: 0.10157
[32m[0906 18-47-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10878, current rewards: 133.29876, mean: 0.10175
[32m[0906 18-47-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10883, current rewards: 138.61275, mean: 0.10192
[32m[0906 18-47-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10887, current rewards: 143.92868, mean: 0.10208
[32m[0906 18-47-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10889, current rewards: 142.92650, mean: 0.09789
[32m[0906 18-47-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10892, current rewards: 145.23044, mean: 0.09618
[32m[0906 18-47-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10894, current rewards: 151.76949, mean: 0.09729
[32m[0906 18-47-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10895, current rewards: 158.31396, mean: 0.09833
[32m[0906 18-48-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10886, current rewards: 164.09104, mean: 0.09885
[32m[0906 18-48-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10876, current rewards: 170.54053, mean: 0.09973
[32m[0906 18-48-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10867, current rewards: 176.98396, mean: 0.10056
[32m[0906 18-48-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10861, current rewards: 172.47202, mean: 0.09529
[32m[0906 18-48-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10852, current rewards: 178.38819, mean: 0.09591
[32m[0906 18-48-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10846, current rewards: 184.30386, mean: 0.09649
[32m[0906 18-48-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10839, current rewards: 190.22074, mean: 0.09705
[32m[0906 18-48-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10834, current rewards: 196.13601, mean: 0.09758
[32m[0906 18-48-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10835, current rewards: 201.99037, mean: 0.09805
[32m[0906 18-48-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10838, current rewards: 207.97842, mean: 0.09857
[32m[0906 18-48-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10839, current rewards: 213.93119, mean: 0.09904
[32m[0906 18-49-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10840, current rewards: 219.88548, mean: 0.09950
[32m[0906 18-49-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10842, current rewards: 225.83620, mean: 0.09993
[32m[0906 18-49-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10842, current rewards: 231.79383, mean: 0.10034
[32m[0906 18-49-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10842, current rewards: 237.74210, mean: 0.10074
[32m[0906 18-49-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10843, current rewards: 243.69379, mean: 0.10112
[32m[0906 18-49-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10844, current rewards: 250.35733, mean: 0.10177
[32m[0906 18-49-34 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 18-49-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-49-34 @MBExp.py:227][0m Rewards obtained: [255.00655882212612], Lows: [15], Highs: [10], Total time: 15043.935489000003
[32m[0906 18-51-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-51-42 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 18-51-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10546, current rewards: -4.65964, mean: -0.46596
[32m[0906 18-51-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10487, current rewards: 0.67717, mean: 0.01129
[32m[0906 18-51-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10497, current rewards: 6.12694, mean: 0.05570
[32m[0906 18-51-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10504, current rewards: 11.57429, mean: 0.07234
[32m[0906 18-52-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10510, current rewards: 17.02521, mean: 0.08107
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10518, current rewards: 22.47647, mean: 0.08645
[32m[0906 18-52-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10526, current rewards: 27.92470, mean: 0.09008
[32m[0906 18-52-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10527, current rewards: 33.37060, mean: 0.09270
[32m[0906 18-52-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10555, current rewards: 39.07026, mean: 0.09529
[32m[0906 18-52-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10598, current rewards: 44.52763, mean: 0.09680
[32m[0906 18-52-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10622, current rewards: 49.97926, mean: 0.09800
[32m[0906 18-52-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10647, current rewards: 55.43596, mean: 0.09899
[32m[0906 18-52-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10702, current rewards: 60.88888, mean: 0.09982
[32m[0906 18-52-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10746, current rewards: 66.34294, mean: 0.10052
[32m[0906 18-52-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10783, current rewards: 58.96978, mean: 0.08306
[32m[0906 18-53-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10817, current rewards: 64.39098, mean: 0.08472
[32m[0906 18-53-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10823, current rewards: 69.65260, mean: 0.08599
[32m[0906 18-53-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10830, current rewards: 75.08044, mean: 0.08730
[32m[0906 18-53-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10835, current rewards: 80.50517, mean: 0.08847
[32m[0906 18-53-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10837, current rewards: 85.93287, mean: 0.08951
[32m[0906 18-53-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10842, current rewards: 80.87121, mean: 0.08007
[32m[0906 18-53-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10847, current rewards: 86.29814, mean: 0.08141
[32m[0906 18-53-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10850, current rewards: 91.73456, mean: 0.08264
[32m[0906 18-53-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10852, current rewards: 97.16885, mean: 0.08377
[32m[0906 18-53-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10854, current rewards: 102.85462, mean: 0.08500
[32m[0906 18-54-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10855, current rewards: 108.27961, mean: 0.08594
[32m[0906 18-54-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10855, current rewards: 113.71973, mean: 0.08681
[32m[0906 18-54-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10858, current rewards: 106.58564, mean: 0.07837
[32m[0906 18-54-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10858, current rewards: 112.17198, mean: 0.07955
[32m[0906 18-54-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10858, current rewards: 117.75831, mean: 0.08066
[32m[0906 18-54-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10860, current rewards: 123.34345, mean: 0.08168
[32m[0906 18-54-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10860, current rewards: 128.92683, mean: 0.08265
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10852, current rewards: 117.51057, mean: 0.07299
[32m[0906 18-54-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10842, current rewards: 126.06505, mean: 0.07594
[32m[0906 18-54-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10832, current rewards: 133.12682, mean: 0.07785
[32m[0906 18-54-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10823, current rewards: 140.18079, mean: 0.07965
[32m[0906 18-54-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10815, current rewards: 147.22810, mean: 0.08134
[32m[0906 18-55-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10806, current rewards: 154.29185, mean: 0.08295
[32m[0906 18-55-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10800, current rewards: 151.24901, mean: 0.07919
[32m[0906 18-55-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10793, current rewards: 157.05220, mean: 0.08013
[32m[0906 18-55-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10788, current rewards: 162.85143, mean: 0.08102
[32m[0906 18-55-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10791, current rewards: 168.09426, mean: 0.08160
[32m[0906 18-55-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10793, current rewards: 173.74922, mean: 0.08235
[32m[0906 18-55-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10794, current rewards: 179.41119, mean: 0.08306
[32m[0906 18-55-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10797, current rewards: 185.06741, mean: 0.08374
[32m[0906 18-55-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10797, current rewards: 190.72677, mean: 0.08439
[32m[0906 18-55-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10798, current rewards: 196.39253, mean: 0.08502
[32m[0906 18-55-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10800, current rewards: 202.05333, mean: 0.08562
[32m[0906 18-56-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10802, current rewards: 207.70808, mean: 0.08619
[32m[0906 18-56-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10803, current rewards: 213.33196, mean: 0.08672
[32m[0906 18-56-13 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 18-56-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 18-56-13 @MBExp.py:227][0m Rewards obtained: [217.85205816424076], Lows: [28], Highs: [11], Total time: 15314.830290000004
[32m[0906 18-58-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-58-24 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 18-58-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10408, current rewards: -4.57419, mean: -0.45742
[32m[0906 18-58-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10557, current rewards: 1.28013, mean: 0.02134
[32m[0906 18-58-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10561, current rewards: 7.59314, mean: 0.06903
[32m[0906 18-58-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10543, current rewards: 13.91116, mean: 0.08694
[32m[0906 18-58-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10536, current rewards: 20.23148, mean: 0.09634
[32m[0906 18-58-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10528, current rewards: 26.54221, mean: 0.10209
[32m[0906 18-58-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10521, current rewards: 32.85244, mean: 0.10598
[32m[0906 18-59-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10515, current rewards: 39.15165, mean: 0.10875
[32m[0906 18-59-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10541, current rewards: 45.66397, mean: 0.11138
[32m[0906 18-59-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10576, current rewards: 51.97914, mean: 0.11300
[32m[0906 18-59-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10604, current rewards: 58.30078, mean: 0.11432
[32m[0906 18-59-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10631, current rewards: 64.61925, mean: 0.11539
[32m[0906 18-59-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10680, current rewards: 60.01283, mean: 0.09838
[32m[0906 18-59-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10722, current rewards: 65.93580, mean: 0.09990
[32m[0906 18-59-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10765, current rewards: 71.86309, mean: 0.10122
[32m[0906 18-59-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10778, current rewards: 77.79066, mean: 0.10236
[32m[0906 18-59-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10785, current rewards: 83.24241, mean: 0.10277
[32m[0906 18-59-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10795, current rewards: 89.04642, mean: 0.10354
[32m[0906 19-00-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10800, current rewards: 94.84953, mean: 0.10423
[32m[0906 19-00-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10805, current rewards: 100.65759, mean: 0.10485
[32m[0906 19-00-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10809, current rewards: 106.46574, mean: 0.10541
[32m[0906 19-00-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10810, current rewards: 101.71700, mean: 0.09596
[32m[0906 19-00-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10812, current rewards: 107.32912, mean: 0.09669
[32m[0906 19-00-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10817, current rewards: 113.05185, mean: 0.09746
[32m[0906 19-00-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10818, current rewards: 120.30913, mean: 0.09943
[32m[0906 19-00-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10818, current rewards: 128.05811, mean: 0.10163
[32m[0906 19-00-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10821, current rewards: 135.51830, mean: 0.10345
[32m[0906 19-00-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10822, current rewards: 142.97850, mean: 0.10513
[32m[0906 19-00-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10823, current rewards: 150.43869, mean: 0.10669
[32m[0906 19-01-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10826, current rewards: 157.89888, mean: 0.10815
[32m[0906 19-01-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10827, current rewards: 165.35907, mean: 0.10951
[32m[0906 19-01-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10828, current rewards: 141.79075, mean: 0.09089
[32m[0906 19-01-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10832, current rewards: 91.79075, mean: 0.05701
[32m[0906 19-01-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10823, current rewards: 41.79075, mean: 0.02518
[32m[0906 19-01-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10815, current rewards: -8.20925, mean: -0.00480
[32m[0906 19-01-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10807, current rewards: -58.20925, mean: -0.03307
[32m[0906 19-01-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10799, current rewards: -108.20925, mean: -0.05978
[32m[0906 19-01-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10792, current rewards: -158.20925, mean: -0.08506
[32m[0906 19-01-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10785, current rewards: -208.20925, mean: -0.10901
[32m[0906 19-01-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10778, current rewards: -258.20925, mean: -0.13174
[32m[0906 19-02-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10778, current rewards: -308.20925, mean: -0.15334
[32m[0906 19-02-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10781, current rewards: -358.20925, mean: -0.17389
[32m[0906 19-02-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10783, current rewards: -408.20925, mean: -0.19346
[32m[0906 19-02-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10785, current rewards: -458.20925, mean: -0.21213
[32m[0906 19-02-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10787, current rewards: -508.20925, mean: -0.22996
[32m[0906 19-02-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10791, current rewards: -558.20925, mean: -0.24700
[32m[0906 19-02-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10792, current rewards: -608.20925, mean: -0.26329
[32m[0906 19-02-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10795, current rewards: -658.20925, mean: -0.27890
[32m[0906 19-02-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10795, current rewards: -708.20925, mean: -0.29386
[32m[0906 19-02-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10798, current rewards: -758.20925, mean: -0.30822
[32m[0906 19-02-55 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 19-02-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-02-55 @MBExp.py:227][0m Rewards obtained: [-798.2092450340787], Lows: [10], Highs: [972], Total time: 15585.604807000003
[32m[0906 19-05-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-05-08 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 19-05-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10436, current rewards: -5.60430, mean: -0.56043
[32m[0906 19-05-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10554, current rewards: -0.11661, mean: -0.00194
[32m[0906 19-05-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10563, current rewards: 5.61507, mean: 0.05105
[32m[0906 19-05-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10555, current rewards: 11.35558, mean: 0.07097
[32m[0906 19-05-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10562, current rewards: 17.08780, mean: 0.08137
[32m[0906 19-05-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10552, current rewards: 22.81911, mean: 0.08777
[32m[0906 19-05-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10549, current rewards: 28.55704, mean: 0.09212
[32m[0906 19-05-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10551, current rewards: 34.29655, mean: 0.09527
[32m[0906 19-05-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10585, current rewards: 40.66588, mean: 0.09919
[32m[0906 19-05-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10619, current rewards: 37.88786, mean: 0.08236
[32m[0906 19-06-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10655, current rewards: 43.45101, mean: 0.08520
[32m[0906 19-06-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10674, current rewards: 49.01416, mean: 0.08753
[32m[0906 19-06-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10720, current rewards: 54.57731, mean: 0.08947
[32m[0906 19-06-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10770, current rewards: 60.14046, mean: 0.09112
[32m[0906 19-06-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10793, current rewards: 65.70360, mean: 0.09254
[32m[0906 19-06-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10803, current rewards: 71.26675, mean: 0.09377
[32m[0906 19-06-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10812, current rewards: 37.93570, mean: 0.04683
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10818, current rewards: -12.06430, mean: -0.01403
[32m[0906 19-06-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10824, current rewards: -62.06430, mean: -0.06820
[32m[0906 19-06-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10832, current rewards: -112.06430, mean: -0.11673
[32m[0906 19-06-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10834, current rewards: -162.06430, mean: -0.16046
[32m[0906 19-07-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10840, current rewards: -212.06430, mean: -0.20006
[32m[0906 19-07-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10846, current rewards: -262.06430, mean: -0.23609
[32m[0906 19-07-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10849, current rewards: -312.06430, mean: -0.26902
[32m[0906 19-07-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10851, current rewards: -362.06430, mean: -0.29923
[32m[0906 19-07-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10856, current rewards: -412.06430, mean: -0.32704
[32m[0906 19-07-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10860, current rewards: -462.06430, mean: -0.35272
[32m[0906 19-07-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10866, current rewards: -512.06430, mean: -0.37652
[32m[0906 19-07-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10871, current rewards: -562.06430, mean: -0.39863
[32m[0906 19-07-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10873, current rewards: -612.06430, mean: -0.41922
[32m[0906 19-07-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10873, current rewards: -662.06430, mean: -0.43845
[32m[0906 19-07-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10876, current rewards: -712.06430, mean: -0.45645
[32m[0906 19-08-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10871, current rewards: -762.06430, mean: -0.47333
[32m[0906 19-08-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10862, current rewards: -812.06430, mean: -0.48920
[32m[0906 19-08-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10854, current rewards: -862.06430, mean: -0.50413
[32m[0906 19-08-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10846, current rewards: -912.06430, mean: -0.51822
[32m[0906 19-08-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10838, current rewards: -962.06430, mean: -0.53153
[32m[0906 19-08-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10831, current rewards: -1012.06430, mean: -0.54412
[32m[0906 19-08-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10825, current rewards: -1062.06430, mean: -0.55605
[32m[0906 19-08-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10819, current rewards: -1112.06430, mean: -0.56738
[32m[0906 19-08-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10824, current rewards: -1162.06430, mean: -0.57814
[32m[0906 19-08-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10826, current rewards: -1212.06430, mean: -0.58838
[32m[0906 19-08-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10831, current rewards: -1262.06430, mean: -0.59813
[32m[0906 19-09-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10831, current rewards: -1312.06430, mean: -0.60744
[32m[0906 19-09-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10833, current rewards: -1362.06430, mean: -0.61632
[32m[0906 19-09-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10836, current rewards: -1412.06430, mean: -0.62481
[32m[0906 19-09-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10839, current rewards: -1462.06430, mean: -0.63293
[32m[0906 19-09-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10841, current rewards: -1512.06430, mean: -0.64071
[32m[0906 19-09-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10844, current rewards: -1562.06430, mean: -0.64816
[32m[0906 19-09-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10845, current rewards: -1612.06430, mean: -0.65531
[32m[0906 19-09-40 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 19-09-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-09-40 @MBExp.py:227][0m Rewards obtained: [-1652.0643020609753], Lows: [6], Highs: [1729], Total time: 15857.509409000004
[32m[0906 19-11-55 @MBExp.py:144][0m ####################################################################
[32m[0906 19-11-55 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 19-11-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10432, current rewards: -4.53999, mean: -0.45400
[32m[0906 19-12-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10495, current rewards: 0.57008, mean: 0.00950
[32m[0906 19-12-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10503, current rewards: 5.71688, mean: 0.05197
[32m[0906 19-12-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10527, current rewards: 10.86370, mean: 0.06790
[32m[0906 19-12-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10527, current rewards: 16.00834, mean: 0.07623
[32m[0906 19-12-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10531, current rewards: 21.16319, mean: 0.08140
[32m[0906 19-12-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10534, current rewards: 26.31145, mean: 0.08488
[32m[0906 19-12-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10528, current rewards: 31.46568, mean: 0.08740
[32m[0906 19-12-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10564, current rewards: 36.52944, mean: 0.08910
[32m[0906 19-12-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10601, current rewards: 34.07484, mean: 0.07408
[32m[0906 19-12-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10625, current rewards: 39.32078, mean: 0.07710
[32m[0906 19-12-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10648, current rewards: 44.52697, mean: 0.07951
[32m[0906 19-13-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10702, current rewards: 49.73329, mean: 0.08153
[32m[0906 19-13-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10738, current rewards: 54.93272, mean: 0.08323
[32m[0906 19-13-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10748, current rewards: 60.13536, mean: 0.08470
[32m[0906 19-13-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10760, current rewards: 65.34191, mean: 0.08598
[32m[0906 19-13-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10772, current rewards: 70.92077, mean: 0.08756
[32m[0906 19-13-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10781, current rewards: 76.18390, mean: 0.08859
[32m[0906 19-13-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10784, current rewards: 81.44183, mean: 0.08950
[32m[0906 19-13-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10787, current rewards: 86.70294, mean: 0.09032
[32m[0906 19-13-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10795, current rewards: 91.96244, mean: 0.09105
[32m[0906 19-13-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10801, current rewards: 97.22396, mean: 0.09172
[32m[0906 19-13-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10805, current rewards: 102.48457, mean: 0.09233
[32m[0906 19-14-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10812, current rewards: 97.46559, mean: 0.08402
[32m[0906 19-14-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10816, current rewards: 103.56094, mean: 0.08559
[32m[0906 19-14-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10817, current rewards: 109.21809, mean: 0.08668
[32m[0906 19-14-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10821, current rewards: 114.87540, mean: 0.08769
[32m[0906 19-14-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10824, current rewards: 120.53378, mean: 0.08863
[32m[0906 19-14-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10826, current rewards: 126.18969, mean: 0.08950
[32m[0906 19-14-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10826, current rewards: 131.84780, mean: 0.09031
[32m[0906 19-14-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10825, current rewards: 137.50390, mean: 0.09106
[32m[0906 19-14-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10822, current rewards: 143.16347, mean: 0.09177
[32m[0906 19-14-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10813, current rewards: 146.56226, mean: 0.09103
[32m[0906 19-14-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10804, current rewards: 144.03623, mean: 0.08677
[32m[0906 19-15-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10794, current rewards: 149.49958, mean: 0.08743
[32m[0906 19-15-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10787, current rewards: 154.96359, mean: 0.08805
[32m[0906 19-15-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10778, current rewards: 160.42586, mean: 0.08863
[32m[0906 19-15-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10772, current rewards: 165.89092, mean: 0.08919
[32m[0906 19-15-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10765, current rewards: 171.35514, mean: 0.08971
[32m[0906 19-15-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10760, current rewards: 176.81682, mean: 0.09021
[32m[0906 19-15-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10763, current rewards: 182.27258, mean: 0.09068
[32m[0906 19-15-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10767, current rewards: 187.30430, mean: 0.09092
[32m[0906 19-15-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10769, current rewards: 192.87067, mean: 0.09141
[32m[0906 19-15-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10770, current rewards: 198.43470, mean: 0.09187
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10774, current rewards: 203.99709, mean: 0.09231
[32m[0906 19-15-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10776, current rewards: 209.56476, mean: 0.09273
[32m[0906 19-16-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10778, current rewards: 197.84876, mean: 0.08565
[32m[0906 19-16-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10781, current rewards: 203.08142, mean: 0.08605
[32m[0906 19-16-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10784, current rewards: 208.31882, mean: 0.08644
[32m[0906 19-16-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10786, current rewards: 214.27725, mean: 0.08710
[32m[0906 19-16-25 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 19-16-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-16-26 @MBExp.py:227][0m Rewards obtained: [218.53819197922394], Lows: [19], Highs: [11], Total time: 16128.021111000004
[32m[0906 19-18-42 @MBExp.py:144][0m ####################################################################
[32m[0906 19-18-42 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 19-18-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10421, current rewards: 1.15588, mean: 0.11559
[32m[0906 19-18-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10562, current rewards: 6.14952, mean: 0.10249
[32m[0906 19-18-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10538, current rewards: 11.14156, mean: 0.10129
[32m[0906 19-18-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10538, current rewards: 16.13261, mean: 0.10083
[32m[0906 19-19-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10553, current rewards: 21.12468, mean: 0.10059
[32m[0906 19-19-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10542, current rewards: 26.11824, mean: 0.10045
[32m[0906 19-19-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10533, current rewards: 31.11094, mean: 0.10036
[32m[0906 19-19-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10536, current rewards: 36.46274, mean: 0.10129
[32m[0906 19-19-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10583, current rewards: 42.15406, mean: 0.10281
[32m[0906 19-19-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10613, current rewards: 47.83113, mean: 0.10398
[32m[0906 19-19-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10647, current rewards: 44.59986, mean: 0.08745
[32m[0906 19-19-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10668, current rewards: -5.40014, mean: -0.00964
[32m[0906 19-19-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10717, current rewards: -55.40014, mean: -0.09082
[32m[0906 19-19-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10739, current rewards: -105.40014, mean: -0.15970
[32m[0906 19-19-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10749, current rewards: -155.40014, mean: -0.21887
[32m[0906 19-20-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10759, current rewards: -205.40014, mean: -0.27026
[32m[0906 19-20-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10772, current rewards: -255.40014, mean: -0.31531
[32m[0906 19-20-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10778, current rewards: -305.40014, mean: -0.35512
[32m[0906 19-20-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10783, current rewards: -355.40014, mean: -0.39055
[32m[0906 19-20-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10788, current rewards: -405.40014, mean: -0.42229
[32m[0906 19-20-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10796, current rewards: -455.40014, mean: -0.45089
[32m[0906 19-20-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10801, current rewards: -505.40014, mean: -0.47679
[32m[0906 19-20-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10804, current rewards: -555.40014, mean: -0.50036
[32m[0906 19-20-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10808, current rewards: -605.40014, mean: -0.52190
[32m[0906 19-20-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10814, current rewards: -655.40014, mean: -0.54165
[32m[0906 19-20-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10817, current rewards: -705.40014, mean: -0.55984
[32m[0906 19-21-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10820, current rewards: -755.40014, mean: -0.57664
[32m[0906 19-21-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10823, current rewards: -805.40014, mean: -0.59221
[32m[0906 19-21-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10824, current rewards: -855.40014, mean: -0.60667
[32m[0906 19-21-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10827, current rewards: -905.40014, mean: -0.62014
[32m[0906 19-21-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10833, current rewards: -955.40014, mean: -0.63272
[32m[0906 19-21-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10825, current rewards: -1005.40014, mean: -0.64449
[32m[0906 19-21-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10817, current rewards: -1055.40014, mean: -0.65553
[32m[0906 19-21-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10810, current rewards: -1105.40014, mean: -0.66590
[32m[0906 19-21-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10803, current rewards: -1155.40014, mean: -0.67567
[32m[0906 19-21-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10797, current rewards: -1205.40014, mean: -0.68489
[32m[0906 19-21-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10792, current rewards: -1255.40014, mean: -0.69359
[32m[0906 19-22-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10784, current rewards: -1305.40014, mean: -0.70183
[32m[0906 19-22-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10778, current rewards: -1355.40014, mean: -0.70963
[32m[0906 19-22-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10778, current rewards: -1405.40014, mean: -0.71704
[32m[0906 19-22-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10780, current rewards: -1455.40014, mean: -0.72408
[32m[0906 19-22-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10783, current rewards: -1505.40014, mean: -0.73078
[32m[0906 19-22-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10788, current rewards: -1555.40014, mean: -0.73716
[32m[0906 19-22-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10791, current rewards: -1605.40014, mean: -0.74324
[32m[0906 19-22-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10793, current rewards: -1655.40014, mean: -0.74905
[32m[0906 19-22-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10796, current rewards: -1705.40014, mean: -0.75460
[32m[0906 19-22-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10798, current rewards: -1755.40014, mean: -0.75991
[32m[0906 19-22-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10799, current rewards: -1805.40014, mean: -0.76500
[32m[0906 19-23-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10803, current rewards: -1855.40014, mean: -0.76988
[32m[0906 19-23-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10804, current rewards: -1905.40014, mean: -0.77455
[32m[0906 19-23-13 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 19-23-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-23-13 @MBExp.py:227][0m Rewards obtained: [-1945.4001371374072], Lows: [0], Highs: [1998], Total time: 16398.922690000003
[32m[0906 19-25-33 @MBExp.py:144][0m ####################################################################
[32m[0906 19-25-33 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 19-25-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10425, current rewards: -4.61969, mean: -0.46197
[32m[0906 19-25-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10569, current rewards: 0.37141, mean: 0.00619
[32m[0906 19-25-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10576, current rewards: 5.57048, mean: 0.05064
[32m[0906 19-25-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10570, current rewards: 10.77087, mean: 0.06732
[32m[0906 19-25-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10587, current rewards: 15.97653, mean: 0.07608
[32m[0906 19-26-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10603, current rewards: 21.17948, mean: 0.08146
[32m[0906 19-26-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10597, current rewards: 26.38711, mean: 0.08512
[32m[0906 19-26-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10601, current rewards: 31.84878, mean: 0.08847
[32m[0906 19-26-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10644, current rewards: 37.06217, mean: 0.09040
[32m[0906 19-26-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10675, current rewards: 42.27679, mean: 0.09191
[32m[0906 19-26-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10704, current rewards: 47.49283, mean: 0.09312
[32m[0906 19-26-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10724, current rewards: 52.70886, mean: 0.09412
[32m[0906 19-26-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10747, current rewards: 57.92864, mean: 0.09496
[32m[0906 19-26-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10765, current rewards: 63.14567, mean: 0.09568
[32m[0906 19-26-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10777, current rewards: 57.96957, mean: 0.08165
[32m[0906 19-26-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10788, current rewards: 63.59149, mean: 0.08367
[32m[0906 19-27-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10801, current rewards: 68.92681, mean: 0.08509
[32m[0906 19-27-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10807, current rewards: 74.25103, mean: 0.08634
[32m[0906 19-27-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10813, current rewards: 79.58415, mean: 0.08746
[32m[0906 19-27-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10822, current rewards: 84.91768, mean: 0.08846
[32m[0906 19-27-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10826, current rewards: 90.24992, mean: 0.08936
[32m[0906 19-27-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10829, current rewards: 95.58809, mean: 0.09018
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10842, current rewards: 89.29451, mean: 0.08045
[32m[0906 19-27-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10847, current rewards: 94.88361, mean: 0.08180
[32m[0906 19-27-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10849, current rewards: 103.45981, mean: 0.08550
[32m[0906 19-27-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10853, current rewards: 112.24847, mean: 0.08909
[32m[0906 19-27-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10855, current rewards: 119.76420, mean: 0.09142
[32m[0906 19-28-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10858, current rewards: 122.18821, mean: 0.08984
[32m[0906 19-28-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10861, current rewards: 124.61222, mean: 0.08838
[32m[0906 19-28-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10861, current rewards: 127.03623, mean: 0.08701
[32m[0906 19-28-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10853, current rewards: 129.46024, mean: 0.08574
[32m[0906 19-28-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10845, current rewards: 131.88425, mean: 0.08454
[32m[0906 19-28-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10834, current rewards: 134.30826, mean: 0.08342
[32m[0906 19-28-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10824, current rewards: 136.73227, mean: 0.08237
[32m[0906 19-28-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10818, current rewards: 139.15628, mean: 0.08138
[32m[0906 19-28-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10810, current rewards: 130.04701, mean: 0.07389
[32m[0906 19-28-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10802, current rewards: 80.04701, mean: 0.04422
[32m[0906 19-28-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10797, current rewards: 30.04701, mean: 0.01615
[32m[0906 19-29-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10790, current rewards: -19.95299, mean: -0.01045
[32m[0906 19-29-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10791, current rewards: -69.95299, mean: -0.03569
[32m[0906 19-29-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10795, current rewards: -119.95299, mean: -0.05968
[32m[0906 19-29-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10797, current rewards: -169.95299, mean: -0.08250
[32m[0906 19-29-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10800, current rewards: -219.95299, mean: -0.10424
[32m[0906 19-29-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10805, current rewards: -269.95299, mean: -0.12498
[32m[0906 19-29-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10808, current rewards: -319.95299, mean: -0.14478
[32m[0906 19-29-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10810, current rewards: -369.95299, mean: -0.16370
[32m[0906 19-29-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10813, current rewards: -419.95299, mean: -0.18180
[32m[0906 19-29-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10815, current rewards: -469.95299, mean: -0.19913
[32m[0906 19-29-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10818, current rewards: -519.95299, mean: -0.21575
[32m[0906 19-30-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10819, current rewards: -569.95299, mean: -0.23169
[32m[0906 19-30-04 @Agent.py:117][0m Average action selection time: 0.1082
[32m[0906 19-30-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-30-04 @MBExp.py:227][0m Rewards obtained: [-609.9529921173134], Lows: [11], Highs: [756], Total time: 16670.208013000003
[32m[0906 19-32-27 @MBExp.py:144][0m ####################################################################
[32m[0906 19-32-27 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 19-32-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10463, current rewards: -12.95174, mean: -1.29517
[32m[0906 19-32-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10535, current rewards: -26.87105, mean: -0.44785
[32m[0906 19-32-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10537, current rewards: -22.23225, mean: -0.20211
[32m[0906 19-32-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10538, current rewards: -17.58831, mean: -0.10993
[32m[0906 19-32-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10541, current rewards: -12.94889, mean: -0.06166
[32m[0906 19-32-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10539, current rewards: -8.30780, mean: -0.03195
[32m[0906 19-33-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10537, current rewards: -3.66712, mean: -0.01183
[32m[0906 19-33-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10543, current rewards: 0.45846, mean: 0.00127
[32m[0906 19-33-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10594, current rewards: -4.94380, mean: -0.01206
[32m[0906 19-33-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10627, current rewards: 0.75490, mean: 0.00164
[32m[0906 19-33-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10663, current rewards: 6.45750, mean: 0.01266
[32m[0906 19-33-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10673, current rewards: 12.15904, mean: 0.02171
[32m[0906 19-33-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10692, current rewards: 17.88517, mean: 0.02932
[32m[0906 19-33-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10716, current rewards: 23.60055, mean: 0.03576
[32m[0906 19-33-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10731, current rewards: 29.29665, mean: 0.04126
[32m[0906 19-33-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10747, current rewards: 35.03104, mean: 0.04609
[32m[0906 19-33-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10766, current rewards: 41.04797, mean: 0.05068
[32m[0906 19-34-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10776, current rewards: 46.37944, mean: 0.05393
[32m[0906 19-34-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10784, current rewards: 51.71122, mean: 0.05683
[32m[0906 19-34-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10794, current rewards: 57.05611, mean: 0.05943
[32m[0906 19-34-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10799, current rewards: 62.38404, mean: 0.06177
[32m[0906 19-34-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10804, current rewards: 67.71240, mean: 0.06388
[32m[0906 19-34-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10810, current rewards: 72.82549, mean: 0.06561
[32m[0906 19-34-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10811, current rewards: 78.94975, mean: 0.06806
[32m[0906 19-34-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10813, current rewards: 84.56524, mean: 0.06989
[32m[0906 19-34-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10817, current rewards: 90.60197, mean: 0.07191
[32m[0906 19-34-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10817, current rewards: 96.63965, mean: 0.07377
[32m[0906 19-34-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10818, current rewards: 102.67383, mean: 0.07550
[32m[0906 19-35-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10822, current rewards: 108.71111, mean: 0.07710
[32m[0906 19-35-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10816, current rewards: 114.75044, mean: 0.07860
[32m[0906 19-35-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10807, current rewards: 120.78503, mean: 0.07999
[32m[0906 19-35-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10800, current rewards: 126.82173, mean: 0.08130
[32m[0906 19-35-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10790, current rewards: 133.70310, mean: 0.08305
[32m[0906 19-35-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10783, current rewards: 116.28761, mean: 0.07005
[32m[0906 19-35-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10778, current rewards: 123.56182, mean: 0.07226
[32m[0906 19-35-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10770, current rewards: 130.83603, mean: 0.07434
[32m[0906 19-35-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10764, current rewards: 116.34605, mean: 0.06428
[32m[0906 19-35-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10761, current rewards: 66.34605, mean: 0.03567
[32m[0906 19-35-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10757, current rewards: 16.34605, mean: 0.00856
[32m[0906 19-35-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10761, current rewards: -33.65395, mean: -0.01717
[32m[0906 19-36-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10766, current rewards: -83.65395, mean: -0.04162
[32m[0906 19-36-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10771, current rewards: -133.65395, mean: -0.06488
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10773, current rewards: -183.65395, mean: -0.08704
[32m[0906 19-36-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10777, current rewards: -233.65395, mean: -0.10817
[32m[0906 19-36-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10779, current rewards: -283.65395, mean: -0.12835
[32m[0906 19-36-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10780, current rewards: -333.65395, mean: -0.14763
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10782, current rewards: -383.65395, mean: -0.16608
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10783, current rewards: -433.65395, mean: -0.18375
[32m[0906 19-36-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10784, current rewards: -483.65395, mean: -0.20069
[32m[0906 19-36-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10786, current rewards: -533.65395, mean: -0.21693
[32m[0906 19-36-57 @Agent.py:117][0m Average action selection time: 0.1079
[32m[0906 19-36-57 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-36-57 @MBExp.py:227][0m Rewards obtained: [-573.6539536189462], Lows: [30], Highs: [714], Total time: 16940.679556000003
[32m[0906 19-39-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-39-22 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 19-39-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10600, current rewards: -4.51195, mean: -0.45119
[32m[0906 19-39-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10621, current rewards: 4.97911, mean: 0.08299
[32m[0906 19-39-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10593, current rewards: 13.96363, mean: 0.12694
[32m[0906 19-39-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10574, current rewards: 23.30687, mean: 0.14567
[32m[0906 19-39-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10575, current rewards: 32.72575, mean: 0.15584
[32m[0906 19-39-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10574, current rewards: 41.60496, mean: 0.16002
[32m[0906 19-39-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10564, current rewards: 47.06107, mean: 0.15181
[32m[0906 19-40-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10578, current rewards: 52.77509, mean: 0.14660
[32m[0906 19-40-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10619, current rewards: 58.74909, mean: 0.14329
[32m[0906 19-40-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10650, current rewards: 64.40612, mean: 0.14001
[32m[0906 19-40-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10678, current rewards: 57.87423, mean: 0.11348
[32m[0906 19-40-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10666, current rewards: 63.16281, mean: 0.11279
[32m[0906 19-40-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10684, current rewards: 68.45376, mean: 0.11222
[32m[0906 19-40-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10707, current rewards: 73.74552, mean: 0.11174
[32m[0906 19-40-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10725, current rewards: 79.03739, mean: 0.11132
[32m[0906 19-40-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10735, current rewards: 84.32802, mean: 0.11096
[32m[0906 19-40-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10751, current rewards: 89.34621, mean: 0.11030
[32m[0906 19-40-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10761, current rewards: 94.98793, mean: 0.11045
[32m[0906 19-41-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10771, current rewards: 100.69530, mean: 0.11065
[32m[0906 19-41-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10781, current rewards: 90.16312, mean: 0.09392
[32m[0906 19-41-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10784, current rewards: 95.77474, mean: 0.09483
[32m[0906 19-41-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10789, current rewards: 101.38579, mean: 0.09565
[32m[0906 19-41-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10799, current rewards: 107.00504, mean: 0.09640
[32m[0906 19-41-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10804, current rewards: 112.62082, mean: 0.09709
[32m[0906 19-41-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10806, current rewards: 118.22973, mean: 0.09771
[32m[0906 19-41-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10813, current rewards: 123.84121, mean: 0.09829
[32m[0906 19-41-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10816, current rewards: 129.45791, mean: 0.09882
[32m[0906 19-41-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10819, current rewards: 135.07639, mean: 0.09932
[32m[0906 19-41-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10823, current rewards: 140.69031, mean: 0.09978
[32m[0906 19-42-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10815, current rewards: 146.30038, mean: 0.10021
[32m[0906 19-42-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10806, current rewards: 151.91076, mean: 0.10060
[32m[0906 19-42-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10800, current rewards: 157.52844, mean: 0.10098
[32m[0906 19-42-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10794, current rewards: 163.49450, mean: 0.10155
[32m[0906 19-42-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10786, current rewards: 169.14232, mean: 0.10189
[32m[0906 19-42-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10782, current rewards: 174.79331, mean: 0.10222
[32m[0906 19-42-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10776, current rewards: 169.94145, mean: 0.09656
[32m[0906 19-42-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10770, current rewards: 176.08820, mean: 0.09729
[32m[0906 19-42-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10765, current rewards: 182.24528, mean: 0.09798
[32m[0906 19-42-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10764, current rewards: 188.40416, mean: 0.09864
[32m[0906 19-42-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10768, current rewards: 194.55982, mean: 0.09927
[32m[0906 19-42-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10772, current rewards: 201.44412, mean: 0.10022
[32m[0906 19-43-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10777, current rewards: 207.71452, mean: 0.10083
[32m[0906 19-43-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10781, current rewards: 213.88149, mean: 0.10137
[32m[0906 19-43-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10785, current rewards: 220.04758, mean: 0.10187
[32m[0906 19-43-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10789, current rewards: 226.21993, mean: 0.10236
[32m[0906 19-43-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10793, current rewards: 231.70441, mean: 0.10252
[32m[0906 19-43-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10796, current rewards: 237.28644, mean: 0.10272
[32m[0906 19-43-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10799, current rewards: 242.86981, mean: 0.10291
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10802, current rewards: 248.44796, mean: 0.10309
[32m[0906 19-43-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10804, current rewards: 253.55161, mean: 0.10307
[32m[0906 19-43-53 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 19-43-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-43-53 @MBExp.py:227][0m Rewards obtained: [257.9748835551727], Lows: [16], Highs: [10], Total time: 17211.660672
[32m[0906 19-46-20 @MBExp.py:144][0m ####################################################################
[32m[0906 19-46-20 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 19-46-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10698, current rewards: -14.00000, mean: -1.40000
[32m[0906 19-46-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10657, current rewards: -13.22996, mean: -0.22050
[32m[0906 19-46-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10634, current rewards: -7.21726, mean: -0.06561
[32m[0906 19-46-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10639, current rewards: -1.20116, mean: -0.00751
[32m[0906 19-46-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10637, current rewards: 4.80989, mean: 0.02290
[32m[0906 19-46-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10621, current rewards: 10.82445, mean: 0.04163
[32m[0906 19-46-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10620, current rewards: 16.83686, mean: 0.05431
[32m[0906 19-46-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10626, current rewards: 23.44234, mean: 0.06512
[32m[0906 19-47-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10668, current rewards: 29.31876, mean: 0.07151
[32m[0906 19-47-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10709, current rewards: 35.18615, mean: 0.07649
[32m[0906 19-47-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10716, current rewards: 41.05413, mean: 0.08050
[32m[0906 19-47-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10707, current rewards: 36.74639, mean: 0.06562
[32m[0906 19-47-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10734, current rewards: 42.40396, mean: 0.06951
[32m[0906 19-47-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10760, current rewards: 48.05792, mean: 0.07282
[32m[0906 19-47-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10789, current rewards: 53.71531, mean: 0.07566
[32m[0906 19-47-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10806, current rewards: 59.06964, mean: 0.07772
[32m[0906 19-47-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10814, current rewards: 64.10704, mean: 0.07914
[32m[0906 19-47-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10822, current rewards: 41.61289, mean: 0.04839
[32m[0906 19-47-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10834, current rewards: -1.45092, mean: -0.00159
[32m[0906 19-48-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10841, current rewards: -46.70566, mean: -0.04865
[32m[0906 19-48-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10843, current rewards: -94.15250, mean: -0.09322
[32m[0906 19-48-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10851, current rewards: -137.24881, mean: -0.12948
[32m[0906 19-48-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10857, current rewards: -182.47216, mean: -0.16439
[32m[0906 19-48-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10860, current rewards: -229.91174, mean: -0.19820
[32m[0906 19-48-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10866, current rewards: -284.16622, mean: -0.23485
[32m[0906 19-48-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10870, current rewards: -343.64922, mean: -0.27274
[32m[0906 19-48-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10873, current rewards: -406.14610, mean: -0.31004
[32m[0906 19-48-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10876, current rewards: -466.14853, mean: -0.34276
[32m[0906 19-48-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10865, current rewards: -526.37121, mean: -0.37331
[32m[0906 19-48-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10856, current rewards: -573.93029, mean: -0.39310
[32m[0906 19-49-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10848, current rewards: -568.48818, mean: -0.37648
[32m[0906 19-49-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10840, current rewards: -563.04486, mean: -0.36093
[32m[0906 19-49-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10832, current rewards: -557.79475, mean: -0.34646
[32m[0906 19-49-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10829, current rewards: -552.36036, mean: -0.33275
[32m[0906 19-49-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10821, current rewards: -546.94322, mean: -0.31985
[32m[0906 19-49-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10816, current rewards: -541.53200, mean: -0.30769
[32m[0906 19-49-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10813, current rewards: -536.11599, mean: -0.29620
[32m[0906 19-49-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10807, current rewards: -530.69625, mean: -0.28532
[32m[0906 19-49-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10806, current rewards: -525.28203, mean: -0.27502
[32m[0906 19-49-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10811, current rewards: -519.86532, mean: -0.26524
[32m[0906 19-49-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10815, current rewards: -514.38596, mean: -0.25591
[32m[0906 19-50-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10818, current rewards: -536.04167, mean: -0.26021
[32m[0906 19-50-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10823, current rewards: -564.80986, mean: -0.26768
[32m[0906 19-50-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10827, current rewards: -591.41312, mean: -0.27380
[32m[0906 19-50-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10830, current rewards: -620.19156, mean: -0.28063
[32m[0906 19-50-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10833, current rewards: -644.28806, mean: -0.28508
[32m[0906 19-50-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10836, current rewards: -638.37018, mean: -0.27635
[32m[0906 19-50-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10839, current rewards: -632.45231, mean: -0.26799
[32m[0906 19-50-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10842, current rewards: -626.53444, mean: -0.25997
[32m[0906 19-50-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10845, current rewards: -642.77510, mean: -0.26129
[32m[0906 19-50-52 @Agent.py:117][0m Average action selection time: 0.1085
[32m[0906 19-50-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-50-52 @MBExp.py:227][0m Rewards obtained: [-682.7750992159972], Lows: [442], Highs: [70], Total time: 17483.627082000003
[32m[0906 19-53-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-53-22 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 19-53-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10482, current rewards: -12.89860, mean: -1.28986
[32m[0906 19-53-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10548, current rewards: -9.29785, mean: -0.15496
[32m[0906 19-53-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10569, current rewards: -3.94540, mean: -0.03587
[32m[0906 19-53-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10566, current rewards: 1.41212, mean: 0.00883
[32m[0906 19-53-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10568, current rewards: 6.76362, mean: 0.03221
[32m[0906 19-53-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10585, current rewards: 12.12106, mean: 0.04662
[32m[0906 19-53-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10580, current rewards: 17.46834, mean: 0.05635
[32m[0906 19-54-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10588, current rewards: 22.86725, mean: 0.06352
[32m[0906 19-54-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10635, current rewards: 28.22145, mean: 0.06883
[32m[0906 19-54-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10665, current rewards: 23.17768, mean: 0.05039
[32m[0906 19-54-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10666, current rewards: 28.60745, mean: 0.05609
[32m[0906 19-54-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10666, current rewards: 34.04450, mean: 0.06079
[32m[0906 19-54-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10684, current rewards: 39.48299, mean: 0.06473
[32m[0906 19-54-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10704, current rewards: 44.91313, mean: 0.06805
[32m[0906 19-54-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10726, current rewards: 50.34795, mean: 0.07091
[32m[0906 19-54-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10741, current rewards: 55.56357, mean: 0.07311
[32m[0906 19-54-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10754, current rewards: 50.24634, mean: 0.06203
[32m[0906 19-54-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10768, current rewards: 55.59736, mean: 0.06465
[32m[0906 19-55-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10777, current rewards: 60.94553, mean: 0.06697
[32m[0906 19-55-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10786, current rewards: 66.29533, mean: 0.06906
[32m[0906 19-55-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10795, current rewards: 71.64835, mean: 0.07094
[32m[0906 19-55-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10803, current rewards: 76.99806, mean: 0.07264
[32m[0906 19-55-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10808, current rewards: 82.35068, mean: 0.07419
[32m[0906 19-55-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10816, current rewards: 87.70456, mean: 0.07561
[32m[0906 19-55-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10822, current rewards: 94.29775, mean: 0.07793
[32m[0906 19-55-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10826, current rewards: 99.79061, mean: 0.07920
[32m[0906 19-55-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10833, current rewards: 98.68057, mean: 0.07533
[32m[0906 19-55-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10825, current rewards: 104.15931, mean: 0.07659
[32m[0906 19-55-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10817, current rewards: 109.63811, mean: 0.07776
[32m[0906 19-56-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10812, current rewards: 115.11731, mean: 0.07885
[32m[0906 19-56-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10805, current rewards: 120.59678, mean: 0.07987
[32m[0906 19-56-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10798, current rewards: 126.07417, mean: 0.08082
[32m[0906 19-56-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10790, current rewards: 131.33320, mean: 0.08157
[32m[0906 19-56-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10784, current rewards: 136.77830, mean: 0.08240
[32m[0906 19-56-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10778, current rewards: 131.77181, mean: 0.07706
[32m[0906 19-56-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10774, current rewards: 137.18715, mean: 0.07795
[32m[0906 19-56-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10769, current rewards: 142.60423, mean: 0.07879
[32m[0906 19-56-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10764, current rewards: 148.01701, mean: 0.07958
[32m[0906 19-56-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10762, current rewards: 153.43350, mean: 0.08033
[32m[0906 19-56-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10767, current rewards: 158.84693, mean: 0.08104
[32m[0906 19-56-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10773, current rewards: 164.26041, mean: 0.08172
[32m[0906 19-57-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10778, current rewards: 169.61315, mean: 0.08234
[32m[0906 19-57-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10782, current rewards: 175.02430, mean: 0.08295
[32m[0906 19-57-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10787, current rewards: 164.63571, mean: 0.07622
[32m[0906 19-57-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10792, current rewards: 170.02460, mean: 0.07693
[32m[0906 19-57-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10794, current rewards: 175.40829, mean: 0.07761
[32m[0906 19-57-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10801, current rewards: 180.78663, mean: 0.07826
[32m[0906 19-57-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10806, current rewards: 186.16359, mean: 0.07888
[32m[0906 19-57-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10808, current rewards: 191.54762, mean: 0.07948
[32m[0906 19-57-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10812, current rewards: 197.21266, mean: 0.08017
[32m[0906 19-57-53 @Agent.py:117][0m Average action selection time: 0.1081
[32m[0906 19-57-53 @Agent.py:118][0m Rollout length: 2505
[32m[0906 19-57-53 @MBExp.py:227][0m Rewards obtained: [201.53498263623558], Lows: [25], Highs: [16], Total time: 17754.794766000003
[32m[0906 20-00-25 @MBExp.py:144][0m ####################################################################
[32m[0906 20-00-25 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 20-00-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10748, current rewards: -4.17383, mean: -0.41738
[32m[0906 20-00-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10557, current rewards: 2.24061, mean: 0.03734
[32m[0906 20-00-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10534, current rewards: 8.12679, mean: 0.07388
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10573, current rewards: 14.01320, mean: 0.08758
[32m[0906 20-00-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10580, current rewards: 19.90024, mean: 0.09476
[32m[0906 20-00-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10574, current rewards: 25.78719, mean: 0.09918
[32m[0906 20-00-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10583, current rewards: 26.91723, mean: 0.08683
[32m[0906 20-01-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10597, current rewards: 32.87748, mean: 0.09133
[32m[0906 20-01-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10633, current rewards: 38.74461, mean: 0.09450
[32m[0906 20-01-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10657, current rewards: 44.62426, mean: 0.09701
[32m[0906 20-01-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10651, current rewards: 50.49977, mean: 0.09902
[32m[0906 20-01-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10643, current rewards: 56.37120, mean: 0.10066
[32m[0906 20-01-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10672, current rewards: 62.24461, mean: 0.10204
[32m[0906 20-01-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10692, current rewards: 68.12449, mean: 0.10322
[32m[0906 20-01-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10714, current rewards: 62.50294, mean: 0.08803
[32m[0906 20-01-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10733, current rewards: 67.92103, mean: 0.08937
[32m[0906 20-01-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10745, current rewards: 73.72030, mean: 0.09101
[32m[0906 20-01-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10758, current rewards: 79.55865, mean: 0.09251
[32m[0906 20-02-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10771, current rewards: 85.39262, mean: 0.09384
[32m[0906 20-02-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10778, current rewards: 91.22472, mean: 0.09503
[32m[0906 20-02-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10786, current rewards: 97.06562, mean: 0.09610
[32m[0906 20-02-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10794, current rewards: 102.90277, mean: 0.09708
[32m[0906 20-02-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10799, current rewards: 108.73844, mean: 0.09796
[32m[0906 20-02-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10804, current rewards: 114.58003, mean: 0.09878
[32m[0906 20-02-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10811, current rewards: 121.03305, mean: 0.10003
[32m[0906 20-02-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10817, current rewards: 126.87450, mean: 0.10069
[32m[0906 20-02-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10820, current rewards: 134.55415, mean: 0.10271
[32m[0906 20-02-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10821, current rewards: 140.38666, mean: 0.10323
[32m[0906 20-02-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10812, current rewards: 146.21898, mean: 0.10370
[32m[0906 20-03-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10803, current rewards: 152.05479, mean: 0.10415
[32m[0906 20-03-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10797, current rewards: 157.88689, mean: 0.10456
[32m[0906 20-03-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10789, current rewards: 163.71731, mean: 0.10495
[32m[0906 20-03-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10781, current rewards: 169.88810, mean: 0.10552
[32m[0906 20-03-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10776, current rewards: 175.73431, mean: 0.10586
[32m[0906 20-03-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10770, current rewards: 179.46231, mean: 0.10495
[32m[0906 20-03-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10764, current rewards: 167.47071, mean: 0.09515
[32m[0906 20-03-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10760, current rewards: 173.38859, mean: 0.09579
[32m[0906 20-03-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10755, current rewards: 179.30646, mean: 0.09640
[32m[0906 20-03-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10752, current rewards: 185.22433, mean: 0.09698
[32m[0906 20-03-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10758, current rewards: 191.14221, mean: 0.09752
[32m[0906 20-04-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10763, current rewards: 198.12175, mean: 0.09857
[32m[0906 20-04-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10767, current rewards: 205.98129, mean: 0.09999
[32m[0906 20-04-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10772, current rewards: 179.12510, mean: 0.08489
[32m[0906 20-04-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10776, current rewards: 129.12510, mean: 0.05978
[32m[0906 20-04-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10779, current rewards: 79.12510, mean: 0.03580
[32m[0906 20-04-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10785, current rewards: 29.12510, mean: 0.01289
[32m[0906 20-04-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10787, current rewards: -20.87490, mean: -0.00904
[32m[0906 20-04-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10790, current rewards: -70.87490, mean: -0.03003
[32m[0906 20-04-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10795, current rewards: -120.87490, mean: -0.05016
[32m[0906 20-04-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10799, current rewards: -170.87490, mean: -0.06946
[32m[0906 20-04-56 @Agent.py:117][0m Average action selection time: 0.1080
[32m[0906 20-04-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-04-56 @MBExp.py:227][0m Rewards obtained: [-210.8748965788743], Lows: [16], Highs: [430], Total time: 18025.640709000003
[32m[0906 20-07-30 @MBExp.py:144][0m ####################################################################
[32m[0906 20-07-30 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 20-07-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10681, current rewards: -4.50538, mean: -0.45054
[32m[0906 20-07-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10677, current rewards: 1.20029, mean: 0.02000
[32m[0906 20-07-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10609, current rewards: 6.90882, mean: 0.06281
[32m[0906 20-07-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10579, current rewards: 12.62324, mean: 0.07890
[32m[0906 20-07-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10584, current rewards: 18.32566, mean: 0.08727
[32m[0906 20-07-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10574, current rewards: 24.03416, mean: 0.09244
[32m[0906 20-08-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10561, current rewards: 29.74126, mean: 0.09594
[32m[0906 20-08-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10587, current rewards: 35.04979, mean: 0.09736
[32m[0906 20-08-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10622, current rewards: 40.71532, mean: 0.09931
[32m[0906 20-08-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10621, current rewards: 34.54138, mean: 0.07509
[32m[0906 20-08-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10622, current rewards: 40.42069, mean: 0.07926
[32m[0906 20-08-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10616, current rewards: 46.29953, mean: 0.08268
[32m[0906 20-08-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10637, current rewards: 52.18013, mean: 0.08554
[32m[0906 20-08-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10664, current rewards: 58.06041, mean: 0.08797
[32m[0906 20-08-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10679, current rewards: 63.94169, mean: 0.09006
[32m[0906 20-08-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10700, current rewards: 69.66199, mean: 0.09166
[32m[0906 20-08-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10718, current rewards: 75.57473, mean: 0.09330
[32m[0906 20-09-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10729, current rewards: 81.48827, mean: 0.09475
[32m[0906 20-09-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10741, current rewards: 70.57924, mean: 0.07756
[32m[0906 20-09-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10754, current rewards: 61.36200, mean: 0.06392
[32m[0906 20-09-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10761, current rewards: 13.76263, mean: 0.01363
[32m[0906 20-09-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10766, current rewards: -86.23737, mean: -0.08136
[32m[0906 20-09-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10773, current rewards: -186.23737, mean: -0.16778
[32m[0906 20-09-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10776, current rewards: -286.23737, mean: -0.24676
[32m[0906 20-09-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10781, current rewards: -386.23737, mean: -0.31920
[32m[0906 20-09-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10785, current rewards: -486.23737, mean: -0.38590
[32m[0906 20-09-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10788, current rewards: -586.23737, mean: -0.44751
[32m[0906 20-09-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10778, current rewards: -686.23737, mean: -0.50459
[32m[0906 20-10-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10771, current rewards: -786.23737, mean: -0.55762
[32m[0906 20-10-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10762, current rewards: -810.60769, mean: -0.55521
[32m[0906 20-10-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10752, current rewards: -804.82556, mean: -0.53300
[32m[0906 20-10-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10744, current rewards: -798.91955, mean: -0.51213
[32m[0906 20-10-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10736, current rewards: -793.12683, mean: -0.49263
[32m[0906 20-10-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10729, current rewards: -787.32943, mean: -0.47429
[32m[0906 20-10-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10724, current rewards: -781.53594, mean: -0.45704
[32m[0906 20-10-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10718, current rewards: -775.74083, mean: -0.44076
[32m[0906 20-10-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10711, current rewards: -769.94520, mean: -0.42538
[32m[0906 20-10-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10708, current rewards: -764.47007, mean: -0.41101
[32m[0906 20-10-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10704, current rewards: -758.76293, mean: -0.39726
[32m[0906 20-11-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10708, current rewards: -753.11148, mean: -0.38424
[32m[0906 20-11-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10714, current rewards: -747.92884, mean: -0.37210
[32m[0906 20-11-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10717, current rewards: -742.25893, mean: -0.36032
[32m[0906 20-11-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10720, current rewards: -736.58662, mean: -0.34909
[32m[0906 20-11-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10724, current rewards: -730.91940, mean: -0.33839
[32m[0906 20-11-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10726, current rewards: -725.24713, mean: -0.32817
[32m[0906 20-11-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10729, current rewards: -719.58393, mean: -0.31840
[32m[0906 20-11-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10733, current rewards: -713.91926, mean: -0.30906
[32m[0906 20-11-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10736, current rewards: -720.59924, mean: -0.30534
[32m[0906 20-11-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10739, current rewards: -715.14441, mean: -0.29674
[32m[0906 20-11-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10743, current rewards: -709.90664, mean: -0.28858
[32m[0906 20-12-00 @Agent.py:117][0m Average action selection time: 0.1074
[32m[0906 20-12-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-12-00 @MBExp.py:227][0m Rewards obtained: [-705.7191584616306], Lows: [469], Highs: [10], Total time: 18295.084687000002
[32m[0906 20-14-36 @MBExp.py:144][0m ####################################################################
[32m[0906 20-14-36 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 20-14-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10403, current rewards: -12.91929, mean: -1.29193
[32m[0906 20-14-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10475, current rewards: -11.07918, mean: -0.18465
[32m[0906 20-14-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10503, current rewards: -5.53831, mean: -0.05035
[32m[0906 20-14-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10508, current rewards: 0.00462, mean: 0.00003
[32m[0906 20-14-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10493, current rewards: 5.55184, mean: 0.02644
[32m[0906 20-15-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10499, current rewards: 11.10045, mean: 0.04269
[32m[0906 20-15-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10488, current rewards: 17.31277, mean: 0.05585
[32m[0906 20-15-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10507, current rewards: 23.00625, mean: 0.06391
[32m[0906 20-15-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10559, current rewards: 18.28151, mean: 0.04459
[32m[0906 20-15-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10553, current rewards: 23.93070, mean: 0.05202
[32m[0906 20-15-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10554, current rewards: 29.57840, mean: 0.05800
[32m[0906 20-15-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10550, current rewards: 35.22916, mean: 0.06291
[32m[0906 20-15-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10571, current rewards: 40.87600, mean: 0.06701
[32m[0906 20-15-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10592, current rewards: 46.52518, mean: 0.07049
[32m[0906 20-15-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10616, current rewards: 52.17281, mean: 0.07348
[32m[0906 20-15-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10632, current rewards: 47.25684, mean: 0.06218
[32m[0906 20-16-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10644, current rewards: 55.63932, mean: 0.06869
[32m[0906 20-16-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10659, current rewards: 63.93944, mean: 0.07435
[32m[0906 20-16-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10668, current rewards: 72.23956, mean: 0.07938
[32m[0906 20-16-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10676, current rewards: 67.71365, mean: 0.07054
[32m[0906 20-16-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10687, current rewards: 17.71365, mean: 0.01754
[32m[0906 20-16-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10694, current rewards: -32.28635, mean: -0.03046
[32m[0906 20-16-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10701, current rewards: -82.28635, mean: -0.07413
[32m[0906 20-16-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10709, current rewards: -132.28635, mean: -0.11404
[32m[0906 20-16-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10711, current rewards: -182.28635, mean: -0.15065
[32m[0906 20-16-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10715, current rewards: -232.28635, mean: -0.18435
[32m[0906 20-16-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10712, current rewards: -282.28635, mean: -0.21549
[32m[0906 20-17-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10705, current rewards: -332.28635, mean: -0.24433
[32m[0906 20-17-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10699, current rewards: -382.28635, mean: -0.27113
[32m[0906 20-17-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10695, current rewards: -432.28635, mean: -0.29609
[32m[0906 20-17-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10687, current rewards: -482.28635, mean: -0.31939
[32m[0906 20-17-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10681, current rewards: -532.28635, mean: -0.34121
[32m[0906 20-17-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10678, current rewards: -582.28635, mean: -0.36167
[32m[0906 20-17-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10675, current rewards: -632.28635, mean: -0.38090
[32m[0906 20-17-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10672, current rewards: -682.28635, mean: -0.39900
[32m[0906 20-17-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10669, current rewards: -732.28635, mean: -0.41607
[32m[0906 20-17-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10663, current rewards: -782.28635, mean: -0.43220
[32m[0906 20-17-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10659, current rewards: -832.28635, mean: -0.44747
[32m[0906 20-18-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10662, current rewards: -882.28635, mean: -0.46193
[32m[0906 20-18-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10666, current rewards: -932.28635, mean: -0.47566
[32m[0906 20-18-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10671, current rewards: -982.28635, mean: -0.48870
[32m[0906 20-18-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10676, current rewards: -1032.28635, mean: -0.50111
[32m[0906 20-18-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10680, current rewards: -1082.28635, mean: -0.51293
[32m[0906 20-18-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10684, current rewards: -1132.28635, mean: -0.52421
[32m[0906 20-18-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10689, current rewards: -1182.28635, mean: -0.53497
[32m[0906 20-18-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10693, current rewards: -1232.28635, mean: -0.54526
[32m[0906 20-18-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10696, current rewards: -1282.28635, mean: -0.55510
[32m[0906 20-18-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10701, current rewards: -1332.28635, mean: -0.56453
[32m[0906 20-18-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10704, current rewards: -1382.28635, mean: -0.57356
[32m[0906 20-19-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10708, current rewards: -1432.28635, mean: -0.58223
[32m[0906 20-19-04 @Agent.py:117][0m Average action selection time: 0.1071
[32m[0906 20-19-04 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-19-04 @MBExp.py:227][0m Rewards obtained: [-1472.2863502285286], Lows: [16], Highs: [1556], Total time: 18563.654245
[32m[0906 20-21-42 @MBExp.py:144][0m ####################################################################
[32m[0906 20-21-42 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 20-21-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10443, current rewards: -4.38396, mean: -0.43840
[32m[0906 20-21-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10540, current rewards: 1.12250, mean: 0.01871
[32m[0906 20-21-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10528, current rewards: 6.60111, mean: 0.06001
[32m[0906 20-21-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10539, current rewards: 12.08604, mean: 0.07554
[32m[0906 20-22-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10533, current rewards: 17.56733, mean: 0.08365
[32m[0906 20-22-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10529, current rewards: 23.04098, mean: 0.08862
[32m[0906 20-22-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10534, current rewards: 29.44549, mean: 0.09499
[32m[0906 20-22-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10551, current rewards: 35.02968, mean: 0.09730
[32m[0906 20-22-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10544, current rewards: 35.39442, mean: 0.08633
[32m[0906 20-22-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10549, current rewards: 40.66892, mean: 0.08841
[32m[0906 20-22-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10546, current rewards: 45.94664, mean: 0.09009
[32m[0906 20-22-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10544, current rewards: 51.22237, mean: 0.09147
[32m[0906 20-22-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10566, current rewards: 56.50417, mean: 0.09263
[32m[0906 20-22-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10593, current rewards: 61.77960, mean: 0.09361
[32m[0906 20-22-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10613, current rewards: 66.86493, mean: 0.09418
[32m[0906 20-23-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10634, current rewards: 71.98416, mean: 0.09472
[32m[0906 20-23-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10647, current rewards: 70.91534, mean: 0.08755
[32m[0906 20-23-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10660, current rewards: 70.37423, mean: 0.08183
[32m[0906 20-23-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10673, current rewards: 75.96477, mean: 0.08348
[32m[0906 20-23-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10681, current rewards: 81.55136, mean: 0.08495
[32m[0906 20-23-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10693, current rewards: 87.13927, mean: 0.08628
[32m[0906 20-23-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10703, current rewards: 92.73034, mean: 0.08748
[32m[0906 20-23-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10712, current rewards: 98.32054, mean: 0.08858
[32m[0906 20-23-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10721, current rewards: 104.00721, mean: 0.08966
[32m[0906 20-23-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10729, current rewards: 109.57459, mean: 0.09056
[32m[0906 20-23-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10730, current rewards: 101.76571, mean: 0.08077
[32m[0906 20-24-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10724, current rewards: 107.02581, mean: 0.08170
[32m[0906 20-24-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10718, current rewards: 112.28631, mean: 0.08256
[32m[0906 20-24-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10711, current rewards: 117.54200, mean: 0.08336
[32m[0906 20-24-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10708, current rewards: 112.34372, mean: 0.07695
[32m[0906 20-24-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10704, current rewards: 117.76708, mean: 0.07799
[32m[0906 20-24-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10698, current rewards: 123.40351, mean: 0.07910
[32m[0906 20-24-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10697, current rewards: 128.84035, mean: 0.08003
[32m[0906 20-24-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10693, current rewards: 134.27108, mean: 0.08089
[32m[0906 20-24-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10687, current rewards: 139.70852, mean: 0.08170
[32m[0906 20-24-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10684, current rewards: 145.14233, mean: 0.08247
[32m[0906 20-24-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10679, current rewards: 150.57866, mean: 0.08319
[32m[0906 20-25-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10674, current rewards: 156.01132, mean: 0.08388
[32m[0906 20-25-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10681, current rewards: 161.44646, mean: 0.08453
[32m[0906 20-25-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10685, current rewards: 153.79624, mean: 0.07847
[32m[0906 20-25-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10689, current rewards: 159.23034, mean: 0.07922
[32m[0906 20-25-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10694, current rewards: 164.66794, mean: 0.07994
[32m[0906 20-25-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10697, current rewards: 170.10391, mean: 0.08062
[32m[0906 20-25-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10701, current rewards: 175.53990, mean: 0.08127
[32m[0906 20-25-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10706, current rewards: 180.97868, mean: 0.08189
[32m[0906 20-25-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10709, current rewards: 186.41776, mean: 0.08249
[32m[0906 20-25-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10712, current rewards: 191.85602, mean: 0.08305
[32m[0906 20-25-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10716, current rewards: 197.18071, mean: 0.08355
[32m[0906 20-26-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10719, current rewards: 202.62957, mean: 0.08408
[32m[0906 20-26-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10720, current rewards: 208.08638, mean: 0.08459
[32m[0906 20-26-11 @Agent.py:117][0m Average action selection time: 0.1072
[32m[0906 20-26-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-26-11 @MBExp.py:227][0m Rewards obtained: [212.45091052752423], Lows: [21], Highs: [15], Total time: 18832.532124
[32m[0906 20-28-51 @MBExp.py:144][0m ####################################################################
[32m[0906 20-28-51 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 20-28-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10434, current rewards: -6.60887, mean: -0.66089
[32m[0906 20-28-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10471, current rewards: -1.07473, mean: -0.01791
[32m[0906 20-29-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10469, current rewards: 4.43075, mean: 0.04028
[32m[0906 20-29-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10485, current rewards: 9.93294, mean: 0.06208
[32m[0906 20-29-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10489, current rewards: 15.43164, mean: 0.07348
[32m[0906 20-29-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10483, current rewards: 20.93247, mean: 0.08051
[32m[0906 20-29-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10488, current rewards: 14.89978, mean: 0.04806
[32m[0906 20-29-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10485, current rewards: 20.62725, mean: 0.05730
[32m[0906 20-29-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10485, current rewards: 26.35087, mean: 0.06427
[32m[0906 20-29-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10492, current rewards: 32.07875, mean: 0.06974
[32m[0906 20-29-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10493, current rewards: 37.80617, mean: 0.07413
[32m[0906 20-29-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10490, current rewards: 43.53579, mean: 0.07774
[32m[0906 20-29-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10520, current rewards: 49.26272, mean: 0.08076
[32m[0906 20-30-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10542, current rewards: 54.98819, mean: 0.08332
[32m[0906 20-30-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10564, current rewards: 61.00087, mean: 0.08592
[32m[0906 20-30-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10583, current rewards: 46.05883, mean: 0.06060
[32m[0906 20-30-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10600, current rewards: 51.94312, mean: 0.06413
[32m[0906 20-30-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10612, current rewards: 57.67073, mean: 0.06706
[32m[0906 20-30-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10625, current rewards: 63.40303, mean: 0.06967
[32m[0906 20-30-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10634, current rewards: 69.13516, mean: 0.07202
[32m[0906 20-30-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10644, current rewards: 74.86860, mean: 0.07413
[32m[0906 20-30-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10654, current rewards: 80.59891, mean: 0.07604
[32m[0906 20-30-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10662, current rewards: 75.25010, mean: 0.06779
[32m[0906 20-30-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10669, current rewards: 80.62297, mean: 0.06950
[32m[0906 20-31-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10674, current rewards: 85.97942, mean: 0.07106
[32m[0906 20-31-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10664, current rewards: 91.33812, mean: 0.07249
[32m[0906 20-31-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10658, current rewards: 96.69970, mean: 0.07382
[32m[0906 20-31-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10651, current rewards: 102.06071, mean: 0.07504
[32m[0906 20-31-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10646, current rewards: 107.42102, mean: 0.07619
[32m[0906 20-31-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10641, current rewards: 112.77526, mean: 0.07724
[32m[0906 20-31-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10637, current rewards: 99.11433, mean: 0.06564
[32m[0906 20-31-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10631, current rewards: 99.96393, mean: 0.06408
[32m[0906 20-31-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10626, current rewards: 105.63056, mean: 0.06561
[32m[0906 20-31-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10624, current rewards: 111.29195, mean: 0.06704
[32m[0906 20-31-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10620, current rewards: 116.95655, mean: 0.06840
[32m[0906 20-31-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10616, current rewards: 122.62236, mean: 0.06967
[32m[0906 20-32-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10614, current rewards: 128.28754, mean: 0.07088
[32m[0906 20-32-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10611, current rewards: 133.95812, mean: 0.07202
[32m[0906 20-32-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10615, current rewards: 139.62793, mean: 0.07310
[32m[0906 20-32-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10623, current rewards: 134.45926, mean: 0.06860
[32m[0906 20-32-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10627, current rewards: 139.92372, mean: 0.06961
[32m[0906 20-32-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10632, current rewards: 145.38789, mean: 0.07058
[32m[0906 20-32-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10639, current rewards: 150.85076, mean: 0.07149
[32m[0906 20-32-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10643, current rewards: 156.31925, mean: 0.07237
[32m[0906 20-32-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10647, current rewards: 161.77987, mean: 0.07320
[32m[0906 20-32-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10652, current rewards: 153.27318, mean: 0.06782
[32m[0906 20-32-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10656, current rewards: 158.96090, mean: 0.06881
[32m[0906 20-33-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10661, current rewards: 164.58743, mean: 0.06974
[32m[0906 20-33-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10665, current rewards: 170.26940, mean: 0.07065
[32m[0906 20-33-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10668, current rewards: 175.95086, mean: 0.07152
[32m[0906 20-33-19 @Agent.py:117][0m Average action selection time: 0.1067
[32m[0906 20-33-19 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-33-19 @MBExp.py:227][0m Rewards obtained: [180.49682379880142], Lows: [37], Highs: [24], Total time: 19100.138596
[32m[0906 20-36-01 @MBExp.py:144][0m ####################################################################
[32m[0906 20-36-01 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 20-36-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10543, current rewards: 0.93499, mean: 0.09350
[32m[0906 20-36-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10529, current rewards: 6.31163, mean: 0.10519
[32m[0906 20-36-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10520, current rewards: 11.93513, mean: 0.10850
[32m[0906 20-36-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10550, current rewards: 17.56180, mean: 0.10976
[32m[0906 20-36-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10538, current rewards: 23.18283, mean: 0.11039
[32m[0906 20-36-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10527, current rewards: 29.70375, mean: 0.11425
[32m[0906 20-36-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10501, current rewards: -3.77670, mean: -0.01218
[32m[0906 20-36-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10486, current rewards: -53.77670, mean: -0.14938
[32m[0906 20-36-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10487, current rewards: -103.77670, mean: -0.25311
[32m[0906 20-36-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10496, current rewards: -153.77670, mean: -0.33430
[32m[0906 20-36-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10499, current rewards: -203.77670, mean: -0.39956
[32m[0906 20-37-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10498, current rewards: -253.77670, mean: -0.45317
[32m[0906 20-37-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10521, current rewards: -303.77670, mean: -0.49799
[32m[0906 20-37-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10547, current rewards: -353.77670, mean: -0.53603
[32m[0906 20-37-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10569, current rewards: -403.77670, mean: -0.56870
[32m[0906 20-37-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10594, current rewards: -453.77670, mean: -0.59707
[32m[0906 20-37-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10609, current rewards: -503.77670, mean: -0.62195
[32m[0906 20-37-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10626, current rewards: -553.77670, mean: -0.64393
[32m[0906 20-37-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10647, current rewards: -603.77670, mean: -0.66349
[32m[0906 20-37-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10657, current rewards: -653.77670, mean: -0.68102
[32m[0906 20-37-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10666, current rewards: -703.77670, mean: -0.69681
[32m[0906 20-37-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10677, current rewards: -753.77670, mean: -0.71111
[32m[0906 20-38-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10686, current rewards: -803.77670, mean: -0.72412
[32m[0906 20-38-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10693, current rewards: -853.77670, mean: -0.73601
[32m[0906 20-38-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10686, current rewards: -903.77670, mean: -0.74692
[32m[0906 20-38-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10679, current rewards: -953.77670, mean: -0.75697
[32m[0906 20-38-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10672, current rewards: -1003.77670, mean: -0.76624
[32m[0906 20-38-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10668, current rewards: -1053.77670, mean: -0.77484
[32m[0906 20-38-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10661, current rewards: -1103.77670, mean: -0.78282
[32m[0906 20-38-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10655, current rewards: -1153.77670, mean: -0.79026
[32m[0906 20-38-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10652, current rewards: -1203.77670, mean: -0.79720
[32m[0906 20-38-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10647, current rewards: -1253.77670, mean: -0.80370
[32m[0906 20-38-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10642, current rewards: -1303.77670, mean: -0.80980
[32m[0906 20-38-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10640, current rewards: -1353.77670, mean: -0.81553
[32m[0906 20-39-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10636, current rewards: -1403.77670, mean: -0.82092
[32m[0906 20-39-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10631, current rewards: -1453.77670, mean: -0.82601
[32m[0906 20-39-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10630, current rewards: -1503.77670, mean: -0.83082
[32m[0906 20-39-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10627, current rewards: -1553.77670, mean: -0.83536
[32m[0906 20-39-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10634, current rewards: -1603.77670, mean: -0.83967
[32m[0906 20-39-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10641, current rewards: -1653.77670, mean: -0.84376
[32m[0906 20-39-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10648, current rewards: -1703.77670, mean: -0.84765
[32m[0906 20-39-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10654, current rewards: -1753.77670, mean: -0.85135
[32m[0906 20-39-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10660, current rewards: -1803.77670, mean: -0.85487
[32m[0906 20-39-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10664, current rewards: -1853.77670, mean: -0.85823
[32m[0906 20-39-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10670, current rewards: -1903.77670, mean: -0.86144
[32m[0906 20-40-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10674, current rewards: -1953.77670, mean: -0.86450
[32m[0906 20-40-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10677, current rewards: -2003.77670, mean: -0.86744
[32m[0906 20-40-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10683, current rewards: -2053.77670, mean: -0.87024
[32m[0906 20-40-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10687, current rewards: -2103.77670, mean: -0.87294
[32m[0906 20-40-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10691, current rewards: -2153.77670, mean: -0.87552
[32m[0906 20-40-29 @Agent.py:117][0m Average action selection time: 0.1069
[32m[0906 20-40-29 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-40-29 @MBExp.py:227][0m Rewards obtained: [-2193.77670363948], Lows: [0], Highs: [2226], Total time: 19368.325997
[32m[0906 20-43-14 @MBExp.py:144][0m ####################################################################
[32m[0906 20-43-14 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 20-43-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.12431, current rewards: -12.94664, mean: -1.29466
[32m[0906 20-43-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10976, current rewards: -17.66078, mean: -0.29435
[32m[0906 20-43-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10792, current rewards: -10.55895, mean: -0.09599
[32m[0906 20-43-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10688, current rewards: -3.44832, mean: -0.02155
[32m[0906 20-43-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10627, current rewards: 3.65765, mean: 0.01742
[32m[0906 20-43-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10608, current rewards: 10.78387, mean: 0.04148
[32m[0906 20-43-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10580, current rewards: 17.63853, mean: 0.05690
[32m[0906 20-43-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10591, current rewards: 24.74273, mean: 0.06873
[32m[0906 20-43-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10583, current rewards: 31.90235, mean: 0.07781
[32m[0906 20-44-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10569, current rewards: 39.04805, mean: 0.08489
[32m[0906 20-44-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10562, current rewards: 46.17394, mean: 0.09054
[32m[0906 20-44-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10557, current rewards: 42.40242, mean: 0.07572
[32m[0906 20-44-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10574, current rewards: 48.45023, mean: 0.07943
[32m[0906 20-44-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10592, current rewards: 54.49711, mean: 0.08257
[32m[0906 20-44-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10610, current rewards: 60.26633, mean: 0.08488
[32m[0906 20-44-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10626, current rewards: 66.26817, mean: 0.08719
[32m[0906 20-44-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10638, current rewards: 72.27358, mean: 0.08923
[32m[0906 20-44-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10649, current rewards: 78.27571, mean: 0.09102
[32m[0906 20-44-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10657, current rewards: 84.28096, mean: 0.09262
[32m[0906 20-44-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10664, current rewards: 90.28405, mean: 0.09405
[32m[0906 20-45-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10673, current rewards: 83.06799, mean: 0.08225
[32m[0906 20-45-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10678, current rewards: 88.09395, mean: 0.08311
[32m[0906 20-45-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10683, current rewards: 93.63657, mean: 0.08436
[32m[0906 20-45-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10677, current rewards: 98.76854, mean: 0.08515
[32m[0906 20-45-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10668, current rewards: 103.94987, mean: 0.08591
[32m[0906 20-45-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10660, current rewards: 109.02524, mean: 0.08653
[32m[0906 20-45-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10654, current rewards: 114.25691, mean: 0.08722
[32m[0906 20-45-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10647, current rewards: 119.49006, mean: 0.08786
[32m[0906 20-45-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10642, current rewards: 122.39952, mean: 0.08681
[32m[0906 20-45-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10638, current rewards: 126.70043, mean: 0.08678
[32m[0906 20-45-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10632, current rewards: 135.37907, mean: 0.08966
[32m[0906 20-46-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10628, current rewards: 144.03750, mean: 0.09233
[32m[0906 20-46-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10625, current rewards: 152.69836, mean: 0.09484
[32m[0906 20-46-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10618, current rewards: 161.34796, mean: 0.09720
[32m[0906 20-46-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10613, current rewards: 170.02692, mean: 0.09943
[32m[0906 20-46-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10612, current rewards: 178.68876, mean: 0.10153
[32m[0906 20-46-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10608, current rewards: 187.33740, mean: 0.10350
[32m[0906 20-46-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10605, current rewards: 196.01117, mean: 0.10538
[32m[0906 20-46-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10606, current rewards: 192.18082, mean: 0.10062
[32m[0906 20-46-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10607, current rewards: 202.57588, mean: 0.10336
[32m[0906 20-46-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10613, current rewards: 210.89775, mean: 0.10492
[32m[0906 20-46-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10618, current rewards: 219.21836, mean: 0.10642
[32m[0906 20-46-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10623, current rewards: 227.54249, mean: 0.10784
[32m[0906 20-47-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10628, current rewards: 235.85881, mean: 0.10919
[32m[0906 20-47-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10633, current rewards: 244.17965, mean: 0.11049
[32m[0906 20-47-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10637, current rewards: 240.03838, mean: 0.10621
[32m[0906 20-47-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10641, current rewards: 244.79682, mean: 0.10597
[32m[0906 20-47-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10647, current rewards: 249.59407, mean: 0.10576
[32m[0906 20-47-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10651, current rewards: 254.59253, mean: 0.10564
[32m[0906 20-47-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10657, current rewards: 259.59197, mean: 0.10553
[32m[0906 20-47-41 @Agent.py:117][0m Average action selection time: 0.1066
[32m[0906 20-47-41 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-47-42 @MBExp.py:227][0m Rewards obtained: [263.5912992044319], Lows: [28], Highs: [17], Total time: 19635.664269
[32m[0906 20-50-28 @MBExp.py:144][0m ####################################################################
[32m[0906 20-50-28 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 20-50-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11101, current rewards: -11.81742, mean: -1.18174
[32m[0906 20-50-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10597, current rewards: -8.49629, mean: -0.14160
[32m[0906 20-50-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10531, current rewards: -2.84866, mean: -0.02590
[32m[0906 20-50-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10506, current rewards: 2.79628, mean: 0.01748
[32m[0906 20-50-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10507, current rewards: 8.43640, mean: 0.04017
[32m[0906 20-50-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10494, current rewards: 15.18353, mean: 0.05840
[32m[0906 20-51-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10488, current rewards: 20.87458, mean: 0.06734
[32m[0906 20-51-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10537, current rewards: 26.57880, mean: 0.07383
[32m[0906 20-51-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10533, current rewards: 32.27657, mean: 0.07872
[32m[0906 20-51-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10527, current rewards: 27.96380, mean: 0.06079
[32m[0906 20-51-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10526, current rewards: 33.40141, mean: 0.06549
[32m[0906 20-51-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10521, current rewards: 38.84030, mean: 0.06936
[32m[0906 20-51-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10537, current rewards: 44.27758, mean: 0.07259
[32m[0906 20-51-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10563, current rewards: 40.86347, mean: 0.06191
[32m[0906 20-51-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10581, current rewards: 46.70912, mean: 0.06579
[32m[0906 20-51-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10597, current rewards: 52.55669, mean: 0.06915
[32m[0906 20-51-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10615, current rewards: 58.41331, mean: 0.07212
[32m[0906 20-51-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10627, current rewards: 64.26738, mean: 0.07473
[32m[0906 20-52-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10638, current rewards: 70.12211, mean: 0.07706
[32m[0906 20-52-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10652, current rewards: 75.97841, mean: 0.07914
[32m[0906 20-52-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10662, current rewards: 81.82783, mean: 0.08102
[32m[0906 20-52-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10670, current rewards: 82.23515, mean: 0.07758
[32m[0906 20-52-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10670, current rewards: 87.79682, mean: 0.07910
[32m[0906 20-52-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10664, current rewards: 93.62599, mean: 0.08071
[32m[0906 20-52-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10657, current rewards: 99.45800, mean: 0.08220
[32m[0906 20-52-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10654, current rewards: 105.28934, mean: 0.08356
[32m[0906 20-52-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10650, current rewards: 111.12175, mean: 0.08483
[32m[0906 20-52-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10642, current rewards: 116.96849, mean: 0.08601
[32m[0906 20-52-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10638, current rewards: 122.81312, mean: 0.08710
[32m[0906 20-53-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10632, current rewards: 128.65317, mean: 0.08812
[32m[0906 20-53-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10626, current rewards: 134.89666, mean: 0.08934
[32m[0906 20-53-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10628, current rewards: 126.23696, mean: 0.08092
[32m[0906 20-53-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10625, current rewards: 131.81581, mean: 0.08187
[32m[0906 20-53-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10620, current rewards: 137.40161, mean: 0.08277
[32m[0906 20-53-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10619, current rewards: 142.97873, mean: 0.08361
[32m[0906 20-53-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10615, current rewards: 148.55917, mean: 0.08441
[32m[0906 20-53-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10611, current rewards: 154.14312, mean: 0.08516
[32m[0906 20-53-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10611, current rewards: 159.72191, mean: 0.08587
[32m[0906 20-53-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10608, current rewards: 165.29796, mean: 0.08654
[32m[0906 20-53-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10606, current rewards: 170.87283, mean: 0.08718
[32m[0906 20-54-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10611, current rewards: 164.52795, mean: 0.08185
[32m[0906 20-54-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10616, current rewards: 169.87511, mean: 0.08246
[32m[0906 20-54-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10621, current rewards: 175.22228, mean: 0.08304
[32m[0906 20-54-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10628, current rewards: 180.56944, mean: 0.08360
[32m[0906 20-54-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10634, current rewards: 164.88468, mean: 0.07461
[32m[0906 20-54-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10638, current rewards: 114.88468, mean: 0.05083
[32m[0906 20-54-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10644, current rewards: 64.88468, mean: 0.02809
[32m[0906 20-54-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10647, current rewards: 14.88468, mean: 0.00631
[32m[0906 20-54-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10652, current rewards: -35.11532, mean: -0.01457
[32m[0906 20-54-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10656, current rewards: -85.11532, mean: -0.03460
[32m[0906 20-54-55 @Agent.py:117][0m Average action selection time: 0.1066
[32m[0906 20-54-55 @Agent.py:118][0m Rollout length: 2505
[32m[0906 20-54-55 @MBExp.py:227][0m Rewards obtained: [-125.11532179907229], Lows: [27], Highs: [320], Total time: 19902.97609
[32m[0906 20-57-44 @MBExp.py:144][0m ####################################################################
[32m[0906 20-57-44 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 20-57-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10412, current rewards: -5.51204, mean: -0.55120
[32m[0906 20-57-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10422, current rewards: -0.56105, mean: -0.00935
[32m[0906 20-57-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10419, current rewards: 4.90640, mean: 0.04460
[32m[0906 20-58-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10451, current rewards: 10.37685, mean: 0.06486
[32m[0906 20-58-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10459, current rewards: 15.84709, mean: 0.07546
[32m[0906 20-58-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10461, current rewards: 22.07981, mean: 0.08492
[32m[0906 20-58-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10468, current rewards: 28.18715, mean: 0.09093
[32m[0906 20-58-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10507, current rewards: 29.00952, mean: 0.08058
[32m[0906 20-58-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10538, current rewards: 34.43837, mean: 0.08400
[32m[0906 20-58-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10571, current rewards: 39.86773, mean: 0.08667
[32m[0906 20-58-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10552, current rewards: 45.30609, mean: 0.08884
[32m[0906 20-58-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10542, current rewards: 50.73136, mean: 0.09059
[32m[0906 20-58-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10559, current rewards: 56.16383, mean: 0.09207
[32m[0906 20-58-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10588, current rewards: 44.72395, mean: 0.06776
[32m[0906 20-58-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10604, current rewards: 44.18259, mean: 0.06223
[32m[0906 20-59-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10621, current rewards: 49.80323, mean: 0.06553
[32m[0906 20-59-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10633, current rewards: 55.44085, mean: 0.06845
[32m[0906 20-59-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10644, current rewards: 55.66450, mean: 0.06473
[32m[0906 20-59-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10660, current rewards: 61.24276, mean: 0.06730
[32m[0906 20-59-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10669, current rewards: 66.79183, mean: 0.06957
[32m[0906 20-59-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10679, current rewards: 72.34187, mean: 0.07163
[32m[0906 20-59-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10690, current rewards: 77.88990, mean: 0.07348
[32m[0906 20-59-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10705, current rewards: 73.19598, mean: 0.06594
[32m[0906 20-59-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10711, current rewards: 78.77596, mean: 0.06791
[32m[0906 20-59-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10703, current rewards: 84.35403, mean: 0.06971
[32m[0906 20-59-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10694, current rewards: 89.93181, mean: 0.07137
[32m[0906 21-00-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10686, current rewards: 95.51430, mean: 0.07291
[32m[0906 21-00-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10680, current rewards: 101.09333, mean: 0.07433
[32m[0906 21-00-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10673, current rewards: 98.03380, mean: 0.06953
[32m[0906 21-00-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10667, current rewards: 103.52006, mean: 0.07090
[32m[0906 21-00-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10662, current rewards: 109.23818, mean: 0.07234
[32m[0906 21-00-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10654, current rewards: 114.74233, mean: 0.07355
[32m[0906 21-00-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10646, current rewards: 120.24296, mean: 0.07469
[32m[0906 21-00-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10640, current rewards: 125.74693, mean: 0.07575
[32m[0906 21-00-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10634, current rewards: 131.24751, mean: 0.07675
[32m[0906 21-00-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10628, current rewards: 136.75177, mean: 0.07770
[32m[0906 21-00-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10625, current rewards: 142.25364, mean: 0.07859
[32m[0906 21-01-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10620, current rewards: 147.57897, mean: 0.07934
[32m[0906 21-01-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10614, current rewards: 152.78606, mean: 0.07999
[32m[0906 21-01-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10611, current rewards: 158.01518, mean: 0.08062
[32m[0906 21-01-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10607, current rewards: 163.43180, mean: 0.08131
[32m[0906 21-01-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10603, current rewards: 168.84856, mean: 0.08197
[32m[0906 21-01-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10604, current rewards: 174.26141, mean: 0.08259
[32m[0906 21-01-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10608, current rewards: 179.67986, mean: 0.08319
[32m[0906 21-01-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10615, current rewards: 172.56120, mean: 0.07808
[32m[0906 21-01-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10619, current rewards: 178.09222, mean: 0.07880
[32m[0906 21-01-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10623, current rewards: 183.62368, mean: 0.07949
[32m[0906 21-01-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10626, current rewards: 189.29230, mean: 0.08021
[32m[0906 21-02-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10629, current rewards: 194.83706, mean: 0.08085
[32m[0906 21-02-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10631, current rewards: 200.37990, mean: 0.08146
[32m[0906 21-02-10 @Agent.py:117][0m Average action selection time: 0.1063
[32m[0906 21-02-10 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-02-11 @MBExp.py:227][0m Rewards obtained: [204.81641713208833], Lows: [24], Highs: [21], Total time: 20169.606905
[32m[0906 21-05-01 @MBExp.py:144][0m ####################################################################
[32m[0906 21-05-01 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 21-05-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10251, current rewards: -11.92004, mean: -1.19200
[32m[0906 21-05-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10412, current rewards: -31.30825, mean: -0.52180
[32m[0906 21-05-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10388, current rewards: -25.47817, mean: -0.23162
[32m[0906 21-05-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10386, current rewards: -19.64492, mean: -0.12278
[32m[0906 21-05-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10402, current rewards: -13.80516, mean: -0.06574
[32m[0906 21-05-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10391, current rewards: -8.05005, mean: -0.03096
[32m[0906 21-05-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10397, current rewards: -13.65302, mean: -0.04404
[32m[0906 21-05-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10450, current rewards: -8.14038, mean: -0.02261
[32m[0906 21-05-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10478, current rewards: -2.63145, mean: -0.00642
[32m[0906 21-05-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10468, current rewards: 2.88630, mean: 0.00627
[32m[0906 21-05-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10464, current rewards: 8.39624, mean: 0.01646
[32m[0906 21-05-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10453, current rewards: 13.90514, mean: 0.02483
[32m[0906 21-06-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10461, current rewards: 19.42126, mean: 0.03184
[32m[0906 21-06-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10484, current rewards: 24.93232, mean: 0.03778
[32m[0906 21-06-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10501, current rewards: 30.44127, mean: 0.04288
[32m[0906 21-06-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10510, current rewards: 35.94603, mean: 0.04730
[32m[0906 21-06-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10526, current rewards: 41.46005, mean: 0.05119
[32m[0906 21-06-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10539, current rewards: 46.96778, mean: 0.05461
[32m[0906 21-06-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10550, current rewards: 52.48285, mean: 0.05767
[32m[0906 21-06-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10559, current rewards: 57.99471, mean: 0.06041
[32m[0906 21-06-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10566, current rewards: 63.50904, mean: 0.06288
[32m[0906 21-06-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10575, current rewards: 69.01978, mean: 0.06511
[32m[0906 21-06-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10589, current rewards: 62.01890, mean: 0.05587
[32m[0906 21-07-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10585, current rewards: 67.55798, mean: 0.05824
[32m[0906 21-07-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10574, current rewards: 73.09763, mean: 0.06041
[32m[0906 21-07-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10569, current rewards: 78.63503, mean: 0.06241
[32m[0906 21-07-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10561, current rewards: 84.17902, mean: 0.06426
[32m[0906 21-07-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10555, current rewards: 89.71914, mean: 0.06597
[32m[0906 21-07-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10550, current rewards: 95.25239, mean: 0.06755
[32m[0906 21-07-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10551, current rewards: 82.09063, mean: 0.05623
[32m[0906 21-07-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10546, current rewards: 88.57982, mean: 0.05866
[32m[0906 21-07-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10541, current rewards: 94.56666, mean: 0.06062
[32m[0906 21-07-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10536, current rewards: 100.55922, mean: 0.06246
[32m[0906 21-07-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10531, current rewards: 106.55169, mean: 0.06419
[32m[0906 21-08-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10527, current rewards: 112.52347, mean: 0.06580
[32m[0906 21-08-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10522, current rewards: 118.50834, mean: 0.06733
[32m[0906 21-08-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10517, current rewards: 124.48360, mean: 0.06878
[32m[0906 21-08-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10514, current rewards: 130.46198, mean: 0.07014
[32m[0906 21-08-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10510, current rewards: 136.80927, mean: 0.07163
[32m[0906 21-08-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10506, current rewards: 132.60902, mean: 0.06766
[32m[0906 21-08-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10504, current rewards: 138.09332, mean: 0.06870
[32m[0906 21-08-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10500, current rewards: 143.67659, mean: 0.06975
[32m[0906 21-08-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10502, current rewards: 149.26353, mean: 0.07074
[32m[0906 21-08-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10507, current rewards: 154.84304, mean: 0.07169
[32m[0906 21-08-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10512, current rewards: 149.87903, mean: 0.06782
[32m[0906 21-08-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10516, current rewards: 155.53316, mean: 0.06882
[32m[0906 21-09-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10522, current rewards: 161.19088, mean: 0.06978
[32m[0906 21-09-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10525, current rewards: 165.99083, mean: 0.07034
[32m[0906 21-09-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10528, current rewards: 171.55355, mean: 0.07118
[32m[0906 21-09-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10531, current rewards: 177.12451, mean: 0.07200
[32m[0906 21-09-25 @Agent.py:117][0m Average action selection time: 0.1053
[32m[0906 21-09-25 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-09-25 @MBExp.py:227][0m Rewards obtained: [181.5796426736823], Lows: [42], Highs: [12], Total time: 20433.768882
[32m[0906 21-12-17 @MBExp.py:144][0m ####################################################################
[32m[0906 21-12-17 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 21-12-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10926, current rewards: -6.65931, mean: -0.66593
[32m[0906 21-12-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10386, current rewards: 0.13261, mean: 0.00221
[32m[0906 21-12-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10361, current rewards: 6.89665, mean: 0.06270
[32m[0906 21-12-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10368, current rewards: 13.66069, mean: 0.08538
[32m[0906 21-12-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10346, current rewards: 20.42472, mean: 0.09726
[32m[0906 21-12-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10342, current rewards: 27.18876, mean: 0.10457
[32m[0906 21-12-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10371, current rewards: 20.35935, mean: 0.06568
[32m[0906 21-12-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10409, current rewards: -29.64065, mean: -0.08234
[32m[0906 21-13-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10412, current rewards: -79.64065, mean: -0.19425
[32m[0906 21-13-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10407, current rewards: -129.64065, mean: -0.28183
[32m[0906 21-13-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10399, current rewards: -179.64065, mean: -0.35224
[32m[0906 21-13-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10392, current rewards: -229.64065, mean: -0.41007
[32m[0906 21-13-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10411, current rewards: -279.64065, mean: -0.45843
[32m[0906 21-13-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10432, current rewards: -329.64065, mean: -0.49946
[32m[0906 21-13-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10446, current rewards: -379.64065, mean: -0.53471
[32m[0906 21-13-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10464, current rewards: -429.64065, mean: -0.56532
[32m[0906 21-13-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10477, current rewards: -479.64065, mean: -0.59215
[32m[0906 21-13-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10488, current rewards: -529.64065, mean: -0.61586
[32m[0906 21-13-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10501, current rewards: -579.64065, mean: -0.63697
[32m[0906 21-13-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10511, current rewards: -629.64065, mean: -0.65588
[32m[0906 21-14-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10518, current rewards: -679.64065, mean: -0.67291
[32m[0906 21-14-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10526, current rewards: -729.64065, mean: -0.68834
[32m[0906 21-14-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10523, current rewards: -779.64065, mean: -0.70238
[32m[0906 21-14-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10513, current rewards: -829.64065, mean: -0.71521
[32m[0906 21-14-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10508, current rewards: -879.64065, mean: -0.72698
[32m[0906 21-14-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10503, current rewards: -929.64065, mean: -0.73781
[32m[0906 21-14-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10497, current rewards: -979.64065, mean: -0.74782
[32m[0906 21-14-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10492, current rewards: -1029.64065, mean: -0.75709
[32m[0906 21-14-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10487, current rewards: -1079.64065, mean: -0.76570
[32m[0906 21-14-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10481, current rewards: -1129.64065, mean: -0.77373
[32m[0906 21-14-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10478, current rewards: -1179.64065, mean: -0.78122
[32m[0906 21-15-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10474, current rewards: -1229.64065, mean: -0.78823
[32m[0906 21-15-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10470, current rewards: -1279.64065, mean: -0.79481
[32m[0906 21-15-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10468, current rewards: -1329.64065, mean: -0.80099
[32m[0906 21-15-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10464, current rewards: -1379.64065, mean: -0.80681
[32m[0906 21-15-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10461, current rewards: -1429.64065, mean: -0.81230
[32m[0906 21-15-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10459, current rewards: -1479.64065, mean: -0.81748
[32m[0906 21-15-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10457, current rewards: -1529.64065, mean: -0.82239
[32m[0906 21-15-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10455, current rewards: -1579.64065, mean: -0.82704
[32m[0906 21-15-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10453, current rewards: -1613.92045, mean: -0.82343
[32m[0906 21-15-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10451, current rewards: -1611.51977, mean: -0.80175
[32m[0906 21-15-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10451, current rewards: -1609.11910, mean: -0.78113
[32m[0906 21-15-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10458, current rewards: -1606.71842, mean: -0.76148
[32m[0906 21-16-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10463, current rewards: -1622.13398, mean: -0.75099
[32m[0906 21-16-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10469, current rewards: -1672.13398, mean: -0.75662
[32m[0906 21-16-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10475, current rewards: -1722.13398, mean: -0.76201
[32m[0906 21-16-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10479, current rewards: -1772.13398, mean: -0.76716
[32m[0906 21-16-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10483, current rewards: -1822.13398, mean: -0.77209
[32m[0906 21-16-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10489, current rewards: -1872.13398, mean: -0.77682
[32m[0906 21-16-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10492, current rewards: -1922.13398, mean: -0.78136
[32m[0906 21-16-40 @Agent.py:117][0m Average action selection time: 0.1049
[32m[0906 21-16-40 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-16-40 @MBExp.py:227][0m Rewards obtained: [-1962.1339776308757], Lows: [2], Highs: [2008], Total time: 20696.948609
[32m[0906 21-19-33 @MBExp.py:144][0m ####################################################################
[32m[0906 21-19-33 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 21-19-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10156, current rewards: -5.55165, mean: -0.55516
[32m[0906 21-19-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10350, current rewards: 0.37594, mean: 0.00627
[32m[0906 21-19-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10374, current rewards: 5.65185, mean: 0.05138
[32m[0906 21-19-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10352, current rewards: 10.94422, mean: 0.06840
[32m[0906 21-19-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10353, current rewards: 16.23272, mean: 0.07730
[32m[0906 21-20-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10347, current rewards: 21.52268, mean: 0.08278
[32m[0906 21-20-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10359, current rewards: 26.80744, mean: 0.08648
[32m[0906 21-20-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10389, current rewards: 32.08955, mean: 0.08914
[32m[0906 21-20-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10381, current rewards: 37.37913, mean: 0.09117
[32m[0906 21-20-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10370, current rewards: 42.67012, mean: 0.09276
[32m[0906 21-20-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10366, current rewards: 47.95984, mean: 0.09404
[32m[0906 21-20-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10362, current rewards: 53.25043, mean: 0.09509
[32m[0906 21-20-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10371, current rewards: 58.53969, mean: 0.09597
[32m[0906 21-20-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10395, current rewards: 63.82213, mean: 0.09670
[32m[0906 21-20-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10414, current rewards: 69.17521, mean: 0.09743
[32m[0906 21-20-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10429, current rewards: 74.51553, mean: 0.09805
[32m[0906 21-20-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10449, current rewards: 79.83385, mean: 0.09856
[32m[0906 21-21-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10457, current rewards: 74.53777, mean: 0.08667
[32m[0906 21-21-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10469, current rewards: 79.94182, mean: 0.08785
[32m[0906 21-21-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10480, current rewards: 85.34044, mean: 0.08890
[32m[0906 21-21-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10486, current rewards: 90.74249, mean: 0.08984
[32m[0906 21-21-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10494, current rewards: 96.14093, mean: 0.09070
[32m[0906 21-21-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10495, current rewards: 101.88003, mean: 0.09178
[32m[0906 21-21-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10486, current rewards: 107.33003, mean: 0.09253
[32m[0906 21-21-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10480, current rewards: 103.06926, mean: 0.08518
[32m[0906 21-21-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10476, current rewards: 109.33718, mean: 0.08678
[32m[0906 21-21-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10471, current rewards: 115.60428, mean: 0.08825
[32m[0906 21-21-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10464, current rewards: 121.86856, mean: 0.08961
[32m[0906 21-22-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10460, current rewards: 128.13852, mean: 0.09088
[32m[0906 21-22-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10456, current rewards: 134.40595, mean: 0.09206
[32m[0906 21-22-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10453, current rewards: 140.64564, mean: 0.09314
[32m[0906 21-22-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10451, current rewards: 146.72660, mean: 0.09406
[32m[0906 21-22-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10446, current rewards: 145.63300, mean: 0.09046
[32m[0906 21-22-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10443, current rewards: 150.96796, mean: 0.09094
[32m[0906 21-22-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10442, current rewards: 156.30016, mean: 0.09140
[32m[0906 21-22-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10440, current rewards: 161.63962, mean: 0.09184
[32m[0906 21-22-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10437, current rewards: 166.97850, mean: 0.09225
[32m[0906 21-22-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10436, current rewards: 172.31452, mean: 0.09264
[32m[0906 21-22-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10434, current rewards: 177.64500, mean: 0.09301
[32m[0906 21-22-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10433, current rewards: 184.01754, mean: 0.09389
[32m[0906 21-23-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10432, current rewards: 179.04184, mean: 0.08908
[32m[0906 21-23-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10432, current rewards: 182.95411, mean: 0.08881
[32m[0906 21-23-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10436, current rewards: 186.83406, mean: 0.08855
[32m[0906 21-23-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10441, current rewards: 190.70159, mean: 0.08829
[32m[0906 21-23-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10445, current rewards: 194.57929, mean: 0.08804
[32m[0906 21-23-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10450, current rewards: 198.45151, mean: 0.08781
[32m[0906 21-23-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10455, current rewards: 202.32485, mean: 0.08759
[32m[0906 21-23-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10459, current rewards: 206.13363, mean: 0.08734
[32m[0906 21-23-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10463, current rewards: 191.36768, mean: 0.07941
[32m[0906 21-23-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10467, current rewards: 197.68311, mean: 0.08036
[32m[0906 21-23-56 @Agent.py:117][0m Average action selection time: 0.1047
[32m[0906 21-23-56 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-23-56 @MBExp.py:227][0m Rewards obtained: [202.7354449552315], Lows: [25], Highs: [12], Total time: 20959.5172
[32m[0906 21-26-52 @MBExp.py:144][0m ####################################################################
[32m[0906 21-26-52 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 21-26-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10254, current rewards: 1.33398, mean: 0.13340
[32m[0906 21-26-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10284, current rewards: 8.09802, mean: 0.13497
[32m[0906 21-27-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10294, current rewards: 14.86206, mean: 0.13511
[32m[0906 21-27-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10284, current rewards: 21.62609, mean: 0.13516
[32m[0906 21-27-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10279, current rewards: 7.95508, mean: 0.03788
[32m[0906 21-27-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10286, current rewards: -42.04492, mean: -0.16171
[32m[0906 21-27-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10306, current rewards: -92.04492, mean: -0.29692
[32m[0906 21-27-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10343, current rewards: -142.04492, mean: -0.39457
[32m[0906 21-27-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10367, current rewards: -192.04492, mean: -0.46840
[32m[0906 21-27-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10367, current rewards: -242.04492, mean: -0.52618
[32m[0906 21-27-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10363, current rewards: -292.04492, mean: -0.57264
[32m[0906 21-27-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10360, current rewards: -342.04492, mean: -0.61079
[32m[0906 21-27-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10370, current rewards: -392.04492, mean: -0.64270
[32m[0906 21-28-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10387, current rewards: -442.04492, mean: -0.66977
[32m[0906 21-28-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10405, current rewards: -492.04492, mean: -0.69302
[32m[0906 21-28-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10414, current rewards: -542.04492, mean: -0.71322
[32m[0906 21-28-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10423, current rewards: -592.04492, mean: -0.73092
[32m[0906 21-28-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10435, current rewards: -642.04492, mean: -0.74656
[32m[0906 21-28-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10444, current rewards: -692.04492, mean: -0.76049
[32m[0906 21-28-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10449, current rewards: -742.04492, mean: -0.77296
[32m[0906 21-28-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10460, current rewards: -792.04492, mean: -0.78420
[32m[0906 21-28-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10459, current rewards: -842.04492, mean: -0.79438
[32m[0906 21-28-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10451, current rewards: -892.04492, mean: -0.80364
[32m[0906 21-28-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10446, current rewards: -942.04492, mean: -0.81211
[32m[0906 21-28-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10441, current rewards: -992.04492, mean: -0.81987
[32m[0906 21-29-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10436, current rewards: -1042.04492, mean: -0.82702
[32m[0906 21-29-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10432, current rewards: -1092.04492, mean: -0.83362
[32m[0906 21-29-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10427, current rewards: -1142.04492, mean: -0.83974
[32m[0906 21-29-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10423, current rewards: -1192.04492, mean: -0.84542
[32m[0906 21-29-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10419, current rewards: -1242.04492, mean: -0.85072
[32m[0906 21-29-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10416, current rewards: -1292.04492, mean: -0.85566
[32m[0906 21-29-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10413, current rewards: -1342.04492, mean: -0.86029
[32m[0906 21-29-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10411, current rewards: -1392.04492, mean: -0.86462
[32m[0906 21-29-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10408, current rewards: -1442.04492, mean: -0.86870
[32m[0906 21-29-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10405, current rewards: -1492.04492, mean: -0.87254
[32m[0906 21-29-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10402, current rewards: -1542.04492, mean: -0.87616
[32m[0906 21-30-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10400, current rewards: -1592.04492, mean: -0.87958
[32m[0906 21-30-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10399, current rewards: -1642.04492, mean: -0.88282
[32m[0906 21-30-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10398, current rewards: -1692.04492, mean: -0.88589
[32m[0906 21-30-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10396, current rewards: -1742.04492, mean: -0.88880
[32m[0906 21-30-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10394, current rewards: -1792.04492, mean: -0.89156
[32m[0906 21-30-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10394, current rewards: -1842.04492, mean: -0.89420
[32m[0906 21-30-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10392, current rewards: -1892.04492, mean: -0.89670
[32m[0906 21-30-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10395, current rewards: -1942.04492, mean: -0.89909
[32m[0906 21-30-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10399, current rewards: -1992.04492, mean: -0.90138
[32m[0906 21-30-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10403, current rewards: -2042.04492, mean: -0.90356
[32m[0906 21-30-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10407, current rewards: -2092.04492, mean: -0.90565
[32m[0906 21-30-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10411, current rewards: -2142.04492, mean: -0.90765
[32m[0906 21-31-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10414, current rewards: -2192.04492, mean: -0.90956
[32m[0906 21-31-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10418, current rewards: -2242.04492, mean: -0.91140
[32m[0906 21-31-13 @Agent.py:117][0m Average action selection time: 0.1042
[32m[0906 21-31-13 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-31-13 @MBExp.py:227][0m Rewards obtained: [-2282.044922459551], Lows: [0], Highs: [2308], Total time: 21220.830113999997
[32m[0906 21-34-11 @MBExp.py:144][0m ####################################################################
[32m[0906 21-34-11 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 21-34-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10285, current rewards: -14.00000, mean: -1.40000
[32m[0906 21-34-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10291, current rewards: -15.12869, mean: -0.25214
[32m[0906 21-34-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10279, current rewards: -9.72792, mean: -0.08844
[32m[0906 21-34-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10295, current rewards: -4.32854, mean: -0.02705
[32m[0906 21-34-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10294, current rewards: 1.06993, mean: 0.00509
[32m[0906 21-34-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10289, current rewards: 6.23068, mean: 0.02396
[32m[0906 21-34-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10308, current rewards: 11.67160, mean: 0.03765
[32m[0906 21-34-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10330, current rewards: 17.10307, mean: 0.04751
[32m[0906 21-34-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10326, current rewards: 22.53862, mean: 0.05497
[32m[0906 21-34-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10327, current rewards: 27.96875, mean: 0.06080
[32m[0906 21-35-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10327, current rewards: 13.14733, mean: 0.02578
[32m[0906 21-35-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10329, current rewards: 19.49207, mean: 0.03481
[32m[0906 21-35-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10337, current rewards: 24.69211, mean: 0.04048
[32m[0906 21-35-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10355, current rewards: 29.89901, mean: 0.04530
[32m[0906 21-35-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10366, current rewards: 35.10079, mean: 0.04944
[32m[0906 21-35-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10380, current rewards: 40.30332, mean: 0.05303
[32m[0906 21-35-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10390, current rewards: 45.50492, mean: 0.05618
[32m[0906 21-35-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10399, current rewards: 50.70883, mean: 0.05896
[32m[0906 21-35-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10411, current rewards: 55.91013, mean: 0.06144
[32m[0906 21-35-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.10416, current rewards: 61.11542, mean: 0.06366
[32m[0906 21-35-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.10419, current rewards: 66.31845, mean: 0.06566
[32m[0906 21-36-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.10415, current rewards: 72.50705, mean: 0.06840
[32m[0906 21-36-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.10408, current rewards: 71.03795, mean: 0.06400
[32m[0906 21-36-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.10404, current rewards: 77.29352, mean: 0.06663
[32m[0906 21-36-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.10401, current rewards: 83.54803, mean: 0.06905
[32m[0906 21-36-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.10399, current rewards: 89.81525, mean: 0.07128
[32m[0906 21-36-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.10396, current rewards: 97.03506, mean: 0.07407
[32m[0906 21-36-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.10391, current rewards: 103.91218, mean: 0.07641
[32m[0906 21-36-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.10387, current rewards: 110.79502, mean: 0.07858
[32m[0906 21-36-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.10382, current rewards: 117.65128, mean: 0.08058
[32m[0906 21-36-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.10379, current rewards: 123.63486, mean: 0.08188
[32m[0906 21-36-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.10376, current rewards: 130.32459, mean: 0.08354
[32m[0906 21-36-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.10373, current rewards: 137.04099, mean: 0.08512
[32m[0906 21-37-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.10372, current rewards: 143.74655, mean: 0.08659
[32m[0906 21-37-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.10369, current rewards: 150.42410, mean: 0.08797
[32m[0906 21-37-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.10365, current rewards: 157.12123, mean: 0.08927
[32m[0906 21-37-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.10363, current rewards: 163.82060, mean: 0.09051
[32m[0906 21-37-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.10360, current rewards: 170.44622, mean: 0.09164
[32m[0906 21-37-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.10358, current rewards: 180.10625, mean: 0.09430
[32m[0906 21-37-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.10358, current rewards: 186.81037, mean: 0.09531
[32m[0906 21-37-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.10356, current rewards: 193.50688, mean: 0.09627
[32m[0906 21-37-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.10355, current rewards: 200.20360, mean: 0.09719
[32m[0906 21-37-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.10357, current rewards: 206.91537, mean: 0.09806
[32m[0906 21-37-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.10361, current rewards: 213.61087, mean: 0.09889
[32m[0906 21-38-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.10364, current rewards: 198.47842, mean: 0.08981
[32m[0906 21-38-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.10371, current rewards: 206.84781, mean: 0.09153
[32m[0906 21-38-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.10375, current rewards: 213.24905, mean: 0.09232
[32m[0906 21-38-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.10378, current rewards: 219.28627, mean: 0.09292
[32m[0906 21-38-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.10383, current rewards: 225.32743, mean: 0.09350
[32m[0906 21-38-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.10386, current rewards: 231.37269, mean: 0.09405
[32m[0906 21-38-31 @Agent.py:117][0m Average action selection time: 0.1039
[32m[0906 21-38-31 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-38-31 @MBExp.py:227][0m Rewards obtained: [236.205204206912], Lows: [30], Highs: [12], Total time: 21481.359417999996
[32m[0906 21-41-16 @MBExp.py:144][0m ####################################################################
[32m[0906 21-41-16 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 21-41-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09563, current rewards: -9.19601, mean: -0.91960
[32m[0906 21-41-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09681, current rewards: -7.47160, mean: -0.12453
[32m[0906 21-41-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09698, current rewards: -1.64955, mean: -0.01500
[32m[0906 21-41-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09698, current rewards: 4.16868, mean: 0.02605
[32m[0906 21-41-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09698, current rewards: 9.98686, mean: 0.04756
[32m[0906 21-41-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09690, current rewards: 15.48191, mean: 0.05955
[32m[0906 21-41-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09729, current rewards: 21.15764, mean: 0.06825
[32m[0906 21-41-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09766, current rewards: 26.82983, mean: 0.07453
[32m[0906 21-41-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09778, current rewards: 21.96266, mean: 0.05357
[32m[0906 21-42-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09769, current rewards: 27.91035, mean: 0.06067
[32m[0906 21-42-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09764, current rewards: 33.86828, mean: 0.06641
[32m[0906 21-42-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09758, current rewards: 39.81961, mean: 0.07111
[32m[0906 21-42-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09772, current rewards: 45.77640, mean: 0.07504
[32m[0906 21-42-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09792, current rewards: 52.55230, mean: 0.07962
[32m[0906 21-42-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09806, current rewards: 58.09128, mean: 0.08182
[32m[0906 21-42-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09820, current rewards: 63.62446, mean: 0.08372
[32m[0906 21-42-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09832, current rewards: 69.16470, mean: 0.08539
[32m[0906 21-42-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09842, current rewards: 74.70359, mean: 0.08686
[32m[0906 21-42-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09851, current rewards: 80.24620, mean: 0.08818
[32m[0906 21-42-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09858, current rewards: 85.78856, mean: 0.08936
[32m[0906 21-42-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09864, current rewards: 91.33108, mean: 0.09043
[32m[0906 21-43-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09860, current rewards: 84.12353, mean: 0.07936
[32m[0906 21-43-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09853, current rewards: 89.41426, mean: 0.08055
[32m[0906 21-43-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09847, current rewards: 94.81395, mean: 0.08174
[32m[0906 21-43-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09840, current rewards: 100.21422, mean: 0.08282
[32m[0906 21-43-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09835, current rewards: 105.61418, mean: 0.08382
[32m[0906 21-43-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09830, current rewards: 111.01267, mean: 0.08474
[32m[0906 21-43-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09828, current rewards: 116.40863, mean: 0.08559
[32m[0906 21-43-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09823, current rewards: 117.27363, mean: 0.08317
[32m[0906 21-43-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09819, current rewards: 122.76834, mean: 0.08409
[32m[0906 21-43-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09815, current rewards: 128.34909, mean: 0.08500
[32m[0906 21-43-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09811, current rewards: 133.95692, mean: 0.08587
[32m[0906 21-43-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09808, current rewards: 139.56651, mean: 0.08669
[32m[0906 21-43-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09805, current rewards: 145.18212, mean: 0.08746
[32m[0906 21-44-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09803, current rewards: 150.78727, mean: 0.08818
[32m[0906 21-44-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09801, current rewards: 156.39652, mean: 0.08886
[32m[0906 21-44-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09800, current rewards: 162.00547, mean: 0.08951
[32m[0906 21-44-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09784, current rewards: 167.59543, mean: 0.09011
[32m[0906 21-44-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09758, current rewards: 173.81811, mean: 0.09100
[32m[0906 21-44-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09735, current rewards: 180.00083, mean: 0.09184
[32m[0906 21-44-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09709, current rewards: 186.18619, mean: 0.09263
[32m[0906 21-44-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09686, current rewards: 192.36397, mean: 0.09338
[32m[0906 21-44-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09666, current rewards: 198.54584, mean: 0.09410
[32m[0906 21-44-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09650, current rewards: 204.73334, mean: 0.09478
[32m[0906 21-44-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09635, current rewards: 210.91051, mean: 0.09543
[32m[0906 21-44-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09619, current rewards: 206.21945, mean: 0.09125
[32m[0906 21-44-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09605, current rewards: 211.51859, mean: 0.09157
[32m[0906 21-45-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09591, current rewards: 216.93296, mean: 0.09192
[32m[0906 21-45-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09579, current rewards: 222.34270, mean: 0.09226
[32m[0906 21-45-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09566, current rewards: 227.75321, mean: 0.09258
[32m[0906 21-45-16 @Agent.py:117][0m Average action selection time: 0.0956
[32m[0906 21-45-16 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-45-16 @MBExp.py:227][0m Rewards obtained: [232.08381751196484], Lows: [20], Highs: [11], Total time: 21721.000369999998
[32m[0906 21-47-43 @MBExp.py:144][0m ####################################################################
[32m[0906 21-47-43 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 21-47-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09984, current rewards: -6.59941, mean: -0.65994
[32m[0906 21-47-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08925, current rewards: -0.99838, mean: -0.01664
[32m[0906 21-47-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08828, current rewards: 4.32771, mean: 0.03934
[32m[0906 21-47-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08797, current rewards: 9.64579, mean: 0.06029
[32m[0906 21-48-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08769, current rewards: 14.86215, mean: 0.07077
[32m[0906 21-48-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08748, current rewards: 20.22392, mean: 0.07778
[32m[0906 21-48-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08775, current rewards: 20.84544, mean: 0.06724
[32m[0906 21-48-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08802, current rewards: 27.98027, mean: 0.07772
[32m[0906 21-48-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08787, current rewards: 35.13732, mean: 0.08570
[32m[0906 21-48-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08779, current rewards: 42.28838, mean: 0.09193
[32m[0906 21-48-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08774, current rewards: 49.44295, mean: 0.09695
[32m[0906 21-48-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08772, current rewards: 56.59621, mean: 0.10106
[32m[0906 21-48-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08779, current rewards: 64.18997, mean: 0.10523
[32m[0906 21-48-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08795, current rewards: 71.32792, mean: 0.10807
[32m[0906 21-48-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08806, current rewards: 78.46941, mean: 0.11052
[32m[0906 21-48-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08817, current rewards: 72.92764, mean: 0.09596
[32m[0906 21-48-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08826, current rewards: 78.44085, mean: 0.09684
[32m[0906 21-48-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08836, current rewards: 83.95003, mean: 0.09762
[32m[0906 21-49-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08844, current rewards: 89.46897, mean: 0.09832
[32m[0906 21-49-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08850, current rewards: 94.98423, mean: 0.09894
[32m[0906 21-49-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08850, current rewards: 100.08188, mean: 0.09909
[32m[0906 21-49-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08844, current rewards: 105.24308, mean: 0.09929
[32m[0906 21-49-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08838, current rewards: 110.62697, mean: 0.09966
[32m[0906 21-49-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08834, current rewards: 116.01251, mean: 0.10001
[32m[0906 21-49-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08828, current rewards: 121.38897, mean: 0.10032
[32m[0906 21-49-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08824, current rewards: 107.81980, mean: 0.08557
[32m[0906 21-49-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08821, current rewards: 113.31924, mean: 0.08650
[32m[0906 21-49-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08817, current rewards: 118.82667, mean: 0.08737
[32m[0906 21-49-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08814, current rewards: 124.34136, mean: 0.08819
[32m[0906 21-49-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08810, current rewards: 129.84961, mean: 0.08894
[32m[0906 21-49-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08807, current rewards: 135.35770, mean: 0.08964
[32m[0906 21-50-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08803, current rewards: 140.86767, mean: 0.09030
[32m[0906 21-50-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08801, current rewards: 146.37978, mean: 0.09092
[32m[0906 21-50-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08800, current rewards: 151.88634, mean: 0.09150
[32m[0906 21-50-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08798, current rewards: 157.38303, mean: 0.09204
[32m[0906 21-50-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08795, current rewards: 162.89127, mean: 0.09255
[32m[0906 21-50-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08792, current rewards: 168.39710, mean: 0.09304
[32m[0906 21-50-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08790, current rewards: 150.71798, mean: 0.08103
[32m[0906 21-50-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08789, current rewards: 157.77589, mean: 0.08261
[32m[0906 21-50-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08788, current rewards: 164.83366, mean: 0.08410
[32m[0906 21-50-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08786, current rewards: 171.89127, mean: 0.08552
[32m[0906 21-50-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08784, current rewards: 178.94570, mean: 0.08687
[32m[0906 21-50-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08787, current rewards: 186.00784, mean: 0.08816
[32m[0906 21-50-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08791, current rewards: 193.06633, mean: 0.08938
[32m[0906 21-50-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08796, current rewards: 200.12358, mean: 0.09055
[32m[0906 21-51-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08800, current rewards: 202.50047, mean: 0.08960
[32m[0906 21-51-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08804, current rewards: 206.00662, mean: 0.08918
[32m[0906 21-51-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08808, current rewards: 211.78745, mean: 0.08974
[32m[0906 21-51-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08811, current rewards: 217.56153, mean: 0.09027
[32m[0906 21-51-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08815, current rewards: 223.32815, mean: 0.09078
[32m[0906 21-51-24 @Agent.py:117][0m Average action selection time: 0.0882
[32m[0906 21-51-24 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-51-24 @MBExp.py:227][0m Rewards obtained: [227.9495673894099], Lows: [25], Highs: [22], Total time: 21942.140086999996
[32m[0906 21-53-54 @MBExp.py:144][0m ####################################################################
[32m[0906 21-53-54 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 21-53-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08896, current rewards: -0.79959, mean: -0.07996
[32m[0906 21-53-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08736, current rewards: 5.38600, mean: 0.08977
[32m[0906 21-54-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08729, current rewards: 11.07312, mean: 0.10066
[32m[0906 21-54-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08729, current rewards: 16.79974, mean: 0.10500
[32m[0906 21-54-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08720, current rewards: 22.43960, mean: 0.10686
[32m[0906 21-54-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08709, current rewards: 28.07348, mean: 0.10797
[32m[0906 21-54-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08746, current rewards: 33.71265, mean: 0.10875
[32m[0906 21-54-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08777, current rewards: 39.34638, mean: 0.10930
[32m[0906 21-54-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08770, current rewards: 40.00827, mean: 0.09758
[32m[0906 21-54-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08766, current rewards: 46.40505, mean: 0.10088
[32m[0906 21-54-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08763, current rewards: 52.80407, mean: 0.10354
[32m[0906 21-54-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08757, current rewards: 59.81360, mean: 0.10681
[32m[0906 21-54-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08783, current rewards: 50.08631, mean: 0.08211
[32m[0906 21-54-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08798, current rewards: 55.27149, mean: 0.08374
[32m[0906 21-54-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08809, current rewards: 60.42231, mean: 0.08510
[32m[0906 21-55-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08820, current rewards: 65.56911, mean: 0.08628
[32m[0906 21-55-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08829, current rewards: 70.72066, mean: 0.08731
[32m[0906 21-55-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08839, current rewards: 75.86751, mean: 0.08822
[32m[0906 21-55-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08845, current rewards: 81.01502, mean: 0.08903
[32m[0906 21-55-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08851, current rewards: 86.19117, mean: 0.08978
[32m[0906 21-55-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08845, current rewards: 91.49038, mean: 0.09058
[32m[0906 21-55-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08839, current rewards: 96.66666, mean: 0.09119
[32m[0906 21-55-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08833, current rewards: 104.29912, mean: 0.09396
[32m[0906 21-55-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08827, current rewards: 109.64215, mean: 0.09452
[32m[0906 21-55-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08822, current rewards: 114.99883, mean: 0.09504
[32m[0906 21-55-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08817, current rewards: 120.34688, mean: 0.09551
[32m[0906 21-55-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08814, current rewards: 125.70463, mean: 0.09596
[32m[0906 21-55-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08810, current rewards: 131.05646, mean: 0.09637
[32m[0906 21-55-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08806, current rewards: 135.82894, mean: 0.09633
[32m[0906 21-56-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08802, current rewards: 141.02574, mean: 0.09659
[32m[0906 21-56-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08799, current rewards: 146.21962, mean: 0.09683
[32m[0906 21-56-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08795, current rewards: 151.40800, mean: 0.09706
[32m[0906 21-56-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08793, current rewards: 156.61086, mean: 0.09727
[32m[0906 21-56-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08790, current rewards: 151.61523, mean: 0.09133
[32m[0906 21-56-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08788, current rewards: 157.85973, mean: 0.09232
[32m[0906 21-56-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08786, current rewards: 164.13450, mean: 0.09326
[32m[0906 21-56-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08784, current rewards: 169.97001, mean: 0.09391
[32m[0906 21-56-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08782, current rewards: 176.24385, mean: 0.09475
[32m[0906 21-56-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08780, current rewards: 182.51162, mean: 0.09556
[32m[0906 21-56-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08778, current rewards: 188.80648, mean: 0.09633
[32m[0906 21-56-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08776, current rewards: 195.09648, mean: 0.09706
[32m[0906 21-56-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08775, current rewards: 201.40614, mean: 0.09777
[32m[0906 21-56-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08775, current rewards: 207.69849, mean: 0.09844
[32m[0906 21-57-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08779, current rewards: 213.99645, mean: 0.09907
[32m[0906 21-57-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08784, current rewards: 221.42253, mean: 0.10019
[32m[0906 21-57-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08789, current rewards: 228.19930, mean: 0.10097
[32m[0906 21-57-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08792, current rewards: 234.05085, mean: 0.10132
[32m[0906 21-57-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08796, current rewards: 239.92274, mean: 0.10166
[32m[0906 21-57-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08800, current rewards: 245.79534, mean: 0.10199
[32m[0906 21-57-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08804, current rewards: 251.67606, mean: 0.10231
[32m[0906 21-57-34 @Agent.py:117][0m Average action selection time: 0.0881
[32m[0906 21-57-34 @Agent.py:118][0m Rollout length: 2505
[32m[0906 21-57-34 @MBExp.py:227][0m Rewards obtained: [256.37128252069704], Lows: [11], Highs: [10], Total time: 22163.012757999997
[32m[0906 22-00-05 @MBExp.py:144][0m ####################################################################
[32m[0906 22-00-05 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 22-00-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08639, current rewards: -5.04256, mean: -0.50426
[32m[0906 22-00-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08695, current rewards: 1.81059, mean: 0.03018
[32m[0906 22-00-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08684, current rewards: 7.76472, mean: 0.07059
[32m[0906 22-00-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08695, current rewards: 15.77742, mean: 0.09861
[32m[0906 22-00-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08695, current rewards: 10.26624, mean: 0.04889
[32m[0906 22-00-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08697, current rewards: -39.73376, mean: -0.15282
[32m[0906 22-00-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08740, current rewards: -89.73376, mean: -0.28946
[32m[0906 22-00-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08778, current rewards: -139.73376, mean: -0.38815
[32m[0906 22-00-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08799, current rewards: -189.73376, mean: -0.46277
[32m[0906 22-00-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08801, current rewards: -239.73376, mean: -0.52116
[32m[0906 22-00-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08793, current rewards: -289.73376, mean: -0.56811
[32m[0906 22-00-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08786, current rewards: -339.73376, mean: -0.60667
[32m[0906 22-00-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08787, current rewards: -389.73376, mean: -0.63891
[32m[0906 22-01-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08802, current rewards: -439.73376, mean: -0.66626
[32m[0906 22-01-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08815, current rewards: -489.73376, mean: -0.68977
[32m[0906 22-01-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08826, current rewards: -539.73376, mean: -0.71018
[32m[0906 22-01-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08835, current rewards: -589.73376, mean: -0.72807
[32m[0906 22-01-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08842, current rewards: -639.73376, mean: -0.74388
[32m[0906 22-01-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08849, current rewards: -689.73376, mean: -0.75795
[32m[0906 22-01-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08856, current rewards: -739.73376, mean: -0.77056
[32m[0906 22-01-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08852, current rewards: -789.73376, mean: -0.78191
[32m[0906 22-01-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08846, current rewards: -839.73376, mean: -0.79220
[32m[0906 22-01-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08839, current rewards: -889.73376, mean: -0.80156
[32m[0906 22-01-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08834, current rewards: -939.73376, mean: -0.81012
[32m[0906 22-01-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08829, current rewards: -989.73376, mean: -0.81796
[32m[0906 22-01-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08825, current rewards: -1039.73376, mean: -0.82519
[32m[0906 22-02-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08821, current rewards: -1089.73376, mean: -0.83186
[32m[0906 22-02-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08816, current rewards: -1139.73376, mean: -0.83804
[32m[0906 22-02-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08814, current rewards: -1189.73376, mean: -0.84378
[32m[0906 22-02-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08810, current rewards: -1239.73376, mean: -0.84913
[32m[0906 22-02-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08808, current rewards: -1289.73376, mean: -0.85413
[32m[0906 22-02-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08805, current rewards: -1339.73376, mean: -0.85880
[32m[0906 22-02-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08802, current rewards: -1389.73376, mean: -0.86319
[32m[0906 22-02-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08802, current rewards: -1439.73376, mean: -0.86731
[32m[0906 22-02-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08799, current rewards: -1489.73376, mean: -0.87119
[32m[0906 22-02-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08796, current rewards: -1539.73376, mean: -0.87485
[32m[0906 22-02-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08795, current rewards: -1589.73376, mean: -0.87831
[32m[0906 22-02-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08793, current rewards: -1625.09175, mean: -0.87371
[32m[0906 22-02-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08791, current rewards: -1618.77633, mean: -0.84753
[32m[0906 22-02-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08788, current rewards: -1612.46090, mean: -0.82268
[32m[0906 22-03-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08787, current rewards: -1606.14548, mean: -0.79908
[32m[0906 22-03-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08786, current rewards: -1599.83005, mean: -0.77662
[32m[0906 22-03-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08784, current rewards: -1593.51463, mean: -0.75522
[32m[0906 22-03-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08782, current rewards: -1599.58860, mean: -0.74055
[32m[0906 22-03-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08783, current rewards: -1649.58860, mean: -0.74642
[32m[0906 22-03-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08788, current rewards: -1699.58860, mean: -0.75203
[32m[0906 22-03-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08792, current rewards: -1749.58860, mean: -0.75740
[32m[0906 22-03-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08796, current rewards: -1799.58860, mean: -0.76254
[32m[0906 22-03-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08799, current rewards: -1849.58860, mean: -0.76746
[32m[0906 22-03-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08803, current rewards: -1899.58860, mean: -0.77219
[32m[0906 22-03-46 @Agent.py:117][0m Average action selection time: 0.0881
[32m[0906 22-03-46 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-03-46 @MBExp.py:227][0m Rewards obtained: [-1939.5885981023573], Lows: [3], Highs: [2000], Total time: 22383.874557999996
[32m[0906 22-06-19 @MBExp.py:144][0m ####################################################################
[32m[0906 22-06-19 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 22-06-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09235, current rewards: -7.90921, mean: -0.79092
[32m[0906 22-06-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08816, current rewards: -2.32007, mean: -0.03867
[32m[0906 22-06-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08765, current rewards: 3.50332, mean: 0.03185
[32m[0906 22-06-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08756, current rewards: 9.04349, mean: 0.05652
[32m[0906 22-06-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08742, current rewards: 14.54862, mean: 0.06928
[32m[0906 22-06-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08737, current rewards: 20.05272, mean: 0.07713
[32m[0906 22-06-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08787, current rewards: 14.98170, mean: 0.04833
[32m[0906 22-06-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08815, current rewards: 20.49831, mean: 0.05694
[32m[0906 22-06-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08827, current rewards: 26.01637, mean: 0.06345
[32m[0906 22-07-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08817, current rewards: 31.52706, mean: 0.06854
[32m[0906 22-07-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08805, current rewards: 37.05006, mean: 0.07265
[32m[0906 22-07-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08796, current rewards: 42.64010, mean: 0.07614
[32m[0906 22-07-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08798, current rewards: 48.15863, mean: 0.07895
[32m[0906 22-07-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08813, current rewards: 53.68073, mean: 0.08133
[32m[0906 22-07-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08826, current rewards: 59.19504, mean: 0.08337
[32m[0906 22-07-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08837, current rewards: 64.70352, mean: 0.08514
[32m[0906 22-07-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08854, current rewards: 56.39049, mean: 0.06962
[32m[0906 22-07-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08861, current rewards: 61.58955, mean: 0.07162
[32m[0906 22-07-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08869, current rewards: 66.78740, mean: 0.07339
[32m[0906 22-07-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08873, current rewards: 71.65394, mean: 0.07464
[32m[0906 22-07-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08870, current rewards: 76.79723, mean: 0.07604
[32m[0906 22-07-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08863, current rewards: 64.74766, mean: 0.06108
[32m[0906 22-07-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08856, current rewards: 68.80074, mean: 0.06198
[32m[0906 22-08-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08849, current rewards: 72.86229, mean: 0.06281
[32m[0906 22-08-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08843, current rewards: 76.92140, mean: 0.06357
[32m[0906 22-08-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08836, current rewards: 80.98069, mean: 0.06427
[32m[0906 22-08-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08832, current rewards: 85.03270, mean: 0.06491
[32m[0906 22-08-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08828, current rewards: 89.40820, mean: 0.06574
[32m[0906 22-08-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08824, current rewards: 93.22197, mean: 0.06611
[32m[0906 22-08-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08819, current rewards: 97.04089, mean: 0.06647
[32m[0906 22-08-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08815, current rewards: 91.63664, mean: 0.06069
[32m[0906 22-08-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08811, current rewards: 96.58488, mean: 0.06191
[32m[0906 22-08-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08808, current rewards: 101.52353, mean: 0.06306
[32m[0906 22-08-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08805, current rewards: 106.45948, mean: 0.06413
[32m[0906 22-08-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08802, current rewards: 111.39657, mean: 0.06514
[32m[0906 22-08-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08803, current rewards: 110.81423, mean: 0.06296
[32m[0906 22-08-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08800, current rewards: 114.87069, mean: 0.06346
[32m[0906 22-09-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08796, current rewards: 118.90205, mean: 0.06393
[32m[0906 22-09-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08793, current rewards: 122.92625, mean: 0.06436
[32m[0906 22-09-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08791, current rewards: 126.94891, mean: 0.06477
[32m[0906 22-09-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08789, current rewards: 130.97001, mean: 0.06516
[32m[0906 22-09-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08787, current rewards: 134.98856, mean: 0.06553
[32m[0906 22-09-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08785, current rewards: 139.01135, mean: 0.06588
[32m[0906 22-09-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08783, current rewards: 143.03162, mean: 0.06622
[32m[0906 22-09-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08784, current rewards: 147.62654, mean: 0.06680
[32m[0906 22-09-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08789, current rewards: 151.87172, mean: 0.06720
[32m[0906 22-09-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08793, current rewards: 147.77854, mean: 0.06397
[32m[0906 22-09-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08796, current rewards: 151.60892, mean: 0.06424
[32m[0906 22-09-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08800, current rewards: 157.13822, mean: 0.06520
[32m[0906 22-09-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08803, current rewards: 162.66889, mean: 0.06613
[32m[0906 22-10-00 @Agent.py:117][0m Average action selection time: 0.0881
[32m[0906 22-10-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-10-00 @MBExp.py:227][0m Rewards obtained: [167.0922209505236], Lows: [30], Highs: [16], Total time: 22604.736377999994
[32m[0906 22-12-34 @MBExp.py:144][0m ####################################################################
[32m[0906 22-12-34 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 22-12-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08615, current rewards: -11.78939, mean: -1.17894
[32m[0906 22-12-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08666, current rewards: -10.81292, mean: -0.18022
[32m[0906 22-12-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08690, current rewards: -5.77283, mean: -0.05248
[32m[0906 22-12-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08705, current rewards: -0.72826, mean: -0.00455
[32m[0906 22-12-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08703, current rewards: 4.32011, mean: 0.02057
[32m[0906 22-12-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08710, current rewards: 9.36252, mean: 0.03601
[32m[0906 22-13-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08755, current rewards: 14.41081, mean: 0.04649
[32m[0906 22-13-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08785, current rewards: 19.45339, mean: 0.05404
[32m[0906 22-13-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08779, current rewards: 24.50263, mean: 0.05976
[32m[0906 22-13-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08773, current rewards: 29.54974, mean: 0.06424
[32m[0906 22-13-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08768, current rewards: 34.53913, mean: 0.06772
[32m[0906 22-13-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08762, current rewards: 39.57659, mean: 0.07067
[32m[0906 22-13-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08767, current rewards: 44.61823, mean: 0.07314
[32m[0906 22-13-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08781, current rewards: 49.65621, mean: 0.07524
[32m[0906 22-13-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08794, current rewards: 54.69748, mean: 0.07704
[32m[0906 22-13-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08842, current rewards: 35.03463, mean: 0.04610
[32m[0906 22-13-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08875, current rewards: 21.21535, mean: 0.02619
[32m[0906 22-13-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08901, current rewards: 5.26408, mean: 0.00612
[32m[0906 22-13-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08935, current rewards: -8.52641, mean: -0.00937
[32m[0906 22-14-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08959, current rewards: -22.28309, mean: -0.02321
[32m[0906 22-14-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08974, current rewards: -38.18892, mean: -0.03781
[32m[0906 22-14-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08981, current rewards: -51.99595, mean: -0.04905
[32m[0906 22-14-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08987, current rewards: -65.79415, mean: -0.05927
[32m[0906 22-14-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08995, current rewards: -81.70790, mean: -0.07044
[32m[0906 22-14-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08998, current rewards: -95.48691, mean: -0.07891
[32m[0906 22-14-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09005, current rewards: -109.28181, mean: -0.08673
[32m[0906 22-14-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09006, current rewards: -124.11094, mean: -0.09474
[32m[0906 22-14-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08998, current rewards: -121.66878, mean: -0.08946
[32m[0906 22-14-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08988, current rewards: -118.70824, mean: -0.08419
[32m[0906 22-14-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08978, current rewards: -120.97986, mean: -0.08286
[32m[0906 22-14-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08969, current rewards: -115.02538, mean: -0.07618
[32m[0906 22-14-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08960, current rewards: -108.93240, mean: -0.06983
[32m[0906 22-14-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08954, current rewards: -102.84297, mean: -0.06388
[32m[0906 22-15-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08946, current rewards: -96.75404, mean: -0.05829
[32m[0906 22-15-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08940, current rewards: -90.66099, mean: -0.05302
[32m[0906 22-15-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08934, current rewards: -96.52231, mean: -0.05484
[32m[0906 22-15-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08927, current rewards: -88.44802, mean: -0.04887
[32m[0906 22-15-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08921, current rewards: -80.37374, mean: -0.04321
[32m[0906 22-15-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08915, current rewards: -72.29945, mean: -0.03785
[32m[0906 22-15-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08909, current rewards: -64.22516, mean: -0.03277
[32m[0906 22-15-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08904, current rewards: -56.15088, mean: -0.02794
[32m[0906 22-15-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08900, current rewards: -48.07659, mean: -0.02334
[32m[0906 22-15-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08896, current rewards: -40.00231, mean: -0.01896
[32m[0906 22-15-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08892, current rewards: -33.16693, mean: -0.01536
[32m[0906 22-15-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08894, current rewards: -83.16693, mean: -0.03763
[32m[0906 22-15-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08896, current rewards: -133.16693, mean: -0.05892
[32m[0906 22-16-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08897, current rewards: -183.16693, mean: -0.07929
[32m[0906 22-16-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08898, current rewards: -233.16693, mean: -0.09880
[32m[0906 22-16-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08899, current rewards: -283.16693, mean: -0.11750
[32m[0906 22-16-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08900, current rewards: -333.16693, mean: -0.13543
[32m[0906 22-16-17 @Agent.py:117][0m Average action selection time: 0.0890
[32m[0906 22-16-17 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-16-18 @MBExp.py:227][0m Rewards obtained: [-373.1669297627416], Lows: [16], Highs: [547], Total time: 22827.993672999994
[32m[0906 22-18-54 @MBExp.py:144][0m ####################################################################
[32m[0906 22-18-54 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 22-18-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08655, current rewards: -9.86629, mean: -0.98663
[32m[0906 22-18-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08709, current rewards: -4.90804, mean: -0.08180
[32m[0906 22-19-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08716, current rewards: -0.12525, mean: -0.00114
[32m[0906 22-19-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08714, current rewards: 4.65384, mean: 0.02909
[32m[0906 22-19-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08705, current rewards: 9.42851, mean: 0.04490
[32m[0906 22-19-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08746, current rewards: 16.71566, mean: 0.06429
[32m[0906 22-19-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08784, current rewards: 21.32059, mean: 0.06878
[32m[0906 22-19-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08789, current rewards: 25.93085, mean: 0.07203
[32m[0906 22-19-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08780, current rewards: 30.53686, mean: 0.07448
[32m[0906 22-19-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08773, current rewards: 35.10951, mean: 0.07633
[32m[0906 22-19-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08766, current rewards: 39.69230, mean: 0.07783
[32m[0906 22-19-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08759, current rewards: 44.27782, mean: 0.07907
[32m[0906 22-19-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08781, current rewards: 48.86046, mean: 0.08010
[32m[0906 22-19-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08795, current rewards: 45.98046, mean: 0.06967
[32m[0906 22-19-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08808, current rewards: 49.00752, mean: 0.06902
[32m[0906 22-20-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08818, current rewards: 53.83512, mean: 0.07084
[32m[0906 22-20-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08827, current rewards: 58.66040, mean: 0.07242
[32m[0906 22-20-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08837, current rewards: 63.47011, mean: 0.07380
[32m[0906 22-20-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08846, current rewards: 68.27283, mean: 0.07503
[32m[0906 22-20-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08841, current rewards: 73.08681, mean: 0.07613
[32m[0906 22-20-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08836, current rewards: 77.89868, mean: 0.07713
[32m[0906 22-20-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08831, current rewards: 82.71409, mean: 0.07803
[32m[0906 22-20-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08825, current rewards: 77.63945, mean: 0.06995
[32m[0906 22-20-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08820, current rewards: 83.04836, mean: 0.07159
[32m[0906 22-20-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08816, current rewards: 88.20880, mean: 0.07290
[32m[0906 22-20-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08813, current rewards: 93.37355, mean: 0.07411
[32m[0906 22-20-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08808, current rewards: 98.62120, mean: 0.07528
[32m[0906 22-20-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08804, current rewards: 103.81183, mean: 0.07633
[32m[0906 22-20-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08802, current rewards: 109.00133, mean: 0.07731
[32m[0906 22-21-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08800, current rewards: 114.18715, mean: 0.07821
[32m[0906 22-21-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08803, current rewards: 109.21287, mean: 0.07233
[32m[0906 22-21-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08800, current rewards: 114.06099, mean: 0.07312
[32m[0906 22-21-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08797, current rewards: 118.91059, mean: 0.07386
[32m[0906 22-21-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08794, current rewards: 123.75743, mean: 0.07455
[32m[0906 22-21-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08792, current rewards: 128.60709, mean: 0.07521
[32m[0906 22-21-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08791, current rewards: 133.45314, mean: 0.07583
[32m[0906 22-21-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08790, current rewards: 138.30412, mean: 0.07641
[32m[0906 22-21-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08788, current rewards: 143.15082, mean: 0.07696
[32m[0906 22-21-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08787, current rewards: 147.99713, mean: 0.07749
[32m[0906 22-21-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08785, current rewards: 143.81036, mean: 0.07337
[32m[0906 22-21-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08784, current rewards: 149.56261, mean: 0.07441
[32m[0906 22-21-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08782, current rewards: 155.31461, mean: 0.07540
[32m[0906 22-22-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08781, current rewards: 161.02082, mean: 0.07631
[32m[0906 22-22-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08779, current rewards: 166.77180, mean: 0.07721
[32m[0906 22-22-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08783, current rewards: 165.77959, mean: 0.07501
[32m[0906 22-22-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08787, current rewards: 170.63454, mean: 0.07550
[32m[0906 22-22-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08792, current rewards: 175.49275, mean: 0.07597
[32m[0906 22-22-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08796, current rewards: 180.34591, mean: 0.07642
[32m[0906 22-22-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08800, current rewards: 185.19903, mean: 0.07685
[32m[0906 22-22-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08803, current rewards: 190.05491, mean: 0.07726
[32m[0906 22-22-35 @Agent.py:117][0m Average action selection time: 0.0881
[32m[0906 22-22-35 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-22-35 @MBExp.py:227][0m Rewards obtained: [194.03940533430122], Lows: [20], Highs: [15], Total time: 23048.862447999993
[32m[0906 22-25-13 @MBExp.py:144][0m ####################################################################
[32m[0906 22-25-13 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 22-25-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08635, current rewards: -14.00000, mean: -1.40000
[32m[0906 22-25-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08677, current rewards: -15.27856, mean: -0.25464
[32m[0906 22-25-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08677, current rewards: -9.85755, mean: -0.08961
[32m[0906 22-25-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08675, current rewards: -4.43193, mean: -0.02770
[32m[0906 22-25-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08674, current rewards: 0.99525, mean: 0.00474
[32m[0906 22-25-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08716, current rewards: 6.41417, mean: 0.02467
[32m[0906 22-25-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08756, current rewards: 11.83620, mean: 0.03818
[32m[0906 22-25-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08751, current rewards: 17.25762, mean: 0.04794
[32m[0906 22-25-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08748, current rewards: 11.80475, mean: 0.02879
[32m[0906 22-25-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08744, current rewards: 16.90569, mean: 0.03675
[32m[0906 22-25-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08737, current rewards: 22.00201, mean: 0.04314
[32m[0906 22-26-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08736, current rewards: 27.10240, mean: 0.04840
[32m[0906 22-26-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08752, current rewards: 32.20043, mean: 0.05279
[32m[0906 22-26-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08770, current rewards: 37.29724, mean: 0.05651
[32m[0906 22-26-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08783, current rewards: 42.39184, mean: 0.05971
[32m[0906 22-26-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08795, current rewards: 47.48626, mean: 0.06248
[32m[0906 22-26-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08805, current rewards: 53.47704, mean: 0.06602
[32m[0906 22-26-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08815, current rewards: 48.48388, mean: 0.05638
[32m[0906 22-26-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08819, current rewards: 54.06603, mean: 0.05941
[32m[0906 22-26-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08812, current rewards: 59.65220, mean: 0.06214
[32m[0906 22-26-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08809, current rewards: 65.23467, mean: 0.06459
[32m[0906 22-26-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08802, current rewards: 70.82412, mean: 0.06682
[32m[0906 22-26-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08798, current rewards: 76.40656, mean: 0.06883
[32m[0906 22-26-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08795, current rewards: 81.99083, mean: 0.07068
[32m[0906 22-26-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08792, current rewards: 87.53881, mean: 0.07235
[32m[0906 22-27-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08789, current rewards: 81.72697, mean: 0.06486
[32m[0906 22-27-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08824, current rewards: 87.17638, mean: 0.06655
[32m[0906 22-27-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08858, current rewards: 92.60073, mean: 0.06809
[32m[0906 22-27-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08888, current rewards: 98.02490, mean: 0.06952
[32m[0906 22-27-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08916, current rewards: 103.44957, mean: 0.07086
[32m[0906 22-27-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08942, current rewards: 108.87472, mean: 0.07210
[32m[0906 22-27-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08968, current rewards: 108.56110, mean: 0.06959
[32m[0906 22-27-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08993, current rewards: 113.82290, mean: 0.07070
[32m[0906 22-27-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09014, current rewards: 119.69377, mean: 0.07210
[32m[0906 22-27-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09035, current rewards: 125.69629, mean: 0.07351
[32m[0906 22-27-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09055, current rewards: 131.70668, mean: 0.07483
[32m[0906 22-27-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09073, current rewards: 137.70960, mean: 0.07608
[32m[0906 22-28-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09091, current rewards: 143.71690, mean: 0.07727
[32m[0906 22-28-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09107, current rewards: 149.72275, mean: 0.07839
[32m[0906 22-28-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09122, current rewards: 155.73267, mean: 0.07946
[32m[0906 22-28-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09137, current rewards: 161.74198, mean: 0.08047
[32m[0906 22-28-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09151, current rewards: 167.72604, mean: 0.08142
[32m[0906 22-28-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09164, current rewards: 173.74730, mean: 0.08234
[32m[0906 22-28-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09179, current rewards: 163.42402, mean: 0.07566
[32m[0906 22-28-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09198, current rewards: 168.85408, mean: 0.07640
[32m[0906 22-28-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09216, current rewards: 174.28496, mean: 0.07712
[32m[0906 22-28-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09233, current rewards: 179.71545, mean: 0.07780
[32m[0906 22-28-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09249, current rewards: 185.14225, mean: 0.07845
[32m[0906 22-28-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09265, current rewards: 186.35378, mean: 0.07733
[32m[0906 22-29-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09281, current rewards: 185.37048, mean: 0.07535
[32m[0906 22-29-05 @Agent.py:117][0m Average action selection time: 0.0929
[32m[0906 22-29-05 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-29-06 @MBExp.py:227][0m Rewards obtained: [189.49563186808987], Lows: [32], Highs: [20], Total time: 23281.90419199999
[32m[0906 22-32-03 @MBExp.py:144][0m ####################################################################
[32m[0906 22-32-03 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 22-32-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09538, current rewards: -15.00000, mean: -1.50000
[32m[0906 22-32-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09683, current rewards: -115.00000, mean: -1.91667
[32m[0906 22-32-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09683, current rewards: -207.62676, mean: -1.88752
[32m[0906 22-32-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09690, current rewards: -295.61518, mean: -1.84759
[32m[0906 22-32-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09694, current rewards: -379.94458, mean: -1.80926
[32m[0906 22-32-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09750, current rewards: -465.87577, mean: -1.79183
[32m[0906 22-32-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09755, current rewards: -565.87577, mean: -1.82541
[32m[0906 22-32-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09745, current rewards: -663.49423, mean: -1.84304
[32m[0906 22-32-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09762, current rewards: -734.89509, mean: -1.79243
[32m[0906 22-32-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09754, current rewards: -795.53500, mean: -1.72942
[32m[0906 22-32-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09751, current rewards: -856.69250, mean: -1.67979
[32m[0906 22-32-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09746, current rewards: -907.87032, mean: -1.62120
[32m[0906 22-33-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09762, current rewards: -963.48618, mean: -1.57949
[32m[0906 22-33-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09780, current rewards: -977.23442, mean: -1.48066
[32m[0906 22-33-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09796, current rewards: -1009.62212, mean: -1.42200
[32m[0906 22-33-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09813, current rewards: -1054.55981, mean: -1.38758
[32m[0906 22-33-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09827, current rewards: -1091.74741, mean: -1.34784
[32m[0906 22-33-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09794, current rewards: -1124.92475, mean: -1.30805
[32m[0906 22-33-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09735, current rewards: -1213.34976, mean: -1.33335
[32m[0906 22-33-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09683, current rewards: -1284.45022, mean: -1.33797
[32m[0906 22-33-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09635, current rewards: -1343.19358, mean: -1.32989
[32m[0906 22-33-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09591, current rewards: -1423.83988, mean: -1.34325
[32m[0906 22-33-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09553, current rewards: -1486.22552, mean: -1.33894
[32m[0906 22-33-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09517, current rewards: -1558.09375, mean: -1.34318
[32m[0906 22-33-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09484, current rewards: -1611.09431, mean: -1.33148
[32m[0906 22-34-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09452, current rewards: -1677.69876, mean: -1.33151
[32m[0906 22-34-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09424, current rewards: -1687.73183, mean: -1.28834
[32m[0906 22-34-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09398, current rewards: -1690.81307, mean: -1.24324
[32m[0906 22-34-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09373, current rewards: -1688.17721, mean: -1.19729
[32m[0906 22-34-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09350, current rewards: -1696.01912, mean: -1.16166
[32m[0906 22-34-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09329, current rewards: -1699.61709, mean: -1.12557
[32m[0906 22-34-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09309, current rewards: -1709.30481, mean: -1.09571
[32m[0906 22-34-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09290, current rewards: -1707.97829, mean: -1.06086
[32m[0906 22-34-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09273, current rewards: -1705.42117, mean: -1.02736
[32m[0906 22-34-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09256, current rewards: -1702.86405, mean: -0.99583
[32m[0906 22-34-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09241, current rewards: -1727.63664, mean: -0.98161
[32m[0906 22-34-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09226, current rewards: -1777.63664, mean: -0.98212
[32m[0906 22-34-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09212, current rewards: -1827.63664, mean: -0.98260
[32m[0906 22-34-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09200, current rewards: -1877.63664, mean: -0.98306
[32m[0906 22-35-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09187, current rewards: -1927.63664, mean: -0.98349
[32m[0906 22-35-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09175, current rewards: -1977.63664, mean: -0.98390
[32m[0906 22-35-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09164, current rewards: -2023.31097, mean: -0.98219
[32m[0906 22-35-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09154, current rewards: -2063.60743, mean: -0.97801
[32m[0906 22-35-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09146, current rewards: -2100.72299, mean: -0.97256
[32m[0906 22-35-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09141, current rewards: -2136.78116, mean: -0.96687
[32m[0906 22-35-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09138, current rewards: -2177.08539, mean: -0.96331
[32m[0906 22-35-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09134, current rewards: -2193.43892, mean: -0.94954
[32m[0906 22-35-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09130, current rewards: -2193.07680, mean: -0.92927
[32m[0906 22-35-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09127, current rewards: -2194.73275, mean: -0.91068
[32m[0906 22-35-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09124, current rewards: -2192.98885, mean: -0.89146
[32m[0906 22-35-52 @Agent.py:117][0m Average action selection time: 0.0912
[32m[0906 22-35-52 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-35-52 @MBExp.py:227][0m Rewards obtained: [-2194.1745540545803], Lows: [908], Highs: [543], Total time: 23510.666843999992
[32m[0906 22-38-34 @MBExp.py:144][0m ####################################################################
[32m[0906 22-38-34 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 22-38-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08609, current rewards: -6.18615, mean: -0.61862
[32m[0906 22-38-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08674, current rewards: -1.00089, mean: -0.01668
[32m[0906 22-38-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08678, current rewards: 4.13696, mean: 0.03761
[32m[0906 22-38-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08682, current rewards: 9.27437, mean: 0.05796
[32m[0906 22-38-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08681, current rewards: 14.41537, mean: 0.06864
[32m[0906 22-38-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08718, current rewards: 19.54597, mean: 0.07518
[32m[0906 22-39-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08717, current rewards: 24.55257, mean: 0.07920
[32m[0906 22-39-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08718, current rewards: 29.69625, mean: 0.08249
[32m[0906 22-39-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08725, current rewards: 29.86476, mean: 0.07284
[32m[0906 22-39-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08726, current rewards: 35.33246, mean: 0.07681
[32m[0906 22-39-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08727, current rewards: 40.76631, mean: 0.07993
[32m[0906 22-39-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08725, current rewards: 46.20104, mean: 0.08250
[32m[0906 22-39-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08735, current rewards: 51.63267, mean: 0.08464
[32m[0906 22-39-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08751, current rewards: 57.07115, mean: 0.08647
[32m[0906 22-39-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08766, current rewards: 62.43913, mean: 0.08794
[32m[0906 22-39-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08778, current rewards: 67.85664, mean: 0.08929
[32m[0906 22-39-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08789, current rewards: 73.28394, mean: 0.09047
[32m[0906 22-39-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08788, current rewards: 78.71020, mean: 0.09152
[32m[0906 22-39-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08787, current rewards: 70.48630, mean: 0.07746
[32m[0906 22-39-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08782, current rewards: 76.31518, mean: 0.07949
[32m[0906 22-40-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08780, current rewards: 82.13559, mean: 0.08132
[32m[0906 22-40-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08777, current rewards: 87.96040, mean: 0.08298
[32m[0906 22-40-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08774, current rewards: 93.52392, mean: 0.08426
[32m[0906 22-40-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08772, current rewards: 86.69749, mean: 0.07474
[32m[0906 22-40-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08770, current rewards: 92.88795, mean: 0.07677
[32m[0906 22-40-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08768, current rewards: 99.08134, mean: 0.07864
[32m[0906 22-40-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08766, current rewards: 105.27055, mean: 0.08036
[32m[0906 22-40-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08763, current rewards: 111.46669, mean: 0.08196
[32m[0906 22-40-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08761, current rewards: 117.65834, mean: 0.08345
[32m[0906 22-40-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08760, current rewards: 109.84109, mean: 0.07523
[32m[0906 22-40-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08757, current rewards: 115.22303, mean: 0.07631
[32m[0906 22-40-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08755, current rewards: 121.12907, mean: 0.07765
[32m[0906 22-40-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08753, current rewards: 126.59260, mean: 0.07863
[32m[0906 22-40-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08751, current rewards: 132.06100, mean: 0.07955
[32m[0906 22-41-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08750, current rewards: 137.52885, mean: 0.08043
[32m[0906 22-41-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08748, current rewards: 142.99158, mean: 0.08125
[32m[0906 22-41-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08748, current rewards: 148.45671, mean: 0.08202
[32m[0906 22-41-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08746, current rewards: 153.92952, mean: 0.08276
[32m[0906 22-41-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08746, current rewards: 159.39421, mean: 0.08345
[32m[0906 22-41-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08745, current rewards: 164.86332, mean: 0.08411
[32m[0906 22-41-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08745, current rewards: 158.44937, mean: 0.07883
[32m[0906 22-41-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08744, current rewards: 163.32364, mean: 0.07928
[32m[0906 22-41-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08742, current rewards: 168.07488, mean: 0.07966
[32m[0906 22-41-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08744, current rewards: 172.82735, mean: 0.08001
[32m[0906 22-41-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08749, current rewards: 177.57968, mean: 0.08035
[32m[0906 22-41-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08753, current rewards: 182.32942, mean: 0.08068
[32m[0906 22-41-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08758, current rewards: 187.07988, mean: 0.08099
[32m[0906 22-42-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08762, current rewards: 186.80953, mean: 0.07916
[32m[0906 22-42-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08766, current rewards: 192.63806, mean: 0.07993
[32m[0906 22-42-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08770, current rewards: 198.46562, mean: 0.08068
[32m[0906 22-42-14 @Agent.py:117][0m Average action selection time: 0.0877
[32m[0906 22-42-14 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-42-14 @MBExp.py:227][0m Rewards obtained: [203.12621726239718], Lows: [28], Highs: [15], Total time: 23730.730806999993
[32m[0906 22-44-58 @MBExp.py:144][0m ####################################################################
[32m[0906 22-44-58 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 22-44-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09180, current rewards: -6.38812, mean: -0.63881
[32m[0906 22-45-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08763, current rewards: -1.16433, mean: -0.01941
[32m[0906 22-45-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08733, current rewards: 3.95594, mean: 0.03596
[32m[0906 22-45-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08718, current rewards: 9.07334, mean: 0.05671
[32m[0906 22-45-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08707, current rewards: 14.19165, mean: 0.06758
[32m[0906 22-45-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08668, current rewards: 20.12373, mean: 0.07740
[32m[0906 22-45-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08638, current rewards: 25.25118, mean: 0.08146
[32m[0906 22-45-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08650, current rewards: -27.72667, mean: -0.07702
[32m[0906 22-45-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08657, current rewards: -108.77067, mean: -0.26529
[32m[0906 22-45-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08664, current rewards: -177.85063, mean: -0.38663
[32m[0906 22-45-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08669, current rewards: -253.86583, mean: -0.49778
[32m[0906 22-45-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08676, current rewards: -324.72652, mean: -0.57987
[32m[0906 22-45-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08691, current rewards: -401.26231, mean: -0.65781
[32m[0906 22-45-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08713, current rewards: -478.48145, mean: -0.72497
[32m[0906 22-46-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08733, current rewards: -513.63995, mean: -0.72344
[32m[0906 22-46-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08747, current rewards: -507.93868, mean: -0.66834
[32m[0906 22-46-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08761, current rewards: -502.24218, mean: -0.62005
[32m[0906 22-46-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08765, current rewards: -496.54534, mean: -0.57738
[32m[0906 22-46-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08763, current rewards: -490.84765, mean: -0.53939
[32m[0906 22-46-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08762, current rewards: -485.14828, mean: -0.50536
[32m[0906 22-46-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08759, current rewards: -479.44655, mean: -0.47470
[32m[0906 22-46-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08756, current rewards: -473.92842, mean: -0.44710
[32m[0906 22-46-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08754, current rewards: -466.56052, mean: -0.42032
[32m[0906 22-46-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08751, current rewards: -459.20492, mean: -0.39587
[32m[0906 22-46-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08750, current rewards: -451.85093, mean: -0.37343
[32m[0906 22-46-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08748, current rewards: -444.49257, mean: -0.35277
[32m[0906 22-46-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08752, current rewards: -437.21435, mean: -0.33375
[32m[0906 22-46-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08751, current rewards: -430.78251, mean: -0.31675
[32m[0906 22-47-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08751, current rewards: -424.35231, mean: -0.30096
[32m[0906 22-47-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08752, current rewards: -417.92932, mean: -0.28625
[32m[0906 22-47-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08751, current rewards: -412.43964, mean: -0.27314
[32m[0906 22-47-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08750, current rewards: -406.07987, mean: -0.26031
[32m[0906 22-47-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08750, current rewards: -399.72190, mean: -0.24827
[32m[0906 22-47-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08749, current rewards: -405.68923, mean: -0.24439
[32m[0906 22-47-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08748, current rewards: -399.49994, mean: -0.23363
[32m[0906 22-47-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08746, current rewards: -393.31347, mean: -0.22347
[32m[0906 22-47-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08746, current rewards: -387.12902, mean: -0.21388
[32m[0906 22-47-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08746, current rewards: -380.94656, mean: -0.20481
[32m[0906 22-47-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08745, current rewards: -374.60063, mean: -0.19613
[32m[0906 22-47-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08744, current rewards: -368.36216, mean: -0.18794
[32m[0906 22-47-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08743, current rewards: -362.12694, mean: -0.18016
[32m[0906 22-47-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08742, current rewards: -355.89451, mean: -0.17276
[32m[0906 22-48-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08742, current rewards: -349.65647, mean: -0.16571
[32m[0906 22-48-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08746, current rewards: -343.42000, mean: -0.15899
[32m[0906 22-48-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08751, current rewards: -337.18272, mean: -0.15257
[32m[0906 22-48-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08756, current rewards: -330.94317, mean: -0.14644
[32m[0906 22-48-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08761, current rewards: -323.93000, mean: -0.14023
[32m[0906 22-48-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08766, current rewards: -317.13482, mean: -0.13438
[32m[0906 22-48-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08770, current rewards: -310.66661, mean: -0.12891
[32m[0906 22-48-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08774, current rewards: -304.20270, mean: -0.12366
[32m[0906 22-48-38 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0906 22-48-38 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-48-38 @MBExp.py:227][0m Rewards obtained: [-343.76672577746905], Lows: [308], Highs: [16], Total time: 23950.916780999993
[32m[0906 22-51-23 @MBExp.py:144][0m ####################################################################
[32m[0906 22-51-23 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 22-51-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08617, current rewards: -4.68185, mean: -0.46818
[32m[0906 22-51-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08710, current rewards: 1.21072, mean: 0.02018
[32m[0906 22-51-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08700, current rewards: 7.25315, mean: 0.06594
[32m[0906 22-51-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08698, current rewards: 13.30150, mean: 0.08313
[32m[0906 22-51-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08696, current rewards: 19.34304, mean: 0.09211
[32m[0906 22-51-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08659, current rewards: 25.22358, mean: 0.09701
[32m[0906 22-51-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08624, current rewards: 25.71051, mean: 0.08294
[32m[0906 22-51-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08627, current rewards: 34.15529, mean: 0.09488
[32m[0906 22-51-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08640, current rewards: 42.86688, mean: 0.10455
[32m[0906 22-52-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08647, current rewards: 51.60964, mean: 0.11219
[32m[0906 22-52-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08653, current rewards: 60.34273, mean: 0.11832
[32m[0906 22-52-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08658, current rewards: 69.04833, mean: 0.12330
[32m[0906 22-52-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08670, current rewards: 77.76609, mean: 0.12749
[32m[0906 22-52-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08692, current rewards: 86.39979, mean: 0.13091
[32m[0906 22-52-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08712, current rewards: 95.13856, mean: 0.13400
[32m[0906 22-52-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08730, current rewards: 103.89497, mean: 0.13670
[32m[0906 22-52-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08744, current rewards: 112.63703, mean: 0.13906
[32m[0906 22-52-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08749, current rewards: 121.39696, mean: 0.14116
[32m[0906 22-52-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08747, current rewards: 130.11343, mean: 0.14298
[32m[0906 22-52-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08744, current rewards: 125.21194, mean: 0.13043
[32m[0906 22-52-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08742, current rewards: 130.18198, mean: 0.12889
[32m[0906 22-52-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08741, current rewards: 135.81822, mean: 0.12813
[32m[0906 22-53-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08740, current rewards: 140.87728, mean: 0.12692
[32m[0906 22-53-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08739, current rewards: 145.93587, mean: 0.12581
[32m[0906 22-53-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08738, current rewards: 150.99466, mean: 0.12479
[32m[0906 22-53-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08736, current rewards: 156.05318, mean: 0.12385
[32m[0906 22-53-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08735, current rewards: 161.11189, mean: 0.12299
[32m[0906 22-53-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08734, current rewards: 166.17078, mean: 0.12218
[32m[0906 22-53-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08733, current rewards: 171.22960, mean: 0.12144
[32m[0906 22-53-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08733, current rewards: 176.11278, mean: 0.12063
[32m[0906 22-53-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08732, current rewards: 180.71699, mean: 0.11968
[32m[0906 22-53-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08732, current rewards: 169.87551, mean: 0.10889
[32m[0906 22-53-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08732, current rewards: 174.65652, mean: 0.10848
[32m[0906 22-53-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08730, current rewards: 179.44021, mean: 0.10810
[32m[0906 22-53-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08730, current rewards: 184.21663, mean: 0.10773
[32m[0906 22-53-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08729, current rewards: 188.99711, mean: 0.10738
[32m[0906 22-54-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08728, current rewards: 193.78087, mean: 0.10706
[32m[0906 22-54-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08728, current rewards: 198.56293, mean: 0.10675
[32m[0906 22-54-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08728, current rewards: 204.36152, mean: 0.10700
[32m[0906 22-54-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08728, current rewards: 209.23169, mean: 0.10675
[32m[0906 22-54-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08728, current rewards: 214.09647, mean: 0.10652
[32m[0906 22-54-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08728, current rewards: 218.96113, mean: 0.10629
[32m[0906 22-54-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08727, current rewards: 223.82587, mean: 0.10608
[32m[0906 22-54-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08728, current rewards: 224.49972, mean: 0.10394
[32m[0906 22-54-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08733, current rewards: 224.32748, mean: 0.10151
[32m[0906 22-54-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08738, current rewards: 229.09510, mean: 0.10137
[32m[0906 22-54-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08743, current rewards: 233.86136, mean: 0.10124
[32m[0906 22-54-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08748, current rewards: 238.62688, mean: 0.10111
[32m[0906 22-54-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08752, current rewards: 243.39488, mean: 0.10099
[32m[0906 22-54-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08758, current rewards: 248.16037, mean: 0.10088
[32m[0906 22-55-03 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0906 22-55-03 @Agent.py:118][0m Rollout length: 2505
[32m[0906 22-55-03 @MBExp.py:227][0m Rewards obtained: [251.97199895845037], Lows: [16], Highs: [15], Total time: 24170.66844399999
[32m[0906 22-57-50 @MBExp.py:144][0m ####################################################################
[32m[0906 22-57-50 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 22-57-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08584, current rewards: -9.97761, mean: -0.99776
[32m[0906 22-57-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08695, current rewards: -8.43910, mean: -0.14065
[32m[0906 22-58-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08699, current rewards: -4.86233, mean: -0.04420
[32m[0906 22-58-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08694, current rewards: -1.28678, mean: -0.00804
[32m[0906 22-58-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08693, current rewards: 2.31767, mean: 0.01104
[32m[0906 22-58-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08695, current rewards: 6.24280, mean: 0.02401
[32m[0906 22-58-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08699, current rewards: 9.90387, mean: 0.03195
[32m[0906 22-58-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08729, current rewards: 13.56548, mean: 0.03768
[32m[0906 22-58-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08758, current rewards: 17.22497, mean: 0.04201
[32m[0906 22-58-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08782, current rewards: 20.88583, mean: 0.04540
[32m[0906 22-58-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08786, current rewards: 19.61293, mean: 0.03846
[32m[0906 22-58-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08779, current rewards: 23.99473, mean: 0.04285
[32m[0906 22-58-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08783, current rewards: 28.37682, mean: 0.04652
[32m[0906 22-58-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08795, current rewards: 32.68673, mean: 0.04953
[32m[0906 22-58-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08808, current rewards: 37.04959, mean: 0.05218
[32m[0906 22-58-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08818, current rewards: 41.41281, mean: 0.05449
[32m[0906 22-59-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08827, current rewards: 45.77463, mean: 0.05651
[32m[0906 22-59-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08819, current rewards: 40.14687, mean: 0.04668
[32m[0906 22-59-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08814, current rewards: 45.13085, mean: 0.04959
[32m[0906 22-59-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08809, current rewards: 50.11766, mean: 0.05221
[32m[0906 22-59-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08804, current rewards: 55.09747, mean: 0.05455
[32m[0906 22-59-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08799, current rewards: 59.70537, mean: 0.05633
[32m[0906 22-59-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08796, current rewards: 64.69136, mean: 0.05828
[32m[0906 22-59-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08792, current rewards: 69.66679, mean: 0.06006
[32m[0906 22-59-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08788, current rewards: 74.63821, mean: 0.06168
[32m[0906 22-59-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08785, current rewards: 69.22321, mean: 0.05494
[32m[0906 22-59-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08782, current rewards: 74.47492, mean: 0.05685
[32m[0906 22-59-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08779, current rewards: 79.72743, mean: 0.05862
[32m[0906 22-59-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08776, current rewards: 84.98043, mean: 0.06027
[32m[0906 22-59-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08774, current rewards: 90.15353, mean: 0.06175
[32m[0906 23-00-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08773, current rewards: 95.28187, mean: 0.06310
[32m[0906 23-00-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08770, current rewards: 95.02818, mean: 0.06092
[32m[0906 23-00-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08767, current rewards: 100.32907, mean: 0.06232
[32m[0906 23-00-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08765, current rewards: 105.63198, mean: 0.06363
[32m[0906 23-00-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08763, current rewards: 110.93764, mean: 0.06488
[32m[0906 23-00-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08762, current rewards: 116.24058, mean: 0.06605
[32m[0906 23-00-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08760, current rewards: 121.54277, mean: 0.06715
[32m[0906 23-00-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08759, current rewards: 126.84304, mean: 0.06820
[32m[0906 23-00-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08758, current rewards: 132.89437, mean: 0.06958
[32m[0906 23-00-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08757, current rewards: 138.23477, mean: 0.07053
[32m[0906 23-00-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08756, current rewards: 143.58309, mean: 0.07143
[32m[0906 23-00-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08756, current rewards: 138.87344, mean: 0.06741
[32m[0906 23-00-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08755, current rewards: 144.56263, mean: 0.06851
[32m[0906 23-01-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08755, current rewards: 150.24099, mean: 0.06956
[32m[0906 23-01-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08754, current rewards: 155.91968, mean: 0.07055
[32m[0906 23-01-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08754, current rewards: 161.59997, mean: 0.07150
[32m[0906 23-01-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08753, current rewards: 167.00760, mean: 0.07230
[32m[0906 23-01-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08753, current rewards: 172.65151, mean: 0.07316
[32m[0906 23-01-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08753, current rewards: 178.29443, mean: 0.07398
[32m[0906 23-01-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08756, current rewards: 183.93972, mean: 0.07477
[32m[0906 23-01-30 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0906 23-01-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-01-30 @MBExp.py:227][0m Rewards obtained: [188.45395129816424], Lows: [19], Highs: [15], Total time: 24390.38804099999
[32m[0906 23-04-19 @MBExp.py:144][0m ####################################################################
[32m[0906 23-04-19 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 23-04-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08623, current rewards: -14.00000, mean: -1.40000
[32m[0906 23-04-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08775, current rewards: -114.00000, mean: -1.90000
[32m[0906 23-04-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08728, current rewards: -211.43468, mean: -1.92213
[32m[0906 23-04-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08733, current rewards: -306.18884, mean: -1.91368
[32m[0906 23-04-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08718, current rewards: -401.08046, mean: -1.90991
[32m[0906 23-04-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08721, current rewards: -501.08046, mean: -1.92723
[32m[0906 23-04-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08776, current rewards: -598.56274, mean: -1.93085
[32m[0906 23-04-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08838, current rewards: -698.56274, mean: -1.94045
[32m[0906 23-04-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08876, current rewards: -795.66216, mean: -1.94064
[32m[0906 23-05-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08901, current rewards: -895.66216, mean: -1.94709
[32m[0906 23-05-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08890, current rewards: -995.66216, mean: -1.95228
[32m[0906 23-05-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08874, current rewards: -1029.11501, mean: -1.83771
[32m[0906 23-05-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08869, current rewards: -1023.46844, mean: -1.67782
[32m[0906 23-05-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08876, current rewards: -1018.31295, mean: -1.54290
[32m[0906 23-05-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08884, current rewards: -1012.73555, mean: -1.42639
[32m[0906 23-05-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08890, current rewards: -1007.16544, mean: -1.32522
[32m[0906 23-05-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08884, current rewards: -1001.59195, mean: -1.23653
[32m[0906 23-05-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08874, current rewards: -1006.52353, mean: -1.17038
[32m[0906 23-05-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08867, current rewards: -1000.88324, mean: -1.09987
[32m[0906 23-05-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08859, current rewards: -995.31305, mean: -1.03678
[32m[0906 23-05-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08854, current rewards: -989.74552, mean: -0.97995
[32m[0906 23-05-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08847, current rewards: -984.24894, mean: -0.92854
[32m[0906 23-05-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08842, current rewards: -978.66864, mean: -0.88168
[32m[0906 23-06-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08836, current rewards: -973.08857, mean: -0.83887
[32m[0906 23-06-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08831, current rewards: -967.50727, mean: -0.79959
[32m[0906 23-06-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08826, current rewards: -961.92588, mean: -0.76343
[32m[0906 23-06-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08824, current rewards: -961.93016, mean: -0.73430
[32m[0906 23-06-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08827, current rewards: -971.78560, mean: -0.71455
[32m[0906 23-06-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08824, current rewards: -965.61739, mean: -0.68484
[32m[0906 23-06-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08820, current rewards: -959.41775, mean: -0.65714
[32m[0906 23-06-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08818, current rewards: -953.22623, mean: -0.63128
[32m[0906 23-06-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08815, current rewards: -947.03534, mean: -0.60707
[32m[0906 23-06-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08812, current rewards: -940.84857, mean: -0.58438
[32m[0906 23-06-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08808, current rewards: -934.66458, mean: -0.56305
[32m[0906 23-06-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08806, current rewards: -928.46853, mean: -0.54296
[32m[0906 23-06-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08803, current rewards: -922.28261, mean: -0.52402
[32m[0906 23-06-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08801, current rewards: -916.09116, mean: -0.50613
[32m[0906 23-07-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08799, current rewards: -909.58191, mean: -0.48902
[32m[0906 23-07-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08797, current rewards: -903.29910, mean: -0.47293
[32m[0906 23-07-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08795, current rewards: -897.00127, mean: -0.45765
[32m[0906 23-07-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08793, current rewards: -890.71038, mean: -0.44314
[32m[0906 23-07-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08796, current rewards: -926.73059, mean: -0.44987
[32m[0906 23-07-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08797, current rewards: -982.90940, mean: -0.46583
[32m[0906 23-07-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08803, current rewards: -1032.30034, mean: -0.47792
[32m[0906 23-07-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08807, current rewards: -1086.32131, mean: -0.49155
[32m[0906 23-07-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08812, current rewards: -1159.23350, mean: -0.51294
[32m[0906 23-07-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08816, current rewards: -1244.92783, mean: -0.53893
[32m[0906 23-07-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08818, current rewards: -1317.52162, mean: -0.55827
[32m[0906 23-07-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08824, current rewards: -1402.99826, mean: -0.58216
[32m[0906 23-07-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08829, current rewards: -1474.67435, mean: -0.59946
[32m[0906 23-08-00 @Agent.py:117][0m Average action selection time: 0.0884
[32m[0906 23-08-00 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-08-00 @MBExp.py:227][0m Rewards obtained: [-1538.825353418811], Lows: [882], Highs: [16], Total time: 24612.02135999999
[32m[0906 23-10-51 @MBExp.py:144][0m ####################################################################
[32m[0906 23-10-51 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 23-10-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08599, current rewards: -11.78661, mean: -1.17866
[32m[0906 23-10-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08689, current rewards: -69.92360, mean: -1.16539
[32m[0906 23-11-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08704, current rewards: -130.92534, mean: -1.19023
[32m[0906 23-11-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08698, current rewards: -198.45278, mean: -1.24033
[32m[0906 23-11-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08695, current rewards: -259.45358, mean: -1.23549
[32m[0906 23-11-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08702, current rewards: -326.92218, mean: -1.25739
[32m[0906 23-11-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08721, current rewards: -387.93459, mean: -1.25140
[32m[0906 23-11-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08752, current rewards: -453.32681, mean: -1.25924
[32m[0906 23-11-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08776, current rewards: -516.46782, mean: -1.25968
[32m[0906 23-11-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08769, current rewards: -579.63175, mean: -1.26007
[32m[0906 23-11-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08762, current rewards: -644.86189, mean: -1.26444
[32m[0906 23-11-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08756, current rewards: -646.00176, mean: -1.15357
[32m[0906 23-11-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08766, current rewards: -641.07527, mean: -1.05094
[32m[0906 23-11-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08783, current rewards: -636.12475, mean: -0.96383
[32m[0906 23-11-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08798, current rewards: -631.17850, mean: -0.88898
[32m[0906 23-11-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08798, current rewards: -626.23003, mean: -0.82399
[32m[0906 23-12-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08793, current rewards: -621.28158, mean: -0.76701
[32m[0906 23-12-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08786, current rewards: -616.33351, mean: -0.71667
[32m[0906 23-12-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08783, current rewards: -611.38633, mean: -0.67185
[32m[0906 23-12-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08780, current rewards: -606.44047, mean: -0.63171
[32m[0906 23-12-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08776, current rewards: -601.55367, mean: -0.59560
[32m[0906 23-12-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08773, current rewards: -596.60440, mean: -0.56283
[32m[0906 23-12-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08770, current rewards: -591.65621, mean: -0.53302
[32m[0906 23-12-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08768, current rewards: -586.70557, mean: -0.50578
[32m[0906 23-12-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08766, current rewards: -581.75725, mean: -0.48079
[32m[0906 23-12-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08764, current rewards: -627.49645, mean: -0.49801
[32m[0906 23-12-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08763, current rewards: -626.96810, mean: -0.47860
[32m[0906 23-12-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08761, current rewards: -621.51560, mean: -0.45700
[32m[0906 23-12-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08759, current rewards: -615.51660, mean: -0.43654
[32m[0906 23-12-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08757, current rewards: -609.98470, mean: -0.41780
[32m[0906 23-13-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08756, current rewards: -604.80874, mean: -0.40054
[32m[0906 23-13-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08754, current rewards: -599.63315, mean: -0.38438
[32m[0906 23-13-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08753, current rewards: -594.45841, mean: -0.36923
[32m[0906 23-13-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08751, current rewards: -633.48456, mean: -0.38162
[32m[0906 23-13-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08751, current rewards: -685.40030, mean: -0.40082
[32m[0906 23-13-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08752, current rewards: -737.02092, mean: -0.41876
[32m[0906 23-13-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08750, current rewards: -788.42039, mean: -0.43559
[32m[0906 23-13-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08749, current rewards: -810.92001, mean: -0.43598
[32m[0906 23-13-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08748, current rewards: -805.14246, mean: -0.42154
[32m[0906 23-13-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08747, current rewards: -799.49039, mean: -0.40790
[32m[0906 23-13-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08745, current rewards: -793.84043, mean: -0.39495
[32m[0906 23-13-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08743, current rewards: -788.19023, mean: -0.38262
[32m[0906 23-13-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08743, current rewards: -782.54197, mean: -0.37087
[32m[0906 23-14-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08742, current rewards: -776.88480, mean: -0.35967
[32m[0906 23-14-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08742, current rewards: -771.23525, mean: -0.34898
[32m[0906 23-14-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08742, current rewards: -765.89783, mean: -0.33889
[32m[0906 23-14-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08742, current rewards: -769.60769, mean: -0.33316
[32m[0906 23-14-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08741, current rewards: -763.59814, mean: -0.32356
[32m[0906 23-14-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08741, current rewards: -757.58819, mean: -0.31435
[32m[0906 23-14-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08745, current rewards: -751.58154, mean: -0.30552
[32m[0906 23-14-30 @Agent.py:117][0m Average action selection time: 0.0875
[32m[0906 23-14-30 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-14-31 @MBExp.py:227][0m Rewards obtained: [-755.4022358230616], Lows: [499], Highs: [17], Total time: 24831.46424099999
[32m[0906 23-17-24 @MBExp.py:144][0m ####################################################################
[32m[0906 23-17-24 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 23-17-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08576, current rewards: -7.30967, mean: -0.73097
[32m[0906 23-17-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08665, current rewards: -9.67125, mean: -0.16119
[32m[0906 23-17-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08648, current rewards: -3.70278, mean: -0.03366
[32m[0906 23-17-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08659, current rewards: 2.26645, mean: 0.01417
[32m[0906 23-17-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08665, current rewards: 7.70139, mean: 0.03667
[32m[0906 23-17-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08678, current rewards: 13.81557, mean: 0.05314
[32m[0906 23-17-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08683, current rewards: 19.92835, mean: 0.06428
[32m[0906 23-17-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08680, current rewards: 26.03919, mean: 0.07233
[32m[0906 23-17-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08683, current rewards: 32.15291, mean: 0.07842
[32m[0906 23-18-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08667, current rewards: 38.27006, mean: 0.08320
[32m[0906 23-18-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08648, current rewards: 44.38996, mean: 0.08704
[32m[0906 23-18-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08652, current rewards: 51.07595, mean: 0.09121
[32m[0906 23-18-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08663, current rewards: 60.51492, mean: 0.09920
[32m[0906 23-18-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08687, current rewards: 67.74080, mean: 0.10264
[32m[0906 23-18-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08700, current rewards: 74.84946, mean: 0.10542
[32m[0906 23-18-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08702, current rewards: 81.96828, mean: 0.10785
[32m[0906 23-18-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08704, current rewards: 89.08554, mean: 0.10998
[32m[0906 23-18-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08706, current rewards: 96.21037, mean: 0.11187
[32m[0906 23-18-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08707, current rewards: 103.33224, mean: 0.11355
[32m[0906 23-18-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08708, current rewards: 110.44230, mean: 0.11504
[32m[0906 23-18-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08706, current rewards: 117.56363, mean: 0.11640
[32m[0906 23-18-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08707, current rewards: 113.49139, mean: 0.10707
[32m[0906 23-19-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08708, current rewards: 118.98045, mean: 0.10719
[32m[0906 23-19-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08708, current rewards: 124.51213, mean: 0.10734
[32m[0906 23-19-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08708, current rewards: 130.04995, mean: 0.10748
[32m[0906 23-19-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08708, current rewards: 135.58913, mean: 0.10761
[32m[0906 23-19-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08708, current rewards: 141.12353, mean: 0.10773
[32m[0906 23-19-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08707, current rewards: 146.66185, mean: 0.10784
[32m[0906 23-19-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08707, current rewards: 152.19720, mean: 0.10794
[32m[0906 23-19-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08707, current rewards: 157.89393, mean: 0.10815
[32m[0906 23-19-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08707, current rewards: 163.44935, mean: 0.10824
[32m[0906 23-19-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08707, current rewards: 168.99989, mean: 0.10833
[32m[0906 23-19-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08707, current rewards: 174.55679, mean: 0.10842
[32m[0906 23-19-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08707, current rewards: 174.59303, mean: 0.10518
[32m[0906 23-19-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08707, current rewards: 180.70700, mean: 0.10568
[32m[0906 23-19-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08706, current rewards: 186.82519, mean: 0.10615
[32m[0906 23-20-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08706, current rewards: 192.93801, mean: 0.10660
[32m[0906 23-20-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08705, current rewards: 199.71212, mean: 0.10737
[32m[0906 23-20-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08704, current rewards: 205.78308, mean: 0.10774
[32m[0906 23-20-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08704, current rewards: 211.85851, mean: 0.10809
[32m[0906 23-20-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08705, current rewards: 217.93487, mean: 0.10843
[32m[0906 23-20-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08704, current rewards: 224.00966, mean: 0.10874
[32m[0906 23-20-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08717, current rewards: 218.81474, mean: 0.10370
[32m[0906 23-20-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08717, current rewards: 224.39799, mean: 0.10389
[32m[0906 23-20-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08716, current rewards: 229.96121, mean: 0.10405
[32m[0906 23-20-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08716, current rewards: 235.43215, mean: 0.10417
[32m[0906 23-20-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08717, current rewards: 241.07769, mean: 0.10436
[32m[0906 23-20-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08716, current rewards: 246.72515, mean: 0.10454
[32m[0906 23-20-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08716, current rewards: 252.37361, mean: 0.10472
[32m[0906 23-20-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08717, current rewards: 253.00674, mean: 0.10285
[32m[0906 23-21-02 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0906 23-21-02 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-21-02 @MBExp.py:227][0m Rewards obtained: [257.3082445581515], Lows: [18], Highs: [16], Total time: 25050.23254499999
[32m[0906 23-23-57 @MBExp.py:144][0m ####################################################################
[32m[0906 23-23-57 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 23-23-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08605, current rewards: -8.40929, mean: -0.84093
[32m[0906 23-24-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08669, current rewards: -2.39729, mean: -0.03995
[32m[0906 23-24-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08675, current rewards: 2.86299, mean: 0.02603
[32m[0906 23-24-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08682, current rewards: 8.12266, mean: 0.05077
[32m[0906 23-24-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08687, current rewards: 13.26393, mean: 0.06316
[32m[0906 23-24-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08691, current rewards: 18.45739, mean: 0.07099
[32m[0906 23-24-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08688, current rewards: 23.65249, mean: 0.07630
[32m[0906 23-24-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08692, current rewards: 28.84744, mean: 0.08013
[32m[0906 23-24-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08685, current rewards: 34.04084, mean: 0.08303
[32m[0906 23-24-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08666, current rewards: 39.23536, mean: 0.08529
[32m[0906 23-24-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08652, current rewards: 44.42917, mean: 0.08712
[32m[0906 23-24-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08653, current rewards: 49.62798, mean: 0.08862
[32m[0906 23-24-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08658, current rewards: 55.41212, mean: 0.09084
[32m[0906 23-24-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08676, current rewards: 60.53384, mean: 0.09172
[32m[0906 23-24-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08677, current rewards: 65.66179, mean: 0.09248
[32m[0906 23-25-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08680, current rewards: 70.78548, mean: 0.09314
[32m[0906 23-25-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08682, current rewards: 75.91426, mean: 0.09372
[32m[0906 23-25-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08685, current rewards: 81.04278, mean: 0.09424
[32m[0906 23-25-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08688, current rewards: 86.16883, mean: 0.09469
[32m[0906 23-25-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08689, current rewards: 91.29209, mean: 0.09510
[32m[0906 23-25-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08689, current rewards: 96.32079, mean: 0.09537
[32m[0906 23-25-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08689, current rewards: 88.02943, mean: 0.08305
[32m[0906 23-25-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08689, current rewards: 93.94731, mean: 0.08464
[32m[0906 23-25-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08689, current rewards: 99.86518, mean: 0.08609
[32m[0906 23-25-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08690, current rewards: 105.78306, mean: 0.08742
[32m[0906 23-25-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08690, current rewards: 111.70093, mean: 0.08865
[32m[0906 23-25-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08690, current rewards: 117.61881, mean: 0.08979
[32m[0906 23-25-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08690, current rewards: 123.53668, mean: 0.09084
[32m[0906 23-26-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08690, current rewards: 83.60190, mean: 0.05929
[32m[0906 23-26-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08691, current rewards: 33.60190, mean: 0.02301
[32m[0906 23-26-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08690, current rewards: -16.39810, mean: -0.01086
[32m[0906 23-26-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08690, current rewards: -66.39810, mean: -0.04256
[32m[0906 23-26-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08691, current rewards: -116.39810, mean: -0.07230
[32m[0906 23-26-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08691, current rewards: -166.39810, mean: -0.10024
[32m[0906 23-26-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08691, current rewards: -216.39810, mean: -0.12655
[32m[0906 23-26-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08691, current rewards: -266.39810, mean: -0.15136
[32m[0906 23-26-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08692, current rewards: -316.39810, mean: -0.17481
[32m[0906 23-26-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08692, current rewards: -366.39810, mean: -0.19699
[32m[0906 23-26-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08692, current rewards: -416.39810, mean: -0.21801
[32m[0906 23-26-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08692, current rewards: -466.39810, mean: -0.23796
[32m[0906 23-26-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08693, current rewards: -516.39810, mean: -0.25691
[32m[0906 23-26-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08694, current rewards: -566.39810, mean: -0.27495
[32m[0906 23-27-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08694, current rewards: -616.39810, mean: -0.29213
[32m[0906 23-27-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08694, current rewards: -666.39810, mean: -0.30852
[32m[0906 23-27-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08694, current rewards: -716.39810, mean: -0.32416
[32m[0906 23-27-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08694, current rewards: -766.39810, mean: -0.33911
[32m[0906 23-27-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08694, current rewards: -781.74015, mean: -0.33842
[32m[0906 23-27-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08694, current rewards: -776.64136, mean: -0.32909
[32m[0906 23-27-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08694, current rewards: -771.54752, mean: -0.32014
[32m[0906 23-27-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08697, current rewards: -766.45568, mean: -0.31157
[32m[0906 23-27-36 @Agent.py:117][0m Average action selection time: 0.0870
[32m[0906 23-27-36 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-27-36 @MBExp.py:227][0m Rewards obtained: [-762.4975862020315], Lows: [10], Highs: [914], Total time: 25268.497344999992
[32m[0906 23-30-33 @MBExp.py:144][0m ####################################################################
[32m[0906 23-30-33 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 23-30-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08596, current rewards: -6.73637, mean: -0.67364
[32m[0906 23-30-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08670, current rewards: -3.45574, mean: -0.05760
[32m[0906 23-30-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08683, current rewards: -0.05178, mean: -0.00047
[32m[0906 23-30-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08689, current rewards: 3.35287, mean: 0.02096
[32m[0906 23-30-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08694, current rewards: 6.92149, mean: 0.03296
[32m[0906 23-30-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08682, current rewards: 10.34472, mean: 0.03979
[32m[0906 23-31-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08686, current rewards: 13.77205, mean: 0.04443
[32m[0906 23-31-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08688, current rewards: 17.19643, mean: 0.04777
[32m[0906 23-31-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08664, current rewards: 4.28255, mean: 0.01045
[32m[0906 23-31-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08644, current rewards: 7.55019, mean: 0.01641
[32m[0906 23-31-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08628, current rewards: 10.81587, mean: 0.02121
[32m[0906 23-31-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08615, current rewards: 14.08151, mean: 0.02515
[32m[0906 23-31-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08601, current rewards: 17.20234, mean: 0.02820
[32m[0906 23-31-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08603, current rewards: 15.72420, mean: 0.02382
[32m[0906 23-31-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08603, current rewards: 20.00969, mean: 0.02818
[32m[0906 23-31-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08611, current rewards: 24.29451, mean: 0.03197
[32m[0906 23-31-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08616, current rewards: 28.58236, mean: 0.03529
[32m[0906 23-31-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08621, current rewards: 32.86730, mean: 0.03822
[32m[0906 23-31-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08626, current rewards: 37.15361, mean: 0.04083
[32m[0906 23-31-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08632, current rewards: 34.02009, mean: 0.03544
[32m[0906 23-32-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08643, current rewards: 16.25200, mean: 0.01609
[32m[0906 23-32-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08649, current rewards: -6.22222, mean: -0.00587
[32m[0906 23-32-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08657, current rewards: -27.59107, mean: -0.02486
[32m[0906 23-32-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08660, current rewards: -48.96329, mean: -0.04221
[32m[0906 23-32-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08664, current rewards: -71.41166, mean: -0.05902
[32m[0906 23-32-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08671, current rewards: -92.96864, mean: -0.07378
[32m[0906 23-32-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08677, current rewards: -112.32238, mean: -0.08574
[32m[0906 23-32-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08680, current rewards: -133.67038, mean: -0.09829
[32m[0906 23-32-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08683, current rewards: -155.03769, mean: -0.10996
[32m[0906 23-32-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08689, current rewards: -175.51697, mean: -0.12022
[32m[0906 23-32-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08693, current rewards: -192.94546, mean: -0.12778
[32m[0906 23-32-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08698, current rewards: -215.02387, mean: -0.13784
[32m[0906 23-32-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08698, current rewards: -210.50043, mean: -0.13075
[32m[0906 23-32-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08699, current rewards: -205.97969, mean: -0.12408
[32m[0906 23-33-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08699, current rewards: -201.45691, mean: -0.11781
[32m[0906 23-33-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08700, current rewards: -196.93114, mean: -0.11189
[32m[0906 23-33-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08701, current rewards: -192.03952, mean: -0.10610
[32m[0906 23-33-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08702, current rewards: -186.96834, mean: -0.10052
[32m[0906 23-33-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08702, current rewards: -188.96245, mean: -0.09893
[32m[0906 23-33-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08703, current rewards: -185.55272, mean: -0.09467
[32m[0906 23-33-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08703, current rewards: -182.13835, mean: -0.09062
[32m[0906 23-33-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08703, current rewards: -178.72266, mean: -0.08676
[32m[0906 23-33-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08703, current rewards: -175.30687, mean: -0.08308
[32m[0906 23-33-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08703, current rewards: -171.89264, mean: -0.07958
[32m[0906 23-33-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08703, current rewards: -168.47733, mean: -0.07623
[32m[0906 23-33-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08704, current rewards: -165.30169, mean: -0.07314
[32m[0906 23-33-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08704, current rewards: -162.04741, mean: -0.07015
[32m[0906 23-33-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08704, current rewards: -158.79261, mean: -0.06729
[32m[0906 23-34-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08705, current rewards: -155.53865, mean: -0.06454
[32m[0906 23-34-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08708, current rewards: -152.28251, mean: -0.06190
[32m[0906 23-34-11 @Agent.py:117][0m Average action selection time: 0.0871
[32m[0906 23-34-11 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-34-11 @MBExp.py:227][0m Rewards obtained: [-148.5084134634875], Lows: [15], Highs: [291], Total time: 25487.087077999993
[32m[0906 23-37-11 @MBExp.py:144][0m ####################################################################
[32m[0906 23-37-11 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 23-37-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08611, current rewards: -15.00000, mean: -1.50000
[32m[0906 23-37-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08777, current rewards: -65.52853, mean: -1.09214
[32m[0906 23-37-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08828, current rewards: -100.20097, mean: -0.91092
[32m[0906 23-37-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08820, current rewards: -146.19186, mean: -0.91370
[32m[0906 23-37-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08787, current rewards: -190.71037, mean: -0.90814
[32m[0906 23-37-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08795, current rewards: -228.92697, mean: -0.88049
[32m[0906 23-37-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08800, current rewards: -272.15149, mean: -0.87791
[32m[0906 23-37-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08798, current rewards: -310.48766, mean: -0.86247
[32m[0906 23-37-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08799, current rewards: -312.97611, mean: -0.76336
[32m[0906 23-37-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08760, current rewards: -294.49918, mean: -0.64022
[32m[0906 23-37-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08740, current rewards: -294.38393, mean: -0.57722
[32m[0906 23-38-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08716, current rewards: -289.56295, mean: -0.51708
[32m[0906 23-38-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08696, current rewards: -284.59548, mean: -0.46655
[32m[0906 23-38-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08669, current rewards: -279.81626, mean: -0.42396
[32m[0906 23-38-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08671, current rewards: -275.04237, mean: -0.38738
[32m[0906 23-38-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08673, current rewards: -274.41614, mean: -0.36107
[32m[0906 23-38-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08677, current rewards: -269.24475, mean: -0.33240
[32m[0906 23-38-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08678, current rewards: -264.08578, mean: -0.30708
[32m[0906 23-38-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08680, current rewards: -260.95939, mean: -0.28677
[32m[0906 23-38-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08691, current rewards: -286.78003, mean: -0.29873
[32m[0906 23-38-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08698, current rewards: -306.02459, mean: -0.30299
[32m[0906 23-38-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08697, current rewards: -346.19865, mean: -0.32660
[32m[0906 23-38-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08703, current rewards: -368.46749, mean: -0.33195
[32m[0906 23-38-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08709, current rewards: -399.50499, mean: -0.34440
[32m[0906 23-38-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08717, current rewards: -417.38025, mean: -0.34494
[32m[0906 23-39-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08718, current rewards: -447.37363, mean: -0.35506
[32m[0906 23-39-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08720, current rewards: -474.08761, mean: -0.36190
[32m[0906 23-39-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08719, current rewards: -467.69626, mean: -0.34389
[32m[0906 23-39-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08720, current rewards: -461.88085, mean: -0.32758
[32m[0906 23-39-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08720, current rewards: -456.71592, mean: -0.31282
[32m[0906 23-39-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08720, current rewards: -451.01891, mean: -0.29869
[32m[0906 23-39-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08720, current rewards: -445.32492, mean: -0.28546
[32m[0906 23-39-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08721, current rewards: -455.89246, mean: -0.28316
[32m[0906 23-39-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08720, current rewards: -450.07699, mean: -0.27113
[32m[0906 23-39-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08721, current rewards: -444.26314, mean: -0.25980
[32m[0906 23-39-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08721, current rewards: -438.44742, mean: -0.24912
[32m[0906 23-39-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08722, current rewards: -432.63155, mean: -0.23902
[32m[0906 23-39-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08721, current rewards: -425.47589, mean: -0.22875
[32m[0906 23-39-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08722, current rewards: -419.81211, mean: -0.21980
[32m[0906 23-40-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08722, current rewards: -414.14745, mean: -0.21130
[32m[0906 23-40-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08721, current rewards: -408.48363, mean: -0.20323
[32m[0906 23-40-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08720, current rewards: -402.82260, mean: -0.19554
[32m[0906 23-40-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08720, current rewards: -397.15980, mean: -0.18823
[32m[0906 23-40-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08719, current rewards: -391.49581, mean: -0.18125
[32m[0906 23-40-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08718, current rewards: -405.01778, mean: -0.18327
[32m[0906 23-40-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08718, current rewards: -399.67475, mean: -0.17685
[32m[0906 23-40-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08718, current rewards: -394.51156, mean: -0.17078
[32m[0906 23-40-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08717, current rewards: -389.44283, mean: -0.16502
[32m[0906 23-40-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08717, current rewards: -384.36875, mean: -0.15949
[32m[0906 23-40-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08717, current rewards: -379.29844, mean: -0.15419
[32m[0906 23-40-49 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0906 23-40-49 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-40-49 @MBExp.py:227][0m Rewards obtained: [-375.2347066084409], Lows: [336], Highs: [40], Total time: 25705.777809999992
[32m[0906 23-43-50 @MBExp.py:144][0m ####################################################################
[32m[0906 23-43-50 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 23-43-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08578, current rewards: 0.59499, mean: 0.05950
[32m[0906 23-43-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08655, current rewards: 2.55832, mean: 0.04264
[32m[0906 23-43-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08672, current rewards: 6.88307, mean: 0.06257
[32m[0906 23-44-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08679, current rewards: 11.20731, mean: 0.07005
[32m[0906 23-44-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08687, current rewards: 15.53204, mean: 0.07396
[32m[0906 23-44-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08686, current rewards: 19.85440, mean: 0.07636
[32m[0906 23-44-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08689, current rewards: 24.17772, mean: 0.07799
[32m[0906 23-44-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08684, current rewards: 28.50109, mean: 0.07917
[32m[0906 23-44-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08666, current rewards: 32.82357, mean: 0.08006
[32m[0906 23-44-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08644, current rewards: 37.14833, mean: 0.08076
[32m[0906 23-44-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08625, current rewards: 36.55805, mean: 0.07168
[32m[0906 23-44-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08612, current rewards: 41.87316, mean: 0.07477
[32m[0906 23-44-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08600, current rewards: 47.11278, mean: 0.07723
[32m[0906 23-44-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08585, current rewards: 52.44008, mean: 0.07945
[32m[0906 23-44-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08573, current rewards: 57.76957, mean: 0.08137
[32m[0906 23-44-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08571, current rewards: 63.09410, mean: 0.08302
[32m[0906 23-45-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08579, current rewards: 68.42520, mean: 0.08448
[32m[0906 23-45-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08586, current rewards: 73.75553, mean: 0.08576
[32m[0906 23-45-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08594, current rewards: 79.08710, mean: 0.08691
[32m[0906 23-45-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08600, current rewards: 84.41627, mean: 0.08793
[32m[0906 23-45-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08605, current rewards: 90.54759, mean: 0.08965
[32m[0906 23-45-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08610, current rewards: 95.75549, mean: 0.09034
[32m[0906 23-45-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08614, current rewards: 100.95785, mean: 0.09095
[32m[0906 23-45-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08618, current rewards: 106.16504, mean: 0.09152
[32m[0906 23-45-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08622, current rewards: 100.68196, mean: 0.08321
[32m[0906 23-45-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08623, current rewards: 105.32975, mean: 0.08360
[32m[0906 23-45-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08626, current rewards: 109.97554, mean: 0.08395
[32m[0906 23-45-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08630, current rewards: 114.62089, mean: 0.08428
[32m[0906 23-45-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08633, current rewards: 119.53743, mean: 0.08478
[32m[0906 23-45-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08636, current rewards: 124.58118, mean: 0.08533
[32m[0906 23-46-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08638, current rewards: 126.20822, mean: 0.08358
[32m[0906 23-46-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08641, current rewards: 128.55033, mean: 0.08240
[32m[0906 23-46-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08643, current rewards: 133.02417, mean: 0.08262
[32m[0906 23-46-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08644, current rewards: 137.49795, mean: 0.08283
[32m[0906 23-46-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08647, current rewards: 141.96820, mean: 0.08302
[32m[0906 23-46-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08649, current rewards: 146.44185, mean: 0.08321
[32m[0906 23-46-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08651, current rewards: 150.91904, mean: 0.08338
[32m[0906 23-46-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08653, current rewards: 155.11539, mean: 0.08340
[32m[0906 23-46-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08654, current rewards: 161.40957, mean: 0.08451
[32m[0906 23-46-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08656, current rewards: 167.47566, mean: 0.08545
[32m[0906 23-46-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08657, current rewards: 173.11219, mean: 0.08613
[32m[0906 23-46-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08658, current rewards: 178.73457, mean: 0.08676
[32m[0906 23-46-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08660, current rewards: 184.35704, mean: 0.08737
[32m[0906 23-46-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08662, current rewards: 189.98699, mean: 0.08796
[32m[0906 23-47-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08663, current rewards: 195.61701, mean: 0.08851
[32m[0906 23-47-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08663, current rewards: 201.22376, mean: 0.08904
[32m[0906 23-47-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08665, current rewards: 206.88768, mean: 0.08956
[32m[0906 23-47-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08665, current rewards: 212.55474, mean: 0.09007
[32m[0906 23-47-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08667, current rewards: 218.21769, mean: 0.09055
[32m[0906 23-47-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08668, current rewards: 223.87781, mean: 0.09101
[32m[0906 23-47-27 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0906 23-47-27 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-47-27 @MBExp.py:227][0m Rewards obtained: [228.4230099130258], Lows: [5], Highs: [12], Total time: 25923.263742999992
[32m[0906 23-50-30 @MBExp.py:144][0m ####################################################################
[32m[0906 23-50-30 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 23-50-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08640, current rewards: -12.90108, mean: -1.29011
[32m[0906 23-50-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08720, current rewards: -26.54171, mean: -0.44236
[32m[0906 23-50-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08716, current rewards: -21.75325, mean: -0.19776
[32m[0906 23-50-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08717, current rewards: -16.78748, mean: -0.10492
[32m[0906 23-50-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08705, current rewards: -12.03232, mean: -0.05730
[32m[0906 23-50-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08702, current rewards: -7.28520, mean: -0.02802
[32m[0906 23-50-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08701, current rewards: -2.53540, mean: -0.00818
[32m[0906 23-51-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08700, current rewards: 2.20937, mean: 0.00614
[32m[0906 23-51-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08700, current rewards: -5.41343, mean: -0.01320
[32m[0906 23-51-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08675, current rewards: -0.02941, mean: -0.00006
[32m[0906 23-51-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08656, current rewards: 5.35453, mean: 0.01050
[32m[0906 23-51-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08636, current rewards: 10.73832, mean: 0.01918
[32m[0906 23-51-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08622, current rewards: 16.11470, mean: 0.02642
[32m[0906 23-51-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08610, current rewards: 21.49954, mean: 0.03258
[32m[0906 23-51-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08590, current rewards: 26.88082, mean: 0.03786
[32m[0906 23-51-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08590, current rewards: 32.26475, mean: 0.04245
[32m[0906 23-51-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08598, current rewards: 37.64731, mean: 0.04648
[32m[0906 23-51-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08604, current rewards: 43.02902, mean: 0.05003
[32m[0906 23-51-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08610, current rewards: 48.41720, mean: 0.05321
[32m[0906 23-51-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08615, current rewards: 54.11353, mean: 0.05637
[32m[0906 23-51-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08619, current rewards: 59.91061, mean: 0.05932
[32m[0906 23-52-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08625, current rewards: 65.30797, mean: 0.06161
[32m[0906 23-52-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08629, current rewards: 72.75017, mean: 0.06554
[32m[0906 23-52-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08634, current rewards: 77.91358, mean: 0.06717
[32m[0906 23-52-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08637, current rewards: 83.07474, mean: 0.06866
[32m[0906 23-52-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08639, current rewards: 88.23423, mean: 0.07003
[32m[0906 23-52-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08641, current rewards: 93.39387, mean: 0.07129
[32m[0906 23-52-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08645, current rewards: 98.55340, mean: 0.07247
[32m[0906 23-52-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08646, current rewards: 103.21896, mean: 0.07320
[32m[0906 23-52-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08649, current rewards: 108.28555, mean: 0.07417
[32m[0906 23-52-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08651, current rewards: 113.35039, mean: 0.07507
[32m[0906 23-52-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08653, current rewards: 118.41964, mean: 0.07591
[32m[0906 23-52-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08655, current rewards: 123.48516, mean: 0.07670
[32m[0906 23-52-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08657, current rewards: 128.55154, mean: 0.07744
[32m[0906 23-52-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08658, current rewards: 133.61736, mean: 0.07814
[32m[0906 23-53-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08659, current rewards: 127.17080, mean: 0.07226
[32m[0906 23-53-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08661, current rewards: 132.44933, mean: 0.07318
[32m[0906 23-53-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08662, current rewards: 137.72495, mean: 0.07405
[32m[0906 23-53-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08663, current rewards: 143.00475, mean: 0.07487
[32m[0906 23-53-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08664, current rewards: 148.28410, mean: 0.07566
[32m[0906 23-53-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08666, current rewards: 153.55690, mean: 0.07640
[32m[0906 23-53-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08666, current rewards: 158.83400, mean: 0.07710
[32m[0906 23-53-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08668, current rewards: 164.11548, mean: 0.07778
[32m[0906 23-53-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08669, current rewards: 169.39120, mean: 0.07842
[32m[0906 23-53-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08670, current rewards: 175.49062, mean: 0.07941
[32m[0906 23-53-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08671, current rewards: 180.78884, mean: 0.08000
[32m[0906 23-53-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08672, current rewards: 186.04910, mean: 0.08054
[32m[0906 23-53-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08672, current rewards: 191.31318, mean: 0.08106
[32m[0906 23-54-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08672, current rewards: 196.57850, mean: 0.08157
[32m[0906 23-54-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08672, current rewards: 197.13203, mean: 0.08013
[32m[0906 23-54-08 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0906 23-54-08 @Agent.py:118][0m Rollout length: 2505
[32m[0906 23-54-08 @MBExp.py:227][0m Rewards obtained: [201.37721599877872], Lows: [25], Highs: [10], Total time: 26140.81543899999
[32m[0906 23-57-12 @MBExp.py:144][0m ####################################################################
[32m[0906 23-57-12 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 23-57-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09668, current rewards: -7.86998, mean: -0.78700
[32m[0906 23-57-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08997, current rewards: -5.97231, mean: -0.09954
[32m[0906 23-57-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08864, current rewards: -0.39656, mean: -0.00361
[32m[0906 23-57-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08804, current rewards: 5.14293, mean: 0.03214
[32m[0906 23-57-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08778, current rewards: 10.70709, mean: 0.05099
[32m[0906 23-57-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08754, current rewards: 1.01227, mean: 0.00389
[32m[0906 23-57-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08750, current rewards: 4.58319, mean: 0.01478
[32m[0906 23-57-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08737, current rewards: 8.14157, mean: 0.02262
[32m[0906 23-57-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08731, current rewards: 11.70366, mean: 0.02855
[32m[0906 23-57-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08701, current rewards: 15.26501, mean: 0.03318
[32m[0906 23-57-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08679, current rewards: 18.82379, mean: 0.03691
[32m[0906 23-58-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08658, current rewards: 22.15632, mean: 0.03956
[32m[0906 23-58-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08641, current rewards: 25.78379, mean: 0.04227
[32m[0906 23-58-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08633, current rewards: 19.52730, mean: 0.02959
[32m[0906 23-58-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08614, current rewards: 25.04405, mean: 0.03527
[32m[0906 23-58-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08599, current rewards: 30.57143, mean: 0.04023
[32m[0906 23-58-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08605, current rewards: 36.09613, mean: 0.04456
[32m[0906 23-58-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08611, current rewards: 41.61597, mean: 0.04839
[32m[0906 23-58-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08616, current rewards: 47.13851, mean: 0.05180
[32m[0906 23-58-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08621, current rewards: 52.68317, mean: 0.05488
[32m[0906 23-58-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08625, current rewards: 58.44506, mean: 0.05787
[32m[0906 23-58-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08629, current rewards: 63.94870, mean: 0.06033
[32m[0906 23-58-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08632, current rewards: 69.44595, mean: 0.06256
[32m[0906 23-58-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08635, current rewards: 74.94144, mean: 0.06460
[32m[0906 23-58-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08639, current rewards: 80.43681, mean: 0.06648
[32m[0906 23-59-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08642, current rewards: 85.93570, mean: 0.06820
[32m[0906 23-59-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08656, current rewards: 72.35104, mean: 0.05523
[32m[0906 23-59-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08678, current rewards: 35.74896, mean: 0.02629
[32m[0906 23-59-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08697, current rewards: 4.93266, mean: 0.00350
[32m[0906 23-59-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08714, current rewards: -23.71743, mean: -0.01624
[32m[0906 23-59-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08721, current rewards: -60.28194, mean: -0.03992
[32m[0906 23-59-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08745, current rewards: -108.63254, mean: -0.06964
[32m[0906 23-59-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08752, current rewards: -153.14348, mean: -0.09512
[32m[0906 23-59-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08768, current rewards: -184.42927, mean: -0.11110
[32m[0906 23-59-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08775, current rewards: -224.49048, mean: -0.13128
[32m[0906 23-59-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08790, current rewards: -256.62131, mean: -0.14581
[32m[0906 23-59-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08803, current rewards: -283.81314, mean: -0.15680
[32m[0906 23-59-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08806, current rewards: -332.82258, mean: -0.17894
[32m[0907 00-00-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08818, current rewards: -370.27799, mean: -0.19386
[32m[0907 00-00-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08820, current rewards: -396.74668, mean: -0.20242
[32m[0907 00-00-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08842, current rewards: -438.89311, mean: -0.21835
[32m[0907 00-00-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08842, current rewards: -435.83791, mean: -0.21157
[32m[0907 00-00-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08839, current rewards: -430.08107, mean: -0.20383
[32m[0907 00-00-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08836, current rewards: -424.32494, mean: -0.19645
[32m[0907 00-00-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08832, current rewards: -418.06326, mean: -0.18917
[32m[0907 00-00-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08831, current rewards: -417.81913, mean: -0.18488
[32m[0907 00-00-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08829, current rewards: -413.53822, mean: -0.17902
[32m[0907 00-00-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08826, current rewards: -409.32237, mean: -0.17344
[32m[0907 00-00-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08824, current rewards: -405.10643, mean: -0.16809
[32m[0907 00-00-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08821, current rewards: -400.89099, mean: -0.16296
[32m[0907 00-00-53 @Agent.py:117][0m Average action selection time: 0.0882
[32m[0907 00-00-53 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-00-53 @MBExp.py:227][0m Rewards obtained: [-397.51768755465065], Lows: [313], Highs: [46], Total time: 26362.06514399999
[32m[0907 00-04-00 @MBExp.py:144][0m ####################################################################
[32m[0907 00-04-00 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 00-04-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08604, current rewards: 1.01274, mean: 0.10127
[32m[0907 00-04-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08682, current rewards: 9.37749, mean: 0.15629
[32m[0907 00-04-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08681, current rewards: 19.05147, mean: 0.17320
[32m[0907 00-04-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08680, current rewards: 26.89874, mean: 0.16812
[32m[0907 00-04-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08686, current rewards: 32.69397, mean: 0.15569
[32m[0907 00-04-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08687, current rewards: 38.48920, mean: 0.14804
[32m[0907 00-04-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08680, current rewards: 20.85043, mean: 0.06726
[32m[0907 00-04-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08675, current rewards: -29.14957, mean: -0.08097
[32m[0907 00-04-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08658, current rewards: -79.14957, mean: -0.19305
[32m[0907 00-04-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08644, current rewards: -129.14957, mean: -0.28076
[32m[0907 00-04-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08628, current rewards: -179.14957, mean: -0.35127
[32m[0907 00-04-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08614, current rewards: -229.14957, mean: -0.40920
[32m[0907 00-04-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08604, current rewards: -279.14957, mean: -0.45762
[32m[0907 00-04-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08596, current rewards: -329.14957, mean: -0.49871
[32m[0907 00-05-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08586, current rewards: -379.14957, mean: -0.53401
[32m[0907 00-05-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08587, current rewards: -429.14957, mean: -0.56467
[32m[0907 00-05-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08596, current rewards: -479.14957, mean: -0.59154
[32m[0907 00-05-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08603, current rewards: -529.14957, mean: -0.61529
[32m[0907 00-05-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08609, current rewards: -579.14957, mean: -0.63643
[32m[0907 00-05-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08615, current rewards: -629.14957, mean: -0.65536
[32m[0907 00-05-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08620, current rewards: -679.14957, mean: -0.67243
[32m[0907 00-05-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08625, current rewards: -729.14957, mean: -0.68788
[32m[0907 00-05-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08629, current rewards: -779.14957, mean: -0.70194
[32m[0907 00-05-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08632, current rewards: -829.14957, mean: -0.71478
[32m[0907 00-05-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08635, current rewards: -879.14957, mean: -0.72657
[32m[0907 00-05-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08637, current rewards: -929.14957, mean: -0.73742
[32m[0907 00-05-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08640, current rewards: -979.14957, mean: -0.74744
[32m[0907 00-05-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08643, current rewards: -1029.14957, mean: -0.75673
[32m[0907 00-06-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08644, current rewards: -1079.14957, mean: -0.76535
[32m[0907 00-06-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08647, current rewards: -1129.14957, mean: -0.77339
[32m[0907 00-06-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08649, current rewards: -1179.14957, mean: -0.78089
[32m[0907 00-06-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08652, current rewards: -1229.14957, mean: -0.78792
[32m[0907 00-06-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08653, current rewards: -1279.14957, mean: -0.79450
[32m[0907 00-06-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08654, current rewards: -1329.14957, mean: -0.80069
[32m[0907 00-06-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08655, current rewards: -1379.14957, mean: -0.80652
[32m[0907 00-06-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08658, current rewards: -1429.14957, mean: -0.81202
[32m[0907 00-06-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08659, current rewards: -1479.14957, mean: -0.81721
[32m[0907 00-06-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08660, current rewards: -1529.14957, mean: -0.82212
[32m[0907 00-06-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08661, current rewards: -1579.14957, mean: -0.82678
[32m[0907 00-06-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08662, current rewards: -1629.14957, mean: -0.83120
[32m[0907 00-06-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08663, current rewards: -1679.14957, mean: -0.83540
[32m[0907 00-06-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08664, current rewards: -1729.14957, mean: -0.83939
[32m[0907 00-07-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08664, current rewards: -1779.14957, mean: -0.84320
[32m[0907 00-07-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08666, current rewards: -1829.14957, mean: -0.84683
[32m[0907 00-07-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08667, current rewards: -1879.14957, mean: -0.85029
[32m[0907 00-07-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08668, current rewards: -1929.14957, mean: -0.85361
[32m[0907 00-07-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08669, current rewards: -1979.14957, mean: -0.85677
[32m[0907 00-07-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08669, current rewards: -2029.14957, mean: -0.85981
[32m[0907 00-07-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08670, current rewards: -2079.14957, mean: -0.86272
[32m[0907 00-07-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08671, current rewards: -2088.89984, mean: -0.84915
[32m[0907 00-07-37 @Agent.py:117][0m Average action selection time: 0.0867
[32m[0907 00-07-37 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-07-37 @MBExp.py:227][0m Rewards obtained: [-2086.531707920165], Lows: [0], Highs: [2133], Total time: 26579.60897699999
[32m[0907 00-10-45 @MBExp.py:144][0m ####################################################################
[32m[0907 00-10-45 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 00-10-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09168, current rewards: -5.25548, mean: -0.52555
[32m[0907 00-10-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08757, current rewards: -14.09167, mean: -0.23486
[32m[0907 00-10-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08701, current rewards: -8.18732, mean: -0.07443
[32m[0907 00-10-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08691, current rewards: -2.27827, mean: -0.01424
[32m[0907 00-11-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08693, current rewards: 3.61991, mean: 0.01724
[32m[0907 00-11-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08692, current rewards: 9.52270, mean: 0.03663
[32m[0907 00-11-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08690, current rewards: 9.07267, mean: 0.02927
[32m[0907 00-11-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08690, current rewards: -50.74859, mean: -0.14097
[32m[0907 00-11-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08686, current rewards: -105.96532, mean: -0.25845
[32m[0907 00-11-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08666, current rewards: -100.07238, mean: -0.21755
[32m[0907 00-11-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08647, current rewards: -94.54930, mean: -0.18539
[32m[0907 00-11-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08632, current rewards: -88.73756, mean: -0.15846
[32m[0907 00-11-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08617, current rewards: -83.09401, mean: -0.13622
[32m[0907 00-11-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08607, current rewards: -77.47817, mean: -0.11739
[32m[0907 00-11-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08605, current rewards: -91.52234, mean: -0.12890
[32m[0907 00-11-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08594, current rewards: -87.08915, mean: -0.11459
[32m[0907 00-11-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08596, current rewards: -82.64552, mean: -0.10203
[32m[0907 00-11-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08600, current rewards: -78.21290, mean: -0.09095
[32m[0907 00-12-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08607, current rewards: -73.77769, mean: -0.08107
[32m[0907 00-12-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08612, current rewards: -69.13452, mean: -0.07202
[32m[0907 00-12-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08616, current rewards: -64.65346, mean: -0.06401
[32m[0907 00-12-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08620, current rewards: -60.17961, mean: -0.05677
[32m[0907 00-12-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08637, current rewards: -88.90366, mean: -0.08009
[32m[0907 00-12-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08649, current rewards: -135.90415, mean: -0.11716
[32m[0907 00-12-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08672, current rewards: -194.01926, mean: -0.16035
[32m[0907 00-12-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08687, current rewards: -254.17035, mean: -0.20172
[32m[0907 00-12-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08691, current rewards: -309.08045, mean: -0.23594
[32m[0907 00-12-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08716, current rewards: -358.31570, mean: -0.26347
[32m[0907 00-12-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08743, current rewards: -406.28202, mean: -0.28814
[32m[0907 00-12-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08764, current rewards: -463.25585, mean: -0.31730
[32m[0907 00-12-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08780, current rewards: -514.22025, mean: -0.34054
[32m[0907 00-13-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08823, current rewards: -572.36920, mean: -0.36690
[32m[0907 00-13-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08842, current rewards: -615.21368, mean: -0.38212
[32m[0907 00-13-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08856, current rewards: -665.17326, mean: -0.40071
[32m[0907 00-13-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08869, current rewards: -711.12583, mean: -0.41586
[32m[0907 00-13-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08892, current rewards: -767.83209, mean: -0.43627
[32m[0907 00-13-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08887, current rewards: -817.91236, mean: -0.45189
[32m[0907 00-13-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08883, current rewards: -813.60542, mean: -0.43742
[32m[0907 00-13-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08878, current rewards: -809.30066, mean: -0.42372
[32m[0907 00-13-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08873, current rewards: -804.99328, mean: -0.41071
[32m[0907 00-13-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08869, current rewards: -800.69025, mean: -0.39835
[32m[0907 00-13-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08865, current rewards: -796.38233, mean: -0.38659
[32m[0907 00-13-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08861, current rewards: -792.07802, mean: -0.37539
[32m[0907 00-13-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08857, current rewards: -801.68238, mean: -0.37115
[32m[0907 00-14-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08854, current rewards: -797.59651, mean: -0.36090
[32m[0907 00-14-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08851, current rewards: -793.60217, mean: -0.35115
[32m[0907 00-14-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08848, current rewards: -789.60546, mean: -0.34182
[32m[0907 00-14-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08845, current rewards: -785.61020, mean: -0.33289
[32m[0907 00-14-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08842, current rewards: -781.61623, mean: -0.32432
[32m[0907 00-14-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08839, current rewards: -790.10132, mean: -0.32118
[32m[0907 00-14-27 @Agent.py:117][0m Average action selection time: 0.0885
[32m[0907 00-14-27 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-14-27 @MBExp.py:227][0m Rewards obtained: [-828.1950830688896], Lows: [488], Highs: [86], Total time: 26801.52889899999
[32m[0907 00-17-37 @MBExp.py:144][0m ####################################################################
[32m[0907 00-17-37 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 00-17-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08587, current rewards: -11.74166, mean: -1.17417
[32m[0907 00-17-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08696, current rewards: -5.83565, mean: -0.09726
[32m[0907 00-17-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08706, current rewards: -0.86762, mean: -0.00789
[32m[0907 00-17-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08691, current rewards: 4.48899, mean: 0.02806
[32m[0907 00-17-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08688, current rewards: 9.85517, mean: 0.04693
[32m[0907 00-17-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08690, current rewards: 15.21222, mean: 0.05851
[32m[0907 00-18-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08684, current rewards: 20.56414, mean: 0.06634
[32m[0907 00-18-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08682, current rewards: 20.96540, mean: 0.05824
[32m[0907 00-18-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08665, current rewards: 33.78772, mean: 0.08241
[32m[0907 00-18-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08645, current rewards: 46.61692, mean: 0.10134
[32m[0907 00-18-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08628, current rewards: 59.02630, mean: 0.11574
[32m[0907 00-18-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08615, current rewards: 73.20271, mean: 0.13072
[32m[0907 00-18-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08605, current rewards: 86.26562, mean: 0.14142
[32m[0907 00-18-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08602, current rewards: 83.99500, mean: 0.12727
[32m[0907 00-18-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08585, current rewards: 89.62669, mean: 0.12623
[32m[0907 00-18-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08589, current rewards: 95.26838, mean: 0.12535
[32m[0907 00-18-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08597, current rewards: 100.90774, mean: 0.12458
[32m[0907 00-18-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08604, current rewards: 106.54236, mean: 0.12389
[32m[0907 00-18-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08610, current rewards: 112.18121, mean: 0.12328
[32m[0907 00-18-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08616, current rewards: 117.81893, mean: 0.12273
[32m[0907 00-19-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08618, current rewards: 123.46007, mean: 0.12224
[32m[0907 00-19-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08622, current rewards: 129.10176, mean: 0.12179
[32m[0907 00-19-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08625, current rewards: 134.74687, mean: 0.12139
[32m[0907 00-19-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08628, current rewards: 140.38602, mean: 0.12102
[32m[0907 00-19-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08633, current rewards: 146.02438, mean: 0.12068
[32m[0907 00-19-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08636, current rewards: 151.66311, mean: 0.12037
[32m[0907 00-19-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08638, current rewards: 146.63310, mean: 0.11193
[32m[0907 00-19-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08641, current rewards: 156.62827, mean: 0.11517
[32m[0907 00-19-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08643, current rewards: 163.50784, mean: 0.11596
[32m[0907 00-19-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08646, current rewards: 170.38751, mean: 0.11670
[32m[0907 00-19-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08650, current rewards: 177.26686, mean: 0.11740
[32m[0907 00-19-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08650, current rewards: 173.57719, mean: 0.11127
[32m[0907 00-19-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08652, current rewards: 179.20068, mean: 0.11130
[32m[0907 00-20-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08654, current rewards: 184.82255, mean: 0.11134
[32m[0907 00-20-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08655, current rewards: 190.44551, mean: 0.11137
[32m[0907 00-20-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08657, current rewards: 195.67198, mean: 0.11118
[32m[0907 00-20-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08659, current rewards: 201.29296, mean: 0.11121
[32m[0907 00-20-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08659, current rewards: 206.90047, mean: 0.11124
[32m[0907 00-20-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08660, current rewards: 212.51537, mean: 0.11126
[32m[0907 00-20-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08662, current rewards: 218.13081, mean: 0.11129
[32m[0907 00-20-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08663, current rewards: 223.74533, mean: 0.11132
[32m[0907 00-20-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08664, current rewards: 229.35690, mean: 0.11134
[32m[0907 00-20-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08673, current rewards: 179.11311, mean: 0.08489
[32m[0907 00-20-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08677, current rewards: 149.91888, mean: 0.06941
[32m[0907 00-20-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08687, current rewards: 121.23057, mean: 0.05486
[32m[0907 00-20-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08687, current rewards: 126.96670, mean: 0.05618
[32m[0907 00-20-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08688, current rewards: 132.70547, mean: 0.05745
[32m[0907 00-21-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08689, current rewards: 138.43484, mean: 0.05866
[32m[0907 00-21-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08694, current rewards: 131.60000, mean: 0.05461
[32m[0907 00-21-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08695, current rewards: 137.22792, mean: 0.05578
[32m[0907 00-21-14 @Agent.py:117][0m Average action selection time: 0.0869
[32m[0907 00-21-14 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-21-15 @MBExp.py:227][0m Rewards obtained: [141.72777781951507], Lows: [46], Highs: [89], Total time: 27019.64759299999
[32m[0907 00-24-26 @MBExp.py:144][0m ####################################################################
[32m[0907 00-24-26 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 00-24-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08595, current rewards: -3.96210, mean: -0.39621
[32m[0907 00-24-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08680, current rewards: -11.13783, mean: -0.18563
[32m[0907 00-24-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08707, current rewards: -6.24739, mean: -0.05679
[32m[0907 00-24-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08710, current rewards: -1.35713, mean: -0.00848
[32m[0907 00-24-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08708, current rewards: 3.53225, mean: 0.01682
[32m[0907 00-24-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08705, current rewards: 8.42009, mean: 0.03238
[32m[0907 00-24-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08705, current rewards: 8.33598, mean: 0.02689
[32m[0907 00-24-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08703, current rewards: 13.71857, mean: 0.03811
[32m[0907 00-25-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08705, current rewards: 19.09844, mean: 0.04658
[32m[0907 00-25-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08683, current rewards: 24.95372, mean: 0.05425
[32m[0907 00-25-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08661, current rewards: 27.05896, mean: 0.05306
[32m[0907 00-25-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08697, current rewards: -22.25989, mean: -0.03975
[32m[0907 00-25-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08729, current rewards: -70.29870, mean: -0.11524
[32m[0907 00-25-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08748, current rewards: -117.20868, mean: -0.17759
[32m[0907 00-25-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08729, current rewards: -177.64008, mean: -0.25020
[32m[0907 00-25-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08803, current rewards: -231.45900, mean: -0.30455
[32m[0907 00-25-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08790, current rewards: -229.13152, mean: -0.28288
[32m[0907 00-25-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08773, current rewards: -223.47795, mean: -0.25986
[32m[0907 00-25-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08769, current rewards: -217.96893, mean: -0.23953
[32m[0907 00-25-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08767, current rewards: -215.67021, mean: -0.22466
[32m[0907 00-25-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08783, current rewards: -239.66101, mean: -0.23729
[32m[0907 00-26-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08811, current rewards: -263.44190, mean: -0.24853
[32m[0907 00-26-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08812, current rewards: -288.96594, mean: -0.26033
[32m[0907 00-26-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08827, current rewards: -331.04056, mean: -0.28538
[32m[0907 00-26-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08822, current rewards: -361.42018, mean: -0.29869
[32m[0907 00-26-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08818, current rewards: -398.13281, mean: -0.31598
[32m[0907 00-26-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08818, current rewards: -427.29350, mean: -0.32618
[32m[0907 00-26-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08814, current rewards: -495.29001, mean: -0.36418
[32m[0907 00-26-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08812, current rewards: -559.16085, mean: -0.39657
[32m[0907 00-26-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08808, current rewards: -622.37572, mean: -0.42628
[32m[0907 00-26-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08806, current rewards: -678.75731, mean: -0.44951
[32m[0907 00-26-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08803, current rewards: -735.78803, mean: -0.47166
[32m[0907 00-26-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08800, current rewards: -790.24829, mean: -0.49084
[32m[0907 00-26-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08799, current rewards: -853.24399, mean: -0.51400
[32m[0907 00-26-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08796, current rewards: -912.79683, mean: -0.53380
[32m[0907 00-27-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08795, current rewards: -971.73829, mean: -0.55212
[32m[0907 00-27-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08799, current rewards: -1030.55522, mean: -0.56937
[32m[0907 00-27-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08801, current rewards: -1087.67243, mean: -0.58477
[32m[0907 00-27-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08800, current rewards: -1082.27756, mean: -0.56664
[32m[0907 00-27-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08797, current rewards: -1076.91546, mean: -0.54945
[32m[0907 00-27-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08795, current rewards: -1071.55446, mean: -0.53311
[32m[0907 00-27-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08793, current rewards: -1066.19507, mean: -0.51757
[32m[0907 00-27-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08791, current rewards: -1060.94516, mean: -0.50282
[32m[0907 00-27-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08792, current rewards: -1110.46736, mean: -0.51411
[32m[0907 00-27-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08794, current rewards: -1175.81501, mean: -0.53204
[32m[0907 00-27-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08794, current rewards: -1241.75949, mean: -0.54945
[32m[0907 00-27-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08793, current rewards: -1296.58788, mean: -0.56129
[32m[0907 00-27-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08792, current rewards: -1362.82032, mean: -0.57747
[32m[0907 00-27-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08790, current rewards: -1425.97101, mean: -0.59169
[32m[0907 00-28-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08790, current rewards: -1474.70332, mean: -0.59947
[32m[0907 00-28-07 @Agent.py:117][0m Average action selection time: 0.0879
[32m[0907 00-28-07 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-28-07 @MBExp.py:227][0m Rewards obtained: [-1522.433109982508], Lows: [869], Highs: [31], Total time: 27240.10569299999
[32m[0907 00-31-21 @MBExp.py:144][0m ####################################################################
[32m[0907 00-31-21 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 00-31-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09126, current rewards: -8.93476, mean: -0.89348
[32m[0907 00-31-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08832, current rewards: -3.91898, mean: -0.06532
[32m[0907 00-31-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08767, current rewards: 4.98810, mean: 0.04535
[32m[0907 00-31-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08764, current rewards: 13.88903, mean: 0.08681
[32m[0907 00-31-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08744, current rewards: 22.80122, mean: 0.10858
[32m[0907 00-31-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08737, current rewards: 31.69068, mean: 0.12189
[32m[0907 00-31-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08731, current rewards: 40.60374, mean: 0.13098
[32m[0907 00-31-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08765, current rewards: 8.44101, mean: 0.02345
[32m[0907 00-31-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08800, current rewards: -27.82628, mean: -0.06787
[32m[0907 00-32-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08839, current rewards: -71.57814, mean: -0.15560
[32m[0907 00-32-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08838, current rewards: -111.42831, mean: -0.21849
[32m[0907 00-32-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08874, current rewards: -139.87602, mean: -0.24978
[32m[0907 00-32-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08860, current rewards: -180.14555, mean: -0.29532
[32m[0907 00-32-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08861, current rewards: -224.62067, mean: -0.34033
[32m[0907 00-32-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08823, current rewards: -261.82442, mean: -0.36877
[32m[0907 00-32-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08805, current rewards: -299.20422, mean: -0.39369
[32m[0907 00-32-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08795, current rewards: -350.87767, mean: -0.43318
[32m[0907 00-32-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08808, current rewards: -387.31397, mean: -0.45037
[32m[0907 00-32-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08807, current rewards: -416.68660, mean: -0.45790
[32m[0907 00-32-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08836, current rewards: -463.21397, mean: -0.48251
[32m[0907 00-32-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08830, current rewards: -521.24010, mean: -0.51608
[32m[0907 00-32-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08823, current rewards: -593.17512, mean: -0.55960
[32m[0907 00-32-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08822, current rewards: -656.84301, mean: -0.59175
[32m[0907 00-33-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08819, current rewards: -721.64563, mean: -0.62211
[32m[0907 00-33-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08815, current rewards: -782.21799, mean: -0.64646
[32m[0907 00-33-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08817, current rewards: -845.47319, mean: -0.67101
[32m[0907 00-33-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08815, current rewards: -902.77398, mean: -0.68914
[32m[0907 00-33-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08811, current rewards: -962.60191, mean: -0.70780
[32m[0907 00-33-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08807, current rewards: -994.58945, mean: -0.70538
[32m[0907 00-33-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08805, current rewards: -987.12926, mean: -0.67612
[32m[0907 00-33-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08799, current rewards: -979.66906, mean: -0.64879
[32m[0907 00-33-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08797, current rewards: -976.80568, mean: -0.62616
[32m[0907 00-33-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08813, current rewards: -985.45617, mean: -0.61208
[32m[0907 00-33-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08809, current rewards: -980.85511, mean: -0.59088
[32m[0907 00-33-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08806, current rewards: -974.57328, mean: -0.56993
[32m[0907 00-33-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08804, current rewards: -968.19837, mean: -0.55011
[32m[0907 00-34-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08801, current rewards: -961.81254, mean: -0.53139
[32m[0907 00-34-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08799, current rewards: -955.45359, mean: -0.51368
[32m[0907 00-34-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08797, current rewards: -949.11310, mean: -0.49692
[32m[0907 00-34-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08794, current rewards: -942.76125, mean: -0.48100
[32m[0907 00-34-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08792, current rewards: -936.40236, mean: -0.46587
[32m[0907 00-34-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08790, current rewards: -930.05761, mean: -0.45148
[32m[0907 00-34-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08788, current rewards: -922.42435, mean: -0.43717
[32m[0907 00-34-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08786, current rewards: -915.07681, mean: -0.42365
[32m[0907 00-34-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08784, current rewards: -907.75042, mean: -0.41075
[32m[0907 00-34-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08783, current rewards: -900.42025, mean: -0.39842
[32m[0907 00-34-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08781, current rewards: -893.09014, mean: -0.38662
[32m[0907 00-34-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08779, current rewards: -918.57988, mean: -0.38923
[32m[0907 00-34-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08779, current rewards: -970.19894, mean: -0.40257
[32m[0907 00-34-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08778, current rewards: -966.44676, mean: -0.39286
[32m[0907 00-35-01 @Agent.py:117][0m Average action selection time: 0.0878
[32m[0907 00-35-01 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-35-01 @MBExp.py:227][0m Rewards obtained: [-961.2214986084962], Lows: [619], Highs: [42], Total time: 27460.29345999999
[32m[0907 00-38-16 @MBExp.py:144][0m ####################################################################
[32m[0907 00-38-16 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 00-38-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08685, current rewards: -13.00000, mean: -1.30000
[32m[0907 00-38-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08711, current rewards: -16.15958, mean: -0.26933
[32m[0907 00-38-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08703, current rewards: -11.08948, mean: -0.10081
[32m[0907 00-38-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08708, current rewards: -6.01371, mean: -0.03759
[32m[0907 00-38-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08712, current rewards: -0.93511, mean: -0.00445
[32m[0907 00-38-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08714, current rewards: 4.13642, mean: 0.01591
[32m[0907 00-38-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08710, current rewards: 9.21442, mean: 0.02972
[32m[0907 00-38-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08704, current rewards: 14.05214, mean: 0.03903
[32m[0907 00-38-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08698, current rewards: 3.87410, mean: 0.00945
[32m[0907 00-38-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08697, current rewards: 8.52849, mean: 0.01854
[32m[0907 00-39-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08700, current rewards: 13.04971, mean: 0.02559
[32m[0907 00-39-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08688, current rewards: 17.56729, mean: 0.03137
[32m[0907 00-39-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08660, current rewards: 22.08162, mean: 0.03620
[32m[0907 00-39-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08640, current rewards: 26.59844, mean: 0.04030
[32m[0907 00-39-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08622, current rewards: 31.11117, mean: 0.04382
[32m[0907 00-39-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08606, current rewards: 35.62800, mean: 0.04688
[32m[0907 00-39-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08671, current rewards: -0.74403, mean: -0.00092
[32m[0907 00-39-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08693, current rewards: 3.92184, mean: 0.00456
[32m[0907 00-39-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08692, current rewards: 9.50842, mean: 0.01045
[32m[0907 00-39-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08695, current rewards: 15.09476, mean: 0.01572
[32m[0907 00-39-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08695, current rewards: 20.68050, mean: 0.02048
[32m[0907 00-39-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08695, current rewards: 26.26280, mean: 0.02478
[32m[0907 00-39-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08700, current rewards: 13.64778, mean: 0.01230
[32m[0907 00-39-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08701, current rewards: 19.21134, mean: 0.01656
[32m[0907 00-40-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08702, current rewards: 24.77674, mean: 0.02048
[32m[0907 00-40-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08702, current rewards: 30.25157, mean: 0.02401
[32m[0907 00-40-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08702, current rewards: 35.85542, mean: 0.02737
[32m[0907 00-40-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08703, current rewards: 41.45093, mean: 0.03048
[32m[0907 00-40-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08706, current rewards: 28.72311, mean: 0.02037
[32m[0907 00-40-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08716, current rewards: -21.49867, mean: -0.01473
[32m[0907 00-40-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08724, current rewards: -54.70112, mean: -0.03623
[32m[0907 00-40-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08723, current rewards: -48.86764, mean: -0.03133
[32m[0907 00-40-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08723, current rewards: -43.35577, mean: -0.02693
[32m[0907 00-40-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08722, current rewards: -37.90506, mean: -0.02283
[32m[0907 00-40-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08722, current rewards: -32.37238, mean: -0.01893
[32m[0907 00-40-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08721, current rewards: -26.83207, mean: -0.01525
[32m[0907 00-40-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08720, current rewards: -21.29301, mean: -0.01176
[32m[0907 00-40-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08720, current rewards: -15.75724, mean: -0.00847
[32m[0907 00-41-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08719, current rewards: -10.21699, mean: -0.00535
[32m[0907 00-41-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08719, current rewards: -4.67431, mean: -0.00238
[32m[0907 00-41-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08719, current rewards: 0.86767, mean: 0.00043
[32m[0907 00-41-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08718, current rewards: 6.33713, mean: 0.00308
[32m[0907 00-41-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08719, current rewards: 11.90835, mean: 0.00564
[32m[0907 00-41-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08718, current rewards: 17.47826, mean: 0.00809
[32m[0907 00-41-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08718, current rewards: 23.04564, mean: 0.01043
[32m[0907 00-41-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08717, current rewards: 17.66131, mean: 0.00781
[32m[0907 00-41-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08717, current rewards: 26.79166, mean: 0.01160
[32m[0907 00-41-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08717, current rewards: 35.91017, mean: 0.01522
[32m[0907 00-41-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08716, current rewards: 45.03533, mean: 0.01869
[32m[0907 00-41-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08716, current rewards: 54.26996, mean: 0.02206
[32m[0907 00-41-54 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0907 00-41-54 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-41-55 @MBExp.py:227][0m Rewards obtained: [61.52961944001969], Lows: [107], Highs: [12], Total time: 27678.94541499999
[32m[0907 00-45-12 @MBExp.py:144][0m ####################################################################
[32m[0907 00-45-12 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 00-45-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08560, current rewards: -5.80538, mean: -0.58054
[32m[0907 00-45-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08650, current rewards: -1.76065, mean: -0.02934
[32m[0907 00-45-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08671, current rewards: 3.78827, mean: 0.03444
[32m[0907 00-45-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08675, current rewards: 9.34048, mean: 0.05838
[32m[0907 00-45-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08678, current rewards: 14.89113, mean: 0.07091
[32m[0907 00-45-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08675, current rewards: 20.44123, mean: 0.07862
[32m[0907 00-45-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08678, current rewards: 25.99188, mean: 0.08384
[32m[0907 00-45-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08679, current rewards: 31.26989, mean: 0.08686
[32m[0907 00-45-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08680, current rewards: 28.88409, mean: 0.07045
[32m[0907 00-45-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08678, current rewards: 33.57741, mean: 0.07299
[32m[0907 00-45-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08671, current rewards: 38.28317, mean: 0.07507
[32m[0907 00-46-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08644, current rewards: 42.98686, mean: 0.07676
[32m[0907 00-46-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08622, current rewards: 47.69225, mean: 0.07818
[32m[0907 00-46-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08603, current rewards: 41.87991, mean: 0.06345
[32m[0907 00-46-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08585, current rewards: 46.56544, mean: 0.06559
[32m[0907 00-46-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08571, current rewards: 51.10535, mean: 0.06724
[32m[0907 00-46-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08564, current rewards: 55.50946, mean: 0.06853
[32m[0907 00-46-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08574, current rewards: 60.07642, mean: 0.06986
[32m[0907 00-46-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08583, current rewards: 64.64334, mean: 0.07104
[32m[0907 00-46-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08590, current rewards: 69.21347, mean: 0.07210
[32m[0907 00-46-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08593, current rewards: 73.77953, mean: 0.07305
[32m[0907 00-46-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08598, current rewards: 78.34715, mean: 0.07391
[32m[0907 00-46-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08602, current rewards: 82.91191, mean: 0.07470
[32m[0907 00-46-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08607, current rewards: 87.47649, mean: 0.07541
[32m[0907 00-46-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08612, current rewards: 92.57601, mean: 0.07651
[32m[0907 00-47-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08617, current rewards: 97.24917, mean: 0.07718
[32m[0907 00-47-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08621, current rewards: 101.92071, mean: 0.07780
[32m[0907 00-47-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08625, current rewards: 96.49942, mean: 0.07096
[32m[0907 00-47-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08627, current rewards: 101.74484, mean: 0.07216
[32m[0907 00-47-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08630, current rewards: 106.99309, mean: 0.07328
[32m[0907 00-47-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08633, current rewards: 112.23852, mean: 0.07433
[32m[0907 00-47-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08636, current rewards: 107.44351, mean: 0.06887
[32m[0907 00-47-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08638, current rewards: 112.64065, mean: 0.06996
[32m[0907 00-47-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08641, current rewards: 118.31468, mean: 0.07127
[32m[0907 00-47-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08642, current rewards: 123.98962, mean: 0.07251
[32m[0907 00-47-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08644, current rewards: 129.65843, mean: 0.07367
[32m[0907 00-47-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08645, current rewards: 135.32930, mean: 0.07477
[32m[0907 00-47-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08647, current rewards: 141.00273, mean: 0.07581
[32m[0907 00-47-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08647, current rewards: 146.66957, mean: 0.07679
[32m[0907 00-48-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08648, current rewards: 152.34203, mean: 0.07773
[32m[0907 00-48-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08649, current rewards: 158.05707, mean: 0.07864
[32m[0907 00-48-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08650, current rewards: 163.71369, mean: 0.07947
[32m[0907 00-48-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08651, current rewards: 169.36733, mean: 0.08027
[32m[0907 00-48-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08652, current rewards: 175.02274, mean: 0.08103
[32m[0907 00-48-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08654, current rewards: 159.80853, mean: 0.07231
[32m[0907 00-48-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08655, current rewards: 164.87294, mean: 0.07295
[32m[0907 00-48-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08655, current rewards: 169.94162, mean: 0.07357
[32m[0907 00-48-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08655, current rewards: 174.99843, mean: 0.07415
[32m[0907 00-48-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08656, current rewards: 180.20447, mean: 0.07477
[32m[0907 00-48-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08657, current rewards: 185.25538, mean: 0.07531
[32m[0907 00-48-49 @Agent.py:117][0m Average action selection time: 0.0866
[32m[0907 00-48-49 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-48-49 @MBExp.py:227][0m Rewards obtained: [189.28195112462026], Lows: [22], Highs: [19], Total time: 27896.13699499999
[32m[0907 00-52-08 @MBExp.py:144][0m ####################################################################
[32m[0907 00-52-08 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 00-52-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08968, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-52-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08708, current rewards: -76.13676, mean: -1.26895
[32m[0907 00-52-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08698, current rewards: -118.13254, mean: -1.07393
[32m[0907 00-52-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08702, current rewards: -185.03379, mean: -1.15646
[32m[0907 00-52-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08718, current rewards: -239.85481, mean: -1.14217
[32m[0907 00-52-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08741, current rewards: -310.67087, mean: -1.19489
[32m[0907 00-52-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08785, current rewards: -390.91558, mean: -1.26102
[32m[0907 00-52-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08808, current rewards: -455.07971, mean: -1.26411
[32m[0907 00-52-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08815, current rewards: -509.61331, mean: -1.24296
[32m[0907 00-52-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08801, current rewards: -586.74539, mean: -1.27553
[32m[0907 00-52-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08777, current rewards: -634.92901, mean: -1.24496
[32m[0907 00-52-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08763, current rewards: -718.51776, mean: -1.28307
[32m[0907 00-53-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08731, current rewards: -805.56926, mean: -1.32061
[32m[0907 00-53-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08708, current rewards: -836.67450, mean: -1.26769
[32m[0907 00-53-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08682, current rewards: -831.67801, mean: -1.17138
[32m[0907 00-53-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08661, current rewards: -826.67660, mean: -1.08773
[32m[0907 00-53-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08650, current rewards: -821.67219, mean: -1.01441
[32m[0907 00-53-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08654, current rewards: -816.66907, mean: -0.94962
[32m[0907 00-53-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08658, current rewards: -821.78168, mean: -0.90306
[32m[0907 00-53-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08660, current rewards: -816.68152, mean: -0.85071
[32m[0907 00-53-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08660, current rewards: -811.57828, mean: -0.80354
[32m[0907 00-53-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08664, current rewards: -806.47567, mean: -0.76083
[32m[0907 00-53-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08666, current rewards: -801.37442, mean: -0.72196
[32m[0907 00-53-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08669, current rewards: -796.36567, mean: -0.68652
[32m[0907 00-53-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08670, current rewards: -791.31117, mean: -0.65398
[32m[0907 00-53-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08672, current rewards: -786.25947, mean: -0.62402
[32m[0907 00-54-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08673, current rewards: -786.69983, mean: -0.60053
[32m[0907 00-54-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08674, current rewards: -781.73883, mean: -0.57481
[32m[0907 00-54-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08677, current rewards: -776.78768, mean: -0.55091
[32m[0907 00-54-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08678, current rewards: -771.83491, mean: -0.52865
[32m[0907 00-54-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08679, current rewards: -766.88582, mean: -0.50787
[32m[0907 00-54-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08681, current rewards: -774.16119, mean: -0.49626
[32m[0907 00-54-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08682, current rewards: -766.84924, mean: -0.47630
[32m[0907 00-54-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08682, current rewards: -759.78239, mean: -0.45770
[32m[0907 00-54-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08683, current rewards: -752.71581, mean: -0.44018
[32m[0907 00-54-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08684, current rewards: -745.64530, mean: -0.42366
[32m[0907 00-54-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08685, current rewards: -738.57903, mean: -0.40805
[32m[0907 00-54-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08686, current rewards: -731.50769, mean: -0.39328
[32m[0907 00-54-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08687, current rewards: -724.43370, mean: -0.37928
[32m[0907 00-54-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08688, current rewards: -717.41300, mean: -0.36603
[32m[0907 00-55-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08688, current rewards: -710.36566, mean: -0.35342
[32m[0907 00-55-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08688, current rewards: -703.31352, mean: -0.34141
[32m[0907 00-55-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08688, current rewards: -696.26606, mean: -0.32998
[32m[0907 00-55-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08688, current rewards: -741.95749, mean: -0.34350
[32m[0907 00-55-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08688, current rewards: -818.32410, mean: -0.37028
[32m[0907 00-55-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08688, current rewards: -889.02416, mean: -0.39337
[32m[0907 00-55-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08693, current rewards: -928.13204, mean: -0.40179
[32m[0907 00-55-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08697, current rewards: -1003.30310, mean: -0.42513
[32m[0907 00-55-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08697, current rewards: -1086.48380, mean: -0.45082
[32m[0907 00-55-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08697, current rewards: -1158.20887, mean: -0.47082
[32m[0907 00-55-46 @Agent.py:117][0m Average action selection time: 0.0870
[32m[0907 00-55-46 @Agent.py:118][0m Rollout length: 2505
[32m[0907 00-55-46 @MBExp.py:227][0m Rewards obtained: [-1156.1412762914135], Lows: [704], Highs: [33], Total time: 28114.31031799999
[32m[0907 00-59-07 @MBExp.py:144][0m ####################################################################
[32m[0907 00-59-07 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 00-59-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08561, current rewards: -1.55178, mean: -0.15518
[32m[0907 00-59-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08680, current rewards: 6.15343, mean: 0.10256
[32m[0907 00-59-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08693, current rewards: 15.22478, mean: 0.13841
[32m[0907 00-59-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08690, current rewards: 24.29746, mean: 0.15186
[32m[0907 00-59-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08687, current rewards: 33.37143, mean: 0.15891
[32m[0907 00-59-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08711, current rewards: 15.07355, mean: 0.05798
[32m[0907 00-59-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08832, current rewards: -11.43283, mean: -0.03688
[32m[0907 00-59-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08854, current rewards: -34.10518, mean: -0.09474
[32m[0907 00-59-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08857, current rewards: -52.81115, mean: -0.12881
[32m[0907 00-59-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08852, current rewards: -72.79899, mean: -0.15826
[32m[0907 00-59-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08820, current rewards: -98.19450, mean: -0.19254
[32m[0907 00-59-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08824, current rewards: -118.87411, mean: -0.21228
[32m[0907 01-00-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08801, current rewards: -151.90502, mean: -0.24902
[32m[0907 01-00-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08792, current rewards: -177.42567, mean: -0.26883
[32m[0907 01-00-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08793, current rewards: -214.50169, mean: -0.30212
[32m[0907 01-00-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08836, current rewards: -257.17985, mean: -0.33839
[32m[0907 01-00-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08827, current rewards: -291.11984, mean: -0.35941
[32m[0907 01-00-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08817, current rewards: -333.45603, mean: -0.38774
[32m[0907 01-00-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08854, current rewards: -383.29890, mean: -0.42121
[32m[0907 01-00-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08868, current rewards: -419.65585, mean: -0.43714
[32m[0907 01-00-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08889, current rewards: -457.83747, mean: -0.45330
[32m[0907 01-00-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08901, current rewards: -507.50928, mean: -0.47878
[32m[0907 01-00-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08915, current rewards: -550.79745, mean: -0.49621
[32m[0907 01-00-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08926, current rewards: -578.88422, mean: -0.49904
[32m[0907 01-00-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08922, current rewards: -609.77002, mean: -0.50394
[32m[0907 01-01-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08937, current rewards: -633.30749, mean: -0.50262
[32m[0907 01-01-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08941, current rewards: -657.04683, mean: -0.50156
[32m[0907 01-01-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08933, current rewards: -690.76128, mean: -0.50791
[32m[0907 01-01-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08942, current rewards: -720.12651, mean: -0.51073
[32m[0907 01-01-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08954, current rewards: -752.62525, mean: -0.51550
[32m[0907 01-01-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08969, current rewards: -782.85332, mean: -0.51845
[32m[0907 01-01-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08968, current rewards: -826.30027, mean: -0.52968
[32m[0907 01-01-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08960, current rewards: -876.30027, mean: -0.54429
[32m[0907 01-01-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08954, current rewards: -926.30027, mean: -0.55801
[32m[0907 01-01-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08946, current rewards: -976.30027, mean: -0.57094
[32m[0907 01-01-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08940, current rewards: -1026.30027, mean: -0.58313
[32m[0907 01-01-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08934, current rewards: -1076.30027, mean: -0.59464
[32m[0907 01-01-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08926, current rewards: -1126.30027, mean: -0.60554
[32m[0907 01-01-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08921, current rewards: -1176.30027, mean: -0.61586
[32m[0907 01-02-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08915, current rewards: -1226.30027, mean: -0.62566
[32m[0907 01-02-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08910, current rewards: -1276.30027, mean: -0.63498
[32m[0907 01-02-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08905, current rewards: -1326.30027, mean: -0.64384
[32m[0907 01-02-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08900, current rewards: -1376.30027, mean: -0.65228
[32m[0907 01-02-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08896, current rewards: -1426.30027, mean: -0.66032
[32m[0907 01-02-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08891, current rewards: -1476.30027, mean: -0.66801
[32m[0907 01-02-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08887, current rewards: -1526.30027, mean: -0.67535
[32m[0907 01-02-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08882, current rewards: -1576.30027, mean: -0.68238
[32m[0907 01-02-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08879, current rewards: -1626.30027, mean: -0.68911
[32m[0907 01-02-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08875, current rewards: -1676.30027, mean: -0.69556
[32m[0907 01-02-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08872, current rewards: -1726.30027, mean: -0.70175
[32m[0907 01-02-49 @Agent.py:117][0m Average action selection time: 0.0887
[32m[0907 01-02-49 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-02-49 @MBExp.py:227][0m Rewards obtained: [-1766.300269088089], Lows: [215], Highs: [1446], Total time: 28336.80924799999
[32m[0907 01-06-12 @MBExp.py:144][0m ####################################################################
[32m[0907 01-06-12 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 01-06-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09142, current rewards: -10.76333, mean: -1.07633
[32m[0907 01-06-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08857, current rewards: -57.60492, mean: -0.96008
[32m[0907 01-06-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08867, current rewards: -105.49913, mean: -0.95908
[32m[0907 01-06-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08819, current rewards: -153.37092, mean: -0.95857
[32m[0907 01-06-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08793, current rewards: -202.32025, mean: -0.96343
[32m[0907 01-06-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08781, current rewards: -251.26190, mean: -0.96639
[32m[0907 01-06-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08783, current rewards: -300.20512, mean: -0.96840
[32m[0907 01-06-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08768, current rewards: -349.15567, mean: -0.96988
[32m[0907 01-06-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08774, current rewards: -398.10431, mean: -0.97099
[32m[0907 01-06-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08723, current rewards: -448.10431, mean: -0.97414
[32m[0907 01-06-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08701, current rewards: -497.03370, mean: -0.97458
[32m[0907 01-07-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08676, current rewards: -547.03370, mean: -0.97685
[32m[0907 01-07-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08650, current rewards: -594.92094, mean: -0.97528
[32m[0907 01-07-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08625, current rewards: -641.76272, mean: -0.97237
[32m[0907 01-07-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08613, current rewards: -687.18590, mean: -0.96787
[32m[0907 01-07-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08603, current rewards: -737.18590, mean: -0.96998
[32m[0907 01-07-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08597, current rewards: -787.18590, mean: -0.97183
[32m[0907 01-07-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08591, current rewards: -837.18590, mean: -0.97347
[32m[0907 01-07-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08582, current rewards: -887.18590, mean: -0.97493
[32m[0907 01-07-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08578, current rewards: -936.13787, mean: -0.97514
[32m[0907 01-07-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08572, current rewards: -985.08555, mean: -0.97533
[32m[0907 01-07-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08569, current rewards: -1035.08555, mean: -0.97650
[32m[0907 01-07-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08568, current rewards: -1085.08555, mean: -0.97755
[32m[0907 01-07-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08591, current rewards: -1125.55660, mean: -0.97031
[32m[0907 01-07-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08596, current rewards: -1167.10466, mean: -0.96455
[32m[0907 01-08-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08607, current rewards: -1208.03724, mean: -0.95876
[32m[0907 01-08-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08616, current rewards: -1250.52582, mean: -0.95460
[32m[0907 01-08-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08619, current rewards: -1294.04744, mean: -0.95151
[32m[0907 01-08-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08649, current rewards: -1344.57731, mean: -0.95360
[32m[0907 01-08-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08689, current rewards: -1394.94781, mean: -0.95544
[32m[0907 01-08-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08717, current rewards: -1443.76679, mean: -0.95614
[32m[0907 01-08-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08729, current rewards: -1496.01142, mean: -0.95898
[32m[0907 01-08-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08744, current rewards: -1553.38439, mean: -0.96484
[32m[0907 01-08-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08744, current rewards: -1603.38439, mean: -0.96589
[32m[0907 01-08-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08742, current rewards: -1653.38439, mean: -0.96689
[32m[0907 01-08-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08742, current rewards: -1703.38439, mean: -0.96783
[32m[0907 01-08-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08741, current rewards: -1753.38439, mean: -0.96872
[32m[0907 01-08-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08740, current rewards: -1803.38439, mean: -0.96956
[32m[0907 01-08-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08740, current rewards: -1853.38439, mean: -0.97036
[32m[0907 01-09-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08739, current rewards: -1903.38439, mean: -0.97111
[32m[0907 01-09-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08763, current rewards: -1960.13655, mean: -0.97519
[32m[0907 01-09-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08772, current rewards: -1999.78038, mean: -0.97077
[32m[0907 01-09-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08770, current rewards: -1989.75678, mean: -0.94301
[32m[0907 01-09-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08769, current rewards: -1979.83373, mean: -0.91659
[32m[0907 01-09-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08768, current rewards: -1969.65552, mean: -0.89125
[32m[0907 01-09-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08767, current rewards: -1959.59327, mean: -0.86708
[32m[0907 01-09-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08765, current rewards: -1949.67119, mean: -0.84401
[32m[0907 01-09-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08764, current rewards: -1939.82675, mean: -0.82196
[32m[0907 01-09-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08763, current rewards: -1946.85178, mean: -0.80782
[32m[0907 01-09-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08763, current rewards: -1996.85178, mean: -0.81173
[32m[0907 01-09-51 @Agent.py:117][0m Average action selection time: 0.0876
[32m[0907 01-09-51 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-09-52 @MBExp.py:227][0m Rewards obtained: [-2036.8517764948565], Lows: [75], Highs: [1965], Total time: 28556.61803999999
[32m[0907 01-13-17 @MBExp.py:144][0m ####################################################################
[32m[0907 01-13-17 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 01-13-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08694, current rewards: -9.72134, mean: -0.97213
[32m[0907 01-13-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08978, current rewards: -82.39397, mean: -1.37323
[32m[0907 01-13-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08857, current rewards: -128.82342, mean: -1.17112
[32m[0907 01-13-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08797, current rewards: -178.82342, mean: -1.11765
[32m[0907 01-13-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08897, current rewards: -218.90214, mean: -1.04239
[32m[0907 01-13-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08855, current rewards: -268.90214, mean: -1.03424
[32m[0907 01-13-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08826, current rewards: -317.85416, mean: -1.02534
[32m[0907 01-13-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08826, current rewards: -340.19006, mean: -0.94497
[32m[0907 01-13-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08815, current rewards: -358.53243, mean: -0.87447
[32m[0907 01-13-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08775, current rewards: -368.56901, mean: -0.80124
[32m[0907 01-14-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08762, current rewards: -395.60093, mean: -0.77569
[32m[0907 01-14-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08753, current rewards: -419.94767, mean: -0.74991
[32m[0907 01-14-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08742, current rewards: -462.49869, mean: -0.75819
[32m[0907 01-14-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08714, current rewards: -502.88266, mean: -0.76194
[32m[0907 01-14-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08703, current rewards: -529.47100, mean: -0.74573
[32m[0907 01-14-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08692, current rewards: -558.48808, mean: -0.73485
[32m[0907 01-14-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08699, current rewards: -584.76162, mean: -0.72193
[32m[0907 01-14-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08690, current rewards: -609.70866, mean: -0.70896
[32m[0907 01-14-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08685, current rewards: -638.81131, mean: -0.70199
[32m[0907 01-14-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08677, current rewards: -680.38376, mean: -0.70873
[32m[0907 01-14-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08691, current rewards: -720.78682, mean: -0.71365
[32m[0907 01-14-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08722, current rewards: -745.80502, mean: -0.70359
[32m[0907 01-14-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08736, current rewards: -803.85780, mean: -0.72420
[32m[0907 01-14-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08765, current rewards: -848.61888, mean: -0.73157
[32m[0907 01-15-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08789, current rewards: -900.53498, mean: -0.74424
[32m[0907 01-15-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08803, current rewards: -960.09618, mean: -0.76198
[32m[0907 01-15-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08834, current rewards: -1009.85309, mean: -0.77088
[32m[0907 01-15-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08874, current rewards: -1067.81214, mean: -0.78516
[32m[0907 01-15-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08889, current rewards: -1125.58147, mean: -0.79828
[32m[0907 01-15-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08907, current rewards: -1183.02874, mean: -0.81029
[32m[0907 01-15-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08930, current rewards: -1235.86877, mean: -0.81846
[32m[0907 01-15-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08940, current rewards: -1282.07623, mean: -0.82184
[32m[0907 01-15-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08974, current rewards: -1330.89350, mean: -0.82664
[32m[0907 01-15-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08967, current rewards: -1424.44501, mean: -0.85810
[32m[0907 01-15-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08960, current rewards: -1524.44501, mean: -0.89149
[32m[0907 01-15-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08950, current rewards: -1624.44501, mean: -0.92298
[32m[0907 01-15-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08944, current rewards: -1724.44501, mean: -0.95273
[32m[0907 01-16-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08938, current rewards: -1824.44501, mean: -0.98088
[32m[0907 01-16-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08931, current rewards: -1924.44501, mean: -1.00756
[32m[0907 01-16-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08925, current rewards: -2024.44501, mean: -1.03288
[32m[0907 01-16-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08920, current rewards: -2124.44501, mean: -1.05694
[32m[0907 01-16-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08916, current rewards: -2224.44501, mean: -1.07983
[32m[0907 01-16-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08910, current rewards: -2324.44501, mean: -1.10163
[32m[0907 01-16-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08905, current rewards: -2424.44501, mean: -1.12243
[32m[0907 01-16-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08900, current rewards: -2524.44501, mean: -1.14228
[32m[0907 01-16-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08895, current rewards: -2624.44501, mean: -1.16126
[32m[0907 01-16-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08892, current rewards: -2724.44501, mean: -1.17941
[32m[0907 01-16-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08888, current rewards: -2824.44501, mean: -1.19680
[32m[0907 01-16-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08884, current rewards: -2924.44501, mean: -1.21346
[32m[0907 01-16-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08881, current rewards: -3024.44501, mean: -1.22945
[32m[0907 01-17-00 @Agent.py:117][0m Average action selection time: 0.0888
[32m[0907 01-17-00 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-17-00 @MBExp.py:227][0m Rewards obtained: [-3104.4450135615416], Lows: [1286], Highs: [612], Total time: 28779.33303299999
[32m[0907 01-20-26 @MBExp.py:144][0m ####################################################################
[32m[0907 01-20-26 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 01-20-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10902, current rewards: -15.00000, mean: -1.50000
[32m[0907 01-20-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09254, current rewards: -74.68400, mean: -1.24473
[32m[0907 01-20-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09020, current rewards: -124.68400, mean: -1.13349
[32m[0907 01-20-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08918, current rewards: -174.68400, mean: -1.09178
[32m[0907 01-20-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08863, current rewards: -224.68400, mean: -1.06992
[32m[0907 01-20-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08836, current rewards: -274.68400, mean: -1.05648
[32m[0907 01-20-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08793, current rewards: -324.68400, mean: -1.04737
[32m[0907 01-20-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08724, current rewards: -374.68400, mean: -1.04079
[32m[0907 01-21-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08678, current rewards: -424.68400, mean: -1.03581
[32m[0907 01-21-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08640, current rewards: -474.68400, mean: -1.03192
[32m[0907 01-21-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08616, current rewards: -524.68400, mean: -1.02879
[32m[0907 01-21-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08592, current rewards: -574.68400, mean: -1.02622
[32m[0907 01-21-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08573, current rewards: -624.68400, mean: -1.02407
[32m[0907 01-21-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08556, current rewards: -674.68400, mean: -1.02225
[32m[0907 01-21-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08540, current rewards: -724.68400, mean: -1.02068
[32m[0907 01-21-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08529, current rewards: -774.68400, mean: -1.01932
[32m[0907 01-21-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08515, current rewards: -824.68400, mean: -1.01813
[32m[0907 01-21-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08506, current rewards: -874.68400, mean: -1.01707
[32m[0907 01-21-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08499, current rewards: -924.68400, mean: -1.01614
[32m[0907 01-21-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08498, current rewards: -963.82167, mean: -1.00398
[32m[0907 01-21-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08498, current rewards: -959.50999, mean: -0.95001
[32m[0907 01-21-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08497, current rewards: -955.19830, mean: -0.90113
[32m[0907 01-22-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08498, current rewards: -950.88662, mean: -0.85665
[32m[0907 01-22-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08499, current rewards: -944.74592, mean: -0.81444
[32m[0907 01-22-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08508, current rewards: -938.28709, mean: -0.77544
[32m[0907 01-22-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08516, current rewards: -931.82827, mean: -0.73955
[32m[0907 01-22-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08522, current rewards: -970.53650, mean: -0.74087
[32m[0907 01-22-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08529, current rewards: -1020.53650, mean: -0.75039
[32m[0907 01-22-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08536, current rewards: -1070.53650, mean: -0.75925
[32m[0907 01-22-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08542, current rewards: -1120.53650, mean: -0.76749
[32m[0907 01-22-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08549, current rewards: -1170.53650, mean: -0.77519
[32m[0907 01-22-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08554, current rewards: -1220.53650, mean: -0.78240
[32m[0907 01-22-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08558, current rewards: -1270.53650, mean: -0.78915
[32m[0907 01-22-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08563, current rewards: -1320.53650, mean: -0.79550
[32m[0907 01-22-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08567, current rewards: -1370.53650, mean: -0.80148
[32m[0907 01-22-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08572, current rewards: -1420.53650, mean: -0.80712
[32m[0907 01-23-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08575, current rewards: -1470.53650, mean: -0.81245
[32m[0907 01-23-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08579, current rewards: -1520.53650, mean: -0.81749
[32m[0907 01-23-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08582, current rewards: -1570.53650, mean: -0.82227
[32m[0907 01-23-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08585, current rewards: -1620.53650, mean: -0.82680
[32m[0907 01-23-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08588, current rewards: -1670.53650, mean: -0.83111
[32m[0907 01-23-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08592, current rewards: -1720.53650, mean: -0.83521
[32m[0907 01-23-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08594, current rewards: -1770.53650, mean: -0.83912
[32m[0907 01-23-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08597, current rewards: -1820.53650, mean: -0.84284
[32m[0907 01-23-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08599, current rewards: -1870.53650, mean: -0.84640
[32m[0907 01-23-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08600, current rewards: -1920.53650, mean: -0.84979
[32m[0907 01-23-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08603, current rewards: -1970.53650, mean: -0.85305
[32m[0907 01-23-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08605, current rewards: -2020.53650, mean: -0.85616
[32m[0907 01-23-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08608, current rewards: -2070.53650, mean: -0.85914
[32m[0907 01-23-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08610, current rewards: -2120.53650, mean: -0.86201
[32m[0907 01-24-02 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 01-24-02 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-24-02 @MBExp.py:227][0m Rewards obtained: [-2160.5365049925895], Lows: [16], Highs: [2163], Total time: 28995.38927899999
[32m[0907 01-27-31 @MBExp.py:144][0m ####################################################################
[32m[0907 01-27-31 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 01-27-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09695, current rewards: -12.89051, mean: -1.28905
[32m[0907 01-27-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08868, current rewards: -112.89051, mean: -1.88151
[32m[0907 01-27-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08788, current rewards: -212.89051, mean: -1.93537
[32m[0907 01-27-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08752, current rewards: -312.89051, mean: -1.95557
[32m[0907 01-27-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08730, current rewards: -412.89051, mean: -1.96615
[32m[0907 01-27-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08727, current rewards: -512.89051, mean: -1.97266
[32m[0907 01-27-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08704, current rewards: -602.89051, mean: -1.94481
[32m[0907 01-28-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08659, current rewards: -700.89051, mean: -1.94692
[32m[0907 01-28-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08626, current rewards: -800.89051, mean: -1.95339
[32m[0907 01-28-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08589, current rewards: -900.89051, mean: -1.95846
[32m[0907 01-28-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08569, current rewards: -1000.89051, mean: -1.96253
[32m[0907 01-28-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08547, current rewards: -1100.89051, mean: -1.96588
[32m[0907 01-28-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08530, current rewards: -1200.89051, mean: -1.96867
[32m[0907 01-28-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08516, current rewards: -1300.89051, mean: -1.97105
[32m[0907 01-28-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08503, current rewards: -1400.89051, mean: -1.97309
[32m[0907 01-28-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08491, current rewards: -1500.89051, mean: -1.97486
[32m[0907 01-28-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08483, current rewards: -1600.89051, mean: -1.97641
[32m[0907 01-28-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08476, current rewards: -1700.89051, mean: -1.97778
[32m[0907 01-28-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08467, current rewards: -1800.89051, mean: -1.97900
[32m[0907 01-28-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08465, current rewards: -1900.89051, mean: -1.98009
[32m[0907 01-28-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08466, current rewards: -2000.89051, mean: -1.98108
[32m[0907 01-29-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08466, current rewards: -2100.89051, mean: -1.98197
[32m[0907 01-29-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08467, current rewards: -2200.89051, mean: -1.98278
[32m[0907 01-29-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08467, current rewards: -2300.89051, mean: -1.98353
[32m[0907 01-29-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08477, current rewards: -2400.89051, mean: -1.98421
[32m[0907 01-29-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08486, current rewards: -2500.89051, mean: -1.98483
[32m[0907 01-29-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08494, current rewards: -2600.89051, mean: -1.98541
[32m[0907 01-29-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08502, current rewards: -2700.89051, mean: -1.98595
[32m[0907 01-29-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08510, current rewards: -2800.89051, mean: -1.98645
[32m[0907 01-29-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08516, current rewards: -2900.89051, mean: -1.98691
[32m[0907 01-29-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08523, current rewards: -3000.89051, mean: -1.98734
[32m[0907 01-29-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08531, current rewards: -3100.89051, mean: -1.98775
[32m[0907 01-29-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08536, current rewards: -3200.89051, mean: -1.98813
[32m[0907 01-29-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08542, current rewards: -3300.89051, mean: -1.98849
[32m[0907 01-29-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08547, current rewards: -3400.89051, mean: -1.98882
[32m[0907 01-30-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08551, current rewards: -3500.89051, mean: -1.98914
[32m[0907 01-30-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08555, current rewards: -3600.89051, mean: -1.98944
[32m[0907 01-30-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08559, current rewards: -3700.89051, mean: -1.98973
[32m[0907 01-30-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08563, current rewards: -3800.89051, mean: -1.99000
[32m[0907 01-30-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08567, current rewards: -3900.89051, mean: -1.99025
[32m[0907 01-30-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08571, current rewards: -4000.89051, mean: -1.99049
[32m[0907 01-30-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08574, current rewards: -4100.89051, mean: -1.99072
[32m[0907 01-30-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08577, current rewards: -4200.89051, mean: -1.99094
[32m[0907 01-30-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08581, current rewards: -4300.89051, mean: -1.99115
[32m[0907 01-30-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08584, current rewards: -4400.89051, mean: -1.99135
[32m[0907 01-30-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08586, current rewards: -4500.89051, mean: -1.99154
[32m[0907 01-30-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08589, current rewards: -4600.89051, mean: -1.99173
[32m[0907 01-30-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08591, current rewards: -4700.89051, mean: -1.99190
[32m[0907 01-30-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08594, current rewards: -4800.89051, mean: -1.99207
[32m[0907 01-31-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08596, current rewards: -4900.89051, mean: -1.99223
[32m[0907 01-31-07 @Agent.py:117][0m Average action selection time: 0.0860
[32m[0907 01-31-07 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-31-07 @MBExp.py:227][0m Rewards obtained: [-4980.8905087424755], Lows: [2482], Highs: [17], Total time: 29211.11109999999
[32m[0907 01-34-38 @MBExp.py:144][0m ####################################################################
[32m[0907 01-34-38 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 01-34-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09146, current rewards: -8.92511, mean: -0.89251
[32m[0907 01-34-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09972, current rewards: -72.17560, mean: -1.20293
[32m[0907 01-34-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09381, current rewards: -172.17560, mean: -1.56523
[32m[0907 01-34-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09160, current rewards: -272.17560, mean: -1.70110
[32m[0907 01-34-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09048, current rewards: -372.17560, mean: -1.77226
[32m[0907 01-35-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08985, current rewards: -472.17560, mean: -1.81606
[32m[0907 01-35-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08882, current rewards: -572.17560, mean: -1.84573
[32m[0907 01-35-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08812, current rewards: -672.17560, mean: -1.86715
[32m[0907 01-35-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08759, current rewards: -772.17560, mean: -1.88336
[32m[0907 01-35-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08719, current rewards: -872.17560, mean: -1.89603
[32m[0907 01-35-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08686, current rewards: -972.17560, mean: -1.90623
[32m[0907 01-35-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08659, current rewards: -1072.17560, mean: -1.91460
[32m[0907 01-35-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08634, current rewards: -1172.17560, mean: -1.92160
[32m[0907 01-35-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08612, current rewards: -1272.17560, mean: -1.92754
[32m[0907 01-35-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08593, current rewards: -1372.17560, mean: -1.93264
[32m[0907 01-35-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08578, current rewards: -1472.17560, mean: -1.93707
[32m[0907 01-35-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08562, current rewards: -1572.17560, mean: -1.94096
[32m[0907 01-35-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08550, current rewards: -1672.17560, mean: -1.94439
[32m[0907 01-35-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08539, current rewards: -1772.17560, mean: -1.94745
[32m[0907 01-36-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08529, current rewards: -1872.17560, mean: -1.95018
[32m[0907 01-36-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08521, current rewards: -1972.17560, mean: -1.95265
[32m[0907 01-36-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08513, current rewards: -2072.17560, mean: -1.95488
[32m[0907 01-36-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08512, current rewards: -2172.17560, mean: -1.95691
[32m[0907 01-36-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08511, current rewards: -2272.17560, mean: -1.95877
[32m[0907 01-36-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08514, current rewards: -2372.17560, mean: -1.96048
[32m[0907 01-36-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08522, current rewards: -2472.17560, mean: -1.96204
[32m[0907 01-36-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08529, current rewards: -2572.17560, mean: -1.96349
[32m[0907 01-36-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08535, current rewards: -2672.17560, mean: -1.96484
[32m[0907 01-36-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08540, current rewards: -2772.17560, mean: -1.96608
[32m[0907 01-36-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08546, current rewards: -2872.17560, mean: -1.96724
[32m[0907 01-36-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08552, current rewards: -2972.17560, mean: -1.96833
[32m[0907 01-36-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08557, current rewards: -3072.17560, mean: -1.96934
[32m[0907 01-36-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08561, current rewards: -3172.17560, mean: -1.97030
[32m[0907 01-37-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08566, current rewards: -3272.17560, mean: -1.97119
[32m[0907 01-37-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08570, current rewards: -3372.17560, mean: -1.97203
[32m[0907 01-37-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08575, current rewards: -3472.17560, mean: -1.97283
[32m[0907 01-37-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08578, current rewards: -3572.17560, mean: -1.97358
[32m[0907 01-37-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08582, current rewards: -3672.17560, mean: -1.97429
[32m[0907 01-37-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08585, current rewards: -3772.17560, mean: -1.97496
[32m[0907 01-37-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08589, current rewards: -3872.17560, mean: -1.97560
[32m[0907 01-37-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08592, current rewards: -3972.17560, mean: -1.97621
[32m[0907 01-37-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08594, current rewards: -4072.17560, mean: -1.97678
[32m[0907 01-37-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08598, current rewards: -4172.17560, mean: -1.97733
[32m[0907 01-37-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08600, current rewards: -4272.17560, mean: -1.97786
[32m[0907 01-37-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08603, current rewards: -4372.17560, mean: -1.97836
[32m[0907 01-37-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08605, current rewards: -4472.17560, mean: -1.97884
[32m[0907 01-37-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08607, current rewards: -4572.17560, mean: -1.97930
[32m[0907 01-38-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08609, current rewards: -4672.17560, mean: -1.97974
[32m[0907 01-38-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08610, current rewards: -4772.17560, mean: -1.98016
[32m[0907 01-38-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08612, current rewards: -4872.17560, mean: -1.98056
[32m[0907 01-38-13 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 01-38-13 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-38-14 @MBExp.py:227][0m Rewards obtained: [-4952.175601912602], Lows: [2464], Highs: [26], Total time: 29427.19920799999
[32m[0907 01-41-46 @MBExp.py:144][0m ####################################################################
[32m[0907 01-41-46 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 01-41-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.11474, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-41-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10290, current rewards: -63.54372, mean: -1.05906
[32m[0907 01-41-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10470, current rewards: -105.31178, mean: -0.95738
[32m[0907 01-42-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10460, current rewards: -164.12032, mean: -1.02575
[32m[0907 01-42-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10562, current rewards: -199.72467, mean: -0.95107
[32m[0907 01-42-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10620, current rewards: -239.68760, mean: -0.92188
[32m[0907 01-42-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10252, current rewards: -287.51346, mean: -0.92746
[32m[0907 01-42-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10023, current rewards: -336.46459, mean: -0.93462
[32m[0907 01-42-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10309, current rewards: -389.85761, mean: -0.95087
[32m[0907 01-42-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10476, current rewards: -443.75046, mean: -0.96467
[32m[0907 01-42-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10595, current rewards: -490.00519, mean: -0.96079
[32m[0907 01-42-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.10622, current rewards: -550.77868, mean: -0.98353
[32m[0907 01-42-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.10697, current rewards: -589.69344, mean: -0.96671
[32m[0907 01-42-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.10710, current rewards: -642.95441, mean: -0.97417
[32m[0907 01-43-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.10542, current rewards: -701.89308, mean: -0.98858
[32m[0907 01-43-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.10397, current rewards: -751.89308, mean: -0.98933
[32m[0907 01-43-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.10270, current rewards: -801.89308, mean: -0.98999
[32m[0907 01-43-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.10159, current rewards: -851.89308, mean: -0.99057
[32m[0907 01-43-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.10059, current rewards: -901.89308, mean: -0.99109
[32m[0907 01-43-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09976, current rewards: -951.89308, mean: -0.99156
[32m[0907 01-43-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09901, current rewards: -1001.89308, mean: -0.99197
[32m[0907 01-43-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09840, current rewards: -1051.89308, mean: -0.99235
[32m[0907 01-43-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09790, current rewards: -1088.23411, mean: -0.98039
[32m[0907 01-43-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09745, current rewards: -1085.72052, mean: -0.93597
[32m[0907 01-43-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09702, current rewards: -1083.20759, mean: -0.89521
[32m[0907 01-43-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09662, current rewards: -1080.70903, mean: -0.85771
[32m[0907 01-43-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09626, current rewards: -1078.21047, mean: -0.82306
[32m[0907 01-43-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09591, current rewards: -1075.68553, mean: -0.79095
[32m[0907 01-44-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09560, current rewards: -1073.18599, mean: -0.76112
[32m[0907 01-44-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09531, current rewards: -1070.68195, mean: -0.73334
[32m[0907 01-44-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09504, current rewards: -1067.23574, mean: -0.70678
[32m[0907 01-44-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09479, current rewards: -1082.04204, mean: -0.69362
[32m[0907 01-44-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09455, current rewards: -1132.04204, mean: -0.70313
[32m[0907 01-44-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09431, current rewards: -1182.04204, mean: -0.71207
[32m[0907 01-44-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09488, current rewards: -1237.44741, mean: -0.72365
[32m[0907 01-44-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09558, current rewards: -1269.83194, mean: -0.72150
[32m[0907 01-44-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09556, current rewards: -1277.60555, mean: -0.70586
[32m[0907 01-44-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09534, current rewards: -1272.39575, mean: -0.68408
[32m[0907 01-44-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09538, current rewards: -1305.84411, mean: -0.68369
[32m[0907 01-44-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09581, current rewards: -1353.72753, mean: -0.69068
[32m[0907 01-45-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09628, current rewards: -1410.34238, mean: -0.70166
[32m[0907 01-45-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09677, current rewards: -1459.02401, mean: -0.70826
[32m[0907 01-45-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09699, current rewards: -1505.54586, mean: -0.71353
[32m[0907 01-45-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09739, current rewards: -1556.76074, mean: -0.72072
[32m[0907 01-45-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09771, current rewards: -1604.96045, mean: -0.72623
[32m[0907 01-45-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09766, current rewards: -1644.96535, mean: -0.72786
[32m[0907 01-45-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09797, current rewards: -1690.53187, mean: -0.73183
[32m[0907 01-45-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09835, current rewards: -1749.19128, mean: -0.74118
[32m[0907 01-45-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09879, current rewards: -1782.12881, mean: -0.73947
[32m[0907 01-45-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09917, current rewards: -1826.45310, mean: -0.74246
[32m[0907 01-45-55 @Agent.py:117][0m Average action selection time: 0.0994
[32m[0907 01-45-55 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-45-56 @MBExp.py:227][0m Rewards obtained: [-1876.297515467768], Lows: [235], Highs: [1481], Total time: 29676.44808499999
[32m[0907 01-49-29 @MBExp.py:144][0m ####################################################################
[32m[0907 01-49-29 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 01-49-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08341, current rewards: -14.00000, mean: -1.40000
[32m[0907 01-49-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.08386, current rewards: -111.48049, mean: -1.85801
[32m[0907 01-49-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08382, current rewards: -211.48049, mean: -1.92255
[32m[0907 01-49-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.08383, current rewards: -311.48049, mean: -1.94675
[32m[0907 01-49-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.08377, current rewards: -411.48049, mean: -1.95943
[32m[0907 01-49-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.08365, current rewards: -511.48049, mean: -1.96723
[32m[0907 01-49-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08370, current rewards: -611.48049, mean: -1.97252
[32m[0907 01-49-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08367, current rewards: -711.48049, mean: -1.97633
[32m[0907 01-50-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08362, current rewards: -743.29265, mean: -1.81291
[32m[0907 01-50-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08353, current rewards: -737.87215, mean: -1.60407
[32m[0907 01-50-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08352, current rewards: -732.45163, mean: -1.43618
[32m[0907 01-50-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08353, current rewards: -727.02864, mean: -1.29827
[32m[0907 01-50-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08351, current rewards: -721.60492, mean: -1.18296
[32m[0907 01-50-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08353, current rewards: -716.52954, mean: -1.08565
[32m[0907 01-50-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08354, current rewards: -721.62290, mean: -1.01637
[32m[0907 01-50-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08353, current rewards: -707.56698, mean: -0.93101
[32m[0907 01-50-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08363, current rewards: -693.50645, mean: -0.85618
[32m[0907 01-50-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08372, current rewards: -683.07428, mean: -0.79427
[32m[0907 01-50-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08382, current rewards: -670.45392, mean: -0.73676
[32m[0907 01-50-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08401, current rewards: -658.95732, mean: -0.68641
[32m[0907 01-50-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08417, current rewards: -644.84112, mean: -0.63846
[32m[0907 01-50-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08432, current rewards: -633.15743, mean: -0.59732
[32m[0907 01-51-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08446, current rewards: -619.05909, mean: -0.55771
[32m[0907 01-51-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08457, current rewards: -611.37068, mean: -0.52704
[32m[0907 01-51-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08470, current rewards: -605.09736, mean: -0.50008
[32m[0907 01-51-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08480, current rewards: -608.87116, mean: -0.48323
[32m[0907 01-51-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08489, current rewards: -596.76348, mean: -0.45554
[32m[0907 01-51-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08499, current rewards: -584.18231, mean: -0.42955
[32m[0907 01-51-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08507, current rewards: -573.94804, mean: -0.40706
[32m[0907 01-51-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08514, current rewards: -573.18659, mean: -0.39259
[32m[0907 01-51-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08522, current rewards: -644.23263, mean: -0.42664
[32m[0907 01-51-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08528, current rewards: -744.23263, mean: -0.47707
[32m[0907 01-51-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08534, current rewards: -844.23263, mean: -0.52437
[32m[0907 01-51-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08540, current rewards: -944.23263, mean: -0.56881
[32m[0907 01-51-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08546, current rewards: -1044.23263, mean: -0.61066
[32m[0907 01-52-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08551, current rewards: -1144.23263, mean: -0.65013
[32m[0907 01-52-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08556, current rewards: -1244.23263, mean: -0.68742
[32m[0907 01-52-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08561, current rewards: -1344.23263, mean: -0.72271
[32m[0907 01-52-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08565, current rewards: -1380.87342, mean: -0.72297
[32m[0907 01-52-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08568, current rewards: -1460.63113, mean: -0.74522
[32m[0907 01-52-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08571, current rewards: -1506.41144, mean: -0.74946
[32m[0907 01-52-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08574, current rewards: -1549.24263, mean: -0.75206
[32m[0907 01-52-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08578, current rewards: -1593.36206, mean: -0.75515
[32m[0907 01-52-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08582, current rewards: -1637.31248, mean: -0.75802
[32m[0907 01-52-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08584, current rewards: -1681.55659, mean: -0.76089
[32m[0907 01-52-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08587, current rewards: -1725.22882, mean: -0.76338
[32m[0907 01-52-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08589, current rewards: -1768.97099, mean: -0.76579
[32m[0907 01-52-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08591, current rewards: -1811.71899, mean: -0.76768
[32m[0907 01-52-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08594, current rewards: -1855.50783, mean: -0.76992
[32m[0907 01-53-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08602, current rewards: -1898.99990, mean: -0.77195
[32m[0907 01-53-05 @Agent.py:117][0m Average action selection time: 0.0861
[32m[0907 01-53-05 @Agent.py:118][0m Rollout length: 2505
[32m[0907 01-53-05 @MBExp.py:227][0m Rewards obtained: [-1933.2964905415215], Lows: [1108], Highs: [16], Total time: 29892.51547199999
[32m[0907 01-56-41 @MBExp.py:144][0m ####################################################################
[32m[0907 01-56-41 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 01-56-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.08338, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-56-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09626, current rewards: -53.26439, mean: -0.88774
[32m[0907 01-56-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.09903, current rewards: -102.92599, mean: -0.93569
[32m[0907 01-56-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09915, current rewards: -144.41082, mean: -0.90257
[32m[0907 01-57-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10066, current rewards: -185.43520, mean: -0.88302
[32m[0907 01-57-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10052, current rewards: -218.84949, mean: -0.84173
[32m[0907 01-57-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.09932, current rewards: -267.68886, mean: -0.86351
[32m[0907 01-57-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.09878, current rewards: -310.56998, mean: -0.86269
[32m[0907 01-57-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.09835, current rewards: -361.62864, mean: -0.88202
[32m[0907 01-57-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.09787, current rewards: -413.22691, mean: -0.89832
[32m[0907 01-57-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.09718, current rewards: -463.22691, mean: -0.90829
[32m[0907 01-57-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.09709, current rewards: -513.61592, mean: -0.91717
[32m[0907 01-57-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.09724, current rewards: -558.31472, mean: -0.91527
[32m[0907 01-57-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.09722, current rewards: -607.25961, mean: -0.92009
[32m[0907 01-57-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.09693, current rewards: -651.75260, mean: -0.91796
[32m[0907 01-57-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.09705, current rewards: -703.27862, mean: -0.92537
[32m[0907 01-58-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.09711, current rewards: -760.93262, mean: -0.93942
[32m[0907 01-58-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.09787, current rewards: -804.10305, mean: -0.93500
[32m[0907 01-58-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.09796, current rewards: -855.36911, mean: -0.93997
[32m[0907 01-58-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.09739, current rewards: -905.56859, mean: -0.94330
[32m[0907 01-58-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.09687, current rewards: -955.56859, mean: -0.94611
[32m[0907 01-58-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.09642, current rewards: -1005.56859, mean: -0.94865
[32m[0907 01-58-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.09599, current rewards: -1019.53442, mean: -0.91850
[32m[0907 01-58-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.09560, current rewards: -1016.45710, mean: -0.87626
[32m[0907 01-58-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.09526, current rewards: -1013.37979, mean: -0.83750
[32m[0907 01-58-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.09493, current rewards: -1010.30247, mean: -0.80183
[32m[0907 01-58-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.09463, current rewards: -1007.22516, mean: -0.76887
[32m[0907 01-58-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.09435, current rewards: -1004.14784, mean: -0.73834
[32m[0907 01-58-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.09409, current rewards: -1001.07053, mean: -0.70998
[32m[0907 01-58-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.09385, current rewards: -1036.20888, mean: -0.70973
[32m[0907 01-59-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.09362, current rewards: -1086.20888, mean: -0.71934
[32m[0907 01-59-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.09340, current rewards: -1136.20888, mean: -0.72834
[32m[0907 01-59-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.09320, current rewards: -1186.20888, mean: -0.73678
[32m[0907 01-59-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.09302, current rewards: -1236.20888, mean: -0.74470
[32m[0907 01-59-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.09284, current rewards: -1286.20888, mean: -0.75217
[32m[0907 01-59-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.09268, current rewards: -1336.20888, mean: -0.75921
[32m[0907 01-59-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.09251, current rewards: -1386.20888, mean: -0.76586
[32m[0907 01-59-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.09237, current rewards: -1436.20888, mean: -0.77216
[32m[0907 01-59-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.09223, current rewards: -1486.20888, mean: -0.77812
[32m[0907 01-59-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.09209, current rewards: -1536.20888, mean: -0.78378
[32m[0907 01-59-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.09198, current rewards: -1586.20888, mean: -0.78916
[32m[0907 01-59-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.09186, current rewards: -1636.20888, mean: -0.79428
[32m[0907 01-59-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.09174, current rewards: -1686.20888, mean: -0.79915
[32m[0907 01-59-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.09163, current rewards: -1736.20888, mean: -0.80380
[32m[0907 02-00-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.09152, current rewards: -1786.20888, mean: -0.80824
[32m[0907 02-00-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.09142, current rewards: -1836.20888, mean: -0.81248
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.09134, current rewards: -1886.20888, mean: -0.81654
[32m[0907 02-00-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.09131, current rewards: -1936.20888, mean: -0.82043
[32m[0907 02-00-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.09129, current rewards: -1986.20888, mean: -0.82415
[32m[0907 02-00-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.09130, current rewards: -2036.20888, mean: -0.82773
[32m[0907 02-00-30 @Agent.py:117][0m Average action selection time: 0.0913
[32m[0907 02-00-30 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-00-30 @MBExp.py:227][0m Rewards obtained: [-2076.2088824926186], Lows: [82], Highs: [1948], Total time: 30121.58595099999
[32m[0907 02-04-07 @MBExp.py:144][0m ####################################################################
[32m[0907 02-04-07 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 02-04-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.09911, current rewards: -15.00000, mean: -1.50000
[32m[0907 02-04-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.09125, current rewards: -64.38912, mean: -1.07315
[32m[0907 02-04-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.08789, current rewards: -109.89191, mean: -0.99902
[32m[0907 02-04-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.09050, current rewards: -194.46410, mean: -1.21540
[32m[0907 02-04-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.09033, current rewards: -285.37796, mean: -1.35894
[32m[0907 02-04-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.09075, current rewards: -332.72516, mean: -1.27971
[32m[0907 02-04-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.08958, current rewards: -324.42504, mean: -1.04653
[32m[0907 02-04-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.08876, current rewards: -316.12492, mean: -0.87812
[32m[0907 02-04-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.08814, current rewards: -307.82480, mean: -0.75079
[32m[0907 02-04-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.08760, current rewards: -299.52468, mean: -0.65114
[32m[0907 02-04-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.08723, current rewards: -300.55258, mean: -0.58932
[32m[0907 02-04-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.08692, current rewards: -350.55258, mean: -0.62599
[32m[0907 02-05-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.08668, current rewards: -400.55258, mean: -0.65664
[32m[0907 02-05-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.08646, current rewards: -450.55258, mean: -0.68266
[32m[0907 02-05-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.08628, current rewards: -500.55258, mean: -0.70500
[32m[0907 02-05-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.08614, current rewards: -550.55258, mean: -0.72441
[32m[0907 02-05-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.08619, current rewards: -600.55258, mean: -0.74142
[32m[0907 02-05-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.08626, current rewards: -650.55258, mean: -0.75646
[32m[0907 02-05-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.08632, current rewards: -700.55258, mean: -0.76984
[32m[0907 02-05-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.08636, current rewards: -750.55258, mean: -0.78183
[32m[0907 02-05-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.08639, current rewards: -800.55258, mean: -0.79263
[32m[0907 02-05-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.08644, current rewards: -850.55258, mean: -0.80241
[32m[0907 02-05-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.08649, current rewards: -900.55258, mean: -0.81131
[32m[0907 02-05-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.08652, current rewards: -950.55258, mean: -0.81944
[32m[0907 02-05-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.08655, current rewards: -1000.55258, mean: -0.82690
[32m[0907 02-05-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.08656, current rewards: -1050.55258, mean: -0.83377
[32m[0907 02-06-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.08658, current rewards: -1100.55258, mean: -0.84012
[32m[0907 02-06-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.08662, current rewards: -1150.55258, mean: -0.84599
[32m[0907 02-06-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.08664, current rewards: -1200.55258, mean: -0.85146
[32m[0907 02-06-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.08666, current rewards: -1250.55258, mean: -0.85654
[32m[0907 02-06-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.08667, current rewards: -1275.37768, mean: -0.84462
[32m[0907 02-06-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.08669, current rewards: -1272.92998, mean: -0.81598
[32m[0907 02-06-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.08671, current rewards: -1270.48227, mean: -0.78912
[32m[0907 02-06-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.08672, current rewards: -1268.03457, mean: -0.76388
[32m[0907 02-06-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.08674, current rewards: -1312.78980, mean: -0.76771
[32m[0907 02-06-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.08676, current rewards: -1362.78980, mean: -0.77431
[32m[0907 02-06-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.08677, current rewards: -1412.78980, mean: -0.78055
[32m[0907 02-06-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.08678, current rewards: -1462.78980, mean: -0.78645
[32m[0907 02-06-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.08679, current rewards: -1512.78980, mean: -0.79204
[32m[0907 02-06-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.08679, current rewards: -1562.78980, mean: -0.79734
[32m[0907 02-07-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.08681, current rewards: -1612.78980, mean: -0.80238
[32m[0907 02-07-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.08683, current rewards: -1662.78980, mean: -0.80718
[32m[0907 02-07-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.08684, current rewards: -1712.78980, mean: -0.81175
[32m[0907 02-07-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.08685, current rewards: -1762.78980, mean: -0.81611
[32m[0907 02-07-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.08686, current rewards: -1812.78980, mean: -0.82027
[32m[0907 02-07-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.08687, current rewards: -1862.78980, mean: -0.82424
[32m[0907 02-07-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.08688, current rewards: -1912.78980, mean: -0.82805
[32m[0907 02-07-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.08695, current rewards: -1962.78980, mean: -0.83169
[32m[0907 02-07-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.08701, current rewards: -2012.78980, mean: -0.83518
[32m[0907 02-07-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.08712, current rewards: -2062.78980, mean: -0.83853
[32m[0907 02-07-45 @Agent.py:117][0m Average action selection time: 0.0872
[32m[0907 02-07-45 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-07-45 @MBExp.py:227][0m Rewards obtained: [-2102.7898023846174], Lows: [127], Highs: [1904], Total time: 30340.37223199999
[32m[0907 02-11-21 @MBExp.py:144][0m ####################################################################
[32m[0907 02-11-21 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 02-11-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.06605, current rewards: -7.71599, mean: -0.77160
[32m[0907 02-11-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.06761, current rewards: -65.36149, mean: -1.08936
[32m[0907 02-11-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.06702, current rewards: -142.35473, mean: -1.29413
[32m[0907 02-11-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.06771, current rewards: -227.58079, mean: -1.42238
[32m[0907 02-11-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.06825, current rewards: -296.92817, mean: -1.41394
[32m[0907 02-11-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.06803, current rewards: -373.89411, mean: -1.43805
[32m[0907 02-11-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.06808, current rewards: -463.53961, mean: -1.49529
[32m[0907 02-11-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.06790, current rewards: -556.56782, mean: -1.54602
[32m[0907 02-11-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.06769, current rewards: -631.87510, mean: -1.54116
[32m[0907 02-11-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.06773, current rewards: -714.32611, mean: -1.55288
[32m[0907 02-11-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.06809, current rewards: -801.03183, mean: -1.57065
[32m[0907 02-11-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.06797, current rewards: -889.47066, mean: -1.58834
[32m[0907 02-12-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.06800, current rewards: -937.28851, mean: -1.53654
[32m[0907 02-12-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.06792, current rewards: -1002.80307, mean: -1.51940
[32m[0907 02-12-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.06796, current rewards: -1084.41998, mean: -1.52735
[32m[0907 02-12-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.06832, current rewards: -1154.77919, mean: -1.51945
[32m[0907 02-12-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.06855, current rewards: -1226.02321, mean: -1.51361
[32m[0907 02-12-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.06864, current rewards: -1311.10434, mean: -1.52454
[32m[0907 02-12-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.06871, current rewards: -1372.41799, mean: -1.50815
[32m[0907 02-12-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.06870, current rewards: -1406.80458, mean: -1.46542
[32m[0907 02-12-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.06870, current rewards: -1401.35110, mean: -1.38748
[32m[0907 02-12-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.06881, current rewards: -1398.43210, mean: -1.31928
[32m[0907 02-12-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.06897, current rewards: -1395.96203, mean: -1.25762
[32m[0907 02-12-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.06913, current rewards: -1393.49195, mean: -1.20129
[32m[0907 02-12-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.06926, current rewards: -1391.02188, mean: -1.14960
[32m[0907 02-12-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.06938, current rewards: -1406.39163, mean: -1.11618
[32m[0907 02-12-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.06949, current rewards: -1456.39163, mean: -1.11175
[32m[0907 02-12-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.06959, current rewards: -1506.39163, mean: -1.10764
[32m[0907 02-13-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.06968, current rewards: -1556.39163, mean: -1.10382
[32m[0907 02-13-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.06978, current rewards: -1606.39163, mean: -1.10027
[32m[0907 02-13-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.06986, current rewards: -1656.39163, mean: -1.09695
[32m[0907 02-13-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.06993, current rewards: -1706.39163, mean: -1.09384
[32m[0907 02-13-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.06999, current rewards: -1756.39163, mean: -1.09093
[32m[0907 02-13-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.07005, current rewards: -1806.39163, mean: -1.08819
[32m[0907 02-13-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.07011, current rewards: -1856.39163, mean: -1.08561
[32m[0907 02-13-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.07017, current rewards: -1906.39163, mean: -1.08318
[32m[0907 02-13-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.07022, current rewards: -1956.39163, mean: -1.08088
[32m[0907 02-13-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.07027, current rewards: -2006.39163, mean: -1.07871
[32m[0907 02-13-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.07032, current rewards: -2056.39163, mean: -1.07664
[32m[0907 02-13-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.07036, current rewards: -2106.39163, mean: -1.07469
[32m[0907 02-13-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.07040, current rewards: -2156.39163, mean: -1.07283
[32m[0907 02-13-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.07044, current rewards: -2206.39163, mean: -1.07106
[32m[0907 02-13-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.07049, current rewards: -2256.39163, mean: -1.06938
[32m[0907 02-13-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.07053, current rewards: -2306.39163, mean: -1.06777
[32m[0907 02-13-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.07057, current rewards: -2356.39163, mean: -1.06624
[32m[0907 02-14-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.07060, current rewards: -2406.39163, mean: -1.06478
[32m[0907 02-14-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.07064, current rewards: -2456.39163, mean: -1.06337
[32m[0907 02-14-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.07067, current rewards: -2506.39163, mean: -1.06203
[32m[0907 02-14-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.07070, current rewards: -2556.39163, mean: -1.06074
[32m[0907 02-14-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.07073, current rewards: -2606.39163, mean: -1.05951
[32m[0907 02-14-18 @Agent.py:117][0m Average action selection time: 0.0707
[32m[0907 02-14-18 @Agent.py:118][0m Rollout length: 2505
[32m[0907 02-14-19 @MBExp.py:227][0m Rewards obtained: [-2646.391626160803], Lows: [683], Highs: [1336], Total time: 30517.92632499999
