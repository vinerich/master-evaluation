[32m[0906 13-40-34 @logger.py:99][0m Log file set to /app/logs/dats-delay-0/zinc-coating-v0_3/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-34 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -12.78883, mean: -1.27888
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -65.48185, mean: -1.09136
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -134.12754, mean: -1.21934
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -191.90060, mean: -1.19938
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -257.48037, mean: -1.22610
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -323.11137, mean: -1.24274
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -388.00780, mean: -1.25164
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -452.00485, mean: -1.25557
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -512.60085, mean: -1.25025
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -576.55234, mean: -1.25337
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -628.02066, mean: -1.23141
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -686.26085, mean: -1.22547
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -747.65156, mean: -1.22566
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -800.21694, mean: -1.21245
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -847.08278, mean: -1.19307
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -892.97154, mean: -1.17496
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -943.71139, mean: -1.16508
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1012.94276, mean: -1.17784
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1096.90998, mean: -1.20540
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1187.60484, mean: -1.23709
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1257.77466, mean: -1.24532
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1342.51171, mean: -1.26652
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1434.06599, mean: -1.29195
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1514.17116, mean: -1.30532
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1601.19915, mean: -1.32331
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1669.24336, mean: -1.32480
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1743.51613, mean: -1.33093
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1810.44671, mean: -1.33121
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1878.16989, mean: -1.33204
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1925.79732, mean: -1.31904
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1978.49784, mean: -1.31026
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -2032.87095, mean: -1.30312
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -2082.17842, mean: -1.29328
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -2131.51901, mean: -1.28405
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2180.70821, mean: -1.27527
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2230.86355, mean: -1.26754
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2284.02646, mean: -1.26189
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2336.92141, mean: -1.25641
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2390.15438, mean: -1.25139
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2431.59091, mean: -1.24061
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2493.26974, mean: -1.24043
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2543.88303, mean: -1.23489
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2596.41342, mean: -1.23053
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2649.38869, mean: -1.22657
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2697.06046, mean: -1.22039
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2747.13558, mean: -1.21555
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2800.98502, mean: -1.21255
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2854.71531, mean: -1.20963
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2902.82746, mean: -1.20449
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2963.55049, mean: -1.20470
[32m[0906 13-40-35 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-40-37 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-37 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03466, current rewards: -0.12458, mean: -0.01246
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02075, current rewards: 5.83991, mean: 0.09733
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 11.85048, mean: 0.10773
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01873, current rewards: 17.87011, mean: 0.11169
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 23.88837, mean: 0.11375
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01834, current rewards: 29.89946, mean: 0.11500
[32m[0906 13-40-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01827, current rewards: 35.91547, mean: 0.11586
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01822, current rewards: 41.30875, mean: 0.11475
[32m[0906 13-40-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01820, current rewards: 46.40233, mean: 0.11318
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01824, current rewards: 50.68592, mean: 0.11019
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01827, current rewards: 54.54840, mean: 0.10696
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01827, current rewards: 58.40819, mean: 0.10430
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01828, current rewards: 62.27122, mean: 0.10208
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01830, current rewards: 66.12935, mean: 0.10020
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01831, current rewards: 69.99043, mean: 0.09858
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01831, current rewards: 73.85178, mean: 0.09717
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01833, current rewards: 77.85403, mean: 0.09612
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01834, current rewards: 82.51041, mean: 0.09594
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01834, current rewards: 87.16593, mean: 0.09579
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01836, current rewards: 91.82237, mean: 0.09565
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01837, current rewards: 96.48400, mean: 0.09553
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01837, current rewards: 101.14013, mean: 0.09542
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01837, current rewards: 105.79984, mean: 0.09532
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01838, current rewards: 110.45607, mean: 0.09522
[32m[0906 13-41-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01836, current rewards: 115.11311, mean: 0.09513
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01836, current rewards: 119.87795, mean: 0.09514
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01834, current rewards: 124.80599, mean: 0.09527
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01834, current rewards: 127.46189, mean: 0.09372
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01833, current rewards: 132.11600, mean: 0.09370
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01833, current rewards: 136.76671, mean: 0.09368
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01834, current rewards: 141.42196, mean: 0.09366
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01834, current rewards: 146.07228, mean: 0.09364
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01835, current rewards: 150.72649, mean: 0.09362
[32m[0906 13-41-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01834, current rewards: 155.51832, mean: 0.09369
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01834, current rewards: 160.59980, mean: 0.09392
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01834, current rewards: 165.68167, mean: 0.09414
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01834, current rewards: 168.67817, mean: 0.09319
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01835, current rewards: 173.52518, mean: 0.09329
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01835, current rewards: 178.37426, mean: 0.09339
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01835, current rewards: 183.22368, mean: 0.09348
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01835, current rewards: 188.06959, mean: 0.09357
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01835, current rewards: 192.93004, mean: 0.09366
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01835, current rewards: 197.82278, mean: 0.09375
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01835, current rewards: 201.55876, mean: 0.09331
[32m[0906 13-41-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01835, current rewards: 206.08810, mean: 0.09325
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01835, current rewards: 210.61551, mean: 0.09319
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01837, current rewards: 215.14056, mean: 0.09313
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01838, current rewards: 219.66683, mean: 0.09308
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01838, current rewards: 224.19684, mean: 0.09303
[32m[0906 13-41-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01838, current rewards: 228.66380, mean: 0.09295
[32m[0906 13-41-24 @Agent.py:117][0m Average action selection time: 0.0184
[32m[0906 13-41-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-41-24 @MBExp.py:227][0m Rewards obtained: [232.00874653519224], Lows: [2], Highs: [2], Total time: 46.647431
[32m[0906 13-41-28 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-28 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02009, current rewards: 1.07083, mean: 0.10708
[32m[0906 13-41-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01997, current rewards: 6.48721, mean: 0.10812
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02007, current rewards: 11.90230, mean: 0.10820
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02007, current rewards: 17.31967, mean: 0.10825
[32m[0906 13-41-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01997, current rewards: 22.73610, mean: 0.10827
[32m[0906 13-41-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01993, current rewards: 28.15279, mean: 0.10828
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01992, current rewards: 33.56799, mean: 0.10828
[32m[0906 13-41-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01990, current rewards: 38.98495, mean: 0.10829
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01993, current rewards: 44.26403, mean: 0.10796
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01997, current rewards: 47.34402, mean: 0.10292
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02000, current rewards: 53.00675, mean: 0.10393
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02000, current rewards: 58.66711, mean: 0.10476
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02001, current rewards: 64.33088, mean: 0.10546
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02003, current rewards: 69.99089, mean: 0.10605
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02006, current rewards: 75.64787, mean: 0.10655
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02009, current rewards: 81.30521, mean: 0.10698
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02011, current rewards: 86.63414, mean: 0.10696
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02014, current rewards: 91.90028, mean: 0.10686
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02016, current rewards: 97.16874, mean: 0.10678
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02016, current rewards: 102.42965, mean: 0.10670
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02018, current rewards: 105.47962, mean: 0.10444
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02019, current rewards: 110.65603, mean: 0.10439
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02020, current rewards: 115.83864, mean: 0.10436
[32m[0906 13-41-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02019, current rewards: 121.01785, mean: 0.10433
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02018, current rewards: 126.00031, mean: 0.10413
[32m[0906 13-41-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02018, current rewards: 130.89032, mean: 0.10388
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02017, current rewards: 135.78152, mean: 0.10365
[32m[0906 13-41-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02017, current rewards: 140.67380, mean: 0.10344
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02016, current rewards: 145.56205, mean: 0.10324
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02017, current rewards: 150.45248, mean: 0.10305
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02018, current rewards: 155.34410, mean: 0.10288
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02019, current rewards: 160.23896, mean: 0.10272
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02020, current rewards: 165.36896, mean: 0.10271
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02021, current rewards: 169.93941, mean: 0.10237
[32m[0906 13-42-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02022, current rewards: 175.32687, mean: 0.10253
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02023, current rewards: 180.72264, mean: 0.10268
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02023, current rewards: 186.11387, mean: 0.10283
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02023, current rewards: 189.71972, mean: 0.10200
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02024, current rewards: 195.76747, mean: 0.10250
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02024, current rewards: 201.81597, mean: 0.10297
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02025, current rewards: 207.86034, mean: 0.10341
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02026, current rewards: 214.09859, mean: 0.10393
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02026, current rewards: 220.34023, mean: 0.10443
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02027, current rewards: 226.57911, mean: 0.10490
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02027, current rewards: 232.82063, mean: 0.10535
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02027, current rewards: 237.79984, mean: 0.10522
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02028, current rewards: 243.81846, mean: 0.10555
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02028, current rewards: 249.84852, mean: 0.10587
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02029, current rewards: 255.86713, mean: 0.10617
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02029, current rewards: 259.39042, mean: 0.10544
[32m[0906 13-42-20 @Agent.py:117][0m Average action selection time: 0.0203
[32m[0906 13-42-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-42-20 @MBExp.py:227][0m Rewards obtained: [263.84114897724135], Lows: [3], Highs: [4], Total time: 98.067218
[32m[0906 13-42-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-27 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02035, current rewards: -0.07868, mean: -0.00787
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02016, current rewards: 5.24235, mean: 0.08737
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02018, current rewards: 10.60205, mean: 0.09638
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02018, current rewards: 15.96074, mean: 0.09975
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02015, current rewards: 21.31721, mean: 0.10151
[32m[0906 13-42-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02012, current rewards: 26.68512, mean: 0.10264
[32m[0906 13-42-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02009, current rewards: 32.04106, mean: 0.10336
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02004, current rewards: 37.39889, mean: 0.10389
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02004, current rewards: 42.65871, mean: 0.10405
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02003, current rewards: 48.19451, mean: 0.10477
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02006, current rewards: 53.72344, mean: 0.10534
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02006, current rewards: 59.25055, mean: 0.10580
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02006, current rewards: 64.77455, mean: 0.10619
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02007, current rewards: 70.29844, mean: 0.10651
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02008, current rewards: 75.82488, mean: 0.10680
[32m[0906 13-42-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02009, current rewards: 81.35606, mean: 0.10705
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02010, current rewards: 86.71587, mean: 0.10706
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02013, current rewards: 92.06054, mean: 0.10705
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02015, current rewards: 97.40636, mean: 0.10704
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02017, current rewards: 100.50276, mean: 0.10469
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02018, current rewards: 105.61670, mean: 0.10457
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02019, current rewards: 110.72932, mean: 0.10446
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02020, current rewards: 115.83665, mean: 0.10436
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02019, current rewards: 120.94648, mean: 0.10426
[32m[0906 13-42-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02019, current rewards: 124.10502, mean: 0.10257
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02019, current rewards: 129.40193, mean: 0.10270
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02019, current rewards: 134.69613, mean: 0.10282
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02019, current rewards: 139.99015, mean: 0.10293
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02019, current rewards: 145.28542, mean: 0.10304
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02019, current rewards: 150.58260, mean: 0.10314
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02019, current rewards: 155.87969, mean: 0.10323
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02019, current rewards: 161.17643, mean: 0.10332
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02020, current rewards: 165.68340, mean: 0.10291
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02022, current rewards: 171.57040, mean: 0.10336
[32m[0906 13-43-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02023, current rewards: 177.45708, mean: 0.10378
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02023, current rewards: 183.35278, mean: 0.10418
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02024, current rewards: 187.79196, mean: 0.10375
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02024, current rewards: 194.88851, mean: 0.10478
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02025, current rewards: 201.98506, mean: 0.10575
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02025, current rewards: 209.08161, mean: 0.10667
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02026, current rewards: 214.81485, mean: 0.10687
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02027, current rewards: 165.86261, mean: 0.08052
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02027, current rewards: 115.86261, mean: 0.05491
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02028, current rewards: 65.86261, mean: 0.03049
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02028, current rewards: 15.86261, mean: 0.00718
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02029, current rewards: -34.13739, mean: -0.01511
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02029, current rewards: -84.13739, mean: -0.03642
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02029, current rewards: -134.13739, mean: -0.05684
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02029, current rewards: -184.13739, mean: -0.07641
[32m[0906 13-43-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02029, current rewards: -234.13739, mean: -0.09518
[32m[0906 13-43-18 @Agent.py:117][0m Average action selection time: 0.0203
[32m[0906 13-43-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-43-18 @MBExp.py:227][0m Rewards obtained: [-274.13739426850094], Lows: [3], Highs: [491], Total time: 149.440673
[32m[0906 13-43-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-27 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02083, current rewards: -0.06750, mean: -0.00675
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02010, current rewards: 5.43658, mean: 0.09061
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02009, current rewards: 10.96169, mean: 0.09965
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02010, current rewards: 16.49007, mean: 0.10306
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02008, current rewards: 22.02373, mean: 0.10487
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02010, current rewards: 27.55657, mean: 0.10599
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02011, current rewards: 33.08428, mean: 0.10672
[32m[0906 13-43-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02010, current rewards: 38.63413, mean: 0.10732
[32m[0906 13-43-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02006, current rewards: 44.18515, mean: 0.10777
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02001, current rewards: 49.73462, mean: 0.10812
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02001, current rewards: 55.27932, mean: 0.10839
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01999, current rewards: 58.71311, mean: 0.10484
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02002, current rewards: 64.22990, mean: 0.10529
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02002, current rewards: 69.74550, mean: 0.10568
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02002, current rewards: 75.26069, mean: 0.10600
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02003, current rewards: 80.60122, mean: 0.10605
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02004, current rewards: 85.90854, mean: 0.10606
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02004, current rewards: 91.21779, mean: 0.10607
[32m[0906 13-43-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02005, current rewards: 96.52415, mean: 0.10607
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02004, current rewards: 101.82965, mean: 0.10607
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02004, current rewards: 107.13777, mean: 0.10608
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02006, current rewards: 112.45294, mean: 0.10609
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02008, current rewards: 117.75920, mean: 0.10609
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02008, current rewards: 123.16129, mean: 0.10617
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02008, current rewards: 129.92970, mean: 0.10738
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02009, current rewards: 107.42132, mean: 0.08526
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02009, current rewards: 57.42132, mean: 0.04383
[32m[0906 13-43-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02010, current rewards: 27.44372, mean: 0.02018
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02011, current rewards: 33.10113, mean: 0.02348
[32m[0906 13-43-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02011, current rewards: 38.75191, mean: 0.02654
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02012, current rewards: 44.41024, mean: 0.02941
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02012, current rewards: 50.06726, mean: 0.03209
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02011, current rewards: 55.47005, mean: 0.03445
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02012, current rewards: 60.70194, mean: 0.03657
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02013, current rewards: 65.93281, mean: 0.03856
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02013, current rewards: 71.19995, mean: 0.04045
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02014, current rewards: 76.44533, mean: 0.04223
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02015, current rewards: 81.69352, mean: 0.04392
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02015, current rewards: 86.93995, mean: 0.04552
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02016, current rewards: 92.18828, mean: 0.04703
[32m[0906 13-44-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02017, current rewards: 97.47550, mean: 0.04850
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02018, current rewards: 102.83035, mean: 0.04992
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02019, current rewards: 106.14718, mean: 0.05031
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02020, current rewards: 111.65546, mean: 0.05169
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02021, current rewards: 117.16657, mean: 0.05302
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02022, current rewards: 122.67710, mean: 0.05428
[32m[0906 13-44-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02023, current rewards: 128.18563, mean: 0.05549
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02022, current rewards: 133.69642, mean: 0.05665
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02022, current rewards: 139.23035, mean: 0.05777
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02022, current rewards: 144.76664, mean: 0.05885
[32m[0906 13-44-18 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-44-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-44-18 @MBExp.py:227][0m Rewards obtained: [149.19836124779837], Lows: [2], Highs: [109], Total time: 200.640407
[32m[0906 13-44-30 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-30 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02015, current rewards: -2.25113, mean: -0.22511
[32m[0906 13-44-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02019, current rewards: 3.30418, mean: 0.05507
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02007, current rewards: 8.85783, mean: 0.08053
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02008, current rewards: 14.41458, mean: 0.09009
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02008, current rewards: 19.96334, mean: 0.09506
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02007, current rewards: 25.51730, mean: 0.09814
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02004, current rewards: 31.07023, mean: 0.10023
[32m[0906 13-44-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02004, current rewards: 36.27097, mean: 0.10075
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02002, current rewards: 41.46912, mean: 0.10114
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02000, current rewards: 46.66999, mean: 0.10146
[32m[0906 13-44-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01997, current rewards: 51.86386, mean: 0.10169
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01995, current rewards: 57.06117, mean: 0.10189
[32m[0906 13-44-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01994, current rewards: 62.25341, mean: 0.10205
[32m[0906 13-44-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01993, current rewards: 67.44903, mean: 0.10220
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01995, current rewards: 72.70747, mean: 0.10240
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01996, current rewards: 77.96555, mean: 0.10259
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01996, current rewards: 83.23532, mean: 0.10276
[32m[0906 13-44-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01998, current rewards: 88.49982, mean: 0.10291
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01997, current rewards: 93.76397, mean: 0.10304
[32m[0906 13-44-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01998, current rewards: 99.02982, mean: 0.10316
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01998, current rewards: 104.29599, mean: 0.10326
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01998, current rewards: 109.56767, mean: 0.10337
[32m[0906 13-44-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01997, current rewards: 114.83483, mean: 0.10345
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01998, current rewards: 120.35352, mean: 0.10375
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01997, current rewards: 126.01222, mean: 0.10414
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01998, current rewards: 130.54597, mean: 0.10361
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01997, current rewards: 134.74384, mean: 0.10286
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01998, current rewards: 138.93495, mean: 0.10216
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01999, current rewards: 143.12535, mean: 0.10151
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02000, current rewards: 147.31727, mean: 0.10090
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02000, current rewards: 151.51301, mean: 0.10034
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02001, current rewards: 154.65062, mean: 0.09914
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02001, current rewards: 160.09888, mean: 0.09944
[32m[0906 13-45-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02001, current rewards: 165.61208, mean: 0.09977
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02000, current rewards: 171.12319, mean: 0.10007
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02001, current rewards: 176.63814, mean: 0.10036
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02002, current rewards: 182.15172, mean: 0.10064
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02003, current rewards: 187.66323, mean: 0.10089
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02004, current rewards: 193.17776, mean: 0.10114
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02005, current rewards: 198.68897, mean: 0.10137
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02006, current rewards: 204.26941, mean: 0.10163
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02007, current rewards: 209.77246, mean: 0.10183
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02008, current rewards: 215.27506, mean: 0.10203
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02008, current rewards: 220.71205, mean: 0.10218
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02009, current rewards: 226.16038, mean: 0.10234
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02009, current rewards: 231.61173, mean: 0.10248
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02009, current rewards: 237.06257, mean: 0.10262
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02010, current rewards: 242.49460, mean: 0.10275
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02009, current rewards: 247.87163, mean: 0.10285
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02010, current rewards: 253.23142, mean: 0.10294
[32m[0906 13-45-21 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 13-45-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-45-21 @MBExp.py:227][0m Rewards obtained: [257.5192111459597], Lows: [1], Highs: [3], Total time: 251.561194
[32m[0906 13-45-34 @MBExp.py:144][0m ####################################################################
[32m[0906 13-45-34 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01979, current rewards: 0.09187, mean: 0.00919
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02002, current rewards: 5.89470, mean: 0.09825
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01993, current rewards: 11.62584, mean: 0.10569
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02002, current rewards: 17.34942, mean: 0.10843
[32m[0906 13-45-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02009, current rewards: 23.08210, mean: 0.10991
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02011, current rewards: 28.80082, mean: 0.11077
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02012, current rewards: 34.52651, mean: 0.11138
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02011, current rewards: 37.88585, mean: 0.10524
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02010, current rewards: 43.32173, mean: 0.10566
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02010, current rewards: 48.75772, mean: 0.10600
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02014, current rewards: 54.19293, mean: 0.10626
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02013, current rewards: 59.62735, mean: 0.10648
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02010, current rewards: 65.06100, mean: 0.10666
[32m[0906 13-45-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02009, current rewards: 70.49783, mean: 0.10681
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02006, current rewards: 75.93597, mean: 0.10695
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02004, current rewards: 81.62163, mean: 0.10740
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02005, current rewards: 87.66689, mean: 0.10823
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02005, current rewards: 75.75754, mean: 0.08809
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02006, current rewards: 81.29143, mean: 0.08933
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02006, current rewards: 86.81920, mean: 0.09044
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02006, current rewards: 92.34903, mean: 0.09143
[32m[0906 13-45-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02005, current rewards: 97.88110, mean: 0.09234
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02004, current rewards: 103.40827, mean: 0.09316
[32m[0906 13-45-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02003, current rewards: 108.90910, mean: 0.09389
[32m[0906 13-45-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02001, current rewards: 114.91635, mean: 0.09497
[32m[0906 13-46-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 120.34783, mean: 0.09551
[32m[0906 13-46-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01999, current rewards: 125.77967, mean: 0.09602
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01999, current rewards: 131.20877, mean: 0.09648
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01998, current rewards: 136.64371, mean: 0.09691
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01998, current rewards: 142.05063, mean: 0.09729
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01998, current rewards: 147.49880, mean: 0.09768
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01998, current rewards: 152.91860, mean: 0.09802
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01999, current rewards: 158.32816, mean: 0.09834
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01999, current rewards: 163.79167, mean: 0.09867
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02000, current rewards: 169.25678, mean: 0.09898
[32m[0906 13-46-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02000, current rewards: 174.69250, mean: 0.09926
[32m[0906 13-46-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02000, current rewards: 180.14153, mean: 0.09953
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02001, current rewards: 185.59256, mean: 0.09978
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02003, current rewards: 191.04484, mean: 0.10002
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02004, current rewards: 196.49230, mean: 0.10025
[32m[0906 13-46-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02005, current rewards: 201.93739, mean: 0.10047
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02006, current rewards: 207.37930, mean: 0.10067
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02006, current rewards: 212.82550, mean: 0.10087
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02006, current rewards: 218.27340, mean: 0.10105
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02006, current rewards: 223.72279, mean: 0.10123
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02006, current rewards: 229.15704, mean: 0.10140
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02006, current rewards: 234.47852, mean: 0.10151
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02006, current rewards: 239.80209, mean: 0.10161
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02006, current rewards: 245.27916, mean: 0.10178
[32m[0906 13-46-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02006, current rewards: 250.73863, mean: 0.10193
[32m[0906 13-46-25 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 13-46-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-46-25 @MBExp.py:227][0m Rewards obtained: [255.1065837454747], Lows: [1], Highs: [17], Total time: 302.391516
[32m[0906 13-46-41 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-41 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02058, current rewards: 0.01106, mean: 0.00111
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02024, current rewards: 5.62700, mean: 0.09378
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02018, current rewards: 11.23725, mean: 0.10216
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02018, current rewards: 16.85805, mean: 0.10536
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02015, current rewards: 22.47758, mean: 0.10704
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02011, current rewards: 28.09086, mean: 0.10804
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02011, current rewards: 33.77241, mean: 0.10894
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02012, current rewards: 39.40453, mean: 0.10946
[32m[0906 13-46-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02016, current rewards: 45.03099, mean: 0.10983
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02017, current rewards: 50.65821, mean: 0.11013
[32m[0906 13-46-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02016, current rewards: 56.29224, mean: 0.11038
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02015, current rewards: 61.92059, mean: 0.11057
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02014, current rewards: 67.38302, mean: 0.11046
[32m[0906 13-46-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02012, current rewards: 72.83537, mean: 0.11036
[32m[0906 13-46-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02010, current rewards: 78.29939, mean: 0.11028
[32m[0906 13-46-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02008, current rewards: 83.72938, mean: 0.11017
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02005, current rewards: 89.16025, mean: 0.11007
[32m[0906 13-46-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02003, current rewards: 94.59520, mean: 0.10999
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02004, current rewards: 100.02735, mean: 0.10992
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02005, current rewards: 105.46331, mean: 0.10986
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02005, current rewards: 110.89344, mean: 0.10980
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02004, current rewards: 116.32574, mean: 0.10974
[32m[0906 13-47-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02002, current rewards: 121.76133, mean: 0.10969
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02001, current rewards: 127.17043, mean: 0.10963
[32m[0906 13-47-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02001, current rewards: 132.66335, mean: 0.10964
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 138.15250, mean: 0.10964
[32m[0906 13-47-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01999, current rewards: 143.64067, mean: 0.10965
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01997, current rewards: 149.13009, mean: 0.10965
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01996, current rewards: 154.62223, mean: 0.10966
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01995, current rewards: 160.11622, mean: 0.10967
[32m[0906 13-47-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01995, current rewards: 165.60998, mean: 0.10968
[32m[0906 13-47-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01995, current rewards: 171.22830, mean: 0.10976
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01994, current rewards: 176.75541, mean: 0.10979
[32m[0906 13-47-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01994, current rewards: 182.20564, mean: 0.10976
[32m[0906 13-47-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01995, current rewards: 187.66179, mean: 0.10974
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01995, current rewards: 193.11367, mean: 0.10972
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01995, current rewards: 198.56615, mean: 0.10971
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 201.96228, mean: 0.10858
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01996, current rewards: 207.49680, mean: 0.10864
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 213.01845, mean: 0.10868
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: 216.08047, mean: 0.10750
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01998, current rewards: 221.25546, mean: 0.10741
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01999, current rewards: 226.42771, mean: 0.10731
[32m[0906 13-47-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01999, current rewards: 231.60087, mean: 0.10722
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02000, current rewards: 235.79580, mean: 0.10669
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01999, current rewards: 241.42947, mean: 0.10683
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02000, current rewards: 247.06072, mean: 0.10695
[32m[0906 13-47-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02000, current rewards: 252.68862, mean: 0.10707
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02000, current rewards: 258.31154, mean: 0.10718
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02001, current rewards: 263.94028, mean: 0.10729
[32m[0906 13-47-32 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-47-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-47-32 @MBExp.py:227][0m Rewards obtained: [268.4429317689984], Lows: [2], Highs: [2], Total time: 353.081245
[32m[0906 13-47-50 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-50 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-47-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01967, current rewards: -1.10952, mean: -0.11095
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01981, current rewards: 4.38017, mean: 0.07300
[32m[0906 13-47-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01996, current rewards: 9.86847, mean: 0.08971
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02003, current rewards: 15.34996, mean: 0.09594
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02008, current rewards: 20.83556, mean: 0.09922
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02011, current rewards: 26.31380, mean: 0.10121
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02009, current rewards: 31.83206, mean: 0.10268
[32m[0906 13-47-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02010, current rewards: 37.31751, mean: 0.10366
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02009, current rewards: 42.80775, mean: 0.10441
[32m[0906 13-47-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02009, current rewards: 48.29915, mean: 0.10500
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02009, current rewards: 53.79639, mean: 0.10548
[32m[0906 13-48-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02010, current rewards: 59.30783, mean: 0.10591
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02010, current rewards: 64.85679, mean: 0.10632
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02008, current rewards: 70.40488, mean: 0.10667
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02007, current rewards: 76.04745, mean: 0.10711
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02006, current rewards: 79.49092, mean: 0.10459
[32m[0906 13-48-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02004, current rewards: 84.99283, mean: 0.10493
[32m[0906 13-48-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02003, current rewards: 90.49403, mean: 0.10523
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02002, current rewards: 95.99747, mean: 0.10549
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02000, current rewards: 101.49920, mean: 0.10573
[32m[0906 13-48-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02000, current rewards: 107.00230, mean: 0.10594
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01999, current rewards: 112.50681, mean: 0.10614
[32m[0906 13-48-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01997, current rewards: 117.96687, mean: 0.10628
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01996, current rewards: 123.42503, mean: 0.10640
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01995, current rewards: 128.96057, mean: 0.10658
[32m[0906 13-48-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01994, current rewards: 134.78489, mean: 0.10697
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 140.06093, mean: 0.10692
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01992, current rewards: 145.33740, mean: 0.10687
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01991, current rewards: 150.61288, mean: 0.10682
[32m[0906 13-48-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01991, current rewards: 155.88605, mean: 0.10677
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01991, current rewards: 160.13743, mean: 0.10605
[32m[0906 13-48-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01990, current rewards: 165.68372, mean: 0.10621
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01989, current rewards: 171.22536, mean: 0.10635
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01989, current rewards: 176.75864, mean: 0.10648
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01989, current rewards: 182.29321, mean: 0.10660
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01988, current rewards: 187.83675, mean: 0.10673
[32m[0906 13-48-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01987, current rewards: 193.37469, mean: 0.10684
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01987, current rewards: 198.92588, mean: 0.10695
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01987, current rewards: 204.48965, mean: 0.10706
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01987, current rewards: 210.06666, mean: 0.10718
[32m[0906 13-48-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01987, current rewards: 215.63034, mean: 0.10728
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01988, current rewards: 221.19953, mean: 0.10738
[32m[0906 13-48-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01989, current rewards: 226.76473, mean: 0.10747
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01989, current rewards: 232.33122, mean: 0.10756
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01990, current rewards: 237.98087, mean: 0.10768
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01991, current rewards: 243.47358, mean: 0.10773
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01991, current rewards: 248.96115, mean: 0.10778
[32m[0906 13-48-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01992, current rewards: 254.38004, mean: 0.10779
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01992, current rewards: 259.84509, mean: 0.10782
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01992, current rewards: 265.31375, mean: 0.10785
[32m[0906 13-48-40 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-48-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-48-40 @MBExp.py:227][0m Rewards obtained: [269.6916348146435], Lows: [1], Highs: [3], Total time: 403.56338400000004
[32m[0906 13-49-01 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-01 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02110, current rewards: -0.09684, mean: -0.00968
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02014, current rewards: 5.29789, mean: 0.08830
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02014, current rewards: 10.69127, mean: 0.09719
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02010, current rewards: 16.08305, mean: 0.10052
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02009, current rewards: 21.47666, mean: 0.10227
[32m[0906 13-49-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02008, current rewards: 26.89566, mean: 0.10344
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02016, current rewards: 32.39378, mean: 0.10450
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02016, current rewards: 37.87142, mean: 0.10520
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02016, current rewards: 43.35068, mean: 0.10573
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02016, current rewards: 48.83155, mean: 0.10616
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02018, current rewards: 54.31516, mean: 0.10650
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02020, current rewards: 59.79377, mean: 0.10677
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02017, current rewards: 65.27361, mean: 0.10701
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02017, current rewards: 70.87825, mean: 0.10739
[32m[0906 13-49-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02016, current rewards: 76.49275, mean: 0.10774
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02015, current rewards: 82.03883, mean: 0.10795
[32m[0906 13-49-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02015, current rewards: 87.57795, mean: 0.10812
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02014, current rewards: 93.11770, mean: 0.10828
[32m[0906 13-49-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02012, current rewards: 98.66289, mean: 0.10842
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02010, current rewards: 104.20284, mean: 0.10854
[32m[0906 13-49-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02008, current rewards: 109.67553, mean: 0.10859
[32m[0906 13-49-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02003, current rewards: 115.01012, mean: 0.10850
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02002, current rewards: 120.30844, mean: 0.10839
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02000, current rewards: 125.83116, mean: 0.10848
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01998, current rewards: 131.37398, mean: 0.10857
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01997, current rewards: 136.92320, mean: 0.10867
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01995, current rewards: 142.37429, mean: 0.10868
[32m[0906 13-49-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01995, current rewards: 147.79162, mean: 0.10867
[32m[0906 13-49-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01995, current rewards: 153.21327, mean: 0.10866
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01993, current rewards: 158.63750, mean: 0.10866
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01993, current rewards: 164.06388, mean: 0.10865
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01992, current rewards: 169.59961, mean: 0.10872
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01991, current rewards: 175.07102, mean: 0.10874
[32m[0906 13-49-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01991, current rewards: 180.54801, mean: 0.10876
[32m[0906 13-49-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01990, current rewards: 186.02289, mean: 0.10879
[32m[0906 13-49-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01989, current rewards: 191.49450, mean: 0.10880
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01987, current rewards: 196.96563, mean: 0.10882
[32m[0906 13-49-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01986, current rewards: 202.47291, mean: 0.10886
[32m[0906 13-49-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01984, current rewards: 207.97907, mean: 0.10889
[32m[0906 13-49-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01983, current rewards: 213.39181, mean: 0.10887
[32m[0906 13-49-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01981, current rewards: 218.83418, mean: 0.10887
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01980, current rewards: 224.27974, mean: 0.10887
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01979, current rewards: 229.72406, mean: 0.10887
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01979, current rewards: 235.16939, mean: 0.10887
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01980, current rewards: 240.61672, mean: 0.10888
[32m[0906 13-49-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01980, current rewards: 246.06385, mean: 0.10888
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01981, current rewards: 251.51848, mean: 0.10888
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01981, current rewards: 256.95449, mean: 0.10888
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01982, current rewards: 262.38525, mean: 0.10887
[32m[0906 13-49-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01983, current rewards: 267.81622, mean: 0.10887
[32m[0906 13-49-51 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-49-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-49-51 @MBExp.py:227][0m Rewards obtained: [271.1149962888484], Lows: [0], Highs: [2], Total time: 453.80784200000005
[32m[0906 13-50-13 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-13 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02025, current rewards: 0.98043, mean: 0.09804
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02013, current rewards: 6.32314, mean: 0.10539
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02016, current rewards: 11.66346, mean: 0.10603
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02014, current rewards: 17.00475, mean: 0.10628
[32m[0906 13-50-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02008, current rewards: 22.34845, mean: 0.10642
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02009, current rewards: 27.70773, mean: 0.10657
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02010, current rewards: 33.27488, mean: 0.10734
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02010, current rewards: 38.83803, mean: 0.10788
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02009, current rewards: 44.40118, mean: 0.10830
[32m[0906 13-50-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02010, current rewards: 49.96433, mean: 0.10862
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02010, current rewards: 55.52748, mean: 0.10888
[32m[0906 13-50-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 56.64558, mean: 0.10115
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02009, current rewards: 18.86104, mean: 0.03092
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02006, current rewards: 24.45733, mean: 0.03706
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02006, current rewards: 29.99928, mean: 0.04225
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02006, current rewards: 35.59323, mean: 0.04683
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02007, current rewards: 41.18937, mean: 0.05085
[32m[0906 13-50-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02007, current rewards: 46.78207, mean: 0.05440
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02008, current rewards: 52.37406, mean: 0.05755
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02009, current rewards: 57.97189, mean: 0.06039
[32m[0906 13-50-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02006, current rewards: 63.62501, mean: 0.06300
[32m[0906 13-50-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02002, current rewards: 69.29550, mean: 0.06537
[32m[0906 13-50-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01999, current rewards: 74.94153, mean: 0.06751
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: 80.63925, mean: 0.06952
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01994, current rewards: 86.33482, mean: 0.07135
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: 92.02176, mean: 0.07303
[32m[0906 13-50-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01992, current rewards: 97.71716, mean: 0.07459
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01991, current rewards: 103.40528, mean: 0.07603
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01990, current rewards: 109.09818, mean: 0.07737
[32m[0906 13-50-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01990, current rewards: 114.79178, mean: 0.07862
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01989, current rewards: 120.54065, mean: 0.07983
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01989, current rewards: 126.19898, mean: 0.08090
[32m[0906 13-50-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01988, current rewards: 131.78858, mean: 0.08186
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01988, current rewards: 137.37871, mean: 0.08276
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01987, current rewards: 142.96694, mean: 0.08361
[32m[0906 13-50-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01985, current rewards: 148.55099, mean: 0.08440
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01983, current rewards: 154.14350, mean: 0.08516
[32m[0906 13-50-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01982, current rewards: 159.72936, mean: 0.08588
[32m[0906 13-50-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01980, current rewards: 165.31864, mean: 0.08655
[32m[0906 13-50-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01979, current rewards: 170.89045, mean: 0.08719
[32m[0906 13-50-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01978, current rewards: 176.56609, mean: 0.08784
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01976, current rewards: 182.19030, mean: 0.08844
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01975, current rewards: 187.74274, mean: 0.08898
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01974, current rewards: 193.29250, mean: 0.08949
[32m[0906 13-50-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01973, current rewards: 198.84696, mean: 0.08998
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01972, current rewards: 204.39710, mean: 0.09044
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01972, current rewards: 209.94399, mean: 0.09088
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01973, current rewards: 215.29670, mean: 0.09123
[32m[0906 13-51-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01974, current rewards: 220.59143, mean: 0.09153
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01974, current rewards: 225.89124, mean: 0.09183
[32m[0906 13-51-03 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-51-03 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-51-03 @MBExp.py:227][0m Rewards obtained: [230.1224523325589], Lows: [0], Highs: [43], Total time: 503.84746500000006
[32m[0906 13-51-28 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-28 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01960, current rewards: -1.11431, mean: -0.11143
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01984, current rewards: 4.63307, mean: 0.07722
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01993, current rewards: 10.37896, mean: 0.09435
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01994, current rewards: 16.12381, mean: 0.10077
[32m[0906 13-51-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01999, current rewards: 21.87291, mean: 0.10416
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02000, current rewards: 27.55454, mean: 0.10598
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02004, current rewards: 33.24522, mean: 0.10724
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02005, current rewards: 38.95839, mean: 0.10822
[32m[0906 13-51-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02006, current rewards: 44.58451, mean: 0.10874
[32m[0906 13-51-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02006, current rewards: 50.17318, mean: 0.10907
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02007, current rewards: 55.77122, mean: 0.10936
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 61.36291, mean: 0.10958
[32m[0906 13-51-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02010, current rewards: 66.95527, mean: 0.10976
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02008, current rewards: 72.54206, mean: 0.10991
[32m[0906 13-51-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02008, current rewards: 78.25078, mean: 0.11021
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02009, current rewards: 83.83982, mean: 0.11032
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02010, current rewards: 89.43431, mean: 0.11041
[32m[0906 13-51-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02008, current rewards: 95.06716, mean: 0.11054
[32m[0906 13-51-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02008, current rewards: 100.68640, mean: 0.11064
[32m[0906 13-51-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02009, current rewards: 106.30609, mean: 0.11074
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02008, current rewards: 111.92124, mean: 0.11081
[32m[0906 13-51-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02007, current rewards: 117.54082, mean: 0.11089
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02005, current rewards: 123.12708, mean: 0.11093
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02001, current rewards: 128.69591, mean: 0.11094
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01998, current rewards: 134.33871, mean: 0.11102
[32m[0906 13-51-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01994, current rewards: 139.98908, mean: 0.11110
[32m[0906 13-51-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 145.63611, mean: 0.11117
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01992, current rewards: 151.28232, mean: 0.11124
[32m[0906 13-51-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01992, current rewards: 156.93654, mean: 0.11130
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01991, current rewards: 162.58424, mean: 0.11136
[32m[0906 13-51-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01991, current rewards: 168.23097, mean: 0.11141
[32m[0906 13-52-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01991, current rewards: 173.97199, mean: 0.11152
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01989, current rewards: 179.62073, mean: 0.11157
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01988, current rewards: 185.26950, mean: 0.11161
[32m[0906 13-52-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01986, current rewards: 191.15036, mean: 0.11178
[32m[0906 13-52-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01985, current rewards: 196.77255, mean: 0.11180
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01983, current rewards: 202.39541, mean: 0.11182
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01982, current rewards: 208.01748, mean: 0.11184
[32m[0906 13-52-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01980, current rewards: 213.64054, mean: 0.11185
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01979, current rewards: 219.26170, mean: 0.11187
[32m[0906 13-52-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01978, current rewards: 224.74539, mean: 0.11181
[32m[0906 13-52-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01977, current rewards: 230.30381, mean: 0.11180
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01976, current rewards: 235.86141, mean: 0.11178
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01975, current rewards: 241.41866, mean: 0.11177
[32m[0906 13-52-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01973, current rewards: 246.97759, mean: 0.11175
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01973, current rewards: 252.53120, mean: 0.11174
[32m[0906 13-52-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01972, current rewards: 258.08574, mean: 0.11173
[32m[0906 13-52-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01971, current rewards: 263.64061, mean: 0.11171
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01970, current rewards: 269.22962, mean: 0.11171
[32m[0906 13-52-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01970, current rewards: 274.74294, mean: 0.11168
[32m[0906 13-52-18 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 13-52-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-52-18 @MBExp.py:227][0m Rewards obtained: [279.1530573562272], Lows: [0], Highs: [2], Total time: 553.778801
[32m[0906 13-52-45 @MBExp.py:144][0m ####################################################################
[32m[0906 13-52-45 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01968, current rewards: -0.05028, mean: -0.00503
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02013, current rewards: 5.32300, mean: 0.08872
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02020, current rewards: 10.76227, mean: 0.09784
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02012, current rewards: 16.19793, mean: 0.10124
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02013, current rewards: 21.63750, mean: 0.10304
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02009, current rewards: 27.08091, mean: 0.10416
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02008, current rewards: 32.51695, mean: 0.10489
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02005, current rewards: 38.06381, mean: 0.10573
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02005, current rewards: 43.50807, mean: 0.10612
[32m[0906 13-52-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02007, current rewards: 48.95168, mean: 0.10642
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02008, current rewards: 54.60469, mean: 0.10707
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02008, current rewards: 60.08587, mean: 0.10730
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02008, current rewards: 65.56490, mean: 0.10748
[32m[0906 13-52-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02007, current rewards: 71.04498, mean: 0.10764
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02008, current rewards: 76.52242, mean: 0.10778
[32m[0906 13-53-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02007, current rewards: 81.96896, mean: 0.10785
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02006, current rewards: 87.33762, mean: 0.10782
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02006, current rewards: 92.78180, mean: 0.10789
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02006, current rewards: 98.22800, mean: 0.10794
[32m[0906 13-53-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02006, current rewards: 103.67081, mean: 0.10799
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02006, current rewards: 109.11342, mean: 0.10803
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02004, current rewards: 114.55813, mean: 0.10807
[32m[0906 13-53-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02003, current rewards: 120.00410, mean: 0.10811
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02002, current rewards: 125.42490, mean: 0.10812
[32m[0906 13-53-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02003, current rewards: 130.86331, mean: 0.10815
[32m[0906 13-53-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 136.31650, mean: 0.10819
[32m[0906 13-53-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01997, current rewards: 141.76806, mean: 0.10822
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01995, current rewards: 147.22321, mean: 0.10825
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01994, current rewards: 152.67203, mean: 0.10828
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01993, current rewards: 158.12279, mean: 0.10830
[32m[0906 13-53-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01991, current rewards: 163.57331, mean: 0.10833
[32m[0906 13-53-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01989, current rewards: 169.02742, mean: 0.10835
[32m[0906 13-53-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01987, current rewards: 174.53090, mean: 0.10840
[32m[0906 13-53-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01985, current rewards: 179.98837, mean: 0.10843
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01984, current rewards: 185.44338, mean: 0.10845
[32m[0906 13-53-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01982, current rewards: 190.90077, mean: 0.10847
[32m[0906 13-53-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01980, current rewards: 196.36074, mean: 0.10849
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01978, current rewards: 201.98577, mean: 0.10859
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01978, current rewards: 207.43467, mean: 0.10860
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01976, current rewards: 212.88478, mean: 0.10861
[32m[0906 13-53-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01976, current rewards: 218.28896, mean: 0.10860
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01975, current rewards: 223.72303, mean: 0.10860
[32m[0906 13-53-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01974, current rewards: 229.15878, mean: 0.10861
[32m[0906 13-53-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01972, current rewards: 234.56567, mean: 0.10860
[32m[0906 13-53-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01971, current rewards: 239.98076, mean: 0.10859
[32m[0906 13-53-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01971, current rewards: 245.39460, mean: 0.10858
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01970, current rewards: 250.80639, mean: 0.10857
[32m[0906 13-53-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01969, current rewards: 256.21971, mean: 0.10857
[32m[0906 13-53-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01968, current rewards: 261.63587, mean: 0.10856
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01967, current rewards: 267.04778, mean: 0.10856
[32m[0906 13-53-35 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 13-53-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-53-35 @MBExp.py:227][0m Rewards obtained: [271.37910220115276], Lows: [0], Highs: [1], Total time: 603.6137610000001
[32m[0906 13-54-04 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-04 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02020, current rewards: 1.50133, mean: 0.15013
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01993, current rewards: 10.28999, mean: 0.17150
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01994, current rewards: 19.07866, mean: 0.17344
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01996, current rewards: 27.86732, mean: 0.17417
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01996, current rewards: 36.65598, mean: 0.17455
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01998, current rewards: 34.86268, mean: 0.13409
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02002, current rewards: -15.13732, mean: -0.04883
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01999, current rewards: -65.13732, mean: -0.18094
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01998, current rewards: -115.13732, mean: -0.28082
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02000, current rewards: -165.13732, mean: -0.35899
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02001, current rewards: -215.13732, mean: -0.42184
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02001, current rewards: -265.13732, mean: -0.47346
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02000, current rewards: -315.13732, mean: -0.51662
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01999, current rewards: -365.13732, mean: -0.55324
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01999, current rewards: -415.13732, mean: -0.58470
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02000, current rewards: -465.13732, mean: -0.61202
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02000, current rewards: -515.13732, mean: -0.63597
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02000, current rewards: -565.13732, mean: -0.65714
[32m[0906 13-54-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02000, current rewards: -615.13732, mean: -0.67598
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01999, current rewards: -665.13732, mean: -0.69285
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01999, current rewards: -715.13732, mean: -0.70806
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01998, current rewards: -765.13732, mean: -0.72183
[32m[0906 13-54-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01997, current rewards: -815.13732, mean: -0.73436
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: -865.13732, mean: -0.74581
[32m[0906 13-54-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01994, current rewards: -915.13732, mean: -0.75631
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: -965.13732, mean: -0.76598
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: -1015.13732, mean: -0.77491
[32m[0906 13-54-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01991, current rewards: -1065.13732, mean: -0.78319
[32m[0906 13-54-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01989, current rewards: -1115.13732, mean: -0.79088
[32m[0906 13-54-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01985, current rewards: -1165.13732, mean: -0.79804
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01982, current rewards: -1215.13732, mean: -0.80473
[32m[0906 13-54-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01980, current rewards: -1265.13732, mean: -0.81099
[32m[0906 13-54-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01977, current rewards: -1315.13732, mean: -0.81686
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01976, current rewards: -1365.13732, mean: -0.82237
[32m[0906 13-54-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01974, current rewards: -1415.13732, mean: -0.82757
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01973, current rewards: -1465.13732, mean: -0.83246
[32m[0906 13-54-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01972, current rewards: -1515.13732, mean: -0.83709
[32m[0906 13-54-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01970, current rewards: -1565.13732, mean: -0.84147
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01969, current rewards: -1615.13732, mean: -0.84562
[32m[0906 13-54-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01968, current rewards: -1665.13732, mean: -0.84956
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01967, current rewards: -1715.13732, mean: -0.85330
[32m[0906 13-54-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01966, current rewards: -1765.13732, mean: -0.85686
[32m[0906 13-54-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01965, current rewards: -1815.13732, mean: -0.86025
[32m[0906 13-54-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01964, current rewards: -1862.98762, mean: -0.86249
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01963, current rewards: -1859.24508, mean: -0.84129
[32m[0906 13-54-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01962, current rewards: -1855.50255, mean: -0.82102
[32m[0906 13-54-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01961, current rewards: -1851.76001, mean: -0.80163
[32m[0906 13-54-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01961, current rewards: -1848.01748, mean: -0.78306
[32m[0906 13-54-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01961, current rewards: -1885.11927, mean: -0.78221
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01960, current rewards: -1935.11927, mean: -0.78663
[32m[0906 13-54-54 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 13-54-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-54-54 @MBExp.py:227][0m Rewards obtained: [-1975.1192695906611], Lows: [0], Highs: [2035], Total time: 653.2676470000001
[32m[0906 13-55-25 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-25 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02023, current rewards: 0.02769, mean: 0.00277
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02015, current rewards: 5.62771, mean: 0.09380
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02008, current rewards: 11.22525, mean: 0.10205
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02018, current rewards: 16.82957, mean: 0.10518
[32m[0906 13-55-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02015, current rewards: 22.43669, mean: 0.10684
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02011, current rewards: 28.04600, mean: 0.10787
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02010, current rewards: 33.62765, mean: 0.10848
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02011, current rewards: 39.28536, mean: 0.10913
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02011, current rewards: 44.94587, mean: 0.10962
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02011, current rewards: 50.89809, mean: 0.11065
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02011, current rewards: 56.71565, mean: 0.11121
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02011, current rewards: 62.53754, mean: 0.11167
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02011, current rewards: 68.34707, mean: 0.11204
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02010, current rewards: 74.16852, mean: 0.11238
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02010, current rewards: 79.99942, mean: 0.11268
[32m[0906 13-55-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02011, current rewards: 85.64097, mean: 0.11269
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02010, current rewards: 91.20613, mean: 0.11260
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02011, current rewards: 96.77115, mean: 0.11252
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02011, current rewards: 102.11564, mean: 0.11221
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02011, current rewards: 107.38778, mean: 0.11186
[32m[0906 13-55-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02011, current rewards: 112.65896, mean: 0.11154
[32m[0906 13-55-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02010, current rewards: 117.92922, mean: 0.11125
[32m[0906 13-55-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02007, current rewards: 123.19940, mean: 0.11099
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02006, current rewards: 128.46104, mean: 0.11074
[32m[0906 13-55-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02004, current rewards: 133.73655, mean: 0.11053
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02003, current rewards: 139.01581, mean: 0.11033
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02001, current rewards: 144.88439, mean: 0.11060
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01999, current rewards: 150.45067, mean: 0.11063
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01996, current rewards: 156.01773, mean: 0.11065
[32m[0906 13-55-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01994, current rewards: 161.58266, mean: 0.11067
[32m[0906 13-55-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01991, current rewards: 166.09675, mean: 0.11000
[32m[0906 13-55-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01987, current rewards: 171.74616, mean: 0.11009
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01985, current rewards: 177.42130, mean: 0.11020
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01984, current rewards: 183.09818, mean: 0.11030
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01982, current rewards: 188.76685, mean: 0.11039
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01980, current rewards: 194.44168, mean: 0.11048
[32m[0906 13-56-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01978, current rewards: 200.11573, mean: 0.11056
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01976, current rewards: 205.79446, mean: 0.11064
[32m[0906 13-56-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01975, current rewards: 211.46783, mean: 0.11072
[32m[0906 13-56-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01974, current rewards: 217.18387, mean: 0.11081
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01973, current rewards: 222.89001, mean: 0.11089
[32m[0906 13-56-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01971, current rewards: 228.59845, mean: 0.11097
[32m[0906 13-56-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01970, current rewards: 234.30271, mean: 0.11104
[32m[0906 13-56-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01968, current rewards: 240.00623, mean: 0.11111
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01967, current rewards: 245.71795, mean: 0.11118
[32m[0906 13-56-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01966, current rewards: 251.42569, mean: 0.11125
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01965, current rewards: 257.05879, mean: 0.11128
[32m[0906 13-56-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01965, current rewards: 262.66916, mean: 0.11130
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01964, current rewards: 268.24114, mean: 0.11130
[32m[0906 13-56-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01963, current rewards: 273.79300, mean: 0.11130
[32m[0906 13-56-15 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 13-56-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-56-15 @MBExp.py:227][0m Rewards obtained: [278.23330177913823], Lows: [0], Highs: [2], Total time: 703.0227270000001
[32m[0906 13-56-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-48 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 13-56-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02066, current rewards: -0.14038, mean: -0.01404
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02010, current rewards: 4.52086, mean: 0.07535
[32m[0906 13-56-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02011, current rewards: 9.18524, mean: 0.08350
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02010, current rewards: 13.85343, mean: 0.08658
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02007, current rewards: 18.52065, mean: 0.08819
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02008, current rewards: 23.19075, mean: 0.08920
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02009, current rewards: 27.78841, mean: 0.08964
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02010, current rewards: 32.30887, mean: 0.08975
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02010, current rewards: 36.83343, mean: 0.08984
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02013, current rewards: 41.35697, mean: 0.08991
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02012, current rewards: 45.87793, mean: 0.08996
[32m[0906 13-57-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02012, current rewards: 50.39507, mean: 0.08999
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02012, current rewards: 54.92149, mean: 0.09004
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02012, current rewards: 59.44626, mean: 0.09007
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02012, current rewards: 64.05505, mean: 0.09022
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02012, current rewards: 69.03689, mean: 0.09084
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02012, current rewards: 71.94905, mean: 0.08883
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02012, current rewards: 77.34411, mean: 0.08994
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02012, current rewards: 82.73962, mean: 0.09092
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02013, current rewards: 88.13689, mean: 0.09181
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02013, current rewards: 93.53096, mean: 0.09260
[32m[0906 13-57-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02013, current rewards: 98.92794, mean: 0.09333
[32m[0906 13-57-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02010, current rewards: 104.32457, mean: 0.09399
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02009, current rewards: 109.72074, mean: 0.09459
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02007, current rewards: 115.11464, mean: 0.09514
[32m[0906 13-57-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02005, current rewards: 120.51002, mean: 0.09564
[32m[0906 13-57-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02002, current rewards: 125.90555, mean: 0.09611
[32m[0906 13-57-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01999, current rewards: 131.30190, mean: 0.09655
[32m[0906 13-57-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01997, current rewards: 135.80557, mean: 0.09632
[32m[0906 13-57-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01995, current rewards: 141.65534, mean: 0.09702
[32m[0906 13-57-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01993, current rewards: 147.51278, mean: 0.09769
[32m[0906 13-57-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01991, current rewards: 153.36784, mean: 0.09831
[32m[0906 13-57-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01989, current rewards: 159.23068, mean: 0.09890
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01987, current rewards: 165.08941, mean: 0.09945
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01986, current rewards: 170.95288, mean: 0.09997
[32m[0906 13-57-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01984, current rewards: 176.80656, mean: 0.10046
[32m[0906 13-57-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01983, current rewards: 182.66766, mean: 0.10092
[32m[0906 13-57-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01981, current rewards: 188.52581, mean: 0.10136
[32m[0906 13-57-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01979, current rewards: 194.38198, mean: 0.10177
[32m[0906 13-57-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01978, current rewards: 200.06275, mean: 0.10207
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01977, current rewards: 205.71093, mean: 0.10234
[32m[0906 13-57-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01976, current rewards: 211.36320, mean: 0.10260
[32m[0906 13-57-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01974, current rewards: 217.01377, mean: 0.10285
[32m[0906 13-57-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01973, current rewards: 222.66578, mean: 0.10309
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01972, current rewards: 228.31613, mean: 0.10331
[32m[0906 13-57-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01971, current rewards: 233.97170, mean: 0.10353
[32m[0906 13-57-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01970, current rewards: 239.62451, mean: 0.10373
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01970, current rewards: 245.39182, mean: 0.10398
[32m[0906 13-57-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01968, current rewards: 251.15581, mean: 0.10421
[32m[0906 13-57-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01968, current rewards: 256.81636, mean: 0.10440
[32m[0906 13-57-38 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 13-57-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-57-38 @MBExp.py:227][0m Rewards obtained: [261.3462074248201], Lows: [1], Highs: [2], Total time: 752.8705960000002
[32m[0906 13-58-14 @MBExp.py:144][0m ####################################################################
[32m[0906 13-58-14 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01991, current rewards: 0.01404, mean: 0.00140
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02008, current rewards: 5.51724, mean: 0.09195
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02010, current rewards: 11.01183, mean: 0.10011
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02008, current rewards: 16.50468, mean: 0.10315
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02009, current rewards: 22.00312, mean: 0.10478
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02014, current rewards: 27.49973, mean: 0.10577
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02012, current rewards: 32.95235, mean: 0.10630
[32m[0906 13-58-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02009, current rewards: 38.42160, mean: 0.10673
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02007, current rewards: 43.89289, mean: 0.10706
[32m[0906 13-58-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02007, current rewards: 49.36407, mean: 0.10731
[32m[0906 13-58-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02007, current rewards: 54.83800, mean: 0.10753
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02007, current rewards: 60.31662, mean: 0.10771
[32m[0906 13-58-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02009, current rewards: 65.82439, mean: 0.10791
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02009, current rewards: 71.33214, mean: 0.10808
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02009, current rewards: 76.88634, mean: 0.10829
[32m[0906 13-58-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02010, current rewards: 82.42643, mean: 0.10846
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02009, current rewards: 88.00723, mean: 0.10865
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02008, current rewards: 93.53576, mean: 0.10876
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02008, current rewards: 99.06303, mean: 0.10886
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02008, current rewards: 104.59375, mean: 0.10895
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02008, current rewards: 110.12511, mean: 0.10903
[32m[0906 13-58-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02008, current rewards: 115.65282, mean: 0.10911
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02008, current rewards: 121.17291, mean: 0.10916
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02006, current rewards: 126.59698, mean: 0.10914
[32m[0906 13-58-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02002, current rewards: 132.11871, mean: 0.10919
[32m[0906 13-58-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 137.63082, mean: 0.10923
[32m[0906 13-58-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01997, current rewards: 143.15063, mean: 0.10928
[32m[0906 13-58-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01995, current rewards: 148.66420, mean: 0.10931
[32m[0906 13-58-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01993, current rewards: 154.17288, mean: 0.10934
[32m[0906 13-58-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01991, current rewards: 159.68652, mean: 0.10937
[32m[0906 13-58-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01990, current rewards: 165.20352, mean: 0.10941
[32m[0906 13-58-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01988, current rewards: 170.84157, mean: 0.10951
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01986, current rewards: 176.35865, mean: 0.10954
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01984, current rewards: 181.86983, mean: 0.10956
[32m[0906 13-58-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01982, current rewards: 187.37812, mean: 0.10958
[32m[0906 13-58-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01981, current rewards: 192.89162, mean: 0.10960
[32m[0906 13-58-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01979, current rewards: 198.39726, mean: 0.10961
[32m[0906 13-58-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01977, current rewards: 203.90872, mean: 0.10963
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01976, current rewards: 209.75696, mean: 0.10982
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01974, current rewards: 217.83125, mean: 0.11114
[32m[0906 13-58-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01973, current rewards: 219.49471, mean: 0.10920
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01972, current rewards: 225.02672, mean: 0.10924
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01970, current rewards: 230.55663, mean: 0.10927
[32m[0906 13-58-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01970, current rewards: 236.08812, mean: 0.10930
[32m[0906 13-58-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01969, current rewards: 241.53422, mean: 0.10929
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01968, current rewards: 246.99832, mean: 0.10929
[32m[0906 13-59-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01967, current rewards: 252.46324, mean: 0.10929
[32m[0906 13-59-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01965, current rewards: 257.92691, mean: 0.10929
[32m[0906 13-59-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01965, current rewards: 263.39582, mean: 0.10929
[32m[0906 13-59-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01964, current rewards: 268.86622, mean: 0.10930
[32m[0906 13-59-04 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 13-59-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-59-04 @MBExp.py:227][0m Rewards obtained: [273.2435095349081], Lows: [0], Highs: [4], Total time: 802.6340260000002
[32m[0906 13-59-41 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-41 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02022, current rewards: 1.08761, mean: 0.10876
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02014, current rewards: 6.64065, mean: 0.11068
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02019, current rewards: 12.19296, mean: 0.11085
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02013, current rewards: 17.74767, mean: 0.11092
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02014, current rewards: 23.30037, mean: 0.11095
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02015, current rewards: 28.85324, mean: 0.11097
[32m[0906 13-59-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02014, current rewards: 34.35667, mean: 0.11083
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02013, current rewards: 39.92642, mean: 0.11091
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02014, current rewards: 45.51297, mean: 0.11101
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02013, current rewards: 51.09781, mean: 0.11108
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02014, current rewards: 56.69067, mean: 0.11116
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02015, current rewards: 62.28017, mean: 0.11121
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02014, current rewards: 67.86892, mean: 0.11126
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02012, current rewards: 73.46184, mean: 0.11131
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02013, current rewards: 79.05044, mean: 0.11134
[32m[0906 13-59-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02011, current rewards: 84.65248, mean: 0.11138
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02010, current rewards: 90.12192, mean: 0.11126
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02010, current rewards: 95.59429, mean: 0.11116
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02010, current rewards: 101.05295, mean: 0.11105
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02010, current rewards: 106.53595, mean: 0.11097
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02011, current rewards: 112.01813, mean: 0.11091
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02011, current rewards: 117.49970, mean: 0.11085
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02010, current rewards: 122.98433, mean: 0.11080
[32m[0906 14-00-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02007, current rewards: 128.43675, mean: 0.11072
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02003, current rewards: 133.92128, mean: 0.11068
[32m[0906 14-00-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 139.38890, mean: 0.11063
[32m[0906 14-00-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01997, current rewards: 144.84049, mean: 0.11057
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01994, current rewards: 150.29136, mean: 0.11051
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01992, current rewards: 155.74080, mean: 0.11045
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01990, current rewards: 161.19482, mean: 0.11041
[32m[0906 14-00-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01988, current rewards: 166.64837, mean: 0.11036
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01987, current rewards: 172.05193, mean: 0.11029
[32m[0906 14-00-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01985, current rewards: 177.55673, mean: 0.11028
[32m[0906 14-00-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01983, current rewards: 183.10124, mean: 0.11030
[32m[0906 14-00-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01982, current rewards: 188.64208, mean: 0.11032
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01981, current rewards: 194.18179, mean: 0.11033
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01979, current rewards: 199.72868, mean: 0.11035
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01978, current rewards: 205.27206, mean: 0.11036
[32m[0906 14-00-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01977, current rewards: 210.81301, mean: 0.11037
[32m[0906 14-00-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01976, current rewards: 216.35811, mean: 0.11039
[32m[0906 14-00-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01974, current rewards: 221.97452, mean: 0.11044
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01973, current rewards: 227.51127, mean: 0.11044
[32m[0906 14-00-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01972, current rewards: 233.04347, mean: 0.11045
[32m[0906 14-00-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01971, current rewards: 238.49505, mean: 0.11041
[32m[0906 14-00-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01970, current rewards: 243.90773, mean: 0.11037
[32m[0906 14-00-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01969, current rewards: 249.32456, mean: 0.11032
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01968, current rewards: 254.74279, mean: 0.11028
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01967, current rewards: 260.16268, mean: 0.11024
[32m[0906 14-00-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01967, current rewards: 265.52374, mean: 0.11018
[32m[0906 14-00-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01966, current rewards: 270.92720, mean: 0.11013
[32m[0906 14-00-31 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-00-31 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-00-31 @MBExp.py:227][0m Rewards obtained: [275.2470948651402], Lows: [0], Highs: [0], Total time: 852.4543050000002
[32m[0906 14-01-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-11 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-01-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01997, current rewards: 1.12762, mean: 0.11276
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01994, current rewards: 6.67985, mean: 0.11133
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01998, current rewards: 12.24679, mean: 0.11133
[32m[0906 14-01-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02000, current rewards: 17.81464, mean: 0.11134
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02003, current rewards: 23.38569, mean: 0.11136
[32m[0906 14-01-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02003, current rewards: 28.95228, mean: 0.11135
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02000, current rewards: 34.53842, mean: 0.11141
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01999, current rewards: 40.11106, mean: 0.11142
[32m[0906 14-01-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01999, current rewards: 45.65504, mean: 0.11135
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02001, current rewards: 51.20056, mean: 0.11131
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02004, current rewards: 56.73423, mean: 0.11124
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02003, current rewards: 62.14048, mean: 0.11097
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02003, current rewards: 67.54321, mean: 0.11073
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02002, current rewards: 72.94687, mean: 0.11053
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02003, current rewards: 78.35233, mean: 0.11036
[32m[0906 14-01-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02002, current rewards: 83.95091, mean: 0.11046
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02002, current rewards: 89.89155, mean: 0.11098
[32m[0906 14-01-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02003, current rewards: 95.83441, mean: 0.11144
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02003, current rewards: 101.77373, mean: 0.11184
[32m[0906 14-01-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02003, current rewards: 107.70956, mean: 0.11220
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02003, current rewards: 113.65335, mean: 0.11253
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02003, current rewards: 119.59199, mean: 0.11282
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02001, current rewards: 125.14714, mean: 0.11275
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01998, current rewards: 130.68441, mean: 0.11266
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01995, current rewards: 136.27582, mean: 0.11262
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: 141.86885, mean: 0.11259
[32m[0906 14-01-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01990, current rewards: 147.46713, mean: 0.11257
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01988, current rewards: 153.06219, mean: 0.11255
[32m[0906 14-01-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01986, current rewards: 158.65598, mean: 0.11252
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01984, current rewards: 164.24644, mean: 0.11250
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01982, current rewards: 169.83660, mean: 0.11247
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01980, current rewards: 175.39760, mean: 0.11243
[32m[0906 14-01-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01979, current rewards: 180.62300, mean: 0.11219
[32m[0906 14-01-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01976, current rewards: 185.84813, mean: 0.11196
[32m[0906 14-01-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01975, current rewards: 191.07330, mean: 0.11174
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01973, current rewards: 196.29876, mean: 0.11153
[32m[0906 14-01-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01972, current rewards: 201.52407, mean: 0.11134
[32m[0906 14-01-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01971, current rewards: 206.74920, mean: 0.11116
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01969, current rewards: 211.97463, mean: 0.11098
[32m[0906 14-01-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01968, current rewards: 217.28000, mean: 0.11086
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01969, current rewards: 222.95236, mean: 0.11092
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01967, current rewards: 228.62562, mean: 0.11098
[32m[0906 14-01-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01966, current rewards: 233.14876, mean: 0.11050
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01965, current rewards: 238.64748, mean: 0.11048
[32m[0906 14-01-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01965, current rewards: 244.15189, mean: 0.11048
[32m[0906 14-01-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01964, current rewards: 249.65747, mean: 0.11047
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01963, current rewards: 255.16393, mean: 0.11046
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01962, current rewards: 260.62476, mean: 0.11043
[32m[0906 14-01-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01961, current rewards: 266.11047, mean: 0.11042
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01960, current rewards: 271.59403, mean: 0.11040
[32m[0906 14-02-01 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-02-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-02-01 @MBExp.py:227][0m Rewards obtained: [275.9890852810522], Lows: [0], Highs: [1], Total time: 902.1406610000003
[32m[0906 14-02-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-43 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02132, current rewards: 1.04104, mean: 0.10410
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02015, current rewards: 6.51253, mean: 0.10854
[32m[0906 14-02-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02010, current rewards: 11.98287, mean: 0.10894
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02011, current rewards: 17.45755, mean: 0.10911
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02012, current rewards: 22.93299, mean: 0.10920
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02011, current rewards: 28.40811, mean: 0.10926
[32m[0906 14-02-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02014, current rewards: 33.89660, mean: 0.10934
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02016, current rewards: 39.36996, mean: 0.10936
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02017, current rewards: 44.84476, mean: 0.10938
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02016, current rewards: 50.32595, mean: 0.10940
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02017, current rewards: 55.80564, mean: 0.10942
[32m[0906 14-02-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02016, current rewards: 61.28943, mean: 0.10945
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02014, current rewards: 66.77004, mean: 0.10946
[32m[0906 14-02-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02013, current rewards: 72.22314, mean: 0.10943
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02014, current rewards: 77.76579, mean: 0.10953
[32m[0906 14-02-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02013, current rewards: 83.30577, mean: 0.10961
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02014, current rewards: 88.84615, mean: 0.10969
[32m[0906 14-03-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02013, current rewards: 94.38821, mean: 0.10975
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02013, current rewards: 99.93118, mean: 0.10981
[32m[0906 14-03-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02012, current rewards: 105.47587, mean: 0.10987
[32m[0906 14-03-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02009, current rewards: 111.02249, mean: 0.10992
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02008, current rewards: 116.56388, mean: 0.10997
[32m[0906 14-03-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02005, current rewards: 122.08733, mean: 0.10999
[32m[0906 14-03-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02002, current rewards: 127.62526, mean: 0.11002
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01999, current rewards: 133.16723, mean: 0.11006
[32m[0906 14-03-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01996, current rewards: 138.60351, mean: 0.11000
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 144.06775, mean: 0.10998
[32m[0906 14-03-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01991, current rewards: 149.52887, mean: 0.10995
[32m[0906 14-03-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01989, current rewards: 154.99336, mean: 0.10992
[32m[0906 14-03-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01987, current rewards: 160.46001, mean: 0.10990
[32m[0906 14-03-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01985, current rewards: 166.07224, mean: 0.10998
[32m[0906 14-03-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01983, current rewards: 171.55619, mean: 0.10997
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01981, current rewards: 177.04411, mean: 0.10997
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01979, current rewards: 182.52469, mean: 0.10995
[32m[0906 14-03-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01977, current rewards: 188.00685, mean: 0.10995
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01976, current rewards: 193.49090, mean: 0.10994
[32m[0906 14-03-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01974, current rewards: 199.01350, mean: 0.10995
[32m[0906 14-03-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01973, current rewards: 204.52451, mean: 0.10996
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01972, current rewards: 209.99731, mean: 0.10995
[32m[0906 14-03-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01971, current rewards: 215.49630, mean: 0.10995
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01971, current rewards: 220.99385, mean: 0.10995
[32m[0906 14-03-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01970, current rewards: 226.49152, mean: 0.10995
[32m[0906 14-03-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01970, current rewards: 231.99337, mean: 0.10995
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01969, current rewards: 237.49061, mean: 0.10995
[32m[0906 14-03-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01968, current rewards: 242.99715, mean: 0.10995
[32m[0906 14-03-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01967, current rewards: 248.49186, mean: 0.10995
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01967, current rewards: 253.95298, mean: 0.10994
[32m[0906 14-03-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01966, current rewards: 259.50154, mean: 0.10996
[32m[0906 14-03-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01965, current rewards: 265.04406, mean: 0.10998
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01964, current rewards: 270.58711, mean: 0.10999
[32m[0906 14-03-32 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-03-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-03-32 @MBExp.py:227][0m Rewards obtained: [275.019516364861], Lows: [0], Highs: [0], Total time: 951.9200560000003
[32m[0906 14-04-17 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-17 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01977, current rewards: 1.04220, mean: 0.10422
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01986, current rewards: 6.56148, mean: 0.10936
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01993, current rewards: 12.08819, mean: 0.10989
[32m[0906 14-04-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01997, current rewards: 17.61387, mean: 0.11009
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01997, current rewards: 23.13879, mean: 0.11018
[32m[0906 14-04-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01996, current rewards: 28.66244, mean: 0.11024
[32m[0906 14-04-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02000, current rewards: 34.18157, mean: 0.11026
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02002, current rewards: 39.69426, mean: 0.11026
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02001, current rewards: 45.21434, mean: 0.11028
[32m[0906 14-04-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02001, current rewards: 50.73696, mean: 0.11030
[32m[0906 14-04-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02000, current rewards: 56.26146, mean: 0.11032
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01999, current rewards: 61.77457, mean: 0.11031
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01998, current rewards: 67.28940, mean: 0.11031
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01999, current rewards: 72.79843, mean: 0.11030
[32m[0906 14-04-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02001, current rewards: 78.31816, mean: 0.11031
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02001, current rewards: 83.97140, mean: 0.11049
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02002, current rewards: 89.62850, mean: 0.11065
[32m[0906 14-04-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02002, current rewards: 95.28854, mean: 0.11080
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02000, current rewards: 100.95206, mean: 0.11094
[32m[0906 14-04-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01999, current rewards: 106.61638, mean: 0.11106
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01997, current rewards: 112.46132, mean: 0.11135
[32m[0906 14-04-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01995, current rewards: 119.57119, mean: 0.11280
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01994, current rewards: 127.22627, mean: 0.11462
[32m[0906 14-04-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01991, current rewards: 134.88135, mean: 0.11628
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01988, current rewards: 142.53643, mean: 0.11780
[32m[0906 14-04-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01987, current rewards: 119.05777, mean: 0.09449
[32m[0906 14-04-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01984, current rewards: 69.05777, mean: 0.05272
[32m[0906 14-04-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01982, current rewards: 19.05777, mean: 0.01401
[32m[0906 14-04-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01980, current rewards: -30.94223, mean: -0.02194
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01979, current rewards: -80.94223, mean: -0.05544
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01976, current rewards: -130.94223, mean: -0.08672
[32m[0906 14-04-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01975, current rewards: -180.94223, mean: -0.11599
[32m[0906 14-04-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01973, current rewards: -230.94223, mean: -0.14344
[32m[0906 14-04-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01972, current rewards: -280.94223, mean: -0.16924
[32m[0906 14-04-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01971, current rewards: -330.94223, mean: -0.19353
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01970, current rewards: -380.94223, mean: -0.21644
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01969, current rewards: -430.94223, mean: -0.23809
[32m[0906 14-04-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01967, current rewards: -480.94223, mean: -0.25857
[32m[0906 14-04-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01967, current rewards: -530.94223, mean: -0.27798
[32m[0906 14-04-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01966, current rewards: -580.94223, mean: -0.29640
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01965, current rewards: -630.94223, mean: -0.31390
[32m[0906 14-04-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01964, current rewards: -680.94223, mean: -0.33055
[32m[0906 14-04-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01963, current rewards: -730.94223, mean: -0.34642
[32m[0906 14-05-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01963, current rewards: -780.94223, mean: -0.36155
[32m[0906 14-05-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01963, current rewards: -816.17315, mean: -0.36931
[32m[0906 14-05-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01963, current rewards: -813.18777, mean: -0.35982
[32m[0906 14-05-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01962, current rewards: -808.80362, mean: -0.35013
[32m[0906 14-05-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01962, current rewards: -804.41948, mean: -0.34086
[32m[0906 14-05-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01961, current rewards: -800.03534, mean: -0.33196
[32m[0906 14-05-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01960, current rewards: -835.89546, mean: -0.33979
[32m[0906 14-05-06 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-05-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-05-06 @MBExp.py:227][0m Rewards obtained: [-875.8954623753236], Lows: [0], Highs: [1040], Total time: 1001.5880960000003
[32m[0906 14-05-53 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-53 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01973, current rewards: 1.26642, mean: 0.12664
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01997, current rewards: 6.72831, mean: 0.11214
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02003, current rewards: 12.28992, mean: 0.11173
[32m[0906 14-05-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02006, current rewards: 17.85616, mean: 0.11160
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02005, current rewards: 23.42298, mean: 0.11154
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02008, current rewards: 28.98557, mean: 0.11148
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02007, current rewards: 34.55568, mean: 0.11147
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02009, current rewards: 40.12273, mean: 0.11145
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02011, current rewards: 45.69022, mean: 0.11144
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02010, current rewards: 51.25863, mean: 0.11143
[32m[0906 14-06-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02009, current rewards: 56.82737, mean: 0.11143
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 62.39505, mean: 0.11142
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02011, current rewards: 67.95918, mean: 0.11141
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02011, current rewards: 73.52321, mean: 0.11140
[32m[0906 14-06-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02010, current rewards: 79.09353, mean: 0.11140
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02009, current rewards: 84.72404, mean: 0.11148
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02008, current rewards: 90.31496, mean: 0.11150
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02005, current rewards: 95.89288, mean: 0.11150
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02003, current rewards: 101.47249, mean: 0.11151
[32m[0906 14-06-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02001, current rewards: 107.06193, mean: 0.11152
[32m[0906 14-06-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01999, current rewards: 112.72345, mean: 0.11161
[32m[0906 14-06-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01997, current rewards: 118.29047, mean: 0.11159
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01996, current rewards: 123.85242, mean: 0.11158
[32m[0906 14-06-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: 129.41836, mean: 0.11157
[32m[0906 14-06-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01991, current rewards: 134.98615, mean: 0.11156
[32m[0906 14-06-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01989, current rewards: 140.54068, mean: 0.11154
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01986, current rewards: 146.10729, mean: 0.11153
[32m[0906 14-06-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01983, current rewards: 151.67979, mean: 0.11153
[32m[0906 14-06-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01981, current rewards: 157.24991, mean: 0.11152
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01980, current rewards: 162.81595, mean: 0.11152
[32m[0906 14-06-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01978, current rewards: 166.18115, mean: 0.11005
[32m[0906 14-06-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01976, current rewards: 171.64690, mean: 0.11003
[32m[0906 14-06-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01974, current rewards: 177.11229, mean: 0.11001
[32m[0906 14-06-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01973, current rewards: 182.57645, mean: 0.10999
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01972, current rewards: 188.04019, mean: 0.10997
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01970, current rewards: 193.50534, mean: 0.10995
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01968, current rewards: 198.00024, mean: 0.10939
[32m[0906 14-06-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01967, current rewards: 203.60941, mean: 0.10947
[32m[0906 14-06-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01965, current rewards: 209.19352, mean: 0.10953
[32m[0906 14-06-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01964, current rewards: 214.78105, mean: 0.10958
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01963, current rewards: 220.36984, mean: 0.10964
[32m[0906 14-06-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01962, current rewards: 225.95600, mean: 0.10969
[32m[0906 14-06-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01961, current rewards: 231.54278, mean: 0.10974
[32m[0906 14-06-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01960, current rewards: 237.12766, mean: 0.10978
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01959, current rewards: 242.71585, mean: 0.10983
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01960, current rewards: 248.20771, mean: 0.10983
[32m[0906 14-06-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01960, current rewards: 253.75735, mean: 0.10985
[32m[0906 14-06-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01960, current rewards: 259.26757, mean: 0.10986
[32m[0906 14-06-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01959, current rewards: 264.77614, mean: 0.10987
[32m[0906 14-06-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01958, current rewards: 270.28768, mean: 0.10987
[32m[0906 14-06-42 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-06-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-06-42 @MBExp.py:227][0m Rewards obtained: [274.7001646909796], Lows: [1], Highs: [1], Total time: 1051.2096810000003
[32m[0906 14-07-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-31 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02030, current rewards: 1.08972, mean: 0.10897
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02015, current rewards: 6.67482, mean: 0.11125
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02010, current rewards: 12.23177, mean: 0.11120
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02006, current rewards: 17.78133, mean: 0.11113
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02015, current rewards: 23.29950, mean: 0.11095
[32m[0906 14-07-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02016, current rewards: 28.84808, mean: 0.11095
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02013, current rewards: 34.39226, mean: 0.11094
[32m[0906 14-07-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02011, current rewards: 39.94031, mean: 0.11095
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02009, current rewards: 45.48724, mean: 0.11094
[32m[0906 14-07-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02012, current rewards: 51.03520, mean: 0.11095
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02014, current rewards: 56.58577, mean: 0.11095
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02014, current rewards: 62.13672, mean: 0.11096
[32m[0906 14-07-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02014, current rewards: 67.66770, mean: 0.11093
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02014, current rewards: 73.21506, mean: 0.11093
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02013, current rewards: 78.76118, mean: 0.11093
[32m[0906 14-07-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02011, current rewards: 84.30967, mean: 0.11093
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02008, current rewards: 89.81654, mean: 0.11088
[32m[0906 14-07-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02006, current rewards: 95.28710, mean: 0.11080
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02004, current rewards: 100.75669, mean: 0.11072
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02002, current rewards: 106.22952, mean: 0.11066
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02000, current rewards: 111.82487, mean: 0.11072
[32m[0906 14-07-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01998, current rewards: 117.32437, mean: 0.11068
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01996, current rewards: 122.82923, mean: 0.11066
[32m[0906 14-07-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: 128.33498, mean: 0.11063
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01991, current rewards: 133.83842, mean: 0.11061
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01990, current rewards: 139.34288, mean: 0.11059
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01987, current rewards: 145.12455, mean: 0.11078
[32m[0906 14-07-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01986, current rewards: 151.43998, mean: 0.11135
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01984, current rewards: 157.61431, mean: 0.11178
[32m[0906 14-08-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01982, current rewards: 123.57331, mean: 0.08464
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01980, current rewards: 73.57331, mean: 0.04872
[32m[0906 14-08-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01978, current rewards: 23.57331, mean: 0.01511
[32m[0906 14-08-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01976, current rewards: -26.42669, mean: -0.01641
[32m[0906 14-08-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01974, current rewards: -76.42669, mean: -0.04604
[32m[0906 14-08-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01974, current rewards: -103.19539, mean: -0.06035
[32m[0906 14-08-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01972, current rewards: -97.73784, mean: -0.05553
[32m[0906 14-08-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01972, current rewards: -92.27803, mean: -0.05098
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01970, current rewards: -86.77315, mean: -0.04665
[32m[0906 14-08-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01969, current rewards: -81.36363, mean: -0.04260
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01968, current rewards: -75.95468, mean: -0.03875
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01967, current rewards: -70.54674, mean: -0.03510
[32m[0906 14-08-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01966, current rewards: -65.01180, mean: -0.03156
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01966, current rewards: -59.48044, mean: -0.02819
[32m[0906 14-08-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01965, current rewards: -53.94780, mean: -0.02498
[32m[0906 14-08-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01964, current rewards: -48.41720, mean: -0.02191
[32m[0906 14-08-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01963, current rewards: -42.87381, mean: -0.01897
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01963, current rewards: -37.34069, mean: -0.01616
[32m[0906 14-08-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01963, current rewards: -31.75006, mean: -0.01345
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01963, current rewards: -26.20382, mean: -0.01087
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01963, current rewards: -20.65997, mean: -0.00840
[32m[0906 14-08-21 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-08-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-08-21 @MBExp.py:227][0m Rewards obtained: [-16.22104314712667], Lows: [0], Highs: [264], Total time: 1100.9654160000002
[32m[0906 14-09-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-12 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-09-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01974, current rewards: -0.95682, mean: -0.09568
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01972, current rewards: 4.63378, mean: 0.07723
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01980, current rewards: 10.22748, mean: 0.09298
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01989, current rewards: 15.79649, mean: 0.09873
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01995, current rewards: 21.37447, mean: 0.10178
[32m[0906 14-09-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01998, current rewards: 26.96596, mean: 0.10372
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02003, current rewards: 32.56112, mean: 0.10504
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02003, current rewards: 38.15335, mean: 0.10598
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02004, current rewards: 43.76091, mean: 0.10673
[32m[0906 14-09-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02004, current rewards: 49.29725, mean: 0.10717
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02003, current rewards: 54.83400, mean: 0.10752
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02003, current rewards: 60.37217, mean: 0.10781
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02004, current rewards: 65.85234, mean: 0.10795
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02001, current rewards: 71.37903, mean: 0.10815
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01998, current rewards: 76.90527, mean: 0.10832
[32m[0906 14-09-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01996, current rewards: 82.42854, mean: 0.10846
[32m[0906 14-09-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01994, current rewards: 87.95556, mean: 0.10859
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01992, current rewards: 93.48362, mean: 0.10870
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01992, current rewards: 99.04845, mean: 0.10884
[32m[0906 14-09-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01990, current rewards: 104.58088, mean: 0.10894
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01990, current rewards: 110.12053, mean: 0.10903
[32m[0906 14-09-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01989, current rewards: 115.65352, mean: 0.10911
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01988, current rewards: 121.19550, mean: 0.10919
[32m[0906 14-09-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01988, current rewards: 126.73222, mean: 0.10925
[32m[0906 14-09-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01985, current rewards: 132.27135, mean: 0.10932
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01982, current rewards: 137.80340, mean: 0.10937
[32m[0906 14-09-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01980, current rewards: 143.33690, mean: 0.10942
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01978, current rewards: 146.70542, mean: 0.10787
[32m[0906 14-09-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01976, current rewards: 152.22066, mean: 0.10796
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01973, current rewards: 157.71083, mean: 0.10802
[32m[0906 14-09-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01971, current rewards: 163.20018, mean: 0.10808
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01970, current rewards: 168.69114, mean: 0.10814
[32m[0906 14-09-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01969, current rewards: 174.18016, mean: 0.10819
[32m[0906 14-09-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01967, current rewards: 179.66883, mean: 0.10823
[32m[0906 14-09-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01966, current rewards: 185.15777, mean: 0.10828
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01966, current rewards: 190.64673, mean: 0.10832
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01965, current rewards: 196.56910, mean: 0.10860
[32m[0906 14-09-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01964, current rewards: 199.92730, mean: 0.10749
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01963, current rewards: 199.82069, mean: 0.10462
[32m[0906 14-09-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01962, current rewards: 205.34175, mean: 0.10477
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01961, current rewards: 210.85999, mean: 0.10491
[32m[0906 14-09-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01960, current rewards: 216.37634, mean: 0.10504
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01959, current rewards: 221.89414, mean: 0.10516
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01958, current rewards: 227.40910, mean: 0.10528
[32m[0906 14-09-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01957, current rewards: 232.86287, mean: 0.10537
[32m[0906 14-09-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01957, current rewards: 238.28613, mean: 0.10544
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01956, current rewards: 243.79216, mean: 0.10554
[32m[0906 14-09-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01956, current rewards: 249.29473, mean: 0.10563
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01956, current rewards: 254.80345, mean: 0.10573
[32m[0906 14-10-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01956, current rewards: 260.35977, mean: 0.10584
[32m[0906 14-10-01 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-10-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-10-01 @MBExp.py:227][0m Rewards obtained: [264.8125800602411], Lows: [2], Highs: [8], Total time: 1150.5693660000002
[32m[0906 14-10-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-54 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02036, current rewards: 1.21846, mean: 0.12185
[32m[0906 14-10-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01973, current rewards: 6.77152, mean: 0.11286
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01966, current rewards: 12.33096, mean: 0.11210
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01964, current rewards: 17.88818, mean: 0.11180
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01975, current rewards: 23.44449, mean: 0.11164
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01985, current rewards: 29.00472, mean: 0.11156
[32m[0906 14-11-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01990, current rewards: 34.56568, mean: 0.11150
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01994, current rewards: 40.11775, mean: 0.11144
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01996, current rewards: 45.66837, mean: 0.11139
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01997, current rewards: 51.21328, mean: 0.11133
[32m[0906 14-11-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01998, current rewards: 56.76793, mean: 0.11131
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01994, current rewards: 62.31357, mean: 0.11127
[32m[0906 14-11-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01991, current rewards: 67.85829, mean: 0.11124
[32m[0906 14-11-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01990, current rewards: 73.38286, mean: 0.11119
[32m[0906 14-11-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01988, current rewards: 78.90451, mean: 0.11113
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01987, current rewards: 84.42397, mean: 0.11108
[32m[0906 14-11-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01986, current rewards: 89.94550, mean: 0.11104
[32m[0906 14-11-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01985, current rewards: 95.46898, mean: 0.11101
[32m[0906 14-11-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01985, current rewards: 100.98590, mean: 0.11097
[32m[0906 14-11-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01983, current rewards: 106.50387, mean: 0.11094
[32m[0906 14-11-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01982, current rewards: 112.02533, mean: 0.11092
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01982, current rewards: 117.54271, mean: 0.11089
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01980, current rewards: 123.24955, mean: 0.11104
[32m[0906 14-11-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01980, current rewards: 128.80539, mean: 0.11104
[32m[0906 14-11-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01977, current rewards: 134.36115, mean: 0.11104
[32m[0906 14-11-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01975, current rewards: 139.91681, mean: 0.11105
[32m[0906 14-11-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01973, current rewards: 144.32810, mean: 0.11017
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01971, current rewards: 149.85030, mean: 0.11018
[32m[0906 14-11-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01969, current rewards: 155.39880, mean: 0.11021
[32m[0906 14-11-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01968, current rewards: 160.94966, mean: 0.11024
[32m[0906 14-11-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01966, current rewards: 166.50147, mean: 0.11027
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01965, current rewards: 172.01982, mean: 0.11027
[32m[0906 14-11-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01964, current rewards: 177.62538, mean: 0.11033
[32m[0906 14-11-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01963, current rewards: 183.23022, mean: 0.11038
[32m[0906 14-11-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01962, current rewards: 188.83930, mean: 0.11043
[32m[0906 14-11-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01961, current rewards: 194.44723, mean: 0.11048
[32m[0906 14-11-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01960, current rewards: 200.05634, mean: 0.11053
[32m[0906 14-11-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01960, current rewards: 205.66282, mean: 0.11057
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01958, current rewards: 211.27648, mean: 0.11062
[32m[0906 14-11-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01957, current rewards: 216.89414, mean: 0.11066
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01956, current rewards: 222.49292, mean: 0.11069
[32m[0906 14-11-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01955, current rewards: 228.09797, mean: 0.11073
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01955, current rewards: 233.70460, mean: 0.11076
[32m[0906 14-11-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01954, current rewards: 239.31524, mean: 0.11079
[32m[0906 14-11-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01953, current rewards: 244.92015, mean: 0.11082
[32m[0906 14-11-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01953, current rewards: 250.52136, mean: 0.11085
[32m[0906 14-11-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01952, current rewards: 256.12249, mean: 0.11088
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01952, current rewards: 261.73480, mean: 0.11090
[32m[0906 14-11-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01952, current rewards: 267.38975, mean: 0.11095
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01951, current rewards: 272.90983, mean: 0.11094
[32m[0906 14-11-44 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-11-44 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-11-44 @MBExp.py:227][0m Rewards obtained: [277.323853525217], Lows: [0], Highs: [1], Total time: 1200.0297790000002
[32m[0906 14-12-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-39 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-12-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01947, current rewards: 1.05674, mean: 0.10567
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01950, current rewards: 6.52984, mean: 0.10883
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01950, current rewards: 12.03614, mean: 0.10942
[32m[0906 14-12-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01961, current rewards: 17.54599, mean: 0.10966
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01960, current rewards: 23.05489, mean: 0.10979
[32m[0906 14-12-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01961, current rewards: 28.56261, mean: 0.10986
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01965, current rewards: 34.07225, mean: 0.10991
[32m[0906 14-12-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01971, current rewards: 39.57665, mean: 0.10994
[32m[0906 14-12-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01975, current rewards: 45.08745, mean: 0.10997
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01973, current rewards: 50.59891, mean: 0.11000
[32m[0906 14-12-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01972, current rewards: 56.27681, mean: 0.11035
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01971, current rewards: 61.84592, mean: 0.11044
[32m[0906 14-12-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01971, current rewards: 67.40756, mean: 0.11050
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01971, current rewards: 73.06207, mean: 0.11070
[32m[0906 14-12-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01971, current rewards: 78.63371, mean: 0.11075
[32m[0906 14-12-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01972, current rewards: 84.20061, mean: 0.11079
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01971, current rewards: 89.76887, mean: 0.11083
[32m[0906 14-12-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01972, current rewards: 95.33523, mean: 0.11085
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01972, current rewards: 100.77883, mean: 0.11075
[32m[0906 14-12-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01972, current rewards: 106.30795, mean: 0.11074
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01973, current rewards: 111.84276, mean: 0.11074
[32m[0906 14-13-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01972, current rewards: 117.37740, mean: 0.11073
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01972, current rewards: 122.90170, mean: 0.11072
[32m[0906 14-13-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01972, current rewards: 128.43826, mean: 0.11072
[32m[0906 14-13-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01971, current rewards: 133.97402, mean: 0.11072
[32m[0906 14-13-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01970, current rewards: 139.50912, mean: 0.11072
[32m[0906 14-13-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01967, current rewards: 145.04585, mean: 0.11072
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01966, current rewards: 150.54527, mean: 0.11070
[32m[0906 14-13-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01964, current rewards: 156.07718, mean: 0.11069
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01963, current rewards: 161.60411, mean: 0.11069
[32m[0906 14-13-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01962, current rewards: 167.13426, mean: 0.11068
[32m[0906 14-13-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01961, current rewards: 172.65949, mean: 0.11068
[32m[0906 14-13-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01959, current rewards: 178.19163, mean: 0.11068
[32m[0906 14-13-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01958, current rewards: 183.71845, mean: 0.11067
[32m[0906 14-13-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01958, current rewards: 189.20339, mean: 0.11065
[32m[0906 14-13-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01957, current rewards: 194.76320, mean: 0.11066
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01956, current rewards: 200.26470, mean: 0.11064
[32m[0906 14-13-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01955, current rewards: 205.76312, mean: 0.11063
[32m[0906 14-13-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01954, current rewards: 211.26691, mean: 0.11061
[32m[0906 14-13-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01953, current rewards: 216.76561, mean: 0.11059
[32m[0906 14-13-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01952, current rewards: 222.26357, mean: 0.11058
[32m[0906 14-13-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01951, current rewards: 227.76065, mean: 0.11056
[32m[0906 14-13-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01951, current rewards: 233.38004, mean: 0.11061
[32m[0906 14-13-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01950, current rewards: 238.99901, mean: 0.11065
[32m[0906 14-13-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01950, current rewards: 244.65089, mean: 0.11070
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01949, current rewards: 250.30144, mean: 0.11075
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01949, current rewards: 255.95015, mean: 0.11080
[32m[0906 14-13-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01949, current rewards: 261.60000, mean: 0.11085
[32m[0906 14-13-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01948, current rewards: 267.25334, mean: 0.11089
[32m[0906 14-13-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01949, current rewards: 272.90349, mean: 0.11094
[32m[0906 14-13-28 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-13-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-13-28 @MBExp.py:227][0m Rewards obtained: [277.4273279624465], Lows: [0], Highs: [0], Total time: 1249.4259520000003
[32m[0906 14-14-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-14-26 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: 0.09570, mean: 0.00957
[32m[0906 14-14-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01979, current rewards: 5.63451, mean: 0.09391
[32m[0906 14-14-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01972, current rewards: 11.13700, mean: 0.10125
[32m[0906 14-14-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01975, current rewards: 16.66480, mean: 0.10416
[32m[0906 14-14-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01974, current rewards: 22.19732, mean: 0.10570
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01973, current rewards: 27.72826, mean: 0.10665
[32m[0906 14-14-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01972, current rewards: 33.25830, mean: 0.10728
[32m[0906 14-14-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01966, current rewards: 38.78894, mean: 0.10775
[32m[0906 14-14-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01960, current rewards: 44.31421, mean: 0.10808
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01961, current rewards: 49.92670, mean: 0.10854
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01961, current rewards: 55.59782, mean: 0.10902
[32m[0906 14-14-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01962, current rewards: 61.16150, mean: 0.10922
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01962, current rewards: 66.72850, mean: 0.10939
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01963, current rewards: 72.29228, mean: 0.10953
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01963, current rewards: 77.85566, mean: 0.10966
[32m[0906 14-14-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01964, current rewards: 83.42236, mean: 0.10977
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01964, current rewards: 88.98380, mean: 0.10986
[32m[0906 14-14-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01964, current rewards: 94.60213, mean: 0.11000
[32m[0906 14-14-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01964, current rewards: 100.12432, mean: 0.11003
[32m[0906 14-14-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01966, current rewards: 105.67453, mean: 0.11008
[32m[0906 14-14-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01966, current rewards: 111.22447, mean: 0.11012
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01967, current rewards: 116.76664, mean: 0.11016
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01968, current rewards: 120.26221, mean: 0.10834
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01968, current rewards: 125.93243, mean: 0.10856
[32m[0906 14-14-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01966, current rewards: 131.60407, mean: 0.10876
[32m[0906 14-14-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01965, current rewards: 137.27519, mean: 0.10895
[32m[0906 14-14-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01963, current rewards: 142.97406, mean: 0.10914
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01962, current rewards: 148.64714, mean: 0.10930
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01961, current rewards: 154.30420, mean: 0.10944
[32m[0906 14-14-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01959, current rewards: 159.95641, mean: 0.10956
[32m[0906 14-14-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01959, current rewards: 165.61152, mean: 0.10968
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01958, current rewards: 171.26478, mean: 0.10979
[32m[0906 14-14-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01957, current rewards: 176.91723, mean: 0.10989
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01956, current rewards: 181.50533, mean: 0.10934
[32m[0906 14-15-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01954, current rewards: 187.06281, mean: 0.10939
[32m[0906 14-15-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01953, current rewards: 192.70434, mean: 0.10949
[32m[0906 14-15-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01952, current rewards: 198.31160, mean: 0.10956
[32m[0906 14-15-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01951, current rewards: 203.92029, mean: 0.10963
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01951, current rewards: 209.53171, mean: 0.10970
[32m[0906 14-15-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01951, current rewards: 215.21529, mean: 0.10980
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01951, current rewards: 220.79827, mean: 0.10985
[32m[0906 14-15-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01950, current rewards: 226.37691, mean: 0.10989
[32m[0906 14-15-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01950, current rewards: 231.96042, mean: 0.10993
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01950, current rewards: 237.51741, mean: 0.10996
[32m[0906 14-15-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01950, current rewards: 243.07269, mean: 0.10999
[32m[0906 14-15-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01949, current rewards: 248.65648, mean: 0.11002
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01949, current rewards: 254.23762, mean: 0.11006
[32m[0906 14-15-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01948, current rewards: 259.82682, mean: 0.11010
[32m[0906 14-15-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01948, current rewards: 265.40850, mean: 0.11013
[32m[0906 14-15-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01947, current rewards: 270.99638, mean: 0.11016
[32m[0906 14-15-15 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-15-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-15-15 @MBExp.py:227][0m Rewards obtained: [275.4625161132254], Lows: [1], Highs: [2], Total time: 1298.7794610000003
[32m[0906 14-16-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-16-15 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-16-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 0.03013, mean: 0.00301
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01945, current rewards: 5.57764, mean: 0.09296
[32m[0906 14-16-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01956, current rewards: 11.13163, mean: 0.10120
[32m[0906 14-16-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01958, current rewards: 16.68366, mean: 0.10427
[32m[0906 14-16-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01960, current rewards: 22.23077, mean: 0.10586
[32m[0906 14-16-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01952, current rewards: 27.78946, mean: 0.10688
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01944, current rewards: 33.33472, mean: 0.10753
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01940, current rewards: 38.88430, mean: 0.10801
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01938, current rewards: 44.42776, mean: 0.10836
[32m[0906 14-16-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01937, current rewards: 49.94670, mean: 0.10858
[32m[0906 14-16-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01935, current rewards: 55.48038, mean: 0.10879
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01938, current rewards: 61.02315, mean: 0.10897
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01941, current rewards: 66.55322, mean: 0.10910
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01941, current rewards: 72.09559, mean: 0.10924
[32m[0906 14-16-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01943, current rewards: 77.63053, mean: 0.10934
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01944, current rewards: 83.16932, mean: 0.10943
[32m[0906 14-16-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01946, current rewards: 88.71356, mean: 0.10952
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01948, current rewards: 94.27047, mean: 0.10962
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01948, current rewards: 99.80474, mean: 0.10968
[32m[0906 14-16-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01949, current rewards: 105.34738, mean: 0.10974
[32m[0906 14-16-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01950, current rewards: 110.88184, mean: 0.10978
[32m[0906 14-16-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01950, current rewards: 116.41010, mean: 0.10982
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01950, current rewards: 121.94618, mean: 0.10986
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01951, current rewards: 127.49094, mean: 0.10991
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01950, current rewards: 133.02773, mean: 0.10994
[32m[0906 14-16-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01949, current rewards: 138.56529, mean: 0.10997
[32m[0906 14-16-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01948, current rewards: 144.17436, mean: 0.11006
[32m[0906 14-16-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01948, current rewards: 149.75541, mean: 0.11011
[32m[0906 14-16-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01946, current rewards: 155.33819, mean: 0.11017
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01946, current rewards: 160.91354, mean: 0.11021
[32m[0906 14-16-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01946, current rewards: 166.49154, mean: 0.11026
[32m[0906 14-16-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01945, current rewards: 172.06817, mean: 0.11030
[32m[0906 14-16-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01944, current rewards: 177.65094, mean: 0.11034
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01943, current rewards: 183.22733, mean: 0.11038
[32m[0906 14-16-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01942, current rewards: 188.67017, mean: 0.11033
[32m[0906 14-16-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01942, current rewards: 194.26052, mean: 0.11038
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01942, current rewards: 199.77915, mean: 0.11038
[32m[0906 14-16-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01941, current rewards: 205.30953, mean: 0.11038
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01941, current rewards: 210.83486, mean: 0.11038
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01941, current rewards: 216.36015, mean: 0.11039
[32m[0906 14-16-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01940, current rewards: 221.88574, mean: 0.11039
[32m[0906 14-16-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01940, current rewards: 227.41233, mean: 0.11039
[32m[0906 14-16-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01940, current rewards: 232.93811, mean: 0.11040
[32m[0906 14-16-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01940, current rewards: 238.63266, mean: 0.11048
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01939, current rewards: 244.09683, mean: 0.11045
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01939, current rewards: 249.55951, mean: 0.11042
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01939, current rewards: 255.02130, mean: 0.11040
[32m[0906 14-17-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01939, current rewards: 260.48406, mean: 0.11037
[32m[0906 14-17-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01939, current rewards: 265.94990, mean: 0.11035
[32m[0906 14-17-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01939, current rewards: 271.41164, mean: 0.11033
[32m[0906 14-17-04 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-17-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-17-04 @MBExp.py:227][0m Rewards obtained: [275.8534642823767], Lows: [0], Highs: [1], Total time: 1347.9198830000003
[32m[0906 14-18-06 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-06 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01982, current rewards: 1.07743, mean: 0.10774
[32m[0906 14-18-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01965, current rewards: 6.67359, mean: 0.11123
[32m[0906 14-18-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01976, current rewards: 12.20271, mean: 0.11093
[32m[0906 14-18-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01967, current rewards: 17.73245, mean: 0.11083
[32m[0906 14-18-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01961, current rewards: 23.25713, mean: 0.11075
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01953, current rewards: 28.78025, mean: 0.11069
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01947, current rewards: 34.30690, mean: 0.11067
[32m[0906 14-18-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01943, current rewards: 39.83304, mean: 0.11065
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01942, current rewards: 45.36209, mean: 0.11064
[32m[0906 14-18-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01943, current rewards: 50.83942, mean: 0.11052
[32m[0906 14-18-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01941, current rewards: 56.36525, mean: 0.11052
[32m[0906 14-18-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01941, current rewards: 59.80077, mean: 0.10679
[32m[0906 14-18-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01941, current rewards: 65.35352, mean: 0.10714
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01944, current rewards: 70.90881, mean: 0.10744
[32m[0906 14-18-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01945, current rewards: 76.46619, mean: 0.10770
[32m[0906 14-18-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01947, current rewards: 82.02091, mean: 0.10792
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01949, current rewards: 87.57301, mean: 0.10811
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01951, current rewards: 93.07204, mean: 0.10822
[32m[0906 14-18-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01955, current rewards: 98.67782, mean: 0.10844
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01956, current rewards: 104.27996, mean: 0.10862
[32m[0906 14-18-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01956, current rewards: 109.87849, mean: 0.10879
[32m[0906 14-18-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01956, current rewards: 115.47935, mean: 0.10894
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01957, current rewards: 121.07702, mean: 0.10908
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01958, current rewards: 126.68116, mean: 0.10921
[32m[0906 14-18-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01957, current rewards: 132.17630, mean: 0.10924
[32m[0906 14-18-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01955, current rewards: 137.70838, mean: 0.10929
[32m[0906 14-18-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01954, current rewards: 143.25140, mean: 0.10935
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01953, current rewards: 148.78633, mean: 0.10940
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01952, current rewards: 154.32504, mean: 0.10945
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01950, current rewards: 159.85752, mean: 0.10949
[32m[0906 14-18-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01950, current rewards: 165.39997, mean: 0.10954
[32m[0906 14-18-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01950, current rewards: 170.93916, mean: 0.10958
[32m[0906 14-18-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01949, current rewards: 176.48320, mean: 0.10962
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01948, current rewards: 182.03596, mean: 0.10966
[32m[0906 14-18-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01948, current rewards: 187.57810, mean: 0.10969
[32m[0906 14-18-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01947, current rewards: 193.11787, mean: 0.10973
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01946, current rewards: 198.66215, mean: 0.10976
[32m[0906 14-18-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01946, current rewards: 204.20289, mean: 0.10979
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01945, current rewards: 209.73875, mean: 0.10981
[32m[0906 14-18-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01945, current rewards: 215.26133, mean: 0.10983
[32m[0906 14-18-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01944, current rewards: 220.78374, mean: 0.10984
[32m[0906 14-18-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01944, current rewards: 226.33230, mean: 0.10987
[32m[0906 14-18-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01943, current rewards: 231.95193, mean: 0.10993
[32m[0906 14-18-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01943, current rewards: 237.47311, mean: 0.10994
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01943, current rewards: 242.99806, mean: 0.10995
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01942, current rewards: 248.63808, mean: 0.11002
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01942, current rewards: 254.18756, mean: 0.11004
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01941, current rewards: 259.73773, mean: 0.11006
[32m[0906 14-18-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01941, current rewards: 265.28376, mean: 0.11008
[32m[0906 14-18-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01941, current rewards: 270.79972, mean: 0.11008
[32m[0906 14-18-55 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-18-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-18-55 @MBExp.py:227][0m Rewards obtained: [275.2025081369061], Lows: [1], Highs: [0], Total time: 1397.1182940000003
[32m[0906 14-19-59 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-59 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-20-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 1.14965, mean: 0.11496
[32m[0906 14-20-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01934, current rewards: 6.70095, mean: 0.11168
[32m[0906 14-20-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 12.25551, mean: 0.11141
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 17.80854, mean: 0.11130
[32m[0906 14-20-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.36348, mean: 0.11125
[32m[0906 14-20-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.91819, mean: 0.11122
[32m[0906 14-20-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01927, current rewards: 34.46519, mean: 0.11118
[32m[0906 14-20-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 40.01716, mean: 0.11116
[32m[0906 14-20-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.59813, mean: 0.11121
[32m[0906 14-20-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 51.15399, mean: 0.11120
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 56.72069, mean: 0.11122
[32m[0906 14-20-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 62.30976, mean: 0.11127
[32m[0906 14-20-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.90218, mean: 0.11132
[32m[0906 14-20-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01923, current rewards: 73.49579, mean: 0.11136
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 79.08534, mean: 0.11139
[32m[0906 14-20-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 85.06004, mean: 0.11192
[32m[0906 14-20-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 90.78535, mean: 0.11208
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01931, current rewards: 96.51108, mean: 0.11222
[32m[0906 14-20-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01934, current rewards: 102.23792, mean: 0.11235
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01936, current rewards: 107.96301, mean: 0.11246
[32m[0906 14-20-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01937, current rewards: 113.68826, mean: 0.11256
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01939, current rewards: 119.41428, mean: 0.11265
[32m[0906 14-20-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01940, current rewards: 125.13999, mean: 0.11274
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01941, current rewards: 128.58785, mean: 0.11085
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01941, current rewards: 134.20202, mean: 0.11091
[32m[0906 14-20-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01940, current rewards: 139.79530, mean: 0.11095
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01940, current rewards: 145.38297, mean: 0.11098
[32m[0906 14-20-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01939, current rewards: 150.96960, mean: 0.11101
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01938, current rewards: 156.55141, mean: 0.11103
[32m[0906 14-20-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01937, current rewards: 162.10886, mean: 0.11103
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01937, current rewards: 167.66591, mean: 0.11104
[32m[0906 14-20-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01936, current rewards: 173.22257, mean: 0.11104
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01936, current rewards: 178.75709, mean: 0.11103
[32m[0906 14-20-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01935, current rewards: 184.24448, mean: 0.11099
[32m[0906 14-20-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01935, current rewards: 190.04575, mean: 0.11114
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01935, current rewards: 195.60177, mean: 0.11114
[32m[0906 14-20-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01935, current rewards: 201.15809, mean: 0.11114
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01935, current rewards: 206.71528, mean: 0.11114
[32m[0906 14-20-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01935, current rewards: 212.26996, mean: 0.11114
[32m[0906 14-20-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01935, current rewards: 217.82734, mean: 0.11114
[32m[0906 14-20-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01934, current rewards: 223.38124, mean: 0.11113
[32m[0906 14-20-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01935, current rewards: 229.06846, mean: 0.11120
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01934, current rewards: 234.68741, mean: 0.11123
[32m[0906 14-20-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01934, current rewards: 240.30478, mean: 0.11125
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01933, current rewards: 245.92500, mean: 0.11128
[32m[0906 14-20-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01933, current rewards: 251.54564, mean: 0.11130
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01933, current rewards: 257.16447, mean: 0.11133
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01932, current rewards: 262.78061, mean: 0.11135
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01932, current rewards: 268.39844, mean: 0.11137
[32m[0906 14-20-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01932, current rewards: 273.97452, mean: 0.11137
[32m[0906 14-20-48 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-20-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-20-48 @MBExp.py:227][0m Rewards obtained: [278.44413433266254], Lows: [0], Highs: [2], Total time: 1446.0957050000004
[32m[0906 14-21-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-21-54 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-21-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01903, current rewards: 1.04835, mean: 0.10483
[32m[0906 14-21-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01924, current rewards: 6.57753, mean: 0.10963
[32m[0906 14-21-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.10385, mean: 0.11004
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 17.63180, mean: 0.11020
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.16442, mean: 0.11031
[32m[0906 14-21-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 28.69543, mean: 0.11037
[32m[0906 14-22-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.22892, mean: 0.11042
[32m[0906 14-22-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 39.85030, mean: 0.11070
[32m[0906 14-22-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.44589, mean: 0.11084
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 51.03231, mean: 0.11094
[32m[0906 14-22-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.62244, mean: 0.11102
[32m[0906 14-22-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 62.20963, mean: 0.11109
[32m[0906 14-22-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.79443, mean: 0.11114
[32m[0906 14-22-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 73.37953, mean: 0.11118
[32m[0906 14-22-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 78.96744, mean: 0.11122
[32m[0906 14-22-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 84.55202, mean: 0.11125
[32m[0906 14-22-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 90.08277, mean: 0.11121
[32m[0906 14-22-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 95.67405, mean: 0.11125
[32m[0906 14-22-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: 101.24459, mean: 0.11126
[32m[0906 14-22-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01927, current rewards: 106.82357, mean: 0.11127
[32m[0906 14-22-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01929, current rewards: 112.40458, mean: 0.11129
[32m[0906 14-22-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01931, current rewards: 117.98818, mean: 0.11131
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01932, current rewards: 123.56634, mean: 0.11132
[32m[0906 14-22-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01933, current rewards: 129.14916, mean: 0.11134
[32m[0906 14-22-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01934, current rewards: 134.78827, mean: 0.11140
[32m[0906 14-22-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01933, current rewards: 140.38261, mean: 0.11141
[32m[0906 14-22-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01932, current rewards: 145.96731, mean: 0.11143
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01932, current rewards: 151.53226, mean: 0.11142
[32m[0906 14-22-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01931, current rewards: 157.10013, mean: 0.11142
[32m[0906 14-22-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01931, current rewards: 162.66688, mean: 0.11142
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01930, current rewards: 168.23449, mean: 0.11141
[32m[0906 14-22-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01930, current rewards: 173.80757, mean: 0.11142
[32m[0906 14-22-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01931, current rewards: 179.42298, mean: 0.11144
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01931, current rewards: 184.98669, mean: 0.11144
[32m[0906 14-22-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01931, current rewards: 190.54404, mean: 0.11143
[32m[0906 14-22-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01931, current rewards: 196.17032, mean: 0.11146
[32m[0906 14-22-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: 201.74377, mean: 0.11146
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01930, current rewards: 207.32336, mean: 0.11146
[32m[0906 14-22-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01930, current rewards: 212.90090, mean: 0.11147
[32m[0906 14-22-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01930, current rewards: 218.47690, mean: 0.11147
[32m[0906 14-22-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01930, current rewards: 223.96982, mean: 0.11143
[32m[0906 14-22-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01930, current rewards: 229.72848, mean: 0.11152
[32m[0906 14-22-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01930, current rewards: 235.28476, mean: 0.11151
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01930, current rewards: 240.83570, mean: 0.11150
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01930, current rewards: 246.38605, mean: 0.11149
[32m[0906 14-22-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01929, current rewards: 251.93828, mean: 0.11148
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01929, current rewards: 257.48972, mean: 0.11147
[32m[0906 14-22-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01929, current rewards: 263.04167, mean: 0.11146
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01929, current rewards: 268.59673, mean: 0.11145
[32m[0906 14-22-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01929, current rewards: 274.19678, mean: 0.11146
[32m[0906 14-22-43 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-22-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-22-43 @MBExp.py:227][0m Rewards obtained: [278.641083704987], Lows: [0], Highs: [0], Total time: 1495.0258300000005
[32m[0906 14-23-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-52 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-23-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01923, current rewards: 1.09730, mean: 0.10973
[32m[0906 14-23-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01930, current rewards: 6.68060, mean: 0.11134
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 12.22747, mean: 0.11116
[32m[0906 14-23-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01930, current rewards: 17.77047, mean: 0.11107
[32m[0906 14-23-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.31405, mean: 0.11102
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 28.86028, mean: 0.11100
[32m[0906 14-23-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.51047, mean: 0.11132
[32m[0906 14-23-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01926, current rewards: 40.06838, mean: 0.11130
[32m[0906 14-24-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.61114, mean: 0.11125
[32m[0906 14-24-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 51.15367, mean: 0.11120
[32m[0906 14-24-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: 56.70063, mean: 0.11118
[32m[0906 14-24-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 62.24354, mean: 0.11115
[32m[0906 14-24-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 69.15173, mean: 0.11336
[32m[0906 14-24-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 76.80681, mean: 0.11637
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: 84.46189, mean: 0.11896
[32m[0906 14-24-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 90.90069, mean: 0.11961
[32m[0906 14-24-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01926, current rewards: 93.55182, mean: 0.11550
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01926, current rewards: 96.20099, mean: 0.11186
[32m[0906 14-24-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01926, current rewards: 98.85017, mean: 0.10863
[32m[0906 14-24-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01927, current rewards: 101.49934, mean: 0.10573
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01928, current rewards: 104.14852, mean: 0.10312
[32m[0906 14-24-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01930, current rewards: 106.79769, mean: 0.10075
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01932, current rewards: 65.22156, mean: 0.05876
[32m[0906 14-24-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01933, current rewards: 15.22156, mean: 0.01312
[32m[0906 14-24-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01935, current rewards: -34.77844, mean: -0.02874
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01934, current rewards: -84.77844, mean: -0.06728
[32m[0906 14-24-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01934, current rewards: -134.77844, mean: -0.10288
[32m[0906 14-24-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01933, current rewards: -184.77844, mean: -0.13587
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01934, current rewards: -234.77844, mean: -0.16651
[32m[0906 14-24-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01933, current rewards: -284.77844, mean: -0.19505
[32m[0906 14-24-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01932, current rewards: -334.77844, mean: -0.22171
[32m[0906 14-24-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01932, current rewards: -384.77844, mean: -0.24665
[32m[0906 14-24-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01931, current rewards: -434.77844, mean: -0.27005
[32m[0906 14-24-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01931, current rewards: -484.77844, mean: -0.29204
[32m[0906 14-24-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01931, current rewards: -534.77844, mean: -0.31274
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01931, current rewards: -584.77844, mean: -0.33226
[32m[0906 14-24-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: -634.77844, mean: -0.35071
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01930, current rewards: -684.77844, mean: -0.36816
[32m[0906 14-24-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01930, current rewards: -734.77844, mean: -0.38470
[32m[0906 14-24-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01931, current rewards: -784.77844, mean: -0.40040
[32m[0906 14-24-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01930, current rewards: -834.77844, mean: -0.41531
[32m[0906 14-24-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01930, current rewards: -884.77844, mean: -0.42950
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01930, current rewards: -934.77844, mean: -0.44302
[32m[0906 14-24-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01930, current rewards: -984.77844, mean: -0.45592
[32m[0906 14-24-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01930, current rewards: -1034.77844, mean: -0.46823
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01929, current rewards: -1084.77844, mean: -0.47999
[32m[0906 14-24-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01929, current rewards: -1134.77844, mean: -0.49125
[32m[0906 14-24-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01929, current rewards: -1142.80235, mean: -0.48424
[32m[0906 14-24-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01929, current rewards: -1136.54714, mean: -0.47160
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01929, current rewards: -1133.21112, mean: -0.46065
[32m[0906 14-24-41 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-24-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-24-41 @MBExp.py:227][0m Rewards obtained: [-1130.5423035550696], Lows: [0], Highs: [1256], Total time: 1543.9248380000006
[32m[0906 14-25-51 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-51 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01898, current rewards: 1.10789, mean: 0.11079
[32m[0906 14-25-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 6.68342, mean: 0.11139
[32m[0906 14-25-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.25862, mean: 0.11144
[32m[0906 14-25-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.83385, mean: 0.11146
[32m[0906 14-25-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.41330, mean: 0.11149
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 28.99607, mean: 0.11152
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.57410, mean: 0.11153
[32m[0906 14-25-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 40.22972, mean: 0.11175
[32m[0906 14-25-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01914, current rewards: 45.81701, mean: 0.11175
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 51.40837, mean: 0.11176
[32m[0906 14-26-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 57.02931, mean: 0.11182
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 62.63519, mean: 0.11185
[32m[0906 14-26-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 68.24220, mean: 0.11187
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 73.84745, mean: 0.11189
[32m[0906 14-26-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 79.43782, mean: 0.11188
[32m[0906 14-26-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 84.90053, mean: 0.11171
[32m[0906 14-26-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 90.47263, mean: 0.11169
[32m[0906 14-26-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 96.05103, mean: 0.11169
[32m[0906 14-26-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: 101.63132, mean: 0.11168
[32m[0906 14-26-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 107.21295, mean: 0.11168
[32m[0906 14-26-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 112.79517, mean: 0.11168
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 118.37754, mean: 0.11168
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 123.91950, mean: 0.11164
[32m[0906 14-26-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01927, current rewards: 129.48311, mean: 0.11162
[32m[0906 14-26-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01929, current rewards: 135.04220, mean: 0.11161
[32m[0906 14-26-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01928, current rewards: 140.59998, mean: 0.11159
[32m[0906 14-26-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01928, current rewards: 146.15283, mean: 0.11157
[32m[0906 14-26-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01928, current rewards: 151.70822, mean: 0.11155
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01927, current rewards: 157.26379, mean: 0.11153
[32m[0906 14-26-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01927, current rewards: 162.81912, mean: 0.11152
[32m[0906 14-26-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01927, current rewards: 168.38589, mean: 0.11151
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01927, current rewards: 173.95140, mean: 0.11151
[32m[0906 14-26-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01927, current rewards: 179.51407, mean: 0.11150
[32m[0906 14-26-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01927, current rewards: 185.07158, mean: 0.11149
[32m[0906 14-26-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01927, current rewards: 190.61770, mean: 0.11147
[32m[0906 14-26-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01928, current rewards: 196.00345, mean: 0.11137
[32m[0906 14-26-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01928, current rewards: 201.39055, mean: 0.11127
[32m[0906 14-26-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01928, current rewards: 206.77450, mean: 0.11117
[32m[0906 14-26-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01928, current rewards: 212.15367, mean: 0.11108
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01928, current rewards: 217.54065, mean: 0.11099
[32m[0906 14-26-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01929, current rewards: 222.93118, mean: 0.11091
[32m[0906 14-26-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01928, current rewards: 228.32097, mean: 0.11084
[32m[0906 14-26-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01928, current rewards: 233.70917, mean: 0.11076
[32m[0906 14-26-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01928, current rewards: 239.09516, mean: 0.11069
[32m[0906 14-26-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: 244.48262, mean: 0.11063
[32m[0906 14-26-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 249.86718, mean: 0.11056
[32m[0906 14-26-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: 255.25645, mean: 0.11050
[32m[0906 14-26-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01928, current rewards: 260.76558, mean: 0.11049
[32m[0906 14-26-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01928, current rewards: 266.41118, mean: 0.11054
[32m[0906 14-26-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01928, current rewards: 271.99564, mean: 0.11057
[32m[0906 14-26-40 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-26-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-26-40 @MBExp.py:227][0m Rewards obtained: [276.4563831760007], Lows: [0], Highs: [0], Total time: 1592.8115340000006
[32m[0906 14-27-53 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-53 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-27-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01928, current rewards: 1.29285, mean: 0.12928
[32m[0906 14-27-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.74501, mean: 0.11242
[32m[0906 14-27-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.18109, mean: 0.11074
[32m[0906 14-27-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.61805, mean: 0.11011
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.10790, mean: 0.11004
[32m[0906 14-27-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 28.60298, mean: 0.11001
[32m[0906 14-27-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 34.00558, mean: 0.10970
[32m[0906 14-28-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.42182, mean: 0.10951
[32m[0906 14-28-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 44.88300, mean: 0.10947
[32m[0906 14-28-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 50.34002, mean: 0.10943
[32m[0906 14-28-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 55.80284, mean: 0.10942
[32m[0906 14-28-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 61.25900, mean: 0.10939
[32m[0906 14-28-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 66.71378, mean: 0.10937
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 72.21082, mean: 0.10941
[32m[0906 14-28-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01925, current rewards: 77.68826, mean: 0.10942
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01927, current rewards: 83.18113, mean: 0.10945
[32m[0906 14-28-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01926, current rewards: 88.63727, mean: 0.10943
[32m[0906 14-28-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01927, current rewards: 94.09375, mean: 0.10941
[32m[0906 14-28-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01926, current rewards: 99.55032, mean: 0.10940
[32m[0906 14-28-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 105.00626, mean: 0.10938
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: 110.45841, mean: 0.10936
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: 115.91578, mean: 0.10935
[32m[0906 14-28-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01926, current rewards: 121.36873, mean: 0.10934
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01926, current rewards: 126.82277, mean: 0.10933
[32m[0906 14-28-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01929, current rewards: 132.27920, mean: 0.10932
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01928, current rewards: 137.73766, mean: 0.10932
[32m[0906 14-28-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01928, current rewards: 143.19073, mean: 0.10931
[32m[0906 14-28-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01927, current rewards: 148.64859, mean: 0.10930
[32m[0906 14-28-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01927, current rewards: 154.10481, mean: 0.10929
[32m[0906 14-28-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01927, current rewards: 159.54118, mean: 0.10927
[32m[0906 14-28-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01927, current rewards: 165.02775, mean: 0.10929
[32m[0906 14-28-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01927, current rewards: 170.53916, mean: 0.10932
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01927, current rewards: 176.02879, mean: 0.10933
[32m[0906 14-28-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01926, current rewards: 181.51965, mean: 0.10935
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01926, current rewards: 187.01194, mean: 0.10936
[32m[0906 14-28-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01926, current rewards: 192.50744, mean: 0.10938
[32m[0906 14-28-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01925, current rewards: 197.99870, mean: 0.10939
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01926, current rewards: 203.49076, mean: 0.10940
[32m[0906 14-28-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01925, current rewards: 208.98339, mean: 0.10942
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01925, current rewards: 214.51375, mean: 0.10945
[32m[0906 14-28-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01925, current rewards: 220.00893, mean: 0.10946
[32m[0906 14-28-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01926, current rewards: 225.51101, mean: 0.10947
[32m[0906 14-28-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01926, current rewards: 231.09450, mean: 0.10952
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01926, current rewards: 236.61494, mean: 0.10954
[32m[0906 14-28-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01926, current rewards: 242.13726, mean: 0.10956
[32m[0906 14-28-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01927, current rewards: 247.65593, mean: 0.10958
[32m[0906 14-28-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01927, current rewards: 253.17455, mean: 0.10960
[32m[0906 14-28-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01926, current rewards: 258.63272, mean: 0.10959
[32m[0906 14-28-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01926, current rewards: 264.16558, mean: 0.10961
[32m[0906 14-28-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: 269.70137, mean: 0.10963
[32m[0906 14-28-42 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-28-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-28-42 @MBExp.py:227][0m Rewards obtained: [274.1254277965226], Lows: [0], Highs: [0], Total time: 1641.6628420000006
[32m[0906 14-29-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-57 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01932, current rewards: -0.99320, mean: -0.09932
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01946, current rewards: 4.53921, mean: 0.07565
[32m[0906 14-29-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01930, current rewards: 10.07064, mean: 0.09155
[32m[0906 14-30-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01928, current rewards: 15.60111, mean: 0.09751
[32m[0906 14-30-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 21.12983, mean: 0.10062
[32m[0906 14-30-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 26.63625, mean: 0.10245
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 32.13370, mean: 0.10366
[32m[0906 14-30-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 37.65524, mean: 0.10460
[32m[0906 14-30-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 43.16787, mean: 0.10529
[32m[0906 14-30-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 48.67902, mean: 0.10582
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: 54.18906, mean: 0.10625
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 59.71077, mean: 0.10663
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 65.22891, mean: 0.10693
[32m[0906 14-30-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 70.74116, mean: 0.10718
[32m[0906 14-30-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: 76.31305, mean: 0.10748
[32m[0906 14-30-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01927, current rewards: 81.81406, mean: 0.10765
[32m[0906 14-30-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01927, current rewards: 87.41828, mean: 0.10792
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01926, current rewards: 92.89376, mean: 0.10802
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 98.37126, mean: 0.10810
[32m[0906 14-30-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: 103.85101, mean: 0.10818
[32m[0906 14-30-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 109.32899, mean: 0.10825
[32m[0906 14-30-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 114.80709, mean: 0.10831
[32m[0906 14-30-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 120.17504, mean: 0.10827
[32m[0906 14-30-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01924, current rewards: 125.68490, mean: 0.10835
[32m[0906 14-30-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01925, current rewards: 131.20735, mean: 0.10844
[32m[0906 14-30-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01923, current rewards: 136.67399, mean: 0.10847
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01922, current rewards: 142.18091, mean: 0.10854
[32m[0906 14-30-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01922, current rewards: 147.68648, mean: 0.10859
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01923, current rewards: 153.19335, mean: 0.10865
[32m[0906 14-30-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01923, current rewards: 158.70043, mean: 0.10870
[32m[0906 14-30-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01923, current rewards: 164.20624, mean: 0.10875
[32m[0906 14-30-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01923, current rewards: 169.74105, mean: 0.10881
[32m[0906 14-30-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01923, current rewards: 175.24782, mean: 0.10885
[32m[0906 14-30-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01923, current rewards: 180.75827, mean: 0.10889
[32m[0906 14-30-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01923, current rewards: 186.26559, mean: 0.10893
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01923, current rewards: 191.77426, mean: 0.10896
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01923, current rewards: 197.25402, mean: 0.10898
[32m[0906 14-30-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01923, current rewards: 202.77668, mean: 0.10902
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01923, current rewards: 208.29351, mean: 0.10905
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01923, current rewards: 213.90929, mean: 0.10914
[32m[0906 14-30-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01923, current rewards: 219.42497, mean: 0.10917
[32m[0906 14-30-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01923, current rewards: 225.83569, mean: 0.10963
[32m[0906 14-30-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01923, current rewards: 232.44393, mean: 0.11016
[32m[0906 14-30-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01923, current rewards: 239.05216, mean: 0.11067
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01923, current rewards: 245.66040, mean: 0.11116
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01923, current rewards: 252.26863, mean: 0.11162
[32m[0906 14-30-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01923, current rewards: 258.87687, mean: 0.11207
[32m[0906 14-30-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01923, current rewards: 264.65127, mean: 0.11214
[32m[0906 14-30-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01923, current rewards: 270.00402, mean: 0.11203
[32m[0906 14-30-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01923, current rewards: 275.41268, mean: 0.11196
[32m[0906 14-30-45 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-30-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-30-45 @MBExp.py:227][0m Rewards obtained: [279.73901315708963], Lows: [1], Highs: [0], Total time: 1690.4232740000007
[32m[0906 14-32-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-32-02 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01950, current rewards: -1.05653, mean: -0.10565
[32m[0906 14-32-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01923, current rewards: 4.41633, mean: 0.07361
[32m[0906 14-32-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 9.89449, mean: 0.08995
[32m[0906 14-32-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 15.37337, mean: 0.09608
[32m[0906 14-32-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 20.85311, mean: 0.09930
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 26.33198, mean: 0.10128
[32m[0906 14-32-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 31.90430, mean: 0.10292
[32m[0906 14-32-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 37.43141, mean: 0.10398
[32m[0906 14-32-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 42.95899, mean: 0.10478
[32m[0906 14-32-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 50.58710, mean: 0.10997
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 58.66140, mean: 0.11502
[32m[0906 14-32-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 66.73569, mean: 0.11917
[32m[0906 14-32-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 74.80998, mean: 0.12264
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 82.88427, mean: 0.12558
[32m[0906 14-32-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 74.36239, mean: 0.10474
[32m[0906 14-32-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 79.83122, mean: 0.10504
[32m[0906 14-32-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 85.37093, mean: 0.10540
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 90.90985, mean: 0.10571
[32m[0906 14-32-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: 96.44766, mean: 0.10599
[32m[0906 14-32-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 101.98480, mean: 0.10623
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 107.51524, mean: 0.10645
[32m[0906 14-32-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 113.04893, mean: 0.10665
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01920, current rewards: 118.58329, mean: 0.10683
[32m[0906 14-32-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 124.20673, mean: 0.10707
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: 129.79270, mean: 0.10727
[32m[0906 14-32-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 135.37791, mean: 0.10744
[32m[0906 14-32-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 140.91327, mean: 0.10757
[32m[0906 14-32-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 146.45258, mean: 0.10769
[32m[0906 14-32-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 151.98914, mean: 0.10779
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 157.52452, mean: 0.10789
[32m[0906 14-32-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 163.05530, mean: 0.10798
[32m[0906 14-32-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 168.51240, mean: 0.10802
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01917, current rewards: 174.03113, mean: 0.10809
[32m[0906 14-32-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 179.54522, mean: 0.10816
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 185.06720, mean: 0.10823
[32m[0906 14-32-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 190.58247, mean: 0.10829
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 196.10148, mean: 0.10834
[32m[0906 14-32-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 201.61262, mean: 0.10839
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01918, current rewards: 207.13418, mean: 0.10845
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01919, current rewards: 212.62833, mean: 0.10848
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 218.11553, mean: 0.10852
[32m[0906 14-32-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 223.59681, mean: 0.10854
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01920, current rewards: 229.08693, mean: 0.10857
[32m[0906 14-32-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01920, current rewards: 234.57676, mean: 0.10860
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 240.07189, mean: 0.10863
[32m[0906 14-32-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: 245.55455, mean: 0.10865
[32m[0906 14-32-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01920, current rewards: 251.04830, mean: 0.10868
[32m[0906 14-32-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: 256.51537, mean: 0.10869
[32m[0906 14-32-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: 262.03053, mean: 0.10873
[32m[0906 14-32-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01920, current rewards: 267.56518, mean: 0.10877
[32m[0906 14-32-51 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-32-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-32-51 @MBExp.py:227][0m Rewards obtained: [271.9995763053977], Lows: [1], Highs: [13], Total time: 1739.1327640000006
[32m[0906 14-34-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-10 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-34-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 1.10153, mean: 0.11015
[32m[0906 14-34-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 6.69012, mean: 0.11150
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 12.26672, mean: 0.11152
[32m[0906 14-34-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.83854, mean: 0.11149
[32m[0906 14-34-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 23.41351, mean: 0.11149
[32m[0906 14-34-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 28.99184, mean: 0.11151
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 34.61121, mean: 0.11165
[32m[0906 14-34-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: 40.17147, mean: 0.11159
[32m[0906 14-34-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 45.73038, mean: 0.11154
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 51.28256, mean: 0.11148
[32m[0906 14-34-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.83765, mean: 0.11145
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 62.38909, mean: 0.11141
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 67.94622, mean: 0.11139
[32m[0906 14-34-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 73.50320, mean: 0.11137
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 79.06084, mean: 0.11135
[32m[0906 14-34-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.62325, mean: 0.11135
[32m[0906 14-34-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 90.18680, mean: 0.11134
[32m[0906 14-34-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 95.74616, mean: 0.11133
[32m[0906 14-34-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 101.30462, mean: 0.11132
[32m[0906 14-34-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 106.86742, mean: 0.11132
[32m[0906 14-34-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 112.41873, mean: 0.11131
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 117.97542, mean: 0.11130
[32m[0906 14-34-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 123.53157, mean: 0.11129
[32m[0906 14-34-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 129.08744, mean: 0.11128
[32m[0906 14-34-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 134.64027, mean: 0.11127
[32m[0906 14-34-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: 140.15598, mean: 0.11123
[32m[0906 14-34-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 145.72930, mean: 0.11124
[32m[0906 14-34-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 151.29934, mean: 0.11125
[32m[0906 14-34-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 156.86653, mean: 0.11125
[32m[0906 14-34-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 162.43629, mean: 0.11126
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 167.96001, mean: 0.11123
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 173.47420, mean: 0.11120
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 178.99142, mean: 0.11117
[32m[0906 14-34-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 184.50724, mean: 0.11115
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 190.02378, mean: 0.11113
[32m[0906 14-34-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: 195.53831, mean: 0.11110
[32m[0906 14-34-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01912, current rewards: 201.04906, mean: 0.11108
[32m[0906 14-34-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: 205.49445, mean: 0.11048
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01912, current rewards: 210.97747, mean: 0.11046
[32m[0906 14-34-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 216.51680, mean: 0.11047
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 222.04889, mean: 0.11047
[32m[0906 14-34-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 227.58296, mean: 0.11048
[32m[0906 14-34-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 233.11557, mean: 0.11048
[32m[0906 14-34-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 238.65907, mean: 0.11049
[32m[0906 14-34-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 244.19498, mean: 0.11050
[32m[0906 14-34-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 249.72922, mean: 0.11050
[32m[0906 14-34-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 255.28338, mean: 0.11051
[32m[0906 14-34-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 260.81407, mean: 0.11051
[32m[0906 14-34-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 266.34789, mean: 0.11052
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 271.86016, mean: 0.11051
[32m[0906 14-34-59 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-34-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-34-59 @MBExp.py:227][0m Rewards obtained: [276.3135383661166], Lows: [0], Highs: [1], Total time: 1787.7262240000007
[32m[0906 14-36-20 @MBExp.py:144][0m ####################################################################
[32m[0906 14-36-20 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-36-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01966, current rewards: 0.99380, mean: 0.09938
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01944, current rewards: 6.48817, mean: 0.10814
[32m[0906 14-36-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01931, current rewards: 11.98060, mean: 0.10891
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01930, current rewards: 17.47223, mean: 0.10920
[32m[0906 14-36-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 22.96745, mean: 0.10937
[32m[0906 14-36-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01927, current rewards: 28.45753, mean: 0.10945
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01927, current rewards: 33.94845, mean: 0.10951
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01928, current rewards: 39.43931, mean: 0.10955
[32m[0906 14-36-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01928, current rewards: 44.93462, mean: 0.10960
[32m[0906 14-36-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01928, current rewards: 50.42777, mean: 0.10963
[32m[0906 14-36-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01930, current rewards: 55.92157, mean: 0.10965
[32m[0906 14-36-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01929, current rewards: 61.41419, mean: 0.10967
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01928, current rewards: 66.90753, mean: 0.10968
[32m[0906 14-36-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 72.46957, mean: 0.10980
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01928, current rewards: 76.91245, mean: 0.10833
[32m[0906 14-36-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: 82.47021, mean: 0.10851
[32m[0906 14-36-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: 88.02858, mean: 0.10868
[32m[0906 14-36-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 93.58759, mean: 0.10882
[32m[0906 14-36-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01928, current rewards: 99.14640, mean: 0.10895
[32m[0906 14-36-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01928, current rewards: 104.70711, mean: 0.10907
[32m[0906 14-36-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: 110.26781, mean: 0.10918
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01927, current rewards: 115.77672, mean: 0.10922
[32m[0906 14-36-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01928, current rewards: 121.34090, mean: 0.10932
[32m[0906 14-36-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01928, current rewards: 126.91183, mean: 0.10941
[32m[0906 14-36-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01929, current rewards: 132.48728, mean: 0.10949
[32m[0906 14-36-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01927, current rewards: 138.06024, mean: 0.10957
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01925, current rewards: 143.63420, mean: 0.10964
[32m[0906 14-36-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01923, current rewards: 149.20907, mean: 0.10971
[32m[0906 14-36-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01921, current rewards: 154.78336, mean: 0.10978
[32m[0906 14-36-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 160.31875, mean: 0.10981
[32m[0906 14-36-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 165.90791, mean: 0.10987
[32m[0906 14-36-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01914, current rewards: 171.48763, mean: 0.10993
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: 177.07374, mean: 0.10998
[32m[0906 14-36-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 182.65584, mean: 0.11003
[32m[0906 14-36-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 188.23868, mean: 0.11008
[32m[0906 14-36-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 193.82550, mean: 0.11013
[32m[0906 14-36-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 199.41231, mean: 0.11017
[32m[0906 14-36-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01916, current rewards: 205.14075, mean: 0.11029
[32m[0906 14-36-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 210.76145, mean: 0.11035
[32m[0906 14-36-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01916, current rewards: 216.34541, mean: 0.11038
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: 221.92849, mean: 0.11041
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01918, current rewards: 227.51955, mean: 0.11045
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 233.09266, mean: 0.11047
[32m[0906 14-37-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: 238.66362, mean: 0.11049
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01919, current rewards: 244.23534, mean: 0.11051
[32m[0906 14-37-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01919, current rewards: 249.80227, mean: 0.11053
[32m[0906 14-37-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01920, current rewards: 255.32307, mean: 0.11053
[32m[0906 14-37-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01919, current rewards: 260.90833, mean: 0.11055
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: 266.49411, mean: 0.11058
[32m[0906 14-37-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01920, current rewards: 272.07749, mean: 0.11060
[32m[0906 14-37-09 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-37-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-37-09 @MBExp.py:227][0m Rewards obtained: [276.54898541534965], Lows: [0], Highs: [1], Total time: 1836.4297840000006
[32m[0906 14-38-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-38-33 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-38-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02018, current rewards: 1.05378, mean: 0.10538
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01931, current rewards: 6.65900, mean: 0.11098
[32m[0906 14-38-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 12.26360, mean: 0.11149
[32m[0906 14-38-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01931, current rewards: 17.87390, mean: 0.11171
[32m[0906 14-38-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01928, current rewards: 23.44834, mean: 0.11166
[32m[0906 14-38-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 29.04811, mean: 0.11172
[32m[0906 14-38-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01927, current rewards: 34.64885, mean: 0.11177
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 40.24330, mean: 0.11179
[32m[0906 14-38-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.83880, mean: 0.11180
[32m[0906 14-38-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 51.43527, mean: 0.11182
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: 57.03150, mean: 0.11183
[32m[0906 14-38-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01924, current rewards: 62.63145, mean: 0.11184
[32m[0906 14-38-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 68.32518, mean: 0.11201
[32m[0906 14-38-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 74.23251, mean: 0.11247
[32m[0906 14-38-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 80.14808, mean: 0.11288
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 86.06165, mean: 0.11324
[32m[0906 14-38-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 91.97921, mean: 0.11355
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 97.89004, mean: 0.11383
[32m[0906 14-38-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: 103.80297, mean: 0.11407
[32m[0906 14-38-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: 108.40559, mean: 0.11292
[32m[0906 14-38-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01924, current rewards: 114.15179, mean: 0.11302
[32m[0906 14-38-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 119.78136, mean: 0.11300
[32m[0906 14-38-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 125.40716, mean: 0.11298
[32m[0906 14-38-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: 131.03668, mean: 0.11296
[32m[0906 14-38-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01926, current rewards: 136.66998, mean: 0.11295
[32m[0906 14-38-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 142.28820, mean: 0.11293
[32m[0906 14-38-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 147.91257, mean: 0.11291
[32m[0906 14-38-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 153.52909, mean: 0.11289
[32m[0906 14-39-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 159.14569, mean: 0.11287
[32m[0906 14-39-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 164.71419, mean: 0.11282
[32m[0906 14-39-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: 170.31155, mean: 0.11279
[32m[0906 14-39-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01913, current rewards: 175.90689, mean: 0.11276
[32m[0906 14-39-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 181.50363, mean: 0.11274
[32m[0906 14-39-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 187.09827, mean: 0.11271
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: 192.69594, mean: 0.11269
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 198.29397, mean: 0.11267
[32m[0906 14-39-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 203.89030, mean: 0.11265
[32m[0906 14-39-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 209.62481, mean: 0.11270
[32m[0906 14-39-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 215.31876, mean: 0.11273
[32m[0906 14-39-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 221.02318, mean: 0.11277
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 226.72351, mean: 0.11280
[32m[0906 14-39-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 232.38955, mean: 0.11281
[32m[0906 14-39-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 238.01749, mean: 0.11280
[32m[0906 14-39-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 243.65012, mean: 0.11280
[32m[0906 14-39-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01916, current rewards: 249.27568, mean: 0.11279
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01916, current rewards: 254.90336, mean: 0.11279
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01916, current rewards: 260.52763, mean: 0.11278
[32m[0906 14-39-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: 266.18346, mean: 0.11279
[32m[0906 14-39-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01917, current rewards: 271.88118, mean: 0.11281
[32m[0906 14-39-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01917, current rewards: 277.57882, mean: 0.11284
[32m[0906 14-39-21 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-39-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-39-22 @MBExp.py:227][0m Rewards obtained: [282.1353262929204], Lows: [0], Highs: [1], Total time: 1885.0708030000005
[32m[0906 14-40-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-40-47 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 14-40-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01978, current rewards: 1.21013, mean: 0.12101
[32m[0906 14-40-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01931, current rewards: 6.75646, mean: 0.11261
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 12.29657, mean: 0.11179
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01924, current rewards: 17.89094, mean: 0.11182
[32m[0906 14-40-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.43979, mean: 0.11162
[32m[0906 14-40-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 28.98893, mean: 0.11150
[32m[0906 14-40-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 34.56954, mean: 0.11151
[32m[0906 14-40-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 40.11878, mean: 0.11144
[32m[0906 14-40-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01925, current rewards: 45.67354, mean: 0.11140
[32m[0906 14-40-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 51.22857, mean: 0.11137
[32m[0906 14-40-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: 56.77780, mean: 0.11133
[32m[0906 14-40-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 62.32153, mean: 0.11129
[32m[0906 14-40-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 67.87704, mean: 0.11127
[32m[0906 14-41-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 73.42587, mean: 0.11125
[32m[0906 14-41-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 78.97330, mean: 0.11123
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 84.51832, mean: 0.11121
[32m[0906 14-41-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 90.06357, mean: 0.11119
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 95.61079, mean: 0.11118
[32m[0906 14-41-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 101.15304, mean: 0.11116
[32m[0906 14-41-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 106.70713, mean: 0.11115
[32m[0906 14-41-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 112.24367, mean: 0.11113
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 117.76801, mean: 0.11110
[32m[0906 14-41-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 123.29097, mean: 0.11107
[32m[0906 14-41-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: 128.81827, mean: 0.11105
[32m[0906 14-41-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: 134.34388, mean: 0.11103
[32m[0906 14-41-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 139.86902, mean: 0.11101
[32m[0906 14-41-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 145.39297, mean: 0.11099
[32m[0906 14-41-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 150.91388, mean: 0.11097
[32m[0906 14-41-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 156.44200, mean: 0.11095
[32m[0906 14-41-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 161.98902, mean: 0.11095
[32m[0906 14-41-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 167.53675, mean: 0.11095
[32m[0906 14-41-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 173.08224, mean: 0.11095
[32m[0906 14-41-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 178.63412, mean: 0.11095
[32m[0906 14-41-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 184.52574, mean: 0.11116
[32m[0906 14-41-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 190.57100, mean: 0.11145
[32m[0906 14-41-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: 196.61627, mean: 0.11171
[32m[0906 14-41-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01904, current rewards: 177.06362, mean: 0.09783
[32m[0906 14-41-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01905, current rewards: 181.46920, mean: 0.09756
[32m[0906 14-41-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 187.02502, mean: 0.09792
[32m[0906 14-41-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 192.57854, mean: 0.09825
[32m[0906 14-41-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 198.13420, mean: 0.09857
[32m[0906 14-41-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 203.68900, mean: 0.09888
[32m[0906 14-41-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 209.24587, mean: 0.09917
[32m[0906 14-41-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 214.80163, mean: 0.09945
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: 220.36309, mean: 0.09971
[32m[0906 14-41-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 225.91545, mean: 0.09996
[32m[0906 14-41-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 231.41338, mean: 0.10018
[32m[0906 14-41-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01911, current rewards: 236.95558, mean: 0.10040
[32m[0906 14-41-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: 242.49389, mean: 0.10062
[32m[0906 14-41-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 248.03962, mean: 0.10083
[32m[0906 14-41-36 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-41-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-41-36 @MBExp.py:227][0m Rewards obtained: [252.469932219301], Lows: [0], Highs: [23], Total time: 1933.5656400000005
[32m[0906 14-43-04 @MBExp.py:144][0m ####################################################################
[32m[0906 14-43-04 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 14-43-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02122, current rewards: 1.10861, mean: 0.11086
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01944, current rewards: 6.79031, mean: 0.11317
[32m[0906 14-43-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01933, current rewards: 12.33144, mean: 0.11210
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01933, current rewards: 17.72077, mean: 0.11075
[32m[0906 14-43-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01930, current rewards: 23.26856, mean: 0.11080
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01927, current rewards: 28.83207, mean: 0.11089
[32m[0906 14-43-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 34.40845, mean: 0.11100
[32m[0906 14-43-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 39.98008, mean: 0.11106
[32m[0906 14-43-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.54903, mean: 0.11110
[32m[0906 14-43-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 51.12379, mean: 0.11114
[32m[0906 14-43-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: 56.70510, mean: 0.11119
[32m[0906 14-43-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: 62.28906, mean: 0.11123
[32m[0906 14-43-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 67.87935, mean: 0.11128
[32m[0906 14-43-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 73.44493, mean: 0.11128
[32m[0906 14-43-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: 79.01332, mean: 0.11129
[32m[0906 14-43-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01927, current rewards: 84.58193, mean: 0.11129
[32m[0906 14-43-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: 90.15139, mean: 0.11130
[32m[0906 14-43-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 95.70096, mean: 0.11128
[32m[0906 14-43-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 101.23676, mean: 0.11125
[32m[0906 14-43-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01928, current rewards: 106.77142, mean: 0.11122
[32m[0906 14-43-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: 112.39319, mean: 0.11128
[32m[0906 14-43-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01928, current rewards: 117.92720, mean: 0.11125
[32m[0906 14-43-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01928, current rewards: 123.46231, mean: 0.11123
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01927, current rewards: 128.99567, mean: 0.11120
[32m[0906 14-43-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01928, current rewards: 134.53091, mean: 0.11118
[32m[0906 14-43-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01925, current rewards: 140.06219, mean: 0.11116
[32m[0906 14-43-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01923, current rewards: 145.61211, mean: 0.11115
[32m[0906 14-43-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01921, current rewards: 151.15636, mean: 0.11114
[32m[0906 14-43-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: 156.70276, mean: 0.11114
[32m[0906 14-43-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 162.24585, mean: 0.11113
[32m[0906 14-43-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 167.79029, mean: 0.11112
[32m[0906 14-43-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01914, current rewards: 173.33386, mean: 0.11111
[32m[0906 14-43-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 178.90097, mean: 0.11112
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01912, current rewards: 184.41661, mean: 0.11109
[32m[0906 14-43-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 189.92244, mean: 0.11107
[32m[0906 14-43-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: 195.43059, mean: 0.11104
[32m[0906 14-43-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 200.83507, mean: 0.11096
[32m[0906 14-43-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 206.36903, mean: 0.11095
[32m[0906 14-43-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01905, current rewards: 211.88998, mean: 0.11094
[32m[0906 14-43-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01906, current rewards: 217.41824, mean: 0.11093
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 222.94385, mean: 0.11092
[32m[0906 14-43-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: 228.47109, mean: 0.11091
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01907, current rewards: 233.99885, mean: 0.11090
[32m[0906 14-43-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 239.52877, mean: 0.11089
[32m[0906 14-43-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: 245.05180, mean: 0.11088
[32m[0906 14-43-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 250.60821, mean: 0.11089
[32m[0906 14-43-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: 256.08944, mean: 0.11086
[32m[0906 14-43-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 261.56803, mean: 0.11083
[32m[0906 14-43-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 267.04520, mean: 0.11081
[32m[0906 14-43-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 272.52492, mean: 0.11078
[32m[0906 14-43-52 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-43-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-43-52 @MBExp.py:227][0m Rewards obtained: [276.9086718207349], Lows: [0], Highs: [0], Total time: 1982.0646860000004
[32m[0906 14-45-23 @MBExp.py:144][0m ####################################################################
[32m[0906 14-45-23 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 14-45-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.14070, mean: 0.11407
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01931, current rewards: 6.69228, mean: 0.11154
[32m[0906 14-45-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01932, current rewards: 12.20810, mean: 0.11098
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 17.71774, mean: 0.11074
[32m[0906 14-45-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01929, current rewards: 23.23417, mean: 0.11064
[32m[0906 14-45-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 28.80597, mean: 0.11079
[32m[0906 14-45-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 34.37253, mean: 0.11088
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.93910, mean: 0.11094
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01925, current rewards: 45.50567, mean: 0.11099
[32m[0906 14-45-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01924, current rewards: 51.07225, mean: 0.11103
[32m[0906 14-45-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.63884, mean: 0.11106
[32m[0906 14-45-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 62.52706, mean: 0.11166
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01923, current rewards: 46.31632, mean: 0.07593
[32m[0906 14-45-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: -3.68368, mean: -0.00558
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: -53.68368, mean: -0.07561
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01924, current rewards: -103.68368, mean: -0.13643
[32m[0906 14-45-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01924, current rewards: -153.68368, mean: -0.18973
[32m[0906 14-45-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01924, current rewards: -203.68368, mean: -0.23684
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: -253.68368, mean: -0.27877
[32m[0906 14-45-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: -303.68368, mean: -0.31634
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: -353.68368, mean: -0.35018
[32m[0906 14-45-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01925, current rewards: -403.68368, mean: -0.38083
[32m[0906 14-45-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: -453.68368, mean: -0.40872
[32m[0906 14-45-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: -503.68368, mean: -0.43421
[32m[0906 14-45-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01925, current rewards: -553.68368, mean: -0.45759
[32m[0906 14-45-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01922, current rewards: -603.68368, mean: -0.47911
[32m[0906 14-45-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01920, current rewards: -653.68368, mean: -0.49900
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: -703.68368, mean: -0.51741
[32m[0906 14-45-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: -753.68368, mean: -0.53453
[32m[0906 14-45-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01914, current rewards: -803.68368, mean: -0.55047
[32m[0906 14-45-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: -853.68368, mean: -0.56535
[32m[0906 14-45-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: -903.68368, mean: -0.57928
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: -953.68368, mean: -0.59235
[32m[0906 14-45-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: -1003.68368, mean: -0.60463
[32m[0906 14-45-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: -1053.68368, mean: -0.61619
[32m[0906 14-45-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: -1103.68368, mean: -0.62709
[32m[0906 14-45-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: -1153.68368, mean: -0.63739
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: -1203.68368, mean: -0.64714
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01901, current rewards: -1253.68368, mean: -0.65638
[32m[0906 14-46-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01900, current rewards: -1303.68368, mean: -0.66514
[32m[0906 14-46-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01899, current rewards: -1353.68368, mean: -0.67347
[32m[0906 14-46-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: -1403.68368, mean: -0.68140
[32m[0906 14-46-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01899, current rewards: -1453.68368, mean: -0.68895
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01900, current rewards: -1503.68368, mean: -0.69615
[32m[0906 14-46-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01900, current rewards: -1553.68368, mean: -0.70302
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: -1603.68368, mean: -0.70959
[32m[0906 14-46-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01901, current rewards: -1653.68368, mean: -0.71588
[32m[0906 14-46-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01902, current rewards: -1703.68368, mean: -0.72190
[32m[0906 14-46-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01902, current rewards: -1753.68368, mean: -0.72767
[32m[0906 14-46-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01902, current rewards: -1803.68368, mean: -0.73320
[32m[0906 14-46-11 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-46-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-46-11 @MBExp.py:227][0m Rewards obtained: [-1843.6836841328457], Lows: [0], Highs: [1910], Total time: 2030.3290670000004
[32m[0906 14-47-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-47-43 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 14-47-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01950, current rewards: 1.17413, mean: 0.11741
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01931, current rewards: 6.74671, mean: 0.11245
[32m[0906 14-47-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 12.27811, mean: 0.11162
[32m[0906 14-47-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.84042, mean: 0.11150
[32m[0906 14-47-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01924, current rewards: 23.39705, mean: 0.11141
[32m[0906 14-47-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01928, current rewards: 28.96248, mean: 0.11139
[32m[0906 14-47-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01930, current rewards: 34.53202, mean: 0.11139
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01930, current rewards: 40.08889, mean: 0.11136
[32m[0906 14-47-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.64594, mean: 0.11133
[32m[0906 14-47-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01928, current rewards: 51.20173, mean: 0.11131
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: 56.88972, mean: 0.11155
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: 62.47238, mean: 0.11156
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 67.93940, mean: 0.11138
[32m[0906 14-47-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 75.59448, mean: 0.11454
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: 83.24956, mean: 0.11725
[32m[0906 14-47-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 90.90464, mean: 0.11961
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 57.04806, mean: 0.07043
[32m[0906 14-48-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: 7.04806, mean: 0.00820
[32m[0906 14-48-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: -42.95194, mean: -0.04720
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: -60.77557, mean: -0.06331
[32m[0906 14-48-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: -55.19789, mean: -0.05465
[32m[0906 14-48-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: -49.61413, mean: -0.04681
[32m[0906 14-48-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: -44.03442, mean: -0.03967
[32m[0906 14-48-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01924, current rewards: -38.45298, mean: -0.03315
[32m[0906 14-48-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01924, current rewards: -32.87466, mean: -0.02717
[32m[0906 14-48-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01922, current rewards: -27.29774, mean: -0.02166
[32m[0906 14-48-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01920, current rewards: -21.71659, mean: -0.01658
[32m[0906 14-48-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: -16.14372, mean: -0.01187
[32m[0906 14-48-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: -10.48676, mean: -0.00744
[32m[0906 14-48-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: -4.91129, mean: -0.00336
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: 0.66372, mean: 0.00044
[32m[0906 14-48-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 6.24099, mean: 0.00400
[32m[0906 14-48-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 11.81929, mean: 0.00734
[32m[0906 14-48-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: 17.39757, mean: 0.01048
[32m[0906 14-48-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 22.97403, mean: 0.01344
[32m[0906 14-48-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 28.51923, mean: 0.01620
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: 34.10049, mean: 0.01884
[32m[0906 14-48-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01905, current rewards: 39.67958, mean: 0.02133
[32m[0906 14-48-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01904, current rewards: 45.25969, mean: 0.02370
[32m[0906 14-48-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01903, current rewards: 50.83101, mean: 0.02593
[32m[0906 14-48-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01902, current rewards: 56.40672, mean: 0.02806
[32m[0906 14-48-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01901, current rewards: 61.97707, mean: 0.03009
[32m[0906 14-48-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01899, current rewards: 67.55766, mean: 0.03202
[32m[0906 14-48-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01898, current rewards: 73.13854, mean: 0.03386
[32m[0906 14-48-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01899, current rewards: 78.71961, mean: 0.03562
[32m[0906 14-48-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 84.26306, mean: 0.03728
[32m[0906 14-48-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01901, current rewards: 89.81789, mean: 0.03888
[32m[0906 14-48-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01901, current rewards: 95.36775, mean: 0.04041
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01902, current rewards: 100.91736, mean: 0.04187
[32m[0906 14-48-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01902, current rewards: 106.46888, mean: 0.04328
[32m[0906 14-48-32 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-48-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-48-32 @MBExp.py:227][0m Rewards obtained: [110.90868009805594], Lows: [1], Highs: [157], Total time: 2078.6046090000004
[32m[0906 14-50-06 @MBExp.py:144][0m ####################################################################
[32m[0906 14-50-06 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 14-50-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 1.03351, mean: 0.10335
[32m[0906 14-50-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01941, current rewards: 6.52373, mean: 0.10873
[32m[0906 14-50-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 12.06430, mean: 0.10968
[32m[0906 14-50-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.63997, mean: 0.11025
[32m[0906 14-50-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01929, current rewards: 23.21573, mean: 0.11055
[32m[0906 14-50-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01929, current rewards: 28.79373, mean: 0.11075
[32m[0906 14-50-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01928, current rewards: 34.37042, mean: 0.11087
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01931, current rewards: 39.94692, mean: 0.11096
[32m[0906 14-50-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01931, current rewards: 45.57978, mean: 0.11117
[32m[0906 14-50-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01930, current rewards: 51.24652, mean: 0.11141
[32m[0906 14-50-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01929, current rewards: 56.91153, mean: 0.11159
[32m[0906 14-50-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 62.58135, mean: 0.11175
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 68.25022, mean: 0.11189
[32m[0906 14-50-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 73.92426, mean: 0.11201
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: 79.60044, mean: 0.11211
[32m[0906 14-50-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: 85.26609, mean: 0.11219
[32m[0906 14-50-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: 90.94310, mean: 0.11228
[32m[0906 14-50-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01929, current rewards: 96.61301, mean: 0.11234
[32m[0906 14-50-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01928, current rewards: 102.34674, mean: 0.11247
[32m[0906 14-50-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01929, current rewards: 107.94592, mean: 0.11244
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01929, current rewards: 113.54114, mean: 0.11242
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01929, current rewards: 119.15144, mean: 0.11241
[32m[0906 14-50-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01929, current rewards: 124.75427, mean: 0.11239
[32m[0906 14-50-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01930, current rewards: 130.35130, mean: 0.11237
[32m[0906 14-50-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01930, current rewards: 135.95460, mean: 0.11236
[32m[0906 14-50-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01927, current rewards: 141.55876, mean: 0.11235
[32m[0906 14-50-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01925, current rewards: 147.11857, mean: 0.11230
[32m[0906 14-50-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01922, current rewards: 152.72359, mean: 0.11230
[32m[0906 14-50-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01921, current rewards: 158.35719, mean: 0.11231
[32m[0906 14-50-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 163.98349, mean: 0.11232
[32m[0906 14-50-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 169.61213, mean: 0.11233
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 175.24165, mean: 0.11233
[32m[0906 14-50-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: 180.86663, mean: 0.11234
[32m[0906 14-50-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01912, current rewards: 186.49519, mean: 0.11235
[32m[0906 14-50-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 192.12515, mean: 0.11235
[32m[0906 14-50-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 197.74248, mean: 0.11235
[32m[0906 14-50-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 203.37173, mean: 0.11236
[32m[0906 14-50-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 209.00302, mean: 0.11237
[32m[0906 14-50-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 214.63933, mean: 0.11238
[32m[0906 14-50-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01905, current rewards: 220.27970, mean: 0.11239
[32m[0906 14-50-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01904, current rewards: 225.90747, mean: 0.11239
[32m[0906 14-50-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01903, current rewards: 231.53612, mean: 0.11240
[32m[0906 14-50-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01902, current rewards: 237.16884, mean: 0.11240
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01901, current rewards: 242.82368, mean: 0.11242
[32m[0906 14-50-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01901, current rewards: 248.35835, mean: 0.11238
[32m[0906 14-50-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 253.93397, mean: 0.11236
[32m[0906 14-50-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01900, current rewards: 259.50954, mean: 0.11234
[32m[0906 14-50-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01902, current rewards: 265.08788, mean: 0.11233
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01902, current rewards: 270.66117, mean: 0.11231
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01902, current rewards: 276.22981, mean: 0.11229
[32m[0906 14-50-55 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-50-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-50-55 @MBExp.py:227][0m Rewards obtained: [280.65473846625986], Lows: [0], Highs: [0], Total time: 2126.8715310000002
[32m[0906 14-52-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-31 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 14-52-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01905, current rewards: 1.14442, mean: 0.11444
[32m[0906 14-52-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.60969, mean: 0.11016
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01920, current rewards: 12.18135, mean: 0.11074
[32m[0906 14-52-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.75134, mean: 0.11095
[32m[0906 14-52-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.32663, mean: 0.11108
[32m[0906 14-52-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.89566, mean: 0.11114
[32m[0906 14-52-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.45576, mean: 0.11115
[32m[0906 14-52-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 40.01531, mean: 0.11115
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.57641, mean: 0.11116
[32m[0906 14-52-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 51.15047, mean: 0.11120
[32m[0906 14-52-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 56.78362, mean: 0.11134
[32m[0906 14-52-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 62.35871, mean: 0.11135
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01924, current rewards: 67.97763, mean: 0.11144
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 73.56452, mean: 0.11146
[32m[0906 14-52-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01925, current rewards: 79.14810, mean: 0.11148
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01924, current rewards: 84.73555, mean: 0.11149
[32m[0906 14-52-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01924, current rewards: 90.32002, mean: 0.11151
[32m[0906 14-52-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 95.93424, mean: 0.11155
[32m[0906 14-52-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: 101.42127, mean: 0.11145
[32m[0906 14-52-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: 106.97947, mean: 0.11144
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 112.53491, mean: 0.11142
[32m[0906 14-52-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01925, current rewards: 118.09721, mean: 0.11141
[32m[0906 14-52-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 123.66060, mean: 0.11141
[32m[0906 14-52-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01927, current rewards: 129.21992, mean: 0.11140
[32m[0906 14-52-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01927, current rewards: 134.78022, mean: 0.11139
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 140.33814, mean: 0.11138
[32m[0906 14-52-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 145.95181, mean: 0.11141
[32m[0906 14-52-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 151.65064, mean: 0.11151
[32m[0906 14-52-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 157.22056, mean: 0.11150
[32m[0906 14-53-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 162.78884, mean: 0.11150
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01915, current rewards: 168.35775, mean: 0.11150
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01914, current rewards: 173.92626, mean: 0.11149
[32m[0906 14-53-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: 179.49067, mean: 0.11148
[32m[0906 14-53-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 185.06034, mean: 0.11148
[32m[0906 14-53-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 190.62746, mean: 0.11148
[32m[0906 14-53-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 196.14290, mean: 0.11144
[32m[0906 14-53-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 201.71962, mean: 0.11145
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 207.29416, mean: 0.11145
[32m[0906 14-53-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01905, current rewards: 211.76169, mean: 0.11087
[32m[0906 14-53-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01905, current rewards: 217.33489, mean: 0.11089
[32m[0906 14-53-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01904, current rewards: 222.90865, mean: 0.11090
[32m[0906 14-53-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01903, current rewards: 228.47915, mean: 0.11091
[32m[0906 14-53-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01903, current rewards: 234.04484, mean: 0.11092
[32m[0906 14-53-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01902, current rewards: 239.70126, mean: 0.11097
[32m[0906 14-53-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01901, current rewards: 245.26991, mean: 0.11098
[32m[0906 14-53-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 249.45345, mean: 0.11038
[32m[0906 14-53-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01900, current rewards: 256.72766, mean: 0.11114
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01899, current rewards: 264.00187, mean: 0.11187
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01900, current rewards: 271.27609, mean: 0.11256
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01900, current rewards: 278.55030, mean: 0.11323
[32m[0906 14-53-20 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-53-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-53-20 @MBExp.py:227][0m Rewards obtained: [282.07870229427715], Lows: [1], Highs: [3], Total time: 2175.08658
[32m[0906 14-54-59 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-59 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 14-54-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01887, current rewards: 1.14311, mean: 0.11431
[32m[0906 14-55-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 6.68053, mean: 0.11134
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01920, current rewards: 12.16071, mean: 0.11055
[32m[0906 14-55-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 17.71535, mean: 0.11072
[32m[0906 14-55-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.25661, mean: 0.11075
[32m[0906 14-55-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 28.80443, mean: 0.11079
[32m[0906 14-55-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01927, current rewards: 34.35396, mean: 0.11082
[32m[0906 14-55-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01928, current rewards: 39.89975, mean: 0.11083
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.44301, mean: 0.11084
[32m[0906 14-55-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 50.98055, mean: 0.11083
[32m[0906 14-55-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: 56.52451, mean: 0.11083
[32m[0906 14-55-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: 62.07092, mean: 0.11084
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01928, current rewards: 67.61639, mean: 0.11085
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 73.16561, mean: 0.11086
[32m[0906 14-55-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01929, current rewards: 78.71055, mean: 0.11086
[32m[0906 14-55-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01930, current rewards: 84.25386, mean: 0.11086
[32m[0906 14-55-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01930, current rewards: 89.78905, mean: 0.11085
[32m[0906 14-55-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01929, current rewards: 95.31897, mean: 0.11084
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01929, current rewards: 100.84774, mean: 0.11082
[32m[0906 14-55-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01929, current rewards: 106.38187, mean: 0.11081
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01930, current rewards: 111.90491, mean: 0.11080
[32m[0906 14-55-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01929, current rewards: 117.43312, mean: 0.11079
[32m[0906 14-55-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01928, current rewards: 122.96814, mean: 0.11078
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01928, current rewards: 128.50151, mean: 0.11078
[32m[0906 14-55-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01926, current rewards: 134.03527, mean: 0.11077
[32m[0906 14-55-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 139.56792, mean: 0.11077
[32m[0906 14-55-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 145.13684, mean: 0.11079
[32m[0906 14-55-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 150.72708, mean: 0.11083
[32m[0906 14-55-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 156.32171, mean: 0.11087
[32m[0906 14-55-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 161.91452, mean: 0.11090
[32m[0906 14-55-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: 167.50667, mean: 0.11093
[32m[0906 14-55-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 173.09823, mean: 0.11096
[32m[0906 14-55-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 178.68778, mean: 0.11099
[32m[0906 14-55-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 184.28333, mean: 0.11101
[32m[0906 14-55-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 190.30631, mean: 0.11129
[32m[0906 14-55-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01906, current rewards: 199.09498, mean: 0.11312
[32m[0906 14-55-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: 205.53209, mean: 0.11355
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01904, current rewards: 155.53209, mean: 0.08362
[32m[0906 14-55-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01903, current rewards: 105.53209, mean: 0.05525
[32m[0906 14-55-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: 55.53209, mean: 0.02833
[32m[0906 14-55-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: 5.53209, mean: 0.00275
[32m[0906 14-55-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: -44.46791, mean: -0.02159
[32m[0906 14-55-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01898, current rewards: -94.46791, mean: -0.04477
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01897, current rewards: -144.46791, mean: -0.06688
[32m[0906 14-55-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01896, current rewards: -194.46791, mean: -0.08799
[32m[0906 14-55-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01894, current rewards: -244.46791, mean: -0.10817
[32m[0906 14-55-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: -294.46791, mean: -0.12748
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01892, current rewards: -344.46791, mean: -0.14596
[32m[0906 14-55-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: -394.46791, mean: -0.16368
[32m[0906 14-55-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: -444.46791, mean: -0.18068
[32m[0906 14-55-47 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-55-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-55-47 @MBExp.py:227][0m Rewards obtained: [-484.4679074826279], Lows: [0], Highs: [692], Total time: 2223.073902
[32m[0906 14-57-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-57-28 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 14-57-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01943, current rewards: 1.13969, mean: 0.11397
[32m[0906 14-57-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01937, current rewards: 6.72964, mean: 0.11216
[32m[0906 14-57-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 12.31210, mean: 0.11193
[32m[0906 14-57-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 17.89179, mean: 0.11182
[32m[0906 14-57-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01923, current rewards: 23.46896, mean: 0.11176
[32m[0906 14-57-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 29.04253, mean: 0.11170
[32m[0906 14-57-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.62559, mean: 0.11170
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 40.20560, mean: 0.11168
[32m[0906 14-57-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.78939, mean: 0.11168
[32m[0906 14-57-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 51.37066, mean: 0.11168
[32m[0906 14-57-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: 56.94630, mean: 0.11166
[32m[0906 14-57-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 62.52557, mean: 0.11165
[32m[0906 14-57-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 68.10550, mean: 0.11165
[32m[0906 14-57-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 73.68558, mean: 0.11164
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 79.27880, mean: 0.11166
[32m[0906 14-57-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 84.88219, mean: 0.11169
[32m[0906 14-57-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 90.48373, mean: 0.11171
[32m[0906 14-57-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 96.07847, mean: 0.11172
[32m[0906 14-57-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 101.66618, mean: 0.11172
[32m[0906 14-57-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 107.26541, mean: 0.11173
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 112.96580, mean: 0.11185
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 118.62258, mean: 0.11191
[32m[0906 14-57-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 124.27938, mean: 0.11196
[32m[0906 14-57-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: 129.93743, mean: 0.11202
[32m[0906 14-57-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 135.59489, mean: 0.11206
[32m[0906 14-57-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: 141.25422, mean: 0.11211
[32m[0906 14-57-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 146.96993, mean: 0.11219
[32m[0906 14-57-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 152.62627, mean: 0.11223
[32m[0906 14-57-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 158.16395, mean: 0.11217
[32m[0906 14-57-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 163.74619, mean: 0.11215
[32m[0906 14-57-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 169.32547, mean: 0.11214
[32m[0906 14-57-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 174.90470, mean: 0.11212
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 180.48390, mean: 0.11210
[32m[0906 14-58-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 186.06691, mean: 0.11209
[32m[0906 14-58-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: 191.68283, mean: 0.11210
[32m[0906 14-58-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01902, current rewards: 197.26324, mean: 0.11208
[32m[0906 14-58-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01901, current rewards: 202.84250, mean: 0.11207
[32m[0906 14-58-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01899, current rewards: 208.42249, mean: 0.11206
[32m[0906 14-58-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 213.99516, mean: 0.11204
[32m[0906 14-58-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 219.57456, mean: 0.11203
[32m[0906 14-58-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01896, current rewards: 225.14950, mean: 0.11201
[32m[0906 14-58-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01895, current rewards: 230.73088, mean: 0.11201
[32m[0906 14-58-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01895, current rewards: 236.32391, mean: 0.11200
[32m[0906 14-58-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01894, current rewards: 241.89894, mean: 0.11199
[32m[0906 14-58-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: 247.46300, mean: 0.11197
[32m[0906 14-58-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: 253.04427, mean: 0.11197
[32m[0906 14-58-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 258.62762, mean: 0.11196
[32m[0906 14-58-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 264.20666, mean: 0.11195
[32m[0906 14-58-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 269.79107, mean: 0.11195
[32m[0906 14-58-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 275.37180, mean: 0.11194
[32m[0906 14-58-16 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-58-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-58-16 @MBExp.py:227][0m Rewards obtained: [279.82423888363866], Lows: [0], Highs: [0], Total time: 2271.039811
[32m[0906 14-59-59 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-59 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 14-59-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: 1.39179, mean: 0.13918
[32m[0906 15-00-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 7.43706, mean: 0.12395
[32m[0906 15-00-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 13.48232, mean: 0.12257
[32m[0906 15-00-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 19.52759, mean: 0.12205
[32m[0906 15-00-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01923, current rewards: 25.57285, mean: 0.12178
[32m[0906 15-00-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 17.04635, mean: 0.06556
[32m[0906 15-00-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: -32.95365, mean: -0.10630
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: -82.95365, mean: -0.23043
[32m[0906 15-00-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01928, current rewards: -132.95365, mean: -0.32428
[32m[0906 15-00-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01928, current rewards: -182.95365, mean: -0.39773
[32m[0906 15-00-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: -232.95365, mean: -0.45677
[32m[0906 15-00-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: -282.95365, mean: -0.50527
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: -332.95365, mean: -0.54583
[32m[0906 15-00-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: -382.95365, mean: -0.58023
[32m[0906 15-00-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: -432.95365, mean: -0.60979
[32m[0906 15-00-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: -482.95365, mean: -0.63547
[32m[0906 15-00-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: -532.95365, mean: -0.65797
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01927, current rewards: -582.95365, mean: -0.67785
[32m[0906 15-00-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01928, current rewards: -632.95365, mean: -0.69555
[32m[0906 15-00-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01928, current rewards: -682.95365, mean: -0.71141
[32m[0906 15-00-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: -732.95365, mean: -0.72570
[32m[0906 15-00-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: -782.95365, mean: -0.73864
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01927, current rewards: -832.95365, mean: -0.75041
[32m[0906 15-00-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01926, current rewards: -882.95365, mean: -0.76117
[32m[0906 15-00-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01923, current rewards: -932.95365, mean: -0.77104
[32m[0906 15-00-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: -982.95365, mean: -0.78012
[32m[0906 15-00-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: -1032.95365, mean: -0.78851
[32m[0906 15-00-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: -1082.95365, mean: -0.79629
[32m[0906 15-00-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: -1132.95365, mean: -0.80351
[32m[0906 15-00-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: -1182.95365, mean: -0.81024
[32m[0906 15-00-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: -1232.95365, mean: -0.81653
[32m[0906 15-00-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: -1282.95365, mean: -0.82241
[32m[0906 15-00-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: -1332.95365, mean: -0.82792
[32m[0906 15-00-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: -1382.95365, mean: -0.83310
[32m[0906 15-00-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: -1432.95365, mean: -0.83798
[32m[0906 15-00-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: -1482.95365, mean: -0.84259
[32m[0906 15-00-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: -1532.95365, mean: -0.84694
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: -1582.95365, mean: -0.85105
[32m[0906 15-00-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01901, current rewards: -1632.95365, mean: -0.85495
[32m[0906 15-00-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01900, current rewards: -1682.95365, mean: -0.85865
[32m[0906 15-00-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01899, current rewards: -1732.95365, mean: -0.86217
[32m[0906 15-00-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01897, current rewards: -1782.95365, mean: -0.86551
[32m[0906 15-00-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: -1832.95365, mean: -0.86870
[32m[0906 15-00-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: -1882.95365, mean: -0.87174
[32m[0906 15-00-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01895, current rewards: -1932.95365, mean: -0.87464
[32m[0906 15-00-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: -1982.95365, mean: -0.87741
[32m[0906 15-00-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01894, current rewards: -2032.95365, mean: -0.88007
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: -2082.95365, mean: -0.88261
[32m[0906 15-00-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: -2132.95365, mean: -0.88504
[32m[0906 15-00-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: -2182.95365, mean: -0.88738
[32m[0906 15-00-47 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-00-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-00-47 @MBExp.py:227][0m Rewards obtained: [-2222.9536495129437], Lows: [0], Highs: [2253], Total time: 2319.0300660000003
[32m[0906 15-02-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-02-32 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-02-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01996, current rewards: 1.08159, mean: 0.10816
[32m[0906 15-02-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 6.66803, mean: 0.11113
[32m[0906 15-02-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.26214, mean: 0.11147
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01924, current rewards: 17.85767, mean: 0.11161
[32m[0906 15-02-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01926, current rewards: 23.44975, mean: 0.11167
[32m[0906 15-02-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 29.04428, mean: 0.11171
[32m[0906 15-02-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.63938, mean: 0.11174
[32m[0906 15-02-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01926, current rewards: 40.23024, mean: 0.11175
[32m[0906 15-02-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.82369, mean: 0.11177
[32m[0906 15-02-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 51.40326, mean: 0.11175
[32m[0906 15-02-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 56.99237, mean: 0.11175
[32m[0906 15-02-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 62.58458, mean: 0.11176
[32m[0906 15-02-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 68.17468, mean: 0.11176
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.76419, mean: 0.11176
[32m[0906 15-02-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 79.35394, mean: 0.11177
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 84.96538, mean: 0.11180
[32m[0906 15-02-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 90.57848, mean: 0.11183
[32m[0906 15-02-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 96.21730, mean: 0.11188
[32m[0906 15-02-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 101.82211, mean: 0.11189
[32m[0906 15-02-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 107.44179, mean: 0.11192
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 110.89879, mean: 0.10980
[32m[0906 15-02-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 116.41564, mean: 0.10983
[32m[0906 15-02-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01923, current rewards: 121.93084, mean: 0.10985
[32m[0906 15-02-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01923, current rewards: 127.44497, mean: 0.10987
[32m[0906 15-02-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 132.95861, mean: 0.10988
[32m[0906 15-02-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 138.47749, mean: 0.10990
[32m[0906 15-02-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 143.98633, mean: 0.10991
[32m[0906 15-02-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01917, current rewards: 149.49332, mean: 0.10992
[32m[0906 15-03-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 155.00873, mean: 0.10994
[32m[0906 15-03-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 160.52073, mean: 0.10995
[32m[0906 15-03-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 166.03276, mean: 0.10996
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 171.54283, mean: 0.10996
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 177.05606, mean: 0.10997
[32m[0906 15-03-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 182.56996, mean: 0.10998
[32m[0906 15-03-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 188.04318, mean: 0.10997
[32m[0906 15-03-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: 193.61438, mean: 0.11001
[32m[0906 15-03-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: 199.18789, mean: 0.11005
[32m[0906 15-03-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: 204.77315, mean: 0.11009
[32m[0906 15-03-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: 210.34592, mean: 0.11013
[32m[0906 15-03-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: 215.92627, mean: 0.11017
[32m[0906 15-03-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: 221.49695, mean: 0.11020
[32m[0906 15-03-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: 227.09698, mean: 0.11024
[32m[0906 15-03-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01899, current rewards: 232.67710, mean: 0.11027
[32m[0906 15-03-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01898, current rewards: 238.29227, mean: 0.11032
[32m[0906 15-03-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01897, current rewards: 243.91216, mean: 0.11037
[32m[0906 15-03-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01896, current rewards: 249.53028, mean: 0.11041
[32m[0906 15-03-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01895, current rewards: 255.14725, mean: 0.11045
[32m[0906 15-03-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01895, current rewards: 260.76327, mean: 0.11049
[32m[0906 15-03-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01895, current rewards: 266.37482, mean: 0.11053
[32m[0906 15-03-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 272.04557, mean: 0.11059
[32m[0906 15-03-20 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-03-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-03-20 @MBExp.py:227][0m Rewards obtained: [276.53414261096884], Lows: [1], Highs: [0], Total time: 2367.0751560000003
[32m[0906 15-05-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-08 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-05-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: 0.08462, mean: 0.00846
[32m[0906 15-05-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: 5.97373, mean: 0.09956
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 11.76525, mean: 0.10696
[32m[0906 15-05-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 17.56265, mean: 0.10977
[32m[0906 15-05-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 23.35610, mean: 0.11122
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 29.05439, mean: 0.11175
[32m[0906 15-05-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.64639, mean: 0.11176
[32m[0906 15-05-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 40.23440, mean: 0.11176
[32m[0906 15-05-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.81328, mean: 0.11174
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.43151, mean: 0.11181
[32m[0906 15-05-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 57.26376, mean: 0.11228
[32m[0906 15-05-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 63.06848, mean: 0.11262
[32m[0906 15-05-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 68.87184, mean: 0.11290
[32m[0906 15-05-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 74.67585, mean: 0.11315
[32m[0906 15-05-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 80.47966, mean: 0.11335
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 86.28337, mean: 0.11353
[32m[0906 15-05-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 93.13571, mean: 0.11498
[32m[0906 15-05-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 100.99525, mean: 0.11744
[32m[0906 15-05-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 108.85479, mean: 0.11962
[32m[0906 15-05-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 105.14242, mean: 0.10952
[32m[0906 15-05-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 55.14242, mean: 0.05460
[32m[0906 15-05-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 5.14242, mean: 0.00485
[32m[0906 15-05-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: -44.85758, mean: -0.04041
[32m[0906 15-05-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: -94.85758, mean: -0.08177
[32m[0906 15-05-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: -144.85758, mean: -0.11972
[32m[0906 15-05-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: -194.85758, mean: -0.15465
[32m[0906 15-05-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: -244.85758, mean: -0.18691
[32m[0906 15-05-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: -294.85758, mean: -0.21681
[32m[0906 15-05-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: -344.85758, mean: -0.24458
[32m[0906 15-05-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: -394.85758, mean: -0.27045
[32m[0906 15-05-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: -444.85758, mean: -0.29461
[32m[0906 15-05-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: -494.85758, mean: -0.31722
[32m[0906 15-05-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: -544.85758, mean: -0.33842
[32m[0906 15-05-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: -594.85758, mean: -0.35835
[32m[0906 15-05-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01904, current rewards: -644.85758, mean: -0.37711
[32m[0906 15-05-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: -694.85758, mean: -0.39481
[32m[0906 15-05-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01902, current rewards: -744.85758, mean: -0.41152
[32m[0906 15-05-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01901, current rewards: -794.85758, mean: -0.42734
[32m[0906 15-05-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01899, current rewards: -844.85758, mean: -0.44233
[32m[0906 15-05-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01899, current rewards: -894.85758, mean: -0.45656
[32m[0906 15-05-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01898, current rewards: -944.85758, mean: -0.47008
[32m[0906 15-05-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: -994.85758, mean: -0.48294
[32m[0906 15-05-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: -1044.85758, mean: -0.49519
[32m[0906 15-05-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: -1094.85758, mean: -0.50688
[32m[0906 15-05-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01895, current rewards: -1144.85758, mean: -0.51804
[32m[0906 15-05-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: -1194.85758, mean: -0.52870
[32m[0906 15-05-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: -1244.85758, mean: -0.53890
[32m[0906 15-05-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: -1294.85758, mean: -0.54867
[32m[0906 15-05-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: -1344.85758, mean: -0.55803
[32m[0906 15-05-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: -1394.85758, mean: -0.56702
[32m[0906 15-05-56 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-05-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-05-56 @MBExp.py:227][0m Rewards obtained: [-1434.8575809129043], Lows: [0], Highs: [1551], Total time: 2415.0516470000002
[32m[0906 15-07-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-07-45 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-07-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01962, current rewards: 1.10708, mean: 0.11071
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01932, current rewards: 6.60872, mean: 0.11015
[32m[0906 15-07-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 12.15060, mean: 0.11046
[32m[0906 15-07-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.69243, mean: 0.11058
[32m[0906 15-07-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.22834, mean: 0.11061
[32m[0906 15-07-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 28.76481, mean: 0.11063
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 34.30464, mean: 0.11066
[32m[0906 15-07-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.84169, mean: 0.11067
[32m[0906 15-07-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.37967, mean: 0.11068
[32m[0906 15-07-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 50.92067, mean: 0.11070
[32m[0906 15-07-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: 56.46531, mean: 0.11072
[32m[0906 15-07-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 62.00325, mean: 0.11072
[32m[0906 15-07-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01928, current rewards: 67.53817, mean: 0.11072
[32m[0906 15-07-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01930, current rewards: 73.07861, mean: 0.11073
[32m[0906 15-07-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01929, current rewards: 78.61648, mean: 0.11073
[32m[0906 15-08-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01930, current rewards: 84.23190, mean: 0.11083
[32m[0906 15-08-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 89.72462, mean: 0.11077
[32m[0906 15-08-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 95.21562, mean: 0.11072
[32m[0906 15-08-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 100.71302, mean: 0.11067
[32m[0906 15-08-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01928, current rewards: 106.19972, mean: 0.11062
[32m[0906 15-08-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01928, current rewards: 111.69250, mean: 0.11059
[32m[0906 15-08-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01927, current rewards: 117.18715, mean: 0.11055
[32m[0906 15-08-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01927, current rewards: 122.67984, mean: 0.11052
[32m[0906 15-08-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: 128.15191, mean: 0.11048
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 133.64202, mean: 0.11045
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 139.14098, mean: 0.11043
[32m[0906 15-08-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 144.63840, mean: 0.11041
[32m[0906 15-08-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 150.12645, mean: 0.11039
[32m[0906 15-08-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 155.61779, mean: 0.11037
[32m[0906 15-08-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01914, current rewards: 161.11132, mean: 0.11035
[32m[0906 15-08-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 166.62087, mean: 0.11034
[32m[0906 15-08-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 172.09446, mean: 0.11032
[32m[0906 15-08-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 177.54939, mean: 0.11028
[32m[0906 15-08-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 183.04142, mean: 0.11027
[32m[0906 15-08-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 188.53532, mean: 0.11025
[32m[0906 15-08-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 194.02383, mean: 0.11024
[32m[0906 15-08-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01904, current rewards: 199.51303, mean: 0.11023
[32m[0906 15-08-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: 205.00839, mean: 0.11022
[32m[0906 15-08-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: 210.49496, mean: 0.11021
[32m[0906 15-08-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01902, current rewards: 215.98413, mean: 0.11020
[32m[0906 15-08-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01901, current rewards: 221.47708, mean: 0.11019
[32m[0906 15-08-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01900, current rewards: 226.96836, mean: 0.11018
[32m[0906 15-08-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01900, current rewards: 232.45777, mean: 0.11017
[32m[0906 15-08-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01899, current rewards: 237.94672, mean: 0.11016
[32m[0906 15-08-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01898, current rewards: 243.50297, mean: 0.11018
[32m[0906 15-08-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01897, current rewards: 249.05334, mean: 0.11020
[32m[0906 15-08-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01896, current rewards: 254.60448, mean: 0.11022
[32m[0906 15-08-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01896, current rewards: 260.15578, mean: 0.11024
[32m[0906 15-08-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01895, current rewards: 265.71146, mean: 0.11025
[32m[0906 15-08-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 271.25874, mean: 0.11027
[32m[0906 15-08-33 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-08-33 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-08-33 @MBExp.py:227][0m Rewards obtained: [275.7020615844183], Lows: [0], Highs: [0], Total time: 2463.0850140000002
[32m[0906 15-10-24 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-24 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-10-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01903, current rewards: 1.11829, mean: 0.11183
[32m[0906 15-10-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01917, current rewards: 6.76587, mean: 0.11276
[32m[0906 15-10-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.32945, mean: 0.11209
[32m[0906 15-10-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.89753, mean: 0.11186
[32m[0906 15-10-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.55803, mean: 0.11218
[32m[0906 15-10-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 29.08336, mean: 0.11186
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 34.56381, mean: 0.11150
[32m[0906 15-10-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 40.08514, mean: 0.11135
[32m[0906 15-10-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.64623, mean: 0.11133
[32m[0906 15-10-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 51.20833, mean: 0.11132
[32m[0906 15-10-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.72289, mean: 0.11122
[32m[0906 15-10-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 62.26542, mean: 0.11119
[32m[0906 15-10-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.80366, mean: 0.11115
[32m[0906 15-10-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 73.33969, mean: 0.11112
[32m[0906 15-10-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.87569, mean: 0.11109
[32m[0906 15-10-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.45940, mean: 0.11113
[32m[0906 15-10-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 90.01386, mean: 0.11113
[32m[0906 15-10-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 95.57146, mean: 0.11113
[32m[0906 15-10-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 101.12646, mean: 0.11113
[32m[0906 15-10-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 106.67970, mean: 0.11112
[32m[0906 15-10-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 112.23298, mean: 0.11112
[32m[0906 15-10-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 117.78327, mean: 0.11112
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 123.34217, mean: 0.11112
[32m[0906 15-10-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 128.86019, mean: 0.11109
[32m[0906 15-10-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 134.43504, mean: 0.11110
[32m[0906 15-10-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 140.00305, mean: 0.11111
[32m[0906 15-10-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 145.57879, mean: 0.11113
[32m[0906 15-10-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 151.15472, mean: 0.11114
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 156.72738, mean: 0.11115
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 162.30270, mean: 0.11117
[32m[0906 15-10-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 167.87593, mean: 0.11118
[32m[0906 15-10-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 173.46779, mean: 0.11120
[32m[0906 15-10-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 179.05478, mean: 0.11121
[32m[0906 15-10-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: 184.63897, mean: 0.11123
[32m[0906 15-10-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: 190.22546, mean: 0.11124
[32m[0906 15-10-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01902, current rewards: 195.80423, mean: 0.11125
[32m[0906 15-10-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01901, current rewards: 201.39240, mean: 0.11127
[32m[0906 15-11-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01900, current rewards: 206.98030, mean: 0.11128
[32m[0906 15-11-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 212.56745, mean: 0.11129
[32m[0906 15-11-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01898, current rewards: 218.22434, mean: 0.11134
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01897, current rewards: 223.82205, mean: 0.11135
[32m[0906 15-11-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01897, current rewards: 229.40194, mean: 0.11136
[32m[0906 15-11-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01896, current rewards: 234.97922, mean: 0.11136
[32m[0906 15-11-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: 240.57634, mean: 0.11138
[32m[0906 15-11-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01895, current rewards: 246.14375, mean: 0.11138
[32m[0906 15-11-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: 251.71248, mean: 0.11138
[32m[0906 15-11-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01894, current rewards: 257.28189, mean: 0.11138
[32m[0906 15-11-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 262.85221, mean: 0.11138
[32m[0906 15-11-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: 268.41860, mean: 0.11138
[32m[0906 15-11-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 273.98487, mean: 0.11138
[32m[0906 15-11-12 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-11-12 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-11-12 @MBExp.py:227][0m Rewards obtained: [278.4414262834976], Lows: [0], Highs: [0], Total time: 2511.1165840000003
[32m[0906 15-13-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-13-06 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-13-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01882, current rewards: 1.11513, mean: 0.11151
[32m[0906 15-13-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.69659, mean: 0.11161
[32m[0906 15-13-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.27480, mean: 0.11159
[32m[0906 15-13-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.85415, mean: 0.11159
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.43028, mean: 0.11157
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 29.00833, mean: 0.11157
[32m[0906 15-13-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.75781, mean: 0.11212
[32m[0906 15-13-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 40.65264, mean: 0.11292
[32m[0906 15-13-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 46.54284, mean: 0.11352
[32m[0906 15-13-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 52.43256, mean: 0.11398
[32m[0906 15-13-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 58.32386, mean: 0.11436
[32m[0906 15-13-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 64.21761, mean: 0.11467
[32m[0906 15-13-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 70.10909, mean: 0.11493
[32m[0906 15-13-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 76.00659, mean: 0.11516
[32m[0906 15-13-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 81.91401, mean: 0.11537
[32m[0906 15-13-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 87.78812, mean: 0.11551
[32m[0906 15-13-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 93.41744, mean: 0.11533
[32m[0906 15-13-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 98.99187, mean: 0.11511
[32m[0906 15-13-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01923, current rewards: 104.56090, mean: 0.11490
[32m[0906 15-13-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 110.14035, mean: 0.11473
[32m[0906 15-13-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 115.77196, mean: 0.11463
[32m[0906 15-13-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 121.40756, mean: 0.11454
[32m[0906 15-13-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 126.99824, mean: 0.11441
[32m[0906 15-13-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 132.64089, mean: 0.11435
[32m[0906 15-13-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 138.28852, mean: 0.11429
[32m[0906 15-13-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 143.93686, mean: 0.11424
[32m[0906 15-13-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 149.58130, mean: 0.11418
[32m[0906 15-13-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 155.22650, mean: 0.11414
[32m[0906 15-13-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 160.87150, mean: 0.11409
[32m[0906 15-13-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 166.51389, mean: 0.11405
[32m[0906 15-13-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 172.15072, mean: 0.11401
[32m[0906 15-13-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 177.69670, mean: 0.11391
[32m[0906 15-13-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 183.24890, mean: 0.11382
[32m[0906 15-13-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: 188.80191, mean: 0.11374
[32m[0906 15-13-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01904, current rewards: 194.35490, mean: 0.11366
[32m[0906 15-13-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: 199.90743, mean: 0.11358
[32m[0906 15-13-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01902, current rewards: 205.46002, mean: 0.11351
[32m[0906 15-13-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01901, current rewards: 211.01322, mean: 0.11345
[32m[0906 15-13-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01901, current rewards: 216.56883, mean: 0.11339
[32m[0906 15-13-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: 222.12338, mean: 0.11333
[32m[0906 15-13-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: 226.69022, mean: 0.11278
[32m[0906 15-13-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: 232.38430, mean: 0.11281
[32m[0906 15-13-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01899, current rewards: 238.07726, mean: 0.11283
[32m[0906 15-13-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01898, current rewards: 243.76479, mean: 0.11285
[32m[0906 15-13-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01897, current rewards: 249.45340, mean: 0.11287
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01896, current rewards: 255.14792, mean: 0.11290
[32m[0906 15-13-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01896, current rewards: 260.84534, mean: 0.11292
[32m[0906 15-13-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01895, current rewards: 266.45897, mean: 0.11291
[32m[0906 15-13-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01894, current rewards: 272.04038, mean: 0.11288
[32m[0906 15-13-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 277.61623, mean: 0.11285
[32m[0906 15-13-53 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-13-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-13-54 @MBExp.py:227][0m Rewards obtained: [282.0819597401695], Lows: [0], Highs: [1], Total time: 2559.1690420000004
[32m[0906 15-15-49 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-49 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.07352, mean: 0.10735
[32m[0906 15-15-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01936, current rewards: 6.63488, mean: 0.11058
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 12.19728, mean: 0.11088
[32m[0906 15-15-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 17.75766, mean: 0.11099
[32m[0906 15-15-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.30915, mean: 0.11100
[32m[0906 15-15-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.97486, mean: 0.11144
[32m[0906 15-15-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 34.54314, mean: 0.11143
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 40.10787, mean: 0.11141
[32m[0906 15-15-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 45.67600, mean: 0.11140
[32m[0906 15-15-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 51.24648, mean: 0.11141
[32m[0906 15-15-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 56.81471, mean: 0.11140
[32m[0906 15-16-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 62.39571, mean: 0.11142
[32m[0906 15-16-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.93194, mean: 0.11136
[32m[0906 15-16-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01923, current rewards: 73.43683, mean: 0.11127
[32m[0906 15-16-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.96805, mean: 0.11122
[32m[0906 15-16-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 84.50461, mean: 0.11119
[32m[0906 15-16-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 90.03770, mean: 0.11116
[32m[0906 15-16-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 95.57246, mean: 0.11113
[32m[0906 15-16-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 101.10424, mean: 0.11110
[32m[0906 15-16-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 106.63508, mean: 0.11108
[32m[0906 15-16-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 112.16787, mean: 0.11106
[32m[0906 15-16-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 117.69969, mean: 0.11104
[32m[0906 15-16-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01920, current rewards: 123.19283, mean: 0.11098
[32m[0906 15-16-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 128.74441, mean: 0.11099
[32m[0906 15-16-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 134.30165, mean: 0.11099
[32m[0906 15-16-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 139.86102, mean: 0.11100
[32m[0906 15-16-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 145.41767, mean: 0.11101
[32m[0906 15-16-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 150.97636, mean: 0.11101
[32m[0906 15-16-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 156.53601, mean: 0.11102
[32m[0906 15-16-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 162.07786, mean: 0.11101
[32m[0906 15-16-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 167.69754, mean: 0.11106
[32m[0906 15-16-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 173.25333, mean: 0.11106
[32m[0906 15-16-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01901, current rewards: 178.80692, mean: 0.11106
[32m[0906 15-16-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01900, current rewards: 184.36406, mean: 0.11106
[32m[0906 15-16-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01899, current rewards: 189.92110, mean: 0.11106
[32m[0906 15-16-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: 195.48193, mean: 0.11107
[32m[0906 15-16-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: 201.03558, mean: 0.11107
[32m[0906 15-16-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: 206.65808, mean: 0.11111
[32m[0906 15-16-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01894, current rewards: 212.21835, mean: 0.11111
[32m[0906 15-16-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01894, current rewards: 217.77635, mean: 0.11111
[32m[0906 15-16-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 223.33303, mean: 0.11111
[32m[0906 15-16-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 228.89700, mean: 0.11112
[32m[0906 15-16-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 234.45981, mean: 0.11112
[32m[0906 15-16-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 240.02979, mean: 0.11112
[32m[0906 15-16-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 245.60180, mean: 0.11113
[32m[0906 15-16-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 251.17268, mean: 0.11114
[32m[0906 15-16-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: 256.74797, mean: 0.11115
[32m[0906 15-16-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 262.35656, mean: 0.11117
[32m[0906 15-16-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 267.92803, mean: 0.11117
[32m[0906 15-16-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 273.49972, mean: 0.11118
[32m[0906 15-16-36 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-16-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-16-37 @MBExp.py:227][0m Rewards obtained: [277.95539594022455], Lows: [0], Highs: [0], Total time: 2607.0369330000003
[32m[0906 15-18-34 @MBExp.py:144][0m ####################################################################
[32m[0906 15-18-34 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-18-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01838, current rewards: 1.07042, mean: 0.10704
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 6.60406, mean: 0.11007
[32m[0906 15-18-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.13724, mean: 0.11034
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.68314, mean: 0.11052
[32m[0906 15-18-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01926, current rewards: 23.27440, mean: 0.11083
[32m[0906 15-18-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01930, current rewards: 28.81235, mean: 0.11082
[32m[0906 15-18-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01929, current rewards: 34.35221, mean: 0.11081
[32m[0906 15-18-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01929, current rewards: 39.89201, mean: 0.11081
[32m[0906 15-18-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01931, current rewards: 45.43021, mean: 0.11081
[32m[0906 15-18-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01932, current rewards: 51.03621, mean: 0.11095
[32m[0906 15-18-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01931, current rewards: 56.55140, mean: 0.11089
[32m[0906 15-18-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01931, current rewards: 62.06896, mean: 0.11084
[32m[0906 15-18-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01930, current rewards: 67.53941, mean: 0.11072
[32m[0906 15-18-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 73.05179, mean: 0.11068
[32m[0906 15-18-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01929, current rewards: 78.56770, mean: 0.11066
[32m[0906 15-18-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01929, current rewards: 84.14633, mean: 0.11072
[32m[0906 15-18-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 89.73529, mean: 0.11078
[32m[0906 15-18-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 95.32471, mean: 0.11084
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 100.91569, mean: 0.11090
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01927, current rewards: 106.50766, mean: 0.11095
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: 112.42331, mean: 0.11131
[32m[0906 15-18-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01927, current rewards: 119.03154, mean: 0.11229
[32m[0906 15-18-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01926, current rewards: 125.63977, mean: 0.11319
[32m[0906 15-18-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: 132.24801, mean: 0.11401
[32m[0906 15-18-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 138.85624, mean: 0.11476
[32m[0906 15-18-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: 145.46447, mean: 0.11545
[32m[0906 15-18-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 141.88322, mean: 0.10831
[32m[0906 15-19-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 132.97497, mean: 0.09778
[32m[0906 15-19-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 138.49246, mean: 0.09822
[32m[0906 15-19-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 144.03409, mean: 0.09865
[32m[0906 15-19-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 149.57011, mean: 0.09905
[32m[0906 15-19-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 155.11304, mean: 0.09943
[32m[0906 15-19-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 160.65364, mean: 0.09978
[32m[0906 15-19-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01901, current rewards: 166.19234, mean: 0.10012
[32m[0906 15-19-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01900, current rewards: 171.73466, mean: 0.10043
[32m[0906 15-19-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: 177.27553, mean: 0.10072
[32m[0906 15-19-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01899, current rewards: 182.80999, mean: 0.10100
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01898, current rewards: 188.25938, mean: 0.10121
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01897, current rewards: 193.79802, mean: 0.10146
[32m[0906 15-19-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01896, current rewards: 199.34038, mean: 0.10170
[32m[0906 15-19-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01895, current rewards: 204.88432, mean: 0.10193
[32m[0906 15-19-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01894, current rewards: 210.42218, mean: 0.10215
[32m[0906 15-19-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: 215.96717, mean: 0.10235
[32m[0906 15-19-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01893, current rewards: 221.51383, mean: 0.10255
[32m[0906 15-19-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: 227.05557, mean: 0.10274
[32m[0906 15-19-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 232.74591, mean: 0.10298
[32m[0906 15-19-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 238.28774, mean: 0.10315
[32m[0906 15-19-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 243.82923, mean: 0.10332
[32m[0906 15-19-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 249.37374, mean: 0.10347
[32m[0906 15-19-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 254.86678, mean: 0.10360
[32m[0906 15-19-22 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-19-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-19-22 @MBExp.py:227][0m Rewards obtained: [259.29524307538793], Lows: [0], Highs: [22], Total time: 2654.9608260000005
[32m[0906 15-21-21 @MBExp.py:144][0m ####################################################################
[32m[0906 15-21-21 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-21-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01952, current rewards: -1.02333, mean: -0.10233
[32m[0906 15-21-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01925, current rewards: 4.47870, mean: 0.07464
[32m[0906 15-21-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 10.01781, mean: 0.09107
[32m[0906 15-21-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 15.55836, mean: 0.09724
[32m[0906 15-21-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 21.13687, mean: 0.10065
[32m[0906 15-21-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 26.70444, mean: 0.10271
[32m[0906 15-21-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 32.29546, mean: 0.10418
[32m[0906 15-21-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 37.88362, mean: 0.10523
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 43.47096, mean: 0.10603
[32m[0906 15-21-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 49.06220, mean: 0.10666
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 54.63461, mean: 0.10713
[32m[0906 15-21-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 60.20633, mean: 0.10751
[32m[0906 15-21-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01923, current rewards: 65.68802, mean: 0.10769
[32m[0906 15-21-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 71.23862, mean: 0.10794
[32m[0906 15-21-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 76.79127, mean: 0.10816
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 82.34025, mean: 0.10834
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 87.89302, mean: 0.10851
[32m[0906 15-21-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: 93.45420, mean: 0.10867
[32m[0906 15-21-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: 98.96618, mean: 0.10875
[32m[0906 15-21-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 104.47698, mean: 0.10883
[32m[0906 15-21-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 110.01924, mean: 0.10893
[32m[0906 15-21-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 115.66934, mean: 0.10912
[32m[0906 15-21-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 121.26282, mean: 0.10925
[32m[0906 15-21-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 126.86627, mean: 0.10937
[32m[0906 15-21-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 132.46894, mean: 0.10948
[32m[0906 15-21-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 138.07081, mean: 0.10958
[32m[0906 15-21-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 143.65926, mean: 0.10966
[32m[0906 15-21-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 149.22130, mean: 0.10972
[32m[0906 15-21-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 154.78243, mean: 0.10977
[32m[0906 15-21-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 160.27488, mean: 0.10978
[32m[0906 15-21-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 165.81654, mean: 0.10981
[32m[0906 15-21-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 171.38045, mean: 0.10986
[32m[0906 15-21-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: 176.90301, mean: 0.10988
[32m[0906 15-21-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01903, current rewards: 182.44825, mean: 0.10991
[32m[0906 15-21-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01902, current rewards: 187.99468, mean: 0.10994
[32m[0906 15-21-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: 193.52797, mean: 0.10996
[32m[0906 15-21-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01899, current rewards: 199.00579, mean: 0.10995
[32m[0906 15-21-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01898, current rewards: 204.50507, mean: 0.10995
[32m[0906 15-21-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 210.04173, mean: 0.10997
[32m[0906 15-21-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 215.54707, mean: 0.10997
[32m[0906 15-21-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01896, current rewards: 221.05762, mean: 0.10998
[32m[0906 15-22-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01895, current rewards: 226.57243, mean: 0.10999
[32m[0906 15-22-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01894, current rewards: 232.08528, mean: 0.10999
[32m[0906 15-22-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01893, current rewards: 237.59627, mean: 0.11000
[32m[0906 15-22-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01893, current rewards: 243.10917, mean: 0.11000
[32m[0906 15-22-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01892, current rewards: 248.62404, mean: 0.11001
[32m[0906 15-22-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 254.15660, mean: 0.11002
[32m[0906 15-22-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 259.71266, mean: 0.11005
[32m[0906 15-22-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 265.27067, mean: 0.11007
[32m[0906 15-22-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 270.82890, mean: 0.11009
[32m[0906 15-22-09 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-22-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-22-09 @MBExp.py:227][0m Rewards obtained: [275.2738270247933], Lows: [1], Highs: [0], Total time: 2702.8923900000004
[32m[0906 15-24-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-09 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-24-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.13450, mean: 0.11345
[32m[0906 15-24-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01920, current rewards: 6.72650, mean: 0.11211
[32m[0906 15-24-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 12.26706, mean: 0.11152
[32m[0906 15-24-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 17.80949, mean: 0.11131
[32m[0906 15-24-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 23.32153, mean: 0.11105
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 28.85288, mean: 0.11097
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 34.40530, mean: 0.11098
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 39.95774, mean: 0.11099
[32m[0906 15-24-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.51416, mean: 0.11101
[32m[0906 15-24-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01929, current rewards: 51.08609, mean: 0.11106
[32m[0906 15-24-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01931, current rewards: 56.64481, mean: 0.11107
[32m[0906 15-24-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01932, current rewards: 62.21116, mean: 0.11109
[32m[0906 15-24-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01931, current rewards: 67.75898, mean: 0.11108
[32m[0906 15-24-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01933, current rewards: 73.27465, mean: 0.11102
[32m[0906 15-24-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01933, current rewards: 78.81911, mean: 0.11101
[32m[0906 15-24-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01933, current rewards: 84.37289, mean: 0.11102
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01933, current rewards: 89.92643, mean: 0.11102
[32m[0906 15-24-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01933, current rewards: 95.47359, mean: 0.11102
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01932, current rewards: 101.02275, mean: 0.11101
[32m[0906 15-24-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01932, current rewards: 106.56408, mean: 0.11100
[32m[0906 15-24-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01932, current rewards: 112.11477, mean: 0.11100
[32m[0906 15-24-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01932, current rewards: 117.67812, mean: 0.11102
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01932, current rewards: 123.22955, mean: 0.11102
[32m[0906 15-24-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01929, current rewards: 128.78272, mean: 0.11102
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01926, current rewards: 134.33671, mean: 0.11102
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 139.88661, mean: 0.11102
[32m[0906 15-24-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01922, current rewards: 145.44265, mean: 0.11102
[32m[0906 15-24-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 150.98898, mean: 0.11102
[32m[0906 15-24-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 156.55761, mean: 0.11103
[32m[0906 15-24-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01917, current rewards: 162.11564, mean: 0.11104
[32m[0906 15-24-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01915, current rewards: 167.68651, mean: 0.11105
[32m[0906 15-24-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01913, current rewards: 173.25769, mean: 0.11106
[32m[0906 15-24-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 178.82522, mean: 0.11107
[32m[0906 15-24-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: 184.39461, mean: 0.11108
[32m[0906 15-24-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 189.96439, mean: 0.11109
[32m[0906 15-24-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 195.53313, mean: 0.11110
[32m[0906 15-24-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01906, current rewards: 201.16631, mean: 0.11114
[32m[0906 15-24-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 206.71945, mean: 0.11114
[32m[0906 15-24-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01905, current rewards: 212.32097, mean: 0.11116
[32m[0906 15-24-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01904, current rewards: 217.92083, mean: 0.11118
[32m[0906 15-24-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01903, current rewards: 223.51774, mean: 0.11120
[32m[0906 15-24-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01902, current rewards: 229.11685, mean: 0.11122
[32m[0906 15-24-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01902, current rewards: 234.71672, mean: 0.11124
[32m[0906 15-24-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01901, current rewards: 240.31685, mean: 0.11126
[32m[0906 15-24-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01899, current rewards: 245.91669, mean: 0.11127
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01899, current rewards: 251.51983, mean: 0.11129
[32m[0906 15-24-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01898, current rewards: 257.12181, mean: 0.11131
[32m[0906 15-24-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01898, current rewards: 262.71901, mean: 0.11132
[32m[0906 15-24-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01897, current rewards: 268.31873, mean: 0.11134
[32m[0906 15-24-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01896, current rewards: 273.91941, mean: 0.11135
[32m[0906 15-24-57 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-24-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-24-58 @MBExp.py:227][0m Rewards obtained: [277.23237434658364], Lows: [0], Highs: [1], Total time: 2751.0041200000005
[32m[0906 15-27-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-27-01 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-27-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01908, current rewards: 1.12909, mean: 0.11291
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 6.69215, mean: 0.11154
[32m[0906 15-27-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 12.25472, mean: 0.11141
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.76533, mean: 0.11103
[32m[0906 15-27-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.33279, mean: 0.11111
[32m[0906 15-27-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 28.86318, mean: 0.11101
[32m[0906 15-27-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.40742, mean: 0.11099
[32m[0906 15-27-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 39.95341, mean: 0.11098
[32m[0906 15-27-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.50417, mean: 0.11099
[32m[0906 15-27-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 51.05197, mean: 0.11098
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.54022, mean: 0.11086
[32m[0906 15-27-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 61.97518, mean: 0.11067
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 67.42418, mean: 0.11053
[32m[0906 15-27-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 72.87014, mean: 0.11041
[32m[0906 15-27-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 78.32385, mean: 0.11032
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 83.77722, mean: 0.11023
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 89.22617, mean: 0.11016
[32m[0906 15-27-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 94.67524, mean: 0.11009
[32m[0906 15-27-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01923, current rewards: 100.12534, mean: 0.11003
[32m[0906 15-27-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 105.60579, mean: 0.11001
[32m[0906 15-27-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 111.16576, mean: 0.11007
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 116.66114, mean: 0.11006
[32m[0906 15-27-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01923, current rewards: 122.15393, mean: 0.11005
[32m[0906 15-27-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 127.68099, mean: 0.11007
[32m[0906 15-27-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 133.22844, mean: 0.11011
[32m[0906 15-27-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 138.77499, mean: 0.11014
[32m[0906 15-27-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: 144.32428, mean: 0.11017
[32m[0906 15-27-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 149.87611, mean: 0.11020
[32m[0906 15-27-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 155.42749, mean: 0.11023
[32m[0906 15-27-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 158.88479, mean: 0.10883
[32m[0906 15-27-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 164.50208, mean: 0.10894
[32m[0906 15-27-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 170.11890, mean: 0.10905
[32m[0906 15-27-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 175.73573, mean: 0.10915
[32m[0906 15-27-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01903, current rewards: 181.35245, mean: 0.10925
[32m[0906 15-27-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01902, current rewards: 186.96899, mean: 0.10934
[32m[0906 15-27-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01901, current rewards: 192.58570, mean: 0.10942
[32m[0906 15-27-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01899, current rewards: 195.94704, mean: 0.10826
[32m[0906 15-27-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01899, current rewards: 201.51393, mean: 0.10834
[32m[0906 15-27-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 207.08204, mean: 0.10842
[32m[0906 15-27-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 212.64837, mean: 0.10849
[32m[0906 15-27-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01897, current rewards: 218.21792, mean: 0.10857
[32m[0906 15-27-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01897, current rewards: 223.78328, mean: 0.10863
[32m[0906 15-27-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01895, current rewards: 229.33019, mean: 0.10869
[32m[0906 15-27-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: 234.89669, mean: 0.10875
[32m[0906 15-27-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: 240.33623, mean: 0.10875
[32m[0906 15-27-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: 245.90303, mean: 0.10881
[32m[0906 15-27-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: 251.48085, mean: 0.10887
[32m[0906 15-27-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01892, current rewards: 257.04768, mean: 0.10892
[32m[0906 15-27-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 262.61993, mean: 0.10897
[32m[0906 15-27-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 268.18696, mean: 0.10902
[32m[0906 15-27-49 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-27-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-27-49 @MBExp.py:227][0m Rewards obtained: [272.6376051045813], Lows: [1], Highs: [2], Total time: 2798.9876760000006
[32m[0906 15-29-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-29-54 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 15-29-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01926, current rewards: 1.11183, mean: 0.11118
[32m[0906 15-29-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01932, current rewards: 6.81537, mean: 0.11359
[32m[0906 15-29-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 12.57427, mean: 0.11431
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 20.36947, mean: 0.12731
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01924, current rewards: -6.48672, mean: -0.03089
[32m[0906 15-29-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: -56.48672, mean: -0.21726
[32m[0906 15-30-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: -106.48672, mean: -0.34351
[32m[0906 15-30-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01926, current rewards: -156.48672, mean: -0.43469
[32m[0906 15-30-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: -206.48672, mean: -0.50363
[32m[0906 15-30-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: -256.48672, mean: -0.55758
[32m[0906 15-30-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: -306.48672, mean: -0.60095
[32m[0906 15-30-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: -356.48672, mean: -0.63658
[32m[0906 15-30-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: -406.48672, mean: -0.66637
[32m[0906 15-30-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: -456.48672, mean: -0.69165
[32m[0906 15-30-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: -506.48672, mean: -0.71336
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: -556.48672, mean: -0.73222
[32m[0906 15-30-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: -606.48672, mean: -0.74875
[32m[0906 15-30-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: -656.48672, mean: -0.76336
[32m[0906 15-30-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: -706.48672, mean: -0.77636
[32m[0906 15-30-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01927, current rewards: -756.48672, mean: -0.78801
[32m[0906 15-30-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: -806.48672, mean: -0.79850
[32m[0906 15-30-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: -856.48672, mean: -0.80801
[32m[0906 15-30-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01927, current rewards: -906.48672, mean: -0.81665
[32m[0906 15-30-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01923, current rewards: -956.48672, mean: -0.82456
[32m[0906 15-30-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: -1006.48672, mean: -0.83181
[32m[0906 15-30-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: -1056.48672, mean: -0.83848
[32m[0906 15-30-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: -1106.48672, mean: -0.84465
[32m[0906 15-30-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: -1156.48672, mean: -0.85036
[32m[0906 15-30-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: -1206.48672, mean: -0.85566
[32m[0906 15-30-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: -1256.48672, mean: -0.86061
[32m[0906 15-30-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: -1306.48672, mean: -0.86522
[32m[0906 15-30-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: -1356.48672, mean: -0.86954
[32m[0906 15-30-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: -1406.48672, mean: -0.87359
[32m[0906 15-30-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: -1456.48672, mean: -0.87740
[32m[0906 15-30-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01902, current rewards: -1506.48672, mean: -0.88099
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01901, current rewards: -1556.48672, mean: -0.88437
[32m[0906 15-30-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01900, current rewards: -1606.48672, mean: -0.88756
[32m[0906 15-30-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01900, current rewards: -1656.48672, mean: -0.89058
[32m[0906 15-30-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: -1706.48672, mean: -0.89345
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01898, current rewards: -1715.10749, mean: -0.87505
[32m[0906 15-30-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01897, current rewards: -1709.18962, mean: -0.85034
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01896, current rewards: -1703.27174, mean: -0.82683
[32m[0906 15-30-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01896, current rewards: -1697.35387, mean: -0.80443
[32m[0906 15-30-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: -1691.43599, mean: -0.78307
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: -1685.68839, mean: -0.76275
[32m[0906 15-30-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01894, current rewards: -1693.46039, mean: -0.74932
[32m[0906 15-30-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: -1743.46039, mean: -0.75474
[32m[0906 15-30-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: -1793.46039, mean: -0.75994
[32m[0906 15-30-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: -1843.46039, mean: -0.76492
[32m[0906 15-30-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: -1893.46039, mean: -0.76970
[32m[0906 15-30-42 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-30-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-30-42 @MBExp.py:227][0m Rewards obtained: [-1933.4603948415095], Lows: [0], Highs: [1995], Total time: 2846.9708740000005
[32m[0906 15-32-48 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-48 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 15-32-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.08179, mean: 0.10818
[32m[0906 15-32-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01893, current rewards: 6.57532, mean: 0.10959
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.13371, mean: 0.11031
[32m[0906 15-32-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.71715, mean: 0.11073
[32m[0906 15-32-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.25787, mean: 0.11075
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 28.79996, mean: 0.11077
[32m[0906 15-32-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 34.33753, mean: 0.11077
[32m[0906 15-32-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01922, current rewards: 39.87580, mean: 0.11077
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 45.37791, mean: 0.11068
[32m[0906 15-32-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 50.88721, mean: 0.11062
[32m[0906 15-32-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 56.39400, mean: 0.11058
[32m[0906 15-32-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 61.85250, mean: 0.11045
[32m[0906 15-33-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 67.36527, mean: 0.11043
[32m[0906 15-33-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 72.87813, mean: 0.11042
[32m[0906 15-33-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 78.38800, mean: 0.11041
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 83.90144, mean: 0.11040
[32m[0906 15-33-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 89.41102, mean: 0.11038
[32m[0906 15-33-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: 94.98362, mean: 0.11045
[32m[0906 15-33-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 100.49782, mean: 0.11044
[32m[0906 15-33-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 106.10858, mean: 0.11053
[32m[0906 15-33-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: 111.62096, mean: 0.11052
[32m[0906 15-33-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01927, current rewards: 117.14604, mean: 0.11052
[32m[0906 15-33-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01927, current rewards: 122.66257, mean: 0.11051
[32m[0906 15-33-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01924, current rewards: 128.18009, mean: 0.11050
[32m[0906 15-33-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: 133.76159, mean: 0.11055
[32m[0906 15-33-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 139.29948, mean: 0.11056
[32m[0906 15-33-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 144.84162, mean: 0.11057
[32m[0906 15-33-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 150.41142, mean: 0.11060
[32m[0906 15-33-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 155.96229, mean: 0.11061
[32m[0906 15-33-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 161.50571, mean: 0.11062
[32m[0906 15-33-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 167.05127, mean: 0.11063
[32m[0906 15-33-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 172.59683, mean: 0.11064
[32m[0906 15-33-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 178.19270, mean: 0.11068
[32m[0906 15-33-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 183.73934, mean: 0.11069
[32m[0906 15-33-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01904, current rewards: 189.29096, mean: 0.11070
[32m[0906 15-33-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: 194.81909, mean: 0.11069
[32m[0906 15-33-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01902, current rewards: 200.30912, mean: 0.11067
[32m[0906 15-33-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01901, current rewards: 205.84977, mean: 0.11067
[32m[0906 15-33-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01900, current rewards: 211.44669, mean: 0.11071
[32m[0906 15-33-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01900, current rewards: 216.97330, mean: 0.11070
[32m[0906 15-33-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01898, current rewards: 222.49651, mean: 0.11069
[32m[0906 15-33-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: 228.01725, mean: 0.11069
[32m[0906 15-33-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: 233.54435, mean: 0.11068
[32m[0906 15-33-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: 239.07034, mean: 0.11068
[32m[0906 15-33-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01896, current rewards: 244.61045, mean: 0.11068
[32m[0906 15-33-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: 250.13652, mean: 0.11068
[32m[0906 15-33-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01894, current rewards: 254.55086, mean: 0.11020
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 260.08921, mean: 0.11021
[32m[0906 15-33-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: 265.62916, mean: 0.11022
[32m[0906 15-33-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 271.16478, mean: 0.11023
[32m[0906 15-33-36 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-33-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-33-36 @MBExp.py:227][0m Rewards obtained: [275.5979823653532], Lows: [0], Highs: [1], Total time: 2894.9854020000007
[32m[0906 15-35-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-35-45 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 15-35-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.35116, mean: 0.13512
[32m[0906 15-35-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 6.83290, mean: 0.11388
[32m[0906 15-35-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 12.43999, mean: 0.11309
[32m[0906 15-35-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01928, current rewards: 18.06051, mean: 0.11288
[32m[0906 15-35-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01931, current rewards: 23.60653, mean: 0.11241
[32m[0906 15-35-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01927, current rewards: 29.15516, mean: 0.11214
[32m[0906 15-35-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 34.80401, mean: 0.11227
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 40.37504, mean: 0.11215
[32m[0906 15-35-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 45.94787, mean: 0.11207
[32m[0906 15-35-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 51.52016, mean: 0.11200
[32m[0906 15-35-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: 57.09551, mean: 0.11195
[32m[0906 15-35-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 62.52704, mean: 0.11166
[32m[0906 15-35-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 68.10108, mean: 0.11164
[32m[0906 15-35-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01928, current rewards: 73.66900, mean: 0.11162
[32m[0906 15-35-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01928, current rewards: 79.24055, mean: 0.11161
[32m[0906 15-36-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01929, current rewards: 84.81198, mean: 0.11159
[32m[0906 15-36-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: 90.38263, mean: 0.11158
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 95.95228, mean: 0.11157
[32m[0906 15-36-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 101.52300, mean: 0.11156
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01927, current rewards: 107.09015, mean: 0.11155
[32m[0906 15-36-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: 112.72782, mean: 0.11161
[32m[0906 15-36-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01928, current rewards: 118.27757, mean: 0.11158
[32m[0906 15-36-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 123.82249, mean: 0.11155
[32m[0906 15-36-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: 129.37463, mean: 0.11153
[32m[0906 15-36-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 134.92699, mean: 0.11151
[32m[0906 15-36-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 140.47807, mean: 0.11149
[32m[0906 15-36-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 146.02690, mean: 0.11147
[32m[0906 15-36-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 151.57867, mean: 0.11145
[32m[0906 15-36-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 157.13027, mean: 0.11144
[32m[0906 15-36-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 162.67963, mean: 0.11142
[32m[0906 15-36-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 168.23647, mean: 0.11141
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 171.64364, mean: 0.11003
[32m[0906 15-36-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 177.14912, mean: 0.11003
[32m[0906 15-36-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 182.65504, mean: 0.11003
[32m[0906 15-36-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 188.16169, mean: 0.11004
[32m[0906 15-36-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 193.66659, mean: 0.11004
[32m[0906 15-36-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01904, current rewards: 199.15260, mean: 0.11003
[32m[0906 15-36-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: 204.82554, mean: 0.11012
[32m[0906 15-36-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: 210.49385, mean: 0.11021
[32m[0906 15-36-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: 216.08852, mean: 0.11025
[32m[0906 15-36-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: 221.62217, mean: 0.11026
[32m[0906 15-36-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01900, current rewards: 227.14565, mean: 0.11026
[32m[0906 15-36-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01899, current rewards: 232.68020, mean: 0.11027
[32m[0906 15-36-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01899, current rewards: 238.21462, mean: 0.11028
[32m[0906 15-36-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01898, current rewards: 243.80253, mean: 0.11032
[32m[0906 15-36-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01898, current rewards: 249.32577, mean: 0.11032
[32m[0906 15-36-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01897, current rewards: 254.84971, mean: 0.11032
[32m[0906 15-36-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01897, current rewards: 260.37928, mean: 0.11033
[32m[0906 15-36-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01896, current rewards: 265.95984, mean: 0.11036
[32m[0906 15-36-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01896, current rewards: 271.54245, mean: 0.11038
[32m[0906 15-36-33 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-36-33 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-36-33 @MBExp.py:227][0m Rewards obtained: [276.0043549183814], Lows: [1], Highs: [0], Total time: 2943.087822000001
[32m[0906 15-38-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-44 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 15-38-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01956, current rewards: 1.08733, mean: 0.10873
[32m[0906 15-38-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 6.64552, mean: 0.11076
[32m[0906 15-38-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01910, current rewards: 12.21768, mean: 0.11107
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.78502, mean: 0.11116
[32m[0906 15-38-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.34449, mean: 0.11116
[32m[0906 15-38-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 28.90199, mean: 0.11116
[32m[0906 15-38-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.45403, mean: 0.11114
[32m[0906 15-38-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 40.01580, mean: 0.11115
[32m[0906 15-38-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.57410, mean: 0.11116
[32m[0906 15-38-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01924, current rewards: 51.13628, mean: 0.11117
[32m[0906 15-38-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: 56.69969, mean: 0.11118
[32m[0906 15-38-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 62.31771, mean: 0.11128
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01924, current rewards: 67.78637, mean: 0.11113
[32m[0906 15-38-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 73.21551, mean: 0.11093
[32m[0906 15-38-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.64282, mean: 0.11076
[32m[0906 15-38-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 84.07437, mean: 0.11062
[32m[0906 15-38-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 89.50195, mean: 0.11050
[32m[0906 15-39-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01924, current rewards: 94.93123, mean: 0.11039
[32m[0906 15-39-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01923, current rewards: 100.32640, mean: 0.11025
[32m[0906 15-39-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 105.84580, mean: 0.11026
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01924, current rewards: 111.46400, mean: 0.11036
[32m[0906 15-39-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 117.09355, mean: 0.11047
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 122.70975, mean: 0.11055
[32m[0906 15-39-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 128.33475, mean: 0.11063
[32m[0906 15-39-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 133.96614, mean: 0.11072
[32m[0906 15-39-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 139.58485, mean: 0.11078
[32m[0906 15-39-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 145.20511, mean: 0.11084
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 150.78575, mean: 0.11087
[32m[0906 15-39-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 156.34682, mean: 0.11088
[32m[0906 15-39-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 161.82748, mean: 0.11084
[32m[0906 15-39-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 167.30414, mean: 0.11080
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01904, current rewards: 174.84292, mean: 0.11208
[32m[0906 15-39-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 182.91721, mean: 0.11361
[32m[0906 15-39-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01901, current rewards: 190.99150, mean: 0.11506
[32m[0906 15-39-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01900, current rewards: 199.06579, mean: 0.11641
[32m[0906 15-39-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01898, current rewards: 207.14008, mean: 0.11769
[32m[0906 15-39-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: 201.55467, mean: 0.11136
[32m[0906 15-39-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: 207.07186, mean: 0.11133
[32m[0906 15-39-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 212.58890, mean: 0.11130
[32m[0906 15-39-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01895, current rewards: 218.10756, mean: 0.11128
[32m[0906 15-39-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 223.62414, mean: 0.11126
[32m[0906 15-39-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01894, current rewards: 229.14425, mean: 0.11124
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: 234.66235, mean: 0.11121
[32m[0906 15-39-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01893, current rewards: 240.18171, mean: 0.11120
[32m[0906 15-39-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: 245.68088, mean: 0.11117
[32m[0906 15-39-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01892, current rewards: 251.23260, mean: 0.11116
[32m[0906 15-39-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 256.78757, mean: 0.11116
[32m[0906 15-39-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 262.34480, mean: 0.11116
[32m[0906 15-39-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 267.89974, mean: 0.11116
[32m[0906 15-39-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 273.45910, mean: 0.11116
[32m[0906 15-39-32 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-39-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-39-32 @MBExp.py:227][0m Rewards obtained: [277.9078784944894], Lows: [0], Highs: [11], Total time: 2991.025911000001
[32m[0906 15-41-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-44 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 15-41-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 1.75213, mean: 0.17521
[32m[0906 15-41-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01926, current rewards: 7.14307, mean: 0.11905
[32m[0906 15-41-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01920, current rewards: 12.74909, mean: 0.11590
[32m[0906 15-41-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 18.92169, mean: 0.11826
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 26.19590, mean: 0.12474
[32m[0906 15-41-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 33.47012, mean: 0.12873
[32m[0906 15-41-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 40.74433, mean: 0.13143
[32m[0906 15-41-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: -5.81922, mean: -0.01616
[32m[0906 15-41-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: -55.81922, mean: -0.13614
[32m[0906 15-41-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: -105.81922, mean: -0.23004
[32m[0906 15-41-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: -155.81922, mean: -0.30553
[32m[0906 15-41-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: -205.81922, mean: -0.36753
[32m[0906 15-41-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: -255.81922, mean: -0.41938
[32m[0906 15-41-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: -305.81922, mean: -0.46336
[32m[0906 15-41-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: -355.81922, mean: -0.50115
[32m[0906 15-41-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: -405.81922, mean: -0.53397
[32m[0906 15-42-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: -455.81922, mean: -0.56274
[32m[0906 15-42-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: -505.81922, mean: -0.58816
[32m[0906 15-42-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: -555.81922, mean: -0.61079
[32m[0906 15-42-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01920, current rewards: -605.81922, mean: -0.63106
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: -655.81922, mean: -0.64933
[32m[0906 15-42-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01918, current rewards: -705.81922, mean: -0.66587
[32m[0906 15-42-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: -755.81922, mean: -0.68092
[32m[0906 15-42-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: -805.81922, mean: -0.69467
[32m[0906 15-42-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: -855.81922, mean: -0.70729
[32m[0906 15-42-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: -905.81922, mean: -0.71890
[32m[0906 15-42-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: -955.81922, mean: -0.72963
[32m[0906 15-42-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: -1005.81922, mean: -0.73957
[32m[0906 15-42-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: -1055.81922, mean: -0.74881
[32m[0906 15-42-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: -1105.81922, mean: -0.75741
[32m[0906 15-42-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: -1155.81922, mean: -0.76544
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01901, current rewards: -1205.81922, mean: -0.77296
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: -1255.81922, mean: -0.78001
[32m[0906 15-42-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: -1305.81922, mean: -0.78664
[32m[0906 15-42-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: -1355.81922, mean: -0.79288
[32m[0906 15-42-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: -1405.81922, mean: -0.79876
[32m[0906 15-42-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: -1455.81922, mean: -0.80432
[32m[0906 15-42-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01895, current rewards: -1505.81922, mean: -0.80958
[32m[0906 15-42-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01893, current rewards: -1555.81922, mean: -0.81457
[32m[0906 15-42-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01892, current rewards: -1605.81922, mean: -0.81930
[32m[0906 15-42-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01892, current rewards: -1655.81922, mean: -0.82379
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01891, current rewards: -1705.81922, mean: -0.82807
[32m[0906 15-42-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01890, current rewards: -1755.81922, mean: -0.83214
[32m[0906 15-42-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: -1805.81922, mean: -0.83603
[32m[0906 15-42-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: -1855.81922, mean: -0.83974
[32m[0906 15-42-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: -1905.81922, mean: -0.84328
[32m[0906 15-42-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: -1955.81922, mean: -0.84667
[32m[0906 15-42-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: -2005.81922, mean: -0.84992
[32m[0906 15-42-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: -2055.81922, mean: -0.85304
[32m[0906 15-42-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: -2105.81922, mean: -0.85602
[32m[0906 15-42-32 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 15-42-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-42-32 @MBExp.py:227][0m Rewards obtained: [-2145.8192157642843], Lows: [0], Highs: [2187], Total time: 3038.877538000001
[32m[0906 15-44-47 @MBExp.py:144][0m ####################################################################
[32m[0906 15-44-47 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 15-44-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: 1.12763, mean: 0.11276
[32m[0906 15-44-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.66445, mean: 0.11107
[32m[0906 15-44-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.19172, mean: 0.11083
[32m[0906 15-44-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.72483, mean: 0.11078
[32m[0906 15-44-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.25303, mean: 0.11073
[32m[0906 15-44-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 28.78415, mean: 0.11071
[32m[0906 15-44-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 34.31689, mean: 0.11070
[32m[0906 15-44-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 39.85570, mean: 0.11071
[32m[0906 15-44-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.39780, mean: 0.11073
[32m[0906 15-44-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 50.94001, mean: 0.11074
[32m[0906 15-44-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.45286, mean: 0.11069
[32m[0906 15-44-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 61.99778, mean: 0.11071
[32m[0906 15-44-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.54230, mean: 0.11073
[32m[0906 15-45-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.08798, mean: 0.11074
[32m[0906 15-45-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 78.62992, mean: 0.11075
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 84.17195, mean: 0.11075
[32m[0906 15-45-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 89.72244, mean: 0.11077
[32m[0906 15-45-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 95.26335, mean: 0.11077
[32m[0906 15-45-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.77266, mean: 0.11074
[32m[0906 15-45-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 106.31438, mean: 0.11074
[32m[0906 15-45-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 111.85639, mean: 0.11075
[32m[0906 15-45-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 117.41564, mean: 0.11077
[32m[0906 15-45-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 123.00967, mean: 0.11082
[32m[0906 15-45-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 128.60149, mean: 0.11086
[32m[0906 15-45-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 134.20067, mean: 0.11091
[32m[0906 15-45-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 139.79424, mean: 0.11095
[32m[0906 15-45-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 145.52405, mean: 0.11109
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 151.08889, mean: 0.11109
[32m[0906 15-45-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 156.65447, mean: 0.11110
[32m[0906 15-45-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 162.21989, mean: 0.11111
[32m[0906 15-45-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 167.78640, mean: 0.11112
[32m[0906 15-45-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 173.35032, mean: 0.11112
[32m[0906 15-45-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: 178.91446, mean: 0.11113
[32m[0906 15-45-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 184.47868, mean: 0.11113
[32m[0906 15-45-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 190.05217, mean: 0.11114
[32m[0906 15-45-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: 195.56525, mean: 0.11112
[32m[0906 15-45-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: 201.11196, mean: 0.11111
[32m[0906 15-45-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01895, current rewards: 206.65862, mean: 0.11111
[32m[0906 15-45-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 212.20427, mean: 0.11110
[32m[0906 15-45-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01895, current rewards: 217.74809, mean: 0.11110
[32m[0906 15-45-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 223.29563, mean: 0.11109
[32m[0906 15-45-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01894, current rewards: 227.71894, mean: 0.11054
[32m[0906 15-45-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: 233.24321, mean: 0.11054
[32m[0906 15-45-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01892, current rewards: 238.71299, mean: 0.11052
[32m[0906 15-45-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: 244.24897, mean: 0.11052
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01892, current rewards: 249.78164, mean: 0.11052
[32m[0906 15-45-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 255.32083, mean: 0.11053
[32m[0906 15-45-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 260.85273, mean: 0.11053
[32m[0906 15-45-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 266.38333, mean: 0.11053
[32m[0906 15-45-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 271.91720, mean: 0.11054
[32m[0906 15-45-35 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-45-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-45-35 @MBExp.py:227][0m Rewards obtained: [276.34553089820037], Lows: [0], Highs: [1], Total time: 3086.8287990000013
[32m[0906 15-47-52 @MBExp.py:144][0m ####################################################################
[32m[0906 15-47-52 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 15-47-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01882, current rewards: 1.05850, mean: 0.10585
[32m[0906 15-47-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 6.66597, mean: 0.11110
[32m[0906 15-47-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01925, current rewards: 12.20866, mean: 0.11099
[32m[0906 15-47-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 17.75205, mean: 0.11095
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01924, current rewards: 23.30334, mean: 0.11097
[32m[0906 15-47-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 28.85627, mean: 0.11099
[32m[0906 15-47-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 34.39914, mean: 0.11096
[32m[0906 15-47-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.94265, mean: 0.11095
[32m[0906 15-48-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 45.48722, mean: 0.11094
[32m[0906 15-48-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 51.00018, mean: 0.11087
[32m[0906 15-48-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.52199, mean: 0.11083
[32m[0906 15-48-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01929, current rewards: 62.06635, mean: 0.11083
[32m[0906 15-48-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01929, current rewards: 67.61082, mean: 0.11084
[32m[0906 15-48-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 73.15579, mean: 0.11084
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01928, current rewards: 78.69629, mean: 0.11084
[32m[0906 15-48-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01929, current rewards: 84.23678, mean: 0.11084
[32m[0906 15-48-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: 89.82342, mean: 0.11089
[32m[0906 15-48-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01929, current rewards: 95.38498, mean: 0.11091
[32m[0906 15-48-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01930, current rewards: 100.94659, mean: 0.11093
[32m[0906 15-48-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01930, current rewards: 106.50803, mean: 0.11095
[32m[0906 15-48-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01930, current rewards: 112.07559, mean: 0.11097
[32m[0906 15-48-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01930, current rewards: 117.63919, mean: 0.11098
[32m[0906 15-48-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01926, current rewards: 123.19965, mean: 0.11099
[32m[0906 15-48-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01923, current rewards: 128.76159, mean: 0.11100
[32m[0906 15-48-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 133.20050, mean: 0.11008
[32m[0906 15-48-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: 138.74265, mean: 0.11011
[32m[0906 15-48-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 144.34845, mean: 0.11019
[32m[0906 15-48-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 149.88531, mean: 0.11021
[32m[0906 15-48-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 155.42124, mean: 0.11023
[32m[0906 15-48-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 160.94967, mean: 0.11024
[32m[0906 15-48-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 166.48514, mean: 0.11026
[32m[0906 15-48-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 172.01250, mean: 0.11026
[32m[0906 15-48-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 173.34861, mean: 0.10767
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 178.89864, mean: 0.10777
[32m[0906 15-48-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 184.36747, mean: 0.10782
[32m[0906 15-48-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: 189.92745, mean: 0.10791
[32m[0906 15-48-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01902, current rewards: 195.49248, mean: 0.10801
[32m[0906 15-48-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01901, current rewards: 201.05321, mean: 0.10809
[32m[0906 15-48-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01900, current rewards: 206.61666, mean: 0.10818
[32m[0906 15-48-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01899, current rewards: 212.18010, mean: 0.10826
[32m[0906 15-48-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01898, current rewards: 217.73638, mean: 0.10833
[32m[0906 15-48-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: 223.28598, mean: 0.10839
[32m[0906 15-48-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: 228.83643, mean: 0.10845
[32m[0906 15-48-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: 234.39053, mean: 0.10851
[32m[0906 15-48-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01896, current rewards: 239.94781, mean: 0.10857
[32m[0906 15-48-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: 245.49602, mean: 0.10863
[32m[0906 15-48-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01895, current rewards: 251.04764, mean: 0.10868
[32m[0906 15-48-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01894, current rewards: 256.59607, mean: 0.10873
[32m[0906 15-48-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: 262.15061, mean: 0.10878
[32m[0906 15-48-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 267.70384, mean: 0.10882
[32m[0906 15-48-40 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-48-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-48-40 @MBExp.py:227][0m Rewards obtained: [272.1477568513833], Lows: [2], Highs: [1], Total time: 3134.8703870000013
[32m[0906 15-50-59 @MBExp.py:144][0m ####################################################################
[32m[0906 15-50-59 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 15-50-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01955, current rewards: 1.14881, mean: 0.11488
[32m[0906 15-51-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01936, current rewards: 6.70211, mean: 0.11170
[32m[0906 15-51-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01933, current rewards: 12.26016, mean: 0.11146
[32m[0906 15-51-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01934, current rewards: 17.82063, mean: 0.11138
[32m[0906 15-51-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01929, current rewards: 23.38372, mean: 0.11135
[32m[0906 15-51-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01931, current rewards: 28.94140, mean: 0.11131
[32m[0906 15-51-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01932, current rewards: 34.50352, mean: 0.11130
[32m[0906 15-51-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01931, current rewards: 40.06237, mean: 0.11128
[32m[0906 15-51-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01930, current rewards: 45.62238, mean: 0.11127
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01931, current rewards: 51.10592, mean: 0.11110
[32m[0906 15-51-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01933, current rewards: 56.69823, mean: 0.11117
[32m[0906 15-51-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01933, current rewards: 62.28609, mean: 0.11123
[32m[0906 15-51-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01933, current rewards: 67.87083, mean: 0.11126
[32m[0906 15-51-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01933, current rewards: 73.45933, mean: 0.11130
[32m[0906 15-51-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01934, current rewards: 79.05005, mean: 0.11134
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01935, current rewards: 84.64087, mean: 0.11137
[32m[0906 15-51-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01935, current rewards: 90.23110, mean: 0.11140
[32m[0906 15-51-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01936, current rewards: 95.88094, mean: 0.11149
[32m[0906 15-51-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01936, current rewards: 101.46866, mean: 0.11150
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01935, current rewards: 107.05614, mean: 0.11152
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01934, current rewards: 112.63457, mean: 0.11152
[32m[0906 15-51-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01932, current rewards: 118.21968, mean: 0.11153
[32m[0906 15-51-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01928, current rewards: 123.80755, mean: 0.11154
[32m[0906 15-51-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: 129.39419, mean: 0.11155
[32m[0906 15-51-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 134.98072, mean: 0.11155
[32m[0906 15-51-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 140.54733, mean: 0.11155
[32m[0906 15-51-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: 146.10715, mean: 0.11153
[32m[0906 15-51-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 151.66640, mean: 0.11152
[32m[0906 15-51-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 157.22400, mean: 0.11151
[32m[0906 15-51-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 162.79558, mean: 0.11150
[32m[0906 15-51-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 168.35147, mean: 0.11149
[32m[0906 15-51-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 173.91769, mean: 0.11149
[32m[0906 15-51-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 179.47795, mean: 0.11148
[32m[0906 15-51-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 185.03422, mean: 0.11147
[32m[0906 15-51-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: 190.66618, mean: 0.11150
[32m[0906 15-51-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 196.20287, mean: 0.11148
[32m[0906 15-51-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01904, current rewards: 202.22305, mean: 0.11173
[32m[0906 15-51-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: 208.26832, mean: 0.11197
[32m[0906 15-51-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: 214.31358, mean: 0.11221
[32m[0906 15-51-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: 220.35885, mean: 0.11243
[32m[0906 15-51-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: 226.40412, mean: 0.11264
[32m[0906 15-51-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: 232.44939, mean: 0.11284
[32m[0906 15-51-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01898, current rewards: 237.97847, mean: 0.11279
[32m[0906 15-51-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01898, current rewards: 243.55842, mean: 0.11276
[32m[0906 15-51-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01897, current rewards: 249.14984, mean: 0.11274
[32m[0906 15-51-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01897, current rewards: 254.74168, mean: 0.11272
[32m[0906 15-51-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01897, current rewards: 260.32899, mean: 0.11270
[32m[0906 15-51-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01896, current rewards: 265.91640, mean: 0.11268
[32m[0906 15-51-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01896, current rewards: 271.50685, mean: 0.11266
[32m[0906 15-51-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01895, current rewards: 277.09891, mean: 0.11264
[32m[0906 15-51-47 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-51-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-51-47 @MBExp.py:227][0m Rewards obtained: [281.56645067929384], Lows: [0], Highs: [0], Total time: 3182.987140000001
[32m[0906 15-54-07 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-07 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 15-54-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01893, current rewards: -0.99837, mean: -0.09984
[32m[0906 15-54-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01929, current rewards: 4.49451, mean: 0.07491
[32m[0906 15-54-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 10.02474, mean: 0.09113
[32m[0906 15-54-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 15.55259, mean: 0.09720
[32m[0906 15-54-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01930, current rewards: 21.08335, mean: 0.10040
[32m[0906 15-54-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01930, current rewards: 26.61385, mean: 0.10236
[32m[0906 15-54-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01929, current rewards: 32.14604, mean: 0.10370
[32m[0906 15-54-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01932, current rewards: 37.67938, mean: 0.10466
[32m[0906 15-54-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 43.21434, mean: 0.10540
[32m[0906 15-54-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 48.79091, mean: 0.10607
[32m[0906 15-54-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: 54.32540, mean: 0.10652
[32m[0906 15-54-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 59.85230, mean: 0.10688
[32m[0906 15-54-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 65.37737, mean: 0.10718
[32m[0906 15-54-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 70.90545, mean: 0.10743
[32m[0906 15-54-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: 76.43633, mean: 0.10766
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 81.97583, mean: 0.10786
[32m[0906 15-54-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01927, current rewards: 87.53149, mean: 0.10806
[32m[0906 15-54-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01927, current rewards: 93.04981, mean: 0.10820
[32m[0906 15-54-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01926, current rewards: 98.61038, mean: 0.10836
[32m[0906 15-54-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 104.17054, mean: 0.10851
[32m[0906 15-54-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 109.72848, mean: 0.10864
[32m[0906 15-54-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 115.28711, mean: 0.10876
[32m[0906 15-54-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 120.84175, mean: 0.10887
[32m[0906 15-54-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 126.40094, mean: 0.10897
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 131.95922, mean: 0.10906
[32m[0906 15-54-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 137.58819, mean: 0.10920
[32m[0906 15-54-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 143.14255, mean: 0.10927
[32m[0906 15-54-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 148.68864, mean: 0.10933
[32m[0906 15-54-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 154.23282, mean: 0.10938
[32m[0906 15-54-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 159.77689, mean: 0.10944
[32m[0906 15-54-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 165.31215, mean: 0.10948
[32m[0906 15-54-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 170.89152, mean: 0.10955
[32m[0906 15-54-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01901, current rewards: 176.47263, mean: 0.10961
[32m[0906 15-54-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 182.07738, mean: 0.10969
[32m[0906 15-54-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 187.67538, mean: 0.10975
[32m[0906 15-54-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01898, current rewards: 193.26874, mean: 0.10981
[32m[0906 15-54-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: 198.80763, mean: 0.10984
[32m[0906 15-54-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: 204.32531, mean: 0.10985
[32m[0906 15-54-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 209.83063, mean: 0.10986
[32m[0906 15-54-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01895, current rewards: 215.34817, mean: 0.10987
[32m[0906 15-54-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 220.87091, mean: 0.10989
[32m[0906 15-54-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01893, current rewards: 226.38985, mean: 0.10990
[32m[0906 15-54-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: 231.79070, mean: 0.10985
[32m[0906 15-54-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01892, current rewards: 237.30021, mean: 0.10986
[32m[0906 15-54-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: 242.81707, mean: 0.10987
[32m[0906 15-54-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 248.33565, mean: 0.10988
[32m[0906 15-54-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: 253.85188, mean: 0.10989
[32m[0906 15-54-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 259.37238, mean: 0.10990
[32m[0906 15-54-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 264.88304, mean: 0.10991
[32m[0906 15-54-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 270.40176, mean: 0.10992
[32m[0906 15-54-55 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-54-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-54-55 @MBExp.py:227][0m Rewards obtained: [274.897695040618], Lows: [1], Highs: [0], Total time: 3230.938435000001
[32m[0906 15-57-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-57-18 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 15-57-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: -1.04684, mean: -0.10468
[32m[0906 15-57-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01912, current rewards: 4.56182, mean: 0.07603
[32m[0906 15-57-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 10.17248, mean: 0.09248
[32m[0906 15-57-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 15.78611, mean: 0.09866
[32m[0906 15-57-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 21.39952, mean: 0.10190
[32m[0906 15-57-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 27.00860, mean: 0.10388
[32m[0906 15-57-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 32.61456, mean: 0.10521
[32m[0906 15-57-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 38.20530, mean: 0.10613
[32m[0906 15-57-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 43.84086, mean: 0.10693
[32m[0906 15-57-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 49.42208, mean: 0.10744
[32m[0906 15-57-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 55.00844, mean: 0.10786
[32m[0906 15-57-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 60.59874, mean: 0.10821
[32m[0906 15-57-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 66.18300, mean: 0.10850
[32m[0906 15-57-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 71.76646, mean: 0.10874
[32m[0906 15-57-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 77.34589, mean: 0.10894
[32m[0906 15-57-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 82.88550, mean: 0.10906
[32m[0906 15-57-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 88.14351, mean: 0.10882
[32m[0906 15-57-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 93.38694, mean: 0.10859
[32m[0906 15-57-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 98.64168, mean: 0.10840
[32m[0906 15-57-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 103.89851, mean: 0.10823
[32m[0906 15-57-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 109.15314, mean: 0.10807
[32m[0906 15-57-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 114.40748, mean: 0.10793
[32m[0906 15-57-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 119.66112, mean: 0.10780
[32m[0906 15-57-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 124.91643, mean: 0.10769
[32m[0906 15-57-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 130.39504, mean: 0.10776
[32m[0906 15-57-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 136.03538, mean: 0.10796
[32m[0906 15-57-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 141.62245, mean: 0.10811
[32m[0906 15-57-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 147.21016, mean: 0.10824
[32m[0906 15-57-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 152.79807, mean: 0.10837
[32m[0906 15-57-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 158.38805, mean: 0.10848
[32m[0906 15-57-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: 163.97389, mean: 0.10859
[32m[0906 15-57-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01901, current rewards: 169.56123, mean: 0.10869
[32m[0906 15-57-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: 175.13314, mean: 0.10878
[32m[0906 15-57-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 180.70773, mean: 0.10886
[32m[0906 15-57-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 186.27997, mean: 0.10894
[32m[0906 15-57-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01898, current rewards: 191.84730, mean: 0.10900
[32m[0906 15-57-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: 197.41696, mean: 0.10907
[32m[0906 15-57-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: 202.98661, mean: 0.10913
[32m[0906 15-57-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 208.55701, mean: 0.10919
[32m[0906 15-57-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01894, current rewards: 214.02523, mean: 0.10920
[32m[0906 15-57-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 219.43866, mean: 0.10917
[32m[0906 15-57-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 224.84490, mean: 0.10915
[32m[0906 15-57-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 230.31686, mean: 0.10915
[32m[0906 15-58-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 235.79273, mean: 0.10916
[32m[0906 15-58-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 241.26557, mean: 0.10917
[32m[0906 15-58-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 246.73665, mean: 0.10918
[32m[0906 15-58-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 252.20546, mean: 0.10918
[32m[0906 15-58-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 257.67729, mean: 0.10919
[32m[0906 15-58-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 263.14778, mean: 0.10919
[32m[0906 15-58-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 268.61104, mean: 0.10919
[32m[0906 15-58-06 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-58-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-58-06 @MBExp.py:227][0m Rewards obtained: [272.9065938745459], Lows: [1], Highs: [0], Total time: 3278.894134000001
[32m[0906 16-00-31 @MBExp.py:144][0m ####################################################################
[32m[0906 16-00-31 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01877, current rewards: 1.22860, mean: 0.12286
[32m[0906 16-00-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.64366, mean: 0.11073
[32m[0906 16-00-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.10075, mean: 0.11001
[32m[0906 16-00-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 17.55629, mean: 0.10973
[32m[0906 16-00-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 23.00842, mean: 0.10956
[32m[0906 16-00-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 28.46740, mean: 0.10949
[32m[0906 16-00-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 34.01436, mean: 0.10972
[32m[0906 16-00-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 39.58512, mean: 0.10996
[32m[0906 16-00-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.11680, mean: 0.11004
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 50.67740, mean: 0.11017
[32m[0906 16-00-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.23929, mean: 0.11027
[32m[0906 16-00-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 61.79946, mean: 0.11036
[32m[0906 16-00-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.35364, mean: 0.11042
[32m[0906 16-00-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 72.91314, mean: 0.11047
[32m[0906 16-00-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 78.46987, mean: 0.11052
[32m[0906 16-00-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 84.03012, mean: 0.11057
[32m[0906 16-00-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 89.61982, mean: 0.11064
[32m[0906 16-00-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 95.19329, mean: 0.11069
[32m[0906 16-00-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 100.76039, mean: 0.11073
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 106.33472, mean: 0.11077
[32m[0906 16-00-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 111.93163, mean: 0.11082
[32m[0906 16-00-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 117.47870, mean: 0.11083
[32m[0906 16-00-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 123.02614, mean: 0.11083
[32m[0906 16-00-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 128.57520, mean: 0.11084
[32m[0906 16-00-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 134.13204, mean: 0.11085
[32m[0906 16-00-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01908, current rewards: 139.67063, mean: 0.11085
[32m[0906 16-00-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: 145.21260, mean: 0.11085
[32m[0906 16-00-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01904, current rewards: 150.75383, mean: 0.11085
[32m[0906 16-00-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: 156.25024, mean: 0.11082
[32m[0906 16-00-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 161.79344, mean: 0.11082
[32m[0906 16-01-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01900, current rewards: 167.33895, mean: 0.11082
[32m[0906 16-01-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01898, current rewards: 172.87907, mean: 0.11082
[32m[0906 16-01-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01897, current rewards: 178.39818, mean: 0.11081
[32m[0906 16-01-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 183.93740, mean: 0.11081
[32m[0906 16-01-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: 189.47497, mean: 0.11080
[32m[0906 16-01-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01893, current rewards: 195.00837, mean: 0.11080
[32m[0906 16-01-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01892, current rewards: 200.54925, mean: 0.11080
[32m[0906 16-01-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01891, current rewards: 206.08512, mean: 0.11080
[32m[0906 16-01-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01890, current rewards: 211.62626, mean: 0.11080
[32m[0906 16-01-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01889, current rewards: 217.16452, mean: 0.11080
[32m[0906 16-01-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 222.74194, mean: 0.11082
[32m[0906 16-01-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 228.25537, mean: 0.11080
[32m[0906 16-01-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 233.80528, mean: 0.11081
[32m[0906 16-01-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 239.35177, mean: 0.11081
[32m[0906 16-01-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 244.90407, mean: 0.11082
[32m[0906 16-01-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 250.45338, mean: 0.11082
[32m[0906 16-01-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 256.00365, mean: 0.11082
[32m[0906 16-01-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 261.55212, mean: 0.11083
[32m[0906 16-01-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 267.13678, mean: 0.11085
[32m[0906 16-01-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: 272.74542, mean: 0.11087
[32m[0906 16-01-19 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-01-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-01-19 @MBExp.py:227][0m Rewards obtained: [277.20070056892746], Lows: [0], Highs: [0], Total time: 3326.759851000001
[32m[0906 16-03-46 @MBExp.py:144][0m ####################################################################
[32m[0906 16-03-46 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-03-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01886, current rewards: 1.10885, mean: 0.11088
[32m[0906 16-03-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01926, current rewards: 6.66311, mean: 0.11105
[32m[0906 16-03-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01932, current rewards: 12.21714, mean: 0.11106
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01931, current rewards: 17.77104, mean: 0.11107
[32m[0906 16-03-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01929, current rewards: 23.32473, mean: 0.11107
[32m[0906 16-03-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01929, current rewards: 28.87938, mean: 0.11107
[32m[0906 16-03-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01935, current rewards: 34.43348, mean: 0.11108
[32m[0906 16-03-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01937, current rewards: 39.98703, mean: 0.11108
[32m[0906 16-03-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01935, current rewards: 43.29019, mean: 0.10559
[32m[0906 16-03-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01933, current rewards: 48.82925, mean: 0.10615
[32m[0906 16-03-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01932, current rewards: 54.37076, mean: 0.10661
[32m[0906 16-03-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01932, current rewards: 59.91439, mean: 0.10699
[32m[0906 16-03-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01930, current rewards: 65.45430, mean: 0.10730
[32m[0906 16-03-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 70.99475, mean: 0.10757
[32m[0906 16-04-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01930, current rewards: 76.53660, mean: 0.10780
[32m[0906 16-04-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01930, current rewards: 81.96192, mean: 0.10784
[32m[0906 16-04-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01930, current rewards: 87.46804, mean: 0.10799
[32m[0906 16-04-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01930, current rewards: 93.01094, mean: 0.10815
[32m[0906 16-04-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01930, current rewards: 98.54826, mean: 0.10829
[32m[0906 16-04-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01929, current rewards: 104.09187, mean: 0.10843
[32m[0906 16-04-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01928, current rewards: 109.63242, mean: 0.10855
[32m[0906 16-04-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 115.17160, mean: 0.10865
[32m[0906 16-04-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 120.71176, mean: 0.10875
[32m[0906 16-04-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 126.29295, mean: 0.10887
[32m[0906 16-04-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 131.82877, mean: 0.10895
[32m[0906 16-04-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 137.37028, mean: 0.10902
[32m[0906 16-04-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: 142.87376, mean: 0.10906
[32m[0906 16-04-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 148.45854, mean: 0.10916
[32m[0906 16-04-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: 154.04322, mean: 0.10925
[32m[0906 16-04-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 159.62831, mean: 0.10933
[32m[0906 16-04-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 165.21325, mean: 0.10941
[32m[0906 16-04-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 170.83361, mean: 0.10951
[32m[0906 16-04-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 176.44697, mean: 0.10959
[32m[0906 16-04-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01902, current rewards: 182.03543, mean: 0.10966
[32m[0906 16-04-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: 187.62437, mean: 0.10972
[32m[0906 16-04-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: 193.21169, mean: 0.10978
[32m[0906 16-04-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01900, current rewards: 198.80053, mean: 0.10983
[32m[0906 16-04-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01899, current rewards: 204.32919, mean: 0.10985
[32m[0906 16-04-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 209.87230, mean: 0.10988
[32m[0906 16-04-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 215.42280, mean: 0.10991
[32m[0906 16-04-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01896, current rewards: 221.01828, mean: 0.10996
[32m[0906 16-04-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01895, current rewards: 226.56768, mean: 0.10998
[32m[0906 16-04-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01894, current rewards: 232.11704, mean: 0.11001
[32m[0906 16-04-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01893, current rewards: 237.66627, mean: 0.11003
[32m[0906 16-04-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01893, current rewards: 243.22073, mean: 0.11005
[32m[0906 16-04-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01892, current rewards: 248.74964, mean: 0.11007
[32m[0906 16-04-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 254.28146, mean: 0.11008
[32m[0906 16-04-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 259.81616, mean: 0.11009
[32m[0906 16-04-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 265.25075, mean: 0.11006
[32m[0906 16-04-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: 270.79197, mean: 0.11008
[32m[0906 16-04-34 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-04-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-04-34 @MBExp.py:227][0m Rewards obtained: [275.2197837933729], Lows: [0], Highs: [2], Total time: 3374.774459000001
[32m[0906 16-07-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-07-03 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01896, current rewards: 1.16467, mean: 0.11647
[32m[0906 16-07-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 6.72226, mean: 0.11204
[32m[0906 16-07-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 12.27645, mean: 0.11160
[32m[0906 16-07-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.83475, mean: 0.11147
[32m[0906 16-07-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.38527, mean: 0.11136
[32m[0906 16-07-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 28.93858, mean: 0.11130
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.47550, mean: 0.11121
[32m[0906 16-07-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.91009, mean: 0.11086
[32m[0906 16-07-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.43603, mean: 0.11082
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 50.96375, mean: 0.11079
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.49027, mean: 0.11077
[32m[0906 16-07-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.01783, mean: 0.11075
[32m[0906 16-07-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.54657, mean: 0.11073
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 73.07512, mean: 0.11072
[32m[0906 16-07-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.59917, mean: 0.11070
[32m[0906 16-07-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.12740, mean: 0.11069
[32m[0906 16-07-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 89.61955, mean: 0.11064
[32m[0906 16-07-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 95.20294, mean: 0.11070
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 100.78924, mean: 0.11076
[32m[0906 16-07-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01920, current rewards: 106.37405, mean: 0.11081
[32m[0906 16-07-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 111.95423, mean: 0.11085
[32m[0906 16-07-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 117.53802, mean: 0.11088
[32m[0906 16-07-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01911, current rewards: 123.12283, mean: 0.11092
[32m[0906 16-07-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 128.79757, mean: 0.11103
[32m[0906 16-07-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 134.38050, mean: 0.11106
[32m[0906 16-07-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 139.92748, mean: 0.11105
[32m[0906 16-07-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01904, current rewards: 145.47804, mean: 0.11105
[32m[0906 16-07-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 151.03230, mean: 0.11105
[32m[0906 16-07-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01901, current rewards: 156.58446, mean: 0.11105
[32m[0906 16-07-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01899, current rewards: 162.13374, mean: 0.11105
[32m[0906 16-07-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01898, current rewards: 167.68725, mean: 0.11105
[32m[0906 16-07-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01896, current rewards: 173.26549, mean: 0.11107
[32m[0906 16-07-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01895, current rewards: 178.82164, mean: 0.11107
[32m[0906 16-07-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01894, current rewards: 184.40516, mean: 0.11109
[32m[0906 16-07-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01893, current rewards: 189.93315, mean: 0.11107
[32m[0906 16-07-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01892, current rewards: 195.46070, mean: 0.11106
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01891, current rewards: 200.99085, mean: 0.11104
[32m[0906 16-07-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01891, current rewards: 206.51982, mean: 0.11103
[32m[0906 16-07-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01890, current rewards: 212.04937, mean: 0.11102
[32m[0906 16-07-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01890, current rewards: 217.56932, mean: 0.11100
[32m[0906 16-07-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 223.08489, mean: 0.11099
[32m[0906 16-07-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 228.57990, mean: 0.11096
[32m[0906 16-07-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 234.11319, mean: 0.11095
[32m[0906 16-07-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 239.64853, mean: 0.11095
[32m[0906 16-07-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 245.18375, mean: 0.11094
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 250.73595, mean: 0.11095
[32m[0906 16-07-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 256.24135, mean: 0.11093
[32m[0906 16-07-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 261.74958, mean: 0.11091
[32m[0906 16-07-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 267.19387, mean: 0.11087
[32m[0906 16-07-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: 272.71845, mean: 0.11086
[32m[0906 16-07-50 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-07-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-07-50 @MBExp.py:227][0m Rewards obtained: [277.1388290693292], Lows: [0], Highs: [0], Total time: 3422.640075000001
[32m[0906 16-10-21 @MBExp.py:144][0m ####################################################################
[32m[0906 16-10-21 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-10-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: -0.97199, mean: -0.09720
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 4.66666, mean: 0.07778
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 10.30020, mean: 0.09364
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 15.93763, mean: 0.09961
[32m[0906 16-10-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 21.57529, mean: 0.10274
[32m[0906 16-10-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 27.21413, mean: 0.10467
[32m[0906 16-10-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 32.86790, mean: 0.10603
[32m[0906 16-10-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 38.49895, mean: 0.10694
[32m[0906 16-10-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 44.55944, mean: 0.10868
[32m[0906 16-10-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 50.51715, mean: 0.10982
[32m[0906 16-10-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 56.47520, mean: 0.11074
[32m[0906 16-10-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 62.43798, mean: 0.11150
[32m[0906 16-10-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 68.39884, mean: 0.11213
[32m[0906 16-10-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 74.35667, mean: 0.11266
[32m[0906 16-10-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 80.30867, mean: 0.11311
[32m[0906 16-10-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 86.31438, mean: 0.11357
[32m[0906 16-10-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 92.31424, mean: 0.11397
[32m[0906 16-10-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 98.30721, mean: 0.11431
[32m[0906 16-10-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: 104.23748, mean: 0.11455
[32m[0906 16-10-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: 109.78777, mean: 0.11436
[32m[0906 16-10-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: 115.33832, mean: 0.11420
[32m[0906 16-10-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 120.88688, mean: 0.11404
[32m[0906 16-10-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 126.44858, mean: 0.11392
[32m[0906 16-10-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 132.05775, mean: 0.11384
[32m[0906 16-10-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 137.62162, mean: 0.11374
[32m[0906 16-10-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 143.18114, mean: 0.11364
[32m[0906 16-10-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 148.73771, mean: 0.11354
[32m[0906 16-10-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 154.29616, mean: 0.11345
[32m[0906 16-10-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: 159.86229, mean: 0.11338
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 165.42102, mean: 0.11330
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 171.19242, mean: 0.11337
[32m[0906 16-10-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 177.01846, mean: 0.11347
[32m[0906 16-10-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01901, current rewards: 182.84182, mean: 0.11357
[32m[0906 16-10-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01900, current rewards: 188.66867, mean: 0.11366
[32m[0906 16-10-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01899, current rewards: 194.49417, mean: 0.11374
[32m[0906 16-10-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: 200.31830, mean: 0.11382
[32m[0906 16-10-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: 206.14274, mean: 0.11389
[32m[0906 16-10-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01895, current rewards: 207.59029, mean: 0.11161
[32m[0906 16-10-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01894, current rewards: 213.19225, mean: 0.11162
[32m[0906 16-10-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01893, current rewards: 218.71144, mean: 0.11159
[32m[0906 16-11-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 224.29780, mean: 0.11159
[32m[0906 16-11-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 229.88212, mean: 0.11159
[32m[0906 16-11-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01891, current rewards: 235.46701, mean: 0.11160
[32m[0906 16-11-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 241.05219, mean: 0.11160
[32m[0906 16-11-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 246.64290, mean: 0.11160
[32m[0906 16-11-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 250.03001, mean: 0.11063
[32m[0906 16-11-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 255.52327, mean: 0.11062
[32m[0906 16-11-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 261.13601, mean: 0.11065
[32m[0906 16-11-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 266.64346, mean: 0.11064
[32m[0906 16-11-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: 272.14977, mean: 0.11063
[32m[0906 16-11-09 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-11-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-11-09 @MBExp.py:227][0m Rewards obtained: [276.56221185627453], Lows: [2], Highs: [4], Total time: 3470.601071000001
[32m[0906 16-13-43 @MBExp.py:144][0m ####################################################################
[32m[0906 16-13-43 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-13-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01862, current rewards: 1.03995, mean: 0.10399
[32m[0906 16-13-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.58703, mean: 0.10978
[32m[0906 16-13-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.13471, mean: 0.11032
[32m[0906 16-13-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 17.67637, mean: 0.11048
[32m[0906 16-13-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01923, current rewards: 23.21639, mean: 0.11055
[32m[0906 16-13-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.76205, mean: 0.11062
[32m[0906 16-13-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 34.33306, mean: 0.11075
[32m[0906 16-13-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.87239, mean: 0.11076
[32m[0906 16-13-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 45.40762, mean: 0.11075
[32m[0906 16-13-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 50.95505, mean: 0.11077
[32m[0906 16-13-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.50454, mean: 0.11079
[32m[0906 16-13-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 62.05411, mean: 0.11081
[32m[0906 16-13-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.60283, mean: 0.11082
[32m[0906 16-13-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 73.15074, mean: 0.11083
[32m[0906 16-13-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 78.67752, mean: 0.11081
[32m[0906 16-13-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01925, current rewards: 84.22853, mean: 0.11083
[32m[0906 16-13-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 89.78553, mean: 0.11085
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: 95.33585, mean: 0.11086
[32m[0906 16-14-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 100.98373, mean: 0.11097
[32m[0906 16-14-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: 106.58959, mean: 0.11103
[32m[0906 16-14-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01924, current rewards: 112.19717, mean: 0.11109
[32m[0906 16-14-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 117.80308, mean: 0.11113
[32m[0906 16-14-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 123.38606, mean: 0.11116
[32m[0906 16-14-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 129.07470, mean: 0.11127
[32m[0906 16-14-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 134.76780, mean: 0.11138
[32m[0906 16-14-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 140.45994, mean: 0.11148
[32m[0906 16-14-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 146.14433, mean: 0.11156
[32m[0906 16-14-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 151.83274, mean: 0.11164
[32m[0906 16-14-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: 157.52411, mean: 0.11172
[32m[0906 16-14-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01906, current rewards: 163.21849, mean: 0.11179
[32m[0906 16-14-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 168.94530, mean: 0.11188
[32m[0906 16-14-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 173.52940, mean: 0.11124
[32m[0906 16-14-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01901, current rewards: 179.07348, mean: 0.11123
[32m[0906 16-14-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 184.61686, mean: 0.11121
[32m[0906 16-14-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 190.16647, mean: 0.11121
[32m[0906 16-14-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: 195.71946, mean: 0.11120
[32m[0906 16-14-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: 201.25683, mean: 0.11119
[32m[0906 16-14-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01895, current rewards: 206.80483, mean: 0.11119
[32m[0906 16-14-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 212.33746, mean: 0.11117
[32m[0906 16-14-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01893, current rewards: 217.88791, mean: 0.11117
[32m[0906 16-14-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01892, current rewards: 223.43896, mean: 0.11116
[32m[0906 16-14-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01891, current rewards: 228.99396, mean: 0.11116
[32m[0906 16-14-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01891, current rewards: 234.53975, mean: 0.11116
[32m[0906 16-14-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 240.08954, mean: 0.11115
[32m[0906 16-14-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: 245.63767, mean: 0.11115
[32m[0906 16-14-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: 251.18364, mean: 0.11114
[32m[0906 16-14-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: 256.72347, mean: 0.11114
[32m[0906 16-14-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 262.26157, mean: 0.11113
[32m[0906 16-14-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 267.79458, mean: 0.11112
[32m[0906 16-14-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 273.32752, mean: 0.11111
[32m[0906 16-14-30 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-14-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-14-31 @MBExp.py:227][0m Rewards obtained: [277.75424164211915], Lows: [0], Highs: [1], Total time: 3518.523024000001
[32m[0906 16-17-05 @MBExp.py:144][0m ####################################################################
[32m[0906 16-17-05 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01868, current rewards: 1.04553, mean: 0.10455
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 6.54149, mean: 0.10902
[32m[0906 16-17-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.11463, mean: 0.11013
[32m[0906 16-17-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.68857, mean: 0.11055
[32m[0906 16-17-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.26249, mean: 0.11077
[32m[0906 16-17-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 28.95824, mean: 0.11138
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.56466, mean: 0.11150
[32m[0906 16-17-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 40.17252, mean: 0.11159
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 45.78674, mean: 0.11167
[32m[0906 16-17-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 51.39200, mean: 0.11172
[32m[0906 16-17-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 57.00252, mean: 0.11177
[32m[0906 16-17-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 62.60688, mean: 0.11180
[32m[0906 16-17-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 68.19705, mean: 0.11180
[32m[0906 16-17-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.76748, mean: 0.11177
[32m[0906 16-17-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 79.35363, mean: 0.11177
[32m[0906 16-17-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 84.95231, mean: 0.11178
[32m[0906 16-17-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 90.54469, mean: 0.11178
[32m[0906 16-17-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 96.13728, mean: 0.11179
[32m[0906 16-17-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 101.72681, mean: 0.11179
[32m[0906 16-17-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01917, current rewards: 107.32011, mean: 0.11179
[32m[0906 16-17-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 112.91257, mean: 0.11179
[32m[0906 16-17-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 118.48324, mean: 0.11178
[32m[0906 16-17-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 124.00046, mean: 0.11171
[32m[0906 16-17-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 129.58798, mean: 0.11171
[32m[0906 16-17-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 135.17197, mean: 0.11171
[32m[0906 16-17-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01907, current rewards: 140.75726, mean: 0.11171
[32m[0906 16-17-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: 146.34341, mean: 0.11171
[32m[0906 16-17-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 151.92645, mean: 0.11171
[32m[0906 16-17-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01904, current rewards: 157.51097, mean: 0.11171
[32m[0906 16-17-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01903, current rewards: 163.09885, mean: 0.11171
[32m[0906 16-17-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01901, current rewards: 168.72274, mean: 0.11174
[32m[0906 16-17-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01900, current rewards: 174.31264, mean: 0.11174
[32m[0906 16-17-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: 179.89950, mean: 0.11174
[32m[0906 16-17-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 185.49030, mean: 0.11174
[32m[0906 16-17-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 191.07999, mean: 0.11174
[32m[0906 16-17-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: 196.66952, mean: 0.11174
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: 202.36401, mean: 0.11180
[32m[0906 16-17-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01895, current rewards: 207.96409, mean: 0.11181
[32m[0906 16-17-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01894, current rewards: 213.53870, mean: 0.11180
[32m[0906 16-17-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01893, current rewards: 219.14423, mean: 0.11181
[32m[0906 16-17-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 224.75368, mean: 0.11182
[32m[0906 16-17-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 230.35592, mean: 0.11182
[32m[0906 16-17-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01891, current rewards: 235.96331, mean: 0.11183
[32m[0906 16-17-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 241.56617, mean: 0.11184
[32m[0906 16-17-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 247.16987, mean: 0.11184
[32m[0906 16-17-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 252.77556, mean: 0.11185
[32m[0906 16-17-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 258.34043, mean: 0.11184
[32m[0906 16-17-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 263.95686, mean: 0.11185
[32m[0906 16-17-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 269.57045, mean: 0.11185
[32m[0906 16-17-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 275.18473, mean: 0.11186
[32m[0906 16-17-53 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-17-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-17-53 @MBExp.py:227][0m Rewards obtained: [279.68199291105645], Lows: [0], Highs: [0], Total time: 3566.485978000001
[32m[0906 16-20-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-30 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01909, current rewards: 1.22573, mean: 0.12257
[32m[0906 16-20-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 6.77018, mean: 0.11284
[32m[0906 16-20-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.31465, mean: 0.11195
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.85367, mean: 0.11159
[32m[0906 16-20-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.33149, mean: 0.11110
[32m[0906 16-20-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 28.83593, mean: 0.11091
[32m[0906 16-20-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.36811, mean: 0.11086
[32m[0906 16-20-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: 39.90774, mean: 0.11085
[32m[0906 16-20-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 45.44054, mean: 0.11083
[32m[0906 16-20-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01921, current rewards: 50.96749, mean: 0.11080
[32m[0906 16-20-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 56.49578, mean: 0.11078
[32m[0906 16-20-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 62.02512, mean: 0.11076
[32m[0906 16-20-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.55423, mean: 0.11074
[32m[0906 16-20-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01922, current rewards: 73.11903, mean: 0.11079
[32m[0906 16-20-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.65030, mean: 0.11078
[32m[0906 16-20-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 84.17987, mean: 0.11076
[32m[0906 16-20-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 89.70771, mean: 0.11075
[32m[0906 16-20-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01926, current rewards: 95.23780, mean: 0.11074
[32m[0906 16-20-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 100.75669, mean: 0.11072
[32m[0906 16-20-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 106.30061, mean: 0.11073
[32m[0906 16-20-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 111.83948, mean: 0.11073
[32m[0906 16-20-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01924, current rewards: 117.32808, mean: 0.11069
[32m[0906 16-20-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 122.88183, mean: 0.11070
[32m[0906 16-20-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 128.42639, mean: 0.11071
[32m[0906 16-20-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 133.97886, mean: 0.11073
[32m[0906 16-20-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 139.52878, mean: 0.11074
[32m[0906 16-20-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 145.03795, mean: 0.11072
[32m[0906 16-20-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 150.57107, mean: 0.11071
[32m[0906 16-20-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: 156.09716, mean: 0.11071
[32m[0906 16-20-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 161.67204, mean: 0.11073
[32m[0906 16-20-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 167.20389, mean: 0.11073
[32m[0906 16-21-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 172.73207, mean: 0.11073
[32m[0906 16-21-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 178.25939, mean: 0.11072
[32m[0906 16-21-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: 183.79079, mean: 0.11072
[32m[0906 16-21-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: 189.32271, mean: 0.11072
[32m[0906 16-21-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01902, current rewards: 194.85158, mean: 0.11071
[32m[0906 16-21-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01901, current rewards: 200.37948, mean: 0.11071
[32m[0906 16-21-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01900, current rewards: 205.92709, mean: 0.11071
[32m[0906 16-21-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 211.45941, mean: 0.11071
[32m[0906 16-21-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 217.00268, mean: 0.11072
[32m[0906 16-21-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01897, current rewards: 222.51875, mean: 0.11071
[32m[0906 16-21-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01896, current rewards: 228.03117, mean: 0.11069
[32m[0906 16-21-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01895, current rewards: 233.54833, mean: 0.11069
[32m[0906 16-21-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: 239.06342, mean: 0.11068
[32m[0906 16-21-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: 244.57856, mean: 0.11067
[32m[0906 16-21-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01894, current rewards: 250.06607, mean: 0.11065
[32m[0906 16-21-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: 255.55347, mean: 0.11063
[32m[0906 16-21-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 261.05551, mean: 0.11062
[32m[0906 16-21-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 266.55497, mean: 0.11060
[32m[0906 16-21-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 272.05594, mean: 0.11059
[32m[0906 16-21-18 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-21-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-21-18 @MBExp.py:227][0m Rewards obtained: [276.4609388159715], Lows: [0], Highs: [0], Total time: 3614.541083000001
[32m[0906 16-23-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-57 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 16-23-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01838, current rewards: 1.95114, mean: 0.19511
[32m[0906 16-23-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01880, current rewards: 7.51612, mean: 0.12527
[32m[0906 16-23-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01889, current rewards: 13.08030, mean: 0.11891
[32m[0906 16-24-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01903, current rewards: 18.65225, mean: 0.11658
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 24.18895, mean: 0.11519
[32m[0906 16-24-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 29.76223, mean: 0.11447
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 35.33415, mean: 0.11398
[32m[0906 16-24-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 40.89024, mean: 0.11358
[32m[0906 16-24-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 46.45792, mean: 0.11331
[32m[0906 16-24-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 52.02110, mean: 0.11309
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 57.58660, mean: 0.11291
[32m[0906 16-24-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 63.19136, mean: 0.11284
[32m[0906 16-24-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 68.69764, mean: 0.11262
[32m[0906 16-24-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 74.25538, mean: 0.11251
[32m[0906 16-24-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 79.81302, mean: 0.11241
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 85.37097, mean: 0.11233
[32m[0906 16-24-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 90.93683, mean: 0.11227
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 96.49221, mean: 0.11220
[32m[0906 16-24-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 102.05327, mean: 0.11215
[32m[0906 16-24-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 107.61472, mean: 0.11210
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 113.21009, mean: 0.11209
[32m[0906 16-24-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 118.78022, mean: 0.11206
[32m[0906 16-24-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 124.36657, mean: 0.11204
[32m[0906 16-24-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 129.90726, mean: 0.11199
[32m[0906 16-24-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 135.44708, mean: 0.11194
[32m[0906 16-24-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 140.98713, mean: 0.11189
[32m[0906 16-24-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01908, current rewards: 146.52850, mean: 0.11185
[32m[0906 16-24-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: 152.06722, mean: 0.11181
[32m[0906 16-24-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: 157.86819, mean: 0.11196
[32m[0906 16-24-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01903, current rewards: 163.50749, mean: 0.11199
[32m[0906 16-24-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01901, current rewards: 169.14782, mean: 0.11202
[32m[0906 16-24-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01900, current rewards: 174.78425, mean: 0.11204
[32m[0906 16-24-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01899, current rewards: 180.42127, mean: 0.11206
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01897, current rewards: 186.05858, mean: 0.11208
[32m[0906 16-24-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01896, current rewards: 191.58507, mean: 0.11204
[32m[0906 16-24-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01894, current rewards: 197.13745, mean: 0.11201
[32m[0906 16-24-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01893, current rewards: 202.70193, mean: 0.11199
[32m[0906 16-24-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01892, current rewards: 208.26016, mean: 0.11197
[32m[0906 16-24-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01891, current rewards: 213.81495, mean: 0.11195
[32m[0906 16-24-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01891, current rewards: 219.36978, mean: 0.11192
[32m[0906 16-24-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01890, current rewards: 224.92436, mean: 0.11190
[32m[0906 16-24-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 230.47825, mean: 0.11188
[32m[0906 16-24-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 236.03351, mean: 0.11186
[32m[0906 16-24-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 241.57372, mean: 0.11184
[32m[0906 16-24-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 247.12306, mean: 0.11182
[32m[0906 16-24-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 252.74958, mean: 0.11184
[32m[0906 16-24-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: 258.29562, mean: 0.11182
[32m[0906 16-24-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 263.84028, mean: 0.11180
[32m[0906 16-24-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 269.38475, mean: 0.11178
[32m[0906 16-24-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: 274.93432, mean: 0.11176
[32m[0906 16-24-45 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-24-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-24-45 @MBExp.py:227][0m Rewards obtained: [279.3713660890197], Lows: [0], Highs: [0], Total time: 3662.398394000001
[32m[0906 16-27-26 @MBExp.py:144][0m ####################################################################
[32m[0906 16-27-26 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 16-27-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: 1.04552, mean: 0.10455
[32m[0906 16-27-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01885, current rewards: 6.58948, mean: 0.10982
[32m[0906 16-27-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.13229, mean: 0.11029
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 17.59690, mean: 0.10998
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 23.13418, mean: 0.11016
[32m[0906 16-27-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 28.64447, mean: 0.11017
[32m[0906 16-27-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 34.18873, mean: 0.11029
[32m[0906 16-27-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 39.73088, mean: 0.11036
[32m[0906 16-27-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 45.27046, mean: 0.11042
[32m[0906 16-27-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.81680, mean: 0.11047
[32m[0906 16-27-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.35345, mean: 0.11050
[32m[0906 16-27-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 61.94426, mean: 0.11061
[32m[0906 16-27-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.55867, mean: 0.11075
[32m[0906 16-27-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.11177, mean: 0.11078
[32m[0906 16-27-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 78.66895, mean: 0.11080
[32m[0906 16-27-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 84.21213, mean: 0.11081
[32m[0906 16-27-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 93.27903, mean: 0.11516
[32m[0906 16-27-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 102.33246, mean: 0.11899
[32m[0906 16-27-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01923, current rewards: 111.38590, mean: 0.12240
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 118.07720, mean: 0.12300
[32m[0906 16-27-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 111.36686, mean: 0.11026
[32m[0906 16-27-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 116.86110, mean: 0.11025
[32m[0906 16-27-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 122.35790, mean: 0.11023
[32m[0906 16-27-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 127.85043, mean: 0.11022
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 133.34229, mean: 0.11020
[32m[0906 16-27-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 138.83636, mean: 0.11019
[32m[0906 16-27-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 144.35912, mean: 0.11020
[32m[0906 16-27-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 149.92777, mean: 0.11024
[32m[0906 16-27-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 155.41451, mean: 0.11022
[32m[0906 16-27-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 160.98603, mean: 0.11026
[32m[0906 16-27-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01905, current rewards: 166.50290, mean: 0.11027
[32m[0906 16-27-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01904, current rewards: 172.02943, mean: 0.11028
[32m[0906 16-27-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 177.55506, mean: 0.11028
[32m[0906 16-27-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01901, current rewards: 183.07885, mean: 0.11029
[32m[0906 16-27-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01900, current rewards: 188.60456, mean: 0.11030
[32m[0906 16-28-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01899, current rewards: 194.12655, mean: 0.11030
[32m[0906 16-28-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01898, current rewards: 199.65451, mean: 0.11031
[32m[0906 16-28-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: 205.18075, mean: 0.11031
[32m[0906 16-28-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 210.70915, mean: 0.11032
[32m[0906 16-28-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01894, current rewards: 216.23400, mean: 0.11032
[32m[0906 16-28-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 221.75852, mean: 0.11033
[32m[0906 16-28-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01893, current rewards: 227.28364, mean: 0.11033
[32m[0906 16-28-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 232.86092, mean: 0.11036
[32m[0906 16-28-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 238.42303, mean: 0.11038
[32m[0906 16-28-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 243.97515, mean: 0.11040
[32m[0906 16-28-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 249.53908, mean: 0.11042
[32m[0906 16-28-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 255.10247, mean: 0.11043
[32m[0906 16-28-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 260.66795, mean: 0.11045
[32m[0906 16-28-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 266.23243, mean: 0.11047
[32m[0906 16-28-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: 271.79218, mean: 0.11048
[32m[0906 16-28-14 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-28-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-28-14 @MBExp.py:227][0m Rewards obtained: [276.2447921322904], Lows: [0], Highs: [13], Total time: 3710.328276000001
[32m[0906 16-30-58 @MBExp.py:144][0m ####################################################################
[32m[0906 16-30-58 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 16-30-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01955, current rewards: 0.04673, mean: 0.00467
[32m[0906 16-30-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01930, current rewards: 5.78851, mean: 0.09648
[32m[0906 16-31-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 11.43925, mean: 0.10399
[32m[0906 16-31-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 16.92633, mean: 0.10579
[32m[0906 16-31-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 22.52611, mean: 0.10727
[32m[0906 16-31-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 28.15494, mean: 0.10829
[32m[0906 16-31-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01922, current rewards: 33.78308, mean: 0.10898
[32m[0906 16-31-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 39.41092, mean: 0.10947
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.03846, mean: 0.10985
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01924, current rewards: 50.60727, mean: 0.11002
[32m[0906 16-31-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.13144, mean: 0.11006
[32m[0906 16-31-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 61.65782, mean: 0.11010
[32m[0906 16-31-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.21442, mean: 0.11019
[32m[0906 16-31-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 72.74797, mean: 0.11022
[32m[0906 16-31-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 78.28090, mean: 0.11025
[32m[0906 16-31-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 83.81214, mean: 0.11028
[32m[0906 16-31-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 89.34022, mean: 0.11030
[32m[0906 16-31-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 92.71055, mean: 0.10780
[32m[0906 16-31-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 98.19483, mean: 0.10791
[32m[0906 16-31-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 103.67605, mean: 0.10800
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 109.16185, mean: 0.10808
[32m[0906 16-31-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 114.64445, mean: 0.10816
[32m[0906 16-31-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 120.13514, mean: 0.10823
[32m[0906 16-31-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 125.62010, mean: 0.10829
[32m[0906 16-31-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 131.10507, mean: 0.10835
[32m[0906 16-31-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 136.58739, mean: 0.10840
[32m[0906 16-31-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01908, current rewards: 142.06948, mean: 0.10845
[32m[0906 16-31-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: 147.55451, mean: 0.10850
[32m[0906 16-31-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 153.12648, mean: 0.10860
[32m[0906 16-31-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 158.61958, mean: 0.10864
[32m[0906 16-31-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: 164.11296, mean: 0.10868
[32m[0906 16-31-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01901, current rewards: 169.59484, mean: 0.10871
[32m[0906 16-31-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: 175.06400, mean: 0.10874
[32m[0906 16-31-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01898, current rewards: 180.53324, mean: 0.10875
[32m[0906 16-31-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01897, current rewards: 186.00690, mean: 0.10878
[32m[0906 16-31-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01896, current rewards: 191.47642, mean: 0.10879
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01895, current rewards: 196.88932, mean: 0.10878
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01893, current rewards: 202.30454, mean: 0.10877
[32m[0906 16-31-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01892, current rewards: 207.75441, mean: 0.10877
[32m[0906 16-31-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01891, current rewards: 213.20342, mean: 0.10878
[32m[0906 16-31-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01891, current rewards: 218.65127, mean: 0.10878
[32m[0906 16-31-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01890, current rewards: 224.10529, mean: 0.10879
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 229.55697, mean: 0.10879
[32m[0906 16-31-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 235.01378, mean: 0.10880
[32m[0906 16-31-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 240.47672, mean: 0.10881
[32m[0906 16-31-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 246.01310, mean: 0.10886
[32m[0906 16-31-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 251.44435, mean: 0.10885
[32m[0906 16-31-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 256.87868, mean: 0.10885
[32m[0906 16-31-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: 262.31594, mean: 0.10884
[32m[0906 16-31-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 267.74795, mean: 0.10884
[32m[0906 16-31-45 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-31-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-31-45 @MBExp.py:227][0m Rewards obtained: [273.2446881679946], Lows: [1], Highs: [1], Total time: 3758.264073000001
[32m[0906 16-34-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-30 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 16-34-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 1.08963, mean: 0.10896
[32m[0906 16-34-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01967, current rewards: 6.72168, mean: 0.11203
[32m[0906 16-34-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01933, current rewards: 12.25482, mean: 0.11141
[32m[0906 16-34-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 17.78774, mean: 0.11117
[32m[0906 16-34-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 23.23900, mean: 0.11066
[32m[0906 16-34-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.77500, mean: 0.11067
[32m[0906 16-34-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.31115, mean: 0.11068
[32m[0906 16-34-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.85045, mean: 0.11070
[32m[0906 16-34-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.38855, mean: 0.11070
[32m[0906 16-34-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 50.93017, mean: 0.11072
[32m[0906 16-34-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.37757, mean: 0.11054
[32m[0906 16-34-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01924, current rewards: 61.82770, mean: 0.11041
[32m[0906 16-34-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01923, current rewards: 67.23847, mean: 0.11023
[32m[0906 16-34-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01923, current rewards: 72.68018, mean: 0.11012
[32m[0906 16-34-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 78.12211, mean: 0.11003
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01924, current rewards: 83.56895, mean: 0.10996
[32m[0906 16-34-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 89.00967, mean: 0.10989
[32m[0906 16-34-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 94.45410, mean: 0.10983
[32m[0906 16-34-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 99.89534, mean: 0.10978
[32m[0906 16-34-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 105.33730, mean: 0.10973
[32m[0906 16-34-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 110.77913, mean: 0.10968
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 116.21498, mean: 0.10964
[32m[0906 16-34-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 121.70655, mean: 0.10965
[32m[0906 16-34-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: 127.21382, mean: 0.10967
[32m[0906 16-34-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 132.72094, mean: 0.10969
[32m[0906 16-34-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 138.23350, mean: 0.10971
[32m[0906 16-34-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 143.74341, mean: 0.10973
[32m[0906 16-34-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: 149.25275, mean: 0.10974
[32m[0906 16-34-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 154.80143, mean: 0.10979
[32m[0906 16-34-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 160.68991, mean: 0.11006
[32m[0906 16-35-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: 129.70199, mean: 0.08590
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01900, current rewards: 79.70199, mean: 0.05109
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01899, current rewards: 29.70199, mean: 0.01845
[32m[0906 16-35-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01898, current rewards: -20.29801, mean: -0.01223
[32m[0906 16-35-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01897, current rewards: -70.29801, mean: -0.04111
[32m[0906 16-35-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01896, current rewards: -120.29801, mean: -0.06835
[32m[0906 16-35-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01895, current rewards: -170.29801, mean: -0.09409
[32m[0906 16-35-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01893, current rewards: -220.29801, mean: -0.11844
[32m[0906 16-35-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01892, current rewards: -270.29801, mean: -0.14152
[32m[0906 16-35-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01891, current rewards: -320.29801, mean: -0.16342
[32m[0906 16-35-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: -370.29801, mean: -0.18423
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: -420.29801, mean: -0.20403
[32m[0906 16-35-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: -470.29801, mean: -0.22289
[32m[0906 16-35-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: -520.29801, mean: -0.24088
[32m[0906 16-35-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: -570.29801, mean: -0.25805
[32m[0906 16-35-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: -620.29801, mean: -0.27447
[32m[0906 16-35-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: -670.29801, mean: -0.29017
[32m[0906 16-35-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: -720.29801, mean: -0.30521
[32m[0906 16-35-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: -770.29801, mean: -0.31963
[32m[0906 16-35-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: -820.29801, mean: -0.33345
[32m[0906 16-35-18 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-35-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-35-18 @MBExp.py:227][0m Rewards obtained: [-860.2980113807198], Lows: [0], Highs: [1023], Total time: 3806.1669290000013
[32m[0906 16-38-06 @MBExp.py:144][0m ####################################################################
[32m[0906 16-38-06 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01898, current rewards: 1.03892, mean: 0.10389
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01954, current rewards: 6.55495, mean: 0.10925
[32m[0906 16-38-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01933, current rewards: 12.07253, mean: 0.10975
[32m[0906 16-38-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 17.60317, mean: 0.11002
[32m[0906 16-38-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01931, current rewards: 23.11955, mean: 0.11009
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 28.63206, mean: 0.11012
[32m[0906 16-38-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01930, current rewards: 34.11670, mean: 0.11005
[32m[0906 16-38-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01930, current rewards: 39.63453, mean: 0.11010
[32m[0906 16-38-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 45.15763, mean: 0.11014
[32m[0906 16-38-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01928, current rewards: 50.67404, mean: 0.11016
[32m[0906 16-38-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01927, current rewards: 56.19006, mean: 0.11018
[32m[0906 16-38-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 61.70967, mean: 0.11020
[32m[0906 16-38-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 67.23315, mean: 0.11022
[32m[0906 16-38-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 72.75528, mean: 0.11024
[32m[0906 16-38-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 78.27378, mean: 0.11024
[32m[0906 16-38-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 83.78691, mean: 0.11025
[32m[0906 16-38-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 89.30532, mean: 0.11025
[32m[0906 16-38-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 94.85259, mean: 0.11029
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.35560, mean: 0.11028
[32m[0906 16-38-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 105.85657, mean: 0.11027
[32m[0906 16-38-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 111.46948, mean: 0.11037
[32m[0906 16-38-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 116.98029, mean: 0.11036
[32m[0906 16-38-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01920, current rewards: 122.49384, mean: 0.11035
[32m[0906 16-38-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 128.00644, mean: 0.11035
[32m[0906 16-38-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 133.52139, mean: 0.11035
[32m[0906 16-38-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 139.03561, mean: 0.11035
[32m[0906 16-38-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 144.54529, mean: 0.11034
[32m[0906 16-38-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 150.30426, mean: 0.11052
[32m[0906 16-38-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: 156.02359, mean: 0.11066
[32m[0906 16-38-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 161.55757, mean: 0.11066
[32m[0906 16-38-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 167.09149, mean: 0.11066
[32m[0906 16-38-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 172.62549, mean: 0.11066
[32m[0906 16-38-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01901, current rewards: 178.15780, mean: 0.11066
[32m[0906 16-38-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01900, current rewards: 183.68770, mean: 0.11066
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 189.22347, mean: 0.11066
[32m[0906 16-38-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01897, current rewards: 194.75343, mean: 0.11066
[32m[0906 16-38-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: 200.28967, mean: 0.11066
[32m[0906 16-38-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01895, current rewards: 206.00463, mean: 0.11076
[32m[0906 16-38-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01894, current rewards: 211.56779, mean: 0.11077
[32m[0906 16-38-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01893, current rewards: 217.13095, mean: 0.11078
[32m[0906 16-38-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 211.52558, mean: 0.10524
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 217.06632, mean: 0.10537
[32m[0906 16-38-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 222.60655, mean: 0.10550
[32m[0906 16-38-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 228.14919, mean: 0.10562
[32m[0906 16-38-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 233.68962, mean: 0.10574
[32m[0906 16-38-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 239.13239, mean: 0.10581
[32m[0906 16-38-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: 244.65713, mean: 0.10591
[32m[0906 16-38-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 250.17836, mean: 0.10601
[32m[0906 16-38-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 255.69746, mean: 0.10610
[32m[0906 16-38-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 261.21351, mean: 0.10618
[32m[0906 16-38-53 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-38-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-38-54 @MBExp.py:227][0m Rewards obtained: [265.63519216364364], Lows: [0], Highs: [10], Total time: 3854.171736000001
[32m[0906 16-41-43 @MBExp.py:144][0m ####################################################################
[32m[0906 16-41-43 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02000, current rewards: 1.27165, mean: 0.12716
[32m[0906 16-41-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01962, current rewards: 6.77596, mean: 0.11293
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01946, current rewards: 12.33574, mean: 0.11214
[32m[0906 16-41-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01946, current rewards: 17.89436, mean: 0.11184
[32m[0906 16-41-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01943, current rewards: 23.53160, mean: 0.11206
[32m[0906 16-41-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01939, current rewards: 29.09826, mean: 0.11192
[32m[0906 16-41-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01935, current rewards: 34.66892, mean: 0.11184
[32m[0906 16-41-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01932, current rewards: 40.23917, mean: 0.11178
[32m[0906 16-41-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01931, current rewards: 45.80516, mean: 0.11172
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01931, current rewards: 51.36920, mean: 0.11167
[32m[0906 16-41-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01932, current rewards: 56.93885, mean: 0.11164
[32m[0906 16-41-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01931, current rewards: 62.50135, mean: 0.11161
[32m[0906 16-41-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01930, current rewards: 68.10465, mean: 0.11165
[32m[0906 16-41-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01930, current rewards: 73.65821, mean: 0.11160
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01929, current rewards: 79.20766, mean: 0.11156
[32m[0906 16-41-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: 84.75725, mean: 0.11152
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01928, current rewards: 90.34389, mean: 0.11154
[32m[0906 16-42-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01927, current rewards: 95.88777, mean: 0.11150
[32m[0906 16-42-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01926, current rewards: 101.44200, mean: 0.11147
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 106.99048, mean: 0.11145
[32m[0906 16-42-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: 112.55769, mean: 0.11144
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: 118.11251, mean: 0.11143
[32m[0906 16-42-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 123.66712, mean: 0.11141
[32m[0906 16-42-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 129.26095, mean: 0.11143
[32m[0906 16-42-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 134.83020, mean: 0.11143
[32m[0906 16-42-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: 140.39947, mean: 0.11143
[32m[0906 16-42-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 145.96693, mean: 0.11143
[32m[0906 16-42-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 151.53419, mean: 0.11142
[32m[0906 16-42-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 157.04096, mean: 0.11138
[32m[0906 16-42-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 162.56750, mean: 0.11135
[32m[0906 16-42-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 168.12379, mean: 0.11134
[32m[0906 16-42-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 173.67643, mean: 0.11133
[32m[0906 16-42-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 179.23017, mean: 0.11132
[32m[0906 16-42-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 184.77704, mean: 0.11131
[32m[0906 16-42-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 190.33025, mean: 0.11130
[32m[0906 16-42-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: 195.88382, mean: 0.11130
[32m[0906 16-42-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: 201.43420, mean: 0.11129
[32m[0906 16-42-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: 206.90887, mean: 0.11124
[32m[0906 16-42-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01901, current rewards: 212.45219, mean: 0.11123
[32m[0906 16-42-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01899, current rewards: 217.99898, mean: 0.11122
[32m[0906 16-42-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01899, current rewards: 223.54710, mean: 0.11122
[32m[0906 16-42-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: 229.09015, mean: 0.11121
[32m[0906 16-42-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: 234.66289, mean: 0.11121
[32m[0906 16-42-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: 240.27516, mean: 0.11124
[32m[0906 16-42-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01896, current rewards: 245.88680, mean: 0.11126
[32m[0906 16-42-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: 251.65155, mean: 0.11135
[32m[0906 16-42-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01894, current rewards: 257.27971, mean: 0.11138
[32m[0906 16-42-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 262.90771, mean: 0.11140
[32m[0906 16-42-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 268.53593, mean: 0.11143
[32m[0906 16-42-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 274.16411, mean: 0.11145
[32m[0906 16-42-31 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-42-31 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-42-31 @MBExp.py:227][0m Rewards obtained: [278.6665249349849], Lows: [0], Highs: [0], Total time: 3902.2331120000013
[32m[0906 16-45-22 @MBExp.py:144][0m ####################################################################
[32m[0906 16-45-22 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 16-45-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01967, current rewards: -0.99021, mean: -0.09902
[32m[0906 16-45-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01960, current rewards: 4.58218, mean: 0.07637
[32m[0906 16-45-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01971, current rewards: 10.14949, mean: 0.09227
[32m[0906 16-45-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01940, current rewards: 15.69824, mean: 0.09811
[32m[0906 16-45-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01934, current rewards: 21.26125, mean: 0.10124
[32m[0906 16-45-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01935, current rewards: 26.82697, mean: 0.10318
[32m[0906 16-45-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01933, current rewards: 32.39099, mean: 0.10449
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01932, current rewards: 37.95469, mean: 0.10543
[32m[0906 16-45-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 43.51615, mean: 0.10614
[32m[0906 16-45-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01928, current rewards: 49.08126, mean: 0.10670
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: 54.67185, mean: 0.10720
[32m[0906 16-45-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 60.25433, mean: 0.10760
[32m[0906 16-45-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 65.87604, mean: 0.10799
[32m[0906 16-45-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 71.45996, mean: 0.10827
[32m[0906 16-45-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: 77.04271, mean: 0.10851
[32m[0906 16-45-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01927, current rewards: 82.62355, mean: 0.10872
[32m[0906 16-45-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01926, current rewards: 88.20849, mean: 0.10890
[32m[0906 16-45-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: 94.04128, mean: 0.10935
[32m[0906 16-45-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 99.95916, mean: 0.10985
[32m[0906 16-45-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: 105.87704, mean: 0.11029
[32m[0906 16-45-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 111.16045, mean: 0.11006
[32m[0906 16-45-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 116.71078, mean: 0.11010
[32m[0906 16-45-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01923, current rewards: 122.26183, mean: 0.11015
[32m[0906 16-45-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 127.81395, mean: 0.11018
[32m[0906 16-45-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 133.36615, mean: 0.11022
[32m[0906 16-45-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 138.91633, mean: 0.11025
[32m[0906 16-45-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 144.44029, mean: 0.11026
[32m[0906 16-45-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 150.00927, mean: 0.11030
[32m[0906 16-45-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 155.57268, mean: 0.11034
[32m[0906 16-45-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 161.15129, mean: 0.11038
[32m[0906 16-45-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 166.72284, mean: 0.11041
[32m[0906 16-45-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 172.29466, mean: 0.11045
[32m[0906 16-45-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 177.92186, mean: 0.11051
[32m[0906 16-45-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01902, current rewards: 183.51049, mean: 0.11055
[32m[0906 16-45-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: 189.09939, mean: 0.11058
[32m[0906 16-45-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01899, current rewards: 194.67777, mean: 0.11061
[32m[0906 16-45-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01898, current rewards: 200.25790, mean: 0.11064
[32m[0906 16-45-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01898, current rewards: 205.83653, mean: 0.11066
[32m[0906 16-45-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01896, current rewards: 211.42177, mean: 0.11069
[32m[0906 16-46-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01896, current rewards: 216.99948, mean: 0.11071
[32m[0906 16-46-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 222.58072, mean: 0.11074
[32m[0906 16-46-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01893, current rewards: 228.17011, mean: 0.11076
[32m[0906 16-46-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 233.75730, mean: 0.11079
[32m[0906 16-46-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 239.34510, mean: 0.11081
[32m[0906 16-46-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 244.94412, mean: 0.11083
[32m[0906 16-46-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 250.53014, mean: 0.11085
[32m[0906 16-46-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: 256.15270, mean: 0.11089
[32m[0906 16-46-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 261.71889, mean: 0.11090
[32m[0906 16-46-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 267.28094, mean: 0.11090
[32m[0906 16-46-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 272.84579, mean: 0.11091
[32m[0906 16-46-10 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-46-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-46-10 @MBExp.py:227][0m Rewards obtained: [277.3007036457317], Lows: [1], Highs: [0], Total time: 3950.214404000001
[32m[0906 16-49-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-49-04 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 16-49-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01952, current rewards: 1.01985, mean: 0.10199
[32m[0906 16-49-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01955, current rewards: 6.55059, mean: 0.10918
[32m[0906 16-49-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01964, current rewards: 12.13227, mean: 0.11029
[32m[0906 16-49-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01938, current rewards: 17.72397, mean: 0.11077
[32m[0906 16-49-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01933, current rewards: 23.25496, mean: 0.11074
[32m[0906 16-49-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01932, current rewards: 28.78566, mean: 0.11071
[32m[0906 16-49-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01934, current rewards: 34.31482, mean: 0.11069
[32m[0906 16-49-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01934, current rewards: 39.84510, mean: 0.11068
[32m[0906 16-49-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01932, current rewards: 45.38013, mean: 0.11068
[32m[0906 16-49-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01930, current rewards: 50.90730, mean: 0.11067
[32m[0906 16-49-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01929, current rewards: 56.44004, mean: 0.11067
[32m[0906 16-49-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01930, current rewards: 61.96033, mean: 0.11064
[32m[0906 16-49-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01929, current rewards: 67.49833, mean: 0.11065
[32m[0906 16-49-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 73.01759, mean: 0.11063
[32m[0906 16-49-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01928, current rewards: 78.54094, mean: 0.11062
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: 84.06746, mean: 0.11062
[32m[0906 16-49-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 89.59885, mean: 0.11062
[32m[0906 16-49-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01929, current rewards: 95.12499, mean: 0.11061
[32m[0906 16-49-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01930, current rewards: 100.65437, mean: 0.11061
[32m[0906 16-49-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01929, current rewards: 106.12652, mean: 0.11055
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01928, current rewards: 111.61505, mean: 0.11051
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01927, current rewards: 117.11241, mean: 0.11048
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01928, current rewards: 122.60565, mean: 0.11046
[32m[0906 16-49-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01924, current rewards: 128.10822, mean: 0.11044
[32m[0906 16-49-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 133.60672, mean: 0.11042
[32m[0906 16-49-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 139.10623, mean: 0.11040
[32m[0906 16-49-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 144.60563, mean: 0.11039
[32m[0906 16-49-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 150.13037, mean: 0.11039
[32m[0906 16-49-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 155.63455, mean: 0.11038
[32m[0906 16-49-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 161.13937, mean: 0.11037
[32m[0906 16-49-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 166.64634, mean: 0.11036
[32m[0906 16-49-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 172.15226, mean: 0.11035
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 177.65758, mean: 0.11035
[32m[0906 16-49-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 183.16218, mean: 0.11034
[32m[0906 16-49-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 188.67121, mean: 0.11033
[32m[0906 16-49-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: 194.16890, mean: 0.11032
[32m[0906 16-49-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: 199.65381, mean: 0.11031
[32m[0906 16-49-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: 205.09534, mean: 0.11027
[32m[0906 16-49-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: 210.53767, mean: 0.11023
[32m[0906 16-49-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: 215.97812, mean: 0.11019
[32m[0906 16-49-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: 221.41850, mean: 0.11016
[32m[0906 16-49-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: 226.85879, mean: 0.11013
[32m[0906 16-49-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01898, current rewards: 232.29858, mean: 0.11009
[32m[0906 16-49-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01898, current rewards: 237.75416, mean: 0.11007
[32m[0906 16-49-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01897, current rewards: 243.17106, mean: 0.11003
[32m[0906 16-49-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01896, current rewards: 248.58923, mean: 0.11000
[32m[0906 16-49-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01895, current rewards: 250.75294, mean: 0.10855
[32m[0906 16-49-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01895, current rewards: 256.27954, mean: 0.10859
[32m[0906 16-49-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01894, current rewards: 261.81412, mean: 0.10864
[32m[0906 16-49-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 267.34229, mean: 0.10868
[32m[0906 16-49-52 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-49-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-49-52 @MBExp.py:227][0m Rewards obtained: [271.77653836819206], Lows: [0], Highs: [3], Total time: 3998.3076210000013
[32m[0906 16-52-47 @MBExp.py:144][0m ####################################################################
[32m[0906 16-52-47 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 16-52-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01982, current rewards: 1.65305, mean: 0.16531
[32m[0906 16-52-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01975, current rewards: 10.26215, mean: 0.17104
[32m[0906 16-52-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01964, current rewards: 13.60844, mean: 0.12371
[32m[0906 16-52-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01947, current rewards: 16.64587, mean: 0.10404
[32m[0906 16-52-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01942, current rewards: 19.68329, mean: 0.09373
[32m[0906 16-52-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01939, current rewards: 5.74875, mean: 0.02211
[32m[0906 16-52-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01936, current rewards: -44.25125, mean: -0.14275
[32m[0906 16-52-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01935, current rewards: -94.25125, mean: -0.26181
[32m[0906 16-52-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01932, current rewards: -144.25125, mean: -0.35183
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01929, current rewards: -194.25125, mean: -0.42229
[32m[0906 16-52-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: -244.25125, mean: -0.47892
[32m[0906 16-52-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: -294.25125, mean: -0.52545
[32m[0906 16-52-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: -344.25125, mean: -0.56435
[32m[0906 16-53-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: -394.25125, mean: -0.59735
[32m[0906 16-53-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: -444.25125, mean: -0.62571
[32m[0906 16-53-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01927, current rewards: -494.25125, mean: -0.65033
[32m[0906 16-53-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: -544.25125, mean: -0.67192
[32m[0906 16-53-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: -594.25125, mean: -0.69099
[32m[0906 16-53-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: -644.25125, mean: -0.70797
[32m[0906 16-53-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: -694.25125, mean: -0.72318
[32m[0906 16-53-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01924, current rewards: -744.25125, mean: -0.73688
[32m[0906 16-53-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: -794.25125, mean: -0.74929
[32m[0906 16-53-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: -844.25125, mean: -0.76059
[32m[0906 16-53-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: -894.25125, mean: -0.77091
[32m[0906 16-53-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: -944.25125, mean: -0.78037
[32m[0906 16-53-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: -994.25125, mean: -0.78909
[32m[0906 16-53-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: -1044.25125, mean: -0.79714
[32m[0906 16-53-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: -1094.25125, mean: -0.80460
[32m[0906 16-53-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: -1144.25125, mean: -0.81153
[32m[0906 16-53-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: -1194.25125, mean: -0.81798
[32m[0906 16-53-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: -1244.25125, mean: -0.82401
[32m[0906 16-53-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: -1294.25125, mean: -0.82965
[32m[0906 16-53-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: -1344.25125, mean: -0.83494
[32m[0906 16-53-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01902, current rewards: -1394.25125, mean: -0.83991
[32m[0906 16-53-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: -1444.25125, mean: -0.84459
[32m[0906 16-53-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: -1494.25125, mean: -0.84901
[32m[0906 16-53-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01898, current rewards: -1544.25125, mean: -0.85318
[32m[0906 16-53-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: -1594.25125, mean: -0.85712
[32m[0906 16-53-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01897, current rewards: -1644.25125, mean: -0.86086
[32m[0906 16-53-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01896, current rewards: -1694.25125, mean: -0.86441
[32m[0906 16-53-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: -1744.25125, mean: -0.86779
[32m[0906 16-53-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01893, current rewards: -1794.25125, mean: -0.87100
[32m[0906 16-53-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: -1844.25125, mean: -0.87405
[32m[0906 16-53-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: -1894.25125, mean: -0.87697
[32m[0906 16-53-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: -1944.25125, mean: -0.87975
[32m[0906 16-53-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: -1994.25125, mean: -0.88241
[32m[0906 16-53-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: -2044.25125, mean: -0.88496
[32m[0906 16-53-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: -2094.25125, mean: -0.88739
[32m[0906 16-53-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: -2144.25125, mean: -0.88973
[32m[0906 16-53-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: -2194.25125, mean: -0.89197
[32m[0906 16-53-35 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-53-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-53-35 @MBExp.py:227][0m Rewards obtained: [-2234.2512539715262], Lows: [0], Highs: [2256], Total time: 4046.298465000001
[32m[0906 16-56-33 @MBExp.py:144][0m ####################################################################
[32m[0906 16-56-33 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 16-56-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01915, current rewards: 0.98700, mean: 0.09870
[32m[0906 16-56-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01963, current rewards: 6.42050, mean: 0.10701
[32m[0906 16-56-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01962, current rewards: 11.85821, mean: 0.10780
[32m[0906 16-56-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01962, current rewards: 17.28818, mean: 0.10805
[32m[0906 16-56-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01946, current rewards: 22.72369, mean: 0.10821
[32m[0906 16-56-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01939, current rewards: 28.16375, mean: 0.10832
[32m[0906 16-56-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01938, current rewards: 33.59874, mean: 0.10838
[32m[0906 16-56-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01939, current rewards: 38.89719, mean: 0.10805
[32m[0906 16-56-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01937, current rewards: 44.55122, mean: 0.10866
[32m[0906 16-56-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01938, current rewards: 50.21001, mean: 0.10915
[32m[0906 16-56-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01938, current rewards: 55.86786, mean: 0.10954
[32m[0906 16-56-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01937, current rewards: 61.52658, mean: 0.10987
[32m[0906 16-56-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01936, current rewards: 67.18595, mean: 0.11014
[32m[0906 16-56-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01935, current rewards: 72.84202, mean: 0.11037
[32m[0906 16-56-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01934, current rewards: 78.51000, mean: 0.11058
[32m[0906 16-56-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01932, current rewards: 84.16747, mean: 0.11075
[32m[0906 16-56-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01930, current rewards: 89.80880, mean: 0.11088
[32m[0906 16-56-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01932, current rewards: 93.30225, mean: 0.10849
[32m[0906 16-56-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01938, current rewards: 98.98010, mean: 0.10877
[32m[0906 16-56-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01944, current rewards: 104.67120, mean: 0.10903
[32m[0906 16-56-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01951, current rewards: 110.31738, mean: 0.10923
[32m[0906 16-56-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01957, current rewards: 116.00051, mean: 0.10943
[32m[0906 16-56-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01960, current rewards: 121.66952, mean: 0.10961
[32m[0906 16-56-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01962, current rewards: 127.35868, mean: 0.10979
[32m[0906 16-56-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01961, current rewards: 133.06300, mean: 0.10997
[32m[0906 16-56-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01970, current rewards: 139.11587, mean: 0.11041
[32m[0906 16-56-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01991, current rewards: 145.35654, mean: 0.11096
[32m[0906 16-57-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02015, current rewards: 151.59646, mean: 0.11147
[32m[0906 16-57-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02040, current rewards: 157.80439, mean: 0.11192
[32m[0906 16-57-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02060, current rewards: 164.03579, mean: 0.11235
[32m[0906 16-57-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02077, current rewards: 170.27450, mean: 0.11276
[32m[0906 16-57-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02094, current rewards: 176.56470, mean: 0.11318
[32m[0906 16-57-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02109, current rewards: 182.82891, mean: 0.11356
[32m[0906 16-57-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02118, current rewards: 190.10539, mean: 0.11452
[32m[0906 16-57-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02128, current rewards: 196.54460, mean: 0.11494
[32m[0906 16-57-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02137, current rewards: 202.97566, mean: 0.11533
[32m[0906 16-57-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02145, current rewards: 209.35655, mean: 0.11567
[32m[0906 16-57-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02153, current rewards: 215.75151, mean: 0.11600
[32m[0906 16-57-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02160, current rewards: 222.18346, mean: 0.11633
[32m[0906 16-57-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02161, current rewards: 228.33876, mean: 0.11650
[32m[0906 16-57-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02154, current rewards: 233.87745, mean: 0.11636
[32m[0906 16-57-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02147, current rewards: 239.35324, mean: 0.11619
[32m[0906 16-57-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02140, current rewards: 244.86721, mean: 0.11605
[32m[0906 16-57-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02133, current rewards: 250.38499, mean: 0.11592
[32m[0906 16-57-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02127, current rewards: 255.90122, mean: 0.11579
[32m[0906 16-57-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02121, current rewards: 261.42143, mean: 0.11567
[32m[0906 16-57-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02115, current rewards: 266.94904, mean: 0.11556
[32m[0906 16-57-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02110, current rewards: 272.47249, mean: 0.11545
[32m[0906 16-57-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02107, current rewards: 278.74157, mean: 0.11566
[32m[0906 16-57-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02109, current rewards: 284.61770, mean: 0.11570
[32m[0906 16-57-26 @Agent.py:117][0m Average action selection time: 0.0211
[32m[0906 16-57-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-57-26 @MBExp.py:227][0m Rewards obtained: [289.31835142450285], Lows: [1], Highs: [0], Total time: 4099.897231000001
[32m[0906 17-00-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-00-26 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-00-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01854, current rewards: 1.14226, mean: 0.11423
[32m[0906 17-00-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.75369, mean: 0.11256
[32m[0906 17-00-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.29293, mean: 0.11175
[32m[0906 17-00-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.83250, mean: 0.11145
[32m[0906 17-00-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 23.37276, mean: 0.11130
[32m[0906 17-00-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 28.91642, mean: 0.11122
[32m[0906 17-00-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 34.45585, mean: 0.11115
[32m[0906 17-00-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 39.99209, mean: 0.11109
[32m[0906 17-00-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 45.52323, mean: 0.11103
[32m[0906 17-00-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 51.15308, mean: 0.11120
[32m[0906 17-00-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.78220, mean: 0.11134
[32m[0906 17-00-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 62.41518, mean: 0.11146
[32m[0906 17-00-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 68.04548, mean: 0.11155
[32m[0906 17-00-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.68020, mean: 0.11164
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 79.31556, mean: 0.11171
[32m[0906 17-00-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 84.94809, mean: 0.11177
[32m[0906 17-00-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 90.58905, mean: 0.11184
[32m[0906 17-00-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 96.12349, mean: 0.11177
[32m[0906 17-00-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 101.63111, mean: 0.11168
[32m[0906 17-00-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 107.14053, mean: 0.11160
[32m[0906 17-00-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 112.64751, mean: 0.11153
[32m[0906 17-00-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 118.15244, mean: 0.11146
[32m[0906 17-00-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01907, current rewards: 123.65834, mean: 0.11140
[32m[0906 17-00-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01906, current rewards: 129.16781, mean: 0.11135
[32m[0906 17-00-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01904, current rewards: 134.67720, mean: 0.11130
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01902, current rewards: 140.31550, mean: 0.11136
[32m[0906 17-00-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 145.87495, mean: 0.11135
[32m[0906 17-00-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01900, current rewards: 151.42943, mean: 0.11135
[32m[0906 17-00-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01899, current rewards: 156.98581, mean: 0.11134
[32m[0906 17-00-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01898, current rewards: 162.54282, mean: 0.11133
[32m[0906 17-00-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01898, current rewards: 168.10122, mean: 0.11133
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01897, current rewards: 173.65521, mean: 0.11132
[32m[0906 17-00-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01895, current rewards: 179.23801, mean: 0.11133
[32m[0906 17-00-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 184.71182, mean: 0.11127
[32m[0906 17-00-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: 190.29946, mean: 0.11129
[32m[0906 17-01-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01892, current rewards: 195.88456, mean: 0.11130
[32m[0906 17-01-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01891, current rewards: 201.46907, mean: 0.11131
[32m[0906 17-01-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01891, current rewards: 207.05102, mean: 0.11132
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01889, current rewards: 212.63663, mean: 0.11133
[32m[0906 17-01-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01889, current rewards: 218.18902, mean: 0.11132
[32m[0906 17-01-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 223.74127, mean: 0.11131
[32m[0906 17-01-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 229.29198, mean: 0.11131
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 234.84083, mean: 0.11130
[32m[0906 17-01-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 240.39454, mean: 0.11129
[32m[0906 17-01-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 245.94845, mean: 0.11129
[32m[0906 17-01-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 251.53013, mean: 0.11130
[32m[0906 17-01-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 257.15596, mean: 0.11132
[32m[0906 17-01-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 262.79091, mean: 0.11135
[32m[0906 17-01-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 268.42423, mean: 0.11138
[32m[0906 17-01-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 274.05973, mean: 0.11141
[32m[0906 17-01-14 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-01-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-01-14 @MBExp.py:227][0m Rewards obtained: [278.6747927892095], Lows: [0], Highs: [0], Total time: 4147.805003
[32m[0906 17-04-16 @MBExp.py:144][0m ####################################################################
[32m[0906 17-04-16 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-04-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01932, current rewards: 1.16314, mean: 0.11631
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 6.73332, mean: 0.11222
[32m[0906 17-04-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.30111, mean: 0.11183
[32m[0906 17-04-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.86981, mean: 0.11169
[32m[0906 17-04-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 23.43521, mean: 0.11160
[32m[0906 17-04-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 29.00609, mean: 0.11156
[32m[0906 17-04-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 34.57634, mean: 0.11154
[32m[0906 17-04-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 40.72698, mean: 0.11313
[32m[0906 17-04-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 46.84838, mean: 0.11426
[32m[0906 17-04-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 52.30163, mean: 0.11370
[32m[0906 17-04-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 57.84823, mean: 0.11343
[32m[0906 17-04-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 63.50600, mean: 0.11340
[32m[0906 17-04-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 69.16285, mean: 0.11338
[32m[0906 17-04-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 74.82020, mean: 0.11336
[32m[0906 17-04-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 80.47721, mean: 0.11335
[32m[0906 17-04-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 79.36654, mean: 0.10443
[32m[0906 17-04-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 84.85125, mean: 0.10475
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 90.35504, mean: 0.10506
[32m[0906 17-04-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 95.85994, mean: 0.10534
[32m[0906 17-04-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 101.36539, mean: 0.10559
[32m[0906 17-04-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 106.86972, mean: 0.10581
[32m[0906 17-04-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 112.37602, mean: 0.10602
[32m[0906 17-04-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01903, current rewards: 117.90288, mean: 0.10622
[32m[0906 17-04-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01902, current rewards: 123.45543, mean: 0.10643
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01900, current rewards: 128.95213, mean: 0.10657
[32m[0906 17-04-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01899, current rewards: 134.45850, mean: 0.10671
[32m[0906 17-04-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01898, current rewards: 139.99471, mean: 0.10687
[32m[0906 17-04-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01896, current rewards: 145.53350, mean: 0.10701
[32m[0906 17-04-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01895, current rewards: 151.07135, mean: 0.10714
[32m[0906 17-04-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01894, current rewards: 156.61127, mean: 0.10727
[32m[0906 17-04-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01893, current rewards: 162.15118, mean: 0.10738
[32m[0906 17-04-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01892, current rewards: 167.69295, mean: 0.10750
[32m[0906 17-04-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01891, current rewards: 173.22873, mean: 0.10760
[32m[0906 17-04-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01890, current rewards: 178.83367, mean: 0.10773
[32m[0906 17-04-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01889, current rewards: 184.43601, mean: 0.10786
[32m[0906 17-04-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01889, current rewards: 189.97486, mean: 0.10794
[32m[0906 17-04-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01888, current rewards: 195.51923, mean: 0.10802
[32m[0906 17-04-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01887, current rewards: 201.05967, mean: 0.10810
[32m[0906 17-04-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01887, current rewards: 206.60023, mean: 0.10817
[32m[0906 17-04-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01886, current rewards: 212.14108, mean: 0.10824
[32m[0906 17-04-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 217.68461, mean: 0.10830
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 223.27294, mean: 0.10838
[32m[0906 17-04-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 228.80088, mean: 0.10844
[32m[0906 17-04-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 234.31082, mean: 0.10848
[32m[0906 17-04-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01882, current rewards: 239.82413, mean: 0.10852
[32m[0906 17-04-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 245.33166, mean: 0.10855
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 250.83844, mean: 0.10859
[32m[0906 17-05-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 256.34923, mean: 0.10862
[32m[0906 17-05-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: 261.85568, mean: 0.10865
[32m[0906 17-05-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: 267.32083, mean: 0.10867
[32m[0906 17-05-04 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-05-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-05-04 @MBExp.py:227][0m Rewards obtained: [271.71969814007446], Lows: [0], Highs: [6], Total time: 4195.592617
[32m[0906 17-08-08 @MBExp.py:144][0m ####################################################################
[32m[0906 17-08-08 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-08-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01870, current rewards: 1.53682, mean: 0.15368
[32m[0906 17-08-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01920, current rewards: 7.18476, mean: 0.11975
[32m[0906 17-08-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01934, current rewards: 12.82978, mean: 0.11663
[32m[0906 17-08-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01957, current rewards: 18.44060, mean: 0.11525
[32m[0906 17-08-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01947, current rewards: 24.10315, mean: 0.11478
[32m[0906 17-08-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01941, current rewards: 29.75373, mean: 0.11444
[32m[0906 17-08-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01939, current rewards: 35.40195, mean: 0.11420
[32m[0906 17-08-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01936, current rewards: 41.06326, mean: 0.11406
[32m[0906 17-08-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01967, current rewards: 46.28112, mean: 0.11288
[32m[0906 17-08-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02004, current rewards: 51.05325, mean: 0.11099
[32m[0906 17-08-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02035, current rewards: 55.80099, mean: 0.10941
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02058, current rewards: 60.54458, mean: 0.10812
[32m[0906 17-08-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02071, current rewards: 65.31038, mean: 0.10707
[32m[0906 17-08-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02084, current rewards: 70.06752, mean: 0.10616
[32m[0906 17-08-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02096, current rewards: 74.83554, mean: 0.10540
[32m[0906 17-08-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02111, current rewards: 79.57437, mean: 0.10470
[32m[0906 17-08-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02115, current rewards: 84.61318, mean: 0.10446
[32m[0906 17-08-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02114, current rewards: 89.76365, mean: 0.10438
[32m[0906 17-08-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02113, current rewards: 94.86464, mean: 0.10425
[32m[0906 17-08-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02115, current rewards: 99.99791, mean: 0.10416
[32m[0906 17-08-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02110, current rewards: 104.17392, mean: 0.10314
[32m[0906 17-08-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02098, current rewards: 109.74140, mean: 0.10353
[32m[0906 17-08-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02087, current rewards: 115.30746, mean: 0.10388
[32m[0906 17-08-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02078, current rewards: 120.87903, mean: 0.10421
[32m[0906 17-08-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02069, current rewards: 126.40021, mean: 0.10446
[32m[0906 17-08-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02061, current rewards: 131.95223, mean: 0.10472
[32m[0906 17-08-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02053, current rewards: 137.53685, mean: 0.10499
[32m[0906 17-08-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02047, current rewards: 143.11211, mean: 0.10523
[32m[0906 17-08-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02040, current rewards: 148.68505, mean: 0.10545
[32m[0906 17-08-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02034, current rewards: 154.26059, mean: 0.10566
[32m[0906 17-08-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02028, current rewards: 159.83780, mean: 0.10585
[32m[0906 17-08-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02022, current rewards: 165.42270, mean: 0.10604
[32m[0906 17-08-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02017, current rewards: 171.08558, mean: 0.10626
[32m[0906 17-08-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02013, current rewards: 176.68452, mean: 0.10644
[32m[0906 17-08-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02009, current rewards: 182.23299, mean: 0.10657
[32m[0906 17-08-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02004, current rewards: 187.78500, mean: 0.10670
[32m[0906 17-08-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02001, current rewards: 193.34386, mean: 0.10682
[32m[0906 17-08-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01997, current rewards: 198.90144, mean: 0.10694
[32m[0906 17-08-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01993, current rewards: 204.45313, mean: 0.10704
[32m[0906 17-08-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01989, current rewards: 210.01391, mean: 0.10715
[32m[0906 17-08-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01986, current rewards: 215.57328, mean: 0.10725
[32m[0906 17-08-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01983, current rewards: 221.15933, mean: 0.10736
[32m[0906 17-08-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01980, current rewards: 226.71796, mean: 0.10745
[32m[0906 17-08-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01978, current rewards: 232.27715, mean: 0.10754
[32m[0906 17-08-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01975, current rewards: 237.83866, mean: 0.10762
[32m[0906 17-08-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01972, current rewards: 243.39672, mean: 0.10770
[32m[0906 17-08-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01969, current rewards: 248.95590, mean: 0.10777
[32m[0906 17-08-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01966, current rewards: 254.59553, mean: 0.10788
[32m[0906 17-08-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01964, current rewards: 260.22430, mean: 0.10798
[32m[0906 17-08-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01962, current rewards: 265.85276, mean: 0.10807
[32m[0906 17-08-58 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 17-08-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-08-58 @MBExp.py:227][0m Rewards obtained: [270.35153558668526], Lows: [0], Highs: [1], Total time: 4245.385661
[32m[0906 17-12-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-12-04 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-12-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01905, current rewards: 1.17085, mean: 0.11709
[32m[0906 17-12-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01912, current rewards: 6.84944, mean: 0.11416
[32m[0906 17-12-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 12.52995, mean: 0.11391
[32m[0906 17-12-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 18.21121, mean: 0.11382
[32m[0906 17-12-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.89236, mean: 0.11377
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 29.57280, mean: 0.11374
[32m[0906 17-12-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 34.10249, mean: 0.11001
[32m[0906 17-12-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 39.61230, mean: 0.11003
[32m[0906 17-12-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 45.13304, mean: 0.11008
[32m[0906 17-12-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 50.64982, mean: 0.11011
[32m[0906 17-12-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.17264, mean: 0.11014
[32m[0906 17-12-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 61.69645, mean: 0.11017
[32m[0906 17-12-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01924, current rewards: 67.21764, mean: 0.11019
[32m[0906 17-12-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01922, current rewards: 72.72592, mean: 0.11019
[32m[0906 17-12-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 78.25648, mean: 0.11022
[32m[0906 17-12-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 83.75983, mean: 0.11021
[32m[0906 17-12-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 89.28551, mean: 0.11023
[32m[0906 17-12-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 94.81666, mean: 0.11025
[32m[0906 17-12-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 100.34960, mean: 0.11027
[32m[0906 17-12-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 105.87838, mean: 0.11029
[32m[0906 17-12-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 111.40057, mean: 0.11030
[32m[0906 17-12-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01907, current rewards: 116.94655, mean: 0.11033
[32m[0906 17-12-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01905, current rewards: 122.48148, mean: 0.11034
[32m[0906 17-12-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01903, current rewards: 128.03926, mean: 0.11038
[32m[0906 17-12-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01902, current rewards: 133.59010, mean: 0.11041
[32m[0906 17-12-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01901, current rewards: 139.13264, mean: 0.11042
[32m[0906 17-12-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01899, current rewards: 144.67191, mean: 0.11044
[32m[0906 17-12-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01898, current rewards: 150.21569, mean: 0.11045
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01897, current rewards: 155.74876, mean: 0.11046
[32m[0906 17-12-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01895, current rewards: 161.28136, mean: 0.11047
[32m[0906 17-12-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01895, current rewards: 166.85327, mean: 0.11050
[32m[0906 17-12-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01894, current rewards: 172.42252, mean: 0.11053
[32m[0906 17-12-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 177.95351, mean: 0.11053
[32m[0906 17-12-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01892, current rewards: 183.51407, mean: 0.11055
[32m[0906 17-12-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01892, current rewards: 189.07483, mean: 0.11057
[32m[0906 17-12-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01891, current rewards: 194.63187, mean: 0.11059
[32m[0906 17-12-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01890, current rewards: 200.19116, mean: 0.11060
[32m[0906 17-12-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01889, current rewards: 205.74650, mean: 0.11062
[32m[0906 17-12-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01888, current rewards: 211.30875, mean: 0.11063
[32m[0906 17-12-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01888, current rewards: 216.87055, mean: 0.11065
[32m[0906 17-12-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 222.50164, mean: 0.11070
[32m[0906 17-12-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 228.04186, mean: 0.11070
[32m[0906 17-12-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 233.58101, mean: 0.11070
[32m[0906 17-12-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 239.12017, mean: 0.11070
[32m[0906 17-12-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 244.66452, mean: 0.11071
[32m[0906 17-12-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 250.20548, mean: 0.11071
[32m[0906 17-12-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: 255.74538, mean: 0.11071
[32m[0906 17-12-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: 261.28800, mean: 0.11072
[32m[0906 17-12-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 266.69640, mean: 0.11066
[32m[0906 17-12-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: 272.23263, mean: 0.11066
[32m[0906 17-12-52 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-12-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-12-52 @MBExp.py:227][0m Rewards obtained: [276.7162140118632], Lows: [0], Highs: [1], Total time: 4293.2504260000005
[32m[0906 17-16-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-16-01 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 17-16-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01924, current rewards: -1.06934, mean: -0.10693
[32m[0906 17-16-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01928, current rewards: 4.32421, mean: 0.07207
[32m[0906 17-16-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01922, current rewards: 9.87088, mean: 0.08974
[32m[0906 17-16-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01922, current rewards: 15.42006, mean: 0.09638
[32m[0906 17-16-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 20.97445, mean: 0.09988
[32m[0906 17-16-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 26.52541, mean: 0.10202
[32m[0906 17-16-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 32.07213, mean: 0.10346
[32m[0906 17-16-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 37.71469, mean: 0.10476
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 43.26197, mean: 0.10552
[32m[0906 17-16-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 48.80682, mean: 0.10610
[32m[0906 17-16-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 54.35190, mean: 0.10657
[32m[0906 17-16-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 59.89851, mean: 0.10696
[32m[0906 17-16-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01923, current rewards: 65.44460, mean: 0.10729
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 70.99342, mean: 0.10757
[32m[0906 17-16-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 76.47907, mean: 0.10772
[32m[0906 17-16-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 82.03559, mean: 0.10794
[32m[0906 17-16-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 87.52831, mean: 0.10806
[32m[0906 17-16-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 93.02203, mean: 0.10817
[32m[0906 17-16-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 98.51538, mean: 0.10826
[32m[0906 17-16-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 104.00929, mean: 0.10834
[32m[0906 17-16-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01906, current rewards: 109.50399, mean: 0.10842
[32m[0906 17-16-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01904, current rewards: 115.00013, mean: 0.10849
[32m[0906 17-16-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01902, current rewards: 120.49303, mean: 0.10855
[32m[0906 17-16-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01901, current rewards: 125.91330, mean: 0.10855
[32m[0906 17-16-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01899, current rewards: 131.22043, mean: 0.10845
[32m[0906 17-16-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01898, current rewards: 136.62834, mean: 0.10844
[32m[0906 17-16-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01896, current rewards: 142.03135, mean: 0.10842
[32m[0906 17-16-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01896, current rewards: 147.43390, mean: 0.10841
[32m[0906 17-16-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01894, current rewards: 152.83314, mean: 0.10839
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01894, current rewards: 158.23343, mean: 0.10838
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01893, current rewards: 163.63918, mean: 0.10837
[32m[0906 17-16-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01891, current rewards: 169.04057, mean: 0.10836
[32m[0906 17-16-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01891, current rewards: 174.42902, mean: 0.10834
[32m[0906 17-16-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01890, current rewards: 179.78338, mean: 0.10830
[32m[0906 17-16-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01889, current rewards: 185.13305, mean: 0.10826
[32m[0906 17-16-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01888, current rewards: 190.48941, mean: 0.10823
[32m[0906 17-16-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01887, current rewards: 195.84326, mean: 0.10820
[32m[0906 17-16-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01886, current rewards: 201.19306, mean: 0.10817
[32m[0906 17-16-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01885, current rewards: 206.54736, mean: 0.10814
[32m[0906 17-16-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01885, current rewards: 211.90110, mean: 0.10811
[32m[0906 17-16-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 217.26215, mean: 0.10809
[32m[0906 17-16-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 222.63228, mean: 0.10807
[32m[0906 17-16-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 228.01459, mean: 0.10806
[32m[0906 17-16-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 233.39532, mean: 0.10805
[32m[0906 17-16-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01882, current rewards: 238.77536, mean: 0.10804
[32m[0906 17-16-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 244.15460, mean: 0.10803
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 249.53016, mean: 0.10802
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 254.90960, mean: 0.10801
[32m[0906 17-16-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01881, current rewards: 260.30576, mean: 0.10801
[32m[0906 17-16-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: 265.77481, mean: 0.10804
[32m[0906 17-16-48 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-16-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-16-48 @MBExp.py:227][0m Rewards obtained: [270.1528017076894], Lows: [1], Highs: [0], Total time: 4341.063349000001
[32m[0906 17-19-58 @MBExp.py:144][0m ####################################################################
[32m[0906 17-19-58 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 17-19-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01860, current rewards: 1.04086, mean: 0.10409
[32m[0906 17-19-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01898, current rewards: 6.59139, mean: 0.10986
[32m[0906 17-20-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.16589, mean: 0.11060
[32m[0906 17-20-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01913, current rewards: 17.73841, mean: 0.11087
[32m[0906 17-20-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.30882, mean: 0.11099
[32m[0906 17-20-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 28.88305, mean: 0.11109
[32m[0906 17-20-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.45731, mean: 0.11115
[32m[0906 17-20-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 40.14480, mean: 0.11151
[32m[0906 17-20-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.72772, mean: 0.11153
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 51.30480, mean: 0.11153
[32m[0906 17-20-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 56.87717, mean: 0.11152
[32m[0906 17-20-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 62.45781, mean: 0.11153
[32m[0906 17-20-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 68.03742, mean: 0.11154
[32m[0906 17-20-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 73.61827, mean: 0.11154
[32m[0906 17-20-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 77.17667, mean: 0.10870
[32m[0906 17-20-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 83.57498, mean: 0.10997
[32m[0906 17-20-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 89.12476, mean: 0.11003
[32m[0906 17-20-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01909, current rewards: 94.67218, mean: 0.11008
[32m[0906 17-20-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01906, current rewards: 100.21881, mean: 0.11013
[32m[0906 17-20-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01903, current rewards: 105.76629, mean: 0.11017
[32m[0906 17-20-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01901, current rewards: 111.31347, mean: 0.11021
[32m[0906 17-20-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01898, current rewards: 116.85676, mean: 0.11024
[32m[0906 17-20-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01897, current rewards: 122.40305, mean: 0.11027
[32m[0906 17-20-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01896, current rewards: 126.83070, mean: 0.10934
[32m[0906 17-20-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01895, current rewards: 132.38483, mean: 0.10941
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01894, current rewards: 137.92930, mean: 0.10947
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01892, current rewards: 143.47851, mean: 0.10953
[32m[0906 17-20-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01891, current rewards: 149.02023, mean: 0.10957
[32m[0906 17-20-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01890, current rewards: 154.56636, mean: 0.10962
[32m[0906 17-20-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01889, current rewards: 160.11562, mean: 0.10967
[32m[0906 17-20-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01888, current rewards: 165.74582, mean: 0.10977
[32m[0906 17-20-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01887, current rewards: 171.46120, mean: 0.10991
[32m[0906 17-20-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01887, current rewards: 177.17469, mean: 0.11005
[32m[0906 17-20-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01886, current rewards: 182.88700, mean: 0.11017
[32m[0906 17-20-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01885, current rewards: 188.59446, mean: 0.11029
[32m[0906 17-20-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 194.31157, mean: 0.11040
[32m[0906 17-20-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 199.99615, mean: 0.11050
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 205.68638, mean: 0.11058
[32m[0906 17-20-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: 211.38435, mean: 0.11067
[32m[0906 17-20-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: 217.08459, mean: 0.11076
[32m[0906 17-20-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 222.67498, mean: 0.11078
[32m[0906 17-20-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01880, current rewards: 228.38037, mean: 0.11086
[32m[0906 17-20-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: 234.08612, mean: 0.11094
[32m[0906 17-20-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 239.79392, mean: 0.11102
[32m[0906 17-20-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01879, current rewards: 245.38252, mean: 0.11103
[32m[0906 17-20-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01879, current rewards: 250.94616, mean: 0.11104
[32m[0906 17-20-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: 256.51014, mean: 0.11104
[32m[0906 17-20-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01878, current rewards: 262.07286, mean: 0.11105
[32m[0906 17-20-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01878, current rewards: 267.73924, mean: 0.11110
[32m[0906 17-20-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01877, current rewards: 273.28821, mean: 0.11109
[32m[0906 17-20-46 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-20-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-20-46 @MBExp.py:227][0m Rewards obtained: [277.7278230640445], Lows: [1], Highs: [1], Total time: 4388.786520000001
[32m[0906 17-23-58 @MBExp.py:144][0m ####################################################################
[32m[0906 17-23-58 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 17-23-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.07457, mean: 0.10746
[32m[0906 17-23-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.63736, mean: 0.11062
[32m[0906 17-24-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01904, current rewards: 12.19850, mean: 0.11090
[32m[0906 17-24-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.76260, mean: 0.11102
[32m[0906 17-24-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.31825, mean: 0.11104
[32m[0906 17-24-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 28.87418, mean: 0.11105
[32m[0906 17-24-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.43309, mean: 0.11107
[32m[0906 17-24-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 39.94678, mean: 0.11096
[32m[0906 17-24-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 45.49809, mean: 0.11097
[32m[0906 17-24-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 51.04317, mean: 0.11096
[32m[0906 17-24-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.59015, mean: 0.11096
[32m[0906 17-24-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 60.17105, mean: 0.10745
[32m[0906 17-24-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 65.77699, mean: 0.10783
[32m[0906 17-24-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 71.38572, mean: 0.10816
[32m[0906 17-24-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 76.99820, mean: 0.10845
[32m[0906 17-24-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 82.66090, mean: 0.10876
[32m[0906 17-24-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 88.23746, mean: 0.10894
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 93.81632, mean: 0.10909
[32m[0906 17-24-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 99.40159, mean: 0.10923
[32m[0906 17-24-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 104.97804, mean: 0.10935
[32m[0906 17-24-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 110.50964, mean: 0.10942
[32m[0906 17-24-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 116.01694, mean: 0.10945
[32m[0906 17-24-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01908, current rewards: 121.52476, mean: 0.10948
[32m[0906 17-24-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01906, current rewards: 127.07084, mean: 0.10954
[32m[0906 17-24-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01904, current rewards: 132.57961, mean: 0.10957
[32m[0906 17-24-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01902, current rewards: 138.09118, mean: 0.10960
[32m[0906 17-24-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01901, current rewards: 143.59930, mean: 0.10962
[32m[0906 17-24-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01900, current rewards: 149.10871, mean: 0.10964
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01898, current rewards: 154.66260, mean: 0.10969
[32m[0906 17-24-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01896, current rewards: 160.22019, mean: 0.10974
[32m[0906 17-24-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01895, current rewards: 165.77654, mean: 0.10979
[32m[0906 17-24-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01894, current rewards: 171.31741, mean: 0.10982
[32m[0906 17-24-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 176.78636, mean: 0.10981
[32m[0906 17-24-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01892, current rewards: 182.37610, mean: 0.10987
[32m[0906 17-24-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01891, current rewards: 187.96577, mean: 0.10992
[32m[0906 17-24-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01890, current rewards: 193.55588, mean: 0.10997
[32m[0906 17-24-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01889, current rewards: 199.14772, mean: 0.11003
[32m[0906 17-24-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01887, current rewards: 204.73321, mean: 0.11007
[32m[0906 17-24-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01887, current rewards: 210.32007, mean: 0.11012
[32m[0906 17-24-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01886, current rewards: 215.90931, mean: 0.11016
[32m[0906 17-24-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01886, current rewards: 221.51181, mean: 0.11020
[32m[0906 17-24-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 227.09875, mean: 0.11024
[32m[0906 17-24-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 232.68651, mean: 0.11028
[32m[0906 17-24-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 238.27550, mean: 0.11031
[32m[0906 17-24-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: 243.86690, mean: 0.11035
[32m[0906 17-24-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01883, current rewards: 249.36875, mean: 0.11034
[32m[0906 17-24-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 254.88414, mean: 0.11034
[32m[0906 17-24-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01882, current rewards: 260.39945, mean: 0.11034
[32m[0906 17-24-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01882, current rewards: 266.01334, mean: 0.11038
[32m[0906 17-24-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: 271.55757, mean: 0.11039
[32m[0906 17-24-46 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-24-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-24-46 @MBExp.py:227][0m Rewards obtained: [275.9936871274533], Lows: [1], Highs: [0], Total time: 4436.633194000001
[32m[0906 17-28-00 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-00 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 17-28-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01834, current rewards: 1.08659, mean: 0.10866
[32m[0906 17-28-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.48877, mean: 0.10815
[32m[0906 17-28-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 11.89323, mean: 0.10812
[32m[0906 17-28-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 17.29335, mean: 0.10808
[32m[0906 17-28-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 22.70229, mean: 0.10811
[32m[0906 17-28-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 28.10875, mean: 0.10811
[32m[0906 17-28-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 33.58140, mean: 0.10833
[32m[0906 17-28-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 39.23078, mean: 0.10897
[32m[0906 17-28-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 44.75026, mean: 0.10915
[32m[0906 17-28-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 50.27432, mean: 0.10929
[32m[0906 17-28-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 55.79565, mean: 0.10940
[32m[0906 17-28-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 61.30225, mean: 0.10947
[32m[0906 17-28-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 66.86277, mean: 0.10961
[32m[0906 17-28-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 72.34098, mean: 0.10961
[32m[0906 17-28-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 77.83476, mean: 0.10963
[32m[0906 17-28-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 83.27314, mean: 0.10957
[32m[0906 17-28-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 88.76615, mean: 0.10959
[32m[0906 17-28-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 94.25521, mean: 0.10960
[32m[0906 17-28-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 99.88073, mean: 0.10976
[32m[0906 17-28-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 105.43981, mean: 0.10983
[32m[0906 17-28-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 110.99964, mean: 0.10990
[32m[0906 17-28-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 116.55610, mean: 0.10996
[32m[0906 17-28-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 122.11398, mean: 0.11001
[32m[0906 17-28-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 127.56632, mean: 0.10997
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01905, current rewards: 133.12224, mean: 0.11002
[32m[0906 17-28-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01903, current rewards: 138.67568, mean: 0.11006
[32m[0906 17-28-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01901, current rewards: 144.23084, mean: 0.11010
[32m[0906 17-28-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01900, current rewards: 149.78592, mean: 0.11014
[32m[0906 17-28-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01899, current rewards: 155.34135, mean: 0.11017
[32m[0906 17-28-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01897, current rewards: 160.89710, mean: 0.11020
[32m[0906 17-28-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01896, current rewards: 166.44958, mean: 0.11023
[32m[0906 17-28-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01895, current rewards: 172.04283, mean: 0.11028
[32m[0906 17-28-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 176.45044, mean: 0.10960
[32m[0906 17-28-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01892, current rewards: 181.94407, mean: 0.10960
[32m[0906 17-28-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01892, current rewards: 187.43601, mean: 0.10961
[32m[0906 17-28-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01891, current rewards: 192.93650, mean: 0.10962
[32m[0906 17-28-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01889, current rewards: 198.43235, mean: 0.10963
[32m[0906 17-28-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01889, current rewards: 203.92361, mean: 0.10964
[32m[0906 17-28-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01888, current rewards: 209.42175, mean: 0.10964
[32m[0906 17-28-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01888, current rewards: 214.91647, mean: 0.10965
[32m[0906 17-28-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 220.27087, mean: 0.10959
[32m[0906 17-28-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01887, current rewards: 225.72484, mean: 0.10958
[32m[0906 17-28-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 231.15762, mean: 0.10955
[32m[0906 17-28-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01886, current rewards: 236.58968, mean: 0.10953
[32m[0906 17-28-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 242.02463, mean: 0.10951
[32m[0906 17-28-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: 247.45565, mean: 0.10949
[32m[0906 17-28-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 252.88487, mean: 0.10947
[32m[0906 17-28-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: 258.31392, mean: 0.10946
[32m[0906 17-28-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 263.86362, mean: 0.10949
[32m[0906 17-28-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01883, current rewards: 269.43952, mean: 0.10953
[32m[0906 17-28-48 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-28-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-28-48 @MBExp.py:227][0m Rewards obtained: [273.83785228261974], Lows: [0], Highs: [1], Total time: 4484.512977000001
[32m[0906 17-32-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-32-04 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 17-32-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01824, current rewards: 1.10047, mean: 0.11005
[32m[0906 17-32-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.69148, mean: 0.11152
[32m[0906 17-32-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.24030, mean: 0.11128
[32m[0906 17-32-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.79006, mean: 0.11119
[32m[0906 17-32-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.33847, mean: 0.11114
[32m[0906 17-32-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 28.88719, mean: 0.11110
[32m[0906 17-32-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.43629, mean: 0.11108
[32m[0906 17-32-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 40.08011, mean: 0.11133
[32m[0906 17-32-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 46.12538, mean: 0.11250
[32m[0906 17-32-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 52.17065, mean: 0.11341
[32m[0906 17-32-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 47.72598, mean: 0.09358
[32m[0906 17-32-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 53.25099, mean: 0.09509
[32m[0906 17-32-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 58.77580, mean: 0.09635
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 64.30184, mean: 0.09743
[32m[0906 17-32-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: 69.82722, mean: 0.09835
[32m[0906 17-32-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01925, current rewards: 75.27322, mean: 0.09904
[32m[0906 17-32-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01926, current rewards: 80.73961, mean: 0.09968
[32m[0906 17-32-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01927, current rewards: 86.24685, mean: 0.10029
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 91.75349, mean: 0.10083
[32m[0906 17-32-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01929, current rewards: 97.25923, mean: 0.10131
[32m[0906 17-32-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01924, current rewards: 102.76566, mean: 0.10175
[32m[0906 17-32-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 108.29549, mean: 0.10217
[32m[0906 17-32-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01918, current rewards: 113.82488, mean: 0.10254
[32m[0906 17-32-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 119.35965, mean: 0.10290
[32m[0906 17-32-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 124.86016, mean: 0.10319
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 130.39999, mean: 0.10349
[32m[0906 17-32-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 135.93866, mean: 0.10377
[32m[0906 17-32-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 141.47974, mean: 0.10403
[32m[0906 17-32-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 147.01517, mean: 0.10427
[32m[0906 17-32-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 152.55669, mean: 0.10449
[32m[0906 17-32-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 158.09701, mean: 0.10470
[32m[0906 17-32-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 163.63449, mean: 0.10489
[32m[0906 17-32-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01902, current rewards: 169.19822, mean: 0.10509
[32m[0906 17-32-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01901, current rewards: 174.73289, mean: 0.10526
[32m[0906 17-32-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01900, current rewards: 180.27152, mean: 0.10542
[32m[0906 17-32-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: 185.80694, mean: 0.10557
[32m[0906 17-32-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01898, current rewards: 191.34711, mean: 0.10572
[32m[0906 17-32-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: 196.86611, mean: 0.10584
[32m[0906 17-32-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01896, current rewards: 202.38071, mean: 0.10596
[32m[0906 17-32-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01896, current rewards: 207.89207, mean: 0.10607
[32m[0906 17-32-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 213.48982, mean: 0.10621
[32m[0906 17-32-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01894, current rewards: 219.01296, mean: 0.10632
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 224.52640, mean: 0.10641
[32m[0906 17-32-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 230.04883, mean: 0.10650
[32m[0906 17-32-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 235.56313, mean: 0.10659
[32m[0906 17-32-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 241.06584, mean: 0.10667
[32m[0906 17-32-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: 246.57297, mean: 0.10674
[32m[0906 17-32-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 252.07583, mean: 0.10681
[32m[0906 17-32-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 257.56932, mean: 0.10688
[32m[0906 17-32-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 262.96308, mean: 0.10690
[32m[0906 17-32-52 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-32-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-32-52 @MBExp.py:227][0m Rewards obtained: [267.3567993249165], Lows: [0], Highs: [9], Total time: 4532.531677000001
[32m[0906 17-36-10 @MBExp.py:144][0m ####################################################################
[32m[0906 17-36-10 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 17-36-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01862, current rewards: 1.60775, mean: 0.16078
[32m[0906 17-36-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 7.15247, mean: 0.11921
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 12.74175, mean: 0.11583
[32m[0906 17-36-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 18.32344, mean: 0.11452
[32m[0906 17-36-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.90650, mean: 0.11384
[32m[0906 17-36-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 29.49075, mean: 0.11343
[32m[0906 17-36-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 35.06869, mean: 0.11312
[32m[0906 17-36-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 40.70711, mean: 0.11308
[32m[0906 17-36-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 46.31481, mean: 0.11296
[32m[0906 17-36-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 49.79956, mean: 0.10826
[32m[0906 17-36-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 55.30804, mean: 0.10845
[32m[0906 17-36-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 60.81689, mean: 0.10860
[32m[0906 17-36-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 66.32489, mean: 0.10873
[32m[0906 17-36-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 71.83341, mean: 0.10884
[32m[0906 17-36-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 77.34207, mean: 0.10893
[32m[0906 17-36-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 82.85124, mean: 0.10901
[32m[0906 17-36-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 88.20556, mean: 0.10890
[32m[0906 17-36-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 93.62778, mean: 0.10887
[32m[0906 17-36-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 99.05367, mean: 0.10885
[32m[0906 17-36-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 104.65425, mean: 0.10901
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01917, current rewards: 110.27350, mean: 0.10918
[32m[0906 17-36-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 115.88832, mean: 0.10933
[32m[0906 17-36-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 121.50471, mean: 0.10946
[32m[0906 17-36-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 127.12324, mean: 0.10959
[32m[0906 17-36-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 132.77504, mean: 0.10973
[32m[0906 17-36-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 138.41613, mean: 0.10985
[32m[0906 17-36-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01904, current rewards: 144.04395, mean: 0.10996
[32m[0906 17-36-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01903, current rewards: 149.67352, mean: 0.11005
[32m[0906 17-36-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01901, current rewards: 153.05236, mean: 0.10855
[32m[0906 17-36-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01900, current rewards: 158.46623, mean: 0.10854
[32m[0906 17-36-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01898, current rewards: 163.87500, mean: 0.10853
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01897, current rewards: 169.29111, mean: 0.10852
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01895, current rewards: 174.82897, mean: 0.10859
[32m[0906 17-36-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 180.30223, mean: 0.10862
[32m[0906 17-36-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: 185.77995, mean: 0.10864
[32m[0906 17-36-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01893, current rewards: 191.25639, mean: 0.10867
[32m[0906 17-36-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01892, current rewards: 196.73001, mean: 0.10869
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01891, current rewards: 202.20943, mean: 0.10871
[32m[0906 17-36-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01890, current rewards: 207.76221, mean: 0.10878
[32m[0906 17-36-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01890, current rewards: 213.45304, mean: 0.10890
[32m[0906 17-36-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 219.14669, mean: 0.10903
[32m[0906 17-36-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 224.80491, mean: 0.10913
[32m[0906 17-36-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 230.47055, mean: 0.10923
[32m[0906 17-36-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: 236.13701, mean: 0.10932
[32m[0906 17-36-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 241.79745, mean: 0.10941
[32m[0906 17-36-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 247.47283, mean: 0.10950
[32m[0906 17-36-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 251.23856, mean: 0.10876
[32m[0906 17-36-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 257.00038, mean: 0.10890
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 262.76097, mean: 0.10903
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 268.44166, mean: 0.10912
[32m[0906 17-36-57 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-36-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-36-57 @MBExp.py:227][0m Rewards obtained: [273.0428962531435], Lows: [3], Highs: [0], Total time: 4580.431018000001
[32m[0906 17-40-17 @MBExp.py:144][0m ####################################################################
[32m[0906 17-40-17 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 17-40-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01881, current rewards: -1.11662, mean: -0.11166
[32m[0906 17-40-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 3.85519, mean: 0.06425
[32m[0906 17-40-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 8.91483, mean: 0.08104
[32m[0906 17-40-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 13.97038, mean: 0.08731
[32m[0906 17-40-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 18.99837, mean: 0.09047
[32m[0906 17-40-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 24.07606, mean: 0.09260
[32m[0906 17-40-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 29.15034, mean: 0.09403
[32m[0906 17-40-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 34.19909, mean: 0.09500
[32m[0906 17-40-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 39.81691, mean: 0.09711
[32m[0906 17-40-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 45.37031, mean: 0.09863
[32m[0906 17-40-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 50.92507, mean: 0.09985
[32m[0906 17-40-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 56.47599, mean: 0.10085
[32m[0906 17-40-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 62.02667, mean: 0.10168
[32m[0906 17-40-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 67.57741, mean: 0.10239
[32m[0906 17-40-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 73.12964, mean: 0.10300
[32m[0906 17-40-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 78.75546, mean: 0.10363
[32m[0906 17-40-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 84.40494, mean: 0.10420
[32m[0906 17-40-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 90.05922, mean: 0.10472
[32m[0906 17-40-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 95.71773, mean: 0.10518
[32m[0906 17-40-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 101.37312, mean: 0.10560
[32m[0906 17-40-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 107.03053, mean: 0.10597
[32m[0906 17-40-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 112.68649, mean: 0.10631
[32m[0906 17-40-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 118.34239, mean: 0.10661
[32m[0906 17-40-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 123.99884, mean: 0.10690
[32m[0906 17-40-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 129.69485, mean: 0.10719
[32m[0906 17-40-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 133.07445, mean: 0.10561
[32m[0906 17-40-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01903, current rewards: 138.69693, mean: 0.10588
[32m[0906 17-40-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 144.32417, mean: 0.10612
[32m[0906 17-40-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01900, current rewards: 149.94603, mean: 0.10634
[32m[0906 17-40-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01899, current rewards: 155.56981, mean: 0.10655
[32m[0906 17-40-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01898, current rewards: 161.18968, mean: 0.10675
[32m[0906 17-40-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01897, current rewards: 166.81437, mean: 0.10693
[32m[0906 17-40-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01895, current rewards: 172.44685, mean: 0.10711
[32m[0906 17-40-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01894, current rewards: 177.33126, mean: 0.10683
[32m[0906 17-40-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01893, current rewards: 182.03504, mean: 0.10645
[32m[0906 17-40-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01892, current rewards: 186.74277, mean: 0.10610
[32m[0906 17-40-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01891, current rewards: 191.45867, mean: 0.10578
[32m[0906 17-40-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01890, current rewards: 196.76166, mean: 0.10579
[32m[0906 17-40-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01889, current rewards: 202.36890, mean: 0.10595
[32m[0906 17-40-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01889, current rewards: 207.98509, mean: 0.10611
[32m[0906 17-40-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 213.51868, mean: 0.10623
[32m[0906 17-40-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01887, current rewards: 219.01202, mean: 0.10632
[32m[0906 17-40-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 224.54381, mean: 0.10642
[32m[0906 17-40-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 230.07294, mean: 0.10652
[32m[0906 17-40-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 235.59686, mean: 0.10660
[32m[0906 17-41-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: 241.12154, mean: 0.10669
[32m[0906 17-41-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 246.64607, mean: 0.10677
[32m[0906 17-41-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: 252.17897, mean: 0.10686
[32m[0906 17-41-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01883, current rewards: 257.70498, mean: 0.10693
[32m[0906 17-41-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: 263.36019, mean: 0.10706
[32m[0906 17-41-05 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-41-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-41-05 @MBExp.py:227][0m Rewards obtained: [267.84732728830517], Lows: [1], Highs: [2], Total time: 4628.306521000001
[32m[0906 17-44-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-44-27 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 17-44-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01914, current rewards: 0.18452, mean: 0.01845
[32m[0906 17-44-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01929, current rewards: 5.81304, mean: 0.09688
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01926, current rewards: 11.36711, mean: 0.10334
[32m[0906 17-44-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01924, current rewards: 16.92722, mean: 0.10580
[32m[0906 17-44-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01929, current rewards: 22.47618, mean: 0.10703
[32m[0906 17-44-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.02671, mean: 0.10780
[32m[0906 17-44-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 33.57056, mean: 0.10829
[32m[0906 17-44-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 39.12727, mean: 0.10869
[32m[0906 17-44-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 44.76880, mean: 0.10919
[32m[0906 17-44-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 50.31098, mean: 0.10937
[32m[0906 17-44-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 55.85082, mean: 0.10951
[32m[0906 17-44-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 61.39222, mean: 0.10963
[32m[0906 17-44-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 66.93363, mean: 0.10973
[32m[0906 17-44-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 72.47108, mean: 0.10980
[32m[0906 17-44-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 78.00875, mean: 0.10987
[32m[0906 17-44-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 80.21976, mean: 0.10555
[32m[0906 17-44-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 85.73702, mean: 0.10585
[32m[0906 17-44-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 91.29190, mean: 0.10615
[32m[0906 17-44-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 96.84441, mean: 0.10642
[32m[0906 17-44-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 102.39728, mean: 0.10666
[32m[0906 17-44-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 107.94724, mean: 0.10688
[32m[0906 17-44-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 113.50507, mean: 0.10708
[32m[0906 17-44-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 119.05768, mean: 0.10726
[32m[0906 17-44-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 124.61492, mean: 0.10743
[32m[0906 17-44-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 130.06067, mean: 0.10749
[32m[0906 17-44-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01908, current rewards: 135.46699, mean: 0.10751
[32m[0906 17-44-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: 140.87415, mean: 0.10754
[32m[0906 17-44-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01904, current rewards: 146.27784, mean: 0.10756
[32m[0906 17-44-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01902, current rewards: 151.68555, mean: 0.10758
[32m[0906 17-44-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01901, current rewards: 157.09242, mean: 0.10760
[32m[0906 17-44-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01900, current rewards: 162.50218, mean: 0.10762
[32m[0906 17-44-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01899, current rewards: 167.90584, mean: 0.10763
[32m[0906 17-44-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01898, current rewards: 173.31535, mean: 0.10765
[32m[0906 17-44-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01898, current rewards: 178.72242, mean: 0.10766
[32m[0906 17-45-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01896, current rewards: 184.12912, mean: 0.10768
[32m[0906 17-45-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01896, current rewards: 189.53406, mean: 0.10769
[32m[0906 17-45-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01895, current rewards: 194.94327, mean: 0.10770
[32m[0906 17-45-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01894, current rewards: 200.34913, mean: 0.10771
[32m[0906 17-45-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01893, current rewards: 205.87500, mean: 0.10779
[32m[0906 17-45-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01892, current rewards: 211.42763, mean: 0.10787
[32m[0906 17-45-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01891, current rewards: 216.96667, mean: 0.10794
[32m[0906 17-45-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01890, current rewards: 222.52480, mean: 0.10802
[32m[0906 17-45-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 228.08686, mean: 0.10810
[32m[0906 17-45-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 233.64595, mean: 0.10817
[32m[0906 17-45-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 239.20343, mean: 0.10824
[32m[0906 17-45-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 244.76475, mean: 0.10830
[32m[0906 17-45-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 250.32436, mean: 0.10837
[32m[0906 17-45-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 255.88494, mean: 0.10843
[32m[0906 17-45-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: 261.50529, mean: 0.10851
[32m[0906 17-45-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 267.06047, mean: 0.10856
[32m[0906 17-45-15 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-45-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-45-15 @MBExp.py:227][0m Rewards obtained: [271.5070078669145], Lows: [0], Highs: [4], Total time: 4676.224487000001
[32m[0906 17-48-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-48-39 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 17-48-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02378, current rewards: 0.15082, mean: 0.01508
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02535, current rewards: 6.09003, mean: 0.10150
[32m[0906 17-48-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02549, current rewards: 12.13117, mean: 0.11028
[32m[0906 17-48-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02601, current rewards: 18.01610, mean: 0.11260
[32m[0906 17-48-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02606, current rewards: 23.51959, mean: 0.11200
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02620, current rewards: 29.47113, mean: 0.11335
[32m[0906 17-48-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02629, current rewards: 35.06917, mean: 0.11313
[32m[0906 17-48-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02625, current rewards: 41.02109, mean: 0.11395
[32m[0906 17-48-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02632, current rewards: 46.88326, mean: 0.11435
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02645, current rewards: 52.41607, mean: 0.11395
[32m[0906 17-48-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02643, current rewards: 58.14683, mean: 0.11401
[32m[0906 17-48-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02643, current rewards: 64.02507, mean: 0.11433
[32m[0906 17-48-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02643, current rewards: 70.05420, mean: 0.11484
[32m[0906 17-48-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02644, current rewards: 77.59255, mean: 0.11756
[32m[0906 17-48-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02649, current rewards: 85.24899, mean: 0.12007
[32m[0906 17-48-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02659, current rewards: 92.06379, mean: 0.12114
[32m[0906 17-49-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02661, current rewards: 99.27135, mean: 0.12256
[32m[0906 17-49-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02654, current rewards: 106.62883, mean: 0.12399
[32m[0906 17-49-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02648, current rewards: 114.27023, mean: 0.12557
[32m[0906 17-49-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02649, current rewards: 121.27146, mean: 0.12632
[32m[0906 17-49-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02644, current rewards: 128.65396, mean: 0.12738
[32m[0906 17-49-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02641, current rewards: 136.30898, mean: 0.12859
[32m[0906 17-49-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02641, current rewards: 143.81845, mean: 0.12957
[32m[0906 17-49-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02641, current rewards: 150.77539, mean: 0.12998
[32m[0906 17-49-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02634, current rewards: 113.99287, mean: 0.09421
[32m[0906 17-49-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02624, current rewards: 66.12138, mean: 0.05248
[32m[0906 17-49-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02616, current rewards: 18.17061, mean: 0.01387
[32m[0906 17-49-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02609, current rewards: -29.74342, mean: -0.02187
[32m[0906 17-49-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02602, current rewards: -77.69057, mean: -0.05510
[32m[0906 17-49-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02597, current rewards: -125.63408, mean: -0.08605
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02590, current rewards: -173.52898, mean: -0.11492
[32m[0906 17-49-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02585, current rewards: -221.40344, mean: -0.14193
[32m[0906 17-49-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02579, current rewards: -269.25486, mean: -0.16724
[32m[0906 17-49-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02576, current rewards: -293.33250, mean: -0.17671
[32m[0906 17-49-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02575, current rewards: -287.18527, mean: -0.16794
[32m[0906 17-49-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02578, current rewards: -281.24955, mean: -0.15980
[32m[0906 17-49-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02580, current rewards: -274.62689, mean: -0.15173
[32m[0906 17-49-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02582, current rewards: -268.65821, mean: -0.14444
[32m[0906 17-49-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02584, current rewards: -262.48641, mean: -0.13743
[32m[0906 17-49-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02584, current rewards: -255.33818, mean: -0.13027
[32m[0906 17-49-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02585, current rewards: -249.52502, mean: -0.12414
[32m[0906 17-49-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02588, current rewards: -242.90019, mean: -0.11791
[32m[0906 17-49-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02589, current rewards: -236.67233, mean: -0.11217
[32m[0906 17-49-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02589, current rewards: -230.44415, mean: -0.10669
[32m[0906 17-49-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02591, current rewards: -224.38373, mean: -0.10153
[32m[0906 17-49-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02591, current rewards: -217.69302, mean: -0.09632
[32m[0906 17-49-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02592, current rewards: -211.74742, mean: -0.09167
[32m[0906 17-49-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02590, current rewards: -204.77942, mean: -0.08677
[32m[0906 17-49-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02575, current rewards: -199.39232, mean: -0.08274
[32m[0906 17-49-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02560, current rewards: -194.00926, mean: -0.07887
[32m[0906 17-49-43 @Agent.py:117][0m Average action selection time: 0.0255
[32m[0906 17-49-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-49-44 @MBExp.py:227][0m Rewards obtained: [-189.6952140197191], Lows: [234], Highs: [1], Total time: 4740.763240000001
[32m[0906 17-53-10 @MBExp.py:144][0m ####################################################################
[32m[0906 17-53-10 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 17-53-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01948, current rewards: 1.15715, mean: 0.11571
[32m[0906 17-53-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01925, current rewards: 6.50713, mean: 0.10845
[32m[0906 17-53-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 12.04778, mean: 0.10953
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01928, current rewards: 17.58812, mean: 0.10993
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01928, current rewards: 23.12950, mean: 0.11014
[32m[0906 17-53-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01931, current rewards: 28.67273, mean: 0.11028
[32m[0906 17-53-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.84915, mean: 0.11242
[32m[0906 17-53-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01906, current rewards: 41.30797, mean: 0.11474
[32m[0906 17-53-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01898, current rewards: 47.76680, mean: 0.11650
[32m[0906 17-53-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01895, current rewards: 54.22562, mean: 0.11788
[32m[0906 17-53-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01890, current rewards: 60.68445, mean: 0.11899
[32m[0906 17-53-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01888, current rewards: 67.14327, mean: 0.11990
[32m[0906 17-53-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01885, current rewards: 43.11433, mean: 0.07068
[32m[0906 17-53-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01882, current rewards: -6.88567, mean: -0.01043
[32m[0906 17-53-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01880, current rewards: -56.88567, mean: -0.08012
[32m[0906 17-53-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01878, current rewards: -106.88567, mean: -0.14064
[32m[0906 17-53-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01877, current rewards: -156.88567, mean: -0.19369
[32m[0906 17-53-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01877, current rewards: -206.88567, mean: -0.24056
[32m[0906 17-53-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01876, current rewards: -256.88567, mean: -0.28229
[32m[0906 17-53-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01876, current rewards: -306.88567, mean: -0.31967
[32m[0906 17-53-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01875, current rewards: -356.88567, mean: -0.35335
[32m[0906 17-53-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01875, current rewards: -406.88567, mean: -0.38385
[32m[0906 17-53-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01874, current rewards: -456.88567, mean: -0.41161
[32m[0906 17-53-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01874, current rewards: -506.88567, mean: -0.43697
[32m[0906 17-53-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01873, current rewards: -556.88567, mean: -0.46024
[32m[0906 17-53-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01873, current rewards: -606.88567, mean: -0.48166
[32m[0906 17-53-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01873, current rewards: -656.88567, mean: -0.50144
[32m[0906 17-53-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01872, current rewards: -706.88567, mean: -0.51977
[32m[0906 17-53-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: -756.88567, mean: -0.53680
[32m[0906 17-53-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: -806.88567, mean: -0.55266
[32m[0906 17-53-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01870, current rewards: -856.88567, mean: -0.56747
[32m[0906 17-53-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: -906.88567, mean: -0.58134
[32m[0906 17-53-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01869, current rewards: -956.88567, mean: -0.59434
[32m[0906 17-53-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01869, current rewards: -1006.88567, mean: -0.60656
[32m[0906 17-53-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01869, current rewards: -1056.88567, mean: -0.61806
[32m[0906 17-53-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01870, current rewards: -1106.88567, mean: -0.62891
[32m[0906 17-53-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01869, current rewards: -1156.88567, mean: -0.63916
[32m[0906 17-53-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01870, current rewards: -1206.88567, mean: -0.64886
[32m[0906 17-53-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01870, current rewards: -1256.88567, mean: -0.65806
[32m[0906 17-53-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01869, current rewards: -1306.88567, mean: -0.66678
[32m[0906 17-53-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01869, current rewards: -1356.88567, mean: -0.67507
[32m[0906 17-53-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01868, current rewards: -1406.88567, mean: -0.68295
[32m[0906 17-53-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01868, current rewards: -1456.88567, mean: -0.69047
[32m[0906 17-53-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01868, current rewards: -1506.88567, mean: -0.69763
[32m[0906 17-53-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01868, current rewards: -1556.88567, mean: -0.70447
[32m[0906 17-53-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01868, current rewards: -1606.88567, mean: -0.71101
[32m[0906 17-53-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01868, current rewards: -1656.88567, mean: -0.71727
[32m[0906 17-53-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01868, current rewards: -1706.88567, mean: -0.72326
[32m[0906 17-53-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01867, current rewards: -1756.88567, mean: -0.72900
[32m[0906 17-53-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01867, current rewards: -1806.88567, mean: -0.73451
[32m[0906 17-53-58 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 17-53-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-53-58 @MBExp.py:227][0m Rewards obtained: [-1846.885672812818], Lows: [0], Highs: [1917], Total time: 4788.2634560000015
[32m[0906 17-57-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-57-28 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 17-57-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01890, current rewards: 0.02980, mean: 0.00298
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01907, current rewards: 5.52700, mean: 0.09212
[32m[0906 17-57-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 10.99066, mean: 0.09992
[32m[0906 17-57-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01922, current rewards: 16.45654, mean: 0.10285
[32m[0906 17-57-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 21.91838, mean: 0.10437
[32m[0906 17-57-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 27.37406, mean: 0.10528
[32m[0906 17-57-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01922, current rewards: 32.75913, mean: 0.10567
[32m[0906 17-57-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 38.20585, mean: 0.10613
[32m[0906 17-57-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 43.70340, mean: 0.10659
[32m[0906 17-57-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 49.21026, mean: 0.10698
[32m[0906 17-57-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 54.71382, mean: 0.10728
[32m[0906 17-57-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 60.21561, mean: 0.10753
[32m[0906 17-57-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 65.71844, mean: 0.10774
[32m[0906 17-57-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: 71.22439, mean: 0.10792
[32m[0906 17-57-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 76.67314, mean: 0.10799
[32m[0906 17-57-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 82.16892, mean: 0.10812
[32m[0906 17-57-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 87.66429, mean: 0.10823
[32m[0906 17-57-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 93.16159, mean: 0.10833
[32m[0906 17-57-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 98.65016, mean: 0.10841
[32m[0906 17-57-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 104.08328, mean: 0.10842
[32m[0906 17-57-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01903, current rewards: 109.52219, mean: 0.10844
[32m[0906 17-57-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01902, current rewards: 114.94324, mean: 0.10844
[32m[0906 17-57-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01900, current rewards: 120.37464, mean: 0.10845
[32m[0906 17-57-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01898, current rewards: 125.80624, mean: 0.10845
[32m[0906 17-57-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01896, current rewards: 131.23967, mean: 0.10846
[32m[0906 17-57-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01895, current rewards: 136.66873, mean: 0.10847
[32m[0906 17-57-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01893, current rewards: 142.10229, mean: 0.10848
[32m[0906 17-57-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01892, current rewards: 147.53332, mean: 0.10848
[32m[0906 17-57-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01890, current rewards: 152.96258, mean: 0.10848
[32m[0906 17-57-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01888, current rewards: 158.39565, mean: 0.10849
[32m[0906 17-57-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01887, current rewards: 163.85223, mean: 0.10851
[32m[0906 17-57-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01888, current rewards: 169.34293, mean: 0.10855
[32m[0906 17-57-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01887, current rewards: 174.82008, mean: 0.10858
[32m[0906 17-57-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01886, current rewards: 180.29672, mean: 0.10861
[32m[0906 17-58-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01885, current rewards: 185.76957, mean: 0.10864
[32m[0906 17-58-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 191.25005, mean: 0.10866
[32m[0906 17-58-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 196.72656, mean: 0.10869
[32m[0906 17-58-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 202.23420, mean: 0.10873
[32m[0906 17-58-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: 207.83320, mean: 0.10881
[32m[0906 17-58-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 213.35579, mean: 0.10885
[32m[0906 17-58-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01883, current rewards: 218.87352, mean: 0.10889
[32m[0906 17-58-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 224.39946, mean: 0.10893
[32m[0906 17-58-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01882, current rewards: 229.92682, mean: 0.10897
[32m[0906 17-58-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 235.45841, mean: 0.10901
[32m[0906 17-58-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 240.98139, mean: 0.10904
[32m[0906 17-58-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 246.50754, mean: 0.10907
[32m[0906 17-58-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 252.04295, mean: 0.10911
[32m[0906 17-58-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 257.73977, mean: 0.10921
[32m[0906 17-58-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: 263.25632, mean: 0.10923
[32m[0906 17-58-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: 268.77323, mean: 0.10926
[32m[0906 17-58-15 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 17-58-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-58-15 @MBExp.py:227][0m Rewards obtained: [273.1838855623977], Lows: [0], Highs: [1], Total time: 4836.064992000001
[32m[0906 18-01-46 @MBExp.py:144][0m ####################################################################
[32m[0906 18-01-46 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-01-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01962, current rewards: 1.10110, mean: 0.11011
[32m[0906 18-01-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 6.62573, mean: 0.11043
[32m[0906 18-01-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 12.15084, mean: 0.11046
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.67655, mean: 0.11048
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.18049, mean: 0.11038
[32m[0906 18-01-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 28.68711, mean: 0.11034
[32m[0906 18-01-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 34.21296, mean: 0.11036
[32m[0906 18-01-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 36.37139, mean: 0.10103
[32m[0906 18-01-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 41.87501, mean: 0.10213
[32m[0906 18-01-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 47.37561, mean: 0.10299
[32m[0906 18-01-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 52.87311, mean: 0.10367
[32m[0906 18-01-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 58.37092, mean: 0.10423
[32m[0906 18-01-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 63.87000, mean: 0.10470
[32m[0906 18-01-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 69.34771, mean: 0.10507
[32m[0906 18-02-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 74.85301, mean: 0.10543
[32m[0906 18-02-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 80.35096, mean: 0.10572
[32m[0906 18-02-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01908, current rewards: 85.85029, mean: 0.10599
[32m[0906 18-02-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01906, current rewards: 91.32778, mean: 0.10620
[32m[0906 18-02-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01904, current rewards: 96.79461, mean: 0.10637
[32m[0906 18-02-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01901, current rewards: 102.26620, mean: 0.10653
[32m[0906 18-02-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01899, current rewards: 107.73829, mean: 0.10667
[32m[0906 18-02-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01899, current rewards: 113.17437, mean: 0.10677
[32m[0906 18-02-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01896, current rewards: 118.65018, mean: 0.10689
[32m[0906 18-02-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01895, current rewards: 124.12292, mean: 0.10700
[32m[0906 18-02-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01894, current rewards: 129.59905, mean: 0.10711
[32m[0906 18-02-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01893, current rewards: 135.07983, mean: 0.10721
[32m[0906 18-02-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01892, current rewards: 140.55822, mean: 0.10730
[32m[0906 18-02-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01891, current rewards: 146.03793, mean: 0.10738
[32m[0906 18-02-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01890, current rewards: 151.51948, mean: 0.10746
[32m[0906 18-02-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01890, current rewards: 157.11826, mean: 0.10762
[32m[0906 18-02-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01888, current rewards: 162.61778, mean: 0.10769
[32m[0906 18-02-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01887, current rewards: 168.11989, mean: 0.10777
[32m[0906 18-02-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01886, current rewards: 173.62229, mean: 0.10784
[32m[0906 18-02-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01885, current rewards: 179.07790, mean: 0.10788
[32m[0906 18-02-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01885, current rewards: 184.57705, mean: 0.10794
[32m[0906 18-02-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 190.07391, mean: 0.10800
[32m[0906 18-02-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01883, current rewards: 195.57034, mean: 0.10805
[32m[0906 18-02-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: 201.08793, mean: 0.10811
[32m[0906 18-02-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 206.56387, mean: 0.10815
[32m[0906 18-02-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 212.05907, mean: 0.10819
[32m[0906 18-02-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 217.55654, mean: 0.10824
[32m[0906 18-02-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: 223.05536, mean: 0.10828
[32m[0906 18-02-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: 228.55454, mean: 0.10832
[32m[0906 18-02-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 234.09942, mean: 0.10838
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01879, current rewards: 239.60171, mean: 0.10842
[32m[0906 18-02-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01879, current rewards: 245.08490, mean: 0.10844
[32m[0906 18-02-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01878, current rewards: 250.53703, mean: 0.10846
[32m[0906 18-02-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01878, current rewards: 256.03268, mean: 0.10849
[32m[0906 18-02-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01877, current rewards: 261.52735, mean: 0.10852
[32m[0906 18-02-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01877, current rewards: 267.01996, mean: 0.10854
[32m[0906 18-02-33 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-02-33 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-02-34 @MBExp.py:227][0m Rewards obtained: [271.41412147553984], Lows: [0], Highs: [3], Total time: 4883.805467000001
[32m[0906 18-06-06 @MBExp.py:144][0m ####################################################################
[32m[0906 18-06-06 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-06-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01883, current rewards: -0.97372, mean: -0.09737
[32m[0906 18-06-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01928, current rewards: 4.50219, mean: 0.07504
[32m[0906 18-06-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01934, current rewards: 10.01385, mean: 0.09103
[32m[0906 18-06-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01934, current rewards: 15.53328, mean: 0.09708
[32m[0906 18-06-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01930, current rewards: 21.04775, mean: 0.10023
[32m[0906 18-06-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 26.55619, mean: 0.10214
[32m[0906 18-06-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01928, current rewards: 32.07531, mean: 0.10347
[32m[0906 18-06-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 37.59488, mean: 0.10443
[32m[0906 18-06-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 43.10519, mean: 0.10513
[32m[0906 18-06-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01929, current rewards: 48.60473, mean: 0.10566
[32m[0906 18-06-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01927, current rewards: 54.10841, mean: 0.10609
[32m[0906 18-06-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01927, current rewards: 59.61793, mean: 0.10646
[32m[0906 18-06-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 65.09830, mean: 0.10672
[32m[0906 18-06-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: 70.60695, mean: 0.10698
[32m[0906 18-06-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: 76.11716, mean: 0.10721
[32m[0906 18-06-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 81.62495, mean: 0.10740
[32m[0906 18-06-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 87.13378, mean: 0.10757
[32m[0906 18-06-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 92.64226, mean: 0.10772
[32m[0906 18-06-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 98.14913, mean: 0.10786
[32m[0906 18-06-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 103.65298, mean: 0.10797
[32m[0906 18-06-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01904, current rewards: 109.23026, mean: 0.10815
[32m[0906 18-06-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01902, current rewards: 116.48471, mean: 0.10989
[32m[0906 18-06-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01900, current rewards: 125.81816, mean: 0.11335
[32m[0906 18-06-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01898, current rewards: 135.15161, mean: 0.11651
[32m[0906 18-06-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01897, current rewards: 144.48505, mean: 0.11941
[32m[0906 18-06-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01895, current rewards: 153.81850, mean: 0.12208
[32m[0906 18-06-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01895, current rewards: 115.68519, mean: 0.08831
[32m[0906 18-06-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01894, current rewards: 65.68519, mean: 0.04830
[32m[0906 18-06-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01893, current rewards: 15.68519, mean: 0.01112
[32m[0906 18-06-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01892, current rewards: -10.97795, mean: -0.00752
[32m[0906 18-06-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01890, current rewards: -5.46435, mean: -0.00362
[32m[0906 18-06-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01889, current rewards: 0.04758, mean: 0.00003
[32m[0906 18-06-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01887, current rewards: 5.55754, mean: 0.00345
[32m[0906 18-06-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01885, current rewards: 11.06560, mean: 0.00667
[32m[0906 18-06-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01885, current rewards: 16.58063, mean: 0.00970
[32m[0906 18-06-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 22.09135, mean: 0.01255
[32m[0906 18-06-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01883, current rewards: 27.61808, mean: 0.01526
[32m[0906 18-06-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 33.14632, mean: 0.01782
[32m[0906 18-06-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 38.67505, mean: 0.02025
[32m[0906 18-06-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: 44.19918, mean: 0.02255
[32m[0906 18-06-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 49.71371, mean: 0.02473
[32m[0906 18-06-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: 55.23450, mean: 0.02681
[32m[0906 18-06-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 60.75804, mean: 0.02880
[32m[0906 18-06-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 66.28689, mean: 0.03069
[32m[0906 18-06-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01880, current rewards: 71.81516, mean: 0.03250
[32m[0906 18-06-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01880, current rewards: 77.32414, mean: 0.03421
[32m[0906 18-06-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01880, current rewards: 82.84437, mean: 0.03586
[32m[0906 18-06-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 88.36536, mean: 0.03744
[32m[0906 18-06-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: 93.89130, mean: 0.03896
[32m[0906 18-06-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01879, current rewards: 99.41601, mean: 0.04041
[32m[0906 18-06-54 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-06-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-06-54 @MBExp.py:227][0m Rewards obtained: [103.83391289782811], Lows: [1], Highs: [169], Total time: 4931.601544000001
[32m[0906 18-10-28 @MBExp.py:144][0m ####################################################################
[32m[0906 18-10-28 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 18-10-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01923, current rewards: -0.07808, mean: -0.00781
[32m[0906 18-10-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01912, current rewards: 5.42848, mean: 0.09047
[32m[0906 18-10-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 10.95022, mean: 0.09955
[32m[0906 18-10-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 16.46683, mean: 0.10292
[32m[0906 18-10-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 21.97473, mean: 0.10464
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 27.49040, mean: 0.10573
[32m[0906 18-10-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 33.00763, mean: 0.10648
[32m[0906 18-10-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 38.52299, mean: 0.10701
[32m[0906 18-10-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 44.04147, mean: 0.10742
[32m[0906 18-10-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 49.54938, mean: 0.10772
[32m[0906 18-10-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 55.06817, mean: 0.10798
[32m[0906 18-10-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 60.58353, mean: 0.10818
[32m[0906 18-10-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 66.10059, mean: 0.10836
[32m[0906 18-10-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 71.61858, mean: 0.10851
[32m[0906 18-10-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 77.13763, mean: 0.10864
[32m[0906 18-10-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 82.65753, mean: 0.10876
[32m[0906 18-10-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 88.17678, mean: 0.10886
[32m[0906 18-10-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 93.69924, mean: 0.10895
[32m[0906 18-10-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: 99.21647, mean: 0.10903
[32m[0906 18-10-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01906, current rewards: 104.69973, mean: 0.10906
[32m[0906 18-10-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01904, current rewards: 110.25559, mean: 0.10916
[32m[0906 18-10-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01903, current rewards: 115.78517, mean: 0.10923
[32m[0906 18-10-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01901, current rewards: 121.31707, mean: 0.10929
[32m[0906 18-10-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01899, current rewards: 126.85060, mean: 0.10935
[32m[0906 18-10-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01898, current rewards: 132.38406, mean: 0.10941
[32m[0906 18-10-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01896, current rewards: 137.91709, mean: 0.10946
[32m[0906 18-10-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01895, current rewards: 143.45128, mean: 0.10950
[32m[0906 18-10-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01894, current rewards: 148.98641, mean: 0.10955
[32m[0906 18-10-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01893, current rewards: 154.48546, mean: 0.10956
[32m[0906 18-10-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01892, current rewards: 160.01628, mean: 0.10960
[32m[0906 18-10-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01891, current rewards: 165.54763, mean: 0.10963
[32m[0906 18-10-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01890, current rewards: 171.07727, mean: 0.10966
[32m[0906 18-10-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01888, current rewards: 176.60601, mean: 0.10969
[32m[0906 18-11-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01887, current rewards: 182.13042, mean: 0.10972
[32m[0906 18-11-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01886, current rewards: 187.67860, mean: 0.10975
[32m[0906 18-11-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01885, current rewards: 193.22121, mean: 0.10978
[32m[0906 18-11-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 198.80175, mean: 0.10984
[32m[0906 18-11-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 204.33784, mean: 0.10986
[32m[0906 18-11-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 209.86976, mean: 0.10988
[32m[0906 18-11-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 215.40338, mean: 0.10990
[32m[0906 18-11-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01883, current rewards: 220.94154, mean: 0.10992
[32m[0906 18-11-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 226.48344, mean: 0.10994
[32m[0906 18-11-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 232.01644, mean: 0.10996
[32m[0906 18-11-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: 237.52958, mean: 0.10997
[32m[0906 18-11-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01882, current rewards: 243.14049, mean: 0.11002
[32m[0906 18-11-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 248.71628, mean: 0.11005
[32m[0906 18-11-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 254.29308, mean: 0.11008
[32m[0906 18-11-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 259.86799, mean: 0.11011
[32m[0906 18-11-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: 265.44474, mean: 0.11014
[32m[0906 18-11-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: 271.02069, mean: 0.11017
[32m[0906 18-11-16 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-11-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-11-16 @MBExp.py:227][0m Rewards obtained: [275.48167471673133], Lows: [0], Highs: [1], Total time: 4979.409639000001
[32m[0906 18-14-52 @MBExp.py:144][0m ####################################################################
[32m[0906 18-14-52 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 18-14-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02534, current rewards: 0.99834, mean: 0.09983
[32m[0906 18-14-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02517, current rewards: 6.30131, mean: 0.10502
[32m[0906 18-14-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02516, current rewards: 11.57493, mean: 0.10523
[32m[0906 18-14-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02416, current rewards: 16.89840, mean: 0.10561
[32m[0906 18-14-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02361, current rewards: 22.12524, mean: 0.10536
[32m[0906 18-14-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02322, current rewards: 27.34170, mean: 0.10516
[32m[0906 18-15-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02298, current rewards: 32.57510, mean: 0.10508
[32m[0906 18-15-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02275, current rewards: 37.80255, mean: 0.10501
[32m[0906 18-15-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02291, current rewards: 41.94946, mean: 0.10232
[32m[0906 18-15-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02315, current rewards: 47.17698, mean: 0.10256
[32m[0906 18-15-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02341, current rewards: 52.44798, mean: 0.10284
[32m[0906 18-15-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02353, current rewards: 55.64015, mean: 0.09936
[32m[0906 18-15-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02382, current rewards: 58.87866, mean: 0.09652
[32m[0906 18-15-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02404, current rewards: 64.05126, mean: 0.09705
[32m[0906 18-15-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02423, current rewards: 65.43896, mean: 0.09217
[32m[0906 18-15-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02416, current rewards: 70.68272, mean: 0.09300
[32m[0906 18-15-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02409, current rewards: 75.95875, mean: 0.09378
[32m[0906 18-15-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02400, current rewards: 81.20794, mean: 0.09443
[32m[0906 18-15-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02389, current rewards: 86.45132, mean: 0.09500
[32m[0906 18-15-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02385, current rewards: 91.67968, mean: 0.09550
[32m[0906 18-15-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02369, current rewards: 97.34822, mean: 0.09638
[32m[0906 18-15-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02354, current rewards: 103.04303, mean: 0.09721
[32m[0906 18-15-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02339, current rewards: 108.79363, mean: 0.09801
[32m[0906 18-15-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02328, current rewards: 114.50855, mean: 0.09871
[32m[0906 18-15-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02316, current rewards: 120.22517, mean: 0.09936
[32m[0906 18-15-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02307, current rewards: 125.94721, mean: 0.09996
[32m[0906 18-15-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02308, current rewards: 129.33415, mean: 0.09873
[32m[0906 18-15-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02304, current rewards: 134.81102, mean: 0.09913
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02300, current rewards: 140.32252, mean: 0.09952
[32m[0906 18-15-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02294, current rewards: 145.83424, mean: 0.09989
[32m[0906 18-15-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02287, current rewards: 151.35360, mean: 0.10023
[32m[0906 18-15-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02279, current rewards: 156.84934, mean: 0.10054
[32m[0906 18-15-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02273, current rewards: 162.36395, mean: 0.10085
[32m[0906 18-15-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02265, current rewards: 167.86064, mean: 0.10112
[32m[0906 18-15-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02259, current rewards: 173.37561, mean: 0.10139
[32m[0906 18-15-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02254, current rewards: 178.89027, mean: 0.10164
[32m[0906 18-15-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02244, current rewards: 184.42000, mean: 0.10189
[32m[0906 18-15-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02233, current rewards: 189.92878, mean: 0.10211
[32m[0906 18-15-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02224, current rewards: 195.44309, mean: 0.10233
[32m[0906 18-15-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02217, current rewards: 199.81140, mean: 0.10194
[32m[0906 18-15-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02213, current rewards: 205.16186, mean: 0.10207
[32m[0906 18-15-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02209, current rewards: 210.52559, mean: 0.10220
[32m[0906 18-15-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02205, current rewards: 215.83487, mean: 0.10229
[32m[0906 18-15-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02201, current rewards: 221.18433, mean: 0.10240
[32m[0906 18-15-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02200, current rewards: 226.49129, mean: 0.10248
[32m[0906 18-15-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02197, current rewards: 231.84812, mean: 0.10259
[32m[0906 18-15-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02195, current rewards: 237.21110, mean: 0.10269
[32m[0906 18-15-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02192, current rewards: 242.56821, mean: 0.10278
[32m[0906 18-15-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02186, current rewards: 241.69596, mean: 0.10029
[32m[0906 18-15-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02180, current rewards: 247.20584, mean: 0.10049
[32m[0906 18-15-47 @Agent.py:117][0m Average action selection time: 0.0218
[32m[0906 18-15-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-15-48 @MBExp.py:227][0m Rewards obtained: [251.61357265822775], Lows: [8], Highs: [2], Total time: 5034.640783000002
[32m[0906 18-19-27 @MBExp.py:144][0m ####################################################################
[32m[0906 18-19-27 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 18-19-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: 1.07341, mean: 0.10734
[32m[0906 18-19-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.58030, mean: 0.10967
[32m[0906 18-19-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 12.14648, mean: 0.11042
[32m[0906 18-19-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.70697, mean: 0.11067
[32m[0906 18-19-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01923, current rewards: 23.27379, mean: 0.11083
[32m[0906 18-19-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01931, current rewards: 28.84123, mean: 0.11093
[32m[0906 18-19-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01931, current rewards: 34.40854, mean: 0.11100
[32m[0906 18-19-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 39.97905, mean: 0.11105
[32m[0906 18-19-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.54978, mean: 0.11110
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01928, current rewards: 51.11464, mean: 0.11112
[32m[0906 18-19-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01927, current rewards: 56.68186, mean: 0.11114
[32m[0906 18-19-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 62.32124, mean: 0.11129
[32m[0906 18-19-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 67.88207, mean: 0.11128
[32m[0906 18-19-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 72.33232, mean: 0.10959
[32m[0906 18-19-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01925, current rewards: 77.85834, mean: 0.10966
[32m[0906 18-19-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 83.39212, mean: 0.10973
[32m[0906 18-19-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 88.91963, mean: 0.10978
[32m[0906 18-19-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 94.44857, mean: 0.10982
[32m[0906 18-19-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: 99.98563, mean: 0.10987
[32m[0906 18-19-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01906, current rewards: 105.55153, mean: 0.10995
[32m[0906 18-19-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01903, current rewards: 111.08921, mean: 0.10999
[32m[0906 18-19-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01901, current rewards: 116.62711, mean: 0.11003
[32m[0906 18-19-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01900, current rewards: 122.16274, mean: 0.11006
[32m[0906 18-19-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01897, current rewards: 127.70283, mean: 0.11009
[32m[0906 18-19-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01896, current rewards: 133.23888, mean: 0.11011
[32m[0906 18-19-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01895, current rewards: 138.83391, mean: 0.11019
[32m[0906 18-19-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01893, current rewards: 144.37904, mean: 0.11021
[32m[0906 18-19-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01891, current rewards: 149.84096, mean: 0.11018
[32m[0906 18-19-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01889, current rewards: 155.39468, mean: 0.11021
[32m[0906 18-19-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01888, current rewards: 160.94035, mean: 0.11023
[32m[0906 18-19-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01887, current rewards: 166.48614, mean: 0.11026
[32m[0906 18-19-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01886, current rewards: 172.03825, mean: 0.11028
[32m[0906 18-19-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01886, current rewards: 177.59027, mean: 0.11030
[32m[0906 18-19-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01886, current rewards: 183.13925, mean: 0.11032
[32m[0906 18-19-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01885, current rewards: 188.69731, mean: 0.11035
[32m[0906 18-20-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 194.32047, mean: 0.11041
[32m[0906 18-20-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 199.90792, mean: 0.11045
[32m[0906 18-20-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 205.45917, mean: 0.11046
[32m[0906 18-20-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: 211.10715, mean: 0.11053
[32m[0906 18-20-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: 216.57576, mean: 0.11050
[32m[0906 18-20-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 222.03685, mean: 0.11047
[32m[0906 18-20-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: 227.50846, mean: 0.11044
[32m[0906 18-20-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 232.97713, mean: 0.11042
[32m[0906 18-20-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 238.44219, mean: 0.11039
[32m[0906 18-20-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01880, current rewards: 243.88468, mean: 0.11036
[32m[0906 18-20-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01880, current rewards: 249.35025, mean: 0.11033
[32m[0906 18-20-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: 254.81999, mean: 0.11031
[32m[0906 18-20-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01879, current rewards: 260.29068, mean: 0.11029
[32m[0906 18-20-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01879, current rewards: 265.75661, mean: 0.11027
[32m[0906 18-20-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01879, current rewards: 271.22519, mean: 0.11025
[32m[0906 18-20-14 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-20-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-20-14 @MBExp.py:227][0m Rewards obtained: [275.63963184557974], Lows: [0], Highs: [1], Total time: 5082.432663000001
[32m[0906 18-23-55 @MBExp.py:144][0m ####################################################################
[32m[0906 18-23-55 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 18-23-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01988, current rewards: 1.04655, mean: 0.10465
[32m[0906 18-23-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02070, current rewards: 6.09895, mean: 0.10165
[32m[0906 18-23-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02138, current rewards: 11.06913, mean: 0.10063
[32m[0906 18-23-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02183, current rewards: 16.20248, mean: 0.10127
[32m[0906 18-24-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02230, current rewards: 21.48937, mean: 0.10233
[32m[0906 18-24-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02258, current rewards: 26.75648, mean: 0.10291
[32m[0906 18-24-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02277, current rewards: 32.02887, mean: 0.10332
[32m[0906 18-24-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02294, current rewards: 37.36884, mean: 0.10380
[32m[0906 18-24-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02314, current rewards: 42.72728, mean: 0.10421
[32m[0906 18-24-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02367, current rewards: 43.82441, mean: 0.09527
[32m[0906 18-24-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02397, current rewards: 24.73079, mean: 0.04849
[32m[0906 18-24-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02440, current rewards: 19.89899, mean: 0.03553
[32m[0906 18-24-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02461, current rewards: 13.10677, mean: 0.02149
[32m[0906 18-24-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02483, current rewards: 5.70885, mean: 0.00865
[32m[0906 18-24-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02502, current rewards: 4.07218, mean: 0.00574
[32m[0906 18-24-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02520, current rewards: -5.77183, mean: -0.00759
[32m[0906 18-24-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02539, current rewards: -2.38979, mean: -0.00295
[32m[0906 18-24-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02552, current rewards: -3.36711, mean: -0.00392
[32m[0906 18-24-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02516, current rewards: 2.10209, mean: 0.00231
[32m[0906 18-24-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02482, current rewards: 7.43174, mean: 0.00774
[32m[0906 18-24-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02451, current rewards: 12.87057, mean: 0.01274
[32m[0906 18-24-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02423, current rewards: 18.31569, mean: 0.01728
[32m[0906 18-24-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02397, current rewards: 23.76785, mean: 0.02141
[32m[0906 18-24-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02374, current rewards: 29.21829, mean: 0.02519
[32m[0906 18-24-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02353, current rewards: 34.67877, mean: 0.02866
[32m[0906 18-24-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02333, current rewards: 40.02306, mean: 0.03176
[32m[0906 18-24-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02316, current rewards: 45.37610, mean: 0.03464
[32m[0906 18-24-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02300, current rewards: 50.74163, mean: 0.03731
[32m[0906 18-24-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02284, current rewards: 56.11073, mean: 0.03979
[32m[0906 18-24-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02269, current rewards: 61.47561, mean: 0.04211
[32m[0906 18-24-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02256, current rewards: 66.84163, mean: 0.04427
[32m[0906 18-24-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02244, current rewards: 72.20834, mean: 0.04629
[32m[0906 18-24-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02233, current rewards: 77.56410, mean: 0.04818
[32m[0906 18-24-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02222, current rewards: 82.92571, mean: 0.04996
[32m[0906 18-24-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02212, current rewards: 88.27718, mean: 0.05162
[32m[0906 18-24-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02202, current rewards: 93.68108, mean: 0.05323
[32m[0906 18-24-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02193, current rewards: 99.20182, mean: 0.05481
[32m[0906 18-24-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02184, current rewards: 104.67596, mean: 0.05628
[32m[0906 18-24-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02177, current rewards: 110.15333, mean: 0.05767
[32m[0906 18-24-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02187, current rewards: 121.21431, mean: 0.06184
[32m[0906 18-24-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02198, current rewards: 131.53415, mean: 0.06544
[32m[0906 18-24-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02205, current rewards: 144.43775, mean: 0.07012
[32m[0906 18-24-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02198, current rewards: 149.98545, mean: 0.07108
[32m[0906 18-24-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02191, current rewards: 155.52879, mean: 0.07200
[32m[0906 18-24-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02183, current rewards: 161.12264, mean: 0.07291
[32m[0906 18-24-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02176, current rewards: 166.67344, mean: 0.07375
[32m[0906 18-24-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02168, current rewards: 172.23044, mean: 0.07456
[32m[0906 18-24-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02162, current rewards: 175.97704, mean: 0.07457
[32m[0906 18-24-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02156, current rewards: 133.83495, mean: 0.05553
[32m[0906 18-24-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02150, current rewards: 91.72234, mean: 0.03729
[32m[0906 18-24-49 @Agent.py:117][0m Average action selection time: 0.0215
[32m[0906 18-24-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-24-49 @MBExp.py:227][0m Rewards obtained: [58.01591521469153], Lows: [161], Highs: [0], Total time: 5136.903374000001
[32m[0906 18-28-33 @MBExp.py:144][0m ####################################################################
[32m[0906 18-28-33 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 18-28-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01908, current rewards: 1.05378, mean: 0.10538
[32m[0906 18-28-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 6.60584, mean: 0.11010
[32m[0906 18-28-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 12.21770, mean: 0.11107
[32m[0906 18-28-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.77082, mean: 0.11107
[32m[0906 18-28-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 23.32463, mean: 0.11107
[32m[0906 18-28-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 28.87690, mean: 0.11107
[32m[0906 18-28-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.42863, mean: 0.11106
[32m[0906 18-28-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 39.98201, mean: 0.11106
[32m[0906 18-28-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 45.53373, mean: 0.11106
[32m[0906 18-28-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.09266, mean: 0.11107
[32m[0906 18-28-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 56.70331, mean: 0.11118
[32m[0906 18-28-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 62.26289, mean: 0.11118
[32m[0906 18-28-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01901, current rewards: 67.82167, mean: 0.11118
[32m[0906 18-28-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01898, current rewards: 73.37980, mean: 0.11118
[32m[0906 18-28-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01897, current rewards: 78.94018, mean: 0.11118
[32m[0906 18-28-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01893, current rewards: 84.49628, mean: 0.11118
[32m[0906 18-28-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01890, current rewards: 90.05320, mean: 0.11118
[32m[0906 18-28-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01888, current rewards: 95.56960, mean: 0.11113
[32m[0906 18-28-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01887, current rewards: 101.12953, mean: 0.11113
[32m[0906 18-28-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01884, current rewards: 106.67193, mean: 0.11112
[32m[0906 18-28-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01883, current rewards: 110.11679, mean: 0.10903
[32m[0906 18-28-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01883, current rewards: 115.68466, mean: 0.10914
[32m[0906 18-28-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01881, current rewards: 121.25117, mean: 0.10924
[32m[0906 18-28-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01881, current rewards: 126.81981, mean: 0.10933
[32m[0906 18-28-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01880, current rewards: 132.38621, mean: 0.10941
[32m[0906 18-28-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01880, current rewards: 137.92057, mean: 0.10946
[32m[0906 18-28-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01879, current rewards: 143.45940, mean: 0.10951
[32m[0906 18-28-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01879, current rewards: 148.93876, mean: 0.10951
[32m[0906 18-28-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01878, current rewards: 154.48801, mean: 0.10957
[32m[0906 18-29-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01877, current rewards: 160.03500, mean: 0.10961
[32m[0906 18-29-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01878, current rewards: 165.58513, mean: 0.10966
[32m[0906 18-29-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01877, current rewards: 171.13214, mean: 0.10970
[32m[0906 18-29-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01877, current rewards: 176.68173, mean: 0.10974
[32m[0906 18-29-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01877, current rewards: 182.22848, mean: 0.10978
[32m[0906 18-29-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: 187.77546, mean: 0.10981
[32m[0906 18-29-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01876, current rewards: 193.40272, mean: 0.10989
[32m[0906 18-29-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 196.89488, mean: 0.10878
[32m[0906 18-29-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01876, current rewards: 203.07256, mean: 0.10918
[32m[0906 18-29-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: 209.25024, mean: 0.10956
[32m[0906 18-29-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01876, current rewards: 215.42793, mean: 0.10991
[32m[0906 18-29-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01875, current rewards: 221.60561, mean: 0.11025
[32m[0906 18-29-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01875, current rewards: 227.78329, mean: 0.11057
[32m[0906 18-29-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01875, current rewards: 233.96097, mean: 0.11088
[32m[0906 18-29-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01875, current rewards: 239.25454, mean: 0.11077
[32m[0906 18-29-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01875, current rewards: 242.59056, mean: 0.10977
[32m[0906 18-29-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01875, current rewards: 245.92659, mean: 0.10882
[32m[0906 18-29-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01875, current rewards: 230.06164, mean: 0.09959
[32m[0906 18-29-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01874, current rewards: 180.06164, mean: 0.07630
[32m[0906 18-29-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01874, current rewards: 130.06164, mean: 0.05397
[32m[0906 18-29-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01874, current rewards: 80.06164, mean: 0.03255
[32m[0906 18-29-20 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-29-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-29-20 @MBExp.py:227][0m Rewards obtained: [40.061639824407024], Lows: [2], Highs: [208], Total time: 5184.5856760000015
[32m[0906 18-33-06 @MBExp.py:144][0m ####################################################################
[32m[0906 18-33-06 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 18-33-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01876, current rewards: 1.05280, mean: 0.10528
[32m[0906 18-33-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 6.58567, mean: 0.10976
[32m[0906 18-33-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 12.11889, mean: 0.11017
[32m[0906 18-33-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01933, current rewards: 17.64868, mean: 0.11030
[32m[0906 18-33-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01935, current rewards: 23.18416, mean: 0.11040
[32m[0906 18-33-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01933, current rewards: 28.69596, mean: 0.11037
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01930, current rewards: 34.24963, mean: 0.11048
[32m[0906 18-33-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01930, current rewards: 39.79779, mean: 0.11055
[32m[0906 18-33-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01930, current rewards: 45.34986, mean: 0.11061
[32m[0906 18-33-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01932, current rewards: 50.91899, mean: 0.11069
[32m[0906 18-33-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 56.52499, mean: 0.11083
[32m[0906 18-33-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 62.08600, mean: 0.11087
[32m[0906 18-33-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.64394, mean: 0.11089
[32m[0906 18-33-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 73.20139, mean: 0.11091
[32m[0906 18-33-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 77.10063, mean: 0.10859
[32m[0906 18-33-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 83.41606, mean: 0.10976
[32m[0906 18-33-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01905, current rewards: 89.73148, mean: 0.11078
[32m[0906 18-33-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01900, current rewards: 96.04691, mean: 0.11168
[32m[0906 18-33-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01899, current rewards: 101.37889, mean: 0.11141
[32m[0906 18-33-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01896, current rewards: 106.85578, mean: 0.11131
[32m[0906 18-33-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01895, current rewards: 112.42043, mean: 0.11131
[32m[0906 18-33-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01893, current rewards: 117.98136, mean: 0.11130
[32m[0906 18-33-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01893, current rewards: 123.54488, mean: 0.11130
[32m[0906 18-33-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01890, current rewards: 129.10922, mean: 0.11130
[32m[0906 18-33-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01889, current rewards: 134.67182, mean: 0.11130
[32m[0906 18-33-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01888, current rewards: 140.23288, mean: 0.11130
[32m[0906 18-33-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01886, current rewards: 145.83253, mean: 0.11132
[32m[0906 18-33-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01885, current rewards: 151.39728, mean: 0.11132
[32m[0906 18-33-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01884, current rewards: 156.95772, mean: 0.11132
[32m[0906 18-33-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01883, current rewards: 161.36042, mean: 0.11052
[32m[0906 18-33-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01883, current rewards: 166.92298, mean: 0.11055
[32m[0906 18-33-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01882, current rewards: 172.48753, mean: 0.11057
[32m[0906 18-33-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01882, current rewards: 178.05853, mean: 0.11060
[32m[0906 18-33-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01882, current rewards: 183.62297, mean: 0.11062
[32m[0906 18-33-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01881, current rewards: 189.19810, mean: 0.11064
[32m[0906 18-33-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: 194.76213, mean: 0.11066
[32m[0906 18-33-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 200.32207, mean: 0.11068
[32m[0906 18-33-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: 205.88772, mean: 0.11069
[32m[0906 18-33-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 211.45166, mean: 0.11071
[32m[0906 18-33-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: 217.00838, mean: 0.11072
[32m[0906 18-33-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01880, current rewards: 222.55202, mean: 0.11072
[32m[0906 18-33-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01879, current rewards: 228.09343, mean: 0.11072
[32m[0906 18-33-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01879, current rewards: 233.55475, mean: 0.11069
[32m[0906 18-33-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01879, current rewards: 239.09468, mean: 0.11069
[32m[0906 18-33-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01878, current rewards: 244.63741, mean: 0.11070
[32m[0906 18-33-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01878, current rewards: 250.18093, mean: 0.11070
[32m[0906 18-33-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01877, current rewards: 255.72173, mean: 0.11070
[32m[0906 18-33-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01877, current rewards: 261.26193, mean: 0.11070
[32m[0906 18-33-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01877, current rewards: 265.68562, mean: 0.11024
[32m[0906 18-33-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01877, current rewards: 271.21826, mean: 0.11025
[32m[0906 18-33-54 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-33-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-33-54 @MBExp.py:227][0m Rewards obtained: [275.6476635413801], Lows: [1], Highs: [2], Total time: 5232.334457000002
[32m[0906 18-37-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-37-42 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 18-37-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01901, current rewards: -20.00000, mean: -2.00000
[32m[0906 18-37-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: -120.00000, mean: -2.00000
[32m[0906 18-37-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: -220.00000, mean: -2.00000
[32m[0906 18-37-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: -320.00000, mean: -2.00000
[32m[0906 18-37-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: -420.00000, mean: -2.00000
[32m[0906 18-37-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: -520.00000, mean: -2.00000
[32m[0906 18-37-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: -620.00000, mean: -2.00000
[32m[0906 18-37-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: -720.00000, mean: -2.00000
[32m[0906 18-37-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: -820.00000, mean: -2.00000
[32m[0906 18-37-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: -920.00000, mean: -2.00000
[32m[0906 18-37-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: -1020.00000, mean: -2.00000
[32m[0906 18-37-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: -1120.00000, mean: -2.00000
[32m[0906 18-37-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01905, current rewards: -1220.00000, mean: -2.00000
[32m[0906 18-37-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01902, current rewards: -1320.00000, mean: -2.00000
[32m[0906 18-37-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01899, current rewards: -1420.00000, mean: -2.00000
[32m[0906 18-37-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01896, current rewards: -1520.00000, mean: -2.00000
[32m[0906 18-37-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01894, current rewards: -1620.00000, mean: -2.00000
[32m[0906 18-37-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01892, current rewards: -1720.00000, mean: -2.00000
[32m[0906 18-37-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01891, current rewards: -1820.00000, mean: -2.00000
[32m[0906 18-38-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01889, current rewards: -1915.50971, mean: -1.99532
[32m[0906 18-38-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01887, current rewards: -1909.71903, mean: -1.89081
[32m[0906 18-38-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01886, current rewards: -1903.96772, mean: -1.79620
[32m[0906 18-38-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01884, current rewards: -1898.21021, mean: -1.71010
[32m[0906 18-38-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01884, current rewards: -1892.45583, mean: -1.63143
[32m[0906 18-38-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01881, current rewards: -1887.08470, mean: -1.55957
[32m[0906 18-38-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01881, current rewards: -1881.60297, mean: -1.49334
[32m[0906 18-38-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01881, current rewards: -1876.13694, mean: -1.43217
[32m[0906 18-38-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01880, current rewards: -1870.59538, mean: -1.37544
[32m[0906 18-38-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01880, current rewards: -1865.06030, mean: -1.32274
[32m[0906 18-38-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01879, current rewards: -1859.51740, mean: -1.27364
[32m[0906 18-38-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01878, current rewards: -1853.97497, mean: -1.22780
[32m[0906 18-38-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01878, current rewards: -1848.43916, mean: -1.18490
[32m[0906 18-38-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: -1842.89642, mean: -1.14466
[32m[0906 18-38-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01878, current rewards: -1837.35632, mean: -1.10684
[32m[0906 18-38-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: -1861.50001, mean: -1.08860
[32m[0906 18-38-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: -1961.50001, mean: -1.11449
[32m[0906 18-38-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: -2061.50001, mean: -1.13895
[32m[0906 18-38-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: -2161.50001, mean: -1.16210
[32m[0906 18-38-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: -2261.50001, mean: -1.18403
[32m[0906 18-38-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01876, current rewards: -2361.50001, mean: -1.20485
[32m[0906 18-38-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01877, current rewards: -2461.50001, mean: -1.22463
[32m[0906 18-38-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01877, current rewards: -2561.50001, mean: -1.24345
[32m[0906 18-38-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01877, current rewards: -2661.50001, mean: -1.26137
[32m[0906 18-38-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01877, current rewards: -2761.50001, mean: -1.27847
[32m[0906 18-38-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01877, current rewards: -2861.50001, mean: -1.29480
[32m[0906 18-38-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01876, current rewards: -2961.50001, mean: -1.31040
[32m[0906 18-38-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01876, current rewards: -3061.50001, mean: -1.32532
[32m[0906 18-38-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01876, current rewards: -3161.50001, mean: -1.33962
[32m[0906 18-38-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01876, current rewards: -3261.50001, mean: -1.35332
[32m[0906 18-38-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01876, current rewards: -3361.50001, mean: -1.36646
[32m[0906 18-38-29 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-38-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-38-29 @MBExp.py:227][0m Rewards obtained: [-3441.500010664192], Lows: [1762], Highs: [0], Total time: 5280.0607930000015
[32m[0906 18-42-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-42-19 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 18-42-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: -0.03920, mean: -0.00392
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 5.49680, mean: 0.09161
[32m[0906 18-42-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 11.02313, mean: 0.10021
[32m[0906 18-42-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 16.54295, mean: 0.10339
[32m[0906 18-42-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 22.06659, mean: 0.10508
[32m[0906 18-42-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01927, current rewards: 27.58867, mean: 0.10611
[32m[0906 18-42-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01928, current rewards: 33.11628, mean: 0.10683
[32m[0906 18-42-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01929, current rewards: 38.54337, mean: 0.10706
[32m[0906 18-42-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 44.00132, mean: 0.10732
[32m[0906 18-42-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01930, current rewards: 49.35455, mean: 0.10729
[32m[0906 18-42-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 54.87957, mean: 0.10761
[32m[0906 18-42-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 60.41481, mean: 0.10788
[32m[0906 18-42-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 65.93711, mean: 0.10809
[32m[0906 18-42-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01905, current rewards: 71.46721, mean: 0.10828
[32m[0906 18-42-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01902, current rewards: 76.96827, mean: 0.10841
[32m[0906 18-42-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01899, current rewards: 82.46996, mean: 0.10851
[32m[0906 18-42-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01897, current rewards: 87.97414, mean: 0.10861
[32m[0906 18-42-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01896, current rewards: 93.56942, mean: 0.10880
[32m[0906 18-42-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01894, current rewards: 99.06942, mean: 0.10887
[32m[0906 18-42-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01892, current rewards: 104.56250, mean: 0.10892
[32m[0906 18-42-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01890, current rewards: 110.05126, mean: 0.10896
[32m[0906 18-42-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01888, current rewards: 115.54089, mean: 0.10900
[32m[0906 18-42-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01888, current rewards: 118.92298, mean: 0.10714
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01887, current rewards: 124.49955, mean: 0.10733
[32m[0906 18-42-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01885, current rewards: 130.07081, mean: 0.10750
[32m[0906 18-42-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01882, current rewards: 135.64124, mean: 0.10765
[32m[0906 18-42-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01882, current rewards: 141.08850, mean: 0.10770
[32m[0906 18-42-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01881, current rewards: 146.64611, mean: 0.10783
[32m[0906 18-42-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01881, current rewards: 152.20069, mean: 0.10794
[32m[0906 18-42-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01880, current rewards: 157.75429, mean: 0.10805
[32m[0906 18-42-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01880, current rewards: 163.31320, mean: 0.10815
[32m[0906 18-42-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01879, current rewards: 168.86377, mean: 0.10825
[32m[0906 18-42-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01879, current rewards: 174.41618, mean: 0.10833
[32m[0906 18-42-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01879, current rewards: 179.97086, mean: 0.10842
[32m[0906 18-42-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: 185.51951, mean: 0.10849
[32m[0906 18-42-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: 191.09275, mean: 0.10858
[32m[0906 18-42-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 196.66922, mean: 0.10866
[32m[0906 18-42-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 202.24848, mean: 0.10874
[32m[0906 18-42-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01877, current rewards: 207.81953, mean: 0.10881
[32m[0906 18-42-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 213.31075, mean: 0.10883
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01877, current rewards: 218.82973, mean: 0.10887
[32m[0906 18-42-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01876, current rewards: 224.35166, mean: 0.10891
[32m[0906 18-42-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01876, current rewards: 229.82715, mean: 0.10892
[32m[0906 18-43-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01876, current rewards: 235.35177, mean: 0.10896
[32m[0906 18-43-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01876, current rewards: 240.87217, mean: 0.10899
[32m[0906 18-43-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01875, current rewards: 246.39232, mean: 0.10902
[32m[0906 18-43-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01875, current rewards: 251.91061, mean: 0.10905
[32m[0906 18-43-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01875, current rewards: 257.43616, mean: 0.10908
[32m[0906 18-43-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01874, current rewards: 262.95436, mean: 0.10911
[32m[0906 18-43-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01874, current rewards: 268.47478, mean: 0.10914
[32m[0906 18-43-06 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-43-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-43-07 @MBExp.py:227][0m Rewards obtained: [272.9206864185107], Lows: [1], Highs: [1], Total time: 5327.764027000001
[32m[0906 18-46-59 @MBExp.py:144][0m ####################################################################
[32m[0906 18-46-59 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 18-46-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01923, current rewards: 1.05187, mean: 0.10519
[32m[0906 18-47-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01919, current rewards: 6.60432, mean: 0.11007
[32m[0906 18-47-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01925, current rewards: 12.17639, mean: 0.11069
[32m[0906 18-47-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.74997, mean: 0.11094
[32m[0906 18-47-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01928, current rewards: 23.31990, mean: 0.11105
[32m[0906 18-47-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01929, current rewards: 28.89164, mean: 0.11112
[32m[0906 18-47-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01929, current rewards: 34.46742, mean: 0.11119
[32m[0906 18-47-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01929, current rewards: 40.03688, mean: 0.11121
[32m[0906 18-47-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 45.61153, mean: 0.11125
[32m[0906 18-47-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01929, current rewards: 51.11509, mean: 0.11112
[32m[0906 18-47-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.70723, mean: 0.11119
[32m[0906 18-47-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 62.26773, mean: 0.11119
[32m[0906 18-47-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 67.82603, mean: 0.11119
[32m[0906 18-47-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 73.38677, mean: 0.11119
[32m[0906 18-47-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 78.94600, mean: 0.11119
[32m[0906 18-47-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01904, current rewards: 84.50290, mean: 0.11119
[32m[0906 18-47-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01902, current rewards: 90.06150, mean: 0.11119
[32m[0906 18-47-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01899, current rewards: 95.74132, mean: 0.11133
[32m[0906 18-47-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01898, current rewards: 101.32343, mean: 0.11134
[32m[0906 18-47-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01897, current rewards: 106.90131, mean: 0.11136
[32m[0906 18-47-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01895, current rewards: 112.47813, mean: 0.11136
[32m[0906 18-47-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01895, current rewards: 118.05494, mean: 0.11137
[32m[0906 18-47-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01894, current rewards: 123.63137, mean: 0.11138
[32m[0906 18-47-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01894, current rewards: 129.14822, mean: 0.11133
[32m[0906 18-47-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01893, current rewards: 134.71645, mean: 0.11134
[32m[0906 18-47-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01891, current rewards: 140.27873, mean: 0.11133
[32m[0906 18-47-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01889, current rewards: 145.84523, mean: 0.11133
[32m[0906 18-47-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01887, current rewards: 151.40781, mean: 0.11133
[32m[0906 18-47-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01886, current rewards: 157.82083, mean: 0.11193
[32m[0906 18-47-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01887, current rewards: 163.37479, mean: 0.11190
[32m[0906 18-47-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01886, current rewards: 168.93080, mean: 0.11187
[32m[0906 18-47-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01886, current rewards: 174.48566, mean: 0.11185
[32m[0906 18-47-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01885, current rewards: 180.04071, mean: 0.11183
[32m[0906 18-47-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01885, current rewards: 185.58958, mean: 0.11180
[32m[0906 18-47-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01884, current rewards: 191.06276, mean: 0.11173
[32m[0906 18-47-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 196.55906, mean: 0.11168
[32m[0906 18-47-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 202.12935, mean: 0.11167
[32m[0906 18-47-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 207.69545, mean: 0.11166
[32m[0906 18-47-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 213.26123, mean: 0.11166
[32m[0906 18-47-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: 218.82528, mean: 0.11165
[32m[0906 18-47-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 224.38808, mean: 0.11164
[32m[0906 18-47-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 229.95286, mean: 0.11163
[32m[0906 18-47-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 235.53375, mean: 0.11163
[32m[0906 18-47-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: 241.10065, mean: 0.11162
[32m[0906 18-47-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 246.66490, mean: 0.11161
[32m[0906 18-47-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01883, current rewards: 252.23233, mean: 0.11161
[32m[0906 18-47-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 257.76878, mean: 0.11159
[32m[0906 18-47-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01883, current rewards: 263.31855, mean: 0.11158
[32m[0906 18-47-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01882, current rewards: 268.86119, mean: 0.11156
[32m[0906 18-47-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: 274.40546, mean: 0.11155
[32m[0906 18-47-46 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-47-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-47-46 @MBExp.py:227][0m Rewards obtained: [278.9266661510175], Lows: [0], Highs: [0], Total time: 5375.638074000001
[32m[0906 18-51-40 @MBExp.py:144][0m ####################################################################
[32m[0906 18-51-40 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 18-51-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01872, current rewards: 1.02616, mean: 0.10262
[32m[0906 18-51-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 6.46407, mean: 0.10773
[32m[0906 18-51-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01926, current rewards: 12.00343, mean: 0.10912
[32m[0906 18-51-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.54507, mean: 0.10966
[32m[0906 18-51-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 23.08905, mean: 0.10995
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01927, current rewards: 28.63485, mean: 0.11013
[32m[0906 18-51-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 34.18313, mean: 0.11027
[32m[0906 18-51-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 39.72416, mean: 0.11034
[32m[0906 18-51-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.27772, mean: 0.11043
[32m[0906 18-51-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 50.87680, mean: 0.11060
[32m[0906 18-51-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.41889, mean: 0.11063
[32m[0906 18-51-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 61.95833, mean: 0.11064
[32m[0906 18-51-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 67.50183, mean: 0.11066
[32m[0906 18-51-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01904, current rewards: 73.04074, mean: 0.11067
[32m[0906 18-51-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01902, current rewards: 78.63650, mean: 0.11076
[32m[0906 18-51-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01899, current rewards: 84.21007, mean: 0.11080
[32m[0906 18-51-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01898, current rewards: 89.78644, mean: 0.11085
[32m[0906 18-51-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01896, current rewards: 95.40082, mean: 0.11093
[32m[0906 18-51-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01893, current rewards: 100.97677, mean: 0.11096
[32m[0906 18-51-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01892, current rewards: 106.55483, mean: 0.11099
[32m[0906 18-51-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01892, current rewards: 112.12863, mean: 0.11102
[32m[0906 18-52-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01891, current rewards: 115.62413, mean: 0.10908
[32m[0906 18-52-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01890, current rewards: 121.18916, mean: 0.10918
[32m[0906 18-52-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01889, current rewards: 126.75641, mean: 0.10927
[32m[0906 18-52-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01887, current rewards: 132.32155, mean: 0.10936
[32m[0906 18-52-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01885, current rewards: 135.82382, mean: 0.10780
[32m[0906 18-52-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01884, current rewards: 141.38289, mean: 0.10793
[32m[0906 18-52-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01884, current rewards: 146.93918, mean: 0.10804
[32m[0906 18-52-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01883, current rewards: 152.49261, mean: 0.10815
[32m[0906 18-52-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01882, current rewards: 158.04656, mean: 0.10825
[32m[0906 18-52-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01882, current rewards: 163.60381, mean: 0.10835
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01881, current rewards: 169.16107, mean: 0.10844
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01881, current rewards: 174.71941, mean: 0.10852
[32m[0906 18-52-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01881, current rewards: 180.27757, mean: 0.10860
[32m[0906 18-52-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01880, current rewards: 185.92169, mean: 0.10873
[32m[0906 18-52-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 191.48485, mean: 0.10880
[32m[0906 18-52-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: 197.04800, mean: 0.10887
[32m[0906 18-52-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01878, current rewards: 202.61115, mean: 0.10893
[32m[0906 18-52-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: 155.94494, mean: 0.08165
[32m[0906 18-52-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01878, current rewards: 105.94494, mean: 0.05405
[32m[0906 18-52-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01877, current rewards: 55.94494, mean: 0.02783
[32m[0906 18-52-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01877, current rewards: 5.94494, mean: 0.00289
[32m[0906 18-52-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01877, current rewards: -44.05506, mean: -0.02088
[32m[0906 18-52-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01877, current rewards: -94.05506, mean: -0.04354
[32m[0906 18-52-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01877, current rewards: -144.05506, mean: -0.06518
[32m[0906 18-52-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01877, current rewards: -194.05506, mean: -0.08587
[32m[0906 18-52-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01877, current rewards: -244.05506, mean: -0.10565
[32m[0906 18-52-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01877, current rewards: -294.05506, mean: -0.12460
[32m[0906 18-52-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01876, current rewards: -344.05506, mean: -0.14276
[32m[0906 18-52-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01876, current rewards: -394.05506, mean: -0.16018
[32m[0906 18-52-27 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-52-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-52-28 @MBExp.py:227][0m Rewards obtained: [-434.0550640943941], Lows: [2], Highs: [637], Total time: 5423.3781450000015
[32m[0906 18-56-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-56-24 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 18-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 0.92120, mean: 0.09212
[32m[0906 18-56-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01919, current rewards: 6.46788, mean: 0.10780
[32m[0906 18-56-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 12.01214, mean: 0.10920
[32m[0906 18-56-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 17.55855, mean: 0.10974
[32m[0906 18-56-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01930, current rewards: 23.10586, mean: 0.11003
[32m[0906 18-56-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01932, current rewards: 28.65457, mean: 0.11021
[32m[0906 18-56-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01935, current rewards: 34.20251, mean: 0.11033
[32m[0906 18-56-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01935, current rewards: 39.74980, mean: 0.11042
[32m[0906 18-56-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01937, current rewards: 45.31557, mean: 0.11053
[32m[0906 18-56-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01931, current rewards: 50.86612, mean: 0.11058
[32m[0906 18-56-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 56.41698, mean: 0.11062
[32m[0906 18-56-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01938, current rewards: 52.91929, mean: 0.09450
[32m[0906 18-56-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01982, current rewards: 30.67574, mean: 0.05029
[32m[0906 18-56-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02019, current rewards: 16.15235, mean: 0.02447
[32m[0906 18-56-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02053, current rewards: 14.52855, mean: 0.02046
[32m[0906 18-56-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02077, current rewards: 8.25390, mean: 0.01086
[32m[0906 18-56-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02106, current rewards: 2.17136, mean: 0.00268
[32m[0906 18-56-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02133, current rewards: -17.52210, mean: -0.02037
[32m[0906 18-56-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02158, current rewards: -32.76210, mean: -0.03600
[32m[0906 18-56-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02177, current rewards: -41.74433, mean: -0.04348
[32m[0906 18-56-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02193, current rewards: -61.61106, mean: -0.06100
[32m[0906 18-56-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02208, current rewards: -75.93706, mean: -0.07164
[32m[0906 18-56-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02222, current rewards: -100.61098, mean: -0.09064
[32m[0906 18-56-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02242, current rewards: -96.84581, mean: -0.08349
[32m[0906 18-56-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02252, current rewards: -115.51597, mean: -0.09547
[32m[0906 18-56-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02267, current rewards: -125.02759, mean: -0.09923
[32m[0906 18-56-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02279, current rewards: -124.84123, mean: -0.09530
[32m[0906 18-56-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02292, current rewards: -124.28310, mean: -0.09138
[32m[0906 18-56-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02307, current rewards: -129.67838, mean: -0.09197
[32m[0906 18-56-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02307, current rewards: -150.79629, mean: -0.10329
[32m[0906 18-56-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02309, current rewards: -169.63452, mean: -0.11234
[32m[0906 18-57-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02311, current rewards: -188.21648, mean: -0.12065
[32m[0906 18-57-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02311, current rewards: -204.60402, mean: -0.12708
[32m[0906 18-57-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02314, current rewards: -217.85914, mean: -0.13124
[32m[0906 18-57-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02315, current rewards: -228.00556, mean: -0.13334
[32m[0906 18-57-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02320, current rewards: -238.24249, mean: -0.13537
[32m[0906 18-57-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02321, current rewards: -250.84238, mean: -0.13859
[32m[0906 18-57-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02323, current rewards: -265.10906, mean: -0.14253
[32m[0906 18-57-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02327, current rewards: -271.78343, mean: -0.14229
[32m[0906 18-57-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02330, current rewards: -281.17603, mean: -0.14346
[32m[0906 18-57-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02337, current rewards: -285.20262, mean: -0.14189
[32m[0906 18-57-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02340, current rewards: -296.22840, mean: -0.14380
[32m[0906 18-57-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02346, current rewards: -316.29538, mean: -0.14990
[32m[0906 18-57-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02351, current rewards: -328.59584, mean: -0.15213
[32m[0906 18-57-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02355, current rewards: -347.08933, mean: -0.15705
[32m[0906 18-57-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02360, current rewards: -365.76108, mean: -0.16184
[32m[0906 18-57-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02365, current rewards: -390.37100, mean: -0.16899
[32m[0906 18-57-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02368, current rewards: -400.64469, mean: -0.16976
[32m[0906 18-57-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02371, current rewards: -403.81229, mean: -0.16756
[32m[0906 18-57-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02371, current rewards: -409.03530, mean: -0.16627
[32m[0906 18-57-24 @Agent.py:117][0m Average action selection time: 0.0237
[32m[0906 18-57-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-57-24 @MBExp.py:227][0m Rewards obtained: [-413.5735141234664], Lows: [193], Highs: [262], Total time: 5483.505899000002
[32m[0906 19-01-21 @MBExp.py:144][0m ####################################################################
[32m[0906 19-01-21 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 19-01-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01820, current rewards: -0.02868, mean: -0.00287
[32m[0906 19-01-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 5.51570, mean: 0.09193
[32m[0906 19-01-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 11.05691, mean: 0.10052
[32m[0906 19-01-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 16.59169, mean: 0.10370
[32m[0906 19-01-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 22.12979, mean: 0.10538
[32m[0906 19-01-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 27.66819, mean: 0.10642
[32m[0906 19-01-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 33.20744, mean: 0.10712
[32m[0906 19-01-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 38.70513, mean: 0.10751
[32m[0906 19-01-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01857, current rewards: 44.22897, mean: 0.10788
[32m[0906 19-01-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01858, current rewards: 49.74914, mean: 0.10815
[32m[0906 19-01-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 55.27493, mean: 0.10838
[32m[0906 19-01-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: 60.80025, mean: 0.10857
[32m[0906 19-01-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 66.33058, mean: 0.10874
[32m[0906 19-01-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 71.85564, mean: 0.10887
[32m[0906 19-01-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 77.38212, mean: 0.10899
[32m[0906 19-01-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 82.90453, mean: 0.10908
[32m[0906 19-01-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 88.43400, mean: 0.10918
[32m[0906 19-01-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 93.96203, mean: 0.10926
[32m[0906 19-01-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 95.23886, mean: 0.10466
[32m[0906 19-01-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 100.74331, mean: 0.10494
[32m[0906 19-01-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 106.25284, mean: 0.10520
[32m[0906 19-01-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 111.75725, mean: 0.10543
[32m[0906 19-01-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 117.26566, mean: 0.10564
[32m[0906 19-01-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 122.89213, mean: 0.10594
[32m[0906 19-01-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 128.43568, mean: 0.10615
[32m[0906 19-01-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: 133.97602, mean: 0.10633
[32m[0906 19-01-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 139.51703, mean: 0.10650
[32m[0906 19-01-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: 145.06150, mean: 0.10666
[32m[0906 19-01-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01860, current rewards: 150.60218, mean: 0.10681
[32m[0906 19-01-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: 156.14570, mean: 0.10695
[32m[0906 19-01-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01860, current rewards: 158.32025, mean: 0.10485
[32m[0906 19-01-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01860, current rewards: 163.80591, mean: 0.10500
[32m[0906 19-01-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01860, current rewards: 169.33366, mean: 0.10518
[32m[0906 19-01-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01860, current rewards: 174.86461, mean: 0.10534
[32m[0906 19-01-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01860, current rewards: 180.39492, mean: 0.10549
[32m[0906 19-01-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01860, current rewards: 185.92598, mean: 0.10564
[32m[0906 19-01-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01860, current rewards: 191.45583, mean: 0.10578
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01860, current rewards: 196.97987, mean: 0.10590
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01860, current rewards: 202.50643, mean: 0.10602
[32m[0906 19-01-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01860, current rewards: 208.03354, mean: 0.10614
[32m[0906 19-01-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: 213.56507, mean: 0.10625
[32m[0906 19-02-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01860, current rewards: 219.09064, mean: 0.10635
[32m[0906 19-02-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: 224.69876, mean: 0.10649
[32m[0906 19-02-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01860, current rewards: 230.23156, mean: 0.10659
[32m[0906 19-02-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01860, current rewards: 235.76271, mean: 0.10668
[32m[0906 19-02-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01861, current rewards: 241.28944, mean: 0.10677
[32m[0906 19-02-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01861, current rewards: 246.81852, mean: 0.10685
[32m[0906 19-02-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: 252.34960, mean: 0.10693
[32m[0906 19-02-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01861, current rewards: 257.88071, mean: 0.10700
[32m[0906 19-02-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01861, current rewards: 263.41273, mean: 0.10708
[32m[0906 19-02-09 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-02-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-02-09 @MBExp.py:227][0m Rewards obtained: [267.84358185886595], Lows: [2], Highs: [4], Total time: 5530.874025000002
[32m[0906 19-06-10 @MBExp.py:144][0m ####################################################################
[32m[0906 19-06-10 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.12984, mean: 0.11298
[32m[0906 19-06-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01917, current rewards: 6.72897, mean: 0.11215
[32m[0906 19-06-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01867, current rewards: 12.26642, mean: 0.11151
[32m[0906 19-06-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: 17.81250, mean: 0.11133
[32m[0906 19-06-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01863, current rewards: 23.36128, mean: 0.11124
[32m[0906 19-06-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01862, current rewards: 28.91013, mean: 0.11119
[32m[0906 19-06-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01862, current rewards: 34.43280, mean: 0.11107
[32m[0906 19-06-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01862, current rewards: 39.97465, mean: 0.11104
[32m[0906 19-06-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01864, current rewards: 45.52236, mean: 0.11103
[32m[0906 19-06-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01861, current rewards: 51.07139, mean: 0.11102
[32m[0906 19-06-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01862, current rewards: 56.76559, mean: 0.11131
[32m[0906 19-06-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 62.31247, mean: 0.11127
[32m[0906 19-06-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 67.86051, mean: 0.11125
[32m[0906 19-06-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01860, current rewards: 73.40422, mean: 0.11122
[32m[0906 19-06-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01860, current rewards: 78.89898, mean: 0.11113
[32m[0906 19-06-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 84.44614, mean: 0.11111
[32m[0906 19-06-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 89.98856, mean: 0.11110
[32m[0906 19-06-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 95.53305, mean: 0.11108
[32m[0906 19-06-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01860, current rewards: 101.07528, mean: 0.11107
[32m[0906 19-06-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01859, current rewards: 106.61390, mean: 0.11106
[32m[0906 19-06-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 112.16097, mean: 0.11105
[32m[0906 19-06-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 117.70766, mean: 0.11104
[32m[0906 19-06-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01861, current rewards: 123.33447, mean: 0.11111
[32m[0906 19-06-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 128.90916, mean: 0.11113
[32m[0906 19-06-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01862, current rewards: 134.42272, mean: 0.11109
[32m[0906 19-06-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 139.95990, mean: 0.11108
[32m[0906 19-06-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 145.49198, mean: 0.11106
[32m[0906 19-06-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 151.02179, mean: 0.11105
[32m[0906 19-06-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 156.55771, mean: 0.11103
[32m[0906 19-06-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 162.09526, mean: 0.11102
[32m[0906 19-06-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01862, current rewards: 165.55203, mean: 0.10964
[32m[0906 19-06-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01863, current rewards: 171.01888, mean: 0.10963
[32m[0906 19-06-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01863, current rewards: 176.56039, mean: 0.10966
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01863, current rewards: 182.10394, mean: 0.10970
[32m[0906 19-06-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01864, current rewards: 187.64682, mean: 0.10973
[32m[0906 19-06-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01864, current rewards: 193.18816, mean: 0.10977
[32m[0906 19-06-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01864, current rewards: 198.73321, mean: 0.10980
[32m[0906 19-06-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01864, current rewards: 204.27573, mean: 0.10983
[32m[0906 19-06-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01864, current rewards: 209.81956, mean: 0.10985
[32m[0906 19-06-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01864, current rewards: 215.28820, mean: 0.10984
[32m[0906 19-06-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01865, current rewards: 220.82942, mean: 0.10987
[32m[0906 19-06-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01865, current rewards: 226.37092, mean: 0.10989
[32m[0906 19-06-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01865, current rewards: 231.90811, mean: 0.10991
[32m[0906 19-06-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01866, current rewards: 237.45267, mean: 0.10993
[32m[0906 19-06-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: 242.99622, mean: 0.10995
[32m[0906 19-06-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01866, current rewards: 248.51921, mean: 0.10996
[32m[0906 19-06-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: 254.06096, mean: 0.10998
[32m[0906 19-06-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: 259.70355, mean: 0.11004
[32m[0906 19-06-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01866, current rewards: 265.30560, mean: 0.11009
[32m[0906 19-06-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01866, current rewards: 270.85139, mean: 0.11010
[32m[0906 19-06-57 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-06-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-06-57 @MBExp.py:227][0m Rewards obtained: [275.28874553257356], Lows: [1], Highs: [0], Total time: 5578.364378000002
[32m[0906 19-11-02 @MBExp.py:144][0m ####################################################################
[32m[0906 19-11-02 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 19-11-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01865, current rewards: 1.08381, mean: 0.10838
[32m[0906 19-11-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.67337, mean: 0.11122
[32m[0906 19-11-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.26563, mean: 0.11151
[32m[0906 19-11-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.85860, mean: 0.11162
[32m[0906 19-11-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.44830, mean: 0.11166
[32m[0906 19-11-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01893, current rewards: 29.04044, mean: 0.11169
[32m[0906 19-11-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01891, current rewards: 34.58430, mean: 0.11156
[32m[0906 19-11-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01891, current rewards: 40.17104, mean: 0.11159
[32m[0906 19-11-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01887, current rewards: 45.75894, mean: 0.11161
[32m[0906 19-11-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01886, current rewards: 50.20369, mean: 0.10914
[32m[0906 19-11-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01884, current rewards: 55.72607, mean: 0.10927
[32m[0906 19-11-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01883, current rewards: 61.25271, mean: 0.10938
[32m[0906 19-11-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01879, current rewards: 66.77621, mean: 0.10947
[32m[0906 19-11-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01879, current rewards: 72.29902, mean: 0.10954
[32m[0906 19-11-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01878, current rewards: 77.87184, mean: 0.10968
[32m[0906 19-11-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01876, current rewards: 83.39148, mean: 0.10973
[32m[0906 19-11-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01876, current rewards: 88.91669, mean: 0.10977
[32m[0906 19-11-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01874, current rewards: 94.61060, mean: 0.11001
[32m[0906 19-11-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01873, current rewards: 100.19303, mean: 0.11010
[32m[0906 19-11-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01873, current rewards: 105.78204, mean: 0.11019
[32m[0906 19-11-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01871, current rewards: 111.36838, mean: 0.11027
[32m[0906 19-11-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01870, current rewards: 116.95360, mean: 0.11033
[32m[0906 19-11-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01870, current rewards: 122.54272, mean: 0.11040
[32m[0906 19-11-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01870, current rewards: 128.13208, mean: 0.11046
[32m[0906 19-11-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01870, current rewards: 133.71994, mean: 0.11051
[32m[0906 19-11-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01870, current rewards: 139.28660, mean: 0.11054
[32m[0906 19-11-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01870, current rewards: 144.83231, mean: 0.11056
[32m[0906 19-11-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: 150.37546, mean: 0.11057
[32m[0906 19-11-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01869, current rewards: 155.91261, mean: 0.11058
[32m[0906 19-11-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: 159.76709, mean: 0.10943
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: 165.82686, mean: 0.10982
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01869, current rewards: 169.12010, mean: 0.10841
[32m[0906 19-11-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01869, current rewards: 172.41054, mean: 0.10709
[32m[0906 19-11-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01868, current rewards: 175.70098, mean: 0.10584
[32m[0906 19-11-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01868, current rewards: 174.72818, mean: 0.10218
[32m[0906 19-11-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01867, current rewards: 124.72818, mean: 0.07087
[32m[0906 19-11-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01867, current rewards: 74.72818, mean: 0.04129
[32m[0906 19-11-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01867, current rewards: 24.72818, mean: 0.01329
[32m[0906 19-11-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01867, current rewards: -25.27182, mean: -0.01323
[32m[0906 19-11-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01866, current rewards: -75.27182, mean: -0.03840
[32m[0906 19-11-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01867, current rewards: -125.27182, mean: -0.06232
[32m[0906 19-11-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01867, current rewards: -145.90424, mean: -0.07083
[32m[0906 19-11-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01867, current rewards: -143.46213, mean: -0.06799
[32m[0906 19-11-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01866, current rewards: -141.02002, mean: -0.06529
[32m[0906 19-11-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: -138.57792, mean: -0.06270
[32m[0906 19-11-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01866, current rewards: -136.13581, mean: -0.06024
[32m[0906 19-11-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: -133.69370, mean: -0.05788
[32m[0906 19-11-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: -173.20528, mean: -0.07339
[32m[0906 19-11-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01865, current rewards: -223.20528, mean: -0.09262
[32m[0906 19-11-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01865, current rewards: -273.20528, mean: -0.11106
[32m[0906 19-11-49 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-11-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-11-49 @MBExp.py:227][0m Rewards obtained: [-313.2052786764699], Lows: [1], Highs: [507], Total time: 5625.833583000002
[32m[0906 19-15-54 @MBExp.py:144][0m ####################################################################
[32m[0906 19-15-54 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01974, current rewards: -0.06510, mean: -0.00651
[32m[0906 19-15-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01938, current rewards: 5.40409, mean: 0.09007
[32m[0906 19-15-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 10.82991, mean: 0.09845
[32m[0906 19-15-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01928, current rewards: 16.25606, mean: 0.10160
[32m[0906 19-15-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 21.68194, mean: 0.10325
[32m[0906 19-15-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 27.07584, mean: 0.10414
[32m[0906 19-16-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01901, current rewards: 32.46596, mean: 0.10473
[32m[0906 19-16-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01895, current rewards: 37.85925, mean: 0.10516
[32m[0906 19-16-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01892, current rewards: 43.25356, mean: 0.10550
[32m[0906 19-16-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01886, current rewards: 48.64468, mean: 0.10575
[32m[0906 19-16-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01884, current rewards: 52.93088, mean: 0.10379
[32m[0906 19-16-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01882, current rewards: 58.44333, mean: 0.10436
[32m[0906 19-16-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01881, current rewards: 63.95291, mean: 0.10484
[32m[0906 19-16-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01881, current rewards: 69.47098, mean: 0.10526
[32m[0906 19-16-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01880, current rewards: 75.06844, mean: 0.10573
[32m[0906 19-16-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01878, current rewards: 80.64829, mean: 0.10612
[32m[0906 19-16-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01876, current rewards: 86.17216, mean: 0.10639
[32m[0906 19-16-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01875, current rewards: 91.69696, mean: 0.10662
[32m[0906 19-16-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01874, current rewards: 97.21637, mean: 0.10683
[32m[0906 19-16-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01873, current rewards: 102.74012, mean: 0.10702
[32m[0906 19-16-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01872, current rewards: 108.26215, mean: 0.10719
[32m[0906 19-16-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01871, current rewards: 113.78184, mean: 0.10734
[32m[0906 19-16-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01870, current rewards: 119.25967, mean: 0.10744
[32m[0906 19-16-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01870, current rewards: 124.79301, mean: 0.10758
[32m[0906 19-16-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01871, current rewards: 130.32488, mean: 0.10771
[32m[0906 19-16-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01871, current rewards: 135.85541, mean: 0.10782
[32m[0906 19-16-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01871, current rewards: 141.38040, mean: 0.10792
[32m[0906 19-16-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01871, current rewards: 146.90766, mean: 0.10802
[32m[0906 19-16-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 152.43728, mean: 0.10811
[32m[0906 19-16-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: 158.26174, mean: 0.10840
[32m[0906 19-16-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: 163.79859, mean: 0.10848
[32m[0906 19-16-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: 169.32123, mean: 0.10854
[32m[0906 19-16-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01870, current rewards: 174.84139, mean: 0.10860
[32m[0906 19-16-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01871, current rewards: 180.36123, mean: 0.10865
[32m[0906 19-16-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 186.16035, mean: 0.10887
[32m[0906 19-16-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01871, current rewards: 191.72092, mean: 0.10893
[32m[0906 19-16-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01871, current rewards: 197.28182, mean: 0.10900
[32m[0906 19-16-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01871, current rewards: 202.84136, mean: 0.10905
[32m[0906 19-16-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01870, current rewards: 208.28110, mean: 0.10905
[32m[0906 19-16-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01870, current rewards: 213.80237, mean: 0.10908
[32m[0906 19-16-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01870, current rewards: 219.32825, mean: 0.10912
[32m[0906 19-16-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01870, current rewards: 224.85648, mean: 0.10915
[32m[0906 19-16-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01869, current rewards: 230.38206, mean: 0.10919
[32m[0906 19-16-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01870, current rewards: 235.90716, mean: 0.10922
[32m[0906 19-16-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01870, current rewards: 241.43434, mean: 0.10925
[32m[0906 19-16-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01870, current rewards: 247.06915, mean: 0.10932
[32m[0906 19-16-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01870, current rewards: 252.44313, mean: 0.10928
[32m[0906 19-16-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01869, current rewards: 257.85135, mean: 0.10926
[32m[0906 19-16-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01870, current rewards: 263.23711, mean: 0.10923
[32m[0906 19-16-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01870, current rewards: 268.62138, mean: 0.10920
[32m[0906 19-16-41 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-16-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-16-42 @MBExp.py:227][0m Rewards obtained: [272.9317247783696], Lows: [0], Highs: [2], Total time: 5673.4241390000025
[32m[0906 19-20-47 @MBExp.py:144][0m ####################################################################
[32m[0906 19-20-47 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 19-20-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01899, current rewards: 0.20026, mean: 0.02003
[32m[0906 19-20-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01982, current rewards: 5.87592, mean: 0.09793
[32m[0906 19-20-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02027, current rewards: 11.47621, mean: 0.10433
[32m[0906 19-20-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02052, current rewards: 17.08878, mean: 0.10680
[32m[0906 19-20-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02056, current rewards: 22.69324, mean: 0.10806
[32m[0906 19-20-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02032, current rewards: 28.22245, mean: 0.10855
[32m[0906 19-20-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02005, current rewards: 33.65721, mean: 0.10857
[32m[0906 19-20-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01986, current rewards: 39.17698, mean: 0.10882
[32m[0906 19-20-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01970, current rewards: 44.77462, mean: 0.10921
[32m[0906 19-20-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01959, current rewards: 50.30020, mean: 0.10935
[32m[0906 19-20-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01951, current rewards: 55.82224, mean: 0.10946
[32m[0906 19-20-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01945, current rewards: 61.35424, mean: 0.10956
[32m[0906 19-20-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01940, current rewards: 66.88258, mean: 0.10964
[32m[0906 19-21-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01933, current rewards: 72.41016, mean: 0.10971
[32m[0906 19-21-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01935, current rewards: 78.07060, mean: 0.10996
[32m[0906 19-21-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01959, current rewards: 83.68129, mean: 0.11011
[32m[0906 19-21-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01982, current rewards: 89.26232, mean: 0.11020
[32m[0906 19-21-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02004, current rewards: 94.83961, mean: 0.11028
[32m[0906 19-21-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02026, current rewards: 100.42860, mean: 0.11036
[32m[0906 19-21-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02027, current rewards: 106.45921, mean: 0.11090
[32m[0906 19-21-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02019, current rewards: 112.05768, mean: 0.11095
[32m[0906 19-21-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02010, current rewards: 117.65474, mean: 0.11100
[32m[0906 19-21-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02004, current rewards: 123.19350, mean: 0.11099
[32m[0906 19-21-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01997, current rewards: 128.77859, mean: 0.11102
[32m[0906 19-21-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01993, current rewards: 134.36890, mean: 0.11105
[32m[0906 19-21-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01988, current rewards: 139.95442, mean: 0.11107
[32m[0906 19-21-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01983, current rewards: 145.54584, mean: 0.11110
[32m[0906 19-21-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01979, current rewards: 151.12979, mean: 0.11112
[32m[0906 19-21-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01977, current rewards: 144.97102, mean: 0.10282
[32m[0906 19-21-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01981, current rewards: 97.26053, mean: 0.06662
[32m[0906 19-21-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01986, current rewards: 49.57901, mean: 0.03283
[32m[0906 19-21-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01989, current rewards: 3.87024, mean: 0.00248
[32m[0906 19-21-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01993, current rewards: -46.03088, mean: -0.02859
[32m[0906 19-21-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01997, current rewards: -91.75198, mean: -0.05527
[32m[0906 19-21-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02001, current rewards: -141.64981, mean: -0.08284
[32m[0906 19-21-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02003, current rewards: -187.38299, mean: -0.10647
[32m[0906 19-21-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02006, current rewards: -237.28134, mean: -0.13109
[32m[0906 19-21-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02009, current rewards: -283.00473, mean: -0.15215
[32m[0906 19-21-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02011, current rewards: -332.90167, mean: -0.17429
[32m[0906 19-21-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02018, current rewards: -375.25822, mean: -0.19146
[32m[0906 19-21-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02025, current rewards: -412.53940, mean: -0.20524
[32m[0906 19-21-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02038, current rewards: -406.89917, mean: -0.19752
[32m[0906 19-21-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02050, current rewards: -401.24558, mean: -0.19016
[32m[0906 19-21-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02062, current rewards: -395.53294, mean: -0.18312
[32m[0906 19-21-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02074, current rewards: -389.89507, mean: -0.17642
[32m[0906 19-21-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02083, current rewards: -384.24278, mean: -0.17002
[32m[0906 19-21-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02095, current rewards: -378.59116, mean: -0.16389
[32m[0906 19-21-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02106, current rewards: -373.06969, mean: -0.15808
[32m[0906 19-21-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02113, current rewards: -367.45532, mean: -0.15247
[32m[0906 19-21-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02119, current rewards: -361.84216, mean: -0.14709
[32m[0906 19-21-41 @Agent.py:117][0m Average action selection time: 0.0212
[32m[0906 19-21-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-21-41 @MBExp.py:227][0m Rewards obtained: [-357.3753873258839], Lows: [299], Highs: [2], Total time: 5727.223230000002
[32m[0906 19-25-50 @MBExp.py:144][0m ####################################################################
[32m[0906 19-25-50 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 19-25-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02684, current rewards: 0.63092, mean: 0.06309
[32m[0906 19-25-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02713, current rewards: 15.46787, mean: 0.25780
[32m[0906 19-25-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02718, current rewards: 30.38554, mean: 0.27623
[32m[0906 19-25-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02750, current rewards: 45.52103, mean: 0.28451
[32m[0906 19-25-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02755, current rewards: 60.19414, mean: 0.28664
[32m[0906 19-25-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02766, current rewards: 71.40904, mean: 0.27465
[32m[0906 19-25-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02797, current rewards: 78.60520, mean: 0.25357
[32m[0906 19-26-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02812, current rewards: 86.67246, mean: 0.24076
[32m[0906 19-26-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02829, current rewards: 93.74038, mean: 0.22864
[32m[0906 19-26-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02826, current rewards: 101.35614, mean: 0.22034
[32m[0906 19-26-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02826, current rewards: 108.90320, mean: 0.21354
[32m[0906 19-26-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02827, current rewards: 110.21189, mean: 0.19681
[32m[0906 19-26-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02839, current rewards: 119.71769, mean: 0.19626
[32m[0906 19-26-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02847, current rewards: 129.19336, mean: 0.19575
[32m[0906 19-26-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02857, current rewards: 139.14285, mean: 0.19598
[32m[0906 19-26-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02863, current rewards: 148.72043, mean: 0.19568
[32m[0906 19-26-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02865, current rewards: 158.42585, mean: 0.19559
[32m[0906 19-26-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02870, current rewards: 168.28908, mean: 0.19568
[32m[0906 19-26-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02873, current rewards: 177.98667, mean: 0.19559
[32m[0906 19-26-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02858, current rewards: 149.18777, mean: 0.15540
[32m[0906 19-26-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02809, current rewards: 49.18777, mean: 0.04870
[32m[0906 19-26-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02765, current rewards: -50.81223, mean: -0.04794
[32m[0906 19-26-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02724, current rewards: -150.81223, mean: -0.13587
[32m[0906 19-26-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02687, current rewards: -250.81223, mean: -0.21622
[32m[0906 19-26-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02653, current rewards: -350.81223, mean: -0.28993
[32m[0906 19-26-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02623, current rewards: -450.81223, mean: -0.35779
[32m[0906 19-26-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02593, current rewards: -550.81223, mean: -0.42047
[32m[0906 19-26-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02576, current rewards: -609.72249, mean: -0.44833
[32m[0906 19-26-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02575, current rewards: -596.19120, mean: -0.42283
[32m[0906 19-26-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02575, current rewards: -582.36782, mean: -0.39888
[32m[0906 19-26-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02575, current rewards: -565.82678, mean: -0.37472
[32m[0906 19-26-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02584, current rewards: -549.23434, mean: -0.35207
[32m[0906 19-26-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02588, current rewards: -536.70224, mean: -0.33336
[32m[0906 19-26-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02593, current rewards: -520.01037, mean: -0.31326
[32m[0906 19-26-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02597, current rewards: -502.43668, mean: -0.29382
[32m[0906 19-26-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02597, current rewards: -484.64437, mean: -0.27537
[32m[0906 19-26-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02599, current rewards: -467.00331, mean: -0.25801
[32m[0906 19-26-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02603, current rewards: -450.65658, mean: -0.24229
[32m[0906 19-26-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02590, current rewards: -445.88765, mean: -0.23345
[32m[0906 19-26-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02571, current rewards: -440.26947, mean: -0.22463
[32m[0906 19-26-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02554, current rewards: -434.64556, mean: -0.21624
[32m[0906 19-26-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02537, current rewards: -429.03786, mean: -0.20827
[32m[0906 19-26-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02521, current rewards: -423.43576, mean: -0.20068
[32m[0906 19-26-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02506, current rewards: -417.82133, mean: -0.19344
[32m[0906 19-26-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02495, current rewards: -423.58719, mean: -0.19167
[32m[0906 19-26-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02500, current rewards: -405.25588, mean: -0.17932
[32m[0906 19-26-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02504, current rewards: -393.76063, mean: -0.17046
[32m[0906 19-26-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02506, current rewards: -378.41478, mean: -0.16035
[32m[0906 19-26-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02508, current rewards: -362.77281, mean: -0.15053
[32m[0906 19-26-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02511, current rewards: -347.24894, mean: -0.14116
[32m[0906 19-26-53 @Agent.py:117][0m Average action selection time: 0.0251
[32m[0906 19-26-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-26-53 @MBExp.py:227][0m Rewards obtained: [-335.18083277153045], Lows: [414], Highs: [4], Total time: 5790.868696000002
[32m[0906 19-31-04 @MBExp.py:144][0m ####################################################################
[32m[0906 19-31-04 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 19-31-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01842, current rewards: -1.94303, mean: -0.19430
[32m[0906 19-31-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01870, current rewards: 3.51341, mean: 0.05856
[32m[0906 19-31-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01866, current rewards: 8.97338, mean: 0.08158
[32m[0906 19-31-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: 14.41943, mean: 0.09012
[32m[0906 19-31-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01863, current rewards: 19.90788, mean: 0.09480
[32m[0906 19-31-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01862, current rewards: 25.33861, mean: 0.09746
[32m[0906 19-31-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01864, current rewards: 30.85345, mean: 0.09953
[32m[0906 19-31-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01865, current rewards: 36.36802, mean: 0.10102
[32m[0906 19-31-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01865, current rewards: 41.87508, mean: 0.10213
[32m[0906 19-31-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01866, current rewards: 47.39215, mean: 0.10303
[32m[0906 19-31-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01865, current rewards: 52.89974, mean: 0.10372
[32m[0906 19-31-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01867, current rewards: 58.40905, mean: 0.10430
[32m[0906 19-31-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01868, current rewards: 59.96141, mean: 0.09830
[32m[0906 19-31-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01883, current rewards: 64.98156, mean: 0.09846
[32m[0906 19-31-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01890, current rewards: 70.01827, mean: 0.09862
[32m[0906 19-31-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01900, current rewards: 75.03320, mean: 0.09873
[32m[0906 19-31-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 80.05111, mean: 0.09883
[32m[0906 19-31-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 85.05827, mean: 0.09890
[32m[0906 19-31-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 90.08821, mean: 0.09900
[32m[0906 19-31-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: 95.08821, mean: 0.09905
[32m[0906 19-31-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: 100.12258, mean: 0.09913
[32m[0906 19-31-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01930, current rewards: 105.19795, mean: 0.09924
[32m[0906 19-31-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01932, current rewards: 110.24457, mean: 0.09932
[32m[0906 19-31-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01932, current rewards: 115.28120, mean: 0.09938
[32m[0906 19-31-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01934, current rewards: 120.31181, mean: 0.09943
[32m[0906 19-31-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01947, current rewards: 125.23377, mean: 0.09939
[32m[0906 19-31-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01972, current rewards: 130.09634, mean: 0.09931
[32m[0906 19-31-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01997, current rewards: 134.94525, mean: 0.09922
[32m[0906 19-31-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02019, current rewards: 139.76926, mean: 0.09913
[32m[0906 19-31-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02036, current rewards: 144.59905, mean: 0.09904
[32m[0906 19-31-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02052, current rewards: 149.53280, mean: 0.09903
[32m[0906 19-31-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02068, current rewards: 154.47614, mean: 0.09902
[32m[0906 19-31-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02081, current rewards: 159.38122, mean: 0.09899
[32m[0906 19-31-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02093, current rewards: 164.28734, mean: 0.09897
[32m[0906 19-31-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02091, current rewards: 91.57003, mean: 0.05355
[32m[0906 19-31-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02085, current rewards: -8.42997, mean: -0.00479
[32m[0906 19-31-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02079, current rewards: -108.42997, mean: -0.05991
[32m[0906 19-31-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02074, current rewards: -208.42997, mean: -0.11206
[32m[0906 19-31-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02069, current rewards: -308.42997, mean: -0.16148
[32m[0906 19-31-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02064, current rewards: -408.42997, mean: -0.20838
[32m[0906 19-31-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02059, current rewards: -508.42997, mean: -0.25295
[32m[0906 19-31-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02054, current rewards: -608.42997, mean: -0.29535
[32m[0906 19-31-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02050, current rewards: -708.42997, mean: -0.33575
[32m[0906 19-31-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02046, current rewards: -808.42997, mean: -0.37427
[32m[0906 19-31-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02042, current rewards: -908.42997, mean: -0.41105
[32m[0906 19-31-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02038, current rewards: -985.00775, mean: -0.43584
[32m[0906 19-31-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02034, current rewards: -979.47663, mean: -0.42402
[32m[0906 19-31-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02031, current rewards: -973.94530, mean: -0.41269
[32m[0906 19-31-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02027, current rewards: -968.40946, mean: -0.40183
[32m[0906 19-31-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02024, current rewards: -962.87419, mean: -0.39141
[32m[0906 19-31-55 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 19-31-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-31-55 @MBExp.py:227][0m Rewards obtained: [-958.4478218526242], Lows: [579], Highs: [1], Total time: 5842.254002000002
[32m[0906 19-35-54 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-54 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 19-35-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01335, current rewards: 1.25986, mean: 0.12599
[32m[0906 19-35-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01336, current rewards: 6.55317, mean: 0.10922
[32m[0906 19-35-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01330, current rewards: 12.09025, mean: 0.10991
[32m[0906 19-35-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01330, current rewards: 17.65066, mean: 0.11032
[32m[0906 19-35-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01331, current rewards: 24.36406, mean: 0.11602
[32m[0906 19-35-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01332, current rewards: 31.46061, mean: 0.12100
[32m[0906 19-35-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01325, current rewards: 13.43469, mean: 0.04334
[32m[0906 19-35-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01325, current rewards: -36.56531, mean: -0.10157
[32m[0906 19-36-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01325, current rewards: -86.56531, mean: -0.21113
[32m[0906 19-36-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01327, current rewards: -136.56531, mean: -0.29688
[32m[0906 19-36-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01327, current rewards: -186.56531, mean: -0.36581
[32m[0906 19-36-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01328, current rewards: -236.56531, mean: -0.42244
[32m[0906 19-36-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01328, current rewards: -286.56531, mean: -0.46978
[32m[0906 19-36-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01328, current rewards: -336.56531, mean: -0.50995
[32m[0906 19-36-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01327, current rewards: -386.56531, mean: -0.54446
[32m[0906 19-36-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01327, current rewards: -436.56531, mean: -0.57443
[32m[0906 19-36-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01327, current rewards: -486.56531, mean: -0.60070
[32m[0906 19-36-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01326, current rewards: -536.56531, mean: -0.62391
[32m[0906 19-36-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01326, current rewards: -586.56531, mean: -0.64458
[32m[0906 19-36-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01326, current rewards: -636.56531, mean: -0.66309
[32m[0906 19-36-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01325, current rewards: -686.56531, mean: -0.67977
[32m[0906 19-36-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01326, current rewards: -736.56531, mean: -0.69487
[32m[0906 19-36-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01326, current rewards: -786.56531, mean: -0.70862
[32m[0906 19-36-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01326, current rewards: -836.56531, mean: -0.72118
[32m[0906 19-36-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01325, current rewards: -886.56531, mean: -0.73270
[32m[0906 19-36-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01325, current rewards: -936.56531, mean: -0.74331
[32m[0906 19-36-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01325, current rewards: -986.56531, mean: -0.75310
[32m[0906 19-36-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01325, current rewards: -1036.56531, mean: -0.76218
[32m[0906 19-36-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01325, current rewards: -1086.56531, mean: -0.77061
[32m[0906 19-36-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01325, current rewards: -1136.56531, mean: -0.77847
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01325, current rewards: -1186.56531, mean: -0.78580
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01325, current rewards: -1236.56531, mean: -0.79267
[32m[0906 19-36-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01325, current rewards: -1286.56531, mean: -0.79911
[32m[0906 19-36-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01324, current rewards: -1336.56531, mean: -0.80516
[32m[0906 19-36-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01324, current rewards: -1386.56531, mean: -0.81086
[32m[0906 19-36-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01324, current rewards: -1436.56531, mean: -0.81623
[32m[0906 19-36-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01324, current rewards: -1486.56531, mean: -0.82131
[32m[0906 19-36-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01324, current rewards: -1536.56531, mean: -0.82611
[32m[0906 19-36-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01324, current rewards: -1586.56531, mean: -0.83066
[32m[0906 19-36-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01324, current rewards: -1636.56531, mean: -0.83498
[32m[0906 19-36-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01324, current rewards: -1686.56531, mean: -0.83909
[32m[0906 19-36-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01325, current rewards: -1736.56531, mean: -0.84299
[32m[0906 19-36-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01325, current rewards: -1786.56531, mean: -0.84671
[32m[0906 19-36-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01325, current rewards: -1836.56531, mean: -0.85026
[32m[0906 19-36-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01325, current rewards: -1886.56531, mean: -0.85365
[32m[0906 19-36-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01325, current rewards: -1936.56531, mean: -0.85689
[32m[0906 19-36-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01325, current rewards: -1986.56531, mean: -0.85998
[32m[0906 19-36-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01325, current rewards: -2036.56531, mean: -0.86295
[32m[0906 19-36-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01325, current rewards: -2086.56531, mean: -0.86579
[32m[0906 19-36-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01325, current rewards: -2136.56531, mean: -0.86852
[32m[0906 19-36-28 @Agent.py:117][0m Average action selection time: 0.0133
[32m[0906 19-36-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-36-28 @MBExp.py:227][0m Rewards obtained: [-2176.5653116982458], Lows: [0], Highs: [2212], Total time: 5876.0670800000025
