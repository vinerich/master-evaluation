[32m[0906 13-40-12 @logger.py:99][0m Log file set to /app/logs/dats-delay-0/zinc-coating-v0_2/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-12 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -7.65831, mean: -0.76583
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -67.49797, mean: -1.12497
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -123.90072, mean: -1.12637
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -186.56600, mean: -1.16604
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -246.21349, mean: -1.17245
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -307.29257, mean: -1.18189
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -359.20513, mean: -1.15873
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -411.09529, mean: -1.14193
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -472.16479, mean: -1.15162
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -518.46899, mean: -1.12711
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -565.74288, mean: -1.10930
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -615.36502, mean: -1.09887
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -664.72547, mean: -1.08971
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -714.29701, mean: -1.08227
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -790.85978, mean: -1.11389
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -868.22459, mean: -1.14240
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -948.64404, mean: -1.17117
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1029.35606, mean: -1.19693
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1097.08788, mean: -1.20559
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1167.24190, mean: -1.21588
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1237.27413, mean: -1.22502
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1294.57183, mean: -1.22129
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1360.16669, mean: -1.22538
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1422.22797, mean: -1.22606
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1482.58721, mean: -1.22528
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1553.29134, mean: -1.23277
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1611.37067, mean: -1.23005
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1662.26009, mean: -1.22225
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1731.48386, mean: -1.22800
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1802.80821, mean: -1.23480
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1868.70515, mean: -1.23755
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1934.40714, mean: -1.24000
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1985.94877, mean: -1.23351
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -2036.15746, mean: -1.22660
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2084.93459, mean: -1.21926
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2127.46953, mean: -1.20879
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2183.79369, mean: -1.20652
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2241.65046, mean: -1.20519
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2295.81051, mean: -1.20200
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2349.26317, mean: -1.19860
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2401.63591, mean: -1.19484
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2445.59074, mean: -1.18718
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2498.40940, mean: -1.18408
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2551.81455, mean: -1.18140
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2601.43160, mean: -1.17712
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2661.84520, mean: -1.17781
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2719.47353, mean: -1.17726
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2773.89155, mean: -1.17538
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2822.63672, mean: -1.17122
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2875.44826, mean: -1.16888
[32m[0906 13-40-12 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-12 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-40-15 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-15 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03137, current rewards: 0.33581, mean: 0.03358
[32m[0906 13-40-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01882, current rewards: 5.90527, mean: 0.09842
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01768, current rewards: 11.34078, mean: 0.10310
[32m[0906 13-40-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01722, current rewards: 16.78419, mean: 0.10490
[32m[0906 13-40-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01707, current rewards: 22.21796, mean: 0.10580
[32m[0906 13-40-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01689, current rewards: 27.65747, mean: 0.10637
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01679, current rewards: 33.09785, mean: 0.10677
[32m[0906 13-40-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01671, current rewards: 38.53972, mean: 0.10705
[32m[0906 13-40-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01669, current rewards: 44.01209, mean: 0.10735
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01665, current rewards: 49.58537, mean: 0.10779
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01662, current rewards: 55.16356, mean: 0.10816
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01659, current rewards: 59.82187, mean: 0.10682
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01657, current rewards: 64.47335, mean: 0.10569
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01656, current rewards: 69.12515, mean: 0.10474
[32m[0906 13-40-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01654, current rewards: 73.77616, mean: 0.10391
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01654, current rewards: 78.42986, mean: 0.10320
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01652, current rewards: 83.08415, mean: 0.10257
[32m[0906 13-40-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01655, current rewards: 87.74011, mean: 0.10202
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01656, current rewards: 92.61970, mean: 0.10178
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01655, current rewards: 97.70967, mean: 0.10178
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01654, current rewards: 102.80628, mean: 0.10179
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01655, current rewards: 107.89507, mean: 0.10179
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01654, current rewards: 112.98794, mean: 0.10179
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01654, current rewards: 118.07887, mean: 0.10179
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01654, current rewards: 123.06286, mean: 0.10170
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01659, current rewards: 127.53267, mean: 0.10122
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01664, current rewards: 132.00684, mean: 0.10077
[32m[0906 13-40-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01670, current rewards: 136.48167, mean: 0.10035
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01674, current rewards: 140.95362, mean: 0.09997
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01676, current rewards: 145.42466, mean: 0.09961
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01679, current rewards: 149.89739, mean: 0.09927
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01682, current rewards: 154.36853, mean: 0.09895
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01684, current rewards: 157.62747, mean: 0.09791
[32m[0906 13-40-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01689, current rewards: 174.54922, mean: 0.10515
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01692, current rewards: 194.76969, mean: 0.11390
[32m[0906 13-40-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01696, current rewards: 214.98872, mean: 0.12215
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01700, current rewards: 235.23804, mean: 0.12997
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01704, current rewards: 255.50666, mean: 0.13737
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01707, current rewards: 275.78808, mean: 0.14439
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01711, current rewards: 296.06186, mean: 0.15105
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01714, current rewards: 307.34008, mean: 0.15291
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01717, current rewards: 314.16612, mean: 0.15251
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01720, current rewards: 318.20734, mean: 0.15081
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01722, current rewards: 322.24894, mean: 0.14919
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01726, current rewards: 326.29514, mean: 0.14764
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01728, current rewards: 330.30424, mean: 0.14615
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01731, current rewards: 333.85479, mean: 0.14453
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01733, current rewards: 337.40395, mean: 0.14297
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01736, current rewards: 340.95357, mean: 0.14147
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01738, current rewards: 344.50129, mean: 0.14004
[32m[0906 13-40-59 @Agent.py:117][0m Average action selection time: 0.0174
[32m[0906 13-40-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-40-59 @MBExp.py:227][0m Rewards obtained: [347.33808165547254], Lows: [1], Highs: [2], Total time: 44.142288
[32m[0906 13-41-03 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-03 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01915, current rewards: -2.17461, mean: -0.21746
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01842, current rewards: 3.50044, mean: 0.05834
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 9.17216, mean: 0.08338
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01839, current rewards: 14.84547, mean: 0.09278
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01839, current rewards: 20.52230, mean: 0.09773
[32m[0906 13-41-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01837, current rewards: 26.19004, mean: 0.10073
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01835, current rewards: 31.86750, mean: 0.10280
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01830, current rewards: 37.53523, mean: 0.10426
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01831, current rewards: 42.71637, mean: 0.10419
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01831, current rewards: 47.73933, mean: 0.10378
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01832, current rewards: 52.76643, mean: 0.10346
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01831, current rewards: 55.53134, mean: 0.09916
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01831, current rewards: 60.28875, mean: 0.09883
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01831, current rewards: 65.04792, mean: 0.09856
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01831, current rewards: 69.80637, mean: 0.09832
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01831, current rewards: 74.55926, mean: 0.09810
[32m[0906 13-41-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01830, current rewards: 79.88298, mean: 0.09862
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01829, current rewards: 86.20023, mean: 0.10023
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01832, current rewards: 92.51449, mean: 0.10166
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01835, current rewards: 98.82283, mean: 0.10294
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01836, current rewards: 105.13240, mean: 0.10409
[32m[0906 13-41-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01836, current rewards: 111.44212, mean: 0.10513
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01836, current rewards: 115.77025, mean: 0.10430
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01834, current rewards: 122.22925, mean: 0.10537
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01833, current rewards: 128.69388, mean: 0.10636
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01834, current rewards: 135.41403, mean: 0.10747
[32m[0906 13-41-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01839, current rewards: 140.27919, mean: 0.10708
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01845, current rewards: 147.37574, mean: 0.10836
[32m[0906 13-41-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01848, current rewards: 154.47229, mean: 0.10955
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 161.56884, mean: 0.11066
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 168.66539, mean: 0.11170
[32m[0906 13-41-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 175.76194, mean: 0.11267
[32m[0906 13-41-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01865, current rewards: 182.85850, mean: 0.11358
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01868, current rewards: 188.75571, mean: 0.11371
[32m[0906 13-41-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01870, current rewards: 194.55094, mean: 0.11377
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01874, current rewards: 187.23904, mean: 0.10639
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: 193.76754, mean: 0.10705
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: 200.30067, mean: 0.10769
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01886, current rewards: 206.83657, mean: 0.10829
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01889, current rewards: 213.36456, mean: 0.10886
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 220.17659, mean: 0.10954
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01896, current rewards: 226.17746, mean: 0.10979
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01900, current rewards: 232.01604, mean: 0.10996
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01903, current rewards: 237.85360, mean: 0.11012
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01906, current rewards: 243.69343, mean: 0.11027
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 249.53583, mean: 0.11041
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 255.36994, mean: 0.11055
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 261.21174, mean: 0.11068
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 267.04122, mean: 0.11081
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01920, current rewards: 272.65676, mean: 0.11084
[32m[0906 13-41-52 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 13-41-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-41-52 @MBExp.py:227][0m Rewards obtained: [277.04392767385116], Lows: [3], Highs: [15], Total time: 92.84873999999999
[32m[0906 13-41-59 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-59 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02174, current rewards: -1.16982, mean: -0.11698
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02039, current rewards: 4.04691, mean: 0.06745
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02033, current rewards: 9.26041, mean: 0.08419
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02027, current rewards: 14.47077, mean: 0.09044
[32m[0906 13-42-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02026, current rewards: 19.68420, mean: 0.09373
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02028, current rewards: 24.90529, mean: 0.09579
[32m[0906 13-42-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02026, current rewards: 30.11913, mean: 0.09716
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02027, current rewards: 35.43476, mean: 0.09843
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02029, current rewards: 39.66229, mean: 0.09674
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02027, current rewards: 44.82547, mean: 0.09745
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02028, current rewards: 49.99622, mean: 0.09803
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02027, current rewards: 55.15378, mean: 0.09849
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02026, current rewards: 60.32156, mean: 0.09889
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02028, current rewards: 65.49104, mean: 0.09923
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02028, current rewards: 70.65614, mean: 0.09952
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02026, current rewards: 75.95256, mean: 0.09994
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02026, current rewards: 81.64526, mean: 0.10080
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02026, current rewards: 87.32716, mean: 0.10154
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02027, current rewards: 93.01109, mean: 0.10221
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02028, current rewards: 98.69224, mean: 0.10280
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02029, current rewards: 104.36783, mean: 0.10333
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02028, current rewards: 108.13438, mean: 0.10201
[32m[0906 13-42-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02025, current rewards: 114.02826, mean: 0.10273
[32m[0906 13-42-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02023, current rewards: 119.91881, mean: 0.10338
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02021, current rewards: 125.43790, mean: 0.10367
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02019, current rewards: 130.98729, mean: 0.10396
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02018, current rewards: 136.53658, mean: 0.10423
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02018, current rewards: 142.08803, mean: 0.10448
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02018, current rewards: 146.46044, mean: 0.10387
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02018, current rewards: 151.89818, mean: 0.10404
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02017, current rewards: 157.34208, mean: 0.10420
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02016, current rewards: 162.77730, mean: 0.10434
[32m[0906 13-42-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02016, current rewards: 168.51192, mean: 0.10467
[32m[0906 13-42-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02015, current rewards: 174.42141, mean: 0.10507
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02014, current rewards: 180.33195, mean: 0.10546
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02013, current rewards: 186.24434, mean: 0.10582
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02011, current rewards: 192.15836, mean: 0.10616
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02011, current rewards: 198.05874, mean: 0.10648
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02011, current rewards: 204.18844, mean: 0.10690
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02011, current rewards: 210.32265, mean: 0.10731
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02011, current rewards: 216.36010, mean: 0.10764
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02011, current rewards: 221.52720, mean: 0.10754
[32m[0906 13-42-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02011, current rewards: 226.66257, mean: 0.10742
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02011, current rewards: 231.79786, mean: 0.10731
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02011, current rewards: 236.93240, mean: 0.10721
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02012, current rewards: 242.05930, mean: 0.10711
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02013, current rewards: 247.19511, mean: 0.10701
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02013, current rewards: 252.33683, mean: 0.10692
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02013, current rewards: 257.47288, mean: 0.10684
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02014, current rewards: 262.60990, mean: 0.10675
[32m[0906 13-42-50 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 13-42-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-42-50 @MBExp.py:227][0m Rewards obtained: [266.7115806326638], Lows: [1], Highs: [4], Total time: 143.884629
[32m[0906 13-42-59 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-59 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02072, current rewards: 0.94582, mean: 0.09458
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02068, current rewards: 6.24520, mean: 0.10409
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02060, current rewards: 11.67884, mean: 0.10617
[32m[0906 13-43-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02053, current rewards: 17.11243, mean: 0.10695
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02056, current rewards: 22.54039, mean: 0.10734
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02049, current rewards: 27.97047, mean: 0.10758
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02046, current rewards: 33.40192, mean: 0.10775
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02042, current rewards: 37.76274, mean: 0.10490
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02041, current rewards: 43.06562, mean: 0.10504
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02042, current rewards: 48.36364, mean: 0.10514
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02042, current rewards: 53.66494, mean: 0.10523
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02042, current rewards: 58.97006, mean: 0.10530
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02041, current rewards: 64.27279, mean: 0.10537
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02041, current rewards: 69.57751, mean: 0.10542
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02041, current rewards: 74.93743, mean: 0.10555
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02040, current rewards: 80.34872, mean: 0.10572
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02038, current rewards: 85.75442, mean: 0.10587
[32m[0906 13-43-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02036, current rewards: 91.16992, mean: 0.10601
[32m[0906 13-43-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02032, current rewards: 96.57999, mean: 0.10613
[32m[0906 13-43-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02028, current rewards: 101.99876, mean: 0.10625
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02025, current rewards: 107.40300, mean: 0.10634
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02023, current rewards: 112.81725, mean: 0.10643
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02020, current rewards: 118.22871, mean: 0.10651
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02018, current rewards: 123.64075, mean: 0.10659
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02016, current rewards: 129.04721, mean: 0.10665
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02015, current rewards: 134.45745, mean: 0.10671
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02014, current rewards: 139.87936, mean: 0.10678
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02014, current rewards: 145.29056, mean: 0.10683
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02013, current rewards: 150.70906, mean: 0.10689
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02012, current rewards: 156.12031, mean: 0.10693
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02011, current rewards: 161.53292, mean: 0.10698
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02011, current rewards: 164.99397, mean: 0.10577
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02011, current rewards: 170.59030, mean: 0.10596
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02011, current rewards: 176.18967, mean: 0.10614
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02011, current rewards: 181.79160, mean: 0.10631
[32m[0906 13-43-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02010, current rewards: 187.38960, mean: 0.10647
[32m[0906 13-43-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02009, current rewards: 192.99210, mean: 0.10663
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02008, current rewards: 198.59189, mean: 0.10677
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02006, current rewards: 204.19598, mean: 0.10691
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02005, current rewards: 209.79318, mean: 0.10704
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02005, current rewards: 215.61376, mean: 0.10727
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02005, current rewards: 221.25391, mean: 0.10740
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02005, current rewards: 225.72549, mean: 0.10698
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02004, current rewards: 231.32147, mean: 0.10709
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02004, current rewards: 236.91682, mean: 0.10720
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02004, current rewards: 242.51187, mean: 0.10731
[32m[0906 13-43-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02004, current rewards: 248.10530, mean: 0.10740
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02004, current rewards: 253.70107, mean: 0.10750
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02003, current rewards: 259.22288, mean: 0.10756
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02003, current rewards: 264.78202, mean: 0.10763
[32m[0906 13-43-50 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-43-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-43-50 @MBExp.py:227][0m Rewards obtained: [269.23248672130825], Lows: [1], Highs: [2], Total time: 194.64525899999998
[32m[0906 13-44-01 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-01 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02019, current rewards: -1.11850, mean: -0.11185
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02046, current rewards: 4.23280, mean: 0.07055
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02052, current rewards: 9.55270, mean: 0.08684
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02047, current rewards: 14.87511, mean: 0.09297
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02041, current rewards: 20.19712, mean: 0.09618
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02041, current rewards: 25.52183, mean: 0.09816
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02039, current rewards: 29.84209, mean: 0.09626
[32m[0906 13-44-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02039, current rewards: 35.33608, mean: 0.09816
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02041, current rewards: 40.83149, mean: 0.09959
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02038, current rewards: 46.32557, mean: 0.10071
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02039, current rewards: 51.82011, mean: 0.10161
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02040, current rewards: 57.32032, mean: 0.10236
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02039, current rewards: 62.80762, mean: 0.10296
[32m[0906 13-44-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02038, current rewards: 68.30416, mean: 0.10349
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02034, current rewards: 73.80070, mean: 0.10394
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02031, current rewards: 79.35133, mean: 0.10441
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02029, current rewards: 84.85678, mean: 0.10476
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02026, current rewards: 90.57088, mean: 0.10531
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02023, current rewards: 95.96508, mean: 0.10546
[32m[0906 13-44-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02021, current rewards: 101.36222, mean: 0.10559
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02018, current rewards: 106.76146, mean: 0.10570
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02014, current rewards: 112.16399, mean: 0.10582
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02012, current rewards: 117.56195, mean: 0.10591
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02011, current rewards: 122.98859, mean: 0.10602
[32m[0906 13-44-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02010, current rewards: 128.40833, mean: 0.10612
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02010, current rewards: 133.83202, mean: 0.10622
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02010, current rewards: 139.25028, mean: 0.10630
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02009, current rewards: 144.73040, mean: 0.10642
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02008, current rewards: 150.36808, mean: 0.10664
[32m[0906 13-44-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02008, current rewards: 156.00016, mean: 0.10685
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02008, current rewards: 161.62894, mean: 0.10704
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02008, current rewards: 167.16924, mean: 0.10716
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02008, current rewards: 172.73268, mean: 0.10729
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02007, current rewards: 178.30145, mean: 0.10741
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02006, current rewards: 183.89563, mean: 0.10754
[32m[0906 13-44-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02006, current rewards: 189.47859, mean: 0.10766
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02005, current rewards: 195.06864, mean: 0.10777
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02005, current rewards: 200.65962, mean: 0.10788
[32m[0906 13-44-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02003, current rewards: 206.24838, mean: 0.10798
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02002, current rewards: 209.44641, mean: 0.10686
[32m[0906 13-44-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02001, current rewards: 214.63651, mean: 0.10678
[32m[0906 13-44-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02001, current rewards: 219.82613, mean: 0.10671
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02000, current rewards: 225.01605, mean: 0.10664
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02000, current rewards: 228.16343, mean: 0.10563
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02000, current rewards: 233.77686, mean: 0.10578
[32m[0906 13-44-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02000, current rewards: 239.38584, mean: 0.10592
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02000, current rewards: 245.00313, mean: 0.10606
[32m[0906 13-44-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02000, current rewards: 250.61169, mean: 0.10619
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02000, current rewards: 256.17304, mean: 0.10630
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02000, current rewards: 261.75897, mean: 0.10641
[32m[0906 13-44-52 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-44-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-44-52 @MBExp.py:227][0m Rewards obtained: [266.23618253467174], Lows: [1], Highs: [5], Total time: 245.317355
[32m[0906 13-45-05 @MBExp.py:144][0m ####################################################################
[32m[0906 13-45-05 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02022, current rewards: 1.06677, mean: 0.10668
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02023, current rewards: 6.41292, mean: 0.10688
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02023, current rewards: 11.75920, mean: 0.10690
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02021, current rewards: 17.10528, mean: 0.10691
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02021, current rewards: 22.45154, mean: 0.10691
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02028, current rewards: 27.79813, mean: 0.10692
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02031, current rewards: 33.09227, mean: 0.10675
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02032, current rewards: 38.41433, mean: 0.10671
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02030, current rewards: 43.73421, mean: 0.10667
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02030, current rewards: 47.96864, mean: 0.10428
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02024, current rewards: 53.59615, mean: 0.10509
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02022, current rewards: 59.22550, mean: 0.10576
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02019, current rewards: 64.85296, mean: 0.10632
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02016, current rewards: 70.47512, mean: 0.10678
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02014, current rewards: 75.98513, mean: 0.10702
[32m[0906 13-45-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02013, current rewards: 81.56478, mean: 0.10732
[32m[0906 13-45-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02009, current rewards: 87.14758, mean: 0.10759
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02005, current rewards: 92.73260, mean: 0.10783
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02002, current rewards: 98.32834, mean: 0.10805
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02001, current rewards: 103.91796, mean: 0.10825
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01998, current rewards: 109.46647, mean: 0.10838
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01998, current rewards: 114.97794, mean: 0.10847
[32m[0906 13-45-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01999, current rewards: 120.53757, mean: 0.10859
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01999, current rewards: 126.05774, mean: 0.10867
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01999, current rewards: 131.57950, mean: 0.10874
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01999, current rewards: 137.10447, mean: 0.10881
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02000, current rewards: 142.62795, mean: 0.10888
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02000, current rewards: 148.15877, mean: 0.10894
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01999, current rewards: 153.68380, mean: 0.10900
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01998, current rewards: 159.20997, mean: 0.10905
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01999, current rewards: 164.73813, mean: 0.10910
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01999, current rewards: 168.20353, mean: 0.10782
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01999, current rewards: 173.80980, mean: 0.10796
[32m[0906 13-45-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01998, current rewards: 179.41885, mean: 0.10808
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01998, current rewards: 185.02487, mean: 0.10820
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01998, current rewards: 190.63654, mean: 0.10832
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01998, current rewards: 196.24784, mean: 0.10842
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01998, current rewards: 201.85805, mean: 0.10853
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01998, current rewards: 207.47918, mean: 0.10863
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 213.30820, mean: 0.10883
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01997, current rewards: 219.04971, mean: 0.10898
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01997, current rewards: 224.78635, mean: 0.10912
[32m[0906 13-45-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01996, current rewards: 230.46393, mean: 0.10922
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01995, current rewards: 236.07754, mean: 0.10930
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01995, current rewards: 241.68902, mean: 0.10936
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01995, current rewards: 247.28851, mean: 0.10942
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01995, current rewards: 252.89698, mean: 0.10948
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01995, current rewards: 258.45571, mean: 0.10952
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01995, current rewards: 264.03801, mean: 0.10956
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01995, current rewards: 269.62004, mean: 0.10960
[32m[0906 13-45-56 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-45-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-45-56 @MBExp.py:227][0m Rewards obtained: [274.08716975875296], Lows: [1], Highs: [1], Total time: 295.874884
[32m[0906 13-46-12 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-12 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02062, current rewards: -0.00964, mean: -0.00096
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02033, current rewards: 5.72645, mean: 0.09544
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02036, current rewards: 11.50359, mean: 0.10458
[32m[0906 13-46-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02042, current rewards: 17.27621, mean: 0.10798
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02040, current rewards: 23.05200, mean: 0.10977
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02038, current rewards: 28.87075, mean: 0.11104
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02030, current rewards: 34.65734, mean: 0.11180
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02025, current rewards: 40.41739, mean: 0.11227
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02021, current rewards: 46.18801, mean: 0.11265
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02017, current rewards: 52.00467, mean: 0.11305
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02013, current rewards: 57.77178, mean: 0.11328
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02013, current rewards: 63.54272, mean: 0.11347
[32m[0906 13-46-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02011, current rewards: 69.30953, mean: 0.11362
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02009, current rewards: 75.08348, mean: 0.11376
[32m[0906 13-46-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02006, current rewards: 80.97646, mean: 0.11405
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02003, current rewards: 86.76728, mean: 0.11417
[32m[0906 13-46-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02001, current rewards: 92.85031, mean: 0.11463
[32m[0906 13-46-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01999, current rewards: 98.60636, mean: 0.11466
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01997, current rewards: 104.36471, mean: 0.11469
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01997, current rewards: 110.12289, mean: 0.11471
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01998, current rewards: 115.87630, mean: 0.11473
[32m[0906 13-46-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02000, current rewards: 121.63533, mean: 0.11475
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02000, current rewards: 127.44620, mean: 0.11482
[32m[0906 13-46-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02000, current rewards: 133.22330, mean: 0.11485
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02000, current rewards: 138.99426, mean: 0.11487
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01999, current rewards: 144.77060, mean: 0.11490
[32m[0906 13-46-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02000, current rewards: 149.22001, mean: 0.11391
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01999, current rewards: 156.31656, mean: 0.11494
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01998, current rewards: 163.41311, mean: 0.11590
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01997, current rewards: 170.50966, mean: 0.11679
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01998, current rewards: 175.00680, mean: 0.11590
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01998, current rewards: 125.00680, mean: 0.08013
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01998, current rewards: 75.00680, mean: 0.04659
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01998, current rewards: 25.00680, mean: 0.01506
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01998, current rewards: -24.99320, mean: -0.01462
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01998, current rewards: -74.99320, mean: -0.04261
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01999, current rewards: -124.99320, mean: -0.06906
[32m[0906 13-46-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01999, current rewards: -174.99320, mean: -0.09408
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01999, current rewards: -224.99320, mean: -0.11780
[32m[0906 13-46-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: -274.99320, mean: -0.14030
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: -324.99320, mean: -0.16169
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01998, current rewards: -374.99320, mean: -0.18204
[32m[0906 13-46-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01998, current rewards: -424.99320, mean: -0.20142
[32m[0906 13-46-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01998, current rewards: -474.99320, mean: -0.21990
[32m[0906 13-46-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01997, current rewards: -524.99320, mean: -0.23755
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01995, current rewards: -574.99320, mean: -0.25442
[32m[0906 13-46-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01995, current rewards: -624.99320, mean: -0.27056
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01994, current rewards: -674.99320, mean: -0.28601
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01994, current rewards: -724.99320, mean: -0.30083
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01994, current rewards: -774.99320, mean: -0.31504
[32m[0906 13-47-02 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-47-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-47-02 @MBExp.py:227][0m Rewards obtained: [-814.9932009024552], Lows: [1], Highs: [992], Total time: 346.404946
[32m[0906 13-47-20 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-20 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02070, current rewards: -1.12006, mean: -0.11201
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02018, current rewards: 4.43842, mean: 0.07397
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02002, current rewards: 10.00367, mean: 0.09094
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01998, current rewards: 15.55670, mean: 0.09723
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01990, current rewards: 21.11307, mean: 0.10054
[32m[0906 13-47-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01993, current rewards: 26.79520, mean: 0.10306
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01993, current rewards: 32.42013, mean: 0.10458
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01993, current rewards: 38.05397, mean: 0.10571
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01997, current rewards: 43.68733, mean: 0.10655
[32m[0906 13-47-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01997, current rewards: 49.36744, mean: 0.10732
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02000, current rewards: 54.94909, mean: 0.10774
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01999, current rewards: 60.52980, mean: 0.10809
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01995, current rewards: 66.11411, mean: 0.10838
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01991, current rewards: 71.67947, mean: 0.10861
[32m[0906 13-47-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01990, current rewards: 77.26899, mean: 0.10883
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01988, current rewards: 83.68449, mean: 0.11011
[32m[0906 13-47-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01986, current rewards: 89.13809, mean: 0.11005
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01986, current rewards: 94.59245, mean: 0.10999
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01986, current rewards: 100.04751, mean: 0.10994
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01987, current rewards: 105.49809, mean: 0.10989
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01988, current rewards: 110.94791, mean: 0.10985
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01988, current rewards: 116.40349, mean: 0.10981
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01988, current rewards: 121.82894, mean: 0.10976
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01989, current rewards: 127.31431, mean: 0.10975
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01989, current rewards: 132.80169, mean: 0.10975
[32m[0906 13-47-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01990, current rewards: 138.34803, mean: 0.10980
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01990, current rewards: 143.95730, mean: 0.10989
[32m[0906 13-47-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01989, current rewards: 149.56103, mean: 0.10997
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01990, current rewards: 155.17007, mean: 0.11005
[32m[0906 13-47-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01990, current rewards: 160.78329, mean: 0.11013
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01990, current rewards: 166.40059, mean: 0.11020
[32m[0906 13-47-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01990, current rewards: 172.01065, mean: 0.11026
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01990, current rewards: 177.61132, mean: 0.11032
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01991, current rewards: 181.11988, mean: 0.10911
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01991, current rewards: 186.69689, mean: 0.10918
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01991, current rewards: 192.27295, mean: 0.10925
[32m[0906 13-47-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01990, current rewards: 197.84964, mean: 0.10931
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01991, current rewards: 203.43024, mean: 0.10937
[32m[0906 13-47-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01990, current rewards: 209.05313, mean: 0.10945
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01991, current rewards: 214.65568, mean: 0.10952
[32m[0906 13-48-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01991, current rewards: 220.26133, mean: 0.10958
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01992, current rewards: 221.41745, mean: 0.10748
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01991, current rewards: 227.05099, mean: 0.10761
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01991, current rewards: 232.68363, mean: 0.10772
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01991, current rewards: 238.32111, mean: 0.10784
[32m[0906 13-48-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01991, current rewards: 243.95723, mean: 0.10795
[32m[0906 13-48-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01990, current rewards: 249.59047, mean: 0.10805
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01989, current rewards: 255.22584, mean: 0.10815
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01989, current rewards: 260.85510, mean: 0.10824
[32m[0906 13-48-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01989, current rewards: 266.77920, mean: 0.10845
[32m[0906 13-48-10 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-48-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-48-11 @MBExp.py:227][0m Rewards obtained: [271.1491610581648], Lows: [1], Highs: [6], Total time: 396.81462899999997
[32m[0906 13-48-31 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-31 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01948, current rewards: -0.06239, mean: -0.00624
[32m[0906 13-48-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02001, current rewards: 5.32401, mean: 0.08873
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01998, current rewards: 10.77921, mean: 0.09799
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02002, current rewards: 16.23255, mean: 0.10145
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02005, current rewards: 21.71686, mean: 0.10341
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02002, current rewards: 27.24400, mean: 0.10478
[32m[0906 13-48-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01997, current rewards: 32.68583, mean: 0.10544
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01995, current rewards: 38.12757, mean: 0.10591
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01997, current rewards: 43.56992, mean: 0.10627
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02000, current rewards: 49.01300, mean: 0.10655
[32m[0906 13-48-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01997, current rewards: 54.45353, mean: 0.10677
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01993, current rewards: 59.89142, mean: 0.10695
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01990, current rewards: 65.46158, mean: 0.10731
[32m[0906 13-48-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01989, current rewards: 70.97214, mean: 0.10753
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01988, current rewards: 76.46820, mean: 0.10770
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01987, current rewards: 81.95908, mean: 0.10784
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01988, current rewards: 87.40411, mean: 0.10791
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01989, current rewards: 92.83555, mean: 0.10795
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01989, current rewards: 98.26481, mean: 0.10798
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01990, current rewards: 103.69596, mean: 0.10802
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01990, current rewards: 109.12791, mean: 0.10805
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01990, current rewards: 114.52214, mean: 0.10804
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01991, current rewards: 119.93697, mean: 0.10805
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01991, current rewards: 125.34226, mean: 0.10805
[32m[0906 13-48-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01991, current rewards: 130.75603, mean: 0.10806
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01992, current rewards: 136.17689, mean: 0.10808
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 141.56068, mean: 0.10806
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01994, current rewards: 146.96524, mean: 0.10806
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01995, current rewards: 152.36009, mean: 0.10806
[32m[0906 13-49-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01994, current rewards: 157.67162, mean: 0.10799
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01994, current rewards: 163.04598, mean: 0.10798
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01994, current rewards: 168.42019, mean: 0.10796
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01994, current rewards: 173.57913, mean: 0.10781
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01994, current rewards: 178.73839, mean: 0.10767
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01995, current rewards: 183.89806, mean: 0.10754
[32m[0906 13-49-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01995, current rewards: 189.05630, mean: 0.10742
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01994, current rewards: 194.21569, mean: 0.10730
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01995, current rewards: 199.50166, mean: 0.10726
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01995, current rewards: 204.90817, mean: 0.10728
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01996, current rewards: 210.25329, mean: 0.10727
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01996, current rewards: 215.59995, mean: 0.10726
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01996, current rewards: 220.95083, mean: 0.10726
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01996, current rewards: 226.29640, mean: 0.10725
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01996, current rewards: 231.63864, mean: 0.10724
[32m[0906 13-49-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01997, current rewards: 236.98701, mean: 0.10723
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01997, current rewards: 242.33937, mean: 0.10723
[32m[0906 13-49-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01997, current rewards: 247.66602, mean: 0.10721
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01997, current rewards: 253.01393, mean: 0.10721
[32m[0906 13-49-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01997, current rewards: 258.38462, mean: 0.10721
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01996, current rewards: 263.78980, mean: 0.10723
[32m[0906 13-49-21 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-49-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-49-21 @MBExp.py:227][0m Rewards obtained: [268.1141149554705], Lows: [0], Highs: [1], Total time: 447.381395
[32m[0906 13-49-44 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-44 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02034, current rewards: 0.01850, mean: 0.00185
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01994, current rewards: 5.68275, mean: 0.09471
[32m[0906 13-49-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01991, current rewards: 11.34563, mean: 0.10314
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01983, current rewards: 17.00468, mean: 0.10628
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01981, current rewards: 22.73857, mean: 0.10828
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01986, current rewards: 28.41015, mean: 0.10927
[32m[0906 13-49-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01986, current rewards: 34.07942, mean: 0.10993
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01984, current rewards: 39.75341, mean: 0.11043
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01981, current rewards: 45.42683, mean: 0.11080
[32m[0906 13-49-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01978, current rewards: 49.11634, mean: 0.10677
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01974, current rewards: 55.57517, mean: 0.10897
[32m[0906 13-49-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01972, current rewards: 62.03399, mean: 0.11077
[32m[0906 13-49-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01970, current rewards: 68.94222, mean: 0.11302
[32m[0906 13-49-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01968, current rewards: 77.01651, mean: 0.11669
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01969, current rewards: 85.09080, mean: 0.11985
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01972, current rewards: 93.16509, mean: 0.12259
[32m[0906 13-50-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01974, current rewards: 101.23937, mean: 0.12499
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01975, current rewards: 64.01572, mean: 0.07444
[32m[0906 13-50-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01976, current rewards: 69.48827, mean: 0.07636
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01977, current rewards: 75.07944, mean: 0.07821
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01978, current rewards: 80.62374, mean: 0.07983
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01980, current rewards: 86.20398, mean: 0.08132
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01980, current rewards: 91.77865, mean: 0.08268
[32m[0906 13-50-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01982, current rewards: 97.35702, mean: 0.08393
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01982, current rewards: 102.93652, mean: 0.08507
[32m[0906 13-50-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01983, current rewards: 108.51067, mean: 0.08612
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01983, current rewards: 114.09117, mean: 0.08709
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01983, current rewards: 119.68257, mean: 0.08800
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01983, current rewards: 125.28273, mean: 0.08885
[32m[0906 13-50-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01981, current rewards: 130.81757, mean: 0.08960
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01981, current rewards: 136.40983, mean: 0.09034
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01982, current rewards: 141.99888, mean: 0.09102
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01982, current rewards: 147.58770, mean: 0.09167
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01982, current rewards: 153.18138, mean: 0.09228
[32m[0906 13-50-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01983, current rewards: 158.78030, mean: 0.09285
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01984, current rewards: 164.37448, mean: 0.09339
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01985, current rewards: 169.99876, mean: 0.09392
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01985, current rewards: 175.76941, mean: 0.09450
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01985, current rewards: 181.44565, mean: 0.09500
[32m[0906 13-50-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01986, current rewards: 187.12760, mean: 0.09547
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01986, current rewards: 192.79806, mean: 0.09592
[32m[0906 13-50-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01987, current rewards: 198.47147, mean: 0.09635
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01987, current rewards: 204.13731, mean: 0.09675
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01987, current rewards: 209.80943, mean: 0.09713
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01987, current rewards: 215.43458, mean: 0.09748
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01988, current rewards: 221.02195, mean: 0.09780
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01988, current rewards: 226.63194, mean: 0.09811
[32m[0906 13-50-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01989, current rewards: 232.25959, mean: 0.09842
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01990, current rewards: 237.88062, mean: 0.09871
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01990, current rewards: 243.50048, mean: 0.09898
[32m[0906 13-50-34 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-50-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-50-34 @MBExp.py:227][0m Rewards obtained: [248.0005142099038], Lows: [1], Highs: [40], Total time: 497.787039
[32m[0906 13-50-59 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-59 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01974, current rewards: 1.04151, mean: 0.10415
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01966, current rewards: 6.53695, mean: 0.10895
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01985, current rewards: 12.03079, mean: 0.10937
[32m[0906 13-51-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01991, current rewards: 17.52869, mean: 0.10955
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01990, current rewards: 22.94196, mean: 0.10925
[32m[0906 13-51-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01988, current rewards: 28.42708, mean: 0.10933
[32m[0906 13-51-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01983, current rewards: 33.88835, mean: 0.10932
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01981, current rewards: 39.31427, mean: 0.10921
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01980, current rewards: 44.73719, mean: 0.10912
[32m[0906 13-51-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01980, current rewards: 50.16191, mean: 0.10905
[32m[0906 13-51-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01977, current rewards: 55.58856, mean: 0.10900
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01977, current rewards: 61.01504, mean: 0.10896
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01978, current rewards: 66.41501, mean: 0.10888
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01980, current rewards: 71.83637, mean: 0.10884
[32m[0906 13-51-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01982, current rewards: 77.25813, mean: 0.10881
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01982, current rewards: 82.68140, mean: 0.10879
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01983, current rewards: 88.09871, mean: 0.10876
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01984, current rewards: 93.51790, mean: 0.10874
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01985, current rewards: 98.94340, mean: 0.10873
[32m[0906 13-51-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01986, current rewards: 104.36282, mean: 0.10871
[32m[0906 13-51-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01987, current rewards: 109.81084, mean: 0.10872
[32m[0906 13-51-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01987, current rewards: 115.23116, mean: 0.10871
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01988, current rewards: 120.65393, mean: 0.10870
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01988, current rewards: 126.07928, mean: 0.10869
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01987, current rewards: 129.14892, mean: 0.10673
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01988, current rewards: 134.25112, mean: 0.10655
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01988, current rewards: 139.35983, mean: 0.10638
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01988, current rewards: 144.46412, mean: 0.10622
[32m[0906 13-51-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01988, current rewards: 149.56493, mean: 0.10607
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01987, current rewards: 154.66788, mean: 0.10594
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01988, current rewards: 159.76652, mean: 0.10581
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01988, current rewards: 164.87077, mean: 0.10569
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01988, current rewards: 169.97438, mean: 0.10557
[32m[0906 13-51-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01988, current rewards: 175.07244, mean: 0.10547
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01989, current rewards: 180.17427, mean: 0.10537
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01990, current rewards: 185.27641, mean: 0.10527
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01990, current rewards: 190.36346, mean: 0.10517
[32m[0906 13-51-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01990, current rewards: 195.47362, mean: 0.10509
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01990, current rewards: 200.58021, mean: 0.10502
[32m[0906 13-51-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01990, current rewards: 205.68774, mean: 0.10494
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01990, current rewards: 210.78575, mean: 0.10487
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01990, current rewards: 216.13995, mean: 0.10492
[32m[0906 13-51-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01990, current rewards: 221.59123, mean: 0.10502
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01990, current rewards: 227.04161, mean: 0.10511
[32m[0906 13-51-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01990, current rewards: 232.51533, mean: 0.10521
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01990, current rewards: 238.03799, mean: 0.10533
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01990, current rewards: 243.48125, mean: 0.10540
[32m[0906 13-51-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01990, current rewards: 248.92031, mean: 0.10547
[32m[0906 13-51-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01991, current rewards: 254.36454, mean: 0.10555
[32m[0906 13-51-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01991, current rewards: 259.80494, mean: 0.10561
[32m[0906 13-51-49 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-51-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-51-49 @MBExp.py:227][0m Rewards obtained: [264.160214393126], Lows: [1], Highs: [0], Total time: 548.237831
[32m[0906 13-52-16 @MBExp.py:144][0m ####################################################################
[32m[0906 13-52-16 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01931, current rewards: 0.03254, mean: 0.00325
[32m[0906 13-52-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01942, current rewards: 5.57319, mean: 0.09289
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01950, current rewards: 11.12127, mean: 0.10110
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01937, current rewards: 16.67247, mean: 0.10420
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01943, current rewards: 22.21446, mean: 0.10578
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01947, current rewards: 27.76584, mean: 0.10679
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01951, current rewards: 33.31161, mean: 0.10746
[32m[0906 13-52-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01952, current rewards: 38.85778, mean: 0.10794
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01954, current rewards: 42.30690, mean: 0.10319
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01956, current rewards: 47.82574, mean: 0.10397
[32m[0906 13-52-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01962, current rewards: 53.34370, mean: 0.10460
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01964, current rewards: 58.89574, mean: 0.10517
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01967, current rewards: 64.41097, mean: 0.10559
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01972, current rewards: 69.92618, mean: 0.10595
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01975, current rewards: 75.44184, mean: 0.10626
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01976, current rewards: 80.95644, mean: 0.10652
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01977, current rewards: 85.36459, mean: 0.10539
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01978, current rewards: 90.92613, mean: 0.10573
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01980, current rewards: 96.48942, mean: 0.10603
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01981, current rewards: 102.05141, mean: 0.10630
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01982, current rewards: 107.61120, mean: 0.10655
[32m[0906 13-52-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01982, current rewards: 113.16954, mean: 0.10676
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01983, current rewards: 118.73068, mean: 0.10696
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01984, current rewards: 124.29609, mean: 0.10715
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01985, current rewards: 129.85560, mean: 0.10732
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01986, current rewards: 135.41909, mean: 0.10748
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01986, current rewards: 140.98166, mean: 0.10762
[32m[0906 13-52-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01986, current rewards: 146.46816, mean: 0.10770
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01985, current rewards: 152.00437, mean: 0.10780
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01984, current rewards: 157.53869, mean: 0.10790
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01985, current rewards: 163.07781, mean: 0.10800
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01986, current rewards: 168.61224, mean: 0.10808
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01987, current rewards: 174.15311, mean: 0.10817
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01988, current rewards: 179.69363, mean: 0.10825
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01988, current rewards: 185.23261, mean: 0.10832
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01988, current rewards: 190.77663, mean: 0.10840
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01987, current rewards: 196.31708, mean: 0.10846
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01987, current rewards: 201.86258, mean: 0.10853
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01988, current rewards: 207.39990, mean: 0.10859
[32m[0906 13-52-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01988, current rewards: 213.02040, mean: 0.10868
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01988, current rewards: 218.57997, mean: 0.10875
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01988, current rewards: 224.13763, mean: 0.10880
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01988, current rewards: 229.69581, mean: 0.10886
[32m[0906 13-52-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01988, current rewards: 235.25863, mean: 0.10892
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01987, current rewards: 240.81799, mean: 0.10897
[32m[0906 13-53-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01987, current rewards: 246.37487, mean: 0.10902
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01987, current rewards: 251.93442, mean: 0.10906
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01987, current rewards: 257.48964, mean: 0.10911
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01988, current rewards: 263.04423, mean: 0.10915
[32m[0906 13-53-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01988, current rewards: 268.59938, mean: 0.10919
[32m[0906 13-53-06 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-53-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-53-06 @MBExp.py:227][0m Rewards obtained: [273.04601144283237], Lows: [1], Highs: [2], Total time: 598.6118280000001
[32m[0906 13-53-35 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-35 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 13-53-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01937, current rewards: 0.02866, mean: 0.00287
[32m[0906 13-53-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: 5.67343, mean: 0.09456
[32m[0906 13-53-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 11.27566, mean: 0.10251
[32m[0906 13-53-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 16.89625, mean: 0.10560
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 22.51575, mean: 0.10722
[32m[0906 13-53-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 28.13444, mean: 0.10821
[32m[0906 13-53-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 33.75305, mean: 0.10888
[32m[0906 13-53-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 39.36823, mean: 0.10936
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 44.98735, mean: 0.10973
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01937, current rewards: 50.28784, mean: 0.10932
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01942, current rewards: 55.34699, mean: 0.10852
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01946, current rewards: 60.37262, mean: 0.10781
[32m[0906 13-53-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01950, current rewards: 65.39551, mean: 0.10721
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01954, current rewards: 70.42176, mean: 0.10670
[32m[0906 13-53-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01958, current rewards: 75.48809, mean: 0.10632
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01961, current rewards: 80.66595, mean: 0.10614
[32m[0906 13-53-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01964, current rewards: 85.84546, mean: 0.10598
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01965, current rewards: 91.02871, mean: 0.10585
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01968, current rewards: 96.48398, mean: 0.10603
[32m[0906 13-53-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01970, current rewards: 102.19212, mean: 0.10645
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01971, current rewards: 107.92874, mean: 0.10686
[32m[0906 13-53-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01971, current rewards: 113.66737, mean: 0.10723
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01973, current rewards: 119.40501, mean: 0.10757
[32m[0906 13-53-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01975, current rewards: 125.14134, mean: 0.10788
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01975, current rewards: 130.87716, mean: 0.10816
[32m[0906 13-54-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01976, current rewards: 136.61492, mean: 0.10842
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01977, current rewards: 142.35615, mean: 0.10867
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01977, current rewards: 148.44564, mean: 0.10915
[32m[0906 13-54-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01977, current rewards: 155.54220, mean: 0.11031
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01976, current rewards: 149.61790, mean: 0.10248
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01977, current rewards: 155.30596, mean: 0.10285
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01978, current rewards: 160.99478, mean: 0.10320
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01979, current rewards: 166.68146, mean: 0.10353
[32m[0906 13-54-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01980, current rewards: 172.37135, mean: 0.10384
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01980, current rewards: 178.05844, mean: 0.10413
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01980, current rewards: 183.71963, mean: 0.10439
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01980, current rewards: 189.38858, mean: 0.10463
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01980, current rewards: 195.03865, mean: 0.10486
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01981, current rewards: 200.65322, mean: 0.10505
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01981, current rewards: 206.27054, mean: 0.10524
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01981, current rewards: 211.88498, mean: 0.10542
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01982, current rewards: 217.50248, mean: 0.10558
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01982, current rewards: 223.11548, mean: 0.10574
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01982, current rewards: 228.73355, mean: 0.10590
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01982, current rewards: 234.34421, mean: 0.10604
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01982, current rewards: 239.64366, mean: 0.10604
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01983, current rewards: 244.66810, mean: 0.10592
[32m[0906 13-54-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01983, current rewards: 249.68809, mean: 0.10580
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01983, current rewards: 254.71205, mean: 0.10569
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01983, current rewards: 259.73028, mean: 0.10558
[32m[0906 13-54-25 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-54-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-54-26 @MBExp.py:227][0m Rewards obtained: [263.7460679423567], Lows: [0], Highs: [12], Total time: 648.8654750000001
[32m[0906 13-54-57 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-57 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 13-54-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01938, current rewards: 1.04357, mean: 0.10436
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01920, current rewards: 6.65195, mean: 0.11087
[32m[0906 13-54-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.26698, mean: 0.11152
[32m[0906 13-55-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01904, current rewards: 17.83808, mean: 0.11149
[32m[0906 13-55-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 23.42097, mean: 0.11153
[32m[0906 13-55-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 28.99767, mean: 0.11153
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.57397, mean: 0.11153
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 40.15264, mean: 0.11154
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 45.72994, mean: 0.11154
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 51.30222, mean: 0.11153
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01934, current rewards: 56.91775, mean: 0.11160
[32m[0906 13-55-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01939, current rewards: 62.47741, mean: 0.11157
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01943, current rewards: 68.03736, mean: 0.11154
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01947, current rewards: 73.60580, mean: 0.11152
[32m[0906 13-55-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01951, current rewards: 79.17458, mean: 0.11151
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01954, current rewards: 84.74075, mean: 0.11150
[32m[0906 13-55-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01958, current rewards: 90.31231, mean: 0.11150
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01960, current rewards: 95.87950, mean: 0.11149
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01961, current rewards: 101.62982, mean: 0.11168
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01962, current rewards: 107.18882, mean: 0.11166
[32m[0906 13-55-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01965, current rewards: 112.74952, mean: 0.11163
[32m[0906 13-55-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01966, current rewards: 118.30470, mean: 0.11161
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01966, current rewards: 123.86431, mean: 0.11159
[32m[0906 13-55-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01968, current rewards: 129.42347, mean: 0.11157
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01969, current rewards: 134.97800, mean: 0.11155
[32m[0906 13-55-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01969, current rewards: 140.53741, mean: 0.11154
[32m[0906 13-55-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01969, current rewards: 146.11909, mean: 0.11154
[32m[0906 13-55-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01969, current rewards: 150.57491, mean: 0.11072
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01969, current rewards: 156.13623, mean: 0.11073
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01970, current rewards: 161.70081, mean: 0.11075
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01971, current rewards: 167.26567, mean: 0.11077
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01973, current rewards: 172.81042, mean: 0.11078
[32m[0906 13-55-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01973, current rewards: 178.33939, mean: 0.11077
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01974, current rewards: 183.87024, mean: 0.11077
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01974, current rewards: 189.38368, mean: 0.11075
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01974, current rewards: 194.90330, mean: 0.11074
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01976, current rewards: 200.42609, mean: 0.11073
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01976, current rewards: 205.94333, mean: 0.11072
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01977, current rewards: 211.47093, mean: 0.11072
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01977, current rewards: 216.98819, mean: 0.11071
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01978, current rewards: 222.52421, mean: 0.11071
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01978, current rewards: 228.06190, mean: 0.11071
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01979, current rewards: 233.58506, mean: 0.11070
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01979, current rewards: 239.12049, mean: 0.11070
[32m[0906 13-55-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01979, current rewards: 244.62848, mean: 0.11069
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01980, current rewards: 250.15093, mean: 0.11069
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01981, current rewards: 255.67012, mean: 0.11068
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01981, current rewards: 261.18645, mean: 0.11067
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01982, current rewards: 266.70124, mean: 0.11066
[32m[0906 13-55-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01982, current rewards: 272.22047, mean: 0.11066
[32m[0906 13-55-47 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-55-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-55-47 @MBExp.py:227][0m Rewards obtained: [276.6405284748396], Lows: [0], Highs: [1], Total time: 699.1115560000001
[32m[0906 13-56-20 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-20 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 13-56-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01912, current rewards: -0.99981, mean: -0.09998
[32m[0906 13-56-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 4.56102, mean: 0.07602
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 10.20043, mean: 0.09273
[32m[0906 13-56-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 15.83868, mean: 0.09899
[32m[0906 13-56-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 21.47695, mean: 0.10227
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 27.11621, mean: 0.10429
[32m[0906 13-56-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01931, current rewards: 32.75482, mean: 0.10566
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01934, current rewards: 38.39621, mean: 0.10666
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01936, current rewards: 43.01588, mean: 0.10492
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01939, current rewards: 48.77478, mean: 0.10603
[32m[0906 13-56-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01940, current rewards: 54.60940, mean: 0.10708
[32m[0906 13-56-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01942, current rewards: 60.43987, mean: 0.10793
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01947, current rewards: 66.27377, mean: 0.10865
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01950, current rewards: 72.10569, mean: 0.10925
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01954, current rewards: 77.93755, mean: 0.10977
[32m[0906 13-56-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01956, current rewards: 83.74094, mean: 0.11019
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01959, current rewards: 89.37923, mean: 0.11034
[32m[0906 13-56-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01960, current rewards: 95.02886, mean: 0.11050
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01962, current rewards: 100.67424, mean: 0.11063
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01963, current rewards: 106.31393, mean: 0.11074
[32m[0906 13-56-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01964, current rewards: 111.95851, mean: 0.11085
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01965, current rewards: 117.58906, mean: 0.11093
[32m[0906 13-56-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01967, current rewards: 123.18917, mean: 0.11098
[32m[0906 13-56-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01969, current rewards: 128.78803, mean: 0.11102
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01970, current rewards: 134.38864, mean: 0.11106
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01972, current rewards: 140.08331, mean: 0.11118
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01971, current rewards: 145.63484, mean: 0.11117
[32m[0906 13-56-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01971, current rewards: 151.18653, mean: 0.11117
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01970, current rewards: 156.73395, mean: 0.11116
[32m[0906 13-56-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01971, current rewards: 162.28493, mean: 0.11115
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01971, current rewards: 167.83245, mean: 0.11115
[32m[0906 13-56-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01973, current rewards: 173.51804, mean: 0.11123
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01974, current rewards: 179.20104, mean: 0.11130
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01975, current rewards: 184.86560, mean: 0.11136
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01976, current rewards: 190.46692, mean: 0.11138
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01977, current rewards: 196.11343, mean: 0.11143
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01977, current rewards: 201.76180, mean: 0.11147
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01978, current rewards: 207.40356, mean: 0.11151
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01979, current rewards: 213.05285, mean: 0.11155
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01979, current rewards: 218.70375, mean: 0.11158
[32m[0906 13-57-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01980, current rewards: 224.34119, mean: 0.11161
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01980, current rewards: 229.98585, mean: 0.11164
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01981, current rewards: 235.55951, mean: 0.11164
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01982, current rewards: 241.19715, mean: 0.11167
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01982, current rewards: 246.82940, mean: 0.11169
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01982, current rewards: 252.45755, mean: 0.11171
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01982, current rewards: 258.17410, mean: 0.11176
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01983, current rewards: 263.99912, mean: 0.11186
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01983, current rewards: 269.83226, mean: 0.11196
[32m[0906 13-57-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01983, current rewards: 275.65669, mean: 0.11206
[32m[0906 13-57-10 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-57-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-57-10 @MBExp.py:227][0m Rewards obtained: [280.35716888175415], Lows: [1], Highs: [1], Total time: 749.3834330000001
[32m[0906 13-57-46 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-46 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01944, current rewards: 1.12529, mean: 0.11253
[32m[0906 13-57-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01929, current rewards: 6.62107, mean: 0.11035
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01926, current rewards: 12.10435, mean: 0.11004
[32m[0906 13-57-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01936, current rewards: 17.58604, mean: 0.10991
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01943, current rewards: 23.06764, mean: 0.10985
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01946, current rewards: 28.54925, mean: 0.10980
[32m[0906 13-57-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01949, current rewards: 32.02501, mean: 0.10331
[32m[0906 13-57-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01950, current rewards: 37.79924, mean: 0.10500
[32m[0906 13-57-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01952, current rewards: 43.58697, mean: 0.10631
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01955, current rewards: 49.40030, mean: 0.10739
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01956, current rewards: 55.21175, mean: 0.10826
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01956, current rewards: 61.01492, mean: 0.10896
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: 66.82191, mean: 0.10954
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01957, current rewards: 72.41535, mean: 0.10972
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01959, current rewards: 77.98270, mean: 0.10983
[32m[0906 13-58-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01963, current rewards: 83.54059, mean: 0.10992
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01965, current rewards: 89.10570, mean: 0.11001
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01966, current rewards: 94.69842, mean: 0.11011
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01969, current rewards: 100.27676, mean: 0.11019
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01971, current rewards: 105.85521, mean: 0.11027
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01972, current rewards: 111.43764, mean: 0.11033
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01975, current rewards: 117.08153, mean: 0.11045
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01976, current rewards: 122.77179, mean: 0.11061
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01977, current rewards: 128.46058, mean: 0.11074
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01978, current rewards: 134.15004, mean: 0.11087
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01979, current rewards: 139.69022, mean: 0.11087
[32m[0906 13-58-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01978, current rewards: 145.27972, mean: 0.11090
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01978, current rewards: 150.84262, mean: 0.11091
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01978, current rewards: 156.37072, mean: 0.11090
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01979, current rewards: 161.90226, mean: 0.11089
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01980, current rewards: 167.43132, mean: 0.11088
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01981, current rewards: 172.96231, mean: 0.11087
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01981, current rewards: 178.48996, mean: 0.11086
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01983, current rewards: 183.97577, mean: 0.11083
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01983, current rewards: 189.49205, mean: 0.11081
[32m[0906 13-58-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01984, current rewards: 195.01171, mean: 0.11080
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01985, current rewards: 200.50188, mean: 0.11077
[32m[0906 13-58-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01985, current rewards: 206.02312, mean: 0.11077
[32m[0906 13-58-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01985, current rewards: 211.54143, mean: 0.11075
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01986, current rewards: 217.06345, mean: 0.11075
[32m[0906 13-58-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01986, current rewards: 222.58592, mean: 0.11074
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01986, current rewards: 228.15798, mean: 0.11076
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01986, current rewards: 233.69459, mean: 0.11076
[32m[0906 13-58-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01986, current rewards: 239.22424, mean: 0.11075
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01987, current rewards: 244.75408, mean: 0.11075
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01987, current rewards: 250.28271, mean: 0.11074
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01987, current rewards: 255.81361, mean: 0.11074
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01987, current rewards: 261.34670, mean: 0.11074
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01987, current rewards: 266.88187, mean: 0.11074
[32m[0906 13-58-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01987, current rewards: 272.41518, mean: 0.11074
[32m[0906 13-58-36 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-58-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-58-36 @MBExp.py:227][0m Rewards obtained: [276.89919891478087], Lows: [0], Highs: [2], Total time: 799.7505140000001
[32m[0906 13-59-14 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-14 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 13-59-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02089, current rewards: 0.07923, mean: 0.00792
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01989, current rewards: 5.84420, mean: 0.09740
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01988, current rewards: 11.58118, mean: 0.10528
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01980, current rewards: 17.32262, mean: 0.10827
[32m[0906 13-59-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01977, current rewards: 23.06171, mean: 0.10982
[32m[0906 13-59-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01974, current rewards: 28.72648, mean: 0.11049
[32m[0906 13-59-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01975, current rewards: 34.31054, mean: 0.11068
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01973, current rewards: 39.89691, mean: 0.11082
[32m[0906 13-59-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01973, current rewards: 45.44220, mean: 0.11083
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01974, current rewards: 51.01435, mean: 0.11090
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01970, current rewards: 56.58798, mean: 0.11096
[32m[0906 13-59-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01967, current rewards: 62.16090, mean: 0.11100
[32m[0906 13-59-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01968, current rewards: 67.73348, mean: 0.11104
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01968, current rewards: 73.30386, mean: 0.11107
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01968, current rewards: 78.87846, mean: 0.11110
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01968, current rewards: 84.45051, mean: 0.11112
[32m[0906 13-59-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01970, current rewards: 90.07541, mean: 0.11120
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01972, current rewards: 95.68142, mean: 0.11126
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01974, current rewards: 101.29359, mean: 0.11131
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01976, current rewards: 106.90139, mean: 0.11136
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01976, current rewards: 112.50993, mean: 0.11140
[32m[0906 13-59-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01976, current rewards: 118.12068, mean: 0.11143
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01976, current rewards: 123.72631, mean: 0.11147
[32m[0906 13-59-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01977, current rewards: 129.33283, mean: 0.11149
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01977, current rewards: 134.90997, mean: 0.11150
[32m[0906 13-59-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01976, current rewards: 140.51760, mean: 0.11152
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01975, current rewards: 146.11809, mean: 0.11154
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01974, current rewards: 151.81884, mean: 0.11163
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01974, current rewards: 157.38885, mean: 0.11162
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01975, current rewards: 162.96154, mean: 0.11162
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01975, current rewards: 168.53319, mean: 0.11161
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01977, current rewards: 174.10051, mean: 0.11160
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01978, current rewards: 179.71049, mean: 0.11162
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01979, current rewards: 185.32119, mean: 0.11164
[32m[0906 13-59-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01979, current rewards: 190.89843, mean: 0.11164
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01978, current rewards: 196.47346, mean: 0.11163
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01979, current rewards: 202.05284, mean: 0.11163
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01980, current rewards: 207.62865, mean: 0.11163
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01980, current rewards: 213.20300, mean: 0.11162
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01981, current rewards: 218.81161, mean: 0.11164
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01981, current rewards: 224.41926, mean: 0.11165
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01982, current rewards: 229.97529, mean: 0.11164
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01983, current rewards: 235.57883, mean: 0.11165
[32m[0906 13-59-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01983, current rewards: 241.18542, mean: 0.11166
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01983, current rewards: 246.78509, mean: 0.11167
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01983, current rewards: 252.76971, mean: 0.11185
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01984, current rewards: 258.26696, mean: 0.11180
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01985, current rewards: 263.76114, mean: 0.11176
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01985, current rewards: 269.25732, mean: 0.11173
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01985, current rewards: 274.81876, mean: 0.11171
[32m[0906 14-00-04 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 14-00-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-00-04 @MBExp.py:227][0m Rewards obtained: [278.12404395922704], Lows: [0], Highs: [2], Total time: 850.084601
[32m[0906 14-00-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-00-44 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-00-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02045, current rewards: -0.03720, mean: -0.00372
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01981, current rewards: 5.51447, mean: 0.09191
[32m[0906 14-00-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01973, current rewards: 11.07159, mean: 0.10065
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01971, current rewards: 16.62714, mean: 0.10392
[32m[0906 14-00-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01971, current rewards: 22.18066, mean: 0.10562
[32m[0906 14-00-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01971, current rewards: 27.73235, mean: 0.10666
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01972, current rewards: 33.42941, mean: 0.10784
[32m[0906 14-00-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01971, current rewards: 39.07384, mean: 0.10854
[32m[0906 14-00-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01970, current rewards: 46.96096, mean: 0.11454
[32m[0906 14-00-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01968, current rewards: 55.26108, mean: 0.12013
[32m[0906 14-00-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01968, current rewards: 44.90516, mean: 0.08805
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01967, current rewards: -5.09484, mean: -0.00910
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01967, current rewards: -55.09484, mean: -0.09032
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01965, current rewards: -105.09484, mean: -0.15923
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01963, current rewards: -155.09484, mean: -0.21844
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01962, current rewards: -205.09484, mean: -0.26986
[32m[0906 14-01-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01961, current rewards: -220.67952, mean: -0.27244
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01961, current rewards: -215.02384, mean: -0.25003
[32m[0906 14-01-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01962, current rewards: -209.45003, mean: -0.23016
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01965, current rewards: -203.87556, mean: -0.21237
[32m[0906 14-01-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01967, current rewards: -198.30007, mean: -0.19634
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01968, current rewards: -192.72607, mean: -0.18182
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01970, current rewards: -187.14963, mean: -0.16860
[32m[0906 14-01-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01972, current rewards: -181.57665, mean: -0.15653
[32m[0906 14-01-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01971, current rewards: -176.00196, mean: -0.14546
[32m[0906 14-01-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01971, current rewards: -170.42715, mean: -0.13526
[32m[0906 14-01-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01970, current rewards: -164.85491, mean: -0.12584
[32m[0906 14-01-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01970, current rewards: -159.28687, mean: -0.11712
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01971, current rewards: -153.71369, mean: -0.10902
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01971, current rewards: -148.14030, mean: -0.10147
[32m[0906 14-01-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01972, current rewards: -142.56633, mean: -0.09441
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01973, current rewards: -136.99501, mean: -0.08782
[32m[0906 14-01-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01973, current rewards: -131.43390, mean: -0.08164
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01974, current rewards: -125.86736, mean: -0.07582
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01975, current rewards: -120.29775, mean: -0.07035
[32m[0906 14-01-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01975, current rewards: -114.72792, mean: -0.06519
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01975, current rewards: -109.17613, mean: -0.06032
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01976, current rewards: -103.61853, mean: -0.05571
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01977, current rewards: -98.05823, mean: -0.05134
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01978, current rewards: -92.49867, mean: -0.04719
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01978, current rewards: -86.94429, mean: -0.04326
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01979, current rewards: -81.38657, mean: -0.03951
[32m[0906 14-01-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01979, current rewards: -75.82877, mean: -0.03594
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01979, current rewards: -70.26858, mean: -0.03253
[32m[0906 14-01-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01980, current rewards: -64.70597, mean: -0.02928
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01980, current rewards: -59.09094, mean: -0.02615
[32m[0906 14-01-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01980, current rewards: -53.47354, mean: -0.02315
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01981, current rewards: -47.86015, mean: -0.02028
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01981, current rewards: -42.33225, mean: -0.01757
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01980, current rewards: -36.73387, mean: -0.01493
[32m[0906 14-01-34 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 14-01-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-01-34 @MBExp.py:227][0m Rewards obtained: [-32.25915029739749], Lows: [0], Highs: [286], Total time: 900.275305
[32m[0906 14-02-16 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-16 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-02-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01886, current rewards: 1.05067, mean: 0.10507
[32m[0906 14-02-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01934, current rewards: 6.46847, mean: 0.10781
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01945, current rewards: 11.95991, mean: 0.10873
[32m[0906 14-02-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01948, current rewards: 17.45078, mean: 0.10907
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01946, current rewards: 22.94018, mean: 0.10924
[32m[0906 14-02-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01951, current rewards: 28.43124, mean: 0.10935
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01953, current rewards: 34.07907, mean: 0.10993
[32m[0906 14-02-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01950, current rewards: 39.70499, mean: 0.11029
[32m[0906 14-02-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01955, current rewards: 45.23979, mean: 0.11034
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01953, current rewards: 50.77500, mean: 0.11038
[32m[0906 14-02-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01953, current rewards: 56.31092, mean: 0.11041
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: 61.84668, mean: 0.11044
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: 66.29018, mean: 0.10867
[32m[0906 14-02-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01956, current rewards: 71.87634, mean: 0.10890
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01956, current rewards: 77.45532, mean: 0.10909
[32m[0906 14-02-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01955, current rewards: 83.04133, mean: 0.10926
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01956, current rewards: 88.62207, mean: 0.10941
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: 94.20689, mean: 0.10954
[32m[0906 14-02-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01957, current rewards: 99.78999, mean: 0.10966
[32m[0906 14-02-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01956, current rewards: 105.37306, mean: 0.10976
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01957, current rewards: 110.95239, mean: 0.10985
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01961, current rewards: 116.50724, mean: 0.10991
[32m[0906 14-02-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01962, current rewards: 122.05120, mean: 0.10996
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01963, current rewards: 127.64357, mean: 0.11004
[32m[0906 14-02-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01964, current rewards: 133.20080, mean: 0.11008
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01963, current rewards: 138.75914, mean: 0.11013
[32m[0906 14-02-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01963, current rewards: 144.31745, mean: 0.11017
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01964, current rewards: 149.87214, mean: 0.11020
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01964, current rewards: 155.42871, mean: 0.11023
[32m[0906 14-02-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01965, current rewards: 160.98628, mean: 0.11026
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01967, current rewards: 166.53824, mean: 0.11029
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01969, current rewards: 172.08797, mean: 0.11031
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01970, current rewards: 177.64116, mean: 0.11034
[32m[0906 14-02-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01970, current rewards: 183.19955, mean: 0.11036
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01971, current rewards: 188.75420, mean: 0.11038
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01972, current rewards: 194.32744, mean: 0.11041
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01973, current rewards: 199.91850, mean: 0.11045
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01974, current rewards: 205.51222, mean: 0.11049
[32m[0906 14-02-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01974, current rewards: 211.10392, mean: 0.11053
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01974, current rewards: 216.68729, mean: 0.11055
[32m[0906 14-02-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01975, current rewards: 222.25613, mean: 0.11058
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01976, current rewards: 227.83918, mean: 0.11060
[32m[0906 14-02-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01977, current rewards: 233.42388, mean: 0.11063
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01977, current rewards: 239.08096, mean: 0.11069
[32m[0906 14-03-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01977, current rewards: 244.60387, mean: 0.11068
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01978, current rewards: 250.12334, mean: 0.11067
[32m[0906 14-03-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01978, current rewards: 255.64539, mean: 0.11067
[32m[0906 14-03-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01978, current rewards: 261.17133, mean: 0.11067
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01977, current rewards: 266.67427, mean: 0.11065
[32m[0906 14-03-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01977, current rewards: 272.21227, mean: 0.11066
[32m[0906 14-03-06 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 14-03-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-03-06 @MBExp.py:227][0m Rewards obtained: [276.64424446863444], Lows: [0], Highs: [1], Total time: 950.374388
[32m[0906 14-03-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-50 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02042, current rewards: -0.01431, mean: -0.00143
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01969, current rewards: 5.62224, mean: 0.09370
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01963, current rewards: 11.18070, mean: 0.10164
[32m[0906 14-03-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01964, current rewards: 16.74007, mean: 0.10463
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01964, current rewards: 22.29993, mean: 0.10619
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01966, current rewards: 27.86188, mean: 0.10716
[32m[0906 14-03-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01962, current rewards: 33.49726, mean: 0.10806
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01960, current rewards: 26.92538, mean: 0.07479
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01959, current rewards: -23.07462, mean: -0.05628
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01958, current rewards: -73.07462, mean: -0.15886
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01956, current rewards: -123.07462, mean: -0.24132
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01954, current rewards: -139.78838, mean: -0.24962
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: -134.25383, mean: -0.22009
[32m[0906 14-04-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01957, current rewards: -128.71833, mean: -0.19503
[32m[0906 14-04-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01957, current rewards: -123.19224, mean: -0.17351
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01956, current rewards: -117.66149, mean: -0.15482
[32m[0906 14-04-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01957, current rewards: -112.12527, mean: -0.13843
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: -106.59171, mean: -0.12394
[32m[0906 14-04-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01956, current rewards: -101.06328, mean: -0.11106
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01955, current rewards: -95.51495, mean: -0.09949
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01956, current rewards: -89.95680, mean: -0.08907
[32m[0906 14-04-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01956, current rewards: -84.39438, mean: -0.07962
[32m[0906 14-04-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01956, current rewards: -78.84386, mean: -0.07103
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01956, current rewards: -73.29817, mean: -0.06319
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01956, current rewards: -67.74005, mean: -0.05598
[32m[0906 14-04-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01958, current rewards: -62.17554, mean: -0.04935
[32m[0906 14-04-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01958, current rewards: -56.61361, mean: -0.04322
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01957, current rewards: -51.05013, mean: -0.03754
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01958, current rewards: -45.48353, mean: -0.03226
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01959, current rewards: -39.91646, mean: -0.02734
[32m[0906 14-04-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01960, current rewards: -34.37563, mean: -0.02277
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01962, current rewards: -28.80394, mean: -0.01846
[32m[0906 14-04-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01963, current rewards: -23.26613, mean: -0.01445
[32m[0906 14-04-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01965, current rewards: -17.72769, mean: -0.01068
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01965, current rewards: -12.18998, mean: -0.00713
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01966, current rewards: -6.65220, mean: -0.00378
[32m[0906 14-04-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01967, current rewards: -1.10973, mean: -0.00061
[32m[0906 14-04-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01968, current rewards: 4.42953, mean: 0.00238
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01968, current rewards: 10.01237, mean: 0.00524
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01969, current rewards: 15.58858, mean: 0.00795
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01969, current rewards: 21.15495, mean: 0.01052
[32m[0906 14-04-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01970, current rewards: 26.72995, mean: 0.01298
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01971, current rewards: 30.40939, mean: 0.01441
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01971, current rewards: 36.45465, mean: 0.01688
[32m[0906 14-04-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01971, current rewards: 42.49992, mean: 0.01923
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01971, current rewards: 48.54519, mean: 0.02148
[32m[0906 14-04-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01971, current rewards: 54.59045, mean: 0.02363
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01970, current rewards: 29.03763, mean: 0.01230
[32m[0906 14-04-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01970, current rewards: -20.96237, mean: -0.00870
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01970, current rewards: -70.96237, mean: -0.02885
[32m[0906 14-04-40 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-04-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-04-40 @MBExp.py:227][0m Rewards obtained: [-110.9623654310495], Lows: [1], Highs: [350], Total time: 1000.302459
[32m[0906 14-05-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-26 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-05-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: 1.09292, mean: 0.10929
[32m[0906 14-05-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01953, current rewards: 6.63119, mean: 0.11052
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01960, current rewards: 12.24588, mean: 0.11133
[32m[0906 14-05-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01956, current rewards: 17.86056, mean: 0.11163
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01959, current rewards: 23.47476, mean: 0.11178
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01959, current rewards: 29.09165, mean: 0.11189
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01962, current rewards: 34.77489, mean: 0.11218
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01962, current rewards: 40.37863, mean: 0.11216
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01965, current rewards: 45.97865, mean: 0.11214
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01966, current rewards: 51.58213, mean: 0.11214
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01965, current rewards: 57.18344, mean: 0.11212
[32m[0906 14-05-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01964, current rewards: 62.78928, mean: 0.11212
[32m[0906 14-05-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01963, current rewards: 68.38870, mean: 0.11211
[32m[0906 14-05-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01963, current rewards: 73.99234, mean: 0.11211
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01962, current rewards: 78.44601, mean: 0.11049
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01960, current rewards: 84.00671, mean: 0.11054
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01960, current rewards: 89.57307, mean: 0.11058
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01960, current rewards: 95.14554, mean: 0.11063
[32m[0906 14-05-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01961, current rewards: 100.70461, mean: 0.11066
[32m[0906 14-05-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01961, current rewards: 106.27356, mean: 0.11070
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01960, current rewards: 111.83798, mean: 0.11073
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01960, current rewards: 117.39899, mean: 0.11075
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01958, current rewards: 122.95016, mean: 0.11077
[32m[0906 14-05-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01957, current rewards: 128.51046, mean: 0.11078
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01956, current rewards: 134.07082, mean: 0.11080
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01956, current rewards: 139.63714, mean: 0.11082
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01956, current rewards: 145.20003, mean: 0.11084
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01958, current rewards: 150.76647, mean: 0.11086
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01959, current rewards: 156.27856, mean: 0.11084
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01960, current rewards: 161.81578, mean: 0.11083
[32m[0906 14-05-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01962, current rewards: 167.35739, mean: 0.11083
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01962, current rewards: 172.90363, mean: 0.11084
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01963, current rewards: 178.44463, mean: 0.11084
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01964, current rewards: 183.98281, mean: 0.11083
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01965, current rewards: 189.52009, mean: 0.11083
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01966, current rewards: 195.06247, mean: 0.11083
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01967, current rewards: 200.60448, mean: 0.11083
[32m[0906 14-06-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01968, current rewards: 206.14386, mean: 0.11083
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01969, current rewards: 211.68729, mean: 0.11083
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01970, current rewards: 217.22376, mean: 0.11083
[32m[0906 14-06-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01971, current rewards: 222.75876, mean: 0.11083
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01971, current rewards: 228.30177, mean: 0.11083
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01972, current rewards: 233.84474, mean: 0.11083
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01971, current rewards: 239.38008, mean: 0.11082
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01971, current rewards: 244.90042, mean: 0.11081
[32m[0906 14-06-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01971, current rewards: 250.41625, mean: 0.11080
[32m[0906 14-06-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01971, current rewards: 255.97935, mean: 0.11081
[32m[0906 14-06-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01971, current rewards: 261.56784, mean: 0.11083
[32m[0906 14-06-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01970, current rewards: 267.10130, mean: 0.11083
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01970, current rewards: 272.63593, mean: 0.11083
[32m[0906 14-06-16 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-06-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-06-16 @MBExp.py:227][0m Rewards obtained: [277.0624919275548], Lows: [0], Highs: [1], Total time: 1050.229829
[32m[0906 14-07-05 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-05 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-07-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02014, current rewards: 1.22281, mean: 0.12228
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01978, current rewards: 6.79528, mean: 0.11325
[32m[0906 14-07-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01974, current rewards: 12.36157, mean: 0.11238
[32m[0906 14-07-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01972, current rewards: 17.92788, mean: 0.11205
[32m[0906 14-07-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01974, current rewards: 23.49989, mean: 0.11190
[32m[0906 14-07-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01972, current rewards: 29.04037, mean: 0.11169
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01972, current rewards: 34.64594, mean: 0.11176
[32m[0906 14-07-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01971, current rewards: 40.25050, mean: 0.11181
[32m[0906 14-07-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01970, current rewards: 45.85337, mean: 0.11184
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01969, current rewards: 51.45664, mean: 0.11186
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01967, current rewards: 57.06139, mean: 0.11189
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01967, current rewards: 62.66960, mean: 0.11191
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01966, current rewards: 68.26220, mean: 0.11191
[32m[0906 14-07-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01966, current rewards: 73.80979, mean: 0.11183
[32m[0906 14-07-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01964, current rewards: 79.29720, mean: 0.11169
[32m[0906 14-07-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01963, current rewards: 84.78064, mean: 0.11155
[32m[0906 14-07-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01962, current rewards: 90.26758, mean: 0.11144
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01961, current rewards: 95.75225, mean: 0.11134
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01961, current rewards: 101.23558, mean: 0.11125
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01962, current rewards: 106.71833, mean: 0.11116
[32m[0906 14-07-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01962, current rewards: 112.20920, mean: 0.11110
[32m[0906 14-07-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01960, current rewards: 117.82300, mean: 0.11115
[32m[0906 14-07-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01958, current rewards: 123.42769, mean: 0.11120
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01956, current rewards: 128.99597, mean: 0.11120
[32m[0906 14-07-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01954, current rewards: 134.56431, mean: 0.11121
[32m[0906 14-07-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01953, current rewards: 140.13261, mean: 0.11122
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01952, current rewards: 145.70102, mean: 0.11122
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01954, current rewards: 151.26926, mean: 0.11123
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01956, current rewards: 152.36945, mean: 0.10806
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01957, current rewards: 157.93498, mean: 0.10817
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01958, current rewards: 163.40277, mean: 0.10821
[32m[0906 14-07-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01959, current rewards: 168.94479, mean: 0.10830
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01960, current rewards: 174.48747, mean: 0.10838
[32m[0906 14-07-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01960, current rewards: 180.03299, mean: 0.10845
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01961, current rewards: 185.57757, mean: 0.10852
[32m[0906 14-07-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01963, current rewards: 191.11926, mean: 0.10859
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01964, current rewards: 196.77410, mean: 0.10871
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01966, current rewards: 202.34606, mean: 0.10879
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01967, current rewards: 207.92484, mean: 0.10886
[32m[0906 14-07-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01968, current rewards: 213.49238, mean: 0.10892
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01969, current rewards: 219.06481, mean: 0.10899
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01968, current rewards: 224.63590, mean: 0.10905
[32m[0906 14-07-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01969, current rewards: 230.20482, mean: 0.10910
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01969, current rewards: 235.77455, mean: 0.10915
[32m[0906 14-07-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01968, current rewards: 241.33532, mean: 0.10920
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01968, current rewards: 246.87568, mean: 0.10924
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01968, current rewards: 252.48637, mean: 0.10930
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01967, current rewards: 258.06414, mean: 0.10935
[32m[0906 14-07-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01967, current rewards: 263.62603, mean: 0.10939
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01966, current rewards: 269.19169, mean: 0.10943
[32m[0906 14-07-55 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-07-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-07-55 @MBExp.py:227][0m Rewards obtained: [273.6442469951006], Lows: [0], Highs: [4], Total time: 1100.0647430000001
[32m[0906 14-08-45 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-45 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01921, current rewards: 1.07089, mean: 0.10709
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01966, current rewards: 6.60642, mean: 0.11011
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01962, current rewards: 12.13941, mean: 0.11036
[32m[0906 14-08-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01957, current rewards: 17.67121, mean: 0.11045
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01957, current rewards: 23.20198, mean: 0.11049
[32m[0906 14-08-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01956, current rewards: 28.82037, mean: 0.11085
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01957, current rewards: 34.35587, mean: 0.11083
[32m[0906 14-08-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01957, current rewards: 39.89320, mean: 0.11081
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01960, current rewards: 45.43644, mean: 0.11082
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01960, current rewards: 50.96909, mean: 0.11080
[32m[0906 14-08-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01960, current rewards: 56.50276, mean: 0.11079
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01960, current rewards: 62.03845, mean: 0.11078
[32m[0906 14-08-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01962, current rewards: 67.57969, mean: 0.11079
[32m[0906 14-08-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01960, current rewards: 73.11609, mean: 0.11078
[32m[0906 14-09-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01960, current rewards: 78.65306, mean: 0.11078
[32m[0906 14-09-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01961, current rewards: 84.19054, mean: 0.11078
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01962, current rewards: 89.72719, mean: 0.11077
[32m[0906 14-09-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01962, current rewards: 95.26773, mean: 0.11078
[32m[0906 14-09-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01961, current rewards: 100.83467, mean: 0.11081
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01961, current rewards: 106.35362, mean: 0.11079
[32m[0906 14-09-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01961, current rewards: 111.87086, mean: 0.11076
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01959, current rewards: 117.33571, mean: 0.11069
[32m[0906 14-09-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01957, current rewards: 122.85224, mean: 0.11068
[32m[0906 14-09-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01954, current rewards: 128.36809, mean: 0.11066
[32m[0906 14-09-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01953, current rewards: 133.88773, mean: 0.11065
[32m[0906 14-09-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01952, current rewards: 139.48842, mean: 0.11071
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01950, current rewards: 144.98023, mean: 0.11067
[32m[0906 14-09-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01950, current rewards: 150.47370, mean: 0.11064
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01950, current rewards: 155.96633, mean: 0.11061
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01951, current rewards: 161.45834, mean: 0.11059
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01953, current rewards: 166.95072, mean: 0.11056
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01955, current rewards: 172.44123, mean: 0.11054
[32m[0906 14-09-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01956, current rewards: 177.93543, mean: 0.11052
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01957, current rewards: 183.42699, mean: 0.11050
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01958, current rewards: 187.86323, mean: 0.10986
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01959, current rewards: 193.40738, mean: 0.10989
[32m[0906 14-09-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01960, current rewards: 198.95134, mean: 0.10992
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01961, current rewards: 204.45483, mean: 0.10992
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01962, current rewards: 209.98912, mean: 0.10994
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01962, current rewards: 215.53084, mean: 0.10996
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01962, current rewards: 221.07351, mean: 0.10999
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01962, current rewards: 226.61055, mean: 0.11001
[32m[0906 14-09-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01962, current rewards: 232.14930, mean: 0.11002
[32m[0906 14-09-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01961, current rewards: 237.68544, mean: 0.11004
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01962, current rewards: 243.22312, mean: 0.11006
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01962, current rewards: 248.75804, mean: 0.11007
[32m[0906 14-09-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01962, current rewards: 254.30693, mean: 0.11009
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01962, current rewards: 259.85050, mean: 0.11011
[32m[0906 14-09-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01962, current rewards: 265.35729, mean: 0.11011
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01962, current rewards: 270.87364, mean: 0.11011
[32m[0906 14-09-35 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-09-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-09-35 @MBExp.py:227][0m Rewards obtained: [275.2820707643431], Lows: [0], Highs: [1], Total time: 1149.793468
[32m[0906 14-10-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-28 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02040, current rewards: 1.07962, mean: 0.10796
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01968, current rewards: 6.57228, mean: 0.10954
[32m[0906 14-10-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01958, current rewards: 12.02899, mean: 0.10935
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01952, current rewards: 17.48637, mean: 0.10929
[32m[0906 14-10-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01948, current rewards: 20.69434, mean: 0.09854
[32m[0906 14-10-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01949, current rewards: 26.23156, mean: 0.10089
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01951, current rewards: 31.76879, mean: 0.10248
[32m[0906 14-10-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01954, current rewards: 37.30148, mean: 0.10362
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01955, current rewards: 42.83863, mean: 0.10448
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01956, current rewards: 48.37076, mean: 0.10515
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01955, current rewards: 53.90386, mean: 0.10569
[32m[0906 14-10-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: 59.57865, mean: 0.10639
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01955, current rewards: 65.00485, mean: 0.10657
[32m[0906 14-10-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01957, current rewards: 70.55020, mean: 0.10689
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01957, current rewards: 76.09463, mean: 0.10718
[32m[0906 14-10-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01958, current rewards: 81.63481, mean: 0.10741
[32m[0906 14-10-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01957, current rewards: 87.18253, mean: 0.10763
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: 92.72613, mean: 0.10782
[32m[0906 14-10-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01956, current rewards: 98.26948, mean: 0.10799
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01956, current rewards: 103.81499, mean: 0.10814
[32m[0906 14-10-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01954, current rewards: 109.38943, mean: 0.10831
[32m[0906 14-10-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01952, current rewards: 115.05024, mean: 0.10854
[32m[0906 14-10-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01950, current rewards: 120.62300, mean: 0.10867
[32m[0906 14-10-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01949, current rewards: 126.16343, mean: 0.10876
[32m[0906 14-10-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01947, current rewards: 131.71742, mean: 0.10886
[32m[0906 14-10-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01946, current rewards: 137.27136, mean: 0.10895
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01945, current rewards: 142.82946, mean: 0.10903
[32m[0906 14-10-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01946, current rewards: 148.38560, mean: 0.10911
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01946, current rewards: 153.99873, mean: 0.10922
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01946, current rewards: 159.57532, mean: 0.10930
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01946, current rewards: 165.23992, mean: 0.10943
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01949, current rewards: 170.91022, mean: 0.10956
[32m[0906 14-11-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01950, current rewards: 176.58173, mean: 0.10968
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01952, current rewards: 182.25421, mean: 0.10979
[32m[0906 14-11-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01954, current rewards: 187.93228, mean: 0.10990
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01955, current rewards: 193.60432, mean: 0.11000
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01956, current rewards: 199.27596, mean: 0.11010
[32m[0906 14-11-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01956, current rewards: 204.94112, mean: 0.11018
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01957, current rewards: 210.71536, mean: 0.11032
[32m[0906 14-11-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01957, current rewards: 216.38535, mean: 0.11040
[32m[0906 14-11-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01957, current rewards: 221.97910, mean: 0.11044
[32m[0906 14-11-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01957, current rewards: 227.53110, mean: 0.11045
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01957, current rewards: 233.08774, mean: 0.11047
[32m[0906 14-11-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01957, current rewards: 238.64288, mean: 0.11048
[32m[0906 14-11-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01957, current rewards: 244.19430, mean: 0.11050
[32m[0906 14-11-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01957, current rewards: 249.78974, mean: 0.11053
[32m[0906 14-11-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01957, current rewards: 255.34098, mean: 0.11054
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01957, current rewards: 260.87685, mean: 0.11054
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01957, current rewards: 266.41201, mean: 0.11054
[32m[0906 14-11-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01957, current rewards: 271.94621, mean: 0.11055
[32m[0906 14-11-18 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-11-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-11-18 @MBExp.py:227][0m Rewards obtained: [276.3758846473595], Lows: [0], Highs: [2], Total time: 1199.4158400000001
[32m[0906 14-12-13 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-13 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01944, current rewards: 1.13985, mean: 0.11398
[32m[0906 14-12-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01957, current rewards: 6.64892, mean: 0.11082
[32m[0906 14-12-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01964, current rewards: 12.16194, mean: 0.11056
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01957, current rewards: 17.67145, mean: 0.11045
[32m[0906 14-12-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01957, current rewards: 23.15629, mean: 0.11027
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01953, current rewards: 28.55414, mean: 0.10982
[32m[0906 14-12-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01954, current rewards: 33.99081, mean: 0.10965
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01956, current rewards: 39.94454, mean: 0.11096
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01955, current rewards: 45.51209, mean: 0.11101
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01957, current rewards: 51.08412, mean: 0.11105
[32m[0906 14-12-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01957, current rewards: 56.65247, mean: 0.11108
[32m[0906 14-12-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01958, current rewards: 62.21989, mean: 0.11111
[32m[0906 14-12-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01958, current rewards: 67.78905, mean: 0.11113
[32m[0906 14-12-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01960, current rewards: 73.35720, mean: 0.11115
[32m[0906 14-12-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01960, current rewards: 78.92391, mean: 0.11116
[32m[0906 14-12-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01959, current rewards: 84.49204, mean: 0.11117
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01959, current rewards: 90.06306, mean: 0.11119
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01959, current rewards: 95.62954, mean: 0.11120
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01958, current rewards: 101.19171, mean: 0.11120
[32m[0906 14-12-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01959, current rewards: 106.72606, mean: 0.11117
[32m[0906 14-12-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01956, current rewards: 112.26399, mean: 0.11115
[32m[0906 14-12-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01954, current rewards: 117.82384, mean: 0.11115
[32m[0906 14-12-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01951, current rewards: 123.34894, mean: 0.11113
[32m[0906 14-12-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01950, current rewards: 128.87496, mean: 0.11110
[32m[0906 14-12-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01948, current rewards: 134.40014, mean: 0.11107
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01947, current rewards: 139.92561, mean: 0.11105
[32m[0906 14-12-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01945, current rewards: 145.63530, mean: 0.11117
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01945, current rewards: 151.22628, mean: 0.11120
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01945, current rewards: 156.81972, mean: 0.11122
[32m[0906 14-12-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01946, current rewards: 162.48551, mean: 0.11129
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01947, current rewards: 166.84381, mean: 0.11049
[32m[0906 14-12-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01947, current rewards: 174.91809, mean: 0.11213
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01948, current rewards: 182.99238, mean: 0.11366
[32m[0906 14-12-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01950, current rewards: 191.06667, mean: 0.11510
[32m[0906 14-12-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01951, current rewards: 199.14095, mean: 0.11646
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01951, current rewards: 207.21524, mean: 0.11774
[32m[0906 14-12-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01951, current rewards: 215.28953, mean: 0.11894
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01951, current rewards: 174.58141, mean: 0.09386
[32m[0906 14-12-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01952, current rewards: 124.58141, mean: 0.06523
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01951, current rewards: 74.58141, mean: 0.03805
[32m[0906 14-12-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01951, current rewards: 24.58141, mean: 0.01223
[32m[0906 14-12-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01951, current rewards: -25.41859, mean: -0.01234
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01951, current rewards: -75.41859, mean: -0.03574
[32m[0906 14-12-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01951, current rewards: -125.41859, mean: -0.05806
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01951, current rewards: -175.41859, mean: -0.07937
[32m[0906 14-12-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01952, current rewards: -225.41859, mean: -0.09974
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01952, current rewards: -275.41859, mean: -0.11923
[32m[0906 14-13-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01952, current rewards: -325.41859, mean: -0.13789
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01952, current rewards: -375.41859, mean: -0.15578
[32m[0906 14-13-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01952, current rewards: -425.41859, mean: -0.17293
[32m[0906 14-13-02 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-13-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-13-02 @MBExp.py:227][0m Rewards obtained: [-465.41858757039046], Lows: [1], Highs: [682], Total time: 1248.89423
[32m[0906 14-14-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-14-00 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01958, current rewards: 1.10778, mean: 0.11078
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01987, current rewards: 6.67508, mean: 0.11125
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01986, current rewards: 12.24012, mean: 0.11127
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01975, current rewards: 17.80910, mean: 0.11131
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01970, current rewards: 23.32187, mean: 0.11106
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01966, current rewards: 28.88399, mean: 0.11109
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01964, current rewards: 34.44491, mean: 0.11111
[32m[0906 14-14-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01965, current rewards: 40.01353, mean: 0.11115
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01964, current rewards: 45.56978, mean: 0.11115
[32m[0906 14-14-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01965, current rewards: 51.12837, mean: 0.11115
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01965, current rewards: 56.68742, mean: 0.11115
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01965, current rewards: 62.24057, mean: 0.11114
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01964, current rewards: 67.83128, mean: 0.11120
[32m[0906 14-14-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01962, current rewards: 73.49567, mean: 0.11136
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01962, current rewards: 79.06496, mean: 0.11136
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01962, current rewards: 84.61152, mean: 0.11133
[32m[0906 14-14-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01961, current rewards: 90.16104, mean: 0.11131
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01960, current rewards: 95.70109, mean: 0.11128
[32m[0906 14-14-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01961, current rewards: 101.24689, mean: 0.11126
[32m[0906 14-14-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01959, current rewards: 107.35897, mean: 0.11183
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01956, current rewards: 113.27685, mean: 0.11216
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01954, current rewards: 112.60550, mean: 0.10623
[32m[0906 14-14-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01953, current rewards: 118.13689, mean: 0.10643
[32m[0906 14-14-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01952, current rewards: 123.67054, mean: 0.10661
[32m[0906 14-14-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01950, current rewards: 129.20473, mean: 0.10678
[32m[0906 14-14-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01949, current rewards: 134.73839, mean: 0.10694
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01947, current rewards: 140.27510, mean: 0.10708
[32m[0906 14-14-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01947, current rewards: 145.80797, mean: 0.10721
[32m[0906 14-14-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01948, current rewards: 151.42011, mean: 0.10739
[32m[0906 14-14-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01950, current rewards: 157.03207, mean: 0.10756
[32m[0906 14-14-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01949, current rewards: 162.64138, mean: 0.10771
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01949, current rewards: 168.26590, mean: 0.10786
[32m[0906 14-14-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01949, current rewards: 173.87628, mean: 0.10800
[32m[0906 14-14-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01949, current rewards: 179.48894, mean: 0.10813
[32m[0906 14-14-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01948, current rewards: 185.10576, mean: 0.10825
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01948, current rewards: 190.72322, mean: 0.10837
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01948, current rewards: 196.33729, mean: 0.10847
[32m[0906 14-14-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01949, current rewards: 201.95438, mean: 0.10858
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01949, current rewards: 207.62955, mean: 0.10871
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01950, current rewards: 213.26719, mean: 0.10881
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01950, current rewards: 218.77498, mean: 0.10884
[32m[0906 14-14-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01950, current rewards: 224.29422, mean: 0.10888
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01950, current rewards: 229.81482, mean: 0.10892
[32m[0906 14-14-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01950, current rewards: 235.33723, mean: 0.10895
[32m[0906 14-14-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01950, current rewards: 240.85414, mean: 0.10898
[32m[0906 14-14-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01951, current rewards: 246.37617, mean: 0.10902
[32m[0906 14-14-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01950, current rewards: 252.00150, mean: 0.10909
[32m[0906 14-14-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01950, current rewards: 257.54032, mean: 0.10913
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01951, current rewards: 263.07700, mean: 0.10916
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01952, current rewards: 268.61699, mean: 0.10919
[32m[0906 14-14-49 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-14-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-14-49 @MBExp.py:227][0m Rewards obtained: [273.0489889654804], Lows: [0], Highs: [5], Total time: 1298.3749730000002
[32m[0906 14-15-49 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-49 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-15-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01949, current rewards: 1.09413, mean: 0.10941
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01958, current rewards: 6.64537, mean: 0.11076
[32m[0906 14-15-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01947, current rewards: 12.18288, mean: 0.11075
[32m[0906 14-15-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01952, current rewards: 17.72051, mean: 0.11075
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01954, current rewards: 23.26250, mean: 0.11077
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01956, current rewards: 29.14279, mean: 0.11209
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01957, current rewards: 35.06067, mean: 0.11310
[32m[0906 14-15-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01956, current rewards: 40.97854, mean: 0.11383
[32m[0906 14-15-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01957, current rewards: 42.42299, mean: 0.10347
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01956, current rewards: -7.57701, mean: -0.01647
[32m[0906 14-15-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01955, current rewards: -57.57701, mean: -0.11290
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: -107.57701, mean: -0.19210
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: -157.57701, mean: -0.25832
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01957, current rewards: -207.57701, mean: -0.31451
[32m[0906 14-16-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01958, current rewards: -257.57701, mean: -0.36278
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01957, current rewards: -307.57701, mean: -0.40471
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01956, current rewards: -357.57701, mean: -0.44145
[32m[0906 14-16-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: -407.57701, mean: -0.47393
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01957, current rewards: -457.57701, mean: -0.50283
[32m[0906 14-16-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01956, current rewards: -507.57701, mean: -0.52873
[32m[0906 14-16-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01954, current rewards: -557.57701, mean: -0.55206
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01952, current rewards: -607.57701, mean: -0.57319
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01950, current rewards: -657.57701, mean: -0.59241
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01949, current rewards: -707.57701, mean: -0.60998
[32m[0906 14-16-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01948, current rewards: -757.57701, mean: -0.62610
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01947, current rewards: -807.57701, mean: -0.64093
[32m[0906 14-16-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01945, current rewards: -857.57701, mean: -0.65464
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01946, current rewards: -907.57701, mean: -0.66734
[32m[0906 14-16-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01946, current rewards: -957.57701, mean: -0.67913
[32m[0906 14-16-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01946, current rewards: -1007.57701, mean: -0.69012
[32m[0906 14-16-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01946, current rewards: -1057.57701, mean: -0.70038
[32m[0906 14-16-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01946, current rewards: -1107.57701, mean: -0.70999
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01944, current rewards: -1157.57701, mean: -0.71899
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01943, current rewards: -1207.57701, mean: -0.72746
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01942, current rewards: -1257.57701, mean: -0.73543
[32m[0906 14-16-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01941, current rewards: -1307.57701, mean: -0.74294
[32m[0906 14-16-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01940, current rewards: -1357.57701, mean: -0.75004
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01941, current rewards: -1407.57701, mean: -0.75676
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01941, current rewards: -1457.57701, mean: -0.76313
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01941, current rewards: -1507.57701, mean: -0.76917
[32m[0906 14-16-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01942, current rewards: -1557.57701, mean: -0.77491
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01942, current rewards: -1607.57701, mean: -0.78038
[32m[0906 14-16-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01942, current rewards: -1657.57701, mean: -0.78558
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01943, current rewards: -1707.57701, mean: -0.79054
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01943, current rewards: -1757.57701, mean: -0.79528
[32m[0906 14-16-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01944, current rewards: -1807.57701, mean: -0.79981
[32m[0906 14-16-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01944, current rewards: -1857.57701, mean: -0.80415
[32m[0906 14-16-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01944, current rewards: -1907.57701, mean: -0.80830
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01944, current rewards: -1957.57701, mean: -0.81227
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01945, current rewards: -2007.57701, mean: -0.81609
[32m[0906 14-16-38 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-16-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-16-38 @MBExp.py:227][0m Rewards obtained: [-2047.5770129486714], Lows: [0], Highs: [2094], Total time: 1347.6945040000003
[32m[0906 14-17-40 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-40 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-17-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01893, current rewards: 1.13997, mean: 0.11400
[32m[0906 14-17-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01948, current rewards: 6.68498, mean: 0.11142
[32m[0906 14-17-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01954, current rewards: 12.23669, mean: 0.11124
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01961, current rewards: 17.78293, mean: 0.11114
[32m[0906 14-17-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01959, current rewards: 23.32804, mean: 0.11109
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01958, current rewards: 28.94455, mean: 0.11133
[32m[0906 14-17-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01956, current rewards: 34.55848, mean: 0.11148
[32m[0906 14-17-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01955, current rewards: 40.08844, mean: 0.11136
[32m[0906 14-17-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01953, current rewards: 45.61537, mean: 0.11126
[32m[0906 14-17-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01952, current rewards: 51.14017, mean: 0.11117
[32m[0906 14-17-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01953, current rewards: 56.66797, mean: 0.11111
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: 62.21277, mean: 0.11109
[32m[0906 14-17-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01957, current rewards: 67.73878, mean: 0.11105
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01957, current rewards: 73.26200, mean: 0.11100
[32m[0906 14-17-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01957, current rewards: 78.79119, mean: 0.11097
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01957, current rewards: 86.69605, mean: 0.11407
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01956, current rewards: 94.77033, mean: 0.11700
[32m[0906 14-17-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: 102.84462, mean: 0.11959
[32m[0906 14-17-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01956, current rewards: 110.91890, mean: 0.12189
[32m[0906 14-17-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01957, current rewards: 109.70130, mean: 0.11427
[32m[0906 14-18-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01954, current rewards: 59.70130, mean: 0.05911
[32m[0906 14-18-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01953, current rewards: 9.70130, mean: 0.00915
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01951, current rewards: -40.29870, mean: -0.03631
[32m[0906 14-18-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01948, current rewards: -90.29870, mean: -0.07784
[32m[0906 14-18-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01947, current rewards: -140.29870, mean: -0.11595
[32m[0906 14-18-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01946, current rewards: -190.29870, mean: -0.15103
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01944, current rewards: -240.29870, mean: -0.18343
[32m[0906 14-18-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01945, current rewards: -290.29870, mean: -0.21345
[32m[0906 14-18-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01946, current rewards: -340.29870, mean: -0.24135
[32m[0906 14-18-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01945, current rewards: -390.29870, mean: -0.26733
[32m[0906 14-18-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01944, current rewards: -440.29870, mean: -0.29159
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01943, current rewards: -490.29870, mean: -0.31429
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01942, current rewards: -540.29870, mean: -0.33559
[32m[0906 14-18-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01940, current rewards: -590.29870, mean: -0.35560
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01940, current rewards: -640.29870, mean: -0.37444
[32m[0906 14-18-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01939, current rewards: -690.29870, mean: -0.39222
[32m[0906 14-18-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01938, current rewards: -740.29870, mean: -0.40900
[32m[0906 14-18-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01937, current rewards: -790.29870, mean: -0.42489
[32m[0906 14-18-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01936, current rewards: -840.29870, mean: -0.43995
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01937, current rewards: -890.29870, mean: -0.45423
[32m[0906 14-18-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01937, current rewards: -940.29870, mean: -0.46781
[32m[0906 14-18-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01938, current rewards: -990.29870, mean: -0.48073
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01939, current rewards: -1040.29870, mean: -0.49303
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01939, current rewards: -1090.29870, mean: -0.50477
[32m[0906 14-18-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01940, current rewards: -1140.29870, mean: -0.51597
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01940, current rewards: -1190.29870, mean: -0.52668
[32m[0906 14-18-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01940, current rewards: -1240.29870, mean: -0.53693
[32m[0906 14-18-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01940, current rewards: -1290.29870, mean: -0.54674
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01941, current rewards: -1340.29870, mean: -0.55614
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01941, current rewards: -1390.29870, mean: -0.56516
[32m[0906 14-18-29 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-18-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-18-29 @MBExp.py:227][0m Rewards obtained: [-1430.2986953597153], Lows: [0], Highs: [1548], Total time: 1396.9282850000002
[32m[0906 14-19-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-34 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01935, current rewards: 1.05855, mean: 0.10586
[32m[0906 14-19-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01946, current rewards: 6.57194, mean: 0.10953
[32m[0906 14-19-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01954, current rewards: 12.08792, mean: 0.10989
[32m[0906 14-19-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01951, current rewards: 17.59050, mean: 0.10994
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01951, current rewards: 23.10612, mean: 0.11003
[32m[0906 14-19-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01950, current rewards: 28.62028, mean: 0.11008
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01952, current rewards: 34.13229, mean: 0.11010
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01951, current rewards: 39.65560, mean: 0.11015
[32m[0906 14-19-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01953, current rewards: 45.17338, mean: 0.11018
[32m[0906 14-19-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01954, current rewards: 50.75231, mean: 0.11033
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01954, current rewards: 56.33358, mean: 0.11046
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01954, current rewards: 61.91490, mean: 0.11056
[32m[0906 14-19-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01955, current rewards: 67.50518, mean: 0.11066
[32m[0906 14-19-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01953, current rewards: 73.09637, mean: 0.11075
[32m[0906 14-19-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01954, current rewards: 78.67704, mean: 0.11081
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01954, current rewards: 84.26170, mean: 0.11087
[32m[0906 14-19-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01955, current rewards: 89.84916, mean: 0.11092
[32m[0906 14-19-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01955, current rewards: 95.43587, mean: 0.11097
[32m[0906 14-19-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01955, current rewards: 101.02189, mean: 0.11101
[32m[0906 14-19-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01954, current rewards: 106.60124, mean: 0.11104
[32m[0906 14-19-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01952, current rewards: 112.12252, mean: 0.11101
[32m[0906 14-19-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01950, current rewards: 117.69949, mean: 0.11104
[32m[0906 14-19-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01948, current rewards: 123.27961, mean: 0.11106
[32m[0906 14-19-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01947, current rewards: 128.85264, mean: 0.11108
[32m[0906 14-19-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01946, current rewards: 130.19927, mean: 0.10760
[32m[0906 14-19-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01945, current rewards: 135.75408, mean: 0.10774
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01944, current rewards: 141.31033, mean: 0.10787
[32m[0906 14-20-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01944, current rewards: 146.86546, mean: 0.10799
[32m[0906 14-20-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01943, current rewards: 152.52869, mean: 0.10818
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01943, current rewards: 158.05133, mean: 0.10825
[32m[0906 14-20-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01942, current rewards: 163.57058, mean: 0.10832
[32m[0906 14-20-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01940, current rewards: 169.09092, mean: 0.10839
[32m[0906 14-20-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01939, current rewards: 174.61153, mean: 0.10845
[32m[0906 14-20-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01939, current rewards: 180.13211, mean: 0.10851
[32m[0906 14-20-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01939, current rewards: 185.65400, mean: 0.10857
[32m[0906 14-20-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01938, current rewards: 191.17876, mean: 0.10862
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01937, current rewards: 195.63210, mean: 0.10808
[32m[0906 14-20-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01936, current rewards: 201.11812, mean: 0.10813
[32m[0906 14-20-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01936, current rewards: 206.60611, mean: 0.10817
[32m[0906 14-20-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01935, current rewards: 212.09555, mean: 0.10821
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01935, current rewards: 217.58312, mean: 0.10825
[32m[0906 14-20-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01935, current rewards: 223.07489, mean: 0.10829
[32m[0906 14-20-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01935, current rewards: 228.56099, mean: 0.10832
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01936, current rewards: 234.18984, mean: 0.10842
[32m[0906 14-20-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01937, current rewards: 239.80427, mean: 0.10851
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01938, current rewards: 245.26794, mean: 0.10853
[32m[0906 14-20-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01938, current rewards: 250.80785, mean: 0.10857
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01938, current rewards: 256.34453, mean: 0.10862
[32m[0906 14-20-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01939, current rewards: 261.86666, mean: 0.10866
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01940, current rewards: 267.36905, mean: 0.10869
[32m[0906 14-20-23 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-20-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-20-23 @MBExp.py:227][0m Rewards obtained: [271.7654380340253], Lows: [2], Highs: [1], Total time: 1446.129429
[32m[0906 14-21-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-21-29 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02003, current rewards: 1.16692, mean: 0.11669
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01972, current rewards: 6.79164, mean: 0.11319
[32m[0906 14-21-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01959, current rewards: 12.41990, mean: 0.11291
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01957, current rewards: 17.99427, mean: 0.11246
[32m[0906 14-21-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01956, current rewards: 23.66877, mean: 0.11271
[32m[0906 14-21-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01954, current rewards: 29.34478, mean: 0.11286
[32m[0906 14-21-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01953, current rewards: 35.02737, mean: 0.11299
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01955, current rewards: 40.69996, mean: 0.11306
[32m[0906 14-21-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01955, current rewards: 46.37038, mean: 0.11310
[32m[0906 14-21-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01956, current rewards: 52.04562, mean: 0.11314
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01956, current rewards: 57.72266, mean: 0.11318
[32m[0906 14-21-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: 63.40635, mean: 0.11323
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: 69.07807, mean: 0.11324
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01955, current rewards: 74.74535, mean: 0.11325
[32m[0906 14-21-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01955, current rewards: 80.35383, mean: 0.11317
[32m[0906 14-21-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01956, current rewards: 85.88311, mean: 0.11300
[32m[0906 14-21-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01956, current rewards: 91.40836, mean: 0.11285
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01955, current rewards: 96.93382, mean: 0.11271
[32m[0906 14-21-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01954, current rewards: 102.46488, mean: 0.11260
[32m[0906 14-21-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01955, current rewards: 108.01566, mean: 0.11252
[32m[0906 14-21-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01952, current rewards: 113.54877, mean: 0.11242
[32m[0906 14-21-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01950, current rewards: 119.08207, mean: 0.11234
[32m[0906 14-21-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01947, current rewards: 124.61220, mean: 0.11226
[32m[0906 14-21-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01945, current rewards: 130.14350, mean: 0.11219
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01944, current rewards: 135.81398, mean: 0.11224
[32m[0906 14-21-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01941, current rewards: 141.42471, mean: 0.11224
[32m[0906 14-21-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01939, current rewards: 147.03634, mean: 0.11224
[32m[0906 14-21-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01939, current rewards: 152.66099, mean: 0.11225
[32m[0906 14-21-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01938, current rewards: 158.27543, mean: 0.11225
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01936, current rewards: 163.88864, mean: 0.11225
[32m[0906 14-21-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01936, current rewards: 169.50636, mean: 0.11226
[32m[0906 14-21-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01935, current rewards: 175.12119, mean: 0.11226
[32m[0906 14-22-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01935, current rewards: 180.73683, mean: 0.11226
[32m[0906 14-22-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01934, current rewards: 186.35009, mean: 0.11226
[32m[0906 14-22-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01933, current rewards: 191.96185, mean: 0.11226
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01932, current rewards: 197.57716, mean: 0.11226
[32m[0906 14-22-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: 203.19200, mean: 0.11226
[32m[0906 14-22-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01930, current rewards: 207.69245, mean: 0.11166
[32m[0906 14-22-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01930, current rewards: 213.17245, mean: 0.11161
[32m[0906 14-22-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01929, current rewards: 218.65731, mean: 0.11156
[32m[0906 14-22-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01929, current rewards: 224.14524, mean: 0.11152
[32m[0906 14-22-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01928, current rewards: 229.62946, mean: 0.11147
[32m[0906 14-22-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01928, current rewards: 235.11622, mean: 0.11143
[32m[0906 14-22-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01928, current rewards: 240.62349, mean: 0.11140
[32m[0906 14-22-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01929, current rewards: 246.15162, mean: 0.11138
[32m[0906 14-22-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01930, current rewards: 251.68203, mean: 0.11136
[32m[0906 14-22-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01930, current rewards: 257.20965, mean: 0.11135
[32m[0906 14-22-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01931, current rewards: 262.73399, mean: 0.11133
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01931, current rewards: 268.26735, mean: 0.11131
[32m[0906 14-22-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01931, current rewards: 273.79546, mean: 0.11130
[32m[0906 14-22-18 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-22-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-22-18 @MBExp.py:227][0m Rewards obtained: [278.21621032956165], Lows: [0], Highs: [1], Total time: 1495.132351
[32m[0906 14-23-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-26 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-23-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01911, current rewards: 1.16789, mean: 0.11679
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01940, current rewards: 6.70179, mean: 0.11170
[32m[0906 14-23-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01950, current rewards: 12.21844, mean: 0.11108
[32m[0906 14-23-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01952, current rewards: 17.74816, mean: 0.11093
[32m[0906 14-23-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01953, current rewards: 23.27433, mean: 0.11083
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01957, current rewards: 28.80251, mean: 0.11078
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01953, current rewards: 34.33200, mean: 0.11075
[32m[0906 14-23-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01951, current rewards: 39.86029, mean: 0.11072
[32m[0906 14-23-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01952, current rewards: 45.46249, mean: 0.11088
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01953, current rewards: 50.96806, mean: 0.11080
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01952, current rewards: 56.34408, mean: 0.11048
[32m[0906 14-23-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01953, current rewards: 61.83972, mean: 0.11043
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01951, current rewards: 67.33824, mean: 0.11039
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01952, current rewards: 72.83612, mean: 0.11036
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01953, current rewards: 78.33390, mean: 0.11033
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01953, current rewards: 83.83453, mean: 0.11031
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01953, current rewards: 89.33712, mean: 0.11029
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01952, current rewards: 94.82899, mean: 0.11027
[32m[0906 14-23-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01952, current rewards: 100.30057, mean: 0.11022
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01952, current rewards: 105.78622, mean: 0.11019
[32m[0906 14-23-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01950, current rewards: 111.27101, mean: 0.11017
[32m[0906 14-23-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01949, current rewards: 116.75243, mean: 0.11014
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01948, current rewards: 122.23778, mean: 0.11012
[32m[0906 14-23-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01946, current rewards: 127.72217, mean: 0.11011
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01942, current rewards: 133.20684, mean: 0.11009
[32m[0906 14-23-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01939, current rewards: 138.68505, mean: 0.11007
[32m[0906 14-23-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01936, current rewards: 144.17116, mean: 0.11005
[32m[0906 14-23-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01936, current rewards: 149.65689, mean: 0.11004
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01936, current rewards: 155.26640, mean: 0.11012
[32m[0906 14-23-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01935, current rewards: 160.81266, mean: 0.11015
[32m[0906 14-23-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01935, current rewards: 166.35524, mean: 0.11017
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01935, current rewards: 171.89943, mean: 0.11019
[32m[0906 14-23-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01934, current rewards: 177.44643, mean: 0.11022
[32m[0906 14-23-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01934, current rewards: 182.98840, mean: 0.11023
[32m[0906 14-24-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01933, current rewards: 188.56602, mean: 0.11027
[32m[0906 14-24-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01931, current rewards: 194.13949, mean: 0.11031
[32m[0906 14-24-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: 199.68468, mean: 0.11032
[32m[0906 14-24-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01931, current rewards: 205.22284, mean: 0.11033
[32m[0906 14-24-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01931, current rewards: 210.76290, mean: 0.11035
[32m[0906 14-24-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01930, current rewards: 214.20518, mean: 0.10929
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01930, current rewards: 219.75303, mean: 0.10933
[32m[0906 14-24-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01930, current rewards: 225.30179, mean: 0.10937
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01929, current rewards: 230.85191, mean: 0.10941
[32m[0906 14-24-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01929, current rewards: 228.99994, mean: 0.10602
[32m[0906 14-24-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01929, current rewards: 190.08660, mean: 0.08601
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01929, current rewards: 195.60683, mean: 0.08655
[32m[0906 14-24-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01930, current rewards: 201.12269, mean: 0.08707
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01930, current rewards: 206.72914, mean: 0.08760
[32m[0906 14-24-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01931, current rewards: 212.24092, mean: 0.08807
[32m[0906 14-24-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01932, current rewards: 217.74911, mean: 0.08852
[32m[0906 14-24-15 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-24-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-24-15 @MBExp.py:227][0m Rewards obtained: [222.1607549318252], Lows: [1], Highs: [48], Total time: 1544.142382
[32m[0906 14-25-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-26 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-25-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01917, current rewards: 1.11414, mean: 0.11141
[32m[0906 14-25-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01946, current rewards: 6.64862, mean: 0.11081
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01952, current rewards: 12.17018, mean: 0.11064
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01946, current rewards: 17.69380, mean: 0.11059
[32m[0906 14-25-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01948, current rewards: 23.21697, mean: 0.11056
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01954, current rewards: 28.74123, mean: 0.11054
[32m[0906 14-25-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01952, current rewards: 33.16682, mean: 0.10699
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01950, current rewards: 38.70996, mean: 0.10753
[32m[0906 14-25-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01950, current rewards: 44.25469, mean: 0.10794
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01951, current rewards: 49.71842, mean: 0.10808
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01950, current rewards: 55.25921, mean: 0.10835
[32m[0906 14-25-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01951, current rewards: 60.79380, mean: 0.10856
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01953, current rewards: 66.33271, mean: 0.10874
[32m[0906 14-25-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01953, current rewards: 71.87754, mean: 0.10891
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01953, current rewards: 77.41855, mean: 0.10904
[32m[0906 14-25-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01955, current rewards: 82.96111, mean: 0.10916
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01954, current rewards: 88.50300, mean: 0.10926
[32m[0906 14-25-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01953, current rewards: 94.05905, mean: 0.10937
[32m[0906 14-25-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01953, current rewards: 99.69535, mean: 0.10956
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01954, current rewards: 105.23276, mean: 0.10962
[32m[0906 14-25-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01951, current rewards: 110.78095, mean: 0.10968
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01949, current rewards: 116.33005, mean: 0.10975
[32m[0906 14-25-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01945, current rewards: 121.87285, mean: 0.10980
[32m[0906 14-25-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01941, current rewards: 127.41664, mean: 0.10984
[32m[0906 14-25-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01938, current rewards: 133.08057, mean: 0.10998
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01934, current rewards: 138.77967, mean: 0.11014
[32m[0906 14-25-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01933, current rewards: 144.44601, mean: 0.11026
[32m[0906 14-25-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01932, current rewards: 150.15391, mean: 0.11041
[32m[0906 14-25-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01932, current rewards: 155.86384, mean: 0.11054
[32m[0906 14-25-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01931, current rewards: 161.57947, mean: 0.11067
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01930, current rewards: 167.25413, mean: 0.11076
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01930, current rewards: 172.80039, mean: 0.11077
[32m[0906 14-25-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01929, current rewards: 178.34591, mean: 0.11077
[32m[0906 14-25-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01929, current rewards: 183.89302, mean: 0.11078
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01928, current rewards: 189.40515, mean: 0.11076
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01928, current rewards: 194.94703, mean: 0.11077
[32m[0906 14-26-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01928, current rewards: 200.49416, mean: 0.11077
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01928, current rewards: 206.03783, mean: 0.11077
[32m[0906 14-26-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01927, current rewards: 211.58161, mean: 0.11078
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01927, current rewards: 217.12461, mean: 0.11078
[32m[0906 14-26-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01926, current rewards: 222.66830, mean: 0.11078
[32m[0906 14-26-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01926, current rewards: 228.21371, mean: 0.11078
[32m[0906 14-26-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01926, current rewards: 233.89774, mean: 0.11085
[32m[0906 14-26-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01926, current rewards: 239.51774, mean: 0.11089
[32m[0906 14-26-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01926, current rewards: 245.13883, mean: 0.11092
[32m[0906 14-26-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01926, current rewards: 250.76571, mean: 0.11096
[32m[0906 14-26-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01925, current rewards: 256.39452, mean: 0.11099
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01926, current rewards: 262.02447, mean: 0.11103
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01926, current rewards: 267.65543, mean: 0.11106
[32m[0906 14-26-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: 273.28216, mean: 0.11109
[32m[0906 14-26-15 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-26-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-26-15 @MBExp.py:227][0m Rewards obtained: [277.7927958057151], Lows: [0], Highs: [1], Total time: 1593.01511
[32m[0906 14-27-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-28 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-27-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01952, current rewards: 0.04577, mean: 0.00458
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01970, current rewards: 5.64336, mean: 0.09406
[32m[0906 14-27-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01968, current rewards: 11.22383, mean: 0.10203
[32m[0906 14-27-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01959, current rewards: 16.80435, mean: 0.10503
[32m[0906 14-27-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01958, current rewards: 22.38662, mean: 0.10660
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01960, current rewards: 27.96975, mean: 0.10758
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01960, current rewards: 33.55223, mean: 0.10823
[32m[0906 14-27-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01960, current rewards: 39.13844, mean: 0.10872
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01960, current rewards: 44.71905, mean: 0.10907
[32m[0906 14-27-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01961, current rewards: 50.27550, mean: 0.10929
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01961, current rewards: 55.64726, mean: 0.10911
[32m[0906 14-27-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01961, current rewards: 61.01877, mean: 0.10896
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01961, current rewards: 66.39017, mean: 0.10884
[32m[0906 14-27-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01960, current rewards: 68.63517, mean: 0.10399
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01961, current rewards: 74.23220, mean: 0.10455
[32m[0906 14-27-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01960, current rewards: 79.82408, mean: 0.10503
[32m[0906 14-27-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01960, current rewards: 85.42062, mean: 0.10546
[32m[0906 14-27-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01962, current rewards: 90.98996, mean: 0.10580
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01963, current rewards: 96.58699, mean: 0.10614
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01962, current rewards: 102.18309, mean: 0.10644
[32m[0906 14-27-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01959, current rewards: 107.78073, mean: 0.10671
[32m[0906 14-27-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01953, current rewards: 113.37788, mean: 0.10696
[32m[0906 14-27-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01948, current rewards: 118.98231, mean: 0.10719
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01944, current rewards: 124.53656, mean: 0.10736
[32m[0906 14-27-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01941, current rewards: 130.08815, mean: 0.10751
[32m[0906 14-27-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01938, current rewards: 135.63011, mean: 0.10764
[32m[0906 14-27-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01937, current rewards: 141.18132, mean: 0.10777
[32m[0906 14-27-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01936, current rewards: 146.74148, mean: 0.10790
[32m[0906 14-27-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01935, current rewards: 152.30039, mean: 0.10801
[32m[0906 14-27-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01934, current rewards: 157.95014, mean: 0.10819
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01933, current rewards: 163.62504, mean: 0.10836
[32m[0906 14-27-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01933, current rewards: 169.29869, mean: 0.10852
[32m[0906 14-27-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01932, current rewards: 174.97266, mean: 0.10868
[32m[0906 14-28-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01932, current rewards: 180.63023, mean: 0.10881
[32m[0906 14-28-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01931, current rewards: 186.33720, mean: 0.10897
[32m[0906 14-28-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01931, current rewards: 192.04857, mean: 0.10912
[32m[0906 14-28-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: 197.47048, mean: 0.10910
[32m[0906 14-28-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01930, current rewards: 202.87644, mean: 0.10907
[32m[0906 14-28-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01930, current rewards: 208.28020, mean: 0.10905
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01930, current rewards: 213.68605, mean: 0.10902
[32m[0906 14-28-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01930, current rewards: 219.09219, mean: 0.10900
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01930, current rewards: 224.53505, mean: 0.10900
[32m[0906 14-28-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01930, current rewards: 230.06497, mean: 0.10904
[32m[0906 14-28-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01929, current rewards: 235.53652, mean: 0.10904
[32m[0906 14-28-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: 241.00595, mean: 0.10905
[32m[0906 14-28-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 246.51442, mean: 0.10908
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: 252.13464, mean: 0.10915
[32m[0906 14-28-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01927, current rewards: 257.75300, mean: 0.10922
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01927, current rewards: 263.37145, mean: 0.10928
[32m[0906 14-28-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: 268.98559, mean: 0.10934
[32m[0906 14-28-17 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-28-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-28-17 @MBExp.py:227][0m Rewards obtained: [273.43265525840616], Lows: [0], Highs: [4], Total time: 1641.8942710000001
[32m[0906 14-29-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-32 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-29-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01971, current rewards: -0.99795, mean: -0.09979
[32m[0906 14-29-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01950, current rewards: 4.43923, mean: 0.07399
[32m[0906 14-29-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01947, current rewards: 10.01397, mean: 0.09104
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01946, current rewards: 15.58343, mean: 0.09740
[32m[0906 14-29-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01951, current rewards: 21.15171, mean: 0.10072
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01954, current rewards: 26.71882, mean: 0.10276
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01956, current rewards: 32.28590, mean: 0.10415
[32m[0906 14-29-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01955, current rewards: 37.85563, mean: 0.10515
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01954, current rewards: 43.42713, mean: 0.10592
[32m[0906 14-29-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01954, current rewards: 48.92384, mean: 0.10636
[32m[0906 14-29-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01955, current rewards: 54.44187, mean: 0.10675
[32m[0906 14-29-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: 59.96242, mean: 0.10708
[32m[0906 14-29-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: 65.48400, mean: 0.10735
[32m[0906 14-29-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01955, current rewards: 71.00712, mean: 0.10759
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01955, current rewards: 76.52939, mean: 0.10779
[32m[0906 14-29-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01956, current rewards: 82.05347, mean: 0.10797
[32m[0906 14-29-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01955, current rewards: 87.57716, mean: 0.10812
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: 93.21798, mean: 0.10839
[32m[0906 14-29-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01955, current rewards: 98.76043, mean: 0.10853
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01952, current rewards: 104.30122, mean: 0.10865
[32m[0906 14-29-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01950, current rewards: 109.83891, mean: 0.10875
[32m[0906 14-29-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01945, current rewards: 115.39328, mean: 0.10886
[32m[0906 14-29-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01941, current rewards: 120.94469, mean: 0.10896
[32m[0906 14-29-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01937, current rewards: 126.50213, mean: 0.10905
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01934, current rewards: 132.05766, mean: 0.10914
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01930, current rewards: 137.55048, mean: 0.10917
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01929, current rewards: 143.10327, mean: 0.10924
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01930, current rewards: 148.65346, mean: 0.10930
[32m[0906 14-29-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01929, current rewards: 154.18783, mean: 0.10935
[32m[0906 14-30-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01929, current rewards: 159.70454, mean: 0.10939
[32m[0906 14-30-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01930, current rewards: 165.21902, mean: 0.10942
[32m[0906 14-30-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01929, current rewards: 170.73645, mean: 0.10945
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01929, current rewards: 176.25056, mean: 0.10947
[32m[0906 14-30-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01929, current rewards: 181.74808, mean: 0.10949
[32m[0906 14-30-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01929, current rewards: 187.32190, mean: 0.10954
[32m[0906 14-30-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01929, current rewards: 192.91404, mean: 0.10961
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01929, current rewards: 198.49996, mean: 0.10967
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01929, current rewards: 204.09262, mean: 0.10973
[32m[0906 14-30-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01928, current rewards: 209.68614, mean: 0.10978
[32m[0906 14-30-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01928, current rewards: 215.28254, mean: 0.10984
[32m[0906 14-30-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 220.87441, mean: 0.10989
[32m[0906 14-30-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01928, current rewards: 226.47301, mean: 0.10994
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01927, current rewards: 232.14129, mean: 0.11002
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01927, current rewards: 237.73244, mean: 0.11006
[32m[0906 14-30-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01926, current rewards: 243.36322, mean: 0.11012
[32m[0906 14-30-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01926, current rewards: 248.90185, mean: 0.11013
[32m[0906 14-30-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01926, current rewards: 254.43793, mean: 0.11015
[32m[0906 14-30-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01926, current rewards: 259.97397, mean: 0.11016
[32m[0906 14-30-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01925, current rewards: 265.51152, mean: 0.11017
[32m[0906 14-30-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01925, current rewards: 271.04349, mean: 0.11018
[32m[0906 14-30-21 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-30-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-30-21 @MBExp.py:227][0m Rewards obtained: [275.38046102513067], Lows: [1], Highs: [0], Total time: 1690.7117620000001
[32m[0906 14-31-38 @MBExp.py:144][0m ####################################################################
[32m[0906 14-31-38 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-31-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01902, current rewards: 1.14176, mean: 0.11418
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01960, current rewards: 6.74323, mean: 0.11239
[32m[0906 14-31-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01960, current rewards: 12.27804, mean: 0.11162
[32m[0906 14-31-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01955, current rewards: 17.81653, mean: 0.11135
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01953, current rewards: 23.35030, mean: 0.11119
[32m[0906 14-31-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01951, current rewards: 28.88705, mean: 0.11110
[32m[0906 14-31-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01952, current rewards: 34.42595, mean: 0.11105
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01954, current rewards: 39.96177, mean: 0.11100
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01955, current rewards: 45.49394, mean: 0.11096
[32m[0906 14-31-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01952, current rewards: 50.94505, mean: 0.11075
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01953, current rewards: 56.57417, mean: 0.11093
[32m[0906 14-31-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01952, current rewards: 62.12546, mean: 0.11094
[32m[0906 14-31-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01951, current rewards: 67.67167, mean: 0.11094
[32m[0906 14-31-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01952, current rewards: 73.21983, mean: 0.11094
[32m[0906 14-31-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01952, current rewards: 78.77373, mean: 0.11095
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01952, current rewards: 84.32592, mean: 0.11096
[32m[0906 14-31-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01951, current rewards: 89.87552, mean: 0.11096
[32m[0906 14-31-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01949, current rewards: 95.48881, mean: 0.11103
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01948, current rewards: 101.04919, mean: 0.11104
[32m[0906 14-31-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01947, current rewards: 105.50744, mean: 0.10990
[32m[0906 14-31-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01944, current rewards: 111.05134, mean: 0.10995
[32m[0906 14-31-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01940, current rewards: 116.59576, mean: 0.11000
[32m[0906 14-32-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01936, current rewards: 122.13452, mean: 0.11003
[32m[0906 14-32-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01933, current rewards: 127.67565, mean: 0.11007
[32m[0906 14-32-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01929, current rewards: 133.21885, mean: 0.11010
[32m[0906 14-32-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01926, current rewards: 138.73944, mean: 0.11011
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01925, current rewards: 144.23232, mean: 0.11010
[32m[0906 14-32-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01925, current rewards: 149.76896, mean: 0.11012
[32m[0906 14-32-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01925, current rewards: 155.54849, mean: 0.11032
[32m[0906 14-32-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 161.09949, mean: 0.11034
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01924, current rewards: 166.65706, mean: 0.11037
[32m[0906 14-32-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01924, current rewards: 172.20790, mean: 0.11039
[32m[0906 14-32-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01924, current rewards: 177.75857, mean: 0.11041
[32m[0906 14-32-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01923, current rewards: 183.31208, mean: 0.11043
[32m[0906 14-32-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01923, current rewards: 188.87645, mean: 0.11045
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01922, current rewards: 194.42822, mean: 0.11047
[32m[0906 14-32-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: 199.98458, mean: 0.11049
[32m[0906 14-32-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01922, current rewards: 205.53997, mean: 0.11051
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01922, current rewards: 211.05860, mean: 0.11050
[32m[0906 14-32-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: 216.57768, mean: 0.11050
[32m[0906 14-32-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01921, current rewards: 222.09402, mean: 0.11049
[32m[0906 14-32-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: 227.61348, mean: 0.11049
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01921, current rewards: 233.12969, mean: 0.11049
[32m[0906 14-32-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01921, current rewards: 238.64715, mean: 0.11048
[32m[0906 14-32-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: 244.20016, mean: 0.11050
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: 249.73234, mean: 0.11050
[32m[0906 14-32-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01920, current rewards: 255.26607, mean: 0.11050
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: 260.80038, mean: 0.11051
[32m[0906 14-32-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: 266.33200, mean: 0.11051
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01919, current rewards: 271.86532, mean: 0.11051
[32m[0906 14-32-27 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-32-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-32-27 @MBExp.py:227][0m Rewards obtained: [276.23352060938305], Lows: [0], Highs: [1], Total time: 1739.39579
[32m[0906 14-33-46 @MBExp.py:144][0m ####################################################################
[32m[0906 14-33-46 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01930, current rewards: -0.99114, mean: -0.09911
[32m[0906 14-33-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01950, current rewards: 4.57860, mean: 0.07631
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01946, current rewards: 10.15358, mean: 0.09231
[32m[0906 14-33-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01952, current rewards: 15.73012, mean: 0.09831
[32m[0906 14-33-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01952, current rewards: 21.30804, mean: 0.10147
[32m[0906 14-33-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01956, current rewards: 26.88885, mean: 0.10342
[32m[0906 14-33-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01956, current rewards: 32.46406, mean: 0.10472
[32m[0906 14-33-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01956, current rewards: 38.02376, mean: 0.10562
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01957, current rewards: 43.54352, mean: 0.10620
[32m[0906 14-33-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01956, current rewards: 49.10291, mean: 0.10675
[32m[0906 14-33-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01959, current rewards: 54.65888, mean: 0.10717
[32m[0906 14-33-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01958, current rewards: 60.21454, mean: 0.10753
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01958, current rewards: 65.77142, mean: 0.10782
[32m[0906 14-33-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01956, current rewards: 71.32435, mean: 0.10807
[32m[0906 14-34-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01955, current rewards: 76.88998, mean: 0.10830
[32m[0906 14-34-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01951, current rewards: 82.44022, mean: 0.10847
[32m[0906 14-34-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01950, current rewards: 88.05695, mean: 0.10871
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01948, current rewards: 93.66406, mean: 0.10891
[32m[0906 14-34-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01946, current rewards: 99.26560, mean: 0.10908
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01946, current rewards: 104.87268, mean: 0.10924
[32m[0906 14-34-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01944, current rewards: 110.47812, mean: 0.10938
[32m[0906 14-34-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01939, current rewards: 116.08375, mean: 0.10951
[32m[0906 14-34-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01935, current rewards: 121.69990, mean: 0.10964
[32m[0906 14-34-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01931, current rewards: 127.31840, mean: 0.10976
[32m[0906 14-34-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01927, current rewards: 132.95972, mean: 0.10988
[32m[0906 14-34-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 138.58341, mean: 0.10999
[32m[0906 14-34-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01924, current rewards: 144.19828, mean: 0.11008
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01924, current rewards: 149.81408, mean: 0.11016
[32m[0906 14-34-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01924, current rewards: 155.70947, mean: 0.11043
[32m[0906 14-34-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 161.62734, mean: 0.11070
[32m[0906 14-34-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01924, current rewards: 167.54522, mean: 0.11096
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01924, current rewards: 173.46309, mean: 0.11119
[32m[0906 14-34-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01924, current rewards: 179.38097, mean: 0.11142
[32m[0906 14-34-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01923, current rewards: 184.53607, mean: 0.11117
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01923, current rewards: 190.09840, mean: 0.11117
[32m[0906 14-34-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01922, current rewards: 195.65894, mean: 0.11117
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01922, current rewards: 201.22015, mean: 0.11117
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01922, current rewards: 206.78653, mean: 0.11118
[32m[0906 14-34-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01922, current rewards: 212.34907, mean: 0.11118
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01922, current rewards: 217.90882, mean: 0.11118
[32m[0906 14-34-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01922, current rewards: 223.45246, mean: 0.11117
[32m[0906 14-34-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01922, current rewards: 229.09819, mean: 0.11121
[32m[0906 14-34-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01921, current rewards: 234.68915, mean: 0.11123
[32m[0906 14-34-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01921, current rewards: 240.27971, mean: 0.11124
[32m[0906 14-34-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: 245.86801, mean: 0.11125
[32m[0906 14-34-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 251.45911, mean: 0.11127
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01921, current rewards: 257.04392, mean: 0.11127
[32m[0906 14-34-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: 262.66489, mean: 0.11130
[32m[0906 14-34-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: 268.28222, mean: 0.11132
[32m[0906 14-34-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01920, current rewards: 273.86033, mean: 0.11133
[32m[0906 14-34-34 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-34-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-34-34 @MBExp.py:227][0m Rewards obtained: [278.36625228144396], Lows: [1], Highs: [0], Total time: 1788.088642
[32m[0906 14-35-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-56 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 1.07284, mean: 0.10728
[32m[0906 14-35-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01939, current rewards: 6.55890, mean: 0.10931
[32m[0906 14-35-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01942, current rewards: 12.04719, mean: 0.10952
[32m[0906 14-35-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01949, current rewards: 17.53506, mean: 0.10959
[32m[0906 14-36-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01953, current rewards: 23.01664, mean: 0.10960
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01954, current rewards: 28.50644, mean: 0.10964
[32m[0906 14-36-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01956, current rewards: 33.99614, mean: 0.10966
[32m[0906 14-36-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01954, current rewards: 39.49649, mean: 0.10971
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01953, current rewards: 44.89297, mean: 0.10950
[32m[0906 14-36-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01955, current rewards: 50.38203, mean: 0.10953
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01956, current rewards: 55.86948, mean: 0.10955
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01957, current rewards: 61.35936, mean: 0.10957
[32m[0906 14-36-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01956, current rewards: 66.84843, mean: 0.10959
[32m[0906 14-36-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01952, current rewards: 72.33140, mean: 0.10959
[32m[0906 14-36-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01948, current rewards: 77.82129, mean: 0.10961
[32m[0906 14-36-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01946, current rewards: 83.30530, mean: 0.10961
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01946, current rewards: 88.93924, mean: 0.10980
[32m[0906 14-36-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01943, current rewards: 94.42849, mean: 0.10980
[32m[0906 14-36-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01942, current rewards: 99.91033, mean: 0.10979
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01940, current rewards: 105.39255, mean: 0.10978
[32m[0906 14-36-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01939, current rewards: 110.92616, mean: 0.10983
[32m[0906 14-36-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01935, current rewards: 116.51549, mean: 0.10992
[32m[0906 14-36-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01931, current rewards: 122.10749, mean: 0.11001
[32m[0906 14-36-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01928, current rewards: 127.69427, mean: 0.11008
[32m[0906 14-36-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01924, current rewards: 133.27620, mean: 0.11015
[32m[0906 14-36-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01921, current rewards: 138.82438, mean: 0.11018
[32m[0906 14-36-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 144.40949, mean: 0.11024
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01921, current rewards: 149.99573, mean: 0.11029
[32m[0906 14-36-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 155.58603, mean: 0.11034
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 161.17268, mean: 0.11039
[32m[0906 14-36-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 166.72385, mean: 0.11041
[32m[0906 14-36-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01918, current rewards: 172.22229, mean: 0.11040
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: 177.71853, mean: 0.11038
[32m[0906 14-36-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 183.30150, mean: 0.11042
[32m[0906 14-36-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01918, current rewards: 188.80985, mean: 0.11042
[32m[0906 14-36-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 194.31992, mean: 0.11041
[32m[0906 14-36-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 199.83276, mean: 0.11040
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 205.34113, mean: 0.11040
[32m[0906 14-36-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01917, current rewards: 210.85209, mean: 0.11039
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01917, current rewards: 216.36496, mean: 0.11039
[32m[0906 14-36-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: 221.87482, mean: 0.11039
[32m[0906 14-36-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 227.54898, mean: 0.11046
[32m[0906 14-36-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 233.08551, mean: 0.11047
[32m[0906 14-36-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 238.62232, mean: 0.11047
[32m[0906 14-36-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01918, current rewards: 244.15863, mean: 0.11048
[32m[0906 14-36-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: 249.69571, mean: 0.11048
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: 255.23248, mean: 0.11049
[32m[0906 14-36-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: 260.66442, mean: 0.11045
[32m[0906 14-36-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 266.15755, mean: 0.11044
[32m[0906 14-36-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01919, current rewards: 271.68452, mean: 0.11044
[32m[0906 14-36-45 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-36-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-36-45 @MBExp.py:227][0m Rewards obtained: [276.08153778021267], Lows: [0], Highs: [0], Total time: 1836.74984
[32m[0906 14-38-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-38-08 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-38-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01949, current rewards: 0.00657, mean: 0.00066
[32m[0906 14-38-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01930, current rewards: 5.55891, mean: 0.09265
[32m[0906 14-38-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01943, current rewards: 11.10832, mean: 0.10098
[32m[0906 14-38-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01949, current rewards: 16.65923, mean: 0.10412
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01950, current rewards: 22.21151, mean: 0.10577
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01949, current rewards: 27.75621, mean: 0.10675
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01951, current rewards: 33.31546, mean: 0.10747
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01949, current rewards: 38.88054, mean: 0.10800
[32m[0906 14-38-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01947, current rewards: 44.43176, mean: 0.10837
[32m[0906 14-38-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01948, current rewards: 49.99668, mean: 0.10869
[32m[0906 14-38-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01950, current rewards: 55.50906, mean: 0.10884
[32m[0906 14-38-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01948, current rewards: 61.01170, mean: 0.10895
[32m[0906 14-38-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01945, current rewards: 66.52313, mean: 0.10905
[32m[0906 14-38-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01942, current rewards: 72.03008, mean: 0.10914
[32m[0906 14-38-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01939, current rewards: 77.54352, mean: 0.10922
[32m[0906 14-38-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01938, current rewards: 83.10416, mean: 0.10935
[32m[0906 14-38-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01937, current rewards: 88.70822, mean: 0.10952
[32m[0906 14-38-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01935, current rewards: 94.21979, mean: 0.10956
[32m[0906 14-38-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01933, current rewards: 99.72601, mean: 0.10959
[32m[0906 14-38-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01932, current rewards: 105.23402, mean: 0.10962
[32m[0906 14-38-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01931, current rewards: 110.76538, mean: 0.10967
[32m[0906 14-38-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01928, current rewards: 116.32514, mean: 0.10974
[32m[0906 14-38-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 121.88787, mean: 0.10981
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 127.44473, mean: 0.10987
[32m[0906 14-38-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 130.49772, mean: 0.10785
[32m[0906 14-38-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 136.04784, mean: 0.10797
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 141.59270, mean: 0.10809
[32m[0906 14-38-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 147.14199, mean: 0.10819
[32m[0906 14-38-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 152.69472, mean: 0.10829
[32m[0906 14-38-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 158.24702, mean: 0.10839
[32m[0906 14-38-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01915, current rewards: 163.79871, mean: 0.10848
[32m[0906 14-38-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 169.34662, mean: 0.10856
[32m[0906 14-38-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01916, current rewards: 174.93135, mean: 0.10865
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: 180.49663, mean: 0.10873
[32m[0906 14-38-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 186.06082, mean: 0.10881
[32m[0906 14-38-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 191.62659, mean: 0.10888
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 197.15649, mean: 0.10893
[32m[0906 14-38-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01915, current rewards: 202.75430, mean: 0.10901
[32m[0906 14-38-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 208.35630, mean: 0.10909
[32m[0906 14-38-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 213.95660, mean: 0.10916
[32m[0906 14-38-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 219.55153, mean: 0.10923
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 225.10820, mean: 0.10928
[32m[0906 14-38-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 230.70309, mean: 0.10934
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 236.29656, mean: 0.10940
[32m[0906 14-38-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 241.89502, mean: 0.10945
[32m[0906 14-38-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 247.49015, mean: 0.10951
[32m[0906 14-38-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01914, current rewards: 253.08823, mean: 0.10956
[32m[0906 14-38-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 258.68479, mean: 0.10961
[32m[0906 14-38-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 264.24833, mean: 0.10965
[32m[0906 14-38-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 269.80507, mean: 0.10968
[32m[0906 14-38-57 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-38-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-38-57 @MBExp.py:227][0m Rewards obtained: [274.25051592941395], Lows: [1], Highs: [1], Total time: 1885.306317
[32m[0906 14-40-23 @MBExp.py:144][0m ####################################################################
[32m[0906 14-40-23 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01977, current rewards: 1.12663, mean: 0.11266
[32m[0906 14-40-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01955, current rewards: 6.56504, mean: 0.10942
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01962, current rewards: 12.07088, mean: 0.10974
[32m[0906 14-40-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01958, current rewards: 17.58210, mean: 0.10989
[32m[0906 14-40-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01957, current rewards: 23.09088, mean: 0.10996
[32m[0906 14-40-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01960, current rewards: 28.59965, mean: 0.11000
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01957, current rewards: 34.10918, mean: 0.11003
[32m[0906 14-40-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01960, current rewards: 39.70511, mean: 0.11029
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01962, current rewards: 45.31280, mean: 0.11052
[32m[0906 14-40-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01959, current rewards: 50.89623, mean: 0.11064
[32m[0906 14-40-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01954, current rewards: 56.47971, mean: 0.11074
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01952, current rewards: 60.85878, mean: 0.10868
[32m[0906 14-40-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01948, current rewards: 66.40964, mean: 0.10887
[32m[0906 14-40-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01945, current rewards: 71.95411, mean: 0.10902
[32m[0906 14-40-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01942, current rewards: 77.50031, mean: 0.10916
[32m[0906 14-40-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01940, current rewards: 83.04100, mean: 0.10926
[32m[0906 14-40-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01937, current rewards: 88.55903, mean: 0.10933
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01936, current rewards: 94.10147, mean: 0.10942
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01936, current rewards: 99.64727, mean: 0.10950
[32m[0906 14-40-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01936, current rewards: 105.24203, mean: 0.10963
[32m[0906 14-40-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01935, current rewards: 110.83362, mean: 0.10974
[32m[0906 14-40-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01933, current rewards: 116.41954, mean: 0.10983
[32m[0906 14-40-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01930, current rewards: 122.01001, mean: 0.10992
[32m[0906 14-40-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01926, current rewards: 127.59187, mean: 0.10999
[32m[0906 14-40-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 133.18065, mean: 0.11007
[32m[0906 14-40-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 138.77011, mean: 0.11014
[32m[0906 14-40-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 144.35679, mean: 0.11020
[32m[0906 14-40-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 149.94648, mean: 0.11025
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 155.53171, mean: 0.11031
[32m[0906 14-40-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 161.12142, mean: 0.11036
[32m[0906 14-40-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 166.70916, mean: 0.11040
[32m[0906 14-40-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01918, current rewards: 172.30979, mean: 0.11045
[32m[0906 14-40-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 177.91886, mean: 0.11051
[32m[0906 14-40-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 183.51294, mean: 0.11055
[32m[0906 14-40-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 189.10450, mean: 0.11059
[32m[0906 14-40-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01917, current rewards: 194.68936, mean: 0.11062
[32m[0906 14-40-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: 200.27891, mean: 0.11065
[32m[0906 14-40-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01916, current rewards: 205.86856, mean: 0.11068
[32m[0906 14-41-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 211.45776, mean: 0.11071
[32m[0906 14-41-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01916, current rewards: 217.04944, mean: 0.11074
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01916, current rewards: 222.64102, mean: 0.11077
[32m[0906 14-41-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01916, current rewards: 228.16626, mean: 0.11076
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01916, current rewards: 233.71354, mean: 0.11076
[32m[0906 14-41-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01916, current rewards: 239.26290, mean: 0.11077
[32m[0906 14-41-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01916, current rewards: 244.81368, mean: 0.11078
[32m[0906 14-41-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 250.35684, mean: 0.11078
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 255.90497, mean: 0.11078
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 261.45169, mean: 0.11078
[32m[0906 14-41-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 266.96445, mean: 0.11077
[32m[0906 14-41-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 272.51452, mean: 0.11078
[32m[0906 14-41-11 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-41-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-41-11 @MBExp.py:227][0m Rewards obtained: [276.94433621877414], Lows: [0], Highs: [1], Total time: 1933.88971
[32m[0906 14-42-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-39 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 14-42-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01948, current rewards: -0.95855, mean: -0.09586
[32m[0906 14-42-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01961, current rewards: 4.66778, mean: 0.07780
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01972, current rewards: 10.29389, mean: 0.09358
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01967, current rewards: 15.91994, mean: 0.09950
[32m[0906 14-42-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01965, current rewards: 21.54616, mean: 0.10260
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01967, current rewards: 27.17214, mean: 0.10451
[32m[0906 14-42-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01964, current rewards: 32.76252, mean: 0.10569
[32m[0906 14-42-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01964, current rewards: 38.36766, mean: 0.10658
[32m[0906 14-42-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01957, current rewards: 43.97472, mean: 0.10726
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01953, current rewards: 49.58298, mean: 0.10779
[32m[0906 14-42-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01949, current rewards: 55.11438, mean: 0.10807
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01948, current rewards: 60.61908, mean: 0.10825
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01945, current rewards: 66.12316, mean: 0.10840
[32m[0906 14-42-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01944, current rewards: 71.62349, mean: 0.10852
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01942, current rewards: 77.06533, mean: 0.10854
[32m[0906 14-42-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01941, current rewards: 82.50680, mean: 0.10856
[32m[0906 14-42-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01940, current rewards: 88.20648, mean: 0.10890
[32m[0906 14-42-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01939, current rewards: 93.83218, mean: 0.10911
[32m[0906 14-42-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01939, current rewards: 99.45545, mean: 0.10929
[32m[0906 14-42-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01937, current rewards: 105.08494, mean: 0.10946
[32m[0906 14-42-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01937, current rewards: 110.71254, mean: 0.10962
[32m[0906 14-43-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01936, current rewards: 116.33673, mean: 0.10975
[32m[0906 14-43-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01931, current rewards: 121.95924, mean: 0.10987
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01928, current rewards: 127.58226, mean: 0.10998
[32m[0906 14-43-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01925, current rewards: 133.21212, mean: 0.11009
[32m[0906 14-43-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01923, current rewards: 138.83750, mean: 0.11019
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01922, current rewards: 144.45948, mean: 0.11027
[32m[0906 14-43-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01921, current rewards: 150.07989, mean: 0.11035
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01922, current rewards: 155.70595, mean: 0.11043
[32m[0906 14-43-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01922, current rewards: 161.32958, mean: 0.11050
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01922, current rewards: 166.95835, mean: 0.11057
[32m[0906 14-43-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01922, current rewards: 172.64588, mean: 0.11067
[32m[0906 14-43-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01921, current rewards: 178.30663, mean: 0.11075
[32m[0906 14-43-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01921, current rewards: 183.96618, mean: 0.11082
[32m[0906 14-43-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01921, current rewards: 189.62761, mean: 0.11089
[32m[0906 14-43-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01921, current rewards: 195.27423, mean: 0.11095
[32m[0906 14-43-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: 200.92649, mean: 0.11101
[32m[0906 14-43-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01921, current rewards: 206.58125, mean: 0.11107
[32m[0906 14-43-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 212.23613, mean: 0.11112
[32m[0906 14-43-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01920, current rewards: 217.79214, mean: 0.11112
[32m[0906 14-43-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01920, current rewards: 223.35760, mean: 0.11112
[32m[0906 14-43-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: 228.92083, mean: 0.11113
[32m[0906 14-43-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01920, current rewards: 234.48595, mean: 0.11113
[32m[0906 14-43-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01921, current rewards: 240.04892, mean: 0.11113
[32m[0906 14-43-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: 245.61771, mean: 0.11114
[32m[0906 14-43-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 251.17869, mean: 0.11114
[32m[0906 14-43-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01921, current rewards: 256.74337, mean: 0.11114
[32m[0906 14-43-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01921, current rewards: 262.26495, mean: 0.11113
[32m[0906 14-43-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: 267.83384, mean: 0.11113
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: 273.41574, mean: 0.11114
[32m[0906 14-43-28 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-43-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-43-28 @MBExp.py:227][0m Rewards obtained: [277.8851735646297], Lows: [1], Highs: [0], Total time: 1982.6077289999998
[32m[0906 14-44-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-58 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01977, current rewards: 1.15251, mean: 0.11525
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01942, current rewards: 6.71985, mean: 0.11200
[32m[0906 14-45-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01947, current rewards: 12.28963, mean: 0.11172
[32m[0906 14-45-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01946, current rewards: 17.85707, mean: 0.11161
[32m[0906 14-45-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01949, current rewards: 23.42323, mean: 0.11154
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01956, current rewards: 28.99117, mean: 0.11150
[32m[0906 14-45-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01948, current rewards: 34.55141, mean: 0.11146
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01943, current rewards: 40.12401, mean: 0.11146
[32m[0906 14-45-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01940, current rewards: 45.69348, mean: 0.11145
[32m[0906 14-45-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01939, current rewards: 51.26810, mean: 0.11145
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01937, current rewards: 56.84114, mean: 0.11145
[32m[0906 14-45-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01935, current rewards: 62.45645, mean: 0.11153
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01934, current rewards: 67.96074, mean: 0.11141
[32m[0906 14-45-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01934, current rewards: 73.46525, mean: 0.11131
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01933, current rewards: 78.97522, mean: 0.11123
[32m[0906 14-45-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01931, current rewards: 84.48312, mean: 0.11116
[32m[0906 14-45-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01930, current rewards: 88.91180, mean: 0.10977
[32m[0906 14-45-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01929, current rewards: 94.48514, mean: 0.10987
[32m[0906 14-45-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01928, current rewards: 100.05955, mean: 0.10996
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01927, current rewards: 105.63800, mean: 0.11004
[32m[0906 14-45-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01927, current rewards: 111.21441, mean: 0.11011
[32m[0906 14-45-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01927, current rewards: 116.79221, mean: 0.11018
[32m[0906 14-45-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01923, current rewards: 122.42610, mean: 0.11029
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 127.97671, mean: 0.11032
[32m[0906 14-45-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 133.52483, mean: 0.11035
[32m[0906 14-45-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 139.07231, mean: 0.11037
[32m[0906 14-45-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: 144.71016, mean: 0.11047
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 150.36268, mean: 0.11056
[32m[0906 14-45-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 156.01222, mean: 0.11065
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 161.66254, mean: 0.11073
[32m[0906 14-45-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01913, current rewards: 167.22864, mean: 0.11075
[32m[0906 14-45-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01913, current rewards: 172.68864, mean: 0.11070
[32m[0906 14-45-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 178.21835, mean: 0.11069
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: 183.76380, mean: 0.11070
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01913, current rewards: 189.31245, mean: 0.11071
[32m[0906 14-45-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 194.85655, mean: 0.11071
[32m[0906 14-45-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 200.40474, mean: 0.11072
[32m[0906 14-45-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: 205.95349, mean: 0.11073
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 211.50046, mean: 0.11073
[32m[0906 14-45-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 217.11391, mean: 0.11077
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 222.68823, mean: 0.11079
[32m[0906 14-45-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01913, current rewards: 228.26250, mean: 0.11081
[32m[0906 14-45-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01913, current rewards: 233.83518, mean: 0.11082
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 239.40246, mean: 0.11083
[32m[0906 14-45-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01913, current rewards: 244.97260, mean: 0.11085
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: 250.61730, mean: 0.11089
[32m[0906 14-45-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 256.22025, mean: 0.11092
[32m[0906 14-45-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 261.85186, mean: 0.11095
[32m[0906 14-45-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: 267.48198, mean: 0.11099
[32m[0906 14-45-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 273.10727, mean: 0.11102
[32m[0906 14-45-47 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-45-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-45-47 @MBExp.py:227][0m Rewards obtained: [277.60742979589514], Lows: [0], Highs: [1], Total time: 2031.1565339999997
[32m[0906 14-47-19 @MBExp.py:144][0m ####################################################################
[32m[0906 14-47-19 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01952, current rewards: 1.10960, mean: 0.11096
[32m[0906 14-47-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01944, current rewards: 6.66271, mean: 0.11105
[32m[0906 14-47-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01950, current rewards: 12.21566, mean: 0.11105
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01955, current rewards: 17.76888, mean: 0.11106
[32m[0906 14-47-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01942, current rewards: 23.32158, mean: 0.11106
[32m[0906 14-47-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01936, current rewards: 28.94153, mean: 0.11131
[32m[0906 14-47-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01929, current rewards: 34.49394, mean: 0.11127
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01928, current rewards: 40.04665, mean: 0.11124
[32m[0906 14-47-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.59415, mean: 0.11121
[32m[0906 14-47-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 51.17826, mean: 0.11126
[32m[0906 14-47-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.76884, mean: 0.11131
[32m[0906 14-47-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 62.36101, mean: 0.11136
[32m[0906 14-47-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 67.95320, mean: 0.11140
[32m[0906 14-47-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 73.53753, mean: 0.11142
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 79.10475, mean: 0.11142
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 84.71343, mean: 0.11147
[32m[0906 14-47-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 90.21605, mean: 0.11138
[32m[0906 14-47-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 95.72447, mean: 0.11131
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 101.22909, mean: 0.11124
[32m[0906 14-47-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 106.73505, mean: 0.11118
[32m[0906 14-47-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 112.24222, mean: 0.11113
[32m[0906 14-47-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 117.74708, mean: 0.11108
[32m[0906 14-47-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01920, current rewards: 123.23798, mean: 0.11103
[32m[0906 14-47-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 128.79141, mean: 0.11103
[32m[0906 14-47-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 134.34453, mean: 0.11103
[32m[0906 14-47-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 139.89881, mean: 0.11103
[32m[0906 14-47-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: 145.45050, mean: 0.11103
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 151.00397, mean: 0.11103
[32m[0906 14-47-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 156.55567, mean: 0.11103
[32m[0906 14-47-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 162.10856, mean: 0.11103
[32m[0906 14-47-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01913, current rewards: 167.66232, mean: 0.11103
[32m[0906 14-47-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01913, current rewards: 173.28303, mean: 0.11108
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: 178.85401, mean: 0.11109
[32m[0906 14-47-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01914, current rewards: 184.42686, mean: 0.11110
[32m[0906 14-47-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01914, current rewards: 190.00048, mean: 0.11111
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01914, current rewards: 195.57435, mean: 0.11112
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 201.14929, mean: 0.11113
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 206.72000, mean: 0.11114
[32m[0906 14-47-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 212.34425, mean: 0.11118
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 217.94164, mean: 0.11119
[32m[0906 14-47-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 223.53783, mean: 0.11121
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 229.13522, mean: 0.11123
[32m[0906 14-48-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 234.73180, mean: 0.11125
[32m[0906 14-48-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01913, current rewards: 240.23166, mean: 0.11122
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: 245.72135, mean: 0.11119
[32m[0906 14-48-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: 251.20422, mean: 0.11115
[32m[0906 14-48-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 256.69063, mean: 0.11112
[32m[0906 14-48-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: 262.18165, mean: 0.11109
[32m[0906 14-48-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: 267.67295, mean: 0.11107
[32m[0906 14-48-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 273.16513, mean: 0.11104
[32m[0906 14-48-07 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-48-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-48-07 @MBExp.py:227][0m Rewards obtained: [277.5573145021836], Lows: [0], Highs: [0], Total time: 2079.69139
[32m[0906 14-49-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-42 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01910, current rewards: 1.06203, mean: 0.10620
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01954, current rewards: 6.65126, mean: 0.11085
[32m[0906 14-49-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01942, current rewards: 12.24887, mean: 0.11135
[32m[0906 14-49-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01932, current rewards: 17.84751, mean: 0.11155
[32m[0906 14-49-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.43840, mean: 0.11161
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 29.03783, mean: 0.11168
[32m[0906 14-49-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 34.63528, mean: 0.11173
[32m[0906 14-49-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 40.23183, mean: 0.11176
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.83380, mean: 0.11179
[32m[0906 14-49-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 51.43132, mean: 0.11181
[32m[0906 14-49-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 57.02853, mean: 0.11182
[32m[0906 14-49-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.62771, mean: 0.11184
[32m[0906 14-49-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 68.21374, mean: 0.11183
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01914, current rewards: 73.81730, mean: 0.11184
[32m[0906 14-49-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 79.35880, mean: 0.11177
[32m[0906 14-49-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 84.90315, mean: 0.11171
[32m[0906 14-49-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 90.44849, mean: 0.11166
[32m[0906 14-49-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 95.99479, mean: 0.11162
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 101.53377, mean: 0.11158
[32m[0906 14-50-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 107.07915, mean: 0.11154
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 112.70072, mean: 0.11158
[32m[0906 14-50-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 118.30563, mean: 0.11161
[32m[0906 14-50-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 123.85741, mean: 0.11158
[32m[0906 14-50-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 129.41284, mean: 0.11156
[32m[0906 14-50-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01907, current rewards: 134.94578, mean: 0.11153
[32m[0906 14-50-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01905, current rewards: 140.49672, mean: 0.11151
[32m[0906 14-50-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01904, current rewards: 146.04383, mean: 0.11148
[32m[0906 14-50-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 151.59221, mean: 0.11146
[32m[0906 14-50-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: 157.14139, mean: 0.11145
[32m[0906 14-50-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 162.71242, mean: 0.11145
[32m[0906 14-50-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 168.25972, mean: 0.11143
[32m[0906 14-50-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 173.79657, mean: 0.11141
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 179.35625, mean: 0.11140
[32m[0906 14-50-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 184.91302, mean: 0.11139
[32m[0906 14-50-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 190.47149, mean: 0.11139
[32m[0906 14-50-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 196.03210, mean: 0.11138
[32m[0906 14-50-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 201.59452, mean: 0.11138
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 207.13355, mean: 0.11136
[32m[0906 14-50-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 212.69145, mean: 0.11136
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 218.23428, mean: 0.11134
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: 223.77544, mean: 0.11133
[32m[0906 14-50-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 229.31836, mean: 0.11132
[32m[0906 14-50-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 234.85823, mean: 0.11131
[32m[0906 14-50-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 240.39844, mean: 0.11130
[32m[0906 14-50-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 245.94484, mean: 0.11129
[32m[0906 14-50-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 251.44495, mean: 0.11126
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 257.01109, mean: 0.11126
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 262.57744, mean: 0.11126
[32m[0906 14-50-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 268.13383, mean: 0.11126
[32m[0906 14-50-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: 273.69437, mean: 0.11126
[32m[0906 14-50-30 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-50-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-50-30 @MBExp.py:227][0m Rewards obtained: [278.1446969751416], Lows: [0], Highs: [0], Total time: 2128.166458
[32m[0906 14-52-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-07 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 14-52-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: 1.07117, mean: 0.10712
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01899, current rewards: 6.56983, mean: 0.10950
[32m[0906 14-52-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01904, current rewards: 12.07057, mean: 0.10973
[32m[0906 14-52-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.63911, mean: 0.11024
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.15932, mean: 0.11028
[32m[0906 14-52-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 28.67796, mean: 0.11030
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.19233, mean: 0.11030
[32m[0906 14-52-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 39.71869, mean: 0.11033
[32m[0906 14-52-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 45.22162, mean: 0.11030
[32m[0906 14-52-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.71533, mean: 0.11025
[32m[0906 14-52-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01908, current rewards: 56.20459, mean: 0.11021
[32m[0906 14-52-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 61.74280, mean: 0.11026
[32m[0906 14-52-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 67.24524, mean: 0.11024
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 72.74974, mean: 0.11023
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 78.25345, mean: 0.11022
[32m[0906 14-52-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 83.75645, mean: 0.11021
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 89.33118, mean: 0.11029
[32m[0906 14-52-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 94.89340, mean: 0.11034
[32m[0906 14-52-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 100.45140, mean: 0.11039
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 106.00195, mean: 0.11042
[32m[0906 14-52-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 111.46712, mean: 0.11036
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 117.00185, mean: 0.11038
[32m[0906 14-52-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 122.53370, mean: 0.11039
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01906, current rewards: 128.06243, mean: 0.11040
[32m[0906 14-52-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01904, current rewards: 133.59444, mean: 0.11041
[32m[0906 14-52-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01902, current rewards: 139.12131, mean: 0.11041
[32m[0906 14-52-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 144.63045, mean: 0.11040
[32m[0906 14-52-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 150.13577, mean: 0.11039
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01901, current rewards: 155.61543, mean: 0.11037
[32m[0906 14-52-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 161.11660, mean: 0.11035
[32m[0906 14-52-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 166.62658, mean: 0.11035
[32m[0906 14-52-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 172.13171, mean: 0.11034
[32m[0906 14-52-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 177.64087, mean: 0.11034
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01903, current rewards: 183.14636, mean: 0.11033
[32m[0906 14-52-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: 188.66085, mean: 0.11033
[32m[0906 14-52-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: 194.16787, mean: 0.11032
[32m[0906 14-52-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01904, current rewards: 199.76459, mean: 0.11037
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01904, current rewards: 205.31444, mean: 0.11038
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01904, current rewards: 210.86208, mean: 0.11040
[32m[0906 14-52-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01904, current rewards: 216.44644, mean: 0.11043
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01905, current rewards: 222.02848, mean: 0.11046
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01905, current rewards: 227.61689, mean: 0.11049
[32m[0906 14-52-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01905, current rewards: 233.20000, mean: 0.11052
[32m[0906 14-52-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01906, current rewards: 238.78333, mean: 0.11055
[32m[0906 14-52-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01906, current rewards: 243.89358, mean: 0.11036
[32m[0906 14-52-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01906, current rewards: 250.70171, mean: 0.11093
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: 257.30994, mean: 0.11139
[32m[0906 14-52-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01907, current rewards: 263.91817, mean: 0.11183
[32m[0906 14-52-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01907, current rewards: 222.97549, mean: 0.09252
[32m[0906 14-52-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01907, current rewards: 172.97549, mean: 0.07032
[32m[0906 14-52-55 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-52-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-52-55 @MBExp.py:227][0m Rewards obtained: [132.9754896608473], Lows: [1], Highs: [132], Total time: 2176.5623290000003
[32m[0906 14-54-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-34 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 14-54-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01876, current rewards: 1.22701, mean: 0.12270
[32m[0906 14-54-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.77408, mean: 0.11290
[32m[0906 14-54-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.32314, mean: 0.11203
[32m[0906 14-54-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.92207, mean: 0.11201
[32m[0906 14-54-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.49167, mean: 0.11187
[32m[0906 14-54-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 29.05881, mean: 0.11176
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.62884, mean: 0.11171
[32m[0906 14-54-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 40.19507, mean: 0.11165
[32m[0906 14-54-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.72374, mean: 0.11152
[32m[0906 14-54-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 51.25555, mean: 0.11143
[32m[0906 14-54-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 56.78344, mean: 0.11134
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.26127, mean: 0.11118
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 67.83024, mean: 0.11120
[32m[0906 14-54-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 73.38433, mean: 0.11119
[32m[0906 14-54-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 78.89967, mean: 0.11113
[32m[0906 14-54-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 84.41693, mean: 0.11107
[32m[0906 14-54-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: 89.93412, mean: 0.11103
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 95.45239, mean: 0.11099
[32m[0906 14-54-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 100.97588, mean: 0.11096
[32m[0906 14-54-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 106.51381, mean: 0.11095
[32m[0906 14-54-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 112.02450, mean: 0.11092
[32m[0906 14-54-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 117.64470, mean: 0.11099
[32m[0906 14-54-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 123.16398, mean: 0.11096
[32m[0906 14-54-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 128.68292, mean: 0.11093
[32m[0906 14-54-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 134.20193, mean: 0.11091
[32m[0906 14-54-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 139.72207, mean: 0.11089
[32m[0906 14-54-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01907, current rewards: 144.15873, mean: 0.11004
[32m[0906 14-55-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: 149.64018, mean: 0.11003
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 155.19817, mean: 0.11007
[32m[0906 14-55-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01908, current rewards: 161.00036, mean: 0.11027
[32m[0906 14-55-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 166.79667, mean: 0.11046
[32m[0906 14-55-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 172.60569, mean: 0.11064
[32m[0906 14-55-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01909, current rewards: 178.42027, mean: 0.11082
[32m[0906 14-55-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 184.21159, mean: 0.11097
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01910, current rewards: 190.00773, mean: 0.11112
[32m[0906 14-55-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 195.80506, mean: 0.11125
[32m[0906 14-55-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 201.50097, mean: 0.11133
[32m[0906 14-55-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01910, current rewards: 207.00401, mean: 0.11129
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01910, current rewards: 212.53855, mean: 0.11128
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01911, current rewards: 218.07683, mean: 0.11126
[32m[0906 14-55-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: 223.61495, mean: 0.11125
[32m[0906 14-55-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 229.15071, mean: 0.11124
[32m[0906 14-55-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 234.69014, mean: 0.11123
[32m[0906 14-55-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 240.22550, mean: 0.11122
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 241.45932, mean: 0.10926
[32m[0906 14-55-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 246.97458, mean: 0.10928
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 252.48853, mean: 0.10930
[32m[0906 14-55-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 258.00367, mean: 0.10932
[32m[0906 14-55-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 263.52002, mean: 0.10934
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 269.03506, mean: 0.10936
[32m[0906 14-55-22 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-55-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-55-22 @MBExp.py:227][0m Rewards obtained: [273.44867634227745], Lows: [2], Highs: [1], Total time: 2225.0857410000003
[32m[0906 14-57-03 @MBExp.py:144][0m ####################################################################
[32m[0906 14-57-03 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01849, current rewards: 1.11707, mean: 0.11171
[32m[0906 14-57-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01926, current rewards: 6.66905, mean: 0.11115
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.20833, mean: 0.11098
[32m[0906 14-57-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.83192, mean: 0.11145
[32m[0906 14-57-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.36514, mean: 0.11126
[32m[0906 14-57-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 28.90094, mean: 0.11116
[32m[0906 14-57-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 36.05686, mean: 0.11631
[32m[0906 14-57-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 43.51705, mean: 0.12088
[32m[0906 14-57-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01907, current rewards: 50.97724, mean: 0.12433
[32m[0906 14-57-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 58.43744, mean: 0.12704
[32m[0906 14-57-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 65.89763, mean: 0.12921
[32m[0906 14-57-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01909, current rewards: 72.59422, mean: 0.12963
[32m[0906 14-57-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 77.64410, mean: 0.12729
[32m[0906 14-57-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 82.69398, mean: 0.12529
[32m[0906 14-57-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 87.74385, mean: 0.12358
[32m[0906 14-57-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 43.24884, mean: 0.05691
[32m[0906 14-57-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01908, current rewards: -6.75116, mean: -0.00833
[32m[0906 14-57-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01908, current rewards: -56.75116, mean: -0.06599
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: -106.75116, mean: -0.11731
[32m[0906 14-57-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01908, current rewards: -156.75116, mean: -0.16328
[32m[0906 14-57-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: -206.75116, mean: -0.20470
[32m[0906 14-57-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01907, current rewards: -256.75116, mean: -0.24222
[32m[0906 14-57-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01906, current rewards: -306.75116, mean: -0.27635
[32m[0906 14-57-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01905, current rewards: -356.75116, mean: -0.30754
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01903, current rewards: -406.75116, mean: -0.33616
[32m[0906 14-57-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01900, current rewards: -456.75116, mean: -0.36250
[32m[0906 14-57-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01898, current rewards: -506.75116, mean: -0.38683
[32m[0906 14-57-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01898, current rewards: -556.75116, mean: -0.40938
[32m[0906 14-57-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01899, current rewards: -606.75116, mean: -0.43032
[32m[0906 14-57-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01900, current rewards: -656.75116, mean: -0.44983
[32m[0906 14-57-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01900, current rewards: -706.75116, mean: -0.46805
[32m[0906 14-57-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01900, current rewards: -756.75116, mean: -0.48510
[32m[0906 14-57-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01901, current rewards: -806.75116, mean: -0.50109
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01901, current rewards: -856.75116, mean: -0.51612
[32m[0906 14-57-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: -906.75116, mean: -0.53026
[32m[0906 14-57-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: -956.75116, mean: -0.54361
[32m[0906 14-57-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: -1006.75116, mean: -0.55622
[32m[0906 14-57-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: -1056.75116, mean: -0.56815
[32m[0906 14-57-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01903, current rewards: -1106.75116, mean: -0.57945
[32m[0906 14-57-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01903, current rewards: -1156.75116, mean: -0.59018
[32m[0906 14-57-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01903, current rewards: -1206.75116, mean: -0.60037
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01903, current rewards: -1256.75116, mean: -0.61007
[32m[0906 14-57-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01903, current rewards: -1306.75116, mean: -0.61931
[32m[0906 14-57-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01903, current rewards: -1356.75116, mean: -0.62813
[32m[0906 14-57-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01904, current rewards: -1406.75116, mean: -0.63654
[32m[0906 14-57-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01904, current rewards: -1456.75116, mean: -0.64458
[32m[0906 14-57-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01904, current rewards: -1506.75116, mean: -0.65227
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01904, current rewards: -1556.75116, mean: -0.65964
[32m[0906 14-57-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01904, current rewards: -1606.75116, mean: -0.66670
[32m[0906 14-57-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01904, current rewards: -1656.75116, mean: -0.67348
[32m[0906 14-57-51 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-57-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-57-51 @MBExp.py:227][0m Rewards obtained: [-1696.7511611704667], Lows: [0], Highs: [1785], Total time: 2273.415949
[32m[0906 14-59-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-34 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 14-59-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: 1.07785, mean: 0.10778
[32m[0906 14-59-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 6.59674, mean: 0.10995
[32m[0906 14-59-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01900, current rewards: 12.18635, mean: 0.11078
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01905, current rewards: 17.70699, mean: 0.11067
[32m[0906 14-59-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 23.23028, mean: 0.11062
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01905, current rewards: 28.75122, mean: 0.11058
[32m[0906 14-59-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01905, current rewards: 34.27312, mean: 0.11056
[32m[0906 14-59-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: 39.81817, mean: 0.11061
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 45.34662, mean: 0.11060
[32m[0906 14-59-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.87353, mean: 0.11059
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 56.36214, mean: 0.11051
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: 61.88310, mean: 0.11051
[32m[0906 14-59-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 67.40906, mean: 0.11051
[32m[0906 14-59-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 72.93407, mean: 0.11051
[32m[0906 14-59-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 78.45896, mean: 0.11051
[32m[0906 14-59-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 83.99417, mean: 0.11052
[32m[0906 14-59-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 89.48878, mean: 0.11048
[32m[0906 14-59-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 94.98456, mean: 0.11045
[32m[0906 14-59-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 100.47887, mean: 0.11042
[32m[0906 14-59-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 107.50599, mean: 0.11199
[32m[0906 14-59-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 115.58028, mean: 0.11444
[32m[0906 14-59-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 123.65457, mean: 0.11666
[32m[0906 14-59-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 131.72885, mean: 0.11867
[32m[0906 14-59-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 109.60451, mean: 0.09449
[32m[0906 14-59-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 59.60451, mean: 0.04926
[32m[0906 14-59-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 9.60451, mean: 0.00762
[32m[0906 14-59-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: -40.39549, mean: -0.03084
[32m[0906 15-00-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01906, current rewards: -90.39549, mean: -0.06647
[32m[0906 15-00-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: -140.39549, mean: -0.09957
[32m[0906 15-00-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: -190.39549, mean: -0.13041
[32m[0906 15-00-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: -240.39549, mean: -0.15920
[32m[0906 15-00-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: -290.39549, mean: -0.18615
[32m[0906 15-00-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: -340.39549, mean: -0.21143
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: -390.39549, mean: -0.23518
[32m[0906 15-00-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: -440.39549, mean: -0.25754
[32m[0906 15-00-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: -490.39549, mean: -0.27863
[32m[0906 15-00-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: -540.39549, mean: -0.29856
[32m[0906 15-00-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: -590.39549, mean: -0.31742
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: -640.39549, mean: -0.33529
[32m[0906 15-00-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: -690.39549, mean: -0.35224
[32m[0906 15-00-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: -740.39549, mean: -0.36836
[32m[0906 15-00-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: -790.39549, mean: -0.38369
[32m[0906 15-00-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01910, current rewards: -840.39549, mean: -0.39829
[32m[0906 15-00-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01910, current rewards: -890.39549, mean: -0.41222
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: -940.39549, mean: -0.42552
[32m[0906 15-00-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: -990.39549, mean: -0.43823
[32m[0906 15-00-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: -1040.39549, mean: -0.45039
[32m[0906 15-00-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: -1090.39549, mean: -0.46203
[32m[0906 15-00-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: -1140.39549, mean: -0.47319
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: -1190.39549, mean: -0.48390
[32m[0906 15-00-22 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-00-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-00-22 @MBExp.py:227][0m Rewards obtained: [-1230.3954887085465], Lows: [0], Highs: [1366], Total time: 2321.900535
[32m[0906 15-02-07 @MBExp.py:144][0m ####################################################################
[32m[0906 15-02-07 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01898, current rewards: 1.23464, mean: 0.12346
[32m[0906 15-02-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01888, current rewards: 6.85496, mean: 0.11425
[32m[0906 15-02-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01888, current rewards: 12.38499, mean: 0.11259
[32m[0906 15-02-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01897, current rewards: 17.92090, mean: 0.11201
[32m[0906 15-02-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01895, current rewards: 23.45543, mean: 0.11169
[32m[0906 15-02-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01899, current rewards: 29.00988, mean: 0.11158
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01900, current rewards: 34.55109, mean: 0.11146
[32m[0906 15-02-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01900, current rewards: 40.09815, mean: 0.11138
[32m[0906 15-02-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01902, current rewards: 45.63830, mean: 0.11131
[32m[0906 15-02-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01902, current rewards: 51.16964, mean: 0.11124
[32m[0906 15-02-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01904, current rewards: 56.72818, mean: 0.11123
[32m[0906 15-02-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01904, current rewards: 62.12840, mean: 0.11094
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01904, current rewards: 67.67283, mean: 0.11094
[32m[0906 15-02-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01904, current rewards: 73.21536, mean: 0.11093
[32m[0906 15-02-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01907, current rewards: 78.76180, mean: 0.11093
[32m[0906 15-02-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01906, current rewards: 84.30902, mean: 0.11093
[32m[0906 15-02-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01907, current rewards: 89.84973, mean: 0.11093
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: 95.39097, mean: 0.11092
[32m[0906 15-02-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: 100.93990, mean: 0.11092
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01908, current rewards: 106.48433, mean: 0.11092
[32m[0906 15-02-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: 112.02995, mean: 0.11092
[32m[0906 15-02-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01908, current rewards: 117.57201, mean: 0.11092
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01908, current rewards: 123.12725, mean: 0.11093
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01908, current rewards: 128.67039, mean: 0.11092
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01905, current rewards: 134.21201, mean: 0.11092
[32m[0906 15-02-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01904, current rewards: 139.75887, mean: 0.11092
[32m[0906 15-02-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01901, current rewards: 145.30545, mean: 0.11092
[32m[0906 15-02-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 150.88214, mean: 0.11094
[32m[0906 15-02-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01902, current rewards: 156.42157, mean: 0.11094
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01903, current rewards: 161.95343, mean: 0.11093
[32m[0906 15-02-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 167.49035, mean: 0.11092
[32m[0906 15-02-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01904, current rewards: 173.03062, mean: 0.11092
[32m[0906 15-02-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: 178.56803, mean: 0.11091
[32m[0906 15-02-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 184.10653, mean: 0.11091
[32m[0906 15-02-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 189.64425, mean: 0.11090
[32m[0906 15-02-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 194.07980, mean: 0.11027
[32m[0906 15-02-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: 199.71387, mean: 0.11034
[32m[0906 15-02-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 205.26772, mean: 0.11036
[32m[0906 15-02-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01905, current rewards: 210.82059, mean: 0.11038
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01905, current rewards: 216.37361, mean: 0.11039
[32m[0906 15-02-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01905, current rewards: 221.90285, mean: 0.11040
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01905, current rewards: 227.43912, mean: 0.11041
[32m[0906 15-02-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01905, current rewards: 232.97055, mean: 0.11041
[32m[0906 15-02-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01906, current rewards: 238.50413, mean: 0.11042
[32m[0906 15-02-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01906, current rewards: 243.91501, mean: 0.11037
[32m[0906 15-02-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01906, current rewards: 249.46035, mean: 0.11038
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01906, current rewards: 255.00783, mean: 0.11039
[32m[0906 15-02-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01906, current rewards: 260.55459, mean: 0.11040
[32m[0906 15-02-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01906, current rewards: 266.10701, mean: 0.11042
[32m[0906 15-02-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01906, current rewards: 271.65023, mean: 0.11043
[32m[0906 15-02-55 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-02-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-02-55 @MBExp.py:227][0m Rewards obtained: [276.0882767461677], Lows: [0], Highs: [1], Total time: 2370.2718750000004
[32m[0906 15-04-42 @MBExp.py:144][0m ####################################################################
[32m[0906 15-04-42 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-04-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01946, current rewards: 0.05499, mean: 0.00550
[32m[0906 15-04-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01922, current rewards: 5.63644, mean: 0.09394
[32m[0906 15-04-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 11.12143, mean: 0.10110
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 16.59679, mean: 0.10373
[32m[0906 15-04-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 22.09693, mean: 0.10522
[32m[0906 15-04-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 27.59705, mean: 0.10614
[32m[0906 15-04-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 33.09636, mean: 0.10676
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 38.60179, mean: 0.10723
[32m[0906 15-04-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 44.10559, mean: 0.10757
[32m[0906 15-04-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 49.65583, mean: 0.10795
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 55.19502, mean: 0.10823
[32m[0906 15-04-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 60.77538, mean: 0.10853
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 66.32475, mean: 0.10873
[32m[0906 15-04-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 71.87363, mean: 0.10890
[32m[0906 15-04-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 77.42677, mean: 0.10905
[32m[0906 15-04-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 82.97688, mean: 0.10918
[32m[0906 15-04-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 88.52495, mean: 0.10929
[32m[0906 15-04-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 94.07472, mean: 0.10939
[32m[0906 15-05-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 99.61960, mean: 0.10947
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 105.13699, mean: 0.10952
[32m[0906 15-05-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 110.65393, mean: 0.10956
[32m[0906 15-05-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 116.19875, mean: 0.10962
[32m[0906 15-05-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 121.73562, mean: 0.10967
[32m[0906 15-05-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 127.27777, mean: 0.10972
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 132.81954, mean: 0.10977
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 138.35959, mean: 0.10981
[32m[0906 15-05-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01907, current rewards: 143.90362, mean: 0.10985
[32m[0906 15-05-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 149.44731, mean: 0.10989
[32m[0906 15-05-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 155.20996, mean: 0.11008
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01908, current rewards: 160.78124, mean: 0.11012
[32m[0906 15-05-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 166.35702, mean: 0.11017
[32m[0906 15-05-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 171.93179, mean: 0.11021
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 177.50107, mean: 0.11025
[32m[0906 15-05-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 183.07333, mean: 0.11029
[32m[0906 15-05-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 188.64703, mean: 0.11032
[32m[0906 15-05-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 194.21968, mean: 0.11035
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 199.77266, mean: 0.11037
[32m[0906 15-05-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 205.34655, mean: 0.11040
[32m[0906 15-05-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 210.92112, mean: 0.11043
[32m[0906 15-05-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 216.49225, mean: 0.11046
[32m[0906 15-05-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: 220.94470, mean: 0.10992
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 226.45392, mean: 0.10993
[32m[0906 15-05-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 231.96248, mean: 0.10993
[32m[0906 15-05-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 237.46653, mean: 0.10994
[32m[0906 15-05-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 242.97473, mean: 0.10994
[32m[0906 15-05-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 248.48340, mean: 0.10995
[32m[0906 15-05-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 253.99236, mean: 0.10995
[32m[0906 15-05-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 259.50178, mean: 0.10996
[32m[0906 15-05-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 265.00961, mean: 0.10996
[32m[0906 15-05-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 270.51693, mean: 0.10997
[32m[0906 15-05-31 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-05-31 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-05-31 @MBExp.py:227][0m Rewards obtained: [274.92129402591695], Lows: [0], Highs: [2], Total time: 2418.758529
[32m[0906 15-07-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-07-19 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-07-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01930, current rewards: 1.11017, mean: 0.11102
[32m[0906 15-07-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.58945, mean: 0.10982
[32m[0906 15-07-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.05204, mean: 0.10956
[32m[0906 15-07-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.53380, mean: 0.10959
[32m[0906 15-07-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.02027, mean: 0.10962
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: 28.49941, mean: 0.10961
[32m[0906 15-07-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 33.97822, mean: 0.10961
[32m[0906 15-07-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 39.44595, mean: 0.10957
[32m[0906 15-07-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 44.92295, mean: 0.10957
[32m[0906 15-07-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01910, current rewards: 50.40622, mean: 0.10958
[32m[0906 15-07-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 55.86768, mean: 0.10954
[32m[0906 15-07-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 61.35677, mean: 0.10957
[32m[0906 15-07-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 66.84600, mean: 0.10958
[32m[0906 15-07-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 72.33153, mean: 0.10959
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 77.82246, mean: 0.10961
[32m[0906 15-07-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 83.31135, mean: 0.10962
[32m[0906 15-07-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 88.79685, mean: 0.10963
[32m[0906 15-07-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 94.28467, mean: 0.10963
[32m[0906 15-07-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 99.83552, mean: 0.10971
[32m[0906 15-07-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 105.32314, mean: 0.10971
[32m[0906 15-07-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 110.80550, mean: 0.10971
[32m[0906 15-07-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 116.28780, mean: 0.10971
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 121.77484, mean: 0.10971
[32m[0906 15-07-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 127.25797, mean: 0.10971
[32m[0906 15-07-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 132.73693, mean: 0.10970
[32m[0906 15-07-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 138.25188, mean: 0.10972
[32m[0906 15-07-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: 143.75951, mean: 0.10974
[32m[0906 15-07-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 149.20044, mean: 0.10971
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: 154.74432, mean: 0.10975
[32m[0906 15-07-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: 160.28921, mean: 0.10979
[32m[0906 15-07-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01905, current rewards: 165.83042, mean: 0.10982
[32m[0906 15-07-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 171.37172, mean: 0.10985
[32m[0906 15-07-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 176.91772, mean: 0.10989
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 182.46338, mean: 0.10992
[32m[0906 15-07-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 188.00375, mean: 0.10994
[32m[0906 15-07-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01906, current rewards: 193.55692, mean: 0.10998
[32m[0906 15-07-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 199.09738, mean: 0.11000
[32m[0906 15-07-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 204.64075, mean: 0.11002
[32m[0906 15-07-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01907, current rewards: 210.18228, mean: 0.11004
[32m[0906 15-07-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 215.89977, mean: 0.11015
[32m[0906 15-07-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 221.19237, mean: 0.11005
[32m[0906 15-07-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: 226.48971, mean: 0.10995
[32m[0906 15-08-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01907, current rewards: 231.78225, mean: 0.10985
[32m[0906 15-08-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 237.09125, mean: 0.10976
[32m[0906 15-08-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01907, current rewards: 242.37250, mean: 0.10967
[32m[0906 15-08-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: 247.65199, mean: 0.10958
[32m[0906 15-08-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: 252.93170, mean: 0.10949
[32m[0906 15-08-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01907, current rewards: 258.20963, mean: 0.10941
[32m[0906 15-08-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01907, current rewards: 263.48824, mean: 0.10933
[32m[0906 15-08-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01908, current rewards: 268.76816, mean: 0.10926
[32m[0906 15-08-07 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-08-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-08-07 @MBExp.py:227][0m Rewards obtained: [272.99371309339256], Lows: [0], Highs: [0], Total time: 2467.165943
[32m[0906 15-09-58 @MBExp.py:144][0m ####################################################################
[32m[0906 15-09-58 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-09-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01847, current rewards: 1.22458, mean: 0.12246
[32m[0906 15-09-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01899, current rewards: 6.65152, mean: 0.11086
[32m[0906 15-10-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.14191, mean: 0.11038
[32m[0906 15-10-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.66200, mean: 0.11039
[32m[0906 15-10-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.18010, mean: 0.11038
[32m[0906 15-10-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 28.70418, mean: 0.11040
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.22389, mean: 0.11040
[32m[0906 15-10-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 39.70721, mean: 0.11030
[32m[0906 15-10-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 45.24744, mean: 0.11036
[32m[0906 15-10-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 50.78454, mean: 0.11040
[32m[0906 15-10-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01908, current rewards: 56.41564, mean: 0.11062
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01909, current rewards: 61.95060, mean: 0.11063
[32m[0906 15-10-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 67.48540, mean: 0.11063
[32m[0906 15-10-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 73.02195, mean: 0.11064
[32m[0906 15-10-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 78.56504, mean: 0.11065
[32m[0906 15-10-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 84.16668, mean: 0.11075
[32m[0906 15-10-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01909, current rewards: 89.71414, mean: 0.11076
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01909, current rewards: 95.26059, mean: 0.11077
[32m[0906 15-10-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 100.71717, mean: 0.11068
[32m[0906 15-10-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 106.28541, mean: 0.11071
[32m[0906 15-10-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 111.84916, mean: 0.11074
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 117.41873, mean: 0.11077
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 122.99257, mean: 0.11080
[32m[0906 15-10-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 128.56077, mean: 0.11083
[32m[0906 15-10-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 134.12583, mean: 0.11085
[32m[0906 15-10-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 139.69957, mean: 0.11087
[32m[0906 15-10-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01905, current rewards: 145.30599, mean: 0.11092
[32m[0906 15-10-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 150.97648, mean: 0.11101
[32m[0906 15-10-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: 156.51674, mean: 0.11100
[32m[0906 15-10-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 162.05617, mean: 0.11100
[32m[0906 15-10-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 167.59416, mean: 0.11099
[32m[0906 15-10-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 173.12807, mean: 0.11098
[32m[0906 15-10-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 180.19534, mean: 0.11192
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 188.26962, mean: 0.11342
[32m[0906 15-10-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 196.34391, mean: 0.11482
[32m[0906 15-10-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01906, current rewards: 202.78405, mean: 0.11522
[32m[0906 15-10-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01906, current rewards: 154.88344, mean: 0.08557
[32m[0906 15-10-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 104.88344, mean: 0.05639
[32m[0906 15-10-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 54.88344, mean: 0.02873
[32m[0906 15-10-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01906, current rewards: 4.88344, mean: 0.00249
[32m[0906 15-10-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01906, current rewards: -45.11656, mean: -0.02245
[32m[0906 15-10-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01906, current rewards: -95.11656, mean: -0.04617
[32m[0906 15-10-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01905, current rewards: -145.11656, mean: -0.06878
[32m[0906 15-10-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01906, current rewards: -195.11656, mean: -0.09033
[32m[0906 15-10-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01906, current rewards: -245.11656, mean: -0.11091
[32m[0906 15-10-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01906, current rewards: -295.11656, mean: -0.13058
[32m[0906 15-10-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: -345.11656, mean: -0.14940
[32m[0906 15-10-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01907, current rewards: -395.11656, mean: -0.16742
[32m[0906 15-10-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01907, current rewards: -445.11656, mean: -0.18470
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01907, current rewards: -495.11656, mean: -0.20127
[32m[0906 15-10-46 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-10-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-10-46 @MBExp.py:227][0m Rewards obtained: [-535.1165589289276], Lows: [0], Highs: [738], Total time: 2515.567926
[32m[0906 15-12-39 @MBExp.py:144][0m ####################################################################
[32m[0906 15-12-39 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-12-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01914, current rewards: 1.07936, mean: 0.10794
[32m[0906 15-12-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01921, current rewards: 6.63356, mean: 0.11056
[32m[0906 15-12-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 12.22506, mean: 0.11114
[32m[0906 15-12-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.78116, mean: 0.11113
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.33247, mean: 0.11111
[32m[0906 15-12-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 30.53428, mean: 0.11744
[32m[0906 15-12-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 37.99447, mean: 0.12256
[32m[0906 15-12-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 45.45466, mean: 0.12626
[32m[0906 15-12-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 52.91485, mean: 0.12906
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 60.37504, mean: 0.13125
[32m[0906 15-12-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 67.83523, mean: 0.13301
[32m[0906 15-12-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 75.29542, mean: 0.13446
[32m[0906 15-12-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 82.75561, mean: 0.13566
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 35.05402, mean: 0.05311
[32m[0906 15-12-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: -14.94598, mean: -0.02105
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: -64.94598, mean: -0.08546
[32m[0906 15-12-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: -114.94598, mean: -0.14191
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: -164.94598, mean: -0.19180
[32m[0906 15-12-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: -214.94598, mean: -0.23620
[32m[0906 15-12-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: -264.94598, mean: -0.27599
[32m[0906 15-12-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: -314.94598, mean: -0.31183
[32m[0906 15-13-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: -364.94598, mean: -0.34429
[32m[0906 15-13-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: -414.94598, mean: -0.37383
[32m[0906 15-13-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: -464.94598, mean: -0.40082
[32m[0906 15-13-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: -514.94598, mean: -0.42558
[32m[0906 15-13-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: -564.94598, mean: -0.44837
[32m[0906 15-13-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01907, current rewards: -614.94598, mean: -0.46942
[32m[0906 15-13-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01904, current rewards: -664.94598, mean: -0.48893
[32m[0906 15-13-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: -714.94598, mean: -0.50705
[32m[0906 15-13-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: -764.94598, mean: -0.52394
[32m[0906 15-13-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01905, current rewards: -814.94598, mean: -0.53970
[32m[0906 15-13-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: -864.94598, mean: -0.55445
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: -914.94598, mean: -0.56829
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: -964.94598, mean: -0.58129
[32m[0906 15-13-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: -1014.94598, mean: -0.59354
[32m[0906 15-13-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01906, current rewards: -1064.94598, mean: -0.60508
[32m[0906 15-13-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01906, current rewards: -1114.94598, mean: -0.61599
[32m[0906 15-13-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: -1164.94598, mean: -0.62632
[32m[0906 15-13-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: -1214.94598, mean: -0.63610
[32m[0906 15-13-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: -1264.94598, mean: -0.64538
[32m[0906 15-13-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01906, current rewards: -1314.94598, mean: -0.65420
[32m[0906 15-13-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01906, current rewards: -1364.94598, mean: -0.66260
[32m[0906 15-13-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01906, current rewards: -1414.94598, mean: -0.67059
[32m[0906 15-13-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01907, current rewards: -1464.94598, mean: -0.67822
[32m[0906 15-13-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01907, current rewards: -1514.94598, mean: -0.68550
[32m[0906 15-13-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: -1564.94598, mean: -0.69245
[32m[0906 15-13-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: -1614.94598, mean: -0.69911
[32m[0906 15-13-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01907, current rewards: -1664.94598, mean: -0.70549
[32m[0906 15-13-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01907, current rewards: -1714.94598, mean: -0.71160
[32m[0906 15-13-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01907, current rewards: -1764.94598, mean: -0.71746
[32m[0906 15-13-28 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-13-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-13-28 @MBExp.py:227][0m Rewards obtained: [-1804.945978044242], Lows: [0], Highs: [1888], Total time: 2563.9571760000003
[32m[0906 15-15-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-22 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-15-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01914, current rewards: -1.02646, mean: -0.10265
[32m[0906 15-15-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01927, current rewards: 4.45567, mean: 0.07426
[32m[0906 15-15-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 9.88533, mean: 0.08987
[32m[0906 15-15-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 15.36733, mean: 0.09605
[32m[0906 15-15-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 20.85611, mean: 0.09931
[32m[0906 15-15-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 26.33462, mean: 0.10129
[32m[0906 15-15-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 31.82692, mean: 0.10267
[32m[0906 15-15-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 37.30536, mean: 0.10363
[32m[0906 15-15-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01907, current rewards: 42.78881, mean: 0.10436
[32m[0906 15-15-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01906, current rewards: 48.27693, mean: 0.10495
[32m[0906 15-15-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01906, current rewards: 53.75912, mean: 0.10541
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01906, current rewards: 59.24747, mean: 0.10580
[32m[0906 15-15-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01907, current rewards: 64.71871, mean: 0.10610
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01907, current rewards: 70.20073, mean: 0.10636
[32m[0906 15-15-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 75.68338, mean: 0.10660
[32m[0906 15-15-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01906, current rewards: 81.17078, mean: 0.10680
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 86.62783, mean: 0.10695
[32m[0906 15-15-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01905, current rewards: 92.16080, mean: 0.10716
[32m[0906 15-15-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01906, current rewards: 97.70131, mean: 0.10736
[32m[0906 15-15-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01905, current rewards: 103.23432, mean: 0.10754
[32m[0906 15-15-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01905, current rewards: 108.76025, mean: 0.10768
[32m[0906 15-15-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01905, current rewards: 114.29277, mean: 0.10782
[32m[0906 15-15-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01905, current rewards: 119.82030, mean: 0.10795
[32m[0906 15-15-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01905, current rewards: 125.35147, mean: 0.10806
[32m[0906 15-15-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01905, current rewards: 130.88092, mean: 0.10817
[32m[0906 15-15-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01904, current rewards: 136.41349, mean: 0.10826
[32m[0906 15-15-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 141.96796, mean: 0.10837
[32m[0906 15-15-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01900, current rewards: 147.49549, mean: 0.10845
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01900, current rewards: 153.01921, mean: 0.10852
[32m[0906 15-15-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01901, current rewards: 158.55829, mean: 0.10860
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: 164.09542, mean: 0.10867
[32m[0906 15-15-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 169.63228, mean: 0.10874
[32m[0906 15-15-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 175.17010, mean: 0.10880
[32m[0906 15-15-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01903, current rewards: 180.71340, mean: 0.10886
[32m[0906 15-15-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: 186.35302, mean: 0.10898
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: 191.90150, mean: 0.10903
[32m[0906 15-15-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: 197.45373, mean: 0.10909
[32m[0906 15-15-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01904, current rewards: 203.00579, mean: 0.10914
[32m[0906 15-15-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01904, current rewards: 208.55842, mean: 0.10919
[32m[0906 15-16-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01905, current rewards: 214.10961, mean: 0.10924
[32m[0906 15-16-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01905, current rewards: 219.65988, mean: 0.10928
[32m[0906 15-16-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01904, current rewards: 225.24981, mean: 0.10934
[32m[0906 15-16-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01905, current rewards: 230.85333, mean: 0.10941
[32m[0906 15-16-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01905, current rewards: 236.42851, mean: 0.10946
[32m[0906 15-16-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01905, current rewards: 242.00369, mean: 0.10950
[32m[0906 15-16-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01905, current rewards: 247.58274, mean: 0.10955
[32m[0906 15-16-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01905, current rewards: 253.15654, mean: 0.10959
[32m[0906 15-16-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01906, current rewards: 258.73811, mean: 0.10963
[32m[0906 15-16-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01906, current rewards: 264.32055, mean: 0.10968
[32m[0906 15-16-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01906, current rewards: 269.89946, mean: 0.10972
[32m[0906 15-16-10 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-16-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-16-10 @MBExp.py:227][0m Rewards obtained: [272.27716761081336], Lows: [2], Highs: [0], Total time: 2612.3457020000005
[32m[0906 15-18-07 @MBExp.py:144][0m ####################################################################
[32m[0906 15-18-07 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-18-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01966, current rewards: 0.05249, mean: 0.00525
[32m[0906 15-18-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 5.53058, mean: 0.09218
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01910, current rewards: 11.05470, mean: 0.10050
[32m[0906 15-18-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 16.57740, mean: 0.10361
[32m[0906 15-18-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 22.10230, mean: 0.10525
[32m[0906 15-18-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 27.62883, mean: 0.10626
[32m[0906 15-18-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 33.15289, mean: 0.10694
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 38.68535, mean: 0.10746
[32m[0906 15-18-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 44.21595, mean: 0.10784
[32m[0906 15-18-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 49.84843, mean: 0.10837
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 55.37073, mean: 0.10857
[32m[0906 15-18-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 60.89167, mean: 0.10874
[32m[0906 15-18-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 66.41996, mean: 0.10889
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 71.89772, mean: 0.10894
[32m[0906 15-18-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 77.37432, mean: 0.10898
[32m[0906 15-18-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 82.85072, mean: 0.10901
[32m[0906 15-18-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: 88.36462, mean: 0.10909
[32m[0906 15-18-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 93.91392, mean: 0.10920
[32m[0906 15-18-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 99.45531, mean: 0.10929
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01917, current rewards: 105.02019, mean: 0.10940
[32m[0906 15-18-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 110.58208, mean: 0.10949
[32m[0906 15-18-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 116.14526, mean: 0.10957
[32m[0906 15-18-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 121.70966, mean: 0.10965
[32m[0906 15-18-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 127.28212, mean: 0.10973
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 132.85214, mean: 0.10980
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 138.42072, mean: 0.10986
[32m[0906 15-18-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 143.97577, mean: 0.10991
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 149.49229, mean: 0.10992
[32m[0906 15-18-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 155.00934, mean: 0.10994
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 160.52461, mean: 0.10995
[32m[0906 15-18-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 166.04252, mean: 0.10996
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 171.73950, mean: 0.11009
[32m[0906 15-18-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 177.28397, mean: 0.11011
[32m[0906 15-18-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: 182.82819, mean: 0.11014
[32m[0906 15-18-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01910, current rewards: 188.41261, mean: 0.11018
[32m[0906 15-18-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: 193.96788, mean: 0.11021
[32m[0906 15-18-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 199.52168, mean: 0.11023
[32m[0906 15-18-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 205.07468, mean: 0.11026
[32m[0906 15-18-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01911, current rewards: 210.62855, mean: 0.11028
[32m[0906 15-18-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01911, current rewards: 215.03644, mean: 0.10971
[32m[0906 15-18-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 220.55089, mean: 0.10973
[32m[0906 15-18-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01911, current rewards: 226.07067, mean: 0.10974
[32m[0906 15-18-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 231.49994, mean: 0.10972
[32m[0906 15-18-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 237.01497, mean: 0.10973
[32m[0906 15-18-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01913, current rewards: 242.53204, mean: 0.10974
[32m[0906 15-18-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: 248.04631, mean: 0.10976
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 253.56439, mean: 0.10977
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: 259.08169, mean: 0.10978
[32m[0906 15-18-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: 264.60416, mean: 0.10979
[32m[0906 15-18-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 270.11597, mean: 0.10980
[32m[0906 15-18-55 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-18-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-18-56 @MBExp.py:227][0m Rewards obtained: [274.5577619160167], Lows: [0], Highs: [2], Total time: 2660.8949290000005
[32m[0906 15-20-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-20-54 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-20-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01861, current rewards: 1.11162, mean: 0.11116
[32m[0906 15-20-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01901, current rewards: 6.67167, mean: 0.11119
[32m[0906 15-20-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.23027, mean: 0.11118
[32m[0906 15-20-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01904, current rewards: 17.78393, mean: 0.11115
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.33698, mean: 0.11113
[32m[0906 15-20-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 28.89434, mean: 0.11113
[32m[0906 15-21-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.44981, mean: 0.11113
[32m[0906 15-21-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 40.00686, mean: 0.11113
[32m[0906 15-21-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 45.56498, mean: 0.11113
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 51.12261, mean: 0.11114
[32m[0906 15-21-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 56.67575, mean: 0.11113
[32m[0906 15-21-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 62.20599, mean: 0.11108
[32m[0906 15-21-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.78306, mean: 0.11112
[32m[0906 15-21-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 73.36143, mean: 0.11115
[32m[0906 15-21-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 78.93773, mean: 0.11118
[32m[0906 15-21-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 84.51366, mean: 0.11120
[32m[0906 15-21-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 90.08227, mean: 0.11121
[32m[0906 15-21-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 95.65404, mean: 0.11123
[32m[0906 15-21-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 101.22957, mean: 0.11124
[32m[0906 15-21-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 106.80847, mean: 0.11126
[32m[0906 15-21-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 112.38530, mean: 0.11127
[32m[0906 15-21-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 117.96298, mean: 0.11129
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 123.58550, mean: 0.11134
[32m[0906 15-21-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 129.13098, mean: 0.11132
[32m[0906 15-21-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 134.70729, mean: 0.11133
[32m[0906 15-21-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 140.24790, mean: 0.11131
[32m[0906 15-21-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 145.79852, mean: 0.11130
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 151.34140, mean: 0.11128
[32m[0906 15-21-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 156.88417, mean: 0.11127
[32m[0906 15-21-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 162.43016, mean: 0.11125
[32m[0906 15-21-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 167.96985, mean: 0.11124
[32m[0906 15-21-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 173.55540, mean: 0.11125
[32m[0906 15-21-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 179.10300, mean: 0.11124
[32m[0906 15-21-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: 184.69692, mean: 0.11126
[32m[0906 15-21-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01910, current rewards: 190.24148, mean: 0.11125
[32m[0906 15-21-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: 195.79064, mean: 0.11124
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 201.31533, mean: 0.11122
[32m[0906 15-21-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 206.83939, mean: 0.11120
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01911, current rewards: 212.36326, mean: 0.11118
[32m[0906 15-21-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01911, current rewards: 217.89124, mean: 0.11117
[32m[0906 15-21-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 223.41800, mean: 0.11115
[32m[0906 15-21-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01911, current rewards: 228.84701, mean: 0.11109
[32m[0906 15-21-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 234.37548, mean: 0.11108
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 239.90680, mean: 0.11107
[32m[0906 15-21-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 245.43868, mean: 0.11106
[32m[0906 15-21-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 250.97569, mean: 0.11105
[32m[0906 15-21-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 256.50264, mean: 0.11104
[32m[0906 15-21-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 262.03054, mean: 0.11103
[32m[0906 15-21-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 267.55670, mean: 0.11102
[32m[0906 15-21-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 273.16017, mean: 0.11104
[32m[0906 15-21-42 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-21-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-21-42 @MBExp.py:227][0m Rewards obtained: [277.86133256174026], Lows: [0], Highs: [0], Total time: 2709.4456640000003
[32m[0906 15-23-43 @MBExp.py:144][0m ####################################################################
[32m[0906 15-23-43 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-23-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: 1.15421, mean: 0.11542
[32m[0906 15-23-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 6.78100, mean: 0.11302
[32m[0906 15-23-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.41185, mean: 0.11284
[32m[0906 15-23-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 18.04855, mean: 0.11280
[32m[0906 15-23-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 23.67205, mean: 0.11272
[32m[0906 15-23-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 29.28876, mean: 0.11265
[32m[0906 15-23-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.90724, mean: 0.11260
[32m[0906 15-23-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 40.53774, mean: 0.11260
[32m[0906 15-23-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 46.04607, mean: 0.11231
[32m[0906 15-23-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 51.62737, mean: 0.11223
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 57.20369, mean: 0.11216
[32m[0906 15-23-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 62.77940, mean: 0.11211
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 68.33694, mean: 0.11203
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 73.89347, mean: 0.11196
[32m[0906 15-23-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 79.45489, mean: 0.11191
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 85.01294, mean: 0.11186
[32m[0906 15-23-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 90.62701, mean: 0.11189
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 96.22688, mean: 0.11189
[32m[0906 15-24-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 101.79327, mean: 0.11186
[32m[0906 15-24-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 107.47386, mean: 0.11195
[32m[0906 15-24-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 113.11495, mean: 0.11199
[32m[0906 15-24-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 118.76294, mean: 0.11204
[32m[0906 15-24-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 124.40886, mean: 0.11208
[32m[0906 15-24-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 130.05015, mean: 0.11211
[32m[0906 15-24-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 135.78855, mean: 0.11222
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 142.55605, mean: 0.11314
[32m[0906 15-24-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 150.01624, mean: 0.11452
[32m[0906 15-24-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 157.47643, mean: 0.11579
[32m[0906 15-24-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 158.04140, mean: 0.11209
[32m[0906 15-24-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 108.04140, mean: 0.07400
[32m[0906 15-24-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 58.04140, mean: 0.03844
[32m[0906 15-24-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 8.04140, mean: 0.00515
[32m[0906 15-24-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: -41.95860, mean: -0.02606
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: -91.95860, mean: -0.05540
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: -141.95860, mean: -0.08302
[32m[0906 15-24-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: -191.95860, mean: -0.10907
[32m[0906 15-24-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: -241.95860, mean: -0.13368
[32m[0906 15-24-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: -291.95860, mean: -0.15697
[32m[0906 15-24-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01910, current rewards: -341.95860, mean: -0.17904
[32m[0906 15-24-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01910, current rewards: -391.95860, mean: -0.19998
[32m[0906 15-24-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: -441.95860, mean: -0.21988
[32m[0906 15-24-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: -491.95860, mean: -0.23881
[32m[0906 15-24-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01910, current rewards: -541.95860, mean: -0.25685
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01910, current rewards: -591.95860, mean: -0.27405
[32m[0906 15-24-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01911, current rewards: -641.95860, mean: -0.29048
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01911, current rewards: -691.95860, mean: -0.30618
[32m[0906 15-24-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01911, current rewards: -741.95860, mean: -0.32119
[32m[0906 15-24-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: -791.95860, mean: -0.33558
[32m[0906 15-24-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: -841.95860, mean: -0.34936
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: -891.95860, mean: -0.36258
[32m[0906 15-24-31 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-24-31 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-24-31 @MBExp.py:227][0m Rewards obtained: [-931.9586013033148], Lows: [0], Highs: [1096], Total time: 2757.956086
[32m[0906 15-26-34 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-34 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-26-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01887, current rewards: 0.00077, mean: 0.00008
[32m[0906 15-26-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 5.42296, mean: 0.09038
[32m[0906 15-26-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01902, current rewards: 10.82054, mean: 0.09837
[32m[0906 15-26-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 16.21773, mean: 0.10136
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 21.61646, mean: 0.10294
[32m[0906 15-26-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 27.07282, mean: 0.10413
[32m[0906 15-26-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 32.57598, mean: 0.10508
[32m[0906 15-26-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 38.07092, mean: 0.10575
[32m[0906 15-26-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 43.57453, mean: 0.10628
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01910, current rewards: 49.07477, mean: 0.10668
[32m[0906 15-26-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 54.57677, mean: 0.10701
[32m[0906 15-26-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 60.08135, mean: 0.10729
[32m[0906 15-26-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 65.57659, mean: 0.10750
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 71.07637, mean: 0.10769
[32m[0906 15-26-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 76.58219, mean: 0.10786
[32m[0906 15-26-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 82.08053, mean: 0.10800
[32m[0906 15-26-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 87.65009, mean: 0.10821
[32m[0906 15-26-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 93.12721, mean: 0.10829
[32m[0906 15-26-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 98.60056, mean: 0.10835
[32m[0906 15-26-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 104.07598, mean: 0.10841
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 109.55009, mean: 0.10847
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 115.02290, mean: 0.10851
[32m[0906 15-26-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 120.49910, mean: 0.10856
[32m[0906 15-26-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 125.97481, mean: 0.10860
[32m[0906 15-26-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 131.50180, mean: 0.10868
[32m[0906 15-26-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 137.01904, mean: 0.10875
[32m[0906 15-26-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 142.53444, mean: 0.10880
[32m[0906 15-27-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 148.05120, mean: 0.10886
[32m[0906 15-27-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 153.56768, mean: 0.10891
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 159.08184, mean: 0.10896
[32m[0906 15-27-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 164.61130, mean: 0.10901
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 170.10697, mean: 0.10904
[32m[0906 15-27-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 175.55139, mean: 0.10904
[32m[0906 15-27-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 181.06685, mean: 0.10908
[32m[0906 15-27-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 186.58259, mean: 0.10911
[32m[0906 15-27-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 192.09656, mean: 0.10915
[32m[0906 15-27-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 197.61587, mean: 0.10918
[32m[0906 15-27-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 203.13025, mean: 0.10921
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 208.64984, mean: 0.10924
[32m[0906 15-27-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01910, current rewards: 214.16642, mean: 0.10927
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 219.62506, mean: 0.10927
[32m[0906 15-27-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 224.98156, mean: 0.10921
[32m[0906 15-27-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 230.43355, mean: 0.10921
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01911, current rewards: 235.89061, mean: 0.10921
[32m[0906 15-27-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01911, current rewards: 241.34178, mean: 0.10920
[32m[0906 15-27-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 246.79390, mean: 0.10920
[32m[0906 15-27-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 252.24721, mean: 0.10920
[32m[0906 15-27-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 257.70051, mean: 0.10920
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 263.15508, mean: 0.10919
[32m[0906 15-27-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 268.67415, mean: 0.10922
[32m[0906 15-27-22 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-27-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-27-22 @MBExp.py:227][0m Rewards obtained: [273.0251356838093], Lows: [0], Highs: [1], Total time: 2806.5131100000003
[32m[0906 15-29-27 @MBExp.py:144][0m ####################################################################
[32m[0906 15-29-27 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 15-29-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01907, current rewards: 1.20645, mean: 0.12065
[32m[0906 15-29-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.79246, mean: 0.11321
[32m[0906 15-29-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01910, current rewards: 12.36277, mean: 0.11239
[32m[0906 15-29-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.92991, mean: 0.11206
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.50195, mean: 0.11191
[32m[0906 15-29-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 29.07016, mean: 0.11181
[32m[0906 15-29-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.64042, mean: 0.11174
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 40.17678, mean: 0.11160
[32m[0906 15-29-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.73041, mean: 0.11154
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.28923, mean: 0.11150
[32m[0906 15-29-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 56.84581, mean: 0.11146
[32m[0906 15-29-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.39917, mean: 0.11143
[32m[0906 15-29-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 67.95465, mean: 0.11140
[32m[0906 15-29-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 73.51005, mean: 0.11138
[32m[0906 15-29-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 79.06420, mean: 0.11136
[32m[0906 15-29-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 84.75826, mean: 0.11152
[32m[0906 15-29-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 90.61528, mean: 0.11187
[32m[0906 15-29-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 96.38502, mean: 0.11208
[32m[0906 15-29-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 102.15729, mean: 0.11226
[32m[0906 15-29-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 107.91427, mean: 0.11241
[32m[0906 15-29-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 113.51477, mean: 0.11239
[32m[0906 15-29-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 119.11524, mean: 0.11237
[32m[0906 15-29-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 124.71693, mean: 0.11236
[32m[0906 15-29-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 130.31698, mean: 0.11234
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 135.81592, mean: 0.11224
[32m[0906 15-29-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 141.39527, mean: 0.11222
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 146.95808, mean: 0.11218
[32m[0906 15-29-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 152.49905, mean: 0.11213
[32m[0906 15-29-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 158.04740, mean: 0.11209
[32m[0906 15-29-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 163.59011, mean: 0.11205
[32m[0906 15-29-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 169.13682, mean: 0.11201
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 174.68137, mean: 0.11198
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: 180.23266, mean: 0.11195
[32m[0906 15-29-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01912, current rewards: 185.86100, mean: 0.11196
[32m[0906 15-30-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: 191.40448, mean: 0.11193
[32m[0906 15-30-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: 196.95106, mean: 0.11190
[32m[0906 15-30-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 202.49555, mean: 0.11188
[32m[0906 15-30-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 208.04107, mean: 0.11185
[32m[0906 15-30-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 213.66174, mean: 0.11186
[32m[0906 15-30-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 219.17579, mean: 0.11182
[32m[0906 15-30-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 224.69292, mean: 0.11179
[32m[0906 15-30-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 230.17790, mean: 0.11174
[32m[0906 15-30-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 235.70104, mean: 0.11171
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 241.22526, mean: 0.11168
[32m[0906 15-30-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: 246.74806, mean: 0.11165
[32m[0906 15-30-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 252.28245, mean: 0.11163
[32m[0906 15-30-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 257.84467, mean: 0.11162
[32m[0906 15-30-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 263.40115, mean: 0.11161
[32m[0906 15-30-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 268.96038, mean: 0.11160
[32m[0906 15-30-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 274.53107, mean: 0.11160
[32m[0906 15-30-15 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-30-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-30-16 @MBExp.py:227][0m Rewards obtained: [278.9758029054873], Lows: [0], Highs: [0], Total time: 2855.099708
[32m[0906 15-32-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-22 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 15-32-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01905, current rewards: 1.14375, mean: 0.11438
[32m[0906 15-32-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.72734, mean: 0.11212
[32m[0906 15-32-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.28780, mean: 0.11171
[32m[0906 15-32-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.84870, mean: 0.11155
[32m[0906 15-32-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.41043, mean: 0.11148
[32m[0906 15-32-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 28.97505, mean: 0.11144
[32m[0906 15-32-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.51492, mean: 0.11134
[32m[0906 15-32-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 40.07160, mean: 0.11131
[32m[0906 15-32-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 45.62868, mean: 0.11129
[32m[0906 15-32-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 51.18461, mean: 0.11127
[32m[0906 15-32-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 57.05513, mean: 0.11187
[32m[0906 15-32-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 62.73219, mean: 0.11202
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 68.40926, mean: 0.11215
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 74.08633, mean: 0.11225
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 79.76339, mean: 0.11234
[32m[0906 15-32-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 85.44046, mean: 0.11242
[32m[0906 15-32-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 91.11753, mean: 0.11249
[32m[0906 15-32-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 96.79459, mean: 0.11255
[32m[0906 15-32-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 74.63312, mean: 0.08201
[32m[0906 15-32-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 24.63312, mean: 0.02566
[32m[0906 15-32-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: -25.36688, mean: -0.02512
[32m[0906 15-32-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: -75.36688, mean: -0.07110
[32m[0906 15-32-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: -125.36688, mean: -0.11294
[32m[0906 15-32-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: -175.36688, mean: -0.15118
[32m[0906 15-32-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: -225.36688, mean: -0.18625
[32m[0906 15-32-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: -275.36688, mean: -0.21855
[32m[0906 15-32-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: -325.36688, mean: -0.24837
[32m[0906 15-32-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: -375.36688, mean: -0.27601
[32m[0906 15-32-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: -425.36688, mean: -0.30168
[32m[0906 15-32-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: -475.36688, mean: -0.32559
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: -525.36688, mean: -0.34793
[32m[0906 15-32-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: -575.36688, mean: -0.36882
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: -625.36688, mean: -0.38843
[32m[0906 15-32-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: -675.36688, mean: -0.40685
[32m[0906 15-32-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: -725.36688, mean: -0.42419
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: -775.36688, mean: -0.44055
[32m[0906 15-32-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: -825.36688, mean: -0.45600
[32m[0906 15-32-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: -875.36688, mean: -0.47063
[32m[0906 15-32-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01912, current rewards: -925.36688, mean: -0.48449
[32m[0906 15-33-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: -975.36688, mean: -0.49764
[32m[0906 15-33-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: -1025.36688, mean: -0.51013
[32m[0906 15-33-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01913, current rewards: -1075.36688, mean: -0.52202
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: -1125.36688, mean: -0.53335
[32m[0906 15-33-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: -1175.36688, mean: -0.54415
[32m[0906 15-33-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: -1225.36688, mean: -0.55446
[32m[0906 15-33-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: -1275.36688, mean: -0.56432
[32m[0906 15-33-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: -1325.36688, mean: -0.57375
[32m[0906 15-33-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: -1375.36688, mean: -0.58278
[32m[0906 15-33-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: -1425.36688, mean: -0.59144
[32m[0906 15-33-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: -1475.36688, mean: -0.59974
[32m[0906 15-33-10 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-33-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-33-10 @MBExp.py:227][0m Rewards obtained: [-1515.3668755180097], Lows: [0], Highs: [1615], Total time: 2903.6312350000003
[32m[0906 15-35-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-35-18 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 15-35-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01877, current rewards: 1.08334, mean: 0.10833
[32m[0906 15-35-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01885, current rewards: 6.64877, mean: 0.11081
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01895, current rewards: 12.22048, mean: 0.11110
[32m[0906 15-35-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01904, current rewards: 17.78467, mean: 0.11115
[32m[0906 15-35-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 23.35052, mean: 0.11119
[32m[0906 15-35-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 28.91626, mean: 0.11122
[32m[0906 15-35-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01907, current rewards: 34.49365, mean: 0.11127
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: 40.08439, mean: 0.11135
[32m[0906 15-35-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01907, current rewards: 45.64841, mean: 0.11134
[32m[0906 15-35-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01906, current rewards: 51.20997, mean: 0.11133
[32m[0906 15-35-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 56.77425, mean: 0.11132
[32m[0906 15-35-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01909, current rewards: 62.40427, mean: 0.11144
[32m[0906 15-35-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 67.96954, mean: 0.11143
[32m[0906 15-35-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 73.53489, mean: 0.11142
[32m[0906 15-35-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 79.09844, mean: 0.11141
[32m[0906 15-35-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 84.67870, mean: 0.11142
[32m[0906 15-35-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 90.23674, mean: 0.11140
[32m[0906 15-35-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 95.88766, mean: 0.11150
[32m[0906 15-35-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 101.35315, mean: 0.11138
[32m[0906 15-35-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 106.82129, mean: 0.11127
[32m[0906 15-35-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 112.29102, mean: 0.11118
[32m[0906 15-35-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 116.65118, mean: 0.11005
[32m[0906 15-35-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 122.39133, mean: 0.11026
[32m[0906 15-35-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 128.07509, mean: 0.11041
[32m[0906 15-35-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 133.72100, mean: 0.11051
[32m[0906 15-35-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 139.37197, mean: 0.11061
[32m[0906 15-35-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 145.01190, mean: 0.11070
[32m[0906 15-35-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 150.63490, mean: 0.11076
[32m[0906 15-35-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 156.18150, mean: 0.11077
[32m[0906 15-35-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 161.72913, mean: 0.11077
[32m[0906 15-35-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 167.28413, mean: 0.11078
[32m[0906 15-35-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 172.85380, mean: 0.11080
[32m[0906 15-35-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 178.39817, mean: 0.11081
[32m[0906 15-35-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 183.94923, mean: 0.11081
[32m[0906 15-35-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 189.49102, mean: 0.11081
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: 195.03291, mean: 0.11081
[32m[0906 15-35-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 200.57746, mean: 0.11082
[32m[0906 15-35-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 205.94011, mean: 0.11072
[32m[0906 15-35-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 211.27538, mean: 0.11062
[32m[0906 15-35-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 216.59101, mean: 0.11051
[32m[0906 15-35-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 221.95774, mean: 0.11043
[32m[0906 15-35-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 227.31898, mean: 0.11035
[32m[0906 15-35-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 232.68199, mean: 0.11028
[32m[0906 15-36-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 238.19489, mean: 0.11028
[32m[0906 15-36-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: 243.66530, mean: 0.11026
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 249.13624, mean: 0.11024
[32m[0906 15-36-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01914, current rewards: 254.60649, mean: 0.11022
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 259.96256, mean: 0.11015
[32m[0906 15-36-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 265.47816, mean: 0.11016
[32m[0906 15-36-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 270.99050, mean: 0.11016
[32m[0906 15-36-07 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-36-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-36-07 @MBExp.py:227][0m Rewards obtained: [275.4020295349868], Lows: [0], Highs: [1], Total time: 2952.2212160000004
[32m[0906 15-38-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-16 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 15-38-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.13340, mean: 0.11334
[32m[0906 15-38-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01892, current rewards: 6.77142, mean: 0.11286
[32m[0906 15-38-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01896, current rewards: 12.36238, mean: 0.11239
[32m[0906 15-38-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01902, current rewards: 17.95815, mean: 0.11224
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 23.55063, mean: 0.11215
[32m[0906 15-38-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: 29.14648, mean: 0.11210
[32m[0906 15-38-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.77135, mean: 0.11217
[32m[0906 15-38-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 40.37710, mean: 0.11216
[32m[0906 15-38-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01907, current rewards: 45.94068, mean: 0.11205
[32m[0906 15-38-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 51.50183, mean: 0.11196
[32m[0906 15-38-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01907, current rewards: 57.06360, mean: 0.11189
[32m[0906 15-38-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01906, current rewards: 62.62701, mean: 0.11183
[32m[0906 15-38-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01906, current rewards: 68.19064, mean: 0.11179
[32m[0906 15-38-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01907, current rewards: 73.75346, mean: 0.11175
[32m[0906 15-38-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01907, current rewards: 79.19657, mean: 0.11154
[32m[0906 15-38-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 84.74479, mean: 0.11151
[32m[0906 15-38-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01909, current rewards: 90.30252, mean: 0.11148
[32m[0906 15-38-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01908, current rewards: 95.85565, mean: 0.11146
[32m[0906 15-38-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 101.41064, mean: 0.11144
[32m[0906 15-38-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 106.96643, mean: 0.11142
[32m[0906 15-38-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 112.52327, mean: 0.11141
[32m[0906 15-38-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 118.08552, mean: 0.11140
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01909, current rewards: 123.66640, mean: 0.11141
[32m[0906 15-38-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 129.31918, mean: 0.11148
[32m[0906 15-38-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 134.85255, mean: 0.11145
[32m[0906 15-38-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 140.38819, mean: 0.11142
[32m[0906 15-38-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 145.92033, mean: 0.11139
[32m[0906 15-38-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 152.77320, mean: 0.11233
[32m[0906 15-38-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01902, current rewards: 160.23340, mean: 0.11364
[32m[0906 15-38-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01903, current rewards: 167.69359, mean: 0.11486
[32m[0906 15-38-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 175.15378, mean: 0.11600
[32m[0906 15-38-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01904, current rewards: 181.81922, mean: 0.11655
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: 165.44638, mean: 0.10276
[32m[0906 15-38-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 170.94402, mean: 0.10298
[32m[0906 15-38-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 176.49717, mean: 0.10321
[32m[0906 15-38-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 182.04998, mean: 0.10344
[32m[0906 15-38-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: 187.60223, mean: 0.10365
[32m[0906 15-38-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01905, current rewards: 193.15912, mean: 0.10385
[32m[0906 15-38-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01905, current rewards: 198.70990, mean: 0.10404
[32m[0906 15-38-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01905, current rewards: 204.28023, mean: 0.10422
[32m[0906 15-38-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01906, current rewards: 209.88250, mean: 0.10442
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01906, current rewards: 215.50190, mean: 0.10461
[32m[0906 15-38-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01906, current rewards: 221.11297, mean: 0.10479
[32m[0906 15-38-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01905, current rewards: 226.72327, mean: 0.10496
[32m[0906 15-38-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01905, current rewards: 232.26322, mean: 0.10510
[32m[0906 15-39-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01905, current rewards: 237.79472, mean: 0.10522
[32m[0906 15-39-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01906, current rewards: 243.32570, mean: 0.10534
[32m[0906 15-39-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01906, current rewards: 248.73540, mean: 0.10540
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01906, current rewards: 254.29044, mean: 0.10551
[32m[0906 15-39-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01906, current rewards: 259.84768, mean: 0.10563
[32m[0906 15-39-05 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-39-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-39-05 @MBExp.py:227][0m Rewards obtained: [264.3035064485546], Lows: [0], Highs: [20], Total time: 3000.636472
[32m[0906 15-41-17 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-17 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 15-41-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01866, current rewards: 1.41652, mean: 0.14165
[32m[0906 15-41-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01902, current rewards: 7.04128, mean: 0.11735
[32m[0906 15-41-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.66002, mean: 0.11509
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01905, current rewards: 18.27678, mean: 0.11423
[32m[0906 15-41-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.90209, mean: 0.11382
[32m[0906 15-41-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 29.51662, mean: 0.11353
[32m[0906 15-41-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 35.13945, mean: 0.11335
[32m[0906 15-41-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 36.54413, mean: 0.10151
[32m[0906 15-41-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 42.12191, mean: 0.10274
[32m[0906 15-41-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 47.70304, mean: 0.10370
[32m[0906 15-41-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 53.28008, mean: 0.10447
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 58.85670, mean: 0.10510
[32m[0906 15-41-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 64.43251, mean: 0.10563
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 69.97794, mean: 0.10603
[32m[0906 15-41-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 75.44309, mean: 0.10626
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01913, current rewards: 81.01266, mean: 0.10660
[32m[0906 15-41-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 86.58474, mean: 0.10689
[32m[0906 15-41-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 92.16462, mean: 0.10717
[32m[0906 15-41-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 97.73585, mean: 0.10740
[32m[0906 15-41-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 103.31731, mean: 0.10762
[32m[0906 15-41-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 108.88750, mean: 0.10781
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 114.45876, mean: 0.10798
[32m[0906 15-41-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 120.16033, mean: 0.10825
[32m[0906 15-41-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 126.15525, mean: 0.10875
[32m[0906 15-41-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 131.95048, mean: 0.10905
[32m[0906 15-41-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 137.74572, mean: 0.10932
[32m[0906 15-41-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 143.54095, mean: 0.10957
[32m[0906 15-41-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 149.33618, mean: 0.10981
[32m[0906 15-41-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 155.13141, mean: 0.11002
[32m[0906 15-41-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 160.92664, mean: 0.11022
[32m[0906 15-41-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 166.72187, mean: 0.11041
[32m[0906 15-41-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 172.51710, mean: 0.11059
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 165.99761, mean: 0.10310
[32m[0906 15-41-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 171.61178, mean: 0.10338
[32m[0906 15-41-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 177.22824, mean: 0.10364
[32m[0906 15-41-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 182.84549, mean: 0.10389
[32m[0906 15-41-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 188.50224, mean: 0.10414
[32m[0906 15-41-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 194.04573, mean: 0.10433
[32m[0906 15-41-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01910, current rewards: 199.58442, mean: 0.10449
[32m[0906 15-41-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01910, current rewards: 205.11168, mean: 0.10465
[32m[0906 15-41-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 210.65399, mean: 0.10480
[32m[0906 15-41-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 216.19500, mean: 0.10495
[32m[0906 15-41-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 221.73546, mean: 0.10509
[32m[0906 15-41-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 227.27435, mean: 0.10522
[32m[0906 15-42-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 232.81263, mean: 0.10535
[32m[0906 15-42-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 238.35373, mean: 0.10547
[32m[0906 15-42-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 243.89293, mean: 0.10558
[32m[0906 15-42-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 249.30989, mean: 0.10564
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 254.84456, mean: 0.10574
[32m[0906 15-42-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 260.38458, mean: 0.10585
[32m[0906 15-42-05 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-42-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-42-05 @MBExp.py:227][0m Rewards obtained: [264.81614634182415], Lows: [2], Highs: [11], Total time: 3049.189683
[32m[0906 15-44-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-44-19 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 15-44-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01885, current rewards: 1.31311, mean: 0.13131
[32m[0906 15-44-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01928, current rewards: 6.90266, mean: 0.11504
[32m[0906 15-44-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.44148, mean: 0.11310
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.97852, mean: 0.11237
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 23.51606, mean: 0.11198
[32m[0906 15-44-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 29.05123, mean: 0.11174
[32m[0906 15-44-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.55961, mean: 0.11148
[32m[0906 15-44-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 40.09874, mean: 0.11139
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 45.63764, mean: 0.11131
[32m[0906 15-44-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 51.17117, mean: 0.11124
[32m[0906 15-44-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 56.70830, mean: 0.11119
[32m[0906 15-44-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 62.24443, mean: 0.11115
[32m[0906 15-44-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 67.78121, mean: 0.11112
[32m[0906 15-44-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.36091, mean: 0.11115
[32m[0906 15-44-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 78.93765, mean: 0.11118
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 84.56387, mean: 0.11127
[32m[0906 15-44-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 90.18123, mean: 0.11133
[32m[0906 15-44-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 95.80224, mean: 0.11140
[32m[0906 15-44-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 101.42250, mean: 0.11145
[32m[0906 15-44-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 107.04115, mean: 0.11150
[32m[0906 15-44-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 112.66163, mean: 0.11155
[32m[0906 15-44-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 118.28188, mean: 0.11159
[32m[0906 15-44-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 124.03957, mean: 0.11175
[32m[0906 15-44-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 129.57517, mean: 0.11170
[32m[0906 15-44-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 135.10617, mean: 0.11166
[32m[0906 15-44-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 140.63688, mean: 0.11162
[32m[0906 15-44-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 146.16764, mean: 0.11158
[32m[0906 15-44-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 151.69585, mean: 0.11154
[32m[0906 15-44-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: 157.22132, mean: 0.11150
[32m[0906 15-44-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 162.75006, mean: 0.11147
[32m[0906 15-44-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 168.27717, mean: 0.11144
[32m[0906 15-44-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 173.68048, mean: 0.11133
[32m[0906 15-44-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 179.13285, mean: 0.11126
[32m[0906 15-44-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 184.57983, mean: 0.11119
[32m[0906 15-44-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 190.02994, mean: 0.11113
[32m[0906 15-44-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: 195.47742, mean: 0.11107
[32m[0906 15-44-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: 200.91818, mean: 0.11100
[32m[0906 15-44-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 206.36314, mean: 0.11095
[32m[0906 15-44-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01912, current rewards: 211.80909, mean: 0.11089
[32m[0906 15-44-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01912, current rewards: 217.25101, mean: 0.11084
[32m[0906 15-44-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: 222.75077, mean: 0.11082
[32m[0906 15-44-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 228.28225, mean: 0.11082
[32m[0906 15-45-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 233.80793, mean: 0.11081
[32m[0906 15-45-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 239.33292, mean: 0.11080
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 244.86295, mean: 0.11080
[32m[0906 15-45-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 250.39330, mean: 0.11079
[32m[0906 15-45-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 255.92148, mean: 0.11079
[32m[0906 15-45-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 261.52501, mean: 0.11082
[32m[0906 15-45-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 267.13782, mean: 0.11085
[32m[0906 15-45-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 272.67719, mean: 0.11084
[32m[0906 15-45-08 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-45-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-45-08 @MBExp.py:227][0m Rewards obtained: [277.10195978424105], Lows: [0], Highs: [0], Total time: 3097.752997
[32m[0906 15-47-24 @MBExp.py:144][0m ####################################################################
[32m[0906 15-47-24 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 15-47-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01938, current rewards: 1.17730, mean: 0.11773
[32m[0906 15-47-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 6.83058, mean: 0.11384
[32m[0906 15-47-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 12.45109, mean: 0.11319
[32m[0906 15-47-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 18.07081, mean: 0.11294
[32m[0906 15-47-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.68629, mean: 0.11279
[32m[0906 15-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 29.30176, mean: 0.11270
[32m[0906 15-47-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.91898, mean: 0.11264
[32m[0906 15-47-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 40.53622, mean: 0.11260
[32m[0906 15-47-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 46.16091, mean: 0.11259
[32m[0906 15-47-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 51.77712, mean: 0.11256
[32m[0906 15-47-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 55.41086, mean: 0.10865
[32m[0906 15-47-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 60.98777, mean: 0.10891
[32m[0906 15-47-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 66.56463, mean: 0.10912
[32m[0906 15-47-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01914, current rewards: 72.14153, mean: 0.10931
[32m[0906 15-47-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 76.49422, mean: 0.10774
[32m[0906 15-47-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 81.98438, mean: 0.10787
[32m[0906 15-47-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 87.51515, mean: 0.10804
[32m[0906 15-47-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 93.04869, mean: 0.10820
[32m[0906 15-47-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 98.58251, mean: 0.10833
[32m[0906 15-47-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 104.11597, mean: 0.10845
[32m[0906 15-47-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 109.64525, mean: 0.10856
[32m[0906 15-47-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 115.20751, mean: 0.10869
[32m[0906 15-47-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 120.74460, mean: 0.10878
[32m[0906 15-47-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 126.43197, mean: 0.10899
[32m[0906 15-47-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 131.98709, mean: 0.10908
[32m[0906 15-47-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 137.54162, mean: 0.10916
[32m[0906 15-47-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 143.09761, mean: 0.10923
[32m[0906 15-47-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 148.65514, mean: 0.10931
[32m[0906 15-47-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 154.21157, mean: 0.10937
[32m[0906 15-47-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 159.76742, mean: 0.10943
[32m[0906 15-47-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 165.32088, mean: 0.10948
[32m[0906 15-47-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 170.79926, mean: 0.10949
[32m[0906 15-47-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 176.34355, mean: 0.10953
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: 181.90559, mean: 0.10958
[32m[0906 15-47-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 187.46369, mean: 0.10963
[32m[0906 15-47-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: 193.02290, mean: 0.10967
[32m[0906 15-47-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: 198.58416, mean: 0.10972
[32m[0906 15-48-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 204.14718, mean: 0.10976
[32m[0906 15-48-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01911, current rewards: 209.75248, mean: 0.10982
[32m[0906 15-48-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01911, current rewards: 215.33602, mean: 0.10987
[32m[0906 15-48-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 220.93376, mean: 0.10992
[32m[0906 15-48-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01911, current rewards: 226.53247, mean: 0.10997
[32m[0906 15-48-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 232.12592, mean: 0.11001
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01911, current rewards: 237.72474, mean: 0.11006
[32m[0906 15-48-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 243.31245, mean: 0.11010
[32m[0906 15-48-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 248.92217, mean: 0.11014
[32m[0906 15-48-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 254.53162, mean: 0.11019
[32m[0906 15-48-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 260.13978, mean: 0.11023
[32m[0906 15-48-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: 265.78978, mean: 0.11029
[32m[0906 15-48-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 271.40489, mean: 0.11033
[32m[0906 15-48-13 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-48-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-48-13 @MBExp.py:227][0m Rewards obtained: [275.88892302416355], Lows: [1], Highs: [1], Total time: 3146.335113
[32m[0906 15-50-31 @MBExp.py:144][0m ####################################################################
[32m[0906 15-50-31 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.16788, mean: 0.11679
[32m[0906 15-50-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01902, current rewards: 6.60525, mean: 0.11009
[32m[0906 15-50-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.03076, mean: 0.10937
[32m[0906 15-50-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01902, current rewards: 17.45462, mean: 0.10909
[32m[0906 15-50-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01901, current rewards: 22.87801, mean: 0.10894
[32m[0906 15-50-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01905, current rewards: 28.30142, mean: 0.10885
[32m[0906 15-50-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01905, current rewards: 33.72934, mean: 0.10880
[32m[0906 15-50-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: 39.15444, mean: 0.10876
[32m[0906 15-50-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 44.80292, mean: 0.10928
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.41110, mean: 0.10959
[32m[0906 15-50-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 56.01966, mean: 0.10984
[32m[0906 15-50-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 61.62857, mean: 0.11005
[32m[0906 15-50-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 67.23416, mean: 0.11022
[32m[0906 15-50-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 72.84309, mean: 0.11037
[32m[0906 15-50-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 78.32791, mean: 0.11032
[32m[0906 15-50-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 83.85483, mean: 0.11034
[32m[0906 15-50-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 89.38443, mean: 0.11035
[32m[0906 15-50-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 94.91082, mean: 0.11036
[32m[0906 15-50-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 100.55331, mean: 0.11050
[32m[0906 15-50-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 106.09592, mean: 0.11052
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 111.63306, mean: 0.11053
[32m[0906 15-50-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 117.17277, mean: 0.11054
[32m[0906 15-50-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 122.71430, mean: 0.11055
[32m[0906 15-50-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 128.20992, mean: 0.11053
[32m[0906 15-50-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 130.48906, mean: 0.10784
[32m[0906 15-50-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 136.04757, mean: 0.10797
[32m[0906 15-50-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 141.57868, mean: 0.10808
[32m[0906 15-50-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 147.10723, mean: 0.10817
[32m[0906 15-50-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 152.63647, mean: 0.10825
[32m[0906 15-50-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01908, current rewards: 158.17092, mean: 0.10834
[32m[0906 15-51-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 163.71423, mean: 0.10842
[32m[0906 15-51-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 169.23645, mean: 0.10848
[32m[0906 15-51-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01909, current rewards: 174.76467, mean: 0.10855
[32m[0906 15-51-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 180.29738, mean: 0.10861
[32m[0906 15-51-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 185.82953, mean: 0.10867
[32m[0906 15-51-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: 191.36839, mean: 0.10873
[32m[0906 15-51-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 196.89354, mean: 0.10878
[32m[0906 15-51-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01910, current rewards: 202.42456, mean: 0.10883
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01911, current rewards: 207.95751, mean: 0.10888
[32m[0906 15-51-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01911, current rewards: 213.49220, mean: 0.10892
[32m[0906 15-51-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 219.02176, mean: 0.10897
[32m[0906 15-51-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 224.55326, mean: 0.10901
[32m[0906 15-51-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 227.97475, mean: 0.10804
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 233.54329, mean: 0.10812
[32m[0906 15-51-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 239.10929, mean: 0.10819
[32m[0906 15-51-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 244.67561, mean: 0.10826
[32m[0906 15-51-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 250.24562, mean: 0.10833
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: 255.99001, mean: 0.10847
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: 261.53125, mean: 0.10852
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 266.95217, mean: 0.10852
[32m[0906 15-51-19 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-51-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-51-19 @MBExp.py:227][0m Rewards obtained: [271.28571686185376], Lows: [2], Highs: [1], Total time: 3194.930768
[32m[0906 15-53-40 @MBExp.py:144][0m ####################################################################
[32m[0906 15-53-40 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 15-53-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01869, current rewards: -0.91686, mean: -0.09169
[32m[0906 15-53-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01895, current rewards: 4.61418, mean: 0.07690
[32m[0906 15-53-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01897, current rewards: 10.14525, mean: 0.09223
[32m[0906 15-53-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01891, current rewards: 15.67586, mean: 0.09797
[32m[0906 15-53-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01895, current rewards: 18.95638, mean: 0.09027
[32m[0906 15-53-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01895, current rewards: 24.30882, mean: 0.09350
[32m[0906 15-53-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01897, current rewards: 29.69242, mean: 0.09578
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01898, current rewards: 35.09048, mean: 0.09747
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01898, current rewards: 40.49797, mean: 0.09878
[32m[0906 15-53-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01900, current rewards: 45.89838, mean: 0.09978
[32m[0906 15-53-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01902, current rewards: 51.30472, mean: 0.10060
[32m[0906 15-53-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01903, current rewards: 56.71024, mean: 0.10127
[32m[0906 15-53-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01905, current rewards: 62.11613, mean: 0.10183
[32m[0906 15-53-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01906, current rewards: 67.51744, mean: 0.10230
[32m[0906 15-53-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01907, current rewards: 73.01974, mean: 0.10284
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01907, current rewards: 78.41264, mean: 0.10317
[32m[0906 15-53-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01908, current rewards: 83.80594, mean: 0.10346
[32m[0906 15-53-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01908, current rewards: 89.19666, mean: 0.10372
[32m[0906 15-53-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 94.73818, mean: 0.10411
[32m[0906 15-53-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01908, current rewards: 100.29797, mean: 0.10448
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 105.86096, mean: 0.10481
[32m[0906 15-54-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 111.42099, mean: 0.10511
[32m[0906 15-54-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01909, current rewards: 116.98044, mean: 0.10539
[32m[0906 15-54-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 122.53814, mean: 0.10564
[32m[0906 15-54-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 128.10295, mean: 0.10587
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 133.66157, mean: 0.10608
[32m[0906 15-54-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 139.16790, mean: 0.10624
[32m[0906 15-54-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 144.66594, mean: 0.10637
[32m[0906 15-54-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: 150.16319, mean: 0.10650
[32m[0906 15-54-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01906, current rewards: 155.66842, mean: 0.10662
[32m[0906 15-54-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 161.18894, mean: 0.10675
[32m[0906 15-54-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 166.69758, mean: 0.10686
[32m[0906 15-54-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 172.26073, mean: 0.10699
[32m[0906 15-54-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 177.82607, mean: 0.10712
[32m[0906 15-54-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: 183.38975, mean: 0.10725
[32m[0906 15-54-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 188.95570, mean: 0.10736
[32m[0906 15-54-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 194.51855, mean: 0.10747
[32m[0906 15-54-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 200.08087, mean: 0.10757
[32m[0906 15-54-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 205.64611, mean: 0.10767
[32m[0906 15-54-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 211.27712, mean: 0.10779
[32m[0906 15-54-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 216.84296, mean: 0.10788
[32m[0906 15-54-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 222.40934, mean: 0.10797
[32m[0906 15-54-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01907, current rewards: 227.95523, mean: 0.10804
[32m[0906 15-54-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01907, current rewards: 233.48513, mean: 0.10809
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 239.01528, mean: 0.10815
[32m[0906 15-54-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01908, current rewards: 244.54873, mean: 0.10821
[32m[0906 15-54-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01908, current rewards: 250.08186, mean: 0.10826
[32m[0906 15-54-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01908, current rewards: 255.60797, mean: 0.10831
[32m[0906 15-54-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01909, current rewards: 261.13538, mean: 0.10835
[32m[0906 15-54-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01908, current rewards: 266.66876, mean: 0.10840
[32m[0906 15-54-28 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-54-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-54-28 @MBExp.py:227][0m Rewards obtained: [271.0919895177373], Lows: [1], Highs: [2], Total time: 3243.403131
[32m[0906 15-56-50 @MBExp.py:144][0m ####################################################################
[32m[0906 15-56-50 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 15-56-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: -0.95244, mean: -0.09524
[32m[0906 15-56-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01917, current rewards: 4.66226, mean: 0.07770
[32m[0906 15-56-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 10.26404, mean: 0.09331
[32m[0906 15-56-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 15.85545, mean: 0.09910
[32m[0906 15-56-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 21.47201, mean: 0.10225
[32m[0906 15-56-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 27.14286, mean: 0.10440
[32m[0906 15-56-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 32.77142, mean: 0.10571
[32m[0906 15-56-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 38.43915, mean: 0.10678
[32m[0906 15-56-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01906, current rewards: 44.09320, mean: 0.10754
[32m[0906 15-56-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 49.75418, mean: 0.10816
[32m[0906 15-57-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 55.40730, mean: 0.10864
[32m[0906 15-57-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 61.06093, mean: 0.10904
[32m[0906 15-57-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 66.57584, mean: 0.10914
[32m[0906 15-57-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 72.08578, mean: 0.10922
[32m[0906 15-57-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 77.62287, mean: 0.10933
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 83.14193, mean: 0.10940
[32m[0906 15-57-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 88.72997, mean: 0.10954
[32m[0906 15-57-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 94.28112, mean: 0.10963
[32m[0906 15-57-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 99.83305, mean: 0.10971
[32m[0906 15-57-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01910, current rewards: 105.38518, mean: 0.10978
[32m[0906 15-57-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 110.93887, mean: 0.10984
[32m[0906 15-57-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 116.49216, mean: 0.10990
[32m[0906 15-57-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 122.02665, mean: 0.10993
[32m[0906 15-57-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 127.56877, mean: 0.10997
[32m[0906 15-57-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 133.08703, mean: 0.10999
[32m[0906 15-57-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 138.60139, mean: 0.11000
[32m[0906 15-57-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 144.12529, mean: 0.11002
[32m[0906 15-57-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 149.64172, mean: 0.11003
[32m[0906 15-57-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 151.00710, mean: 0.10710
[32m[0906 15-57-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 156.56005, mean: 0.10723
[32m[0906 15-57-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 162.09930, mean: 0.10735
[32m[0906 15-57-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 167.65492, mean: 0.10747
[32m[0906 15-57-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 173.21289, mean: 0.10759
[32m[0906 15-57-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 178.77021, mean: 0.10769
[32m[0906 15-57-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 184.31814, mean: 0.10779
[32m[0906 15-57-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 189.82461, mean: 0.10785
[32m[0906 15-57-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 195.32545, mean: 0.10791
[32m[0906 15-57-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 200.83031, mean: 0.10797
[32m[0906 15-57-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 206.23254, mean: 0.10798
[32m[0906 15-57-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 211.64097, mean: 0.10798
[32m[0906 15-57-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: 217.05246, mean: 0.10799
[32m[0906 15-57-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 222.47029, mean: 0.10800
[32m[0906 15-57-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 227.88723, mean: 0.10800
[32m[0906 15-57-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 233.29169, mean: 0.10801
[32m[0906 15-57-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 238.69812, mean: 0.10801
[32m[0906 15-57-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 244.10943, mean: 0.10801
[32m[0906 15-57-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 249.66695, mean: 0.10808
[32m[0906 15-57-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01911, current rewards: 255.32388, mean: 0.10819
[32m[0906 15-57-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: 260.86873, mean: 0.10824
[32m[0906 15-57-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 266.41525, mean: 0.10830
[32m[0906 15-57-38 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-57-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-57-39 @MBExp.py:227][0m Rewards obtained: [270.85514302400395], Lows: [3], Highs: [0], Total time: 3291.960291
[32m[0906 16-00-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-00-03 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01877, current rewards: 0.33086, mean: 0.03309
[32m[0906 16-00-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 5.90133, mean: 0.09836
[32m[0906 16-00-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01904, current rewards: 11.40172, mean: 0.10365
[32m[0906 16-00-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 16.89867, mean: 0.10562
[32m[0906 16-00-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 22.40363, mean: 0.10668
[32m[0906 16-00-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 27.91569, mean: 0.10737
[32m[0906 16-00-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 33.50588, mean: 0.10808
[32m[0906 16-00-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 39.29064, mean: 0.10914
[32m[0906 16-00-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.07715, mean: 0.10994
[32m[0906 16-00-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 50.87041, mean: 0.11059
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 56.64923, mean: 0.11108
[32m[0906 16-00-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 62.42387, mean: 0.11147
[32m[0906 16-00-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 68.21574, mean: 0.11183
[32m[0906 16-00-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.99213, mean: 0.11211
[32m[0906 16-00-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 79.76164, mean: 0.11234
[32m[0906 16-00-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01913, current rewards: 85.53955, mean: 0.11255
[32m[0906 16-00-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 91.32162, mean: 0.11274
[32m[0906 16-00-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 97.09881, mean: 0.11291
[32m[0906 16-00-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 102.86901, mean: 0.11304
[32m[0906 16-00-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 104.32556, mean: 0.10867
[32m[0906 16-00-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 109.89823, mean: 0.10881
[32m[0906 16-00-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 115.47075, mean: 0.10893
[32m[0906 16-00-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 121.06050, mean: 0.10906
[32m[0906 16-00-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 126.63041, mean: 0.10916
[32m[0906 16-00-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 132.20352, mean: 0.10926
[32m[0906 16-00-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 137.77537, mean: 0.10935
[32m[0906 16-00-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 143.35057, mean: 0.10943
[32m[0906 16-00-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 148.92253, mean: 0.10950
[32m[0906 16-00-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 154.49751, mean: 0.10957
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01908, current rewards: 160.07188, mean: 0.10964
[32m[0906 16-00-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 165.68076, mean: 0.10972
[32m[0906 16-00-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 171.25743, mean: 0.10978
[32m[0906 16-00-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 176.79198, mean: 0.10981
[32m[0906 16-00-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 182.33423, mean: 0.10984
[32m[0906 16-00-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 187.87260, mean: 0.10987
[32m[0906 16-00-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 193.41207, mean: 0.10989
[32m[0906 16-00-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 198.95701, mean: 0.10992
[32m[0906 16-00-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 204.49743, mean: 0.10994
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 209.98479, mean: 0.10994
[32m[0906 16-00-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 215.58036, mean: 0.10999
[32m[0906 16-00-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 221.16413, mean: 0.11003
[32m[0906 16-00-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 226.75934, mean: 0.11008
[32m[0906 16-00-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 232.34661, mean: 0.11012
[32m[0906 16-00-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 237.93455, mean: 0.11015
[32m[0906 16-00-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: 243.51668, mean: 0.11019
[32m[0906 16-00-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 249.10447, mean: 0.11022
[32m[0906 16-00-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: 254.73478, mean: 0.11027
[32m[0906 16-00-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01909, current rewards: 260.88740, mean: 0.11055
[32m[0906 16-00-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01909, current rewards: 267.34623, mean: 0.11093
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 273.80505, mean: 0.11130
[32m[0906 16-00-51 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-00-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-00-51 @MBExp.py:227][0m Rewards obtained: [278.97211451369947], Lows: [2], Highs: [1], Total time: 3340.457582
[32m[0906 16-03-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-03-17 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-03-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: 1.76337, mean: 0.17634
[32m[0906 16-03-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01907, current rewards: 7.23909, mean: 0.12065
[32m[0906 16-03-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 12.76448, mean: 0.11604
[32m[0906 16-03-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 18.29064, mean: 0.11432
[32m[0906 16-03-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.81564, mean: 0.11341
[32m[0906 16-03-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 29.34443, mean: 0.11286
[32m[0906 16-03-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.86382, mean: 0.11246
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 40.38926, mean: 0.11219
[32m[0906 16-03-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 45.92145, mean: 0.11200
[32m[0906 16-03-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 51.44790, mean: 0.11184
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 56.97514, mean: 0.11172
[32m[0906 16-03-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 62.50720, mean: 0.11162
[32m[0906 16-03-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 68.03450, mean: 0.11153
[32m[0906 16-03-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 73.59582, mean: 0.11151
[32m[0906 16-03-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 79.23685, mean: 0.11160
[32m[0906 16-03-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 84.82030, mean: 0.11161
[32m[0906 16-03-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 90.40513, mean: 0.11161
[32m[0906 16-03-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 95.98664, mean: 0.11161
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 101.56812, mean: 0.11161
[32m[0906 16-03-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 107.14900, mean: 0.11161
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 111.63021, mean: 0.11052
[32m[0906 16-03-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 117.18282, mean: 0.11055
[32m[0906 16-03-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 122.70455, mean: 0.11054
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 128.25836, mean: 0.11057
[32m[0906 16-03-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 133.80840, mean: 0.11059
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 139.35437, mean: 0.11060
[32m[0906 16-03-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 144.83865, mean: 0.11056
[32m[0906 16-03-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 150.34855, mean: 0.11055
[32m[0906 16-03-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 155.85715, mean: 0.11054
[32m[0906 16-03-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 161.36722, mean: 0.11053
[32m[0906 16-03-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 166.96356, mean: 0.11057
[32m[0906 16-03-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 172.47214, mean: 0.11056
[32m[0906 16-03-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 177.97505, mean: 0.11054
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 183.53984, mean: 0.11057
[32m[0906 16-03-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 189.09961, mean: 0.11058
[32m[0906 16-03-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: 194.65727, mean: 0.11060
[32m[0906 16-03-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 200.24420, mean: 0.11063
[32m[0906 16-03-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 205.89376, mean: 0.11070
[32m[0906 16-03-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 211.50979, mean: 0.11074
[32m[0906 16-03-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 217.20597, mean: 0.11082
[32m[0906 16-03-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 222.93544, mean: 0.11091
[32m[0906 16-03-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 228.66583, mean: 0.11100
[32m[0906 16-03-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 234.40429, mean: 0.11109
[32m[0906 16-03-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 239.92828, mean: 0.11108
[32m[0906 16-04-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 245.49105, mean: 0.11108
[32m[0906 16-04-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 251.05407, mean: 0.11109
[32m[0906 16-04-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01914, current rewards: 256.61999, mean: 0.11109
[32m[0906 16-04-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 262.27250, mean: 0.11113
[32m[0906 16-04-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 267.86774, mean: 0.11115
[32m[0906 16-04-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 273.52227, mean: 0.11119
[32m[0906 16-04-06 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-04-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-04-06 @MBExp.py:227][0m Rewards obtained: [278.05296076264074], Lows: [0], Highs: [1], Total time: 3389.096018
[32m[0906 16-06-34 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-34 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-06-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01944, current rewards: 1.07613, mean: 0.10761
[32m[0906 16-06-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.55480, mean: 0.10925
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.02985, mean: 0.10936
[32m[0906 16-06-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.50101, mean: 0.10938
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 22.97293, mean: 0.10939
[32m[0906 16-06-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01904, current rewards: 28.36795, mean: 0.10911
[32m[0906 16-06-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01902, current rewards: 33.79190, mean: 0.10901
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01902, current rewards: 39.25904, mean: 0.10905
[32m[0906 16-06-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01901, current rewards: 44.72234, mean: 0.10908
[32m[0906 16-06-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01902, current rewards: 50.19038, mean: 0.10911
[32m[0906 16-06-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01904, current rewards: 55.65523, mean: 0.10913
[32m[0906 16-06-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01904, current rewards: 61.12221, mean: 0.10915
[32m[0906 16-06-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01905, current rewards: 66.59762, mean: 0.10918
[32m[0906 16-06-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01907, current rewards: 72.07004, mean: 0.10920
[32m[0906 16-06-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 77.52909, mean: 0.10920
[32m[0906 16-06-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 82.99939, mean: 0.10921
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 88.47245, mean: 0.10923
[32m[0906 16-06-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 93.94219, mean: 0.10924
[32m[0906 16-06-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 99.40920, mean: 0.10924
[32m[0906 16-06-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 104.88217, mean: 0.10925
[32m[0906 16-06-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 110.35429, mean: 0.10926
[32m[0906 16-06-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 115.82583, mean: 0.10927
[32m[0906 16-06-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 121.39628, mean: 0.10937
[32m[0906 16-06-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 126.88163, mean: 0.10938
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 132.36912, mean: 0.10940
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 137.84901, mean: 0.10940
[32m[0906 16-06-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 143.56117, mean: 0.10959
[32m[0906 16-07-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 148.99829, mean: 0.10956
[32m[0906 16-07-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: 154.43911, mean: 0.10953
[32m[0906 16-07-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 159.87597, mean: 0.10950
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 165.28155, mean: 0.10946
[32m[0906 16-07-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 170.67834, mean: 0.10941
[32m[0906 16-07-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 176.12603, mean: 0.10940
[32m[0906 16-07-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 181.66345, mean: 0.10944
[32m[0906 16-07-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: 187.20520, mean: 0.10948
[32m[0906 16-07-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 192.74516, mean: 0.10951
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 198.29436, mean: 0.10955
[32m[0906 16-07-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 203.84094, mean: 0.10959
[32m[0906 16-07-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01907, current rewards: 209.38164, mean: 0.10962
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 214.92597, mean: 0.10966
[32m[0906 16-07-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 220.46669, mean: 0.10968
[32m[0906 16-07-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 226.01179, mean: 0.10971
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01908, current rewards: 231.55713, mean: 0.10974
[32m[0906 16-07-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 237.23213, mean: 0.10983
[32m[0906 16-07-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 242.77636, mean: 0.10985
[32m[0906 16-07-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01908, current rewards: 248.32429, mean: 0.10988
[32m[0906 16-07-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01908, current rewards: 253.86614, mean: 0.10990
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01908, current rewards: 259.40395, mean: 0.10992
[32m[0906 16-07-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01908, current rewards: 264.97896, mean: 0.10995
[32m[0906 16-07-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 270.55187, mean: 0.10998
[32m[0906 16-07-22 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-07-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-07-23 @MBExp.py:227][0m Rewards obtained: [275.01292765597333], Lows: [0], Highs: [0], Total time: 3437.5897
[32m[0906 16-09-53 @MBExp.py:144][0m ####################################################################
[32m[0906 16-09-53 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01952, current rewards: 0.15788, mean: 0.01579
[32m[0906 16-09-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 5.66600, mean: 0.09443
[32m[0906 16-09-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 11.15781, mean: 0.10143
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 16.64948, mean: 0.10406
[32m[0906 16-09-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 22.14583, mean: 0.10546
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 27.62909, mean: 0.10627
[32m[0906 16-09-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 33.14534, mean: 0.10692
[32m[0906 16-10-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 38.70485, mean: 0.10751
[32m[0906 16-10-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 44.26310, mean: 0.10796
[32m[0906 16-10-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01911, current rewards: 49.82147, mean: 0.10831
[32m[0906 16-10-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 55.38509, mean: 0.10860
[32m[0906 16-10-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 60.94203, mean: 0.10883
[32m[0906 16-10-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 66.49983, mean: 0.10902
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 72.06132, mean: 0.10918
[32m[0906 16-10-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 77.61680, mean: 0.10932
[32m[0906 16-10-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 83.16205, mean: 0.10942
[32m[0906 16-10-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 88.71558, mean: 0.10953
[32m[0906 16-10-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 94.27510, mean: 0.10962
[32m[0906 16-10-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 97.72898, mean: 0.10739
[32m[0906 16-10-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 103.27153, mean: 0.10757
[32m[0906 16-10-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 108.81121, mean: 0.10773
[32m[0906 16-10-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 114.40190, mean: 0.10793
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 119.96096, mean: 0.10807
[32m[0906 16-10-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 125.51921, mean: 0.10821
[32m[0906 16-10-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 131.07734, mean: 0.10833
[32m[0906 16-10-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 136.63539, mean: 0.10844
[32m[0906 16-10-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: 142.19368, mean: 0.10854
[32m[0906 16-10-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 147.75167, mean: 0.10864
[32m[0906 16-10-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 147.76758, mean: 0.10480
[32m[0906 16-10-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 153.28703, mean: 0.10499
[32m[0906 16-10-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 158.80429, mean: 0.10517
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 164.31846, mean: 0.10533
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 169.83522, mean: 0.10549
[32m[0906 16-10-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 175.35254, mean: 0.10563
[32m[0906 16-10-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 180.87966, mean: 0.10578
[32m[0906 16-10-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: 186.41821, mean: 0.10592
[32m[0906 16-10-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01912, current rewards: 191.95565, mean: 0.10605
[32m[0906 16-10-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: 197.45769, mean: 0.10616
[32m[0906 16-10-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 202.95391, mean: 0.10626
[32m[0906 16-10-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01912, current rewards: 208.48172, mean: 0.10637
[32m[0906 16-10-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: 214.01819, mean: 0.10648
[32m[0906 16-10-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 219.54613, mean: 0.10658
[32m[0906 16-10-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 225.07568, mean: 0.10667
[32m[0906 16-10-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 230.60873, mean: 0.10676
[32m[0906 16-10-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 236.13994, mean: 0.10685
[32m[0906 16-10-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 241.67199, mean: 0.10693
[32m[0906 16-10-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 247.48433, mean: 0.10714
[32m[0906 16-10-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 253.02437, mean: 0.10721
[32m[0906 16-10-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 258.56413, mean: 0.10729
[32m[0906 16-10-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: 264.10380, mean: 0.10736
[32m[0906 16-10-41 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-10-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-10-41 @MBExp.py:227][0m Rewards obtained: [268.53563003085225], Lows: [1], Highs: [6], Total time: 3486.209393
[32m[0906 16-13-14 @MBExp.py:144][0m ####################################################################
[32m[0906 16-13-14 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-13-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01858, current rewards: 1.17038, mean: 0.11704
[32m[0906 16-13-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01880, current rewards: 6.83830, mean: 0.11397
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01891, current rewards: 12.50813, mean: 0.11371
[32m[0906 16-13-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01895, current rewards: 18.17875, mean: 0.11362
[32m[0906 16-13-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01902, current rewards: 23.84782, mean: 0.11356
[32m[0906 16-13-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01904, current rewards: 29.52012, mean: 0.11354
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01903, current rewards: 35.19153, mean: 0.11352
[32m[0906 16-13-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01904, current rewards: 40.85986, mean: 0.11350
[32m[0906 16-13-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01903, current rewards: 46.53189, mean: 0.11349
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01905, current rewards: 52.20553, mean: 0.11349
[32m[0906 16-13-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01907, current rewards: 57.84432, mean: 0.11342
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 63.47149, mean: 0.11334
[32m[0906 16-13-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01907, current rewards: 69.09712, mean: 0.11327
[32m[0906 16-13-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 74.72407, mean: 0.11322
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 80.35546, mean: 0.11318
[32m[0906 16-13-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 85.98636, mean: 0.11314
[32m[0906 16-13-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01909, current rewards: 91.61590, mean: 0.11311
[32m[0906 16-13-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01909, current rewards: 97.24795, mean: 0.11308
[32m[0906 16-13-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 102.87991, mean: 0.11305
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01908, current rewards: 108.51064, mean: 0.11303
[32m[0906 16-13-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 114.14047, mean: 0.11301
[32m[0906 16-13-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 119.59461, mean: 0.11283
[32m[0906 16-13-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01941, current rewards: 124.44065, mean: 0.11211
[32m[0906 16-13-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01963, current rewards: 129.27996, mean: 0.11145
[32m[0906 16-13-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01985, current rewards: 134.15882, mean: 0.11088
[32m[0906 16-13-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02007, current rewards: 139.00912, mean: 0.11032
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02025, current rewards: 143.84811, mean: 0.10981
[32m[0906 16-13-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02040, current rewards: 148.70696, mean: 0.10934
[32m[0906 16-13-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02054, current rewards: 153.63874, mean: 0.10896
[32m[0906 16-13-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02049, current rewards: 155.07982, mean: 0.10622
[32m[0906 16-13-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02044, current rewards: 160.70367, mean: 0.10643
[32m[0906 16-13-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02040, current rewards: 166.32633, mean: 0.10662
[32m[0906 16-13-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02036, current rewards: 171.94446, mean: 0.10680
[32m[0906 16-13-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02032, current rewards: 177.56538, mean: 0.10697
[32m[0906 16-13-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02029, current rewards: 183.18674, mean: 0.10713
[32m[0906 16-13-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02025, current rewards: 188.80835, mean: 0.10728
[32m[0906 16-13-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02022, current rewards: 194.40472, mean: 0.10741
[32m[0906 16-13-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02019, current rewards: 200.03506, mean: 0.10755
[32m[0906 16-13-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02016, current rewards: 205.66470, mean: 0.10768
[32m[0906 16-13-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02013, current rewards: 211.29458, mean: 0.10780
[32m[0906 16-13-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02011, current rewards: 216.88572, mean: 0.10790
[32m[0906 16-13-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02009, current rewards: 222.51343, mean: 0.10802
[32m[0906 16-13-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02007, current rewards: 228.13962, mean: 0.10812
[32m[0906 16-13-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02004, current rewards: 233.76672, mean: 0.10823
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02002, current rewards: 239.37922, mean: 0.10832
[32m[0906 16-14-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02000, current rewards: 245.00455, mean: 0.10841
[32m[0906 16-14-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01998, current rewards: 250.64057, mean: 0.10850
[32m[0906 16-14-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01997, current rewards: 256.27057, mean: 0.10859
[32m[0906 16-14-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01995, current rewards: 261.90129, mean: 0.10867
[32m[0906 16-14-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01993, current rewards: 267.52894, mean: 0.10875
[32m[0906 16-14-04 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 16-14-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-14-04 @MBExp.py:227][0m Rewards obtained: [272.0955478837329], Lows: [2], Highs: [0], Total time: 3536.774594
[32m[0906 16-16-38 @MBExp.py:144][0m ####################################################################
[32m[0906 16-16-38 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-16-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: -0.01014, mean: -0.00101
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01895, current rewards: 5.50273, mean: 0.09171
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01902, current rewards: 11.04894, mean: 0.10044
[32m[0906 16-16-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01902, current rewards: 16.56554, mean: 0.10353
[32m[0906 16-16-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 22.07417, mean: 0.10512
[32m[0906 16-16-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01903, current rewards: 27.59001, mean: 0.10612
[32m[0906 16-16-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01904, current rewards: 33.09991, mean: 0.10677
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01904, current rewards: 38.61338, mean: 0.10726
[32m[0906 16-16-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01905, current rewards: 44.12431, mean: 0.10762
[32m[0906 16-16-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01906, current rewards: 49.64312, mean: 0.10792
[32m[0906 16-16-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01908, current rewards: 55.15923, mean: 0.10816
[32m[0906 16-16-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 60.76509, mean: 0.10851
[32m[0906 16-16-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 66.31843, mean: 0.10872
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 71.87405, mean: 0.10890
[32m[0906 16-16-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 77.42626, mean: 0.10905
[32m[0906 16-16-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 82.97923, mean: 0.10918
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 88.53309, mean: 0.10930
[32m[0906 16-16-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 94.08637, mean: 0.10940
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 99.64076, mean: 0.10950
[32m[0906 16-16-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01910, current rewards: 105.19440, mean: 0.10958
[32m[0906 16-16-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 110.74916, mean: 0.10965
[32m[0906 16-16-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 115.16825, mean: 0.10865
[32m[0906 16-17-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 120.72290, mean: 0.10876
[32m[0906 16-17-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 126.27320, mean: 0.10886
[32m[0906 16-17-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 131.81526, mean: 0.10894
[32m[0906 16-17-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 137.37140, mean: 0.10902
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 142.91030, mean: 0.10909
[32m[0906 16-17-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 148.38085, mean: 0.10910
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: 153.91235, mean: 0.10916
[32m[0906 16-17-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 159.43822, mean: 0.10920
[32m[0906 16-17-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 164.95759, mean: 0.10924
[32m[0906 16-17-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 170.48820, mean: 0.10929
[32m[0906 16-17-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 176.02053, mean: 0.10933
[32m[0906 16-17-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 181.59349, mean: 0.10939
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 187.16668, mean: 0.10945
[32m[0906 16-17-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 192.87320, mean: 0.10959
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 198.48443, mean: 0.10966
[32m[0906 16-17-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 204.09513, mean: 0.10973
[32m[0906 16-17-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 209.65386, mean: 0.10977
[32m[0906 16-17-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 215.17893, mean: 0.10979
[32m[0906 16-17-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 220.70433, mean: 0.10980
[32m[0906 16-17-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 226.23062, mean: 0.10982
[32m[0906 16-17-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 231.75669, mean: 0.10984
[32m[0906 16-17-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 237.27544, mean: 0.10985
[32m[0906 16-17-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: 242.75806, mean: 0.10985
[32m[0906 16-17-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 248.32798, mean: 0.10988
[32m[0906 16-17-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: 253.88849, mean: 0.10991
[32m[0906 16-17-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01909, current rewards: 259.45706, mean: 0.10994
[32m[0906 16-17-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01909, current rewards: 265.02456, mean: 0.10997
[32m[0906 16-17-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 270.59954, mean: 0.11000
[32m[0906 16-17-27 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-17-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-17-27 @MBExp.py:227][0m Rewards obtained: [275.05597655048575], Lows: [0], Highs: [2], Total time: 3585.306001
[32m[0906 16-20-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-04 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-20-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01847, current rewards: 1.16724, mean: 0.11672
[32m[0906 16-20-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.97472, mean: 0.11625
[32m[0906 16-20-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.68387, mean: 0.11531
[32m[0906 16-20-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 18.38930, mean: 0.11493
[32m[0906 16-20-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 24.09514, mean: 0.11474
[32m[0906 16-20-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: 29.80573, mean: 0.11464
[32m[0906 16-20-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 35.51491, mean: 0.11456
[32m[0906 16-20-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 41.21720, mean: 0.11449
[32m[0906 16-20-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 46.93456, mean: 0.11447
[32m[0906 16-20-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01910, current rewards: 52.62111, mean: 0.11439
[32m[0906 16-20-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 58.21089, mean: 0.11414
[32m[0906 16-20-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 63.68603, mean: 0.11373
[32m[0906 16-20-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 69.28536, mean: 0.11358
[32m[0906 16-20-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 74.88814, mean: 0.11347
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 80.48984, mean: 0.11337
[32m[0906 16-20-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 86.08918, mean: 0.11328
[32m[0906 16-20-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 91.68735, mean: 0.11319
[32m[0906 16-20-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 97.29103, mean: 0.11313
[32m[0906 16-20-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 102.89454, mean: 0.11307
[32m[0906 16-20-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 108.55789, mean: 0.11308
[32m[0906 16-20-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 114.20728, mean: 0.11308
[32m[0906 16-20-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 119.82732, mean: 0.11304
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01911, current rewards: 125.45308, mean: 0.11302
[32m[0906 16-20-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 131.08040, mean: 0.11300
[32m[0906 16-20-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 136.70700, mean: 0.11298
[32m[0906 16-20-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 142.54575, mean: 0.11313
[32m[0906 16-20-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 148.72343, mean: 0.11353
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 154.90111, mean: 0.11390
[32m[0906 16-20-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 145.35531, mean: 0.10309
[32m[0906 16-20-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01908, current rewards: 150.90488, mean: 0.10336
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 156.45032, mean: 0.10361
[32m[0906 16-20-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 161.99877, mean: 0.10385
[32m[0906 16-20-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 167.54273, mean: 0.10406
[32m[0906 16-20-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 173.08951, mean: 0.10427
[32m[0906 16-20-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 178.63897, mean: 0.10447
[32m[0906 16-20-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 184.18418, mean: 0.10465
[32m[0906 16-20-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 189.71707, mean: 0.10482
[32m[0906 16-20-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 195.22809, mean: 0.10496
[32m[0906 16-20-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 200.73436, mean: 0.10510
[32m[0906 16-20-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 206.25152, mean: 0.10523
[32m[0906 16-20-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: 211.76847, mean: 0.10536
[32m[0906 16-20-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 217.27487, mean: 0.10547
[32m[0906 16-20-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 222.78679, mean: 0.10559
[32m[0906 16-20-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 228.29521, mean: 0.10569
[32m[0906 16-20-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 233.81332, mean: 0.10580
[32m[0906 16-20-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 239.32497, mean: 0.10590
[32m[0906 16-20-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 244.83311, mean: 0.10599
[32m[0906 16-20-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01911, current rewards: 250.34408, mean: 0.10608
[32m[0906 16-20-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 255.85305, mean: 0.10616
[32m[0906 16-20-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: 261.36329, mean: 0.10625
[32m[0906 16-20-52 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-20-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-20-52 @MBExp.py:227][0m Rewards obtained: [265.7708293724971], Lows: [0], Highs: [13], Total time: 3633.8512459999997
[32m[0906 16-23-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-30 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 16-23-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.10144, mean: 0.11014
[32m[0906 16-23-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01902, current rewards: 6.82800, mean: 0.11380
[32m[0906 16-23-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.55257, mean: 0.11411
[32m[0906 16-23-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 18.34076, mean: 0.11463
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 24.05272, mean: 0.11454
[32m[0906 16-23-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 29.77404, mean: 0.11452
[32m[0906 16-23-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 35.50233, mean: 0.11452
[32m[0906 16-23-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 41.22723, mean: 0.11452
[32m[0906 16-23-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 46.94508, mean: 0.11450
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 50.50934, mean: 0.10980
[32m[0906 16-23-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 56.04646, mean: 0.10990
[32m[0906 16-23-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 61.54318, mean: 0.10990
[32m[0906 16-23-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.07057, mean: 0.10995
[32m[0906 16-23-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 72.60032, mean: 0.11000
[32m[0906 16-23-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 78.12701, mean: 0.11004
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 83.65643, mean: 0.11007
[32m[0906 16-23-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 89.12843, mean: 0.11004
[32m[0906 16-23-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 94.65277, mean: 0.11006
[32m[0906 16-23-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 100.17659, mean: 0.11008
[32m[0906 16-23-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 105.73431, mean: 0.11014
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 111.25524, mean: 0.11015
[32m[0906 16-23-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 116.77527, mean: 0.11017
[32m[0906 16-23-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 122.29891, mean: 0.11018
[32m[0906 16-23-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 127.82250, mean: 0.11019
[32m[0906 16-23-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 133.35821, mean: 0.11021
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 138.90716, mean: 0.11024
[32m[0906 16-23-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 144.46095, mean: 0.11028
[32m[0906 16-23-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 149.97239, mean: 0.11027
[32m[0906 16-23-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 155.53692, mean: 0.11031
[32m[0906 16-23-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 161.09229, mean: 0.11034
[32m[0906 16-24-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01913, current rewards: 166.64349, mean: 0.11036
[32m[0906 16-24-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 172.19909, mean: 0.11038
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 177.74963, mean: 0.11040
[32m[0906 16-24-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: 183.30960, mean: 0.11043
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01913, current rewards: 188.86794, mean: 0.11045
[32m[0906 16-24-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 194.42259, mean: 0.11047
[32m[0906 16-24-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 199.98042, mean: 0.11049
[32m[0906 16-24-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 205.52808, mean: 0.11050
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 211.08262, mean: 0.11051
[32m[0906 16-24-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 216.64988, mean: 0.11054
[32m[0906 16-24-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 222.19375, mean: 0.11054
[32m[0906 16-24-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 227.73366, mean: 0.11055
[32m[0906 16-24-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 233.27481, mean: 0.11056
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 238.82678, mean: 0.11057
[32m[0906 16-24-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 244.45926, mean: 0.11062
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 250.00063, mean: 0.11062
[32m[0906 16-24-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 255.54263, mean: 0.11062
[32m[0906 16-24-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 261.08382, mean: 0.11063
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 266.62765, mean: 0.11063
[32m[0906 16-24-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 272.16766, mean: 0.11064
[32m[0906 16-24-19 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-24-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-24-19 @MBExp.py:227][0m Rewards obtained: [276.60022018985853], Lows: [1], Highs: [0], Total time: 3682.4392209999996
[32m[0906 16-26-59 @MBExp.py:144][0m ####################################################################
[32m[0906 16-26-59 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 16-27-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01886, current rewards: -0.96201, mean: -0.09620
[32m[0906 16-27-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 4.49854, mean: 0.07498
[32m[0906 16-27-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 10.03902, mean: 0.09126
[32m[0906 16-27-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 15.65228, mean: 0.09783
[32m[0906 16-27-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 21.26512, mean: 0.10126
[32m[0906 16-27-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 26.87805, mean: 0.10338
[32m[0906 16-27-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 32.48885, mean: 0.10480
[32m[0906 16-27-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 38.10426, mean: 0.10585
[32m[0906 16-27-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 43.64655, mean: 0.10646
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 49.19817, mean: 0.10695
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 54.78158, mean: 0.10741
[32m[0906 16-27-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 60.37734, mean: 0.10782
[32m[0906 16-27-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01907, current rewards: 65.92177, mean: 0.10807
[32m[0906 16-27-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 71.46622, mean: 0.10828
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 77.01397, mean: 0.10847
[32m[0906 16-27-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01907, current rewards: 82.55856, mean: 0.10863
[32m[0906 16-27-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01907, current rewards: 88.12595, mean: 0.10880
[32m[0906 16-27-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: 93.69728, mean: 0.10895
[32m[0906 16-27-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: 99.26756, mean: 0.10909
[32m[0906 16-27-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 104.84318, mean: 0.10921
[32m[0906 16-27-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01906, current rewards: 110.41170, mean: 0.10932
[32m[0906 16-27-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01907, current rewards: 115.98052, mean: 0.10942
[32m[0906 16-27-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01907, current rewards: 121.55134, mean: 0.10951
[32m[0906 16-27-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 127.12066, mean: 0.10959
[32m[0906 16-27-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 132.59138, mean: 0.10958
[32m[0906 16-27-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 138.10059, mean: 0.10960
[32m[0906 16-27-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 143.60089, mean: 0.10962
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 148.95659, mean: 0.10953
[32m[0906 16-27-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 154.42051, mean: 0.10952
[32m[0906 16-27-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: 159.89250, mean: 0.10952
[32m[0906 16-27-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 165.36586, mean: 0.10951
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 170.83325, mean: 0.10951
[32m[0906 16-27-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01909, current rewards: 176.30078, mean: 0.10950
[32m[0906 16-27-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 181.77713, mean: 0.10950
[32m[0906 16-27-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 187.32282, mean: 0.10955
[32m[0906 16-27-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 192.93225, mean: 0.10962
[32m[0906 16-27-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 198.44120, mean: 0.10964
[32m[0906 16-27-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 203.95143, mean: 0.10965
[32m[0906 16-27-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 209.46588, mean: 0.10967
[32m[0906 16-27-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 214.97929, mean: 0.10968
[32m[0906 16-27-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 220.45354, mean: 0.10968
[32m[0906 16-27-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 225.90318, mean: 0.10966
[32m[0906 16-27-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01910, current rewards: 231.35624, mean: 0.10965
[32m[0906 16-27-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01910, current rewards: 236.82248, mean: 0.10964
[32m[0906 16-27-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 242.17901, mean: 0.10958
[32m[0906 16-27-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 247.57341, mean: 0.10955
[32m[0906 16-27-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 252.97317, mean: 0.10951
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 258.36862, mean: 0.10948
[32m[0906 16-27-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 263.76528, mean: 0.10945
[32m[0906 16-27-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: 269.15954, mean: 0.10941
[32m[0906 16-27-48 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-27-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-27-48 @MBExp.py:227][0m Rewards obtained: [273.47464428049506], Lows: [1], Highs: [0], Total time: 3730.9805409999994
[32m[0906 16-30-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-30-30 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 16-30-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01895, current rewards: 1.10592, mean: 0.11059
[32m[0906 16-30-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 6.99412, mean: 0.11657
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.91200, mean: 0.11738
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 18.82987, mean: 0.11769
[32m[0906 16-30-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 24.74775, mean: 0.11785
[32m[0906 16-30-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 30.66563, mean: 0.11794
[32m[0906 16-30-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: -3.67737, mean: -0.01186
[32m[0906 16-30-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: -53.67737, mean: -0.14910
[32m[0906 16-30-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: -103.67737, mean: -0.25287
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01911, current rewards: -153.67737, mean: -0.33408
[32m[0906 16-30-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: -203.67737, mean: -0.39937
[32m[0906 16-30-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: -253.67737, mean: -0.45300
[32m[0906 16-30-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: -303.67737, mean: -0.49783
[32m[0906 16-30-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: -353.67737, mean: -0.53587
[32m[0906 16-30-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: -403.67737, mean: -0.56856
[32m[0906 16-30-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: -453.67737, mean: -0.59694
[32m[0906 16-30-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01908, current rewards: -503.67737, mean: -0.62182
[32m[0906 16-30-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: -553.67737, mean: -0.64381
[32m[0906 16-30-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: -603.67737, mean: -0.66338
[32m[0906 16-30-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: -653.67737, mean: -0.68091
[32m[0906 16-30-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: -703.67737, mean: -0.69671
[32m[0906 16-30-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01908, current rewards: -753.67737, mean: -0.71102
[32m[0906 16-30-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01908, current rewards: -803.67737, mean: -0.72403
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01908, current rewards: -853.67737, mean: -0.73593
[32m[0906 16-30-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: -903.67737, mean: -0.74684
[32m[0906 16-30-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: -953.67737, mean: -0.75689
[32m[0906 16-30-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: -1003.67737, mean: -0.76617
[32m[0906 16-30-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: -1053.67737, mean: -0.77476
[32m[0906 16-30-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: -1103.67737, mean: -0.78275
[32m[0906 16-30-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: -1153.67737, mean: -0.79019
[32m[0906 16-31-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: -1203.67737, mean: -0.79714
[32m[0906 16-31-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: -1253.67737, mean: -0.80364
[32m[0906 16-31-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: -1303.67737, mean: -0.80974
[32m[0906 16-31-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: -1353.67737, mean: -0.81547
[32m[0906 16-31-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: -1403.67737, mean: -0.82086
[32m[0906 16-31-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: -1453.67737, mean: -0.82595
[32m[0906 16-31-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: -1503.67737, mean: -0.83076
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: -1553.67737, mean: -0.83531
[32m[0906 16-31-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: -1603.67737, mean: -0.83962
[32m[0906 16-31-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: -1653.67737, mean: -0.84371
[32m[0906 16-31-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: -1703.67737, mean: -0.84760
[32m[0906 16-31-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: -1753.67737, mean: -0.85130
[32m[0906 16-31-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: -1803.67737, mean: -0.85482
[32m[0906 16-31-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: -1853.67737, mean: -0.85818
[32m[0906 16-31-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: -1903.67737, mean: -0.86139
[32m[0906 16-31-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: -1953.67737, mean: -0.86446
[32m[0906 16-31-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: -2003.67737, mean: -0.86739
[32m[0906 16-31-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01909, current rewards: -2053.67737, mean: -0.87020
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01909, current rewards: -2103.67737, mean: -0.87290
[32m[0906 16-31-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: -2153.67737, mean: -0.87548
[32m[0906 16-31-19 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-31-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-31-19 @MBExp.py:227][0m Rewards obtained: [-2193.6773668708256], Lows: [0], Highs: [2226], Total time: 3779.5152909999993
[32m[0906 16-34-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-04 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 16-34-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01892, current rewards: 1.08205, mean: 0.10820
[32m[0906 16-34-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01895, current rewards: 6.78349, mean: 0.11306
[32m[0906 16-34-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01895, current rewards: 12.45852, mean: 0.11326
[32m[0906 16-34-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 18.12807, mean: 0.11330
[32m[0906 16-34-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.79812, mean: 0.11332
[32m[0906 16-34-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 29.47441, mean: 0.11336
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 35.00902, mean: 0.11293
[32m[0906 16-34-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 40.54274, mean: 0.11262
[32m[0906 16-34-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 46.07046, mean: 0.11237
[32m[0906 16-34-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 51.57614, mean: 0.11212
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 57.06229, mean: 0.11189
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 62.57639, mean: 0.11174
[32m[0906 16-34-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 68.09382, mean: 0.11163
[32m[0906 16-34-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 73.60524, mean: 0.11152
[32m[0906 16-34-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 79.25200, mean: 0.11162
[32m[0906 16-34-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01913, current rewards: 85.02046, mean: 0.11187
[32m[0906 16-34-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 90.76771, mean: 0.11206
[32m[0906 16-34-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 96.52651, mean: 0.11224
[32m[0906 16-34-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 102.28263, mean: 0.11240
[32m[0906 16-34-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 107.89689, mean: 0.11239
[32m[0906 16-34-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 113.50899, mean: 0.11239
[32m[0906 16-34-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 119.12345, mean: 0.11238
[32m[0906 16-34-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 124.74154, mean: 0.11238
[32m[0906 16-34-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 130.35675, mean: 0.11238
[32m[0906 16-34-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 135.95731, mean: 0.11236
[32m[0906 16-34-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 141.53208, mean: 0.11233
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 147.08824, mean: 0.11228
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 152.64747, mean: 0.11224
[32m[0906 16-34-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 158.23298, mean: 0.11222
[32m[0906 16-34-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 163.81783, mean: 0.11220
[32m[0906 16-34-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 169.40134, mean: 0.11219
[32m[0906 16-34-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 174.98222, mean: 0.11217
[32m[0906 16-34-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01916, current rewards: 180.56787, mean: 0.11215
[32m[0906 16-34-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: 186.16300, mean: 0.11215
[32m[0906 16-34-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 191.72679, mean: 0.11212
[32m[0906 16-34-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 197.31271, mean: 0.11211
[32m[0906 16-34-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 202.88434, mean: 0.11209
[32m[0906 16-34-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01915, current rewards: 208.45575, mean: 0.11207
[32m[0906 16-34-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 214.02730, mean: 0.11206
[32m[0906 16-34-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 219.59875, mean: 0.11204
[32m[0906 16-34-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 225.17034, mean: 0.11203
[32m[0906 16-34-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 230.74182, mean: 0.11201
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 234.58832, mean: 0.11118
[32m[0906 16-34-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 240.07548, mean: 0.11115
[32m[0906 16-34-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: 245.63643, mean: 0.11115
[32m[0906 16-34-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 251.19318, mean: 0.11115
[32m[0906 16-34-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01914, current rewards: 256.75363, mean: 0.11115
[32m[0906 16-34-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 262.31301, mean: 0.11115
[32m[0906 16-34-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 267.87579, mean: 0.11115
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 273.43222, mean: 0.11115
[32m[0906 16-34-52 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-34-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-34-52 @MBExp.py:227][0m Rewards obtained: [277.8824236900178], Lows: [0], Highs: [2], Total time: 3828.1575979999993
[32m[0906 16-37-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-37-39 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 16-37-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01951, current rewards: 1.06967, mean: 0.10697
[32m[0906 16-37-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01923, current rewards: 6.53916, mean: 0.10899
[32m[0906 16-37-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 12.22706, mean: 0.11116
[32m[0906 16-37-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 17.79853, mean: 0.11124
[32m[0906 16-37-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.67725, mean: 0.11275
[32m[0906 16-37-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 32.21518, mean: 0.12390
[32m[0906 16-37-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 40.75310, mean: 0.13146
[32m[0906 16-37-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 49.29102, mean: 0.13692
[32m[0906 16-37-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 49.63363, mean: 0.12106
[32m[0906 16-37-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01910, current rewards: -0.36637, mean: -0.00080
[32m[0906 16-37-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: -50.36637, mean: -0.09876
[32m[0906 16-37-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01909, current rewards: -100.36637, mean: -0.17923
[32m[0906 16-37-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: -150.36637, mean: -0.24650
[32m[0906 16-37-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: -200.36637, mean: -0.30359
[32m[0906 16-37-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: -250.36637, mean: -0.35263
[32m[0906 16-37-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: -300.36637, mean: -0.39522
[32m[0906 16-37-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: -350.36637, mean: -0.43255
[32m[0906 16-37-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: -400.36637, mean: -0.46554
[32m[0906 16-37-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: -450.36637, mean: -0.49491
[32m[0906 16-37-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: -500.36637, mean: -0.52121
[32m[0906 16-37-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: -550.36637, mean: -0.54492
[32m[0906 16-37-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: -600.36637, mean: -0.56638
[32m[0906 16-38-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: -650.36637, mean: -0.58592
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: -700.36637, mean: -0.60376
[32m[0906 16-38-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: -750.36637, mean: -0.62014
[32m[0906 16-38-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: -800.36637, mean: -0.63521
[32m[0906 16-38-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: -850.36637, mean: -0.64913
[32m[0906 16-38-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: -900.36637, mean: -0.66203
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: -950.36637, mean: -0.67402
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01915, current rewards: -1000.36637, mean: -0.68518
[32m[0906 16-38-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: -1050.36637, mean: -0.69561
[32m[0906 16-38-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01914, current rewards: -1100.36637, mean: -0.70536
[32m[0906 16-38-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: -1150.36637, mean: -0.71451
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: -1200.36637, mean: -0.72311
[32m[0906 16-38-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01914, current rewards: -1250.36637, mean: -0.73121
[32m[0906 16-38-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: -1300.36637, mean: -0.73884
[32m[0906 16-38-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: -1350.36637, mean: -0.74606
[32m[0906 16-38-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: -1400.36637, mean: -0.75289
[32m[0906 16-38-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: -1450.36637, mean: -0.75935
[32m[0906 16-38-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: -1500.36637, mean: -0.76549
[32m[0906 16-38-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: -1550.36637, mean: -0.77133
[32m[0906 16-38-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: -1600.36637, mean: -0.77688
[32m[0906 16-38-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: -1650.36637, mean: -0.78216
[32m[0906 16-38-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: -1700.36637, mean: -0.78721
[32m[0906 16-38-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01913, current rewards: -1750.36637, mean: -0.79202
[32m[0906 16-38-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: -1800.36637, mean: -0.79662
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: -1850.36637, mean: -0.80102
[32m[0906 16-38-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: -1900.36637, mean: -0.80524
[32m[0906 16-38-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: -1950.36637, mean: -0.80928
[32m[0906 16-38-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: -2000.36637, mean: -0.81316
[32m[0906 16-38-27 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-38-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-38-27 @MBExp.py:227][0m Rewards obtained: [-2040.3663666011], Lows: [0], Highs: [2097], Total time: 3876.7707129999994
[32m[0906 16-41-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-41-16 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 16-41-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: -0.02828, mean: -0.00283
[32m[0906 16-41-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 5.47782, mean: 0.09130
[32m[0906 16-41-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 11.11701, mean: 0.10106
[32m[0906 16-41-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 16.46193, mean: 0.10289
[32m[0906 16-41-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 21.80508, mean: 0.10383
[32m[0906 16-41-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 27.16094, mean: 0.10447
[32m[0906 16-41-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 32.49572, mean: 0.10482
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 37.83785, mean: 0.10511
[32m[0906 16-41-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 43.19601, mean: 0.10536
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01910, current rewards: 48.53778, mean: 0.10552
[32m[0906 16-41-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 53.82153, mean: 0.10553
[32m[0906 16-41-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 58.92743, mean: 0.10523
[32m[0906 16-41-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 64.13107, mean: 0.10513
[32m[0906 16-41-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 69.33435, mean: 0.10505
[32m[0906 16-41-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 74.53916, mean: 0.10498
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 79.74126, mean: 0.10492
[32m[0906 16-41-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 84.93933, mean: 0.10486
[32m[0906 16-41-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 90.13609, mean: 0.10481
[32m[0906 16-41-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 95.34071, mean: 0.10477
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 100.67139, mean: 0.10487
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 108.07781, mean: 0.10701
[32m[0906 16-41-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 115.73289, mean: 0.10918
[32m[0906 16-41-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 123.38797, mean: 0.11116
[32m[0906 16-41-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 131.04305, mean: 0.11297
[32m[0906 16-41-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 138.69813, mean: 0.11463
[32m[0906 16-41-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 146.35321, mean: 0.11615
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 154.00829, mean: 0.11756
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 148.97925, mean: 0.10954
[32m[0906 16-41-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 98.97925, mean: 0.07020
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01915, current rewards: 48.97925, mean: 0.03355
[32m[0906 16-41-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: -1.02075, mean: -0.00068
[32m[0906 16-41-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01914, current rewards: -51.02075, mean: -0.03271
[32m[0906 16-41-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: -101.02075, mean: -0.06275
[32m[0906 16-41-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: -151.02075, mean: -0.09098
[32m[0906 16-41-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01913, current rewards: -201.02075, mean: -0.11756
[32m[0906 16-41-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01914, current rewards: -251.02075, mean: -0.14263
[32m[0906 16-41-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: -301.02075, mean: -0.16631
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: -351.02075, mean: -0.18872
[32m[0906 16-41-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: -401.02075, mean: -0.20996
[32m[0906 16-41-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: -451.02075, mean: -0.23011
[32m[0906 16-41-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: -501.02075, mean: -0.24926
[32m[0906 16-41-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01913, current rewards: -551.02075, mean: -0.26749
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01913, current rewards: -601.02075, mean: -0.28484
[32m[0906 16-41-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01913, current rewards: -651.02075, mean: -0.30140
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: -701.02075, mean: -0.31720
[32m[0906 16-42-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: -751.02075, mean: -0.33231
[32m[0906 16-42-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: -801.02075, mean: -0.34676
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: -851.02075, mean: -0.36060
[32m[0906 16-42-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: -901.02075, mean: -0.37387
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: -951.02075, mean: -0.38659
[32m[0906 16-42-05 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-42-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-42-05 @MBExp.py:227][0m Rewards obtained: [-991.0207482847086], Lows: [0], Highs: [1152], Total time: 3925.3844439999993
[32m[0906 16-44-56 @MBExp.py:144][0m ####################################################################
[32m[0906 16-44-56 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 16-44-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: 1.03063, mean: 0.10306
[32m[0906 16-44-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 6.54281, mean: 0.10905
[32m[0906 16-44-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 12.11675, mean: 0.11015
[32m[0906 16-44-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.75109, mean: 0.11094
[32m[0906 16-45-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.31011, mean: 0.11100
[32m[0906 16-45-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 28.83954, mean: 0.11092
[32m[0906 16-45-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.36733, mean: 0.11086
[32m[0906 16-45-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: 39.89693, mean: 0.11082
[32m[0906 16-45-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 45.42951, mean: 0.11080
[32m[0906 16-45-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01905, current rewards: 50.96127, mean: 0.11079
[32m[0906 16-45-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01905, current rewards: 56.48994, mean: 0.11076
[32m[0906 16-45-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 61.97996, mean: 0.11068
[32m[0906 16-45-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01905, current rewards: 67.50845, mean: 0.11067
[32m[0906 16-45-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01905, current rewards: 73.03306, mean: 0.11066
[32m[0906 16-45-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01905, current rewards: 78.56369, mean: 0.11065
[32m[0906 16-45-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01905, current rewards: 84.08868, mean: 0.11064
[32m[0906 16-45-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01905, current rewards: 89.56331, mean: 0.11057
[32m[0906 16-45-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01905, current rewards: 95.05836, mean: 0.11053
[32m[0906 16-45-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01906, current rewards: 100.55607, mean: 0.11050
[32m[0906 16-45-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 105.96068, mean: 0.11038
[32m[0906 16-45-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01907, current rewards: 111.45678, mean: 0.11035
[32m[0906 16-45-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01907, current rewards: 116.95319, mean: 0.11033
[32m[0906 16-45-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01907, current rewards: 122.44839, mean: 0.11031
[32m[0906 16-45-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 127.94356, mean: 0.11030
[32m[0906 16-45-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01907, current rewards: 133.43746, mean: 0.11028
[32m[0906 16-45-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01908, current rewards: 138.93090, mean: 0.11026
[32m[0906 16-45-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01908, current rewards: 144.42857, mean: 0.11025
[32m[0906 16-45-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: 149.93122, mean: 0.11024
[32m[0906 16-45-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: 155.54095, mean: 0.11031
[32m[0906 16-45-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 159.00271, mean: 0.10891
[32m[0906 16-45-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 165.61097, mean: 0.10968
[32m[0906 16-45-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 172.21920, mean: 0.11040
[32m[0906 16-45-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 178.82743, mean: 0.11107
[32m[0906 16-45-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 185.43567, mean: 0.11171
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 166.00411, mean: 0.09708
[32m[0906 16-45-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 116.00411, mean: 0.06591
[32m[0906 16-45-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 66.00411, mean: 0.03647
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 16.00411, mean: 0.00860
[32m[0906 16-45-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: -33.99589, mean: -0.01780
[32m[0906 16-45-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: -83.99589, mean: -0.04286
[32m[0906 16-45-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: -133.99589, mean: -0.06666
[32m[0906 16-45-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: -183.99589, mean: -0.08932
[32m[0906 16-45-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: -188.40888, mean: -0.08929
[32m[0906 16-45-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: -182.87178, mean: -0.08466
[32m[0906 16-45-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: -177.33019, mean: -0.08024
[32m[0906 16-45-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01908, current rewards: -171.79451, mean: -0.07602
[32m[0906 16-45-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01908, current rewards: -166.26341, mean: -0.07198
[32m[0906 16-45-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01908, current rewards: -160.73297, mean: -0.06811
[32m[0906 16-45-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01908, current rewards: -155.20324, mean: -0.06440
[32m[0906 16-45-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01908, current rewards: -149.68300, mean: -0.06085
[32m[0906 16-45-44 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 16-45-44 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-45-44 @MBExp.py:227][0m Rewards obtained: [-145.25606068728916], Lows: [1], Highs: [382], Total time: 3973.9006739999995
[32m[0906 16-48-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-37 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01895, current rewards: 1.03494, mean: 0.10349
[32m[0906 16-48-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.57621, mean: 0.10960
[32m[0906 16-48-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.15935, mean: 0.11054
[32m[0906 16-48-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 17.69960, mean: 0.11062
[32m[0906 16-48-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.23873, mean: 0.11066
[32m[0906 16-48-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 28.77531, mean: 0.11067
[32m[0906 16-48-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.31486, mean: 0.11069
[32m[0906 16-48-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 39.85662, mean: 0.11071
[32m[0906 16-48-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 45.39771, mean: 0.11073
[32m[0906 16-48-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01911, current rewards: 50.93678, mean: 0.11073
[32m[0906 16-48-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 55.32413, mean: 0.10848
[32m[0906 16-48-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01909, current rewards: 60.54957, mean: 0.10812
[32m[0906 16-48-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: 65.78477, mean: 0.10784
[32m[0906 16-48-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 71.03457, mean: 0.10763
[32m[0906 16-48-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 76.26782, mean: 0.10742
[32m[0906 16-48-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 81.47627, mean: 0.10721
[32m[0906 16-48-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01909, current rewards: 86.70681, mean: 0.10705
[32m[0906 16-48-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 91.94155, mean: 0.10691
[32m[0906 16-48-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 97.23026, mean: 0.10685
[32m[0906 16-48-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01910, current rewards: 102.73541, mean: 0.10702
[32m[0906 16-48-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 108.23948, mean: 0.10717
[32m[0906 16-48-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 113.73965, mean: 0.10730
[32m[0906 16-48-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 119.24077, mean: 0.10742
[32m[0906 16-49-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 124.74737, mean: 0.10754
[32m[0906 16-49-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 130.25196, mean: 0.10765
[32m[0906 16-49-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 135.74929, mean: 0.10774
[32m[0906 16-49-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 140.62893, mean: 0.10735
[32m[0906 16-49-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01917, current rewards: 145.62489, mean: 0.10708
[32m[0906 16-49-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: 150.67812, mean: 0.10686
[32m[0906 16-49-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01921, current rewards: 155.71778, mean: 0.10666
[32m[0906 16-49-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01920, current rewards: 160.74842, mean: 0.10646
[32m[0906 16-49-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 165.81110, mean: 0.10629
[32m[0906 16-49-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: 170.99508, mean: 0.10621
[32m[0906 16-49-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: 176.46608, mean: 0.10630
[32m[0906 16-49-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: 181.93616, mean: 0.10640
[32m[0906 16-49-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01919, current rewards: 187.45152, mean: 0.10651
[32m[0906 16-49-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01919, current rewards: 192.90976, mean: 0.10658
[32m[0906 16-49-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: 198.36579, mean: 0.10665
[32m[0906 16-49-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01919, current rewards: 203.82322, mean: 0.10671
[32m[0906 16-49-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01918, current rewards: 209.28368, mean: 0.10678
[32m[0906 16-49-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01918, current rewards: 214.74626, mean: 0.10684
[32m[0906 16-49-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01919, current rewards: 220.20485, mean: 0.10690
[32m[0906 16-49-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 225.66193, mean: 0.10695
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01918, current rewards: 231.04402, mean: 0.10696
[32m[0906 16-49-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01918, current rewards: 236.52959, mean: 0.10703
[32m[0906 16-49-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: 241.99430, mean: 0.10708
[32m[0906 16-49-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: 247.26487, mean: 0.10704
[32m[0906 16-49-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: 252.52877, mean: 0.10700
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 257.79325, mean: 0.10697
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01918, current rewards: 263.05681, mean: 0.10693
[32m[0906 16-49-26 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 16-49-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-49-26 @MBExp.py:227][0m Rewards obtained: [267.26295219714956], Lows: [0], Highs: [1], Total time: 4022.6436429999994
[32m[0906 16-52-21 @MBExp.py:144][0m ####################################################################
[32m[0906 16-52-21 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 16-52-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01876, current rewards: 1.03159, mean: 0.10316
[32m[0906 16-52-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 6.49948, mean: 0.10832
[32m[0906 16-52-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 12.00460, mean: 0.10913
[32m[0906 16-52-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.51210, mean: 0.10945
[32m[0906 16-52-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.00647, mean: 0.10955
[32m[0906 16-52-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 28.51143, mean: 0.10966
[32m[0906 16-52-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 34.00703, mean: 0.10970
[32m[0906 16-52-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 39.53070, mean: 0.10981
[32m[0906 16-52-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 44.98341, mean: 0.10972
[32m[0906 16-52-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 50.45486, mean: 0.10968
[32m[0906 16-52-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 55.97660, mean: 0.10976
[32m[0906 16-52-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 61.47348, mean: 0.10977
[32m[0906 16-52-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 66.96794, mean: 0.10978
[32m[0906 16-52-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 72.46338, mean: 0.10979
[32m[0906 16-52-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 69.51722, mean: 0.09791
[32m[0906 16-52-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 75.08343, mean: 0.09879
[32m[0906 16-52-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 80.65393, mean: 0.09957
[32m[0906 16-52-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 86.22655, mean: 0.10026
[32m[0906 16-52-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 91.74331, mean: 0.10082
[32m[0906 16-52-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 97.25942, mean: 0.10131
[32m[0906 16-52-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 102.60582, mean: 0.10159
[32m[0906 16-52-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 107.94676, mean: 0.10184
[32m[0906 16-52-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 113.29318, mean: 0.10207
[32m[0906 16-52-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 118.63838, mean: 0.10227
[32m[0906 16-52-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 123.98274, mean: 0.10247
[32m[0906 16-52-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 129.32955, mean: 0.10264
[32m[0906 16-52-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 134.70879, mean: 0.10283
[32m[0906 16-52-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 140.06329, mean: 0.10299
[32m[0906 16-52-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 145.41558, mean: 0.10313
[32m[0906 16-52-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01917, current rewards: 150.77351, mean: 0.10327
[32m[0906 16-52-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 156.12950, mean: 0.10340
[32m[0906 16-52-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01921, current rewards: 158.97569, mean: 0.10191
[32m[0906 16-52-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01926, current rewards: 163.98192, mean: 0.10185
[32m[0906 16-52-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01931, current rewards: 168.98082, mean: 0.10180
[32m[0906 16-52-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01938, current rewards: 173.99478, mean: 0.10175
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01943, current rewards: 179.04372, mean: 0.10173
[32m[0906 16-52-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01948, current rewards: 184.07683, mean: 0.10170
[32m[0906 16-52-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01953, current rewards: 189.12953, mean: 0.10168
[32m[0906 16-52-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01953, current rewards: 194.61615, mean: 0.10189
[32m[0906 16-53-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01952, current rewards: 200.10071, mean: 0.10209
[32m[0906 16-53-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01951, current rewards: 205.58616, mean: 0.10228
[32m[0906 16-53-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01950, current rewards: 211.07161, mean: 0.10246
[32m[0906 16-53-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01948, current rewards: 216.55200, mean: 0.10263
[32m[0906 16-53-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01948, current rewards: 221.96647, mean: 0.10276
[32m[0906 16-53-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01947, current rewards: 227.44835, mean: 0.10292
[32m[0906 16-53-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01947, current rewards: 232.92800, mean: 0.10307
[32m[0906 16-53-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01946, current rewards: 238.40171, mean: 0.10320
[32m[0906 16-53-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01945, current rewards: 243.88604, mean: 0.10334
[32m[0906 16-53-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01944, current rewards: 249.36768, mean: 0.10347
[32m[0906 16-53-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01943, current rewards: 254.87377, mean: 0.10361
[32m[0906 16-53-10 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 16-53-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-53-10 @MBExp.py:227][0m Rewards obtained: [259.2968690486572], Lows: [4], Highs: [2], Total time: 4072.0297779999996
[32m[0906 16-56-07 @MBExp.py:144][0m ####################################################################
[32m[0906 16-56-07 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 16-56-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: -0.79614, mean: -0.07961
[32m[0906 16-56-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 4.90386, mean: 0.08173
[32m[0906 16-56-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 10.76564, mean: 0.09787
[32m[0906 16-56-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 16.55226, mean: 0.10345
[32m[0906 16-56-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01905, current rewards: 22.33504, mean: 0.10636
[32m[0906 16-56-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01904, current rewards: 28.13034, mean: 0.10819
[32m[0906 16-56-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01906, current rewards: 32.32802, mean: 0.10428
[32m[0906 16-56-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 38.50571, mean: 0.10696
[32m[0906 16-56-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 44.68340, mean: 0.10898
[32m[0906 16-56-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 50.86110, mean: 0.11057
[32m[0906 16-56-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01907, current rewards: 56.60957, mean: 0.11100
[32m[0906 16-56-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 62.13221, mean: 0.11095
[32m[0906 16-56-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: 63.44323, mean: 0.10401
[32m[0906 16-56-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 69.19818, mean: 0.10485
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 74.94628, mean: 0.10556
[32m[0906 16-56-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 80.69790, mean: 0.10618
[32m[0906 16-56-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 86.45284, mean: 0.10673
[32m[0906 16-56-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 92.20632, mean: 0.10722
[32m[0906 16-56-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 98.00088, mean: 0.10769
[32m[0906 16-56-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 103.74699, mean: 0.10807
[32m[0906 16-56-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 109.49938, mean: 0.10842
[32m[0906 16-56-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 115.91372, mean: 0.10935
[32m[0906 16-56-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 121.53920, mean: 0.10949
[32m[0906 16-56-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 127.16403, mean: 0.10962
[32m[0906 16-56-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 132.78560, mean: 0.10974
[32m[0906 16-56-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 138.41221, mean: 0.10985
[32m[0906 16-56-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 143.97508, mean: 0.10990
[32m[0906 16-56-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 149.57400, mean: 0.10998
[32m[0906 16-56-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 155.18419, mean: 0.11006
[32m[0906 16-56-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 160.79505, mean: 0.11013
[32m[0906 16-56-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: 166.40493, mean: 0.11020
[32m[0906 16-56-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01918, current rewards: 172.01681, mean: 0.11027
[32m[0906 16-56-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 177.53802, mean: 0.11027
[32m[0906 16-56-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 183.09838, mean: 0.11030
[32m[0906 16-56-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: 188.65771, mean: 0.11033
[32m[0906 16-56-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01920, current rewards: 194.30434, mean: 0.11040
[32m[0906 16-56-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01919, current rewards: 199.86924, mean: 0.11042
[32m[0906 16-56-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: 205.43406, mean: 0.11045
[32m[0906 16-56-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01919, current rewards: 211.00875, mean: 0.11048
[32m[0906 16-56-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01919, current rewards: 216.57837, mean: 0.11050
[32m[0906 16-56-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 222.10421, mean: 0.11050
[32m[0906 16-56-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01918, current rewards: 227.66751, mean: 0.11052
[32m[0906 16-56-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 233.23917, mean: 0.11054
[32m[0906 16-56-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 238.65040, mean: 0.11049
[32m[0906 16-56-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01917, current rewards: 244.17896, mean: 0.11049
[32m[0906 16-56-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01917, current rewards: 249.70137, mean: 0.11049
[32m[0906 16-56-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01917, current rewards: 255.22354, mean: 0.11049
[32m[0906 16-56-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01917, current rewards: 260.75475, mean: 0.11049
[32m[0906 16-56-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 266.28544, mean: 0.11049
[32m[0906 16-56-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 271.81704, mean: 0.11049
[32m[0906 16-56-56 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 16-56-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-56-56 @MBExp.py:227][0m Rewards obtained: [276.3949526725475], Lows: [3], Highs: [2], Total time: 4120.742566999999
[32m[0906 16-59-55 @MBExp.py:144][0m ####################################################################
[32m[0906 16-59-55 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 16-59-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01853, current rewards: 1.20670, mean: 0.12067
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.75088, mean: 0.11251
[32m[0906 16-59-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.35258, mean: 0.11230
[32m[0906 16-59-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.88429, mean: 0.11178
[32m[0906 16-59-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.42095, mean: 0.11153
[32m[0906 17-00-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 28.96000, mean: 0.11138
[32m[0906 17-00-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.57843, mean: 0.11154
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 40.15306, mean: 0.11154
[32m[0906 17-00-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 45.72303, mean: 0.11152
[32m[0906 17-00-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01911, current rewards: 51.29349, mean: 0.11151
[32m[0906 17-00-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01907, current rewards: 56.79982, mean: 0.11137
[32m[0906 17-00-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 62.36797, mean: 0.11137
[32m[0906 17-00-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 67.94202, mean: 0.11138
[32m[0906 17-00-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 73.50900, mean: 0.11138
[32m[0906 17-00-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 79.06509, mean: 0.11136
[32m[0906 17-00-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 84.62815, mean: 0.11135
[32m[0906 17-00-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 90.19525, mean: 0.11135
[32m[0906 17-00-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 95.75975, mean: 0.11135
[32m[0906 17-00-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 101.31857, mean: 0.11134
[32m[0906 17-00-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 106.88147, mean: 0.11133
[32m[0906 17-00-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 112.44428, mean: 0.11133
[32m[0906 17-00-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 118.00308, mean: 0.11132
[32m[0906 17-00-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01911, current rewards: 123.56483, mean: 0.11132
[32m[0906 17-00-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 129.12850, mean: 0.11132
[32m[0906 17-00-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 134.68840, mean: 0.11131
[32m[0906 17-00-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 140.42313, mean: 0.11145
[32m[0906 17-00-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 146.15614, mean: 0.11157
[32m[0906 17-00-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 151.81321, mean: 0.11163
[32m[0906 17-00-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 157.45137, mean: 0.11167
[32m[0906 17-00-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 163.08865, mean: 0.11170
[32m[0906 17-00-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 168.72705, mean: 0.11174
[32m[0906 17-00-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 173.81578, mean: 0.11142
[32m[0906 17-00-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 181.08999, mean: 0.11248
[32m[0906 17-00-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 188.36421, mean: 0.11347
[32m[0906 17-00-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 195.63842, mean: 0.11441
[32m[0906 17-00-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 175.05771, mean: 0.09946
[32m[0906 17-00-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 125.05771, mean: 0.06909
[32m[0906 17-00-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 75.05771, mean: 0.04035
[32m[0906 17-00-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 25.05771, mean: 0.01312
[32m[0906 17-00-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: -24.94229, mean: -0.01273
[32m[0906 17-00-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: -74.94229, mean: -0.03728
[32m[0906 17-00-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: -124.94229, mean: -0.06065
[32m[0906 17-00-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01907, current rewards: -174.94229, mean: -0.08291
[32m[0906 17-00-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01907, current rewards: -224.94229, mean: -0.10414
[32m[0906 17-00-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01906, current rewards: -274.94229, mean: -0.12441
[32m[0906 17-00-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: -324.94229, mean: -0.14378
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: -374.94229, mean: -0.16231
[32m[0906 17-00-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01906, current rewards: -424.94229, mean: -0.18006
[32m[0906 17-00-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01906, current rewards: -474.94229, mean: -0.19707
[32m[0906 17-00-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01906, current rewards: -524.94229, mean: -0.21339
[32m[0906 17-00-44 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-00-44 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-00-44 @MBExp.py:227][0m Rewards obtained: [-564.9422932410776], Lows: [1], Highs: [763], Total time: 4169.201429999999
[32m[0906 17-03-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-03-45 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-03-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01907, current rewards: -1.00878, mean: -0.10088
[32m[0906 17-03-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 4.55888, mean: 0.07598
[32m[0906 17-03-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01896, current rewards: 10.19445, mean: 0.09268
[32m[0906 17-03-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01902, current rewards: 15.76669, mean: 0.09854
[32m[0906 17-03-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 21.34090, mean: 0.10162
[32m[0906 17-03-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01904, current rewards: 26.91098, mean: 0.10350
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01904, current rewards: 32.47927, mean: 0.10477
[32m[0906 17-03-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01945, current rewards: 36.55828, mean: 0.10155
[32m[0906 17-03-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02005, current rewards: 42.80913, mean: 0.10441
[32m[0906 17-03-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02050, current rewards: 49.13932, mean: 0.10682
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02065, current rewards: 55.44924, mean: 0.10872
[32m[0906 17-03-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02053, current rewards: 61.53135, mean: 0.10988
[32m[0906 17-03-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02044, current rewards: 67.61798, mean: 0.11085
[32m[0906 17-03-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02036, current rewards: 73.73242, mean: 0.11172
[32m[0906 17-04-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02030, current rewards: 79.85945, mean: 0.11248
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02022, current rewards: 85.95046, mean: 0.11309
[32m[0906 17-04-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02014, current rewards: 89.90241, mean: 0.11099
[32m[0906 17-04-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02009, current rewards: 95.39602, mean: 0.11093
[32m[0906 17-04-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02004, current rewards: 100.88342, mean: 0.11086
[32m[0906 17-04-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02001, current rewards: 106.36494, mean: 0.11080
[32m[0906 17-04-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01997, current rewards: 111.85035, mean: 0.11074
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01995, current rewards: 117.33554, mean: 0.11069
[32m[0906 17-04-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01991, current rewards: 122.82012, mean: 0.11065
[32m[0906 17-04-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01987, current rewards: 128.30870, mean: 0.11061
[32m[0906 17-04-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01985, current rewards: 133.79362, mean: 0.11057
[32m[0906 17-04-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01982, current rewards: 139.28138, mean: 0.11054
[32m[0906 17-04-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01980, current rewards: 145.66993, mean: 0.11120
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01977, current rewards: 152.25623, mean: 0.11195
[32m[0906 17-04-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01974, current rewards: 158.78391, mean: 0.11261
[32m[0906 17-04-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01973, current rewards: 165.23712, mean: 0.11318
[32m[0906 17-04-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01969, current rewards: 171.49032, mean: 0.11357
[32m[0906 17-04-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01965, current rewards: 176.98460, mean: 0.11345
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01963, current rewards: 182.48171, mean: 0.11334
[32m[0906 17-04-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01962, current rewards: 187.97700, mean: 0.11324
[32m[0906 17-04-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01960, current rewards: 193.46293, mean: 0.11314
[32m[0906 17-04-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01960, current rewards: 196.96560, mean: 0.11191
[32m[0906 17-04-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01958, current rewards: 202.44069, mean: 0.11185
[32m[0906 17-04-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01957, current rewards: 207.91516, mean: 0.11178
[32m[0906 17-04-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01956, current rewards: 213.39172, mean: 0.11172
[32m[0906 17-04-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01955, current rewards: 218.86943, mean: 0.11167
[32m[0906 17-04-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01954, current rewards: 224.34473, mean: 0.11161
[32m[0906 17-04-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01953, current rewards: 229.82101, mean: 0.11156
[32m[0906 17-04-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01951, current rewards: 235.29724, mean: 0.11152
[32m[0906 17-04-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01951, current rewards: 240.72012, mean: 0.11144
[32m[0906 17-04-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01950, current rewards: 246.17769, mean: 0.11139
[32m[0906 17-04-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01949, current rewards: 251.63428, mean: 0.11134
[32m[0906 17-04-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01948, current rewards: 257.09250, mean: 0.11130
[32m[0906 17-04-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01947, current rewards: 262.54950, mean: 0.11125
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01947, current rewards: 265.98145, mean: 0.11037
[32m[0906 17-04-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01946, current rewards: 271.54210, mean: 0.11038
[32m[0906 17-04-34 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 17-04-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-04-35 @MBExp.py:227][0m Rewards obtained: [275.9981236455521], Lows: [5], Highs: [0], Total time: 4218.637771999999
[32m[0906 17-07-38 @MBExp.py:144][0m ####################################################################
[32m[0906 17-07-38 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-07-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01979, current rewards: 0.11954, mean: 0.01195
[32m[0906 17-07-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 5.90850, mean: 0.09847
[32m[0906 17-07-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 11.79275, mean: 0.10721
[32m[0906 17-07-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.68302, mean: 0.11052
[32m[0906 17-07-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.56611, mean: 0.11222
[32m[0906 17-07-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 29.45363, mean: 0.11328
[32m[0906 17-07-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 35.33238, mean: 0.11398
[32m[0906 17-07-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 41.21746, mean: 0.11449
[32m[0906 17-07-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 47.10249, mean: 0.11488
[32m[0906 17-07-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 44.36795, mean: 0.09645
[32m[0906 17-07-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 49.94976, mean: 0.09794
[32m[0906 17-07-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: 55.58362, mean: 0.09926
[32m[0906 17-07-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 61.21757, mean: 0.10036
[32m[0906 17-07-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 66.85351, mean: 0.10129
[32m[0906 17-07-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 72.48394, mean: 0.10209
[32m[0906 17-07-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 78.11144, mean: 0.10278
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 83.75142, mean: 0.10340
[32m[0906 17-07-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01909, current rewards: 89.38374, mean: 0.10393
[32m[0906 17-07-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 95.06545, mean: 0.10447
[32m[0906 17-07-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 99.89811, mean: 0.10406
[32m[0906 17-07-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 106.09736, mean: 0.10505
[32m[0906 17-07-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 112.28956, mean: 0.10593
[32m[0906 17-07-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 118.48410, mean: 0.10674
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 124.66982, mean: 0.10747
[32m[0906 17-08-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 130.52280, mean: 0.10787
[32m[0906 17-08-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 136.03680, mean: 0.10797
[32m[0906 17-08-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 141.63863, mean: 0.10812
[32m[0906 17-08-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 147.14098, mean: 0.10819
[32m[0906 17-08-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 152.64073, mean: 0.10826
[32m[0906 17-08-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 158.14550, mean: 0.10832
[32m[0906 17-08-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 163.64673, mean: 0.10838
[32m[0906 17-08-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 169.15534, mean: 0.10843
[32m[0906 17-08-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 174.66519, mean: 0.10849
[32m[0906 17-08-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 180.39552, mean: 0.10867
[32m[0906 17-08-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 186.30944, mean: 0.10895
[32m[0906 17-08-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 192.19732, mean: 0.10920
[32m[0906 17-08-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 198.07553, mean: 0.10943
[32m[0906 17-08-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 203.96611, mean: 0.10966
[32m[0906 17-08-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 209.84447, mean: 0.10987
[32m[0906 17-08-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 215.82301, mean: 0.11011
[32m[0906 17-08-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 221.34034, mean: 0.11012
[32m[0906 17-08-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: 226.87218, mean: 0.11013
[32m[0906 17-08-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01908, current rewards: 232.41252, mean: 0.11015
[32m[0906 17-08-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 238.76036, mean: 0.11054
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 245.32117, mean: 0.11101
[32m[0906 17-08-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01908, current rewards: 251.88349, mean: 0.11145
[32m[0906 17-08-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01908, current rewards: 258.43647, mean: 0.11188
[32m[0906 17-08-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01908, current rewards: 265.00576, mean: 0.11229
[32m[0906 17-08-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01908, current rewards: 271.57104, mean: 0.11269
[32m[0906 17-08-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01908, current rewards: 278.12587, mean: 0.11306
[32m[0906 17-08-26 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-08-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-08-26 @MBExp.py:227][0m Rewards obtained: [283.3764496569034], Lows: [4], Highs: [2], Total time: 4267.172474999999
[32m[0906 17-11-32 @MBExp.py:144][0m ####################################################################
[32m[0906 17-11-32 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-11-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01907, current rewards: 1.03667, mean: 0.10367
[32m[0906 17-11-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.55733, mean: 0.10929
[32m[0906 17-11-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.06409, mean: 0.10967
[32m[0906 17-11-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.57090, mean: 0.10982
[32m[0906 17-11-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.08056, mean: 0.10991
[32m[0906 17-11-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 28.58892, mean: 0.10996
[32m[0906 17-11-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 32.01930, mean: 0.10329
[32m[0906 17-11-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 37.51284, mean: 0.10420
[32m[0906 17-11-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 43.00583, mean: 0.10489
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 48.36061, mean: 0.10513
[32m[0906 17-11-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 53.79770, mean: 0.10549
[32m[0906 17-11-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 59.23331, mean: 0.10577
[32m[0906 17-11-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 64.67464, mean: 0.10602
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 70.11098, mean: 0.10623
[32m[0906 17-11-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 75.54199, mean: 0.10640
[32m[0906 17-11-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 80.97587, mean: 0.10655
[32m[0906 17-11-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 83.29406, mean: 0.10283
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 88.98810, mean: 0.10347
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 94.62776, mean: 0.10399
[32m[0906 17-11-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 100.23771, mean: 0.10441
[32m[0906 17-11-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 105.84875, mean: 0.10480
[32m[0906 17-11-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 111.45798, mean: 0.10515
[32m[0906 17-11-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 117.06569, mean: 0.10546
[32m[0906 17-11-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 122.67755, mean: 0.10576
[32m[0906 17-11-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 124.07406, mean: 0.10254
[32m[0906 17-11-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 129.68501, mean: 0.10292
[32m[0906 17-11-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 135.08613, mean: 0.10312
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 140.51858, mean: 0.10332
[32m[0906 17-11-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 145.95302, mean: 0.10351
[32m[0906 17-12-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 151.38814, mean: 0.10369
[32m[0906 17-12-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 156.86505, mean: 0.10388
[32m[0906 17-12-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 162.34341, mean: 0.10407
[32m[0906 17-12-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01908, current rewards: 167.81707, mean: 0.10423
[32m[0906 17-12-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 173.29658, mean: 0.10440
[32m[0906 17-12-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 178.84164, mean: 0.10459
[32m[0906 17-12-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 184.32118, mean: 0.10473
[32m[0906 17-12-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: 189.88967, mean: 0.10491
[32m[0906 17-12-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 195.52167, mean: 0.10512
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 201.15698, mean: 0.10532
[32m[0906 17-12-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01906, current rewards: 206.78448, mean: 0.10550
[32m[0906 17-12-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01906, current rewards: 212.41891, mean: 0.10568
[32m[0906 17-12-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: 218.04761, mean: 0.10585
[32m[0906 17-12-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01907, current rewards: 223.68581, mean: 0.10601
[32m[0906 17-12-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01907, current rewards: 229.27367, mean: 0.10615
[32m[0906 17-12-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01907, current rewards: 234.79949, mean: 0.10624
[32m[0906 17-12-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: 240.32807, mean: 0.10634
[32m[0906 17-12-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: 245.85537, mean: 0.10643
[32m[0906 17-12-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01907, current rewards: 251.37978, mean: 0.10652
[32m[0906 17-12-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01907, current rewards: 256.90586, mean: 0.10660
[32m[0906 17-12-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01908, current rewards: 262.43017, mean: 0.10668
[32m[0906 17-12-20 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-12-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-12-20 @MBExp.py:227][0m Rewards obtained: [266.7856858571934], Lows: [4], Highs: [1], Total time: 4315.686247999999
[32m[0906 17-15-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-15-28 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 17-15-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01890, current rewards: 1.26983, mean: 0.12698
[32m[0906 17-15-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01888, current rewards: 4.18972, mean: 0.06983
[32m[0906 17-15-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01892, current rewards: 6.93641, mean: 0.06306
[32m[0906 17-15-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01898, current rewards: 9.68310, mean: 0.06052
[32m[0906 17-15-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01897, current rewards: 12.42980, mean: 0.05919
[32m[0906 17-15-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01900, current rewards: 15.17649, mean: 0.05837
[32m[0906 17-15-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01901, current rewards: -11.61496, mean: -0.03747
[32m[0906 17-15-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01901, current rewards: -61.61496, mean: -0.17115
[32m[0906 17-15-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01901, current rewards: -111.61496, mean: -0.27223
[32m[0906 17-15-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01901, current rewards: -161.61496, mean: -0.35134
[32m[0906 17-15-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01901, current rewards: -211.61496, mean: -0.41493
[32m[0906 17-15-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01902, current rewards: -261.61496, mean: -0.46717
[32m[0906 17-15-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01903, current rewards: -311.61496, mean: -0.51084
[32m[0906 17-15-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01902, current rewards: -361.61496, mean: -0.54790
[32m[0906 17-15-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01903, current rewards: -411.61496, mean: -0.57974
[32m[0906 17-15-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01904, current rewards: -461.61496, mean: -0.60739
[32m[0906 17-15-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01904, current rewards: -511.61496, mean: -0.63162
[32m[0906 17-15-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01904, current rewards: -561.61496, mean: -0.65304
[32m[0906 17-15-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01904, current rewards: -611.61496, mean: -0.67210
[32m[0906 17-15-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01904, current rewards: -661.61496, mean: -0.68918
[32m[0906 17-15-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01904, current rewards: -711.61496, mean: -0.70457
[32m[0906 17-15-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01905, current rewards: -761.61496, mean: -0.71850
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01905, current rewards: -811.61496, mean: -0.73118
[32m[0906 17-15-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01905, current rewards: -861.61496, mean: -0.74277
[32m[0906 17-15-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01905, current rewards: -911.61496, mean: -0.75340
[32m[0906 17-15-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01905, current rewards: -961.61496, mean: -0.76319
[32m[0906 17-15-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01905, current rewards: -1011.61496, mean: -0.77223
[32m[0906 17-15-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01906, current rewards: -1061.61496, mean: -0.78060
[32m[0906 17-15-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: -1111.61496, mean: -0.78838
[32m[0906 17-15-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01907, current rewards: -1161.61496, mean: -0.79563
[32m[0906 17-15-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: -1211.61496, mean: -0.80239
[32m[0906 17-15-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: -1261.61496, mean: -0.80873
[32m[0906 17-15-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: -1311.61496, mean: -0.81467
[32m[0906 17-16-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01902, current rewards: -1361.61496, mean: -0.82025
[32m[0906 17-16-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01900, current rewards: -1411.61496, mean: -0.82551
[32m[0906 17-16-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01901, current rewards: -1461.61496, mean: -0.83046
[32m[0906 17-16-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01901, current rewards: -1511.61496, mean: -0.83515
[32m[0906 17-16-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: -1561.61496, mean: -0.83958
[32m[0906 17-16-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: -1611.61496, mean: -0.84378
[32m[0906 17-16-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01902, current rewards: -1661.61496, mean: -0.84776
[32m[0906 17-16-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01903, current rewards: -1711.61496, mean: -0.85155
[32m[0906 17-16-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01903, current rewards: -1761.61496, mean: -0.85515
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01903, current rewards: -1811.61496, mean: -0.85859
[32m[0906 17-16-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01904, current rewards: -1861.61496, mean: -0.86186
[32m[0906 17-16-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01904, current rewards: -1911.61496, mean: -0.86498
[32m[0906 17-16-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01904, current rewards: -1961.61496, mean: -0.86797
[32m[0906 17-16-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01904, current rewards: -2011.61496, mean: -0.87083
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01904, current rewards: -2061.61496, mean: -0.87357
[32m[0906 17-16-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01904, current rewards: -2111.61496, mean: -0.87619
[32m[0906 17-16-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01904, current rewards: -2161.61496, mean: -0.87871
[32m[0906 17-16-16 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 17-16-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-16-16 @MBExp.py:227][0m Rewards obtained: [-2201.6149607225325], Lows: [0], Highs: [2218], Total time: 4364.124194999999
[32m[0906 17-19-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-19-26 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 17-19-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01889, current rewards: 1.18591, mean: 0.11859
[32m[0906 17-19-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.73359, mean: 0.11223
[32m[0906 17-19-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.28309, mean: 0.11166
[32m[0906 17-19-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01901, current rewards: 17.83178, mean: 0.11145
[32m[0906 17-19-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01902, current rewards: 23.37329, mean: 0.11130
[32m[0906 17-19-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01901, current rewards: 28.91015, mean: 0.11119
[32m[0906 17-19-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01900, current rewards: 34.45478, mean: 0.11114
[32m[0906 17-19-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01897, current rewards: 39.99593, mean: 0.11110
[32m[0906 17-19-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01898, current rewards: 45.43344, mean: 0.11081
[32m[0906 17-19-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01899, current rewards: 50.99871, mean: 0.11087
[32m[0906 17-19-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01900, current rewards: 56.56260, mean: 0.11091
[32m[0906 17-19-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01900, current rewards: 62.06519, mean: 0.11083
[32m[0906 17-19-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01901, current rewards: 67.59105, mean: 0.11080
[32m[0906 17-19-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01900, current rewards: 73.10899, mean: 0.11077
[32m[0906 17-19-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01902, current rewards: 78.62844, mean: 0.11074
[32m[0906 17-19-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01903, current rewards: 84.15370, mean: 0.11073
[32m[0906 17-19-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01904, current rewards: 89.70822, mean: 0.11075
[32m[0906 17-19-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01904, current rewards: 95.28037, mean: 0.11079
[32m[0906 17-19-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01905, current rewards: 100.81751, mean: 0.11079
[32m[0906 17-19-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01905, current rewards: 106.35536, mean: 0.11079
[32m[0906 17-19-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01906, current rewards: 111.89521, mean: 0.11079
[32m[0906 17-19-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 117.42843, mean: 0.11078
[32m[0906 17-19-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01905, current rewards: 122.96949, mean: 0.11078
[32m[0906 17-19-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01905, current rewards: 128.48759, mean: 0.11077
[32m[0906 17-19-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01906, current rewards: 134.00885, mean: 0.11075
[32m[0906 17-19-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 139.48065, mean: 0.11070
[32m[0906 17-19-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: 145.00384, mean: 0.11069
[32m[0906 17-19-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01906, current rewards: 150.52485, mean: 0.11068
[32m[0906 17-19-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 156.04340, mean: 0.11067
[32m[0906 17-19-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01906, current rewards: 161.56688, mean: 0.11066
[32m[0906 17-19-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 167.09273, mean: 0.11066
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 172.61381, mean: 0.11065
[32m[0906 17-19-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 178.13492, mean: 0.11064
[32m[0906 17-19-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01903, current rewards: 183.64223, mean: 0.11063
[32m[0906 17-19-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: 187.53273, mean: 0.10967
[32m[0906 17-20-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01902, current rewards: 193.51269, mean: 0.10995
[32m[0906 17-20-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01902, current rewards: 199.49404, mean: 0.11022
[32m[0906 17-20-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: 205.46863, mean: 0.11047
[32m[0906 17-20-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: 211.44395, mean: 0.11070
[32m[0906 17-20-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01903, current rewards: 217.42643, mean: 0.11093
[32m[0906 17-20-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01903, current rewards: 223.40533, mean: 0.11115
[32m[0906 17-20-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01903, current rewards: 229.37751, mean: 0.11135
[32m[0906 17-20-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01903, current rewards: 235.36495, mean: 0.11155
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01903, current rewards: 241.36462, mean: 0.11174
[32m[0906 17-20-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01903, current rewards: 247.35256, mean: 0.11192
[32m[0906 17-20-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01903, current rewards: 253.34568, mean: 0.11210
[32m[0906 17-20-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01903, current rewards: 259.04902, mean: 0.11214
[32m[0906 17-20-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01903, current rewards: 264.61024, mean: 0.11212
[32m[0906 17-20-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01904, current rewards: 270.17423, mean: 0.11211
[32m[0906 17-20-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01904, current rewards: 275.87716, mean: 0.11215
[32m[0906 17-20-14 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 17-20-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-20-14 @MBExp.py:227][0m Rewards obtained: [280.3131495794868], Lows: [1], Highs: [0], Total time: 4412.553274999999
[32m[0906 17-23-25 @MBExp.py:144][0m ####################################################################
[32m[0906 17-23-25 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 17-23-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: -6.14494, mean: -0.61449
[32m[0906 17-23-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02179, current rewards: 0.97084, mean: 0.01618
[32m[0906 17-23-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02236, current rewards: 7.87931, mean: 0.07163
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02278, current rewards: 14.76057, mean: 0.09225
[32m[0906 17-23-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02261, current rewards: 22.01521, mean: 0.10483
[32m[0906 17-23-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02217, current rewards: 27.05646, mean: 0.10406
[32m[0906 17-23-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02167, current rewards: 32.88772, mean: 0.10609
[32m[0906 17-23-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02131, current rewards: 38.79790, mean: 0.10777
[32m[0906 17-23-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02105, current rewards: 44.51727, mean: 0.10858
[32m[0906 17-23-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02084, current rewards: 50.31042, mean: 0.10937
[32m[0906 17-23-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02068, current rewards: 56.18527, mean: 0.11017
[32m[0906 17-23-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02055, current rewards: 62.03553, mean: 0.11078
[32m[0906 17-23-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02043, current rewards: 67.92703, mean: 0.11136
[32m[0906 17-23-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02032, current rewards: 73.80602, mean: 0.11183
[32m[0906 17-23-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02023, current rewards: 79.72094, mean: 0.11228
[32m[0906 17-23-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02015, current rewards: 85.57065, mean: 0.11259
[32m[0906 17-23-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02009, current rewards: 83.74850, mean: 0.10339
[32m[0906 17-23-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02003, current rewards: 93.80756, mean: 0.10908
[32m[0906 17-23-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01998, current rewards: 103.88037, mean: 0.11415
[32m[0906 17-23-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01993, current rewards: 114.09589, mean: 0.11885
[32m[0906 17-23-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01990, current rewards: 124.26609, mean: 0.12304
[32m[0906 17-23-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01986, current rewards: 134.40788, mean: 0.12680
[32m[0906 17-23-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01983, current rewards: 144.49017, mean: 0.13017
[32m[0906 17-23-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01980, current rewards: 152.26797, mean: 0.13127
[32m[0906 17-23-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01981, current rewards: 155.09048, mean: 0.12817
[32m[0906 17-23-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01987, current rewards: 159.51919, mean: 0.12660
[32m[0906 17-23-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02007, current rewards: 154.24334, mean: 0.11774
[32m[0906 17-23-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02026, current rewards: 144.65297, mean: 0.10636
[32m[0906 17-23-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02042, current rewards: 136.28149, mean: 0.09665
[32m[0906 17-23-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02057, current rewards: 133.23402, mean: 0.09126
[32m[0906 17-23-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02070, current rewards: 132.29881, mean: 0.08762
[32m[0906 17-23-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02078, current rewards: 124.73373, mean: 0.07996
[32m[0906 17-23-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02090, current rewards: 121.60471, mean: 0.07553
[32m[0906 17-24-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02101, current rewards: 114.78893, mean: 0.06915
[32m[0906 17-24-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02103, current rewards: 121.93677, mean: 0.07131
[32m[0906 17-24-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02098, current rewards: 126.24721, mean: 0.07173
[32m[0906 17-24-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02093, current rewards: 131.50414, mean: 0.07265
[32m[0906 17-24-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02088, current rewards: 136.75967, mean: 0.07353
[32m[0906 17-24-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02083, current rewards: 142.01624, mean: 0.07435
[32m[0906 17-24-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02078, current rewards: 147.27585, mean: 0.07514
[32m[0906 17-24-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02075, current rewards: 148.51776, mean: 0.07389
[32m[0906 17-24-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02071, current rewards: 153.52910, mean: 0.07453
[32m[0906 17-24-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02067, current rewards: 158.35545, mean: 0.07505
[32m[0906 17-24-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02065, current rewards: 163.38616, mean: 0.07564
[32m[0906 17-24-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02061, current rewards: 168.42112, mean: 0.07621
[32m[0906 17-24-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02058, current rewards: 173.45581, mean: 0.07675
[32m[0906 17-24-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02054, current rewards: 178.46997, mean: 0.07726
[32m[0906 17-24-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02052, current rewards: 183.49607, mean: 0.07775
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02048, current rewards: 188.53073, mean: 0.07823
[32m[0906 17-24-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02046, current rewards: 193.55769, mean: 0.07868
[32m[0906 17-24-17 @Agent.py:117][0m Average action selection time: 0.0204
[32m[0906 17-24-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-24-17 @MBExp.py:227][0m Rewards obtained: [197.6280861870108], Lows: [11], Highs: [113], Total time: 4464.458208999999
[32m[0906 17-27-31 @MBExp.py:144][0m ####################################################################
[32m[0906 17-27-31 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 17-27-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: 1.67298, mean: 0.16730
[32m[0906 17-27-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 7.18029, mean: 0.11967
[32m[0906 17-27-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 12.69464, mean: 0.11541
[32m[0906 17-27-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 18.21189, mean: 0.11382
[32m[0906 17-27-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.72623, mean: 0.11298
[32m[0906 17-27-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 29.23912, mean: 0.11246
[32m[0906 17-27-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.75697, mean: 0.11212
[32m[0906 17-27-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 40.27282, mean: 0.11187
[32m[0906 17-27-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 45.78039, mean: 0.11166
[32m[0906 17-27-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 51.29447, mean: 0.11151
[32m[0906 17-27-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 55.07883, mean: 0.10800
[32m[0906 17-27-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 60.99671, mean: 0.10892
[32m[0906 17-27-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 66.91459, mean: 0.10970
[32m[0906 17-27-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 72.83246, mean: 0.11035
[32m[0906 17-27-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 78.75034, mean: 0.11092
[32m[0906 17-27-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 84.66822, mean: 0.11141
[32m[0906 17-27-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 90.45918, mean: 0.11168
[32m[0906 17-27-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 95.72808, mean: 0.11131
[32m[0906 17-27-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 101.26226, mean: 0.11128
[32m[0906 17-27-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 106.74093, mean: 0.11119
[32m[0906 17-27-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 112.28032, mean: 0.11117
[32m[0906 17-27-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 117.81350, mean: 0.11114
[32m[0906 17-27-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 123.34149, mean: 0.11112
[32m[0906 17-27-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 128.88579, mean: 0.11111
[32m[0906 17-27-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 134.42337, mean: 0.11109
[32m[0906 17-27-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 140.15121, mean: 0.11123
[32m[0906 17-27-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 145.67551, mean: 0.11120
[32m[0906 17-27-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 151.19723, mean: 0.11117
[32m[0906 17-27-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 156.72166, mean: 0.11115
[32m[0906 17-27-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 162.24563, mean: 0.11113
[32m[0906 17-28-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 167.77127, mean: 0.11111
[32m[0906 17-28-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 173.29478, mean: 0.11109
[32m[0906 17-28-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 178.81834, mean: 0.11107
[32m[0906 17-28-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 184.50224, mean: 0.11115
[32m[0906 17-28-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: 190.26847, mean: 0.11127
[32m[0906 17-28-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 196.03756, mean: 0.11138
[32m[0906 17-28-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 201.81876, mean: 0.11150
[32m[0906 17-28-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 207.58632, mean: 0.11161
[32m[0906 17-28-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01907, current rewards: 213.35155, mean: 0.11170
[32m[0906 17-28-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 219.12328, mean: 0.11180
[32m[0906 17-28-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 224.89342, mean: 0.11189
[32m[0906 17-28-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: 230.67564, mean: 0.11198
[32m[0906 17-28-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01907, current rewards: 236.21112, mean: 0.11195
[32m[0906 17-28-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01907, current rewards: 241.74826, mean: 0.11192
[32m[0906 17-28-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 247.27975, mean: 0.11189
[32m[0906 17-28-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: 252.81311, mean: 0.11186
[32m[0906 17-28-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: 258.34579, mean: 0.11184
[32m[0906 17-28-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01907, current rewards: 263.88329, mean: 0.11181
[32m[0906 17-28-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01907, current rewards: 269.42494, mean: 0.11179
[32m[0906 17-28-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01907, current rewards: 275.05387, mean: 0.11181
[32m[0906 17-28-19 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-28-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-28-19 @MBExp.py:227][0m Rewards obtained: [279.4612605097676], Lows: [1], Highs: [0], Total time: 4512.963817999999
[32m[0906 17-31-34 @MBExp.py:144][0m ####################################################################
[32m[0906 17-31-34 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: 1.37552, mean: 0.13755
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 6.93728, mean: 0.11562
[32m[0906 17-31-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.49494, mean: 0.11359
[32m[0906 17-31-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 18.05084, mean: 0.11282
[32m[0906 17-31-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 23.60254, mean: 0.11239
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 29.14968, mean: 0.11211
[32m[0906 17-31-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.69935, mean: 0.11193
[32m[0906 17-31-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 40.48911, mean: 0.11247
[32m[0906 17-31-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 46.07841, mean: 0.11239
[32m[0906 17-31-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 51.59522, mean: 0.11216
[32m[0906 17-31-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 57.10681, mean: 0.11197
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 62.55587, mean: 0.11171
[32m[0906 17-31-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 68.06642, mean: 0.11158
[32m[0906 17-31-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 73.56982, mean: 0.11147
[32m[0906 17-31-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 79.07434, mean: 0.11137
[32m[0906 17-31-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 84.57835, mean: 0.11129
[32m[0906 17-31-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 90.08143, mean: 0.11121
[32m[0906 17-31-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 95.58754, mean: 0.11115
[32m[0906 17-31-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 101.25949, mean: 0.11127
[32m[0906 17-31-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 106.79484, mean: 0.11124
[32m[0906 17-31-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 112.33031, mean: 0.11122
[32m[0906 17-31-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 114.64710, mean: 0.10816
[32m[0906 17-31-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 120.11393, mean: 0.10821
[32m[0906 17-31-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 125.57862, mean: 0.10826
[32m[0906 17-31-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 130.92330, mean: 0.10820
[32m[0906 17-31-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 136.35974, mean: 0.10822
[32m[0906 17-32-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 141.79523, mean: 0.10824
[32m[0906 17-32-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 147.23236, mean: 0.10826
[32m[0906 17-32-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 152.66768, mean: 0.10827
[32m[0906 17-32-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 158.11226, mean: 0.10830
[32m[0906 17-32-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 163.53602, mean: 0.10830
[32m[0906 17-32-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 168.96903, mean: 0.10831
[32m[0906 17-32-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 174.36514, mean: 0.10830
[32m[0906 17-32-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: 179.78261, mean: 0.10830
[32m[0906 17-32-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 183.14130, mean: 0.10710
[32m[0906 17-32-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: 188.73177, mean: 0.10723
[32m[0906 17-32-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: 194.31273, mean: 0.10736
[32m[0906 17-32-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 199.90315, mean: 0.10747
[32m[0906 17-32-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01912, current rewards: 205.48806, mean: 0.10759
[32m[0906 17-32-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01912, current rewards: 211.07723, mean: 0.10769
[32m[0906 17-32-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: 216.66268, mean: 0.10779
[32m[0906 17-32-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 222.25124, mean: 0.10789
[32m[0906 17-32-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 227.83570, mean: 0.10798
[32m[0906 17-32-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 233.38897, mean: 0.10805
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 238.83916, mean: 0.10807
[32m[0906 17-32-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 244.28832, mean: 0.10809
[32m[0906 17-32-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 249.74145, mean: 0.10811
[32m[0906 17-32-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 255.19677, mean: 0.10813
[32m[0906 17-32-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 260.67280, mean: 0.10816
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 266.12429, mean: 0.10818
[32m[0906 17-32-23 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-32-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-32-23 @MBExp.py:227][0m Rewards obtained: [270.48686250994314], Lows: [1], Highs: [3], Total time: 4561.597647999999
[32m[0906 17-35-40 @MBExp.py:144][0m ####################################################################
[32m[0906 17-35-40 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 17-35-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01918, current rewards: 1.07597, mean: 0.10760
[32m[0906 17-35-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01900, current rewards: 6.52238, mean: 0.10871
[32m[0906 17-35-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01908, current rewards: 12.04479, mean: 0.10950
[32m[0906 17-35-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 17.56667, mean: 0.10979
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 23.08665, mean: 0.10994
[32m[0906 17-35-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01904, current rewards: 28.60766, mean: 0.11003
[32m[0906 17-35-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01905, current rewards: 34.12531, mean: 0.11008
[32m[0906 17-35-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 39.64935, mean: 0.11014
[32m[0906 17-35-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 45.16557, mean: 0.11016
[32m[0906 17-35-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.65836, mean: 0.11013
[32m[0906 17-35-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 56.21406, mean: 0.11022
[32m[0906 17-35-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: 61.75705, mean: 0.11028
[32m[0906 17-35-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01906, current rewards: 67.31024, mean: 0.11034
[32m[0906 17-35-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01907, current rewards: 72.85999, mean: 0.11039
[32m[0906 17-35-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 78.41304, mean: 0.11044
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 84.11478, mean: 0.11068
[32m[0906 17-35-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 89.63418, mean: 0.11066
[32m[0906 17-35-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 95.15878, mean: 0.11065
[32m[0906 17-35-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 100.68547, mean: 0.11064
[32m[0906 17-35-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01910, current rewards: 106.21266, mean: 0.11064
[32m[0906 17-36-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 111.74057, mean: 0.11063
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 117.27286, mean: 0.11063
[32m[0906 17-36-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 122.80368, mean: 0.11063
[32m[0906 17-36-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 128.29829, mean: 0.11060
[32m[0906 17-36-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 133.82961, mean: 0.11060
[32m[0906 17-36-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 139.35758, mean: 0.11060
[32m[0906 17-36-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 144.84749, mean: 0.11057
[32m[0906 17-36-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 150.36105, mean: 0.11056
[32m[0906 17-36-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 155.87952, mean: 0.11055
[32m[0906 17-36-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 161.40095, mean: 0.11055
[32m[0906 17-36-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 166.92187, mean: 0.11054
[32m[0906 17-36-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 172.44599, mean: 0.11054
[32m[0906 17-36-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 177.92886, mean: 0.11051
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 183.44685, mean: 0.11051
[32m[0906 17-36-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 188.96813, mean: 0.11051
[32m[0906 17-36-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 194.48711, mean: 0.11050
[32m[0906 17-36-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 200.00715, mean: 0.11050
[32m[0906 17-36-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01908, current rewards: 205.53457, mean: 0.11050
[32m[0906 17-36-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 211.15280, mean: 0.11055
[32m[0906 17-36-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 216.67157, mean: 0.11055
[32m[0906 17-36-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: 222.18800, mean: 0.11054
[32m[0906 17-36-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 227.70664, mean: 0.11054
[32m[0906 17-36-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 233.22213, mean: 0.11053
[32m[0906 17-36-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 238.75246, mean: 0.11053
[32m[0906 17-36-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 244.27700, mean: 0.11053
[32m[0906 17-36-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 249.79779, mean: 0.11053
[32m[0906 17-36-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 255.31350, mean: 0.11053
[32m[0906 17-36-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 260.83658, mean: 0.11052
[32m[0906 17-36-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 266.37617, mean: 0.11053
[32m[0906 17-36-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: 271.89647, mean: 0.11053
[32m[0906 17-36-29 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-36-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-36-29 @MBExp.py:227][0m Rewards obtained: [276.29592571361593], Lows: [0], Highs: [0], Total time: 4610.172483999999
[32m[0906 17-39-48 @MBExp.py:144][0m ####################################################################
[32m[0906 17-39-48 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 17-39-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: 1.07310, mean: 0.10731
[32m[0906 17-39-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01901, current rewards: 6.51611, mean: 0.10860
[32m[0906 17-39-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01896, current rewards: 12.04860, mean: 0.10953
[32m[0906 17-39-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01901, current rewards: 17.57736, mean: 0.10986
[32m[0906 17-39-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 23.10982, mean: 0.11005
[32m[0906 17-39-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 28.63443, mean: 0.11013
[32m[0906 17-39-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01907, current rewards: 34.13564, mean: 0.11011
[32m[0906 17-39-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 39.66213, mean: 0.11017
[32m[0906 17-39-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 45.18785, mean: 0.11021
[32m[0906 17-39-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.71482, mean: 0.11025
[32m[0906 17-39-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 54.13697, mean: 0.10615
[32m[0906 17-39-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 59.67793, mean: 0.10657
[32m[0906 17-40-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 65.22361, mean: 0.10692
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 70.76769, mean: 0.10722
[32m[0906 17-40-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 76.27390, mean: 0.10743
[32m[0906 17-40-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 81.82851, mean: 0.10767
[32m[0906 17-40-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 87.38054, mean: 0.10788
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 92.92835, mean: 0.10806
[32m[0906 17-40-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 98.47772, mean: 0.10822
[32m[0906 17-40-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 104.02772, mean: 0.10836
[32m[0906 17-40-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 109.57589, mean: 0.10849
[32m[0906 17-40-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 115.12655, mean: 0.10861
[32m[0906 17-40-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 120.67646, mean: 0.10872
[32m[0906 17-40-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 126.38161, mean: 0.10895
[32m[0906 17-40-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 131.92801, mean: 0.10903
[32m[0906 17-40-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 137.39739, mean: 0.10905
[32m[0906 17-40-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 142.93938, mean: 0.10911
[32m[0906 17-40-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 148.48421, mean: 0.10918
[32m[0906 17-40-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 154.02652, mean: 0.10924
[32m[0906 17-40-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 159.57000, mean: 0.10929
[32m[0906 17-40-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: 165.11793, mean: 0.10935
[32m[0906 17-40-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 170.68595, mean: 0.10941
[32m[0906 17-40-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 176.23297, mean: 0.10946
[32m[0906 17-40-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 181.82501, mean: 0.10953
[32m[0906 17-40-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 187.49195, mean: 0.10964
[32m[0906 17-40-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 193.16235, mean: 0.10975
[32m[0906 17-40-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 198.83008, mean: 0.10985
[32m[0906 17-40-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 204.50013, mean: 0.10995
[32m[0906 17-40-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01907, current rewards: 210.16731, mean: 0.11004
[32m[0906 17-40-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 215.78106, mean: 0.11009
[32m[0906 17-40-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 221.44199, mean: 0.11017
[32m[0906 17-40-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 227.11118, mean: 0.11025
[32m[0906 17-40-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01908, current rewards: 232.77598, mean: 0.11032
[32m[0906 17-40-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 238.39407, mean: 0.11037
[32m[0906 17-40-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 243.92997, mean: 0.11038
[32m[0906 17-40-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 249.46394, mean: 0.11038
[32m[0906 17-40-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: 255.00238, mean: 0.11039
[32m[0906 17-40-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01909, current rewards: 260.51365, mean: 0.11039
[32m[0906 17-40-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01909, current rewards: 266.04641, mean: 0.11039
[32m[0906 17-40-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 271.58708, mean: 0.11040
[32m[0906 17-40-36 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-40-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-40-36 @MBExp.py:227][0m Rewards obtained: [276.01868528249145], Lows: [1], Highs: [0], Total time: 4658.747730999999
[32m[0906 17-43-58 @MBExp.py:144][0m ####################################################################
[32m[0906 17-43-58 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 17-43-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01885, current rewards: 1.04192, mean: 0.10419
[32m[0906 17-43-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01899, current rewards: 6.58420, mean: 0.10974
[32m[0906 17-44-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01900, current rewards: 12.12772, mean: 0.11025
[32m[0906 17-44-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01902, current rewards: 17.68434, mean: 0.11053
[32m[0906 17-44-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01900, current rewards: 23.23097, mean: 0.11062
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01903, current rewards: 28.77423, mean: 0.11067
[32m[0906 17-44-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01905, current rewards: 34.33574, mean: 0.11076
[32m[0906 17-44-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01906, current rewards: 40.18620, mean: 0.11163
[32m[0906 17-44-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01906, current rewards: 45.76304, mean: 0.11162
[32m[0906 17-44-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01906, current rewards: 51.33102, mean: 0.11159
[32m[0906 17-44-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01907, current rewards: 56.90202, mean: 0.11157
[32m[0906 17-44-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 62.47409, mean: 0.11156
[32m[0906 17-44-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 68.04936, mean: 0.11156
[32m[0906 17-44-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 73.61897, mean: 0.11154
[32m[0906 17-44-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 79.39023, mean: 0.11182
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 85.31691, mean: 0.11226
[32m[0906 17-44-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 90.94699, mean: 0.11228
[32m[0906 17-44-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01909, current rewards: 96.56856, mean: 0.11229
[32m[0906 17-44-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 102.19610, mean: 0.11230
[32m[0906 17-44-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01908, current rewards: 107.82606, mean: 0.11232
[32m[0906 17-44-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: 113.45232, mean: 0.11233
[32m[0906 17-44-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 119.08182, mean: 0.11234
[32m[0906 17-44-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 124.52759, mean: 0.11219
[32m[0906 17-44-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 129.89055, mean: 0.11197
[32m[0906 17-44-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 135.25148, mean: 0.11178
[32m[0906 17-44-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01910, current rewards: 140.62272, mean: 0.11161
[32m[0906 17-44-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 145.97936, mean: 0.11143
[32m[0906 17-44-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01910, current rewards: 151.34391, mean: 0.11128
[32m[0906 17-44-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 156.71175, mean: 0.11114
[32m[0906 17-44-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 162.07883, mean: 0.11101
[32m[0906 17-44-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 165.51607, mean: 0.10961
[32m[0906 17-44-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 171.14837, mean: 0.10971
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 176.78119, mean: 0.10980
[32m[0906 17-44-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 182.41949, mean: 0.10989
[32m[0906 17-44-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 188.05833, mean: 0.10998
[32m[0906 17-44-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: 193.69630, mean: 0.11005
[32m[0906 17-44-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 199.32985, mean: 0.11013
[32m[0906 17-44-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 204.96767, mean: 0.11020
[32m[0906 17-44-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01911, current rewards: 210.59348, mean: 0.11026
[32m[0906 17-44-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01911, current rewards: 216.23549, mean: 0.11032
[32m[0906 17-44-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 221.87547, mean: 0.11039
[32m[0906 17-44-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01911, current rewards: 227.51510, mean: 0.11044
[32m[0906 17-44-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 233.15065, mean: 0.11050
[32m[0906 17-44-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01911, current rewards: 236.72311, mean: 0.10959
[32m[0906 17-44-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01911, current rewards: 242.40507, mean: 0.10969
[32m[0906 17-44-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01911, current rewards: 248.07796, mean: 0.10977
[32m[0906 17-44-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01911, current rewards: 253.68746, mean: 0.10982
[32m[0906 17-44-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01911, current rewards: 259.36369, mean: 0.10990
[32m[0906 17-44-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: 265.04969, mean: 0.10998
[32m[0906 17-44-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 270.73131, mean: 0.11005
[32m[0906 17-44-47 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 17-44-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-44-47 @MBExp.py:227][0m Rewards obtained: [275.27928128617816], Lows: [2], Highs: [0], Total time: 4707.376206999998
[32m[0906 17-48-10 @MBExp.py:144][0m ####################################################################
[32m[0906 17-48-10 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 17-48-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02094, current rewards: -1.98008, mean: -0.19801
[32m[0906 17-48-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01928, current rewards: 3.56080, mean: 0.05935
[32m[0906 17-48-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 9.10106, mean: 0.08274
[32m[0906 17-48-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 14.63720, mean: 0.09148
[32m[0906 17-48-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 20.17199, mean: 0.09606
[32m[0906 17-48-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 25.70274, mean: 0.09886
[32m[0906 17-48-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 31.24000, mean: 0.10077
[32m[0906 17-48-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 36.77958, mean: 0.10217
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 42.30726, mean: 0.10319
[32m[0906 17-48-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 47.84535, mean: 0.10401
[32m[0906 17-48-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 53.39060, mean: 0.10469
[32m[0906 17-48-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 58.93161, mean: 0.10524
[32m[0906 17-48-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 64.46432, mean: 0.10568
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 69.97882, mean: 0.10603
[32m[0906 17-48-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 75.53650, mean: 0.10639
[32m[0906 17-48-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 81.20491, mean: 0.10685
[32m[0906 17-48-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01954, current rewards: 87.10471, mean: 0.10754
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01993, current rewards: 93.08801, mean: 0.10824
[32m[0906 17-48-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02022, current rewards: 99.02199, mean: 0.10882
[32m[0906 17-48-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02048, current rewards: 105.24288, mean: 0.10963
[32m[0906 17-48-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02069, current rewards: 111.48267, mean: 0.11038
[32m[0906 17-48-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02091, current rewards: 117.66352, mean: 0.11100
[32m[0906 17-48-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02098, current rewards: 123.42015, mean: 0.11119
[32m[0906 17-48-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02091, current rewards: 129.00640, mean: 0.11121
[32m[0906 17-48-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02084, current rewards: 134.59756, mean: 0.11124
[32m[0906 17-48-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02077, current rewards: 140.18630, mean: 0.11126
[32m[0906 17-48-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02070, current rewards: 145.77669, mean: 0.11128
[32m[0906 17-48-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02063, current rewards: 151.36212, mean: 0.11130
[32m[0906 17-48-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02056, current rewards: 156.94541, mean: 0.11131
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02051, current rewards: 162.73658, mean: 0.11146
[32m[0906 17-48-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02047, current rewards: 168.75995, mean: 0.11176
[32m[0906 17-48-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02042, current rewards: 174.59823, mean: 0.11192
[32m[0906 17-48-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02037, current rewards: 180.44144, mean: 0.11208
[32m[0906 17-48-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02033, current rewards: 186.28195, mean: 0.11222
[32m[0906 17-48-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02029, current rewards: 192.12249, mean: 0.11235
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02026, current rewards: 197.96161, mean: 0.11248
[32m[0906 17-48-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02022, current rewards: 202.15594, mean: 0.11169
[32m[0906 17-48-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02019, current rewards: 207.34442, mean: 0.11148
[32m[0906 17-48-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02016, current rewards: 212.54720, mean: 0.11128
[32m[0906 17-48-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02013, current rewards: 217.74015, mean: 0.11109
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02010, current rewards: 222.93481, mean: 0.11091
[32m[0906 17-48-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02008, current rewards: 228.13046, mean: 0.11074
[32m[0906 17-48-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02005, current rewards: 233.32739, mean: 0.11058
[32m[0906 17-48-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02003, current rewards: 238.52747, mean: 0.11043
[32m[0906 17-48-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02001, current rewards: 243.72307, mean: 0.11028
[32m[0906 17-48-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01999, current rewards: 247.05307, mean: 0.10932
[32m[0906 17-48-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01997, current rewards: 252.58690, mean: 0.10934
[32m[0906 17-48-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01995, current rewards: 258.12117, mean: 0.10937
[32m[0906 17-48-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01994, current rewards: 263.65764, mean: 0.10940
[32m[0906 17-49-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01992, current rewards: 269.19422, mean: 0.10943
[32m[0906 17-49-01 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 17-49-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-49-01 @MBExp.py:227][0m Rewards obtained: [273.62350427812237], Lows: [2], Highs: [2], Total time: 4757.974428999998
[32m[0906 17-52-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-52-28 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 17-52-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01915, current rewards: 1.07337, mean: 0.10734
[32m[0906 17-52-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 6.58910, mean: 0.10982
[32m[0906 17-52-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.10439, mean: 0.11004
[32m[0906 17-52-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 17.61927, mean: 0.11012
[32m[0906 17-52-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 23.13249, mean: 0.11015
[32m[0906 17-52-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 28.62396, mean: 0.11009
[32m[0906 17-52-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01906, current rewards: 34.13449, mean: 0.11011
[32m[0906 17-52-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: 39.64613, mean: 0.11013
[32m[0906 17-52-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01906, current rewards: 45.15673, mean: 0.11014
[32m[0906 17-52-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01907, current rewards: 50.66824, mean: 0.11015
[32m[0906 17-52-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01907, current rewards: 56.17541, mean: 0.11015
[32m[0906 17-52-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 61.67933, mean: 0.11014
[32m[0906 17-52-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 67.14975, mean: 0.11008
[32m[0906 17-52-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 72.65369, mean: 0.11008
[32m[0906 17-52-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 78.16836, mean: 0.11010
[32m[0906 17-52-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 81.60871, mean: 0.10738
[32m[0906 17-52-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01908, current rewards: 87.11725, mean: 0.10755
[32m[0906 17-52-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: 92.62855, mean: 0.10771
[32m[0906 17-52-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01907, current rewards: 98.13946, mean: 0.10785
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 103.65097, mean: 0.10797
[32m[0906 17-52-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01907, current rewards: 109.12403, mean: 0.10804
[32m[0906 17-52-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01907, current rewards: 114.63887, mean: 0.10815
[32m[0906 17-52-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01906, current rewards: 120.15340, mean: 0.10825
[32m[0906 17-52-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 125.66768, mean: 0.10833
[32m[0906 17-52-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01907, current rewards: 131.18111, mean: 0.10841
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01907, current rewards: 136.69355, mean: 0.10849
[32m[0906 17-52-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01907, current rewards: 138.93575, mean: 0.10606
[32m[0906 17-52-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01907, current rewards: 144.41696, mean: 0.10619
[32m[0906 17-52-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01904, current rewards: 149.96321, mean: 0.10636
[32m[0906 17-52-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 155.43161, mean: 0.10646
[32m[0906 17-52-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01901, current rewards: 160.90500, mean: 0.10656
[32m[0906 17-52-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01899, current rewards: 166.37453, mean: 0.10665
[32m[0906 17-52-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01897, current rewards: 171.85024, mean: 0.10674
[32m[0906 17-53-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 177.32802, mean: 0.10682
[32m[0906 17-53-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: 182.79397, mean: 0.10690
[32m[0906 17-53-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01892, current rewards: 188.26061, mean: 0.10697
[32m[0906 17-53-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01892, current rewards: 194.39469, mean: 0.10740
[32m[0906 17-53-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01891, current rewards: 199.91601, mean: 0.10748
[32m[0906 17-53-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01889, current rewards: 205.44290, mean: 0.10756
[32m[0906 17-53-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01888, current rewards: 210.96335, mean: 0.10763
[32m[0906 17-53-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 216.48750, mean: 0.10771
[32m[0906 17-53-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 222.00397, mean: 0.10777
[32m[0906 17-53-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 227.52671, mean: 0.10783
[32m[0906 17-53-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 233.68653, mean: 0.10819
[32m[0906 17-53-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: 239.15516, mean: 0.10822
[32m[0906 17-53-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: 244.87760, mean: 0.10835
[32m[0906 17-53-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: 250.64425, mean: 0.10850
[32m[0906 17-53-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 256.41034, mean: 0.10865
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: 262.17579, mean: 0.10879
[32m[0906 17-53-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: 267.94694, mean: 0.10892
[32m[0906 17-53-16 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-53-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-53-16 @MBExp.py:227][0m Rewards obtained: [272.5643265458691], Lows: [2], Highs: [1], Total time: 4805.989960999998
[32m[0906 17-56-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-45 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 17-56-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01875, current rewards: -20.00000, mean: -2.00000
[32m[0906 17-56-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: -120.00000, mean: -2.00000
[32m[0906 17-56-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: -220.00000, mean: -2.00000
[32m[0906 17-56-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01952, current rewards: -249.95790, mean: -1.56224
[32m[0906 17-56-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01940, current rewards: -283.11977, mean: -1.34819
[32m[0906 17-56-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02027, current rewards: -314.20877, mean: -1.20850
[32m[0906 17-56-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02116, current rewards: -346.15257, mean: -1.11662
[32m[0906 17-56-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02185, current rewards: -375.12162, mean: -1.04200
[32m[0906 17-56-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02230, current rewards: -408.97990, mean: -0.99751
[32m[0906 17-56-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02268, current rewards: -444.06480, mean: -0.96536
[32m[0906 17-56-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02294, current rewards: -477.81488, mean: -0.93689
[32m[0906 17-56-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02321, current rewards: -507.73450, mean: -0.90667
[32m[0906 17-56-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02334, current rewards: -505.31395, mean: -0.82838
[32m[0906 17-57-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02341, current rewards: -500.83266, mean: -0.75884
[32m[0906 17-57-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02354, current rewards: -497.42743, mean: -0.70060
[32m[0906 17-57-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02365, current rewards: -493.10872, mean: -0.64883
[32m[0906 17-57-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02365, current rewards: -494.56134, mean: -0.61057
[32m[0906 17-57-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02343, current rewards: -540.28748, mean: -0.62824
[32m[0906 17-57-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02344, current rewards: -569.98180, mean: -0.62635
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02332, current rewards: -609.27987, mean: -0.63467
[32m[0906 17-57-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02323, current rewards: -647.41007, mean: -0.64100
[32m[0906 17-57-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02311, current rewards: -686.60366, mean: -0.64774
[32m[0906 17-57-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02312, current rewards: -708.13883, mean: -0.63796
[32m[0906 17-57-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02311, current rewards: -714.43112, mean: -0.61589
[32m[0906 17-57-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02310, current rewards: -720.53210, mean: -0.59548
[32m[0906 17-57-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02310, current rewards: -731.71375, mean: -0.58073
[32m[0906 17-57-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02312, current rewards: -746.24938, mean: -0.56966
[32m[0906 17-57-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02315, current rewards: -760.41379, mean: -0.55913
[32m[0906 17-57-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02307, current rewards: -793.40225, mean: -0.56270
[32m[0906 17-57-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02292, current rewards: -832.92321, mean: -0.57050
[32m[0906 17-57-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02280, current rewards: -871.39757, mean: -0.57708
[32m[0906 17-57-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02268, current rewards: -909.87121, mean: -0.58325
[32m[0906 17-57-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02259, current rewards: -947.29816, mean: -0.58838
[32m[0906 17-57-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02248, current rewards: -984.72472, mean: -0.59321
[32m[0906 17-57-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02238, current rewards: -1023.19893, mean: -0.59836
[32m[0906 17-57-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02230, current rewards: -1047.99716, mean: -0.59545
[32m[0906 17-57-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02220, current rewards: -1042.51837, mean: -0.57598
[32m[0906 17-57-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02210, current rewards: -1036.99744, mean: -0.55753
[32m[0906 17-57-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02201, current rewards: -1031.47785, mean: -0.54004
[32m[0906 17-57-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02193, current rewards: -1025.95515, mean: -0.52345
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02186, current rewards: -1020.43407, mean: -0.50768
[32m[0906 17-57-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02180, current rewards: -1014.91146, mean: -0.49268
[32m[0906 17-57-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02173, current rewards: -1009.39198, mean: -0.47838
[32m[0906 17-57-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02167, current rewards: -1003.86791, mean: -0.46475
[32m[0906 17-57-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02170, current rewards: -1015.57488, mean: -0.45954
[32m[0906 17-57-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02181, current rewards: -1021.24505, mean: -0.45188
[32m[0906 17-57-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02192, current rewards: -1026.77514, mean: -0.44449
[32m[0906 17-57-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02203, current rewards: -1031.13844, mean: -0.43692
[32m[0906 17-57-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02212, current rewards: -1033.86157, mean: -0.42899
[32m[0906 17-57-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02220, current rewards: -1040.59088, mean: -0.42300
[32m[0906 17-57-41 @Agent.py:117][0m Average action selection time: 0.0223
[32m[0906 17-57-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-57-41 @MBExp.py:227][0m Rewards obtained: [-1044.614870483689], Lows: [204], Highs: [803], Total time: 4862.487062999999
[32m[0906 18-01-12 @MBExp.py:144][0m ####################################################################
[32m[0906 18-01-12 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-01-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: 0.98561, mean: 0.09856
[32m[0906 18-01-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 5.91823, mean: 0.09864
[32m[0906 18-01-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01901, current rewards: 10.87762, mean: 0.09889
[32m[0906 18-01-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01904, current rewards: 15.83550, mean: 0.09897
[32m[0906 18-01-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 20.80737, mean: 0.09908
[32m[0906 18-01-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 25.78108, mean: 0.09916
[32m[0906 18-01-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 30.75630, mean: 0.09921
[32m[0906 18-01-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 35.72915, mean: 0.09925
[32m[0906 18-01-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 40.70213, mean: 0.09927
[32m[0906 18-01-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 42.62659, mean: 0.09267
[32m[0906 18-01-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 48.17474, mean: 0.09446
[32m[0906 18-01-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 53.75205, mean: 0.09599
[32m[0906 18-01-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: 59.28671, mean: 0.09719
[32m[0906 18-01-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 64.82853, mean: 0.09823
[32m[0906 18-01-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 70.36747, mean: 0.09911
[32m[0906 18-01-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 73.73705, mean: 0.09702
[32m[0906 18-01-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01909, current rewards: 78.63092, mean: 0.09708
[32m[0906 18-01-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 83.52425, mean: 0.09712
[32m[0906 18-01-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 88.41707, mean: 0.09716
[32m[0906 18-01-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01905, current rewards: 93.31019, mean: 0.09720
[32m[0906 18-01-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01902, current rewards: 98.20322, mean: 0.09723
[32m[0906 18-01-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01899, current rewards: 103.09660, mean: 0.09726
[32m[0906 18-01-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01895, current rewards: 107.98971, mean: 0.09729
[32m[0906 18-01-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01894, current rewards: 112.88269, mean: 0.09731
[32m[0906 18-01-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01893, current rewards: 117.77609, mean: 0.09734
[32m[0906 18-01-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01891, current rewards: 122.66890, mean: 0.09736
[32m[0906 18-01-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01889, current rewards: 126.90001, mean: 0.09687
[32m[0906 18-01-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01889, current rewards: 132.46395, mean: 0.09740
[32m[0906 18-01-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01888, current rewards: 137.97585, mean: 0.09786
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01887, current rewards: 143.49887, mean: 0.09829
[32m[0906 18-01-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01885, current rewards: 149.01462, mean: 0.09869
[32m[0906 18-01-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01884, current rewards: 154.53985, mean: 0.09906
[32m[0906 18-01-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01883, current rewards: 160.05756, mean: 0.09941
[32m[0906 18-01-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01881, current rewards: 165.85164, mean: 0.09991
[32m[0906 18-01-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01881, current rewards: 171.40818, mean: 0.10024
[32m[0906 18-01-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: 176.98482, mean: 0.10056
[32m[0906 18-01-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 182.53624, mean: 0.10085
[32m[0906 18-01-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: 188.08713, mean: 0.10112
[32m[0906 18-01-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: 193.63840, mean: 0.10138
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 199.19287, mean: 0.10163
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 204.74407, mean: 0.10186
[32m[0906 18-01-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 210.29635, mean: 0.10209
[32m[0906 18-01-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 215.85339, mean: 0.10230
[32m[0906 18-01-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 221.82384, mean: 0.10270
[32m[0906 18-01-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 227.40344, mean: 0.10290
[32m[0906 18-01-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 233.01619, mean: 0.10310
[32m[0906 18-01-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 238.63091, mean: 0.10330
[32m[0906 18-01-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 244.24687, mean: 0.10349
[32m[0906 18-01-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 249.85988, mean: 0.10368
[32m[0906 18-01-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 255.47592, mean: 0.10385
[32m[0906 18-02-00 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 18-02-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-02-00 @MBExp.py:227][0m Rewards obtained: [259.96591580561136], Lows: [2], Highs: [2], Total time: 4910.533149999998
[32m[0906 18-05-32 @MBExp.py:144][0m ####################################################################
[32m[0906 18-05-32 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-05-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01883, current rewards: 1.71047, mean: 0.17105
[32m[0906 18-05-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 7.10508, mean: 0.11842
[32m[0906 18-05-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.52370, mean: 0.11385
[32m[0906 18-05-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.85657, mean: 0.11160
[32m[0906 18-05-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.18865, mean: 0.11042
[32m[0906 18-05-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 28.52276, mean: 0.10970
[32m[0906 18-05-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 33.85342, mean: 0.10920
[32m[0906 18-05-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 39.18666, mean: 0.10885
[32m[0906 18-05-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 45.09545, mean: 0.10999
[32m[0906 18-05-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 49.95448, mean: 0.10860
[32m[0906 18-05-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 54.81008, mean: 0.10747
[32m[0906 18-05-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 59.67551, mean: 0.10656
[32m[0906 18-05-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 64.54192, mean: 0.10581
[32m[0906 18-05-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 69.40720, mean: 0.10516
[32m[0906 18-05-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 74.27214, mean: 0.10461
[32m[0906 18-05-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 74.81055, mean: 0.09843
[32m[0906 18-05-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 80.20583, mean: 0.09902
[32m[0906 18-05-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 85.59490, mean: 0.09953
[32m[0906 18-05-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 90.91315, mean: 0.09990
[32m[0906 18-05-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01910, current rewards: 96.29642, mean: 0.10031
[32m[0906 18-05-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01906, current rewards: 101.69492, mean: 0.10069
[32m[0906 18-05-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01904, current rewards: 107.08785, mean: 0.10103
[32m[0906 18-05-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01901, current rewards: 112.47762, mean: 0.10133
[32m[0906 18-05-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01900, current rewards: 117.88009, mean: 0.10162
[32m[0906 18-05-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01898, current rewards: 123.27220, mean: 0.10188
[32m[0906 18-05-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01897, current rewards: 128.66372, mean: 0.10211
[32m[0906 18-05-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01896, current rewards: 134.08751, mean: 0.10236
[32m[0906 18-05-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01894, current rewards: 139.50414, mean: 0.10258
[32m[0906 18-05-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01891, current rewards: 144.90005, mean: 0.10277
[32m[0906 18-06-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01889, current rewards: 150.29321, mean: 0.10294
[32m[0906 18-06-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01888, current rewards: 155.78435, mean: 0.10317
[32m[0906 18-06-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01887, current rewards: 161.21892, mean: 0.10335
[32m[0906 18-06-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01885, current rewards: 166.65021, mean: 0.10351
[32m[0906 18-06-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01884, current rewards: 172.08408, mean: 0.10367
[32m[0906 18-06-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01883, current rewards: 177.51343, mean: 0.10381
[32m[0906 18-06-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01882, current rewards: 182.95044, mean: 0.10395
[32m[0906 18-06-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: 188.38455, mean: 0.10408
[32m[0906 18-06-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 193.81700, mean: 0.10420
[32m[0906 18-06-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 199.24795, mean: 0.10432
[32m[0906 18-06-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: 204.67934, mean: 0.10443
[32m[0906 18-06-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 210.11065, mean: 0.10453
[32m[0906 18-06-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 213.45664, mean: 0.10362
[32m[0906 18-06-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: 218.82137, mean: 0.10371
[32m[0906 18-06-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: 224.19190, mean: 0.10379
[32m[0906 18-06-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 229.55419, mean: 0.10387
[32m[0906 18-06-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: 234.91709, mean: 0.10395
[32m[0906 18-06-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 240.28226, mean: 0.10402
[32m[0906 18-06-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 245.64715, mean: 0.10409
[32m[0906 18-06-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 251.01544, mean: 0.10416
[32m[0906 18-06-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: 256.37944, mean: 0.10422
[32m[0906 18-06-20 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 18-06-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-06-20 @MBExp.py:227][0m Rewards obtained: [260.6634953484082], Lows: [1], Highs: [4], Total time: 4958.623835999998
[32m[0906 18-09-55 @MBExp.py:144][0m ####################################################################
[32m[0906 18-09-55 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 18-09-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01860, current rewards: 1.19247, mean: 0.11925
[32m[0906 18-09-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.76892, mean: 0.11282
[32m[0906 18-09-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.30108, mean: 0.11183
[32m[0906 18-09-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 17.83032, mean: 0.11144
[32m[0906 18-09-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.36101, mean: 0.11124
[32m[0906 18-10-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 28.89293, mean: 0.11113
[32m[0906 18-10-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.42433, mean: 0.11105
[32m[0906 18-10-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 39.95754, mean: 0.11099
[32m[0906 18-10-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 44.53633, mean: 0.10863
[32m[0906 18-10-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01907, current rewards: 50.20075, mean: 0.10913
[32m[0906 18-10-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01908, current rewards: 55.76759, mean: 0.10935
[32m[0906 18-10-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01909, current rewards: 61.33783, mean: 0.10953
[32m[0906 18-10-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01909, current rewards: 66.91302, mean: 0.10969
[32m[0906 18-10-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 72.47655, mean: 0.10981
[32m[0906 18-10-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 78.04816, mean: 0.10993
[32m[0906 18-10-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 83.61457, mean: 0.11002
[32m[0906 18-10-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 89.59030, mean: 0.11061
[32m[0906 18-10-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 95.10801, mean: 0.11059
[32m[0906 18-10-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 100.65071, mean: 0.11061
[32m[0906 18-10-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 106.20497, mean: 0.11063
[32m[0906 18-10-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: 111.75774, mean: 0.11065
[32m[0906 18-10-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01905, current rewards: 117.30730, mean: 0.11067
[32m[0906 18-10-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01903, current rewards: 122.76849, mean: 0.11060
[32m[0906 18-10-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01901, current rewards: 127.85397, mean: 0.11022
[32m[0906 18-10-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01898, current rewards: 132.93960, mean: 0.10987
[32m[0906 18-10-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01896, current rewards: 138.02215, mean: 0.10954
[32m[0906 18-10-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01895, current rewards: 143.06112, mean: 0.10921
[32m[0906 18-10-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01894, current rewards: 148.17253, mean: 0.10895
[32m[0906 18-10-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01893, current rewards: 153.28629, mean: 0.10871
[32m[0906 18-10-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01891, current rewards: 158.39956, mean: 0.10849
[32m[0906 18-10-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01890, current rewards: 163.51029, mean: 0.10828
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01888, current rewards: 168.63051, mean: 0.10810
[32m[0906 18-10-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01886, current rewards: 173.74915, mean: 0.10792
[32m[0906 18-10-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01886, current rewards: 178.86059, mean: 0.10775
[32m[0906 18-10-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01885, current rewards: 184.03915, mean: 0.10763
[32m[0906 18-10-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 189.13662, mean: 0.10746
[32m[0906 18-10-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 194.21751, mean: 0.10730
[32m[0906 18-10-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01885, current rewards: 199.65348, mean: 0.10734
[32m[0906 18-10-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01885, current rewards: 205.22119, mean: 0.10745
[32m[0906 18-10-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01886, current rewards: 210.78865, mean: 0.10755
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 216.35578, mean: 0.10764
[32m[0906 18-10-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 221.91867, mean: 0.10773
[32m[0906 18-10-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 227.48784, mean: 0.10781
[32m[0906 18-10-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 232.97307, mean: 0.10786
[32m[0906 18-10-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 238.53760, mean: 0.10794
[32m[0906 18-10-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 244.23929, mean: 0.10807
[32m[0906 18-10-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 249.78790, mean: 0.10813
[32m[0906 18-10-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01892, current rewards: 255.33211, mean: 0.10819
[32m[0906 18-10-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 260.88062, mean: 0.10825
[32m[0906 18-10-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 266.42736, mean: 0.10830
[32m[0906 18-10-43 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 18-10-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-10-43 @MBExp.py:227][0m Rewards obtained: [270.8645738805651], Lows: [0], Highs: [1], Total time: 5006.794957999998
[32m[0906 18-14-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-14-19 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 18-14-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01853, current rewards: 0.99817, mean: 0.09982
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01899, current rewards: 6.40377, mean: 0.10673
[32m[0906 18-14-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 11.86162, mean: 0.10783
[32m[0906 18-14-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.36158, mean: 0.10851
[32m[0906 18-14-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 22.85461, mean: 0.10883
[32m[0906 18-14-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01905, current rewards: 28.35761, mean: 0.10907
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01907, current rewards: 33.84873, mean: 0.10919
[32m[0906 18-14-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01906, current rewards: 39.35785, mean: 0.10933
[32m[0906 18-14-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01908, current rewards: 44.84646, mean: 0.10938
[32m[0906 18-14-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 43.96346, mean: 0.09557
[32m[0906 18-14-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01955, current rewards: 47.81743, mean: 0.09376
[32m[0906 18-14-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01986, current rewards: 51.45326, mean: 0.09188
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02017, current rewards: 55.08643, mean: 0.09031
[32m[0906 18-14-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02038, current rewards: 58.72366, mean: 0.08898
[32m[0906 18-14-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02056, current rewards: 62.36180, mean: 0.08783
[32m[0906 18-14-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02077, current rewards: 66.00223, mean: 0.08685
[32m[0906 18-14-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02094, current rewards: 69.64783, mean: 0.08598
[32m[0906 18-14-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02112, current rewards: 73.29451, mean: 0.08523
[32m[0906 18-14-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02138, current rewards: 77.90481, mean: 0.08561
[32m[0906 18-14-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02149, current rewards: 82.35995, mean: 0.08579
[32m[0906 18-14-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02164, current rewards: 86.86626, mean: 0.08601
[32m[0906 18-14-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02177, current rewards: 91.15623, mean: 0.08600
[32m[0906 18-14-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02191, current rewards: 95.72773, mean: 0.08624
[32m[0906 18-14-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02199, current rewards: 99.62821, mean: 0.08589
[32m[0906 18-14-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02185, current rewards: 104.88924, mean: 0.08669
[32m[0906 18-14-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02171, current rewards: 110.13981, mean: 0.08741
[32m[0906 18-14-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02159, current rewards: 115.38375, mean: 0.08808
[32m[0906 18-14-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02148, current rewards: 120.54088, mean: 0.08863
[32m[0906 18-14-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02139, current rewards: 125.69042, mean: 0.08914
[32m[0906 18-14-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02129, current rewards: 130.84294, mean: 0.08962
[32m[0906 18-14-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02120, current rewards: 136.00292, mean: 0.09007
[32m[0906 18-14-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02112, current rewards: 135.43986, mean: 0.08682
[32m[0906 18-14-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02106, current rewards: 141.27132, mean: 0.08775
[32m[0906 18-14-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02102, current rewards: 147.10019, mean: 0.08861
[32m[0906 18-14-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02106, current rewards: 147.85056, mean: 0.08646
[32m[0906 18-14-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02117, current rewards: 146.05978, mean: 0.08299
[32m[0906 18-14-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02121, current rewards: 136.58579, mean: 0.07546
[32m[0906 18-14-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02130, current rewards: 130.18909, mean: 0.06999
[32m[0906 18-15-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02135, current rewards: 124.33122, mean: 0.06509
[32m[0906 18-15-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02138, current rewards: 115.51186, mean: 0.05893
[32m[0906 18-15-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02143, current rewards: 101.49974, mean: 0.05050
[32m[0906 18-15-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02146, current rewards: 91.28542, mean: 0.04431
[32m[0906 18-15-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02146, current rewards: 84.66465, mean: 0.04013
[32m[0906 18-15-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02152, current rewards: 79.79045, mean: 0.03694
[32m[0906 18-15-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02159, current rewards: 77.99333, mean: 0.03529
[32m[0906 18-15-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02165, current rewards: 76.29732, mean: 0.03376
[32m[0906 18-15-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02170, current rewards: 74.46800, mean: 0.03224
[32m[0906 18-15-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02177, current rewards: 73.82977, mean: 0.03128
[32m[0906 18-15-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02177, current rewards: 68.09979, mean: 0.02826
[32m[0906 18-15-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02172, current rewards: 72.89203, mean: 0.02963
[32m[0906 18-15-13 @Agent.py:117][0m Average action selection time: 0.0217
[32m[0906 18-15-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-15-14 @MBExp.py:227][0m Rewards obtained: [76.72728596111361], Lows: [16], Highs: [125], Total time: 5061.8336169999975
[32m[0906 18-18-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-18-53 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01926, current rewards: 0.95803, mean: 0.09580
[32m[0906 18-18-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 5.70705, mean: 0.09512
[32m[0906 18-18-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 10.45474, mean: 0.09504
[32m[0906 18-18-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 15.20659, mean: 0.09504
[32m[0906 18-18-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 19.95324, mean: 0.09502
[32m[0906 18-18-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 24.70081, mean: 0.09500
[32m[0906 18-18-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 29.44892, mean: 0.09500
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 34.19626, mean: 0.09499
[32m[0906 18-19-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 37.36777, mean: 0.09114
[32m[0906 18-19-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 42.80953, mean: 0.09306
[32m[0906 18-19-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 48.35827, mean: 0.09482
[32m[0906 18-19-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 53.91208, mean: 0.09627
[32m[0906 18-19-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 59.46624, mean: 0.09749
[32m[0906 18-19-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 65.01444, mean: 0.09851
[32m[0906 18-19-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01904, current rewards: 70.56470, mean: 0.09939
[32m[0906 18-19-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01900, current rewards: 76.12200, mean: 0.10016
[32m[0906 18-19-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01897, current rewards: 81.66880, mean: 0.10083
[32m[0906 18-19-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01894, current rewards: 87.20390, mean: 0.10140
[32m[0906 18-19-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01891, current rewards: 92.72696, mean: 0.10190
[32m[0906 18-19-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01888, current rewards: 97.15983, mean: 0.10121
[32m[0906 18-19-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01886, current rewards: 101.80564, mean: 0.10080
[32m[0906 18-19-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01884, current rewards: 106.47097, mean: 0.10044
[32m[0906 18-19-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01881, current rewards: 111.13191, mean: 0.10012
[32m[0906 18-19-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01880, current rewards: 115.79368, mean: 0.09982
[32m[0906 18-19-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01880, current rewards: 120.45733, mean: 0.09955
[32m[0906 18-19-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01878, current rewards: 125.11861, mean: 0.09930
[32m[0906 18-19-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01878, current rewards: 129.77693, mean: 0.09907
[32m[0906 18-19-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01877, current rewards: 134.44108, mean: 0.09885
[32m[0906 18-19-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01876, current rewards: 139.09966, mean: 0.09865
[32m[0906 18-19-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01875, current rewards: 143.76607, mean: 0.09847
[32m[0906 18-19-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 148.42819, mean: 0.09830
[32m[0906 18-19-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 153.09410, mean: 0.09814
[32m[0906 18-19-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01873, current rewards: 157.75941, mean: 0.09799
[32m[0906 18-19-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: 162.42110, mean: 0.09784
[32m[0906 18-19-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 165.60338, mean: 0.09684
[32m[0906 18-19-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01870, current rewards: 170.64748, mean: 0.09696
[32m[0906 18-19-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01870, current rewards: 175.68847, mean: 0.09707
[32m[0906 18-19-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01872, current rewards: 180.73161, mean: 0.09717
[32m[0906 18-19-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01873, current rewards: 185.78195, mean: 0.09727
[32m[0906 18-19-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01874, current rewards: 190.82889, mean: 0.09736
[32m[0906 18-19-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01875, current rewards: 195.87503, mean: 0.09745
[32m[0906 18-19-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01876, current rewards: 200.91941, mean: 0.09753
[32m[0906 18-19-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01877, current rewards: 205.94383, mean: 0.09760
[32m[0906 18-19-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01878, current rewards: 211.01400, mean: 0.09769
[32m[0906 18-19-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01879, current rewards: 213.93793, mean: 0.09680
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01880, current rewards: 218.85599, mean: 0.09684
[32m[0906 18-19-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 223.77486, mean: 0.09687
[32m[0906 18-19-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 228.69368, mean: 0.09690
[32m[0906 18-19-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01882, current rewards: 233.61284, mean: 0.09693
[32m[0906 18-19-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: 238.53168, mean: 0.09696
[32m[0906 18-19-41 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-19-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-19-41 @MBExp.py:227][0m Rewards obtained: [242.43949060737327], Lows: [3], Highs: [1], Total time: 5109.736956999997
[32m[0906 18-23-21 @MBExp.py:144][0m ####################################################################
[32m[0906 18-23-21 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01887, current rewards: 1.06693, mean: 0.10669
[32m[0906 18-23-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 6.61089, mean: 0.11018
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01904, current rewards: 12.21094, mean: 0.11101
[32m[0906 18-23-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01903, current rewards: 17.82005, mean: 0.11138
[32m[0906 18-23-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.42293, mean: 0.11154
[32m[0906 18-23-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 29.02004, mean: 0.11162
[32m[0906 18-23-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 34.61611, mean: 0.11166
[32m[0906 18-23-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 40.22740, mean: 0.11174
[32m[0906 18-23-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01905, current rewards: 43.91851, mean: 0.10712
[32m[0906 18-23-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01907, current rewards: 49.74142, mean: 0.10813
[32m[0906 18-23-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01908, current rewards: 55.54948, mean: 0.10892
[32m[0906 18-23-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: 61.36344, mean: 0.10958
[32m[0906 18-23-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 67.17225, mean: 0.11012
[32m[0906 18-23-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 72.98201, mean: 0.11058
[32m[0906 18-23-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 78.79156, mean: 0.11097
[32m[0906 18-23-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01902, current rewards: 84.60321, mean: 0.11132
[32m[0906 18-23-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01898, current rewards: 90.41223, mean: 0.11162
[32m[0906 18-23-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01894, current rewards: 92.99708, mean: 0.10814
[32m[0906 18-23-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01892, current rewards: 98.80967, mean: 0.10858
[32m[0906 18-23-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01889, current rewards: 104.62902, mean: 0.10899
[32m[0906 18-23-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01888, current rewards: 110.44843, mean: 0.10935
[32m[0906 18-23-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01886, current rewards: 116.26285, mean: 0.10968
[32m[0906 18-23-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01884, current rewards: 122.07460, mean: 0.10998
[32m[0906 18-23-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01884, current rewards: 127.88541, mean: 0.11025
[32m[0906 18-23-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01882, current rewards: 134.36439, mean: 0.11104
[32m[0906 18-23-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01882, current rewards: 140.04917, mean: 0.11115
[32m[0906 18-23-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01880, current rewards: 145.72351, mean: 0.11124
[32m[0906 18-23-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01879, current rewards: 151.39068, mean: 0.11132
[32m[0906 18-23-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01878, current rewards: 157.05800, mean: 0.11139
[32m[0906 18-23-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01877, current rewards: 162.72724, mean: 0.11146
[32m[0906 18-23-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01877, current rewards: 168.40235, mean: 0.11152
[32m[0906 18-23-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01876, current rewards: 174.07142, mean: 0.11158
[32m[0906 18-23-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: 179.74209, mean: 0.11164
[32m[0906 18-23-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01875, current rewards: 185.42182, mean: 0.11170
[32m[0906 18-23-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 191.08331, mean: 0.11174
[32m[0906 18-23-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01874, current rewards: 196.32328, mean: 0.11155
[32m[0906 18-23-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01874, current rewards: 201.13709, mean: 0.11113
[32m[0906 18-23-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01875, current rewards: 205.95115, mean: 0.11073
[32m[0906 18-23-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: 210.76165, mean: 0.11035
[32m[0906 18-23-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 215.56978, mean: 0.10998
[32m[0906 18-23-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01878, current rewards: 220.34404, mean: 0.10962
[32m[0906 18-24-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01878, current rewards: 225.07222, mean: 0.10926
[32m[0906 18-24-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01879, current rewards: 229.80649, mean: 0.10891
[32m[0906 18-24-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 234.54178, mean: 0.10858
[32m[0906 18-24-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 239.27377, mean: 0.10827
[32m[0906 18-24-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 244.00602, mean: 0.10797
[32m[0906 18-24-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 248.74034, mean: 0.10768
[32m[0906 18-24-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01883, current rewards: 253.53340, mean: 0.10743
[32m[0906 18-24-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 258.33543, mean: 0.10719
[32m[0906 18-24-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 263.08845, mean: 0.10695
[32m[0906 18-24-09 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 18-24-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-24-09 @MBExp.py:227][0m Rewards obtained: [266.904527894429], Lows: [2], Highs: [1], Total time: 5157.720847999997
[32m[0906 18-27-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-27-53 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01869, current rewards: 1.08683, mean: 0.10868
[32m[0906 18-27-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.67053, mean: 0.11118
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.23233, mean: 0.11120
[32m[0906 18-27-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.79670, mean: 0.11123
[32m[0906 18-27-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.40708, mean: 0.11146
[32m[0906 18-27-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 29.09368, mean: 0.11190
[32m[0906 18-27-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.76631, mean: 0.11215
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 40.44114, mean: 0.11234
[32m[0906 18-28-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.99091, mean: 0.11217
[32m[0906 18-28-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 51.63726, mean: 0.11225
[32m[0906 18-28-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 57.27990, mean: 0.11231
[32m[0906 18-28-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 62.92364, mean: 0.11236
[32m[0906 18-28-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 68.56295, mean: 0.11240
[32m[0906 18-28-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 74.20201, mean: 0.11243
[32m[0906 18-28-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 77.81346, mean: 0.10960
[32m[0906 18-28-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01902, current rewards: 83.64248, mean: 0.11006
[32m[0906 18-28-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01899, current rewards: 89.36702, mean: 0.11033
[32m[0906 18-28-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01895, current rewards: 95.15051, mean: 0.11064
[32m[0906 18-28-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01893, current rewards: 100.93146, mean: 0.11091
[32m[0906 18-28-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01891, current rewards: 106.71210, mean: 0.11116
[32m[0906 18-28-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01889, current rewards: 112.49639, mean: 0.11138
[32m[0906 18-28-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01887, current rewards: 118.27442, mean: 0.11158
[32m[0906 18-28-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01884, current rewards: 124.05502, mean: 0.11176
[32m[0906 18-28-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01883, current rewards: 129.83820, mean: 0.11193
[32m[0906 18-28-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01882, current rewards: 135.69520, mean: 0.11214
[32m[0906 18-28-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01881, current rewards: 142.85560, mean: 0.11338
[32m[0906 18-28-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01880, current rewards: 140.13277, mean: 0.10697
[32m[0906 18-28-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01879, current rewards: 90.13277, mean: 0.06627
[32m[0906 18-28-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01878, current rewards: 40.13277, mean: 0.02846
[32m[0906 18-28-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01877, current rewards: -9.86723, mean: -0.00676
[32m[0906 18-28-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01876, current rewards: -59.86723, mean: -0.03965
[32m[0906 18-28-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01875, current rewards: -109.86723, mean: -0.07043
[32m[0906 18-28-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: -159.86723, mean: -0.09930
[32m[0906 18-28-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: -209.86723, mean: -0.12643
[32m[0906 18-28-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: -259.86723, mean: -0.15197
[32m[0906 18-28-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01871, current rewards: -309.86723, mean: -0.17606
[32m[0906 18-28-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01870, current rewards: -359.86723, mean: -0.19882
[32m[0906 18-28-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01870, current rewards: -409.86723, mean: -0.22036
[32m[0906 18-28-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01870, current rewards: -459.86723, mean: -0.24077
[32m[0906 18-28-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01869, current rewards: -509.86723, mean: -0.26014
[32m[0906 18-28-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01869, current rewards: -559.86723, mean: -0.27854
[32m[0906 18-28-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01869, current rewards: -609.86723, mean: -0.29605
[32m[0906 18-28-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01868, current rewards: -659.86723, mean: -0.31273
[32m[0906 18-28-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01869, current rewards: -709.86723, mean: -0.32864
[32m[0906 18-28-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01870, current rewards: -759.86723, mean: -0.34383
[32m[0906 18-28-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01871, current rewards: -809.86723, mean: -0.35835
[32m[0906 18-28-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01872, current rewards: -859.86723, mean: -0.37224
[32m[0906 18-28-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01873, current rewards: -909.86723, mean: -0.38554
[32m[0906 18-28-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01874, current rewards: -959.86723, mean: -0.39829
[32m[0906 18-28-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01875, current rewards: -1009.86723, mean: -0.41052
[32m[0906 18-28-40 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-28-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-28-41 @MBExp.py:227][0m Rewards obtained: [-1049.8672346322214], Lows: [1], Highs: [1199], Total time: 5205.453254999998
[32m[0906 18-32-26 @MBExp.py:144][0m ####################################################################
[32m[0906 18-32-26 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 18-32-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 1.14296, mean: 0.11430
[32m[0906 18-32-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.55612, mean: 0.10927
[32m[0906 18-32-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 11.97351, mean: 0.10885
[32m[0906 18-32-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 17.38805, mean: 0.10868
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 22.80414, mean: 0.10859
[32m[0906 18-32-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.21846, mean: 0.10853
[32m[0906 18-32-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 33.63348, mean: 0.10850
[32m[0906 18-32-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 39.30686, mean: 0.10919
[32m[0906 18-32-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 44.97853, mean: 0.10970
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 50.63527, mean: 0.11008
[32m[0906 18-32-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 56.29174, mean: 0.11038
[32m[0906 18-32-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 61.94080, mean: 0.11061
[32m[0906 18-32-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.59547, mean: 0.11081
[32m[0906 18-32-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.29268, mean: 0.11105
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.75449, mean: 0.11092
[32m[0906 18-32-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.21629, mean: 0.11081
[32m[0906 18-32-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 89.68020, mean: 0.11072
[32m[0906 18-32-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 95.14953, mean: 0.11064
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 99.93128, mean: 0.10981
[32m[0906 18-32-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01928, current rewards: 105.43879, mean: 0.10983
[32m[0906 18-32-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01948, current rewards: 110.94304, mean: 0.10984
[32m[0906 18-32-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01965, current rewards: 116.45500, mean: 0.10986
[32m[0906 18-32-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01980, current rewards: 121.99839, mean: 0.10991
[32m[0906 18-32-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: 127.56263, mean: 0.10997
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02003, current rewards: 133.16310, mean: 0.11005
[32m[0906 18-32-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02012, current rewards: 138.86854, mean: 0.11021
[32m[0906 18-32-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02019, current rewards: 144.55598, mean: 0.11035
[32m[0906 18-32-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02015, current rewards: 150.31157, mean: 0.11052
[32m[0906 18-32-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02010, current rewards: 156.03556, mean: 0.11066
[32m[0906 18-32-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02004, current rewards: 161.76286, mean: 0.11080
[32m[0906 18-32-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01999, current rewards: 167.49205, mean: 0.11092
[32m[0906 18-32-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01994, current rewards: 173.21913, mean: 0.11104
[32m[0906 18-32-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01990, current rewards: 179.01438, mean: 0.11119
[32m[0906 18-33-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01986, current rewards: 184.81845, mean: 0.11134
[32m[0906 18-33-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01981, current rewards: 193.11857, mean: 0.11293
[32m[0906 18-33-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01978, current rewards: 201.41870, mean: 0.11444
[32m[0906 18-33-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01975, current rewards: 209.71882, mean: 0.11587
[32m[0906 18-33-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01972, current rewards: 218.01895, mean: 0.11721
[32m[0906 18-33-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01969, current rewards: 219.32306, mean: 0.11483
[32m[0906 18-33-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01965, current rewards: 169.32306, mean: 0.08639
[32m[0906 18-33-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01962, current rewards: 119.32306, mean: 0.05936
[32m[0906 18-33-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01961, current rewards: 69.32306, mean: 0.03365
[32m[0906 18-33-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01960, current rewards: 19.32306, mean: 0.00916
[32m[0906 18-33-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01959, current rewards: -30.67694, mean: -0.01420
[32m[0906 18-33-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01958, current rewards: -80.67694, mean: -0.03651
[32m[0906 18-33-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01957, current rewards: -130.67694, mean: -0.05782
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01957, current rewards: -180.67694, mean: -0.07822
[32m[0906 18-33-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01955, current rewards: -230.67694, mean: -0.09774
[32m[0906 18-33-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01954, current rewards: -280.67694, mean: -0.11646
[32m[0906 18-33-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01954, current rewards: -330.67694, mean: -0.13442
[32m[0906 18-33-16 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 18-33-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-33-16 @MBExp.py:227][0m Rewards obtained: [-370.67693820611214], Lows: [1], Highs: [597], Total time: 5255.1334659999975
[32m[0906 18-37-04 @MBExp.py:144][0m ####################################################################
[32m[0906 18-37-04 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01872, current rewards: 1.04490, mean: 0.10449
[32m[0906 18-37-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.65569, mean: 0.11093
[32m[0906 18-37-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.26903, mean: 0.11154
[32m[0906 18-37-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.88000, mean: 0.11175
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.48984, mean: 0.11186
[32m[0906 18-37-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 29.10232, mean: 0.11193
[32m[0906 18-37-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.71292, mean: 0.11198
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: 37.14232, mean: 0.10317
[32m[0906 18-37-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 42.65073, mean: 0.10403
[32m[0906 18-37-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 48.15673, mean: 0.10469
[32m[0906 18-37-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 53.66789, mean: 0.10523
[32m[0906 18-37-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 59.17947, mean: 0.10568
[32m[0906 18-37-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 64.68234, mean: 0.10604
[32m[0906 18-37-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 68.15629, mean: 0.10327
[32m[0906 18-37-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 73.69258, mean: 0.10379
[32m[0906 18-37-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 79.22374, mean: 0.10424
[32m[0906 18-37-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01907, current rewards: 84.73959, mean: 0.10462
[32m[0906 18-37-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01904, current rewards: 90.28601, mean: 0.10498
[32m[0906 18-37-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01901, current rewards: 95.82766, mean: 0.10531
[32m[0906 18-37-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01899, current rewards: 101.37408, mean: 0.10560
[32m[0906 18-37-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01896, current rewards: 106.91982, mean: 0.10586
[32m[0906 18-37-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01894, current rewards: 112.46462, mean: 0.10610
[32m[0906 18-37-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01891, current rewards: 117.97713, mean: 0.10629
[32m[0906 18-37-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01890, current rewards: 123.50817, mean: 0.10647
[32m[0906 18-37-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01888, current rewards: 129.02482, mean: 0.10663
[32m[0906 18-37-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01886, current rewards: 134.55294, mean: 0.10679
[32m[0906 18-37-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01886, current rewards: 140.07729, mean: 0.10693
[32m[0906 18-37-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01884, current rewards: 145.60438, mean: 0.10706
[32m[0906 18-37-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01883, current rewards: 151.13051, mean: 0.10718
[32m[0906 18-37-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01881, current rewards: 157.00629, mean: 0.10754
[32m[0906 18-37-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01880, current rewards: 162.53873, mean: 0.10764
[32m[0906 18-37-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01880, current rewards: 168.06820, mean: 0.10774
[32m[0906 18-37-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01880, current rewards: 173.59806, mean: 0.10782
[32m[0906 18-37-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01879, current rewards: 179.13279, mean: 0.10791
[32m[0906 18-37-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: 184.66881, mean: 0.10799
[32m[0906 18-37-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: 190.26861, mean: 0.10811
[32m[0906 18-37-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 195.89423, mean: 0.10823
[32m[0906 18-37-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 201.53545, mean: 0.10835
[32m[0906 18-37-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01877, current rewards: 207.16315, mean: 0.10846
[32m[0906 18-37-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 212.80599, mean: 0.10857
[32m[0906 18-37-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01876, current rewards: 218.54186, mean: 0.10873
[32m[0906 18-37-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01877, current rewards: 224.20999, mean: 0.10884
[32m[0906 18-37-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01878, current rewards: 229.87915, mean: 0.10895
[32m[0906 18-37-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 235.54717, mean: 0.10905
[32m[0906 18-37-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01880, current rewards: 241.21240, mean: 0.10915
[32m[0906 18-37-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 246.87089, mean: 0.10923
[32m[0906 18-37-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01882, current rewards: 252.53582, mean: 0.10932
[32m[0906 18-37-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01882, current rewards: 254.64461, mean: 0.10790
[32m[0906 18-37-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01883, current rewards: 260.33459, mean: 0.10802
[32m[0906 18-37-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: 266.02092, mean: 0.10814
[32m[0906 18-37-51 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-37-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-37-52 @MBExp.py:227][0m Rewards obtained: [270.5695088793821], Lows: [4], Highs: [1], Total time: 5303.078088999998
[32m[0906 18-41-41 @MBExp.py:144][0m ####################################################################
[32m[0906 18-41-41 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 18-41-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01901, current rewards: -2.08803, mean: -0.20880
[32m[0906 18-41-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01898, current rewards: 3.33577, mean: 0.05560
[32m[0906 18-41-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 8.73496, mean: 0.07941
[32m[0906 18-41-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 14.14216, mean: 0.08839
[32m[0906 18-41-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 17.87666, mean: 0.08513
[32m[0906 18-41-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 23.79453, mean: 0.09152
[32m[0906 18-41-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 29.36367, mean: 0.09472
[32m[0906 18-41-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: -11.13212, mean: -0.03092
[32m[0906 18-41-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: -61.13212, mean: -0.14910
[32m[0906 18-41-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: -111.13212, mean: -0.24159
[32m[0906 18-41-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: -161.13212, mean: -0.31595
[32m[0906 18-41-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: -211.13212, mean: -0.37702
[32m[0906 18-41-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: -261.13212, mean: -0.42809
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01914, current rewards: -311.13212, mean: -0.47141
[32m[0906 18-41-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: -361.13212, mean: -0.50864
[32m[0906 18-41-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01906, current rewards: -382.92482, mean: -0.50385
[32m[0906 18-41-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01901, current rewards: -432.92482, mean: -0.53448
[32m[0906 18-41-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01897, current rewards: -482.92482, mean: -0.56154
[32m[0906 18-41-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01893, current rewards: -532.92482, mean: -0.58563
[32m[0906 18-41-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01892, current rewards: -582.92482, mean: -0.60721
[32m[0906 18-42-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01890, current rewards: -632.92482, mean: -0.62666
[32m[0906 18-42-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01888, current rewards: -682.92482, mean: -0.64427
[32m[0906 18-42-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01887, current rewards: -732.92482, mean: -0.66029
[32m[0906 18-42-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01886, current rewards: -782.92482, mean: -0.67494
[32m[0906 18-42-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01884, current rewards: -832.92482, mean: -0.68837
[32m[0906 18-42-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01883, current rewards: -882.92482, mean: -0.70073
[32m[0906 18-42-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01882, current rewards: -932.92482, mean: -0.71216
[32m[0906 18-42-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01881, current rewards: -982.92482, mean: -0.72274
[32m[0906 18-42-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01880, current rewards: -1032.92482, mean: -0.73257
[32m[0906 18-42-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01880, current rewards: -1082.92482, mean: -0.74173
[32m[0906 18-42-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01878, current rewards: -1132.92482, mean: -0.75028
[32m[0906 18-42-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01878, current rewards: -1182.92482, mean: -0.75829
[32m[0906 18-42-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01877, current rewards: -1232.92482, mean: -0.76579
[32m[0906 18-42-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: -1282.92482, mean: -0.77285
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: -1332.92482, mean: -0.77949
[32m[0906 18-42-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: -1382.92482, mean: -0.78575
[32m[0906 18-42-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01874, current rewards: -1432.92482, mean: -0.79167
[32m[0906 18-42-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01873, current rewards: -1482.92482, mean: -0.79727
[32m[0906 18-42-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01872, current rewards: -1532.92482, mean: -0.80258
[32m[0906 18-42-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01872, current rewards: -1582.92482, mean: -0.80761
[32m[0906 18-42-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01872, current rewards: -1632.92482, mean: -0.81240
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01872, current rewards: -1682.92482, mean: -0.81695
[32m[0906 18-42-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01873, current rewards: -1732.92482, mean: -0.82129
[32m[0906 18-42-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01874, current rewards: -1782.92482, mean: -0.82543
[32m[0906 18-42-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01875, current rewards: -1832.92482, mean: -0.82938
[32m[0906 18-42-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01876, current rewards: -1882.92482, mean: -0.83315
[32m[0906 18-42-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01877, current rewards: -1932.92482, mean: -0.83676
[32m[0906 18-42-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01878, current rewards: -1982.92482, mean: -0.84022
[32m[0906 18-42-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01879, current rewards: -2032.92482, mean: -0.84354
[32m[0906 18-42-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: -2082.92482, mean: -0.84672
[32m[0906 18-42-28 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-42-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-42-29 @MBExp.py:227][0m Rewards obtained: [-2122.9248172267185], Lows: [2], Highs: [2156], Total time: 5350.9174319999975
[32m[0906 18-46-20 @MBExp.py:144][0m ####################################################################
[32m[0906 18-46-20 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.05534, mean: 0.10553
[32m[0906 18-46-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01917, current rewards: 6.37116, mean: 0.10619
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 11.77097, mean: 0.10701
[32m[0906 18-46-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01915, current rewards: 17.17759, mean: 0.10736
[32m[0906 18-46-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 22.57295, mean: 0.10749
[32m[0906 18-46-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 27.96816, mean: 0.10757
[32m[0906 18-46-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 33.37270, mean: 0.10765
[32m[0906 18-46-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 38.81227, mean: 0.10781
[32m[0906 18-46-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 44.19704, mean: 0.10780
[32m[0906 18-46-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 49.58304, mean: 0.10779
[32m[0906 18-46-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 54.96547, mean: 0.10778
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 58.26508, mean: 0.10404
[32m[0906 18-46-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 63.82124, mean: 0.10462
[32m[0906 18-46-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 69.37421, mean: 0.10511
[32m[0906 18-46-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 74.92683, mean: 0.10553
[32m[0906 18-46-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 80.37709, mean: 0.10576
[32m[0906 18-46-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01902, current rewards: 85.83651, mean: 0.10597
[32m[0906 18-46-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01899, current rewards: 91.29668, mean: 0.10616
[32m[0906 18-46-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01896, current rewards: 96.75300, mean: 0.10632
[32m[0906 18-46-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01895, current rewards: 89.21225, mean: 0.09293
[32m[0906 18-46-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01892, current rewards: 60.96138, mean: 0.06036
[32m[0906 18-46-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01891, current rewards: 32.46990, mean: 0.03063
[32m[0906 18-46-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01889, current rewards: 6.25613, mean: 0.00564
[32m[0906 18-46-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01887, current rewards: -22.36434, mean: -0.01928
[32m[0906 18-46-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01886, current rewards: -51.56111, mean: -0.04261
[32m[0906 18-46-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01884, current rewards: -78.52894, mean: -0.06232
[32m[0906 18-46-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01883, current rewards: -107.21162, mean: -0.08184
[32m[0906 18-46-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01883, current rewards: -127.06134, mean: -0.09343
[32m[0906 18-46-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01881, current rewards: -156.24608, mean: -0.11081
[32m[0906 18-46-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01881, current rewards: -183.11147, mean: -0.12542
[32m[0906 18-46-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01881, current rewards: -210.31975, mean: -0.13928
[32m[0906 18-46-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01880, current rewards: -236.50420, mean: -0.15161
[32m[0906 18-46-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01880, current rewards: -235.32224, mean: -0.14616
[32m[0906 18-46-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01880, current rewards: -229.90162, mean: -0.13849
[32m[0906 18-46-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: -226.36609, mean: -0.13238
[32m[0906 18-46-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: -220.82041, mean: -0.12547
[32m[0906 18-46-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: -215.27409, mean: -0.11894
[32m[0906 18-46-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01876, current rewards: -211.78743, mean: -0.11386
[32m[0906 18-46-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01875, current rewards: -206.23863, mean: -0.10798
[32m[0906 18-46-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01875, current rewards: -200.68588, mean: -0.10239
[32m[0906 18-46-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01874, current rewards: -195.23396, mean: -0.09713
[32m[0906 18-46-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01874, current rewards: -189.67896, mean: -0.09208
[32m[0906 18-47-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01876, current rewards: -184.12577, mean: -0.08726
[32m[0906 18-47-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01877, current rewards: -178.57366, mean: -0.08267
[32m[0906 18-47-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01878, current rewards: -173.01864, mean: -0.07829
[32m[0906 18-47-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01879, current rewards: -167.46235, mean: -0.07410
[32m[0906 18-47-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01880, current rewards: -161.91002, mean: -0.07009
[32m[0906 18-47-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: -156.35332, mean: -0.06625
[32m[0906 18-47-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01882, current rewards: -150.79142, mean: -0.06257
[32m[0906 18-47-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: -145.23791, mean: -0.05904
[32m[0906 18-47-08 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-47-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-47-08 @MBExp.py:227][0m Rewards obtained: [-140.77845997476246], Lows: [205], Highs: [5], Total time: 5398.847330999997
[32m[0906 18-51-01 @MBExp.py:144][0m ####################################################################
[32m[0906 18-51-01 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 18-51-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 1.08284, mean: 0.10828
[32m[0906 18-51-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01907, current rewards: 6.64289, mean: 0.11071
[32m[0906 18-51-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.20124, mean: 0.11092
[32m[0906 18-51-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.75568, mean: 0.11097
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.31627, mean: 0.11103
[32m[0906 18-51-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 28.87793, mean: 0.11107
[32m[0906 18-51-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 34.44856, mean: 0.11112
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 40.00340, mean: 0.11112
[32m[0906 18-51-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.56294, mean: 0.11113
[32m[0906 18-51-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 49.04790, mean: 0.10663
[32m[0906 18-51-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 54.63843, mean: 0.10713
[32m[0906 18-51-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 60.23205, mean: 0.10756
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 65.82412, mean: 0.10791
[32m[0906 18-51-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 71.41828, mean: 0.10821
[32m[0906 18-51-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 76.99167, mean: 0.10844
[32m[0906 18-51-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 82.53548, mean: 0.10860
[32m[0906 18-51-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 88.71811, mean: 0.10953
[32m[0906 18-51-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01901, current rewards: 94.31693, mean: 0.10967
[32m[0906 18-51-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01899, current rewards: 99.91589, mean: 0.10980
[32m[0906 18-51-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01897, current rewards: 105.51428, mean: 0.10991
[32m[0906 18-51-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01895, current rewards: 111.11048, mean: 0.11001
[32m[0906 18-51-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01894, current rewards: 116.70704, mean: 0.11010
[32m[0906 18-51-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01893, current rewards: 122.30277, mean: 0.11018
[32m[0906 18-51-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01891, current rewards: 127.81928, mean: 0.11019
[32m[0906 18-51-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01889, current rewards: 133.40795, mean: 0.11025
[32m[0906 18-51-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01888, current rewards: 138.99858, mean: 0.11032
[32m[0906 18-51-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01886, current rewards: 100.11763, mean: 0.07643
[32m[0906 18-51-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01886, current rewards: 50.11763, mean: 0.03685
[32m[0906 18-51-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01885, current rewards: 0.11763, mean: 0.00008
[32m[0906 18-51-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01885, current rewards: -49.88237, mean: -0.03417
[32m[0906 18-51-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01884, current rewards: -99.88237, mean: -0.06615
[32m[0906 18-51-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01884, current rewards: -132.16061, mean: -0.08472
[32m[0906 18-51-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01883, current rewards: -126.53491, mean: -0.07859
[32m[0906 18-51-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01882, current rewards: -120.91209, mean: -0.07284
[32m[0906 18-51-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01882, current rewards: -115.28768, mean: -0.06742
[32m[0906 18-51-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01882, current rewards: -109.65913, mean: -0.06231
[32m[0906 18-51-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01881, current rewards: -104.02968, mean: -0.05747
[32m[0906 18-51-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01881, current rewards: -99.42167, mean: -0.05345
[32m[0906 18-51-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: -93.97907, mean: -0.04920
[32m[0906 18-51-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: -88.58634, mean: -0.04520
[32m[0906 18-51-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01880, current rewards: -83.10472, mean: -0.04135
[32m[0906 18-51-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01879, current rewards: -77.61308, mean: -0.03768
[32m[0906 18-51-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: -72.12295, mean: -0.03418
[32m[0906 18-51-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: -66.63131, mean: -0.03085
[32m[0906 18-51-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: -61.13361, mean: -0.02766
[32m[0906 18-51-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01883, current rewards: -55.64108, mean: -0.02462
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: -50.14794, mean: -0.02171
[32m[0906 18-51-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: -44.65620, mean: -0.01892
[32m[0906 18-51-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: -39.11045, mean: -0.01623
[32m[0906 18-51-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: -33.69053, mean: -0.01370
[32m[0906 18-51-49 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 18-51-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-51-49 @MBExp.py:227][0m Rewards obtained: [-29.355747811407248], Lows: [1], Highs: [275], Total time: 5446.877233999997
[32m[0906 18-55-45 @MBExp.py:144][0m ####################################################################
[32m[0906 18-55-45 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 18-55-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: 1.18110, mean: 0.11811
[32m[0906 18-55-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.73187, mean: 0.11220
[32m[0906 18-55-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.29001, mean: 0.11173
[32m[0906 18-55-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.84739, mean: 0.11155
[32m[0906 18-55-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 23.40379, mean: 0.11145
[32m[0906 18-55-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 29.07834, mean: 0.11184
[32m[0906 18-55-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 34.67341, mean: 0.11185
[32m[0906 18-55-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 40.22227, mean: 0.11173
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 45.76527, mean: 0.11162
[32m[0906 18-55-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 51.31509, mean: 0.11155
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 56.86194, mean: 0.11149
[32m[0906 18-55-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 62.40438, mean: 0.11144
[32m[0906 18-55-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 68.21844, mean: 0.11183
[32m[0906 18-55-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01914, current rewards: 73.64678, mean: 0.11159
[32m[0906 18-55-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 79.05835, mean: 0.11135
[32m[0906 18-55-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 84.47773, mean: 0.11115
[32m[0906 18-56-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01904, current rewards: 89.91095, mean: 0.11100
[32m[0906 18-56-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01900, current rewards: 95.34057, mean: 0.11086
[32m[0906 18-56-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01898, current rewards: 100.76283, mean: 0.11073
[32m[0906 18-56-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01893, current rewards: 106.19293, mean: 0.11062
[32m[0906 18-56-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01893, current rewards: 109.67524, mean: 0.10859
[32m[0906 18-56-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01892, current rewards: 115.22403, mean: 0.10870
[32m[0906 18-56-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01890, current rewards: 120.77356, mean: 0.10881
[32m[0906 18-56-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01888, current rewards: 126.32224, mean: 0.10890
[32m[0906 18-56-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01887, current rewards: 127.56359, mean: 0.10542
[32m[0906 18-56-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01886, current rewards: 133.11488, mean: 0.10565
[32m[0906 18-56-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01884, current rewards: 138.67087, mean: 0.10586
[32m[0906 18-56-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01883, current rewards: 144.23312, mean: 0.10605
[32m[0906 18-56-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01882, current rewards: 149.78443, mean: 0.10623
[32m[0906 18-56-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01881, current rewards: 155.34043, mean: 0.10640
[32m[0906 18-56-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01880, current rewards: 160.89692, mean: 0.10655
[32m[0906 18-56-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01879, current rewards: 166.50679, mean: 0.10674
[32m[0906 18-56-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: 172.07233, mean: 0.10688
[32m[0906 18-56-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01879, current rewards: 175.52005, mean: 0.10573
[32m[0906 18-56-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: 181.08257, mean: 0.10590
[32m[0906 18-56-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: 186.64881, mean: 0.10605
[32m[0906 18-56-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 192.21187, mean: 0.10619
[32m[0906 18-56-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 197.77763, mean: 0.10633
[32m[0906 18-56-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: 203.34561, mean: 0.10646
[32m[0906 18-56-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01876, current rewards: 208.78525, mean: 0.10652
[32m[0906 18-56-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01874, current rewards: 214.36081, mean: 0.10665
[32m[0906 18-56-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01874, current rewards: 219.93664, mean: 0.10677
[32m[0906 18-56-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01875, current rewards: 225.50864, mean: 0.10688
[32m[0906 18-56-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01876, current rewards: 231.08507, mean: 0.10698
[32m[0906 18-56-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01877, current rewards: 237.06251, mean: 0.10727
[32m[0906 18-56-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01878, current rewards: 242.61196, mean: 0.10735
[32m[0906 18-56-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: 248.17453, mean: 0.10743
[32m[0906 18-56-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 253.78671, mean: 0.10754
[32m[0906 18-56-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01881, current rewards: 259.43846, mean: 0.10765
[32m[0906 18-56-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: 264.98795, mean: 0.10772
[32m[0906 18-56-32 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-56-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-56-33 @MBExp.py:227][0m Rewards obtained: [269.7630862034843], Lows: [3], Highs: [2], Total time: 5494.768500999997
[32m[0906 19-00-31 @MBExp.py:144][0m ####################################################################
[32m[0906 19-00-31 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 19-00-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01911, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-00-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01901, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-00-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01897, current rewards: -110.00000, mean: -1.00000
[32m[0906 19-00-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01901, current rewards: -160.00000, mean: -1.00000
[32m[0906 19-00-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01903, current rewards: -210.00000, mean: -1.00000
[32m[0906 19-00-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: -260.00000, mean: -1.00000
[32m[0906 19-00-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01906, current rewards: -310.00000, mean: -1.00000
[32m[0906 19-00-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: -360.00000, mean: -1.00000
[32m[0906 19-00-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01907, current rewards: -454.00000, mean: -1.10732
[32m[0906 19-00-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: -554.00000, mean: -1.20435
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: -654.00000, mean: -1.28235
[32m[0906 19-00-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: -754.00000, mean: -1.34643
[32m[0906 19-00-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: -854.00000, mean: -1.40000
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01906, current rewards: -954.00000, mean: -1.44545
[32m[0906 19-00-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: -1054.00000, mean: -1.48451
[32m[0906 19-00-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: -1154.00000, mean: -1.51842
[32m[0906 19-00-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01901, current rewards: -1254.00000, mean: -1.54815
[32m[0906 19-00-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01900, current rewards: -1354.00000, mean: -1.57442
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01896, current rewards: -1454.00000, mean: -1.59780
[32m[0906 19-00-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01894, current rewards: -1554.00000, mean: -1.61875
[32m[0906 19-00-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01890, current rewards: -1654.00000, mean: -1.63762
[32m[0906 19-00-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01888, current rewards: -1754.00000, mean: -1.65472
[32m[0906 19-00-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01886, current rewards: -1854.00000, mean: -1.67027
[32m[0906 19-00-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01884, current rewards: -1954.00000, mean: -1.68448
[32m[0906 19-00-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01883, current rewards: -2054.00000, mean: -1.69752
[32m[0906 19-00-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01882, current rewards: -2154.00000, mean: -1.70952
[32m[0906 19-00-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01880, current rewards: -2254.00000, mean: -1.72061
[32m[0906 19-00-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01879, current rewards: -2354.00000, mean: -1.73088
[32m[0906 19-00-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01878, current rewards: -2454.00000, mean: -1.74043
[32m[0906 19-00-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01878, current rewards: -2554.00000, mean: -1.74932
[32m[0906 19-00-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01877, current rewards: -2654.00000, mean: -1.75762
[32m[0906 19-01-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01876, current rewards: -2754.00000, mean: -1.76538
[32m[0906 19-01-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: -2854.00000, mean: -1.77267
[32m[0906 19-01-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01875, current rewards: -2954.00000, mean: -1.77952
[32m[0906 19-01-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: -3054.00000, mean: -1.78596
[32m[0906 19-01-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01873, current rewards: -3154.00000, mean: -1.79205
[32m[0906 19-01-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01873, current rewards: -3254.00000, mean: -1.79779
[32m[0906 19-01-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01873, current rewards: -3354.00000, mean: -1.80323
[32m[0906 19-01-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01873, current rewards: -3454.00000, mean: -1.80838
[32m[0906 19-01-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01872, current rewards: -3554.00000, mean: -1.81327
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01872, current rewards: -3654.00000, mean: -1.81791
[32m[0906 19-01-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01872, current rewards: -3754.00000, mean: -1.82233
[32m[0906 19-01-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01871, current rewards: -3854.00000, mean: -1.82654
[32m[0906 19-01-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01871, current rewards: -3954.00000, mean: -1.83056
[32m[0906 19-01-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01871, current rewards: -4054.00000, mean: -1.83439
[32m[0906 19-01-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01870, current rewards: -4154.00000, mean: -1.83805
[32m[0906 19-01-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01869, current rewards: -4254.00000, mean: -1.84156
[32m[0906 19-01-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01869, current rewards: -4354.00000, mean: -1.84492
[32m[0906 19-01-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01869, current rewards: -4454.00000, mean: -1.84813
[32m[0906 19-01-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01869, current rewards: -4554.00000, mean: -1.85122
[32m[0906 19-01-18 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-01-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-01-18 @MBExp.py:227][0m Rewards obtained: [-4634], Lows: [2134], Highs: [366], Total time: 5542.327860999997
[32m[0906 19-05-18 @MBExp.py:144][0m ####################################################################
[32m[0906 19-05-18 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 19-05-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: 1.15254, mean: 0.11525
[32m[0906 19-05-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01929, current rewards: 7.29706, mean: 0.12162
[32m[0906 19-05-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 13.47476, mean: 0.12250
[32m[0906 19-05-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01915, current rewards: 19.65246, mean: 0.12283
[32m[0906 19-05-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 25.83016, mean: 0.12300
[32m[0906 19-05-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 32.00785, mean: 0.12311
[32m[0906 19-05-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01946, current rewards: 17.59147, mean: 0.05675
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01992, current rewards: 10.36157, mean: 0.02878
[32m[0906 19-05-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02041, current rewards: -1.93332, mean: -0.00472
[32m[0906 19-05-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02063, current rewards: -7.42935, mean: -0.01615
[32m[0906 19-05-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02096, current rewards: -14.64916, mean: -0.02872
[32m[0906 19-05-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02119, current rewards: -21.85648, mean: -0.03903
[32m[0906 19-05-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02140, current rewards: -25.46518, mean: -0.04175
[32m[0906 19-05-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02153, current rewards: -32.27282, mean: -0.04890
[32m[0906 19-05-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02165, current rewards: -37.62476, mean: -0.05299
[32m[0906 19-05-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02178, current rewards: -50.39459, mean: -0.06631
[32m[0906 19-05-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02186, current rewards: -71.25298, mean: -0.08797
[32m[0906 19-05-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02196, current rewards: -67.56504, mean: -0.07856
[32m[0906 19-05-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02204, current rewards: -61.89533, mean: -0.06802
[32m[0906 19-05-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02214, current rewards: -56.19898, mean: -0.05854
[32m[0906 19-05-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02222, current rewards: -50.50272, mean: -0.05000
[32m[0906 19-05-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02230, current rewards: -44.88549, mean: -0.04234
[32m[0906 19-05-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02237, current rewards: -39.25150, mean: -0.03536
[32m[0906 19-05-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02243, current rewards: -43.91093, mean: -0.03785
[32m[0906 19-05-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02252, current rewards: -38.01078, mean: -0.03141
[32m[0906 19-05-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02262, current rewards: -32.33501, mean: -0.02566
[32m[0906 19-05-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02268, current rewards: -28.61606, mean: -0.02184
[32m[0906 19-05-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02274, current rewards: -22.69786, mean: -0.01669
[32m[0906 19-05-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02276, current rewards: -17.13712, mean: -0.01215
[32m[0906 19-05-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02261, current rewards: -11.87974, mean: -0.00814
[32m[0906 19-05-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02248, current rewards: -6.62885, mean: -0.00439
[32m[0906 19-05-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02234, current rewards: -1.33580, mean: -0.00086
[32m[0906 19-05-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02223, current rewards: 3.96058, mean: 0.00246
[32m[0906 19-05-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02212, current rewards: 7.23658, mean: 0.00436
[32m[0906 19-05-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02202, current rewards: 12.75760, mean: 0.00746
[32m[0906 19-05-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02192, current rewards: 18.27954, mean: 0.01039
[32m[0906 19-05-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02183, current rewards: 23.79852, mean: 0.01315
[32m[0906 19-05-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02173, current rewards: 29.31668, mean: 0.01576
[32m[0906 19-06-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02165, current rewards: 34.83270, mean: 0.01824
[32m[0906 19-06-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02157, current rewards: 40.35766, mean: 0.02059
[32m[0906 19-06-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02149, current rewards: 45.80325, mean: 0.02279
[32m[0906 19-06-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02143, current rewards: 49.21595, mean: 0.02389
[32m[0906 19-06-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02136, current rewards: 54.76391, mean: 0.02595
[32m[0906 19-06-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02129, current rewards: 60.30812, mean: 0.02792
[32m[0906 19-06-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02122, current rewards: 65.85463, mean: 0.02980
[32m[0906 19-06-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02117, current rewards: 71.39145, mean: 0.03159
[32m[0906 19-06-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02111, current rewards: 76.92923, mean: 0.03330
[32m[0906 19-06-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02105, current rewards: 82.47370, mean: 0.03495
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02100, current rewards: 88.04727, mean: 0.03653
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02096, current rewards: 93.58260, mean: 0.03804
[32m[0906 19-06-11 @Agent.py:117][0m Average action selection time: 0.0209
[32m[0906 19-06-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-06-11 @MBExp.py:227][0m Rewards obtained: [98.01153195996956], Lows: [91], Highs: [7], Total time: 5595.511844999997
[32m[0906 19-10-15 @MBExp.py:144][0m ####################################################################
[32m[0906 19-10-15 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 19-10-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01862, current rewards: 0.04422, mean: 0.00442
[32m[0906 19-10-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01902, current rewards: 5.66320, mean: 0.09439
[32m[0906 19-10-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 11.20571, mean: 0.10187
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 16.75092, mean: 0.10469
[32m[0906 19-10-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 22.29845, mean: 0.10618
[32m[0906 19-10-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 27.84525, mean: 0.10710
[32m[0906 19-10-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 33.39096, mean: 0.10771
[32m[0906 19-10-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 35.66207, mean: 0.09906
[32m[0906 19-10-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 41.19747, mean: 0.10048
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 46.72664, mean: 0.10158
[32m[0906 19-10-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 52.25058, mean: 0.10245
[32m[0906 19-10-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 57.78624, mean: 0.10319
[32m[0906 19-10-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 63.31846, mean: 0.10380
[32m[0906 19-10-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 68.85075, mean: 0.10432
[32m[0906 19-10-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 74.37983, mean: 0.10476
[32m[0906 19-10-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01901, current rewards: 79.89624, mean: 0.10513
[32m[0906 19-10-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01896, current rewards: 85.43035, mean: 0.10547
[32m[0906 19-10-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01894, current rewards: 88.82906, mean: 0.10329
[32m[0906 19-10-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01892, current rewards: 94.35091, mean: 0.10368
[32m[0906 19-10-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01890, current rewards: 99.87118, mean: 0.10403
[32m[0906 19-10-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01888, current rewards: 105.39913, mean: 0.10436
[32m[0906 19-10-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01887, current rewards: 110.92593, mean: 0.10465
[32m[0906 19-10-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01885, current rewards: 116.45128, mean: 0.10491
[32m[0906 19-10-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01883, current rewards: 122.10668, mean: 0.10526
[32m[0906 19-10-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01883, current rewards: 127.62776, mean: 0.10548
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01882, current rewards: 133.14855, mean: 0.10567
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01881, current rewards: 138.66607, mean: 0.10585
[32m[0906 19-10-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01882, current rewards: 142.16844, mean: 0.10454
[32m[0906 19-10-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01881, current rewards: 147.72693, mean: 0.10477
[32m[0906 19-10-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01880, current rewards: 153.28770, mean: 0.10499
[32m[0906 19-10-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01878, current rewards: 157.88140, mean: 0.10456
[32m[0906 19-10-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01878, current rewards: 163.34459, mean: 0.10471
[32m[0906 19-10-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01877, current rewards: 168.87612, mean: 0.10489
[32m[0906 19-10-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01877, current rewards: 174.40311, mean: 0.10506
[32m[0906 19-10-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: 179.94388, mean: 0.10523
[32m[0906 19-10-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: 185.47994, mean: 0.10539
[32m[0906 19-10-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01875, current rewards: 191.01444, mean: 0.10553
[32m[0906 19-10-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01874, current rewards: 196.54883, mean: 0.10567
[32m[0906 19-10-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01873, current rewards: 202.08574, mean: 0.10580
[32m[0906 19-10-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01894, current rewards: 199.53299, mean: 0.10180
[32m[0906 19-10-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 176.78067, mean: 0.08795
[32m[0906 19-10-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01923, current rewards: 143.38167, mean: 0.06960
[32m[0906 19-10-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01936, current rewards: 119.85230, mean: 0.05680
[32m[0906 19-10-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01948, current rewards: 86.28244, mean: 0.03995
[32m[0906 19-10-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01959, current rewards: 61.38453, mean: 0.02778
[32m[0906 19-11-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01970, current rewards: 30.48492, mean: 0.01349
[32m[0906 19-11-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01980, current rewards: -2.04667, mean: -0.00089
[32m[0906 19-11-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01991, current rewards: -32.25511, mean: -0.01367
[32m[0906 19-11-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02007, current rewards: -36.70513, mean: -0.01523
[32m[0906 19-11-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02015, current rewards: -30.98141, mean: -0.01259
[32m[0906 19-11-06 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 19-11-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-11-07 @MBExp.py:227][0m Rewards obtained: [-26.54671393348454], Lows: [151], Highs: [3], Total time: 5646.711231999997
[32m[0906 19-15-11 @MBExp.py:144][0m ####################################################################
[32m[0906 19-15-11 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 19-15-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01868, current rewards: -0.11452, mean: -0.01145
[32m[0906 19-15-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 5.39952, mean: 0.08999
[32m[0906 19-15-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 10.91726, mean: 0.09925
[32m[0906 19-15-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 16.43296, mean: 0.10271
[32m[0906 19-15-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 21.95140, mean: 0.10453
[32m[0906 19-15-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 27.47246, mean: 0.10566
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 32.95900, mean: 0.10632
[32m[0906 19-15-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 38.47286, mean: 0.10687
[32m[0906 19-15-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01914, current rewards: 43.98348, mean: 0.10728
[32m[0906 19-15-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01901, current rewards: 49.49984, mean: 0.10761
[32m[0906 19-15-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01896, current rewards: 55.01030, mean: 0.10786
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01891, current rewards: 60.58659, mean: 0.10819
[32m[0906 19-15-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01889, current rewards: 66.16245, mean: 0.10846
[32m[0906 19-15-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01886, current rewards: 71.74003, mean: 0.10870
[32m[0906 19-15-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01884, current rewards: 77.35488, mean: 0.10895
[32m[0906 19-15-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01881, current rewards: 82.96672, mean: 0.10917
[32m[0906 19-15-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01878, current rewards: 88.53488, mean: 0.10930
[32m[0906 19-15-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01876, current rewards: 94.09814, mean: 0.10942
[32m[0906 19-15-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01876, current rewards: 96.47486, mean: 0.10602
[32m[0906 19-15-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01874, current rewards: 102.00947, mean: 0.10626
[32m[0906 19-15-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01872, current rewards: 107.54753, mean: 0.10648
[32m[0906 19-15-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01871, current rewards: 113.08535, mean: 0.10668
[32m[0906 19-15-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01871, current rewards: 118.62615, mean: 0.10687
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01869, current rewards: 124.05559, mean: 0.10694
[32m[0906 19-15-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01868, current rewards: 129.43887, mean: 0.10697
[32m[0906 19-15-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01867, current rewards: 134.78894, mean: 0.10698
[32m[0906 19-15-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01866, current rewards: 140.13877, mean: 0.10698
[32m[0906 19-15-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: 145.48788, mean: 0.10698
[32m[0906 19-15-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01865, current rewards: 150.83183, mean: 0.10697
[32m[0906 19-15-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01865, current rewards: 156.18692, mean: 0.10698
[32m[0906 19-15-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01865, current rewards: 161.53478, mean: 0.10698
[32m[0906 19-15-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01864, current rewards: 166.97324, mean: 0.10703
[32m[0906 19-15-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01864, current rewards: 172.31226, mean: 0.10703
[32m[0906 19-15-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01864, current rewards: 177.62865, mean: 0.10701
[32m[0906 19-15-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01863, current rewards: 182.94013, mean: 0.10698
[32m[0906 19-15-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: 186.26092, mean: 0.10583
[32m[0906 19-15-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01862, current rewards: 191.70024, mean: 0.10591
[32m[0906 19-15-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01862, current rewards: 197.14287, mean: 0.10599
[32m[0906 19-15-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: 202.58606, mean: 0.10607
[32m[0906 19-15-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01862, current rewards: 208.02824, mean: 0.10614
[32m[0906 19-15-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 213.40595, mean: 0.10617
[32m[0906 19-15-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: 218.82199, mean: 0.10622
[32m[0906 19-15-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 224.23386, mean: 0.10627
[32m[0906 19-15-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 229.65079, mean: 0.10632
[32m[0906 19-15-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01861, current rewards: 235.06819, mean: 0.10637
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01861, current rewards: 240.60575, mean: 0.10646
[32m[0906 19-15-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01862, current rewards: 246.14562, mean: 0.10656
[32m[0906 19-15-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01864, current rewards: 251.68549, mean: 0.10665
[32m[0906 19-15-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01865, current rewards: 258.10961, mean: 0.10710
[32m[0906 19-15-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01866, current rewards: 265.38382, mean: 0.10788
[32m[0906 19-15-58 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-15-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-15-59 @MBExp.py:227][0m Rewards obtained: [271.20319559660976], Lows: [2], Highs: [2], Total time: 5694.224046999997
[32m[0906 19-20-04 @MBExp.py:144][0m ####################################################################
[32m[0906 19-20-04 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 19-20-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 0.94630, mean: 0.09463
[32m[0906 19-20-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 5.99139, mean: 0.09986
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01910, current rewards: 11.03099, mean: 0.10028
[32m[0906 19-20-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 16.07253, mean: 0.10045
[32m[0906 19-20-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 21.11570, mean: 0.10055
[32m[0906 19-20-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 26.15799, mean: 0.10061
[32m[0906 19-20-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 31.26728, mean: 0.10086
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 36.24393, mean: 0.10068
[32m[0906 19-20-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 41.22134, mean: 0.10054
[32m[0906 19-20-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01907, current rewards: 46.19854, mean: 0.10043
[32m[0906 19-20-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01903, current rewards: 50.16281, mean: 0.09836
[32m[0906 19-20-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01897, current rewards: 55.58030, mean: 0.09925
[32m[0906 19-20-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01893, current rewards: 60.98237, mean: 0.09997
[32m[0906 19-20-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01891, current rewards: 66.38464, mean: 0.10058
[32m[0906 19-20-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01888, current rewards: 71.75893, mean: 0.10107
[32m[0906 19-20-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01886, current rewards: 77.05030, mean: 0.10138
[32m[0906 19-20-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01884, current rewards: 82.44361, mean: 0.10178
[32m[0906 19-20-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01883, current rewards: 88.00303, mean: 0.10233
[32m[0906 19-20-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01881, current rewards: 93.56471, mean: 0.10282
[32m[0906 19-20-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01879, current rewards: 99.12769, mean: 0.10326
[32m[0906 19-20-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01878, current rewards: 104.68650, mean: 0.10365
[32m[0906 19-20-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01877, current rewards: 110.24446, mean: 0.10400
[32m[0906 19-20-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01876, current rewards: 115.80224, mean: 0.10433
[32m[0906 19-20-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01876, current rewards: 121.38705, mean: 0.10464
[32m[0906 19-20-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01873, current rewards: 126.94163, mean: 0.10491
[32m[0906 19-20-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01872, current rewards: 132.49550, mean: 0.10516
[32m[0906 19-20-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01872, current rewards: 138.04715, mean: 0.10538
[32m[0906 19-20-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01872, current rewards: 143.59522, mean: 0.10558
[32m[0906 19-20-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 149.14695, mean: 0.10578
[32m[0906 19-20-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01872, current rewards: 154.69548, mean: 0.10596
[32m[0906 19-20-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01872, current rewards: 160.24881, mean: 0.10613
[32m[0906 19-20-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01871, current rewards: 165.88506, mean: 0.10634
[32m[0906 19-20-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01871, current rewards: 171.39347, mean: 0.10646
[32m[0906 19-20-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01870, current rewards: 176.74956, mean: 0.10648
[32m[0906 19-20-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01870, current rewards: 182.16344, mean: 0.10653
[32m[0906 19-20-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01869, current rewards: 187.58193, mean: 0.10658
[32m[0906 19-20-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01868, current rewards: 193.00024, mean: 0.10663
[32m[0906 19-20-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01868, current rewards: 198.41256, mean: 0.10667
[32m[0906 19-20-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01868, current rewards: 203.82885, mean: 0.10672
[32m[0906 19-20-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01867, current rewards: 209.23949, mean: 0.10675
[32m[0906 19-20-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01867, current rewards: 214.66104, mean: 0.10680
[32m[0906 19-20-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01867, current rewards: 220.07688, mean: 0.10683
[32m[0906 19-20-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01866, current rewards: 225.61548, mean: 0.10693
[32m[0906 19-20-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01866, current rewards: 231.11997, mean: 0.10700
[32m[0906 19-20-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: 236.63052, mean: 0.10707
[32m[0906 19-20-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01865, current rewards: 242.13669, mean: 0.10714
[32m[0906 19-20-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: 245.49515, mean: 0.10627
[32m[0906 19-20-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01867, current rewards: 250.53824, mean: 0.10616
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01868, current rewards: 255.57867, mean: 0.10605
[32m[0906 19-20-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01869, current rewards: 260.61984, mean: 0.10594
[32m[0906 19-20-52 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-20-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-20-52 @MBExp.py:227][0m Rewards obtained: [264.65224178780977], Lows: [1], Highs: [1], Total time: 5741.840491999997
[32m[0906 19-25-01 @MBExp.py:144][0m ####################################################################
[32m[0906 19-25-01 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 19-25-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01841, current rewards: 0.20517, mean: 0.02052
[32m[0906 19-25-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01888, current rewards: 5.78766, mean: 0.09646
[32m[0906 19-25-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01897, current rewards: 11.33024, mean: 0.10300
[32m[0906 19-25-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01898, current rewards: 16.87704, mean: 0.10548
[32m[0906 19-25-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 22.41773, mean: 0.10675
[32m[0906 19-25-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 27.95420, mean: 0.10752
[32m[0906 19-25-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 33.48425, mean: 0.10801
[32m[0906 19-25-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.01973, mean: 0.10839
[32m[0906 19-25-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 44.56466, mean: 0.10869
[32m[0906 19-25-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 50.10994, mean: 0.10893
[32m[0906 19-25-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01904, current rewards: 55.93632, mean: 0.10968
[32m[0906 19-25-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01901, current rewards: 61.48626, mean: 0.10980
[32m[0906 19-25-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01898, current rewards: 67.03337, mean: 0.10989
[32m[0906 19-25-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01894, current rewards: 72.58473, mean: 0.10998
[32m[0906 19-25-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01893, current rewards: 78.10463, mean: 0.11001
[32m[0906 19-25-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01889, current rewards: 83.64863, mean: 0.11006
[32m[0906 19-25-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01887, current rewards: 89.19322, mean: 0.11012
[32m[0906 19-25-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01884, current rewards: 94.73772, mean: 0.11016
[32m[0906 19-25-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01883, current rewards: 100.28570, mean: 0.11020
[32m[0906 19-25-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01881, current rewards: 105.84038, mean: 0.11025
[32m[0906 19-25-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01880, current rewards: 111.38555, mean: 0.11028
[32m[0906 19-25-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01879, current rewards: 116.72783, mean: 0.11012
[32m[0906 19-25-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01878, current rewards: 122.07704, mean: 0.10998
[32m[0906 19-25-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01876, current rewards: 127.40032, mean: 0.10983
[32m[0906 19-25-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01873, current rewards: 132.72384, mean: 0.10969
[32m[0906 19-25-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01873, current rewards: 138.03980, mean: 0.10956
[32m[0906 19-25-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01873, current rewards: 143.35298, mean: 0.10943
[32m[0906 19-25-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01872, current rewards: 148.66737, mean: 0.10931
[32m[0906 19-25-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 153.98885, mean: 0.10921
[32m[0906 19-25-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: 159.31010, mean: 0.10912
[32m[0906 19-25-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: 164.60290, mean: 0.10901
[32m[0906 19-25-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: 169.94744, mean: 0.10894
[32m[0906 19-25-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01870, current rewards: 175.28751, mean: 0.10887
[32m[0906 19-25-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01869, current rewards: 178.52160, mean: 0.10754
[32m[0906 19-25-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01868, current rewards: 184.15240, mean: 0.10769
[32m[0906 19-25-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01868, current rewards: 189.77464, mean: 0.10783
[32m[0906 19-25-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01868, current rewards: 195.39676, mean: 0.10795
[32m[0906 19-25-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01868, current rewards: 201.02006, mean: 0.10808
[32m[0906 19-25-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01868, current rewards: 206.70421, mean: 0.10822
[32m[0906 19-25-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01868, current rewards: 212.42027, mean: 0.10838
[32m[0906 19-25-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01868, current rewards: 218.04916, mean: 0.10848
[32m[0906 19-25-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01868, current rewards: 223.67824, mean: 0.10858
[32m[0906 19-25-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01868, current rewards: 229.30845, mean: 0.10868
[32m[0906 19-25-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01867, current rewards: 234.94582, mean: 0.10877
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01867, current rewards: 240.51203, mean: 0.10883
[32m[0906 19-25-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01867, current rewards: 246.07736, mean: 0.10888
[32m[0906 19-25-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01867, current rewards: 251.64189, mean: 0.10894
[32m[0906 19-25-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: 257.16047, mean: 0.10897
[32m[0906 19-25-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01866, current rewards: 262.71697, mean: 0.10901
[32m[0906 19-25-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01866, current rewards: 268.27836, mean: 0.10906
[32m[0906 19-25-48 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-25-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-25-49 @MBExp.py:227][0m Rewards obtained: [272.72527701997217], Lows: [1], Highs: [1], Total time: 5789.321945999996
[32m[0906 19-30-01 @MBExp.py:144][0m ####################################################################
[32m[0906 19-30-01 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 19-30-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01902, current rewards: -2.12489, mean: -0.21249
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 3.32931, mean: 0.05549
[32m[0906 19-30-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 8.83724, mean: 0.08034
[32m[0906 19-30-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 14.34613, mean: 0.08966
[32m[0906 19-30-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01924, current rewards: 19.85083, mean: 0.09453
[32m[0906 19-30-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 25.35188, mean: 0.09751
[32m[0906 19-30-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 30.85287, mean: 0.09953
[32m[0906 19-30-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 36.35409, mean: 0.10098
[32m[0906 19-30-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 41.85599, mean: 0.10209
[32m[0906 19-30-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 47.36286, mean: 0.10296
[32m[0906 19-30-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 50.75854, mean: 0.09953
[32m[0906 19-30-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 56.28570, mean: 0.10051
[32m[0906 19-30-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01902, current rewards: 61.81577, mean: 0.10134
[32m[0906 19-30-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01900, current rewards: 67.34648, mean: 0.10204
[32m[0906 19-30-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01894, current rewards: 73.02204, mean: 0.10285
[32m[0906 19-30-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01891, current rewards: 76.94611, mean: 0.10124
[32m[0906 19-30-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01887, current rewards: 84.22033, mean: 0.10398
[32m[0906 19-30-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01885, current rewards: 91.49455, mean: 0.10639
[32m[0906 19-30-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01883, current rewards: 98.76877, mean: 0.10854
[32m[0906 19-30-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01881, current rewards: 106.04299, mean: 0.11046
[32m[0906 19-30-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01879, current rewards: 81.24364, mean: 0.08044
[32m[0906 19-30-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01877, current rewards: 31.24364, mean: 0.02948
[32m[0906 19-30-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01876, current rewards: -18.75636, mean: -0.01690
[32m[0906 19-30-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01874, current rewards: -68.75636, mean: -0.05927
[32m[0906 19-30-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01872, current rewards: -118.75636, mean: -0.09815
[32m[0906 19-30-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01871, current rewards: -168.75636, mean: -0.13393
[32m[0906 19-30-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01870, current rewards: -218.75636, mean: -0.16699
[32m[0906 19-30-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: -268.75636, mean: -0.19761
[32m[0906 19-30-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01870, current rewards: -318.75636, mean: -0.22607
[32m[0906 19-30-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: -368.75636, mean: -0.25257
[32m[0906 19-30-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: -418.75636, mean: -0.27732
[32m[0906 19-30-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01869, current rewards: -468.75636, mean: -0.30048
[32m[0906 19-30-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01869, current rewards: -518.75636, mean: -0.32221
[32m[0906 19-30-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01869, current rewards: -568.75636, mean: -0.34262
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01868, current rewards: -618.75636, mean: -0.36185
[32m[0906 19-30-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01868, current rewards: -668.75636, mean: -0.37998
[32m[0906 19-30-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01868, current rewards: -718.75636, mean: -0.39710
[32m[0906 19-30-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01867, current rewards: -768.75636, mean: -0.41331
[32m[0906 19-30-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01867, current rewards: -818.75636, mean: -0.42867
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01867, current rewards: -868.75636, mean: -0.44324
[32m[0906 19-30-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01867, current rewards: -918.75636, mean: -0.45709
[32m[0906 19-30-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01867, current rewards: -968.75636, mean: -0.47027
[32m[0906 19-30-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01867, current rewards: -1018.75636, mean: -0.48282
[32m[0906 19-30-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01866, current rewards: -1068.75636, mean: -0.49479
[32m[0906 19-30-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: -1118.75636, mean: -0.50622
[32m[0906 19-30-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01866, current rewards: -1168.75636, mean: -0.51715
[32m[0906 19-30-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: -1218.75636, mean: -0.52760
[32m[0906 19-30-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: -1268.75636, mean: -0.53761
[32m[0906 19-30-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01866, current rewards: -1318.75636, mean: -0.54720
[32m[0906 19-30-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01866, current rewards: -1368.75636, mean: -0.55641
[32m[0906 19-30-48 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-30-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-30-48 @MBExp.py:227][0m Rewards obtained: [-1408.75635686559], Lows: [3], Highs: [1519], Total time: 5836.833490999997
[32m[0906 19-34-59 @MBExp.py:144][0m ####################################################################
[32m[0906 19-34-59 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 19-34-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01769, current rewards: 1.07995, mean: 0.10800
[32m[0906 19-35-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01716, current rewards: 6.62809, mean: 0.11047
[32m[0906 19-35-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01720, current rewards: 12.17782, mean: 0.11071
[32m[0906 19-35-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01720, current rewards: 17.72453, mean: 0.11078
[32m[0906 19-35-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01721, current rewards: 21.23509, mean: 0.10112
[32m[0906 19-35-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01717, current rewards: 26.77558, mean: 0.10298
[32m[0906 19-35-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01717, current rewards: 32.33402, mean: 0.10430
[32m[0906 19-35-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01718, current rewards: 37.87673, mean: 0.10521
[32m[0906 19-35-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01716, current rewards: 43.41101, mean: 0.10588
[32m[0906 19-35-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01699, current rewards: 48.84002, mean: 0.10617
[32m[0906 19-35-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01679, current rewards: 54.29723, mean: 0.10647
[32m[0906 19-35-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01661, current rewards: 59.74554, mean: 0.10669
[32m[0906 19-35-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01646, current rewards: 65.19818, mean: 0.10688
[32m[0906 19-35-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01634, current rewards: 70.65254, mean: 0.10705
[32m[0906 19-35-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01623, current rewards: 76.03610, mean: 0.10709
[32m[0906 19-35-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01613, current rewards: 81.49925, mean: 0.10724
[32m[0906 19-35-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01605, current rewards: 86.96435, mean: 0.10736
[32m[0906 19-35-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01597, current rewards: 92.42670, mean: 0.10747
[32m[0906 19-35-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01589, current rewards: 97.89599, mean: 0.10758
[32m[0906 19-35-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01584, current rewards: 103.73038, mean: 0.10805
[32m[0906 19-35-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01579, current rewards: 109.29115, mean: 0.10821
[32m[0906 19-35-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01574, current rewards: 114.85448, mean: 0.10835
[32m[0906 19-35-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01570, current rewards: 120.41131, mean: 0.10848
[32m[0906 19-35-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01564, current rewards: 125.97226, mean: 0.10860
[32m[0906 19-35-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01560, current rewards: 131.53018, mean: 0.10870
[32m[0906 19-35-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01557, current rewards: 137.09189, mean: 0.10880
[32m[0906 19-35-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01554, current rewards: 142.65154, mean: 0.10889
[32m[0906 19-35-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01552, current rewards: 148.20990, mean: 0.10898
[32m[0906 19-35-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01549, current rewards: 153.76918, mean: 0.10906
[32m[0906 19-35-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01547, current rewards: 159.32880, mean: 0.10913
[32m[0906 19-35-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01545, current rewards: 164.93617, mean: 0.10923
[32m[0906 19-35-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01542, current rewards: 170.44108, mean: 0.10926
[32m[0906 19-35-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01540, current rewards: 175.94642, mean: 0.10928
[32m[0906 19-35-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01538, current rewards: 181.45208, mean: 0.10931
[32m[0906 19-35-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01536, current rewards: 184.75694, mean: 0.10804
[32m[0906 19-35-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01535, current rewards: 190.30309, mean: 0.10813
[32m[0906 19-35-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01533, current rewards: 195.85454, mean: 0.10821
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01532, current rewards: 201.40776, mean: 0.10828
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01530, current rewards: 207.00273, mean: 0.10838
[32m[0906 19-35-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01529, current rewards: 212.59854, mean: 0.10847
[32m[0906 19-35-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01528, current rewards: 218.14616, mean: 0.10853
[32m[0906 19-35-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01527, current rewards: 221.67550, mean: 0.10761
[32m[0906 19-35-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01525, current rewards: 227.22372, mean: 0.10769
[32m[0906 19-35-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01525, current rewards: 232.76901, mean: 0.10776
[32m[0906 19-35-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01523, current rewards: 238.31838, mean: 0.10784
[32m[0906 19-35-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01522, current rewards: 243.86792, mean: 0.10791
[32m[0906 19-35-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01522, current rewards: 249.41842, mean: 0.10797
[32m[0906 19-35-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01521, current rewards: 254.93357, mean: 0.10802
[32m[0906 19-35-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01520, current rewards: 260.48795, mean: 0.10809
[32m[0906 19-35-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01519, current rewards: 266.02846, mean: 0.10814
[32m[0906 19-35-37 @Agent.py:117][0m Average action selection time: 0.0152
[32m[0906 19-35-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-35-37 @MBExp.py:227][0m Rewards obtained: [270.45959318730183], Lows: [2], Highs: [2], Total time: 5875.545070999997
