[32m[0906 13-41-26 @logger.py:99][0m Log file set to /app/logs/dats-delay-0/zinc-coating-v0_4/Tuesday_06_September_2022_01-41PM.log
[32m[0906 13-41-26 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00003, current rewards: -15.77801, mean: -1.57780
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -92.69435, mean: -1.54491
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -165.33458, mean: -1.50304
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -245.88265, mean: -1.53677
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -312.56474, mean: -1.48840
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -382.78007, mean: -1.47223
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -441.86705, mean: -1.42538
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -504.72495, mean: -1.40201
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -573.65286, mean: -1.39915
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -649.77680, mean: -1.41256
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -718.85060, mean: -1.40951
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -796.52817, mean: -1.42237
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -871.15205, mean: -1.42812
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -928.15172, mean: -1.40629
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -976.69607, mean: -1.37563
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -1037.67929, mean: -1.36537
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -1096.54726, mean: -1.35376
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1157.18064, mean: -1.34556
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1210.28647, mean: -1.32999
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1259.42646, mean: -1.31190
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1308.71916, mean: -1.29576
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1363.22434, mean: -1.28606
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1408.90471, mean: -1.26928
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1478.25949, mean: -1.27436
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1536.27389, mean: -1.26965
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1613.84988, mean: -1.28083
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1664.22457, mean: -1.27040
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1723.90720, mean: -1.26758
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1790.24105, mean: -1.26967
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1861.12658, mean: -1.27474
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1922.82255, mean: -1.27339
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1977.93581, mean: -1.26791
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -2032.53222, mean: -1.26244
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -2095.99022, mean: -1.26264
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2147.83866, mean: -1.25605
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2212.80320, mean: -1.25727
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2267.75098, mean: -1.25290
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2319.98152, mean: -1.24730
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2378.72908, mean: -1.24541
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2435.27781, mean: -1.24249
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2482.85184, mean: -1.23525
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2527.93002, mean: -1.22715
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2581.39025, mean: -1.22341
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2632.54311, mean: -1.21877
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2694.81579, mean: -1.21937
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2750.54058, mean: -1.21705
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2823.26096, mean: -1.22219
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2879.65990, mean: -1.22019
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2939.82220, mean: -1.21984
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -3001.91315, mean: -1.22029
[32m[0906 13-41-26 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-41-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-41-29 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-29 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03781, current rewards: -2.25405, mean: -0.22540
[32m[0906 13-41-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02317, current rewards: 4.28459, mean: 0.07141
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02172, current rewards: 10.84802, mean: 0.09862
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02121, current rewards: 17.41696, mean: 0.10886
[32m[0906 13-41-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02088, current rewards: 23.99080, mean: 0.11424
[32m[0906 13-41-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02070, current rewards: 29.05942, mean: 0.11177
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02057, current rewards: 34.84336, mean: 0.11240
[32m[0906 13-41-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02052, current rewards: 40.62711, mean: 0.11285
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02051, current rewards: 46.48428, mean: 0.11338
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02047, current rewards: 53.78922, mean: 0.11693
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02047, current rewards: 60.55091, mean: 0.11873
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02045, current rewards: 70.39274, mean: 0.12570
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02047, current rewards: 80.23508, mean: 0.13153
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02048, current rewards: 90.07790, mean: 0.13648
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02049, current rewards: 99.91801, mean: 0.14073
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02049, current rewards: 109.75822, mean: 0.14442
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02048, current rewards: 119.60028, mean: 0.14765
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02050, current rewards: 129.44268, mean: 0.15051
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02050, current rewards: 139.28470, mean: 0.15306
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02050, current rewards: 146.93528, mean: 0.15306
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02049, current rewards: 157.99648, mean: 0.15643
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02049, current rewards: 169.09042, mean: 0.15952
[32m[0906 13-41-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02049, current rewards: 180.18949, mean: 0.16233
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02048, current rewards: 191.29130, mean: 0.16491
[32m[0906 13-41-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02047, current rewards: 202.37702, mean: 0.16725
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02047, current rewards: 209.46822, mean: 0.16624
[32m[0906 13-41-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02046, current rewards: 214.61729, mean: 0.16383
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02044, current rewards: 219.76378, mean: 0.16159
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02043, current rewards: 224.90700, mean: 0.15951
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02043, current rewards: 226.83388, mean: 0.15537
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02043, current rewards: 230.72502, mean: 0.15280
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02043, current rewards: 234.61796, mean: 0.15040
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02043, current rewards: 238.50932, mean: 0.14814
[32m[0906 13-42-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02043, current rewards: 242.40349, mean: 0.14603
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02044, current rewards: 246.29624, mean: 0.14403
[32m[0906 13-42-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02044, current rewards: 250.18716, mean: 0.14215
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02045, current rewards: 254.07909, mean: 0.14038
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02045, current rewards: 257.97020, mean: 0.13869
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02045, current rewards: 261.85897, mean: 0.13710
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02045, current rewards: 265.75112, mean: 0.13559
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02045, current rewards: 268.56454, mean: 0.13361
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02046, current rewards: 272.69325, mean: 0.13238
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02046, current rewards: 279.44781, mean: 0.13244
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02047, current rewards: 286.67640, mean: 0.13272
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02047, current rewards: 293.93080, mean: 0.13300
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02047, current rewards: 301.17245, mean: 0.13326
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02048, current rewards: 308.40935, mean: 0.13351
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02048, current rewards: 315.65721, mean: 0.13375
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02049, current rewards: 322.90595, mean: 0.13399
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02049, current rewards: 330.07194, mean: 0.13418
[32m[0906 13-42-21 @Agent.py:117][0m Average action selection time: 0.0205
[32m[0906 13-42-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-42-21 @MBExp.py:227][0m Rewards obtained: [334.91961057050725], Lows: [2], Highs: [7], Total time: 51.931371
[32m[0906 13-42-25 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-25 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02031, current rewards: -2.33368, mean: -0.23337
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02059, current rewards: 2.07820, mean: 0.03464
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02033, current rewards: 6.49405, mean: 0.05904
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02027, current rewards: 10.90790, mean: 0.06817
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02025, current rewards: 15.31796, mean: 0.07294
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02020, current rewards: 19.73486, mean: 0.07590
[32m[0906 13-42-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02019, current rewards: 24.14473, mean: 0.07789
[32m[0906 13-42-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02015, current rewards: 28.55927, mean: 0.07933
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02011, current rewards: 32.93978, mean: 0.08034
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02009, current rewards: 37.24826, mean: 0.08097
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02007, current rewards: 41.55803, mean: 0.08149
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02008, current rewards: 45.86631, mean: 0.08190
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02009, current rewards: 50.17533, mean: 0.08225
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02009, current rewards: 54.48442, mean: 0.08255
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02008, current rewards: 58.79145, mean: 0.08280
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02008, current rewards: 63.09874, mean: 0.08302
[32m[0906 13-42-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02009, current rewards: 67.44155, mean: 0.08326
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02010, current rewards: 70.43975, mean: 0.08191
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02013, current rewards: 75.70142, mean: 0.08319
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02015, current rewards: 80.96443, mean: 0.08434
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02016, current rewards: 86.22710, mean: 0.08537
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02018, current rewards: 90.35043, mean: 0.08524
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02019, current rewards: 95.49069, mean: 0.08603
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02020, current rewards: 100.62282, mean: 0.08674
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02020, current rewards: 105.75955, mean: 0.08740
[32m[0906 13-42-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02019, current rewards: 110.57882, mean: 0.08776
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02019, current rewards: 115.64577, mean: 0.08828
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02019, current rewards: 120.28759, mean: 0.08845
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02019, current rewards: 124.92644, mean: 0.08860
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02019, current rewards: 129.56894, mean: 0.08875
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02019, current rewards: 134.20246, mean: 0.08888
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02019, current rewards: 138.84579, mean: 0.08900
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02019, current rewards: 143.48477, mean: 0.08912
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02019, current rewards: 148.29011, mean: 0.08933
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02019, current rewards: 153.39675, mean: 0.08971
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02020, current rewards: 158.50347, mean: 0.09006
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02020, current rewards: 163.60783, mean: 0.09039
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02022, current rewards: 168.71146, mean: 0.09071
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02022, current rewards: 173.81466, mean: 0.09100
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02023, current rewards: 178.91676, mean: 0.09128
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02024, current rewards: 181.94284, mean: 0.09052
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02024, current rewards: 187.59161, mean: 0.09106
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02025, current rewards: 192.72132, mean: 0.09134
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02026, current rewards: 197.86981, mean: 0.09161
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02026, current rewards: 203.01972, mean: 0.09186
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02027, current rewards: 208.16252, mean: 0.09211
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02027, current rewards: 213.31223, mean: 0.09234
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02027, current rewards: 218.45934, mean: 0.09257
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02027, current rewards: 223.60541, mean: 0.09278
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02027, current rewards: 228.74565, mean: 0.09299
[32m[0906 13-43-17 @Agent.py:117][0m Average action selection time: 0.0203
[32m[0906 13-43-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-43-17 @MBExp.py:227][0m Rewards obtained: [233.15775455205477], Lows: [2], Highs: [4], Total time: 103.269957
[32m[0906 13-43-24 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-24 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02053, current rewards: 1.14183, mean: 0.11418
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02000, current rewards: 7.09276, mean: 0.11821
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01998, current rewards: 13.04509, mean: 0.11859
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02008, current rewards: 18.99997, mean: 0.11875
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02002, current rewards: 24.95229, mean: 0.11882
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02001, current rewards: 30.90772, mean: 0.11888
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02002, current rewards: 36.85961, mean: 0.11890
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02004, current rewards: 42.81331, mean: 0.11893
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02005, current rewards: 48.78776, mean: 0.11899
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02006, current rewards: 54.76126, mean: 0.11905
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02005, current rewards: 59.51716, mean: 0.11670
[32m[0906 13-43-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02003, current rewards: 65.28019, mean: 0.11657
[32m[0906 13-43-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01999, current rewards: 71.03878, mean: 0.11646
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01996, current rewards: 76.78973, mean: 0.11635
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01994, current rewards: 82.55218, mean: 0.11627
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01995, current rewards: 88.31312, mean: 0.11620
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01997, current rewards: 94.00093, mean: 0.11605
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01997, current rewards: 99.43163, mean: 0.11562
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01997, current rewards: 104.88984, mean: 0.11526
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01999, current rewards: 110.34475, mean: 0.11494
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02000, current rewards: 115.80641, mean: 0.11466
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02000, current rewards: 121.32644, mean: 0.11446
[32m[0906 13-43-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02000, current rewards: 126.73646, mean: 0.11418
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01999, current rewards: 132.14474, mean: 0.11392
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02001, current rewards: 137.54858, mean: 0.11368
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02003, current rewards: 143.26434, mean: 0.11370
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02003, current rewards: 149.00043, mean: 0.11374
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02004, current rewards: 154.73493, mean: 0.11378
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02005, current rewards: 158.47933, mean: 0.11240
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02006, current rewards: 164.49951, mean: 0.11267
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02007, current rewards: 170.52406, mean: 0.11293
[32m[0906 13-43-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02007, current rewards: 176.55098, mean: 0.11317
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02007, current rewards: 182.35580, mean: 0.11326
[32m[0906 13-43-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02008, current rewards: 188.08601, mean: 0.11330
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02008, current rewards: 193.32718, mean: 0.11306
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02008, current rewards: 198.60909, mean: 0.11285
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02008, current rewards: 203.89297, mean: 0.11265
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02009, current rewards: 209.17139, mean: 0.11246
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02009, current rewards: 214.45069, mean: 0.11228
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02011, current rewards: 219.73055, mean: 0.11211
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02011, current rewards: 223.91660, mean: 0.11140
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02012, current rewards: 229.18218, mean: 0.11125
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02012, current rewards: 234.45744, mean: 0.11112
[32m[0906 13-44-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02013, current rewards: 239.72161, mean: 0.11098
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02014, current rewards: 244.99466, mean: 0.11086
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02015, current rewards: 250.25979, mean: 0.11073
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02016, current rewards: 255.52290, mean: 0.11062
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02017, current rewards: 260.78021, mean: 0.11050
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02017, current rewards: 266.05360, mean: 0.11040
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02018, current rewards: 271.32078, mean: 0.11029
[32m[0906 13-44-15 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-44-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-44-15 @MBExp.py:227][0m Rewards obtained: [275.54494434433036], Lows: [1], Highs: [2], Total time: 154.37541900000002
[32m[0906 13-44-24 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-24 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02019, current rewards: -0.14765, mean: -0.01476
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01992, current rewards: 4.77970, mean: 0.07966
[32m[0906 13-44-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01997, current rewards: 9.71062, mean: 0.08828
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01997, current rewards: 14.63616, mean: 0.09148
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01999, current rewards: 19.56214, mean: 0.09315
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01999, current rewards: 24.48991, mean: 0.09419
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02003, current rewards: 29.41616, mean: 0.09489
[32m[0906 13-44-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02005, current rewards: 34.76516, mean: 0.09657
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02006, current rewards: 40.03178, mean: 0.09764
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02006, current rewards: 45.26880, mean: 0.09841
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02005, current rewards: 50.54438, mean: 0.09911
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02005, current rewards: 55.82048, mean: 0.09968
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02004, current rewards: 61.08878, mean: 0.10015
[32m[0906 13-44-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02003, current rewards: 66.35766, mean: 0.10054
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02004, current rewards: 71.63107, mean: 0.10089
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02002, current rewards: 76.90019, mean: 0.10118
[32m[0906 13-44-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02002, current rewards: 82.17215, mean: 0.10145
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01999, current rewards: 87.65950, mean: 0.10193
[32m[0906 13-44-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01998, current rewards: 93.05843, mean: 0.10226
[32m[0906 13-44-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01998, current rewards: 98.46256, mean: 0.10257
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01999, current rewards: 103.86026, mean: 0.10283
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01999, current rewards: 109.42990, mean: 0.10324
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01999, current rewards: 115.04100, mean: 0.10364
[32m[0906 13-44-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01998, current rewards: 120.65126, mean: 0.10401
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01999, current rewards: 126.26183, mean: 0.10435
[32m[0906 13-44-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01998, current rewards: 131.90976, mean: 0.10469
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01999, current rewards: 137.56089, mean: 0.10501
[32m[0906 13-44-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01999, current rewards: 143.21333, mean: 0.10530
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01998, current rewards: 148.87323, mean: 0.10558
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01997, current rewards: 154.40112, mean: 0.10575
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01996, current rewards: 159.92657, mean: 0.10591
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01998, current rewards: 165.45604, mean: 0.10606
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01998, current rewards: 170.98704, mean: 0.10620
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01999, current rewards: 176.48805, mean: 0.10632
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02000, current rewards: 182.00842, mean: 0.10644
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02000, current rewards: 187.52681, mean: 0.10655
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02000, current rewards: 190.95849, mean: 0.10550
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02001, current rewards: 196.56109, mean: 0.10568
[32m[0906 13-45-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02001, current rewards: 202.16333, mean: 0.10584
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02001, current rewards: 207.76552, mean: 0.10600
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02002, current rewards: 213.36805, mean: 0.10615
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02003, current rewards: 218.94562, mean: 0.10628
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02004, current rewards: 224.41845, mean: 0.10636
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02005, current rewards: 228.82607, mean: 0.10594
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02006, current rewards: 234.29121, mean: 0.10601
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02006, current rewards: 239.75147, mean: 0.10608
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02007, current rewards: 245.21587, mean: 0.10615
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02008, current rewards: 250.67761, mean: 0.10622
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02008, current rewards: 256.09004, mean: 0.10626
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02009, current rewards: 260.90663, mean: 0.10606
[32m[0906 13-45-15 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 13-45-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-45-15 @MBExp.py:227][0m Rewards obtained: [264.8470400969847], Lows: [1], Highs: [2], Total time: 205.29190300000002
[32m[0906 13-45-26 @MBExp.py:144][0m ####################################################################
[32m[0906 13-45-26 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02056, current rewards: -2.26804, mean: -0.22680
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02022, current rewards: 3.03221, mean: 0.05054
[32m[0906 13-45-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02007, current rewards: 8.33260, mean: 0.07575
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02006, current rewards: 13.63081, mean: 0.08519
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02007, current rewards: 18.93404, mean: 0.09016
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02007, current rewards: 24.23364, mean: 0.09321
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02007, current rewards: 29.70369, mean: 0.09582
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02008, current rewards: 35.12121, mean: 0.09756
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02003, current rewards: 40.64921, mean: 0.09914
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02005, current rewards: 46.09304, mean: 0.10020
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02004, current rewards: 51.53949, mean: 0.10106
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02005, current rewards: 56.98489, mean: 0.10176
[32m[0906 13-45-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02004, current rewards: 62.43066, mean: 0.10235
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02004, current rewards: 67.87564, mean: 0.10284
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02006, current rewards: 73.31839, mean: 0.10327
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02005, current rewards: 78.73568, mean: 0.10360
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02005, current rewards: 84.15533, mean: 0.10390
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02005, current rewards: 89.56874, mean: 0.10415
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02005, current rewards: 94.98140, mean: 0.10438
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02003, current rewards: 100.40092, mean: 0.10458
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02002, current rewards: 105.80213, mean: 0.10475
[32m[0906 13-45-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01999, current rewards: 111.29134, mean: 0.10499
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01998, current rewards: 116.77488, mean: 0.10520
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01998, current rewards: 122.25543, mean: 0.10539
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01998, current rewards: 127.76988, mean: 0.10559
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01999, current rewards: 133.27715, mean: 0.10578
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02000, current rewards: 138.63931, mean: 0.10583
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02000, current rewards: 144.00685, mean: 0.10589
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02000, current rewards: 149.37137, mean: 0.10594
[32m[0906 13-45-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02000, current rewards: 154.72766, mean: 0.10598
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01999, current rewards: 160.09676, mean: 0.10602
[32m[0906 13-45-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01999, current rewards: 165.46383, mean: 0.10607
[32m[0906 13-45-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01998, current rewards: 170.83163, mean: 0.10611
[32m[0906 13-46-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01997, current rewards: 174.44092, mean: 0.10508
[32m[0906 13-46-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01996, current rewards: 181.36759, mean: 0.10606
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01995, current rewards: 188.29424, mean: 0.10699
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01995, current rewards: 195.22090, mean: 0.10786
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01995, current rewards: 202.14756, mean: 0.10868
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01995, current rewards: 209.07422, mean: 0.10946
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01996, current rewards: 204.61555, mean: 0.10440
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01995, current rewards: 154.61555, mean: 0.07692
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01996, current rewards: 104.61555, mean: 0.05078
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01996, current rewards: 54.61555, mean: 0.02588
[32m[0906 13-46-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01997, current rewards: 4.61555, mean: 0.00214
[32m[0906 13-46-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01997, current rewards: -45.38445, mean: -0.02054
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01997, current rewards: -95.38445, mean: -0.04221
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01999, current rewards: -145.38445, mean: -0.06294
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02000, current rewards: -195.38445, mean: -0.08279
[32m[0906 13-46-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02001, current rewards: -245.38445, mean: -0.10182
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02002, current rewards: -295.38445, mean: -0.12007
[32m[0906 13-46-17 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-46-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-46-17 @MBExp.py:227][0m Rewards obtained: [-335.38445250761555], Lows: [1], Highs: [553], Total time: 256.005888
[32m[0906 13-46-31 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-31 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02020, current rewards: -2.25359, mean: -0.22536
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02021, current rewards: 3.12248, mean: 0.05204
[32m[0906 13-46-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02020, current rewards: 8.50121, mean: 0.07728
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02017, current rewards: 13.87994, mean: 0.08675
[32m[0906 13-46-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02019, current rewards: 19.26363, mean: 0.09173
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02018, current rewards: 24.64287, mean: 0.09478
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02016, current rewards: 30.02386, mean: 0.09685
[32m[0906 13-46-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02017, current rewards: 35.39956, mean: 0.09833
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02015, current rewards: 40.78468, mean: 0.09947
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02011, current rewards: 46.45457, mean: 0.10099
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02007, current rewards: 51.85554, mean: 0.10168
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 57.25454, mean: 0.10224
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02009, current rewards: 62.65499, mean: 0.10271
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02008, current rewards: 68.05728, mean: 0.10312
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02009, current rewards: 71.55024, mean: 0.10077
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02008, current rewards: 77.44756, mean: 0.10190
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02008, current rewards: 82.56918, mean: 0.10194
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02009, current rewards: 87.93574, mean: 0.10225
[32m[0906 13-46-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02010, current rewards: 93.29475, mean: 0.10252
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02011, current rewards: 98.65605, mean: 0.10277
[32m[0906 13-46-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02011, current rewards: 104.01839, mean: 0.10299
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02011, current rewards: 109.38084, mean: 0.10319
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02011, current rewards: 114.74719, mean: 0.10338
[32m[0906 13-46-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02011, current rewards: 120.11146, mean: 0.10354
[32m[0906 13-46-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02009, current rewards: 125.62968, mean: 0.10383
[32m[0906 13-46-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02008, current rewards: 131.13332, mean: 0.10407
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02006, current rewards: 136.63659, mean: 0.10430
[32m[0906 13-46-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02005, current rewards: 142.13989, mean: 0.10451
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02005, current rewards: 146.48552, mean: 0.10389
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02005, current rewards: 151.89596, mean: 0.10404
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02006, current rewards: 157.30827, mean: 0.10418
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02005, current rewards: 162.72204, mean: 0.10431
[32m[0906 13-47-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02004, current rewards: 168.09755, mean: 0.10441
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02003, current rewards: 173.47187, mean: 0.10450
[32m[0906 13-47-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02003, current rewards: 178.84497, mean: 0.10459
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02003, current rewards: 184.24674, mean: 0.10469
[32m[0906 13-47-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02002, current rewards: 189.60163, mean: 0.10475
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02001, current rewards: 194.95849, mean: 0.10482
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02000, current rewards: 200.31654, mean: 0.10488
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01999, current rewards: 205.66850, mean: 0.10493
[32m[0906 13-47-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01999, current rewards: 210.99511, mean: 0.10497
[32m[0906 13-47-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01999, current rewards: 216.30404, mean: 0.10500
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01998, current rewards: 221.63571, mean: 0.10504
[32m[0906 13-47-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01998, current rewards: 226.95476, mean: 0.10507
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01998, current rewards: 232.28501, mean: 0.10511
[32m[0906 13-47-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01998, current rewards: 237.61486, mean: 0.10514
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01998, current rewards: 242.94096, mean: 0.10517
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01999, current rewards: 248.27559, mean: 0.10520
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01999, current rewards: 253.59948, mean: 0.10523
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02000, current rewards: 259.12178, mean: 0.10533
[32m[0906 13-47-21 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-47-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-47-21 @MBExp.py:227][0m Rewards obtained: [263.40809961695084], Lows: [1], Highs: [4], Total time: 306.69031600000005
[32m[0906 13-47-37 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-37 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01986, current rewards: -2.19726, mean: -0.21973
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02003, current rewards: 3.77188, mean: 0.06286
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02014, current rewards: 9.75767, mean: 0.08871
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02009, current rewards: 15.74414, mean: 0.09840
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02010, current rewards: 21.73118, mean: 0.10348
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02007, current rewards: 27.71545, mean: 0.10660
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02009, current rewards: 33.70272, mean: 0.10872
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02009, current rewards: 39.69089, mean: 0.11025
[32m[0906 13-47-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02010, current rewards: 45.65292, mean: 0.11135
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02010, current rewards: 51.62045, mean: 0.11222
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02008, current rewards: 57.58258, mean: 0.11291
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 63.54555, mean: 0.11347
[32m[0906 13-47-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02007, current rewards: 69.50393, mean: 0.11394
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02005, current rewards: 75.50578, mean: 0.11440
[32m[0906 13-47-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02005, current rewards: 81.51093, mean: 0.11480
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02007, current rewards: 87.51531, mean: 0.11515
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02008, current rewards: 93.43022, mean: 0.11535
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02008, current rewards: 99.34432, mean: 0.11552
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02008, current rewards: 105.35976, mean: 0.11578
[32m[0906 13-47-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02007, current rewards: 111.27797, mean: 0.11591
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02008, current rewards: 117.19300, mean: 0.11603
[32m[0906 13-47-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02008, current rewards: 123.10673, mean: 0.11614
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02008, current rewards: 129.02516, mean: 0.11624
[32m[0906 13-48-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02009, current rewards: 134.95456, mean: 0.11634
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02009, current rewards: 140.93214, mean: 0.11647
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02010, current rewards: 146.75751, mean: 0.11647
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02009, current rewards: 152.58339, mean: 0.11648
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02009, current rewards: 158.40828, mean: 0.11648
[32m[0906 13-48-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02008, current rewards: 164.23552, mean: 0.11648
[32m[0906 13-48-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02007, current rewards: 170.06362, mean: 0.11648
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02005, current rewards: 174.04343, mean: 0.11526
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02005, current rewards: 180.21508, mean: 0.11552
[32m[0906 13-48-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02004, current rewards: 185.83297, mean: 0.11542
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02004, current rewards: 191.89744, mean: 0.11560
[32m[0906 13-48-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02003, current rewards: 197.96608, mean: 0.11577
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02002, current rewards: 203.98136, mean: 0.11590
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02001, current rewards: 209.97676, mean: 0.11601
[32m[0906 13-48-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02000, current rewards: 215.97086, mean: 0.11611
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01999, current rewards: 221.96629, mean: 0.11621
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 227.96103, mean: 0.11631
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: 234.04069, mean: 0.11644
[32m[0906 13-48-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01997, current rewards: 239.90337, mean: 0.11646
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01997, current rewards: 245.76696, mean: 0.11648
[32m[0906 13-48-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01996, current rewards: 251.55635, mean: 0.11646
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01996, current rewards: 257.35946, mean: 0.11645
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01995, current rewards: 263.16583, mean: 0.11645
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01995, current rewards: 268.97003, mean: 0.11644
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01994, current rewards: 274.77189, mean: 0.11643
[32m[0906 13-48-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01994, current rewards: 280.55612, mean: 0.11641
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01993, current rewards: 286.45291, mean: 0.11644
[32m[0906 13-48-28 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-48-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-48-28 @MBExp.py:227][0m Rewards obtained: [291.22667490050867], Lows: [1], Highs: [3], Total time: 357.1805810000001
[32m[0906 13-48-46 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-46 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02053, current rewards: -0.00845, mean: -0.00085
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02010, current rewards: 5.60632, mean: 0.09344
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02014, current rewards: 11.20126, mean: 0.10183
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02019, current rewards: 16.79212, mean: 0.10495
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02019, current rewards: 22.38186, mean: 0.10658
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02018, current rewards: 27.97482, mean: 0.10760
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02016, current rewards: 33.56685, mean: 0.10828
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02015, current rewards: 39.22810, mean: 0.10897
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02016, current rewards: 44.80718, mean: 0.10929
[32m[0906 13-48-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02015, current rewards: 50.38628, mean: 0.10954
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02016, current rewards: 55.96540, mean: 0.10974
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02017, current rewards: 53.71871, mean: 0.09593
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02019, current rewards: 59.27699, mean: 0.09718
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02020, current rewards: 64.83823, mean: 0.09824
[32m[0906 13-49-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02017, current rewards: 70.39887, mean: 0.09915
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02016, current rewards: 75.93213, mean: 0.09991
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02016, current rewards: 81.50876, mean: 0.10063
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02014, current rewards: 87.08113, mean: 0.10126
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02014, current rewards: 92.65059, mean: 0.10181
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02014, current rewards: 98.19502, mean: 0.10229
[32m[0906 13-49-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02014, current rewards: 103.74956, mean: 0.10272
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02013, current rewards: 109.30321, mean: 0.10312
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02014, current rewards: 114.85326, mean: 0.10347
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02014, current rewards: 120.39416, mean: 0.10379
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02013, current rewards: 125.93684, mean: 0.10408
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02013, current rewards: 131.51668, mean: 0.10438
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02014, current rewards: 137.10308, mean: 0.10466
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02014, current rewards: 142.68771, mean: 0.10492
[32m[0906 13-49-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02014, current rewards: 148.27409, mean: 0.10516
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02014, current rewards: 153.85827, mean: 0.10538
[32m[0906 13-49-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02014, current rewards: 159.44120, mean: 0.10559
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02014, current rewards: 165.02806, mean: 0.10579
[32m[0906 13-49-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02013, current rewards: 170.70977, mean: 0.10603
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02012, current rewards: 176.30103, mean: 0.10621
[32m[0906 13-49-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02010, current rewards: 181.89551, mean: 0.10637
[32m[0906 13-49-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02008, current rewards: 187.48730, mean: 0.10653
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02007, current rewards: 192.96209, mean: 0.10661
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02006, current rewards: 198.47751, mean: 0.10671
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02005, current rewards: 203.98911, mean: 0.10680
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02004, current rewards: 209.50331, mean: 0.10689
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02003, current rewards: 215.01015, mean: 0.10697
[32m[0906 13-49-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02003, current rewards: 220.53619, mean: 0.10706
[32m[0906 13-49-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02002, current rewards: 226.06300, mean: 0.10714
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02001, current rewards: 231.58640, mean: 0.10722
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02001, current rewards: 237.09462, mean: 0.10728
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02000, current rewards: 242.69697, mean: 0.10739
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01999, current rewards: 248.30132, mean: 0.10749
[32m[0906 13-49-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01999, current rewards: 253.90271, mean: 0.10759
[32m[0906 13-49-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01998, current rewards: 259.50321, mean: 0.10768
[32m[0906 13-49-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01998, current rewards: 265.10510, mean: 0.10777
[32m[0906 13-49-36 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-49-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-49-36 @MBExp.py:227][0m Rewards obtained: [269.5897880334065], Lows: [0], Highs: [8], Total time: 407.76496900000006
[32m[0906 13-49-57 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-57 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-49-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02034, current rewards: -1.15759, mean: -0.11576
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01999, current rewards: 3.93700, mean: 0.06562
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02000, current rewards: 8.94495, mean: 0.08132
[32m[0906 13-50-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02015, current rewards: 13.95579, mean: 0.08722
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02008, current rewards: 18.96354, mean: 0.09030
[32m[0906 13-50-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02008, current rewards: 23.97068, mean: 0.09219
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02006, current rewards: 28.97897, mean: 0.09348
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02008, current rewards: 33.97300, mean: 0.09437
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02010, current rewards: 39.09735, mean: 0.09536
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02010, current rewards: 44.75232, mean: 0.09729
[32m[0906 13-50-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02010, current rewards: 50.40936, mean: 0.09884
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 56.06124, mean: 0.10011
[32m[0906 13-50-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02009, current rewards: 61.71779, mean: 0.10118
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02009, current rewards: 67.30214, mean: 0.10197
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02009, current rewards: 72.86583, mean: 0.10263
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02009, current rewards: 78.37117, mean: 0.10312
[32m[0906 13-50-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02006, current rewards: 83.94619, mean: 0.10364
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02005, current rewards: 89.51852, mean: 0.10409
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02005, current rewards: 95.09468, mean: 0.10450
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02005, current rewards: 100.67167, mean: 0.10487
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02005, current rewards: 106.24707, mean: 0.10520
[32m[0906 13-50-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02004, current rewards: 109.72146, mean: 0.10351
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02004, current rewards: 115.35610, mean: 0.10392
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02003, current rewards: 121.02667, mean: 0.10433
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02004, current rewards: 126.71115, mean: 0.10472
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02003, current rewards: 132.36190, mean: 0.10505
[32m[0906 13-50-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02004, current rewards: 138.00987, mean: 0.10535
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02004, current rewards: 143.66547, mean: 0.10564
[32m[0906 13-50-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02004, current rewards: 149.34378, mean: 0.10592
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02005, current rewards: 154.98835, mean: 0.10616
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02005, current rewards: 160.63367, mean: 0.10638
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02005, current rewards: 166.28106, mean: 0.10659
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02005, current rewards: 171.83556, mean: 0.10673
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02005, current rewards: 177.50099, mean: 0.10693
[32m[0906 13-50-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02006, current rewards: 183.15959, mean: 0.10711
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02006, current rewards: 188.81836, mean: 0.10728
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02006, current rewards: 194.48677, mean: 0.10745
[32m[0906 13-50-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02004, current rewards: 200.14259, mean: 0.10760
[32m[0906 13-50-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02002, current rewards: 205.81077, mean: 0.10775
[32m[0906 13-50-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02000, current rewards: 211.47859, mean: 0.10790
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: 217.13182, mean: 0.10803
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01997, current rewards: 222.79833, mean: 0.10815
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01997, current rewards: 228.45399, mean: 0.10827
[32m[0906 13-50-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01996, current rewards: 234.13570, mean: 0.10840
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01995, current rewards: 239.77207, mean: 0.10849
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01995, current rewards: 245.40802, mean: 0.10859
[32m[0906 13-50-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01994, current rewards: 251.04679, mean: 0.10868
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01994, current rewards: 256.68380, mean: 0.10876
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01994, current rewards: 262.35290, mean: 0.10886
[32m[0906 13-50-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01993, current rewards: 267.97819, mean: 0.10893
[32m[0906 13-50-47 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-50-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-50-47 @MBExp.py:227][0m Rewards obtained: [272.47507363617405], Lows: [1], Highs: [2], Total time: 458.23951000000005
[32m[0906 13-51-10 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-10 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02023, current rewards: -0.02285, mean: -0.00228
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02003, current rewards: 5.51500, mean: 0.09192
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01997, current rewards: 11.04677, mean: 0.10043
[32m[0906 13-51-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02002, current rewards: 16.58679, mean: 0.10367
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02006, current rewards: 22.12210, mean: 0.10534
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02009, current rewards: 27.66442, mean: 0.10640
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02012, current rewards: 33.19026, mean: 0.10707
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02012, current rewards: 38.69021, mean: 0.10747
[32m[0906 13-51-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02012, current rewards: 44.24076, mean: 0.10790
[32m[0906 13-51-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02013, current rewards: 49.79323, mean: 0.10825
[32m[0906 13-51-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02011, current rewards: 55.34510, mean: 0.10852
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02009, current rewards: 60.89735, mean: 0.10875
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02009, current rewards: 66.45314, mean: 0.10894
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02008, current rewards: 72.00223, mean: 0.10909
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02008, current rewards: 77.55493, mean: 0.10923
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02008, current rewards: 83.16100, mean: 0.10942
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02006, current rewards: 88.70309, mean: 0.10951
[32m[0906 13-51-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02005, current rewards: 94.19872, mean: 0.10953
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02003, current rewards: 99.69279, mean: 0.10955
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02003, current rewards: 105.18879, mean: 0.10957
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02003, current rewards: 110.68334, mean: 0.10959
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02003, current rewards: 116.17917, mean: 0.10960
[32m[0906 13-51-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02004, current rewards: 121.67232, mean: 0.10961
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02005, current rewards: 127.15334, mean: 0.10961
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02005, current rewards: 132.71193, mean: 0.10968
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02006, current rewards: 138.26685, mean: 0.10974
[32m[0906 13-51-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02007, current rewards: 143.82106, mean: 0.10979
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02007, current rewards: 149.37699, mean: 0.10984
[32m[0906 13-51-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02006, current rewards: 154.93376, mean: 0.10988
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02006, current rewards: 160.48965, mean: 0.10992
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02006, current rewards: 166.04318, mean: 0.10996
[32m[0906 13-51-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02006, current rewards: 171.59220, mean: 0.11000
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02006, current rewards: 177.15151, mean: 0.11003
[32m[0906 13-51-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02006, current rewards: 182.70508, mean: 0.11006
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02006, current rewards: 188.60070, mean: 0.11029
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02005, current rewards: 194.17822, mean: 0.11033
[32m[0906 13-51-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02005, current rewards: 199.75841, mean: 0.11036
[32m[0906 13-51-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02005, current rewards: 205.33779, mean: 0.11040
[32m[0906 13-51-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02005, current rewards: 210.91760, mean: 0.11043
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02005, current rewards: 216.44945, mean: 0.11043
[32m[0906 13-51-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02004, current rewards: 222.02982, mean: 0.11046
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02002, current rewards: 227.61536, mean: 0.11049
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02000, current rewards: 233.19853, mean: 0.11052
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01999, current rewards: 238.75926, mean: 0.11054
[32m[0906 13-51-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01998, current rewards: 244.30444, mean: 0.11054
[32m[0906 13-51-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01997, current rewards: 249.84864, mean: 0.11055
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01996, current rewards: 255.39395, mean: 0.11056
[32m[0906 13-51-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01996, current rewards: 260.95669, mean: 0.11057
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01995, current rewards: 266.58510, mean: 0.11062
[32m[0906 13-51-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01994, current rewards: 272.14361, mean: 0.11063
[32m[0906 13-52-00 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-52-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-52-00 @MBExp.py:227][0m Rewards obtained: [276.5895748416761], Lows: [0], Highs: [1], Total time: 508.74617600000005
[32m[0906 13-52-25 @MBExp.py:144][0m ####################################################################
[32m[0906 13-52-25 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02014, current rewards: -0.02638, mean: -0.00264
[32m[0906 13-52-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02010, current rewards: 5.52367, mean: 0.09206
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02010, current rewards: 11.06953, mean: 0.10063
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02014, current rewards: 16.61213, mean: 0.10383
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02018, current rewards: 22.15495, mean: 0.10550
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02020, current rewards: 27.70311, mean: 0.10655
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02016, current rewards: 33.23583, mean: 0.10721
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02015, current rewards: 38.78528, mean: 0.10774
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02015, current rewards: 44.33284, mean: 0.10813
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02013, current rewards: 49.88800, mean: 0.10845
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02012, current rewards: 55.44118, mean: 0.10871
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02012, current rewards: 60.98537, mean: 0.10890
[32m[0906 13-52-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02011, current rewards: 66.54094, mean: 0.10908
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02012, current rewards: 72.09169, mean: 0.10923
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02013, current rewards: 77.68593, mean: 0.10942
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02012, current rewards: 81.11925, mean: 0.10674
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02012, current rewards: 86.65409, mean: 0.10698
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02012, current rewards: 92.18913, mean: 0.10720
[32m[0906 13-52-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02012, current rewards: 97.72399, mean: 0.10739
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02010, current rewards: 103.25765, mean: 0.10756
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02008, current rewards: 108.79163, mean: 0.10771
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02009, current rewards: 114.32494, mean: 0.10785
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02008, current rewards: 119.85264, mean: 0.10798
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02009, current rewards: 124.26535, mean: 0.10713
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02009, current rewards: 129.79602, mean: 0.10727
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02009, current rewards: 135.32653, mean: 0.10740
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02008, current rewards: 140.85310, mean: 0.10752
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02008, current rewards: 146.48781, mean: 0.10771
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02009, current rewards: 152.04030, mean: 0.10783
[32m[0906 13-52-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02009, current rewards: 157.59631, mean: 0.10794
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02009, current rewards: 163.13585, mean: 0.10804
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02009, current rewards: 168.65665, mean: 0.10811
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02009, current rewards: 174.21670, mean: 0.10821
[32m[0906 13-52-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02009, current rewards: 179.77706, mean: 0.10830
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02009, current rewards: 185.33248, mean: 0.10838
[32m[0906 13-53-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02008, current rewards: 190.88668, mean: 0.10846
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02008, current rewards: 196.44714, mean: 0.10853
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02008, current rewards: 202.01194, mean: 0.10861
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02008, current rewards: 207.57140, mean: 0.10868
[32m[0906 13-53-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02008, current rewards: 213.12985, mean: 0.10874
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02008, current rewards: 218.68541, mean: 0.10880
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02007, current rewards: 224.25420, mean: 0.10886
[32m[0906 13-53-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02006, current rewards: 229.81791, mean: 0.10892
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02006, current rewards: 235.38177, mean: 0.10897
[32m[0906 13-53-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02005, current rewards: 240.95001, mean: 0.10903
[32m[0906 13-53-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02004, current rewards: 246.51934, mean: 0.10908
[32m[0906 13-53-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02002, current rewards: 252.08820, mean: 0.10913
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02001, current rewards: 257.66278, mean: 0.10918
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02000, current rewards: 263.22838, mean: 0.10922
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01999, current rewards: 268.79300, mean: 0.10927
[32m[0906 13-53-15 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-53-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-53-15 @MBExp.py:227][0m Rewards obtained: [273.2436817012463], Lows: [1], Highs: [2], Total time: 559.368686
[32m[0906 13-53-42 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-42 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01999, current rewards: 0.09013, mean: 0.00901
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02016, current rewards: 5.73743, mean: 0.09562
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02009, current rewards: 11.34101, mean: 0.10310
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02006, current rewards: 16.94511, mean: 0.10591
[32m[0906 13-53-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02011, current rewards: 22.55403, mean: 0.10740
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02011, current rewards: 28.12619, mean: 0.10818
[32m[0906 13-53-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02010, current rewards: 33.72299, mean: 0.10878
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02009, current rewards: 39.31957, mean: 0.10922
[32m[0906 13-53-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02008, current rewards: 44.91468, mean: 0.10955
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02007, current rewards: 50.55152, mean: 0.10989
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02006, current rewards: 56.19063, mean: 0.11018
[32m[0906 13-53-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02007, current rewards: 61.82461, mean: 0.11040
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02006, current rewards: 67.46129, mean: 0.11059
[32m[0906 13-53-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02006, current rewards: 73.08114, mean: 0.11073
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02006, current rewards: 78.68039, mean: 0.11082
[32m[0906 13-53-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02006, current rewards: 84.32874, mean: 0.11096
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02007, current rewards: 89.98550, mean: 0.11109
[32m[0906 13-54-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02006, current rewards: 95.63696, mean: 0.11121
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02005, current rewards: 101.29248, mean: 0.11131
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02005, current rewards: 106.94073, mean: 0.11140
[32m[0906 13-54-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02003, current rewards: 112.59249, mean: 0.11148
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02001, current rewards: 118.46273, mean: 0.11176
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02001, current rewards: 124.10226, mean: 0.11180
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02000, current rewards: 129.71460, mean: 0.11182
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02001, current rewards: 135.32715, mean: 0.11184
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 140.94069, mean: 0.11186
[32m[0906 13-54-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02000, current rewards: 146.55159, mean: 0.11187
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02000, current rewards: 152.16674, mean: 0.11189
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02001, current rewards: 157.77934, mean: 0.11190
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02000, current rewards: 163.39258, mean: 0.11191
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02000, current rewards: 169.05133, mean: 0.11195
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02001, current rewards: 174.66605, mean: 0.11197
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02001, current rewards: 180.27825, mean: 0.11197
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02001, current rewards: 185.89060, mean: 0.11198
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02001, current rewards: 191.50822, mean: 0.11199
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02001, current rewards: 197.06284, mean: 0.11197
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02001, current rewards: 202.69064, mean: 0.11198
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02001, current rewards: 208.32314, mean: 0.11200
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02001, current rewards: 213.89206, mean: 0.11199
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02001, current rewards: 219.52097, mean: 0.11200
[32m[0906 13-54-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02001, current rewards: 225.15445, mean: 0.11202
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02001, current rewards: 230.78499, mean: 0.11203
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02001, current rewards: 236.41024, mean: 0.11204
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02001, current rewards: 242.04230, mean: 0.11206
[32m[0906 13-54-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02000, current rewards: 247.67346, mean: 0.11207
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01999, current rewards: 253.30425, mean: 0.11208
[32m[0906 13-54-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01999, current rewards: 259.00292, mean: 0.11212
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01998, current rewards: 264.63917, mean: 0.11214
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01997, current rewards: 270.26890, mean: 0.11214
[32m[0906 13-54-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01997, current rewards: 275.84514, mean: 0.11213
[32m[0906 13-54-33 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-54-33 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-54-33 @MBExp.py:227][0m Rewards obtained: [280.327107407197], Lows: [0], Highs: [1], Total time: 609.925241
[32m[0906 13-55-02 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-02 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 13-55-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01941, current rewards: 1.17267, mean: 0.11727
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01962, current rewards: 7.09055, mean: 0.11818
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01959, current rewards: 13.00843, mean: 0.11826
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01967, current rewards: 18.92630, mean: 0.11829
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01975, current rewards: 24.84418, mean: 0.11831
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01983, current rewards: 30.44280, mean: 0.11709
[32m[0906 13-55-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01983, current rewards: 26.00459, mean: 0.08389
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01986, current rewards: 3.71834, mean: 0.01033
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01989, current rewards: 9.26978, mean: 0.02261
[32m[0906 13-55-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01991, current rewards: 14.81733, mean: 0.03221
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01993, current rewards: 20.36730, mean: 0.03994
[32m[0906 13-55-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01993, current rewards: 25.91856, mean: 0.04628
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01993, current rewards: 31.46670, mean: 0.05158
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01994, current rewards: 36.98309, mean: 0.05603
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01997, current rewards: 42.53034, mean: 0.05990
[32m[0906 13-55-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01998, current rewards: 48.07606, mean: 0.06326
[32m[0906 13-55-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01997, current rewards: 53.63200, mean: 0.06621
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01998, current rewards: 59.17769, mean: 0.06881
[32m[0906 13-55-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01998, current rewards: 64.72493, mean: 0.07113
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01999, current rewards: 70.26929, mean: 0.07320
[32m[0906 13-55-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01998, current rewards: 75.81239, mean: 0.07506
[32m[0906 13-55-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01996, current rewards: 81.29376, mean: 0.07669
[32m[0906 13-55-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01995, current rewards: 86.83817, mean: 0.07823
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: 92.34160, mean: 0.07960
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01995, current rewards: 97.88969, mean: 0.08090
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01996, current rewards: 103.43316, mean: 0.08209
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01996, current rewards: 108.98067, mean: 0.08319
[32m[0906 13-55-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01997, current rewards: 114.52828, mean: 0.08421
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01997, current rewards: 120.07484, mean: 0.08516
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01998, current rewards: 125.70424, mean: 0.08610
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01999, current rewards: 131.28750, mean: 0.08695
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01999, current rewards: 136.83330, mean: 0.08771
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01999, current rewards: 142.38578, mean: 0.08844
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01999, current rewards: 147.93142, mean: 0.08912
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01999, current rewards: 153.48279, mean: 0.08976
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02000, current rewards: 159.12130, mean: 0.09041
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02000, current rewards: 164.66647, mean: 0.09098
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02001, current rewards: 170.21813, mean: 0.09152
[32m[0906 13-55-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02001, current rewards: 175.76104, mean: 0.09202
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02001, current rewards: 181.30638, mean: 0.09250
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02001, current rewards: 186.85203, mean: 0.09296
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02001, current rewards: 192.40829, mean: 0.09340
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02001, current rewards: 197.98259, mean: 0.09383
[32m[0906 13-55-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02001, current rewards: 203.55762, mean: 0.09424
[32m[0906 13-55-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02001, current rewards: 209.12986, mean: 0.09463
[32m[0906 13-55-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02000, current rewards: 214.77986, mean: 0.09504
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01999, current rewards: 220.23255, mean: 0.09534
[32m[0906 13-55-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01998, current rewards: 225.76702, mean: 0.09566
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01998, current rewards: 231.30197, mean: 0.09598
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01997, current rewards: 236.83747, mean: 0.09628
[32m[0906 13-55-52 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-55-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-55-52 @MBExp.py:227][0m Rewards obtained: [241.26516986625379], Lows: [0], Highs: [34], Total time: 660.51709
[32m[0906 13-56-24 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-24 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 13-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: 1.09534, mean: 0.10953
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01969, current rewards: 6.60107, mean: 0.11002
[32m[0906 13-56-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01969, current rewards: 12.10875, mean: 0.11008
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01969, current rewards: 17.61445, mean: 0.11009
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01970, current rewards: 23.06211, mean: 0.10982
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01969, current rewards: 28.51676, mean: 0.10968
[32m[0906 13-56-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01969, current rewards: 34.00783, mean: 0.10970
[32m[0906 13-56-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01968, current rewards: 39.49962, mean: 0.10972
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01970, current rewards: 44.98786, mean: 0.10973
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01973, current rewards: 50.47982, mean: 0.10974
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01976, current rewards: 55.96868, mean: 0.10974
[32m[0906 13-56-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01978, current rewards: 61.45892, mean: 0.10975
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01982, current rewards: 66.94718, mean: 0.10975
[32m[0906 13-56-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01984, current rewards: 72.55610, mean: 0.10993
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01985, current rewards: 73.65897, mean: 0.10375
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01986, current rewards: 79.20496, mean: 0.10422
[32m[0906 13-56-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01988, current rewards: 84.74654, mean: 0.10463
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01989, current rewards: 90.28801, mean: 0.10499
[32m[0906 13-56-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01991, current rewards: 95.83420, mean: 0.10531
[32m[0906 13-56-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01992, current rewards: 101.43292, mean: 0.10566
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01993, current rewards: 106.96207, mean: 0.10590
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01994, current rewards: 112.48981, mean: 0.10612
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01992, current rewards: 118.01825, mean: 0.10632
[32m[0906 13-56-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01991, current rewards: 123.55553, mean: 0.10651
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01990, current rewards: 129.07535, mean: 0.10667
[32m[0906 13-56-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01990, current rewards: 134.59308, mean: 0.10682
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01991, current rewards: 140.10778, mean: 0.10695
[32m[0906 13-56-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01992, current rewards: 145.62778, mean: 0.10708
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01993, current rewards: 151.15000, mean: 0.10720
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01993, current rewards: 156.67347, mean: 0.10731
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01994, current rewards: 162.23154, mean: 0.10744
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01995, current rewards: 167.78781, mean: 0.10756
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01995, current rewards: 173.34589, mean: 0.10767
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01995, current rewards: 178.90300, mean: 0.10777
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01996, current rewards: 184.46194, mean: 0.10787
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01996, current rewards: 190.02588, mean: 0.10797
[32m[0906 13-57-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01996, current rewards: 195.58411, mean: 0.10806
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 201.14423, mean: 0.10814
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01997, current rewards: 206.70246, mean: 0.10822
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 212.26824, mean: 0.10830
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: 217.77086, mean: 0.10834
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01998, current rewards: 223.25173, mean: 0.10837
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01999, current rewards: 228.73177, mean: 0.10840
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01999, current rewards: 234.21188, mean: 0.10843
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02000, current rewards: 239.69240, mean: 0.10846
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02000, current rewards: 245.15060, mean: 0.10847
[32m[0906 13-57-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01999, current rewards: 250.63271, mean: 0.10850
[32m[0906 13-57-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01999, current rewards: 256.11558, mean: 0.10852
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01998, current rewards: 261.59708, mean: 0.10855
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01997, current rewards: 267.07816, mean: 0.10857
[32m[0906 13-57-14 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-57-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-57-14 @MBExp.py:227][0m Rewards obtained: [271.462572760564], Lows: [0], Highs: [4], Total time: 711.103646
[32m[0906 13-57-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-48 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01974, current rewards: 1.02170, mean: 0.10217
[32m[0906 13-57-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01958, current rewards: 6.58127, mean: 0.10969
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01965, current rewards: 12.13638, mean: 0.11033
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01969, current rewards: 17.69744, mean: 0.11061
[32m[0906 13-57-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01970, current rewards: 23.25513, mean: 0.11074
[32m[0906 13-57-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01967, current rewards: 28.80839, mean: 0.11080
[32m[0906 13-57-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01967, current rewards: 34.35981, mean: 0.11084
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01970, current rewards: 39.91136, mean: 0.11086
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01969, current rewards: 45.46515, mean: 0.11089
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01967, current rewards: 51.01973, mean: 0.11091
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01967, current rewards: 56.57850, mean: 0.11094
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01968, current rewards: 62.13755, mean: 0.11096
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01970, current rewards: 67.69652, mean: 0.11098
[32m[0906 13-58-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01972, current rewards: 73.25632, mean: 0.11099
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01974, current rewards: 78.81347, mean: 0.11100
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01977, current rewards: 84.38146, mean: 0.11103
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01979, current rewards: 89.98536, mean: 0.11109
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01981, current rewards: 95.59010, mean: 0.11115
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01982, current rewards: 101.19713, mean: 0.11121
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01984, current rewards: 106.79969, mean: 0.11125
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01986, current rewards: 112.45782, mean: 0.11134
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01987, current rewards: 118.06389, mean: 0.11138
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01988, current rewards: 123.66323, mean: 0.11141
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01989, current rewards: 129.26348, mean: 0.11143
[32m[0906 13-58-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01988, current rewards: 134.86327, mean: 0.11146
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01988, current rewards: 140.46762, mean: 0.11148
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01987, current rewards: 146.06592, mean: 0.11150
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01988, current rewards: 151.66633, mean: 0.11152
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01990, current rewards: 157.38480, mean: 0.11162
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01990, current rewards: 162.95143, mean: 0.11161
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01991, current rewards: 168.51765, mean: 0.11160
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01992, current rewards: 174.08363, mean: 0.11159
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01992, current rewards: 179.64946, mean: 0.11158
[32m[0906 13-58-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01992, current rewards: 185.21392, mean: 0.11157
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01993, current rewards: 190.78074, mean: 0.11157
[32m[0906 13-58-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01993, current rewards: 196.29031, mean: 0.11153
[32m[0906 13-58-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01993, current rewards: 201.85463, mean: 0.11152
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01994, current rewards: 207.40288, mean: 0.11151
[32m[0906 13-58-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01995, current rewards: 212.99232, mean: 0.11151
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01995, current rewards: 218.57490, mean: 0.11152
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01995, current rewards: 224.16410, mean: 0.11152
[32m[0906 13-58-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01995, current rewards: 229.75747, mean: 0.11153
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01995, current rewards: 235.30789, mean: 0.11152
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01996, current rewards: 240.87516, mean: 0.11152
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01996, current rewards: 246.44538, mean: 0.11151
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01996, current rewards: 251.95544, mean: 0.11148
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01997, current rewards: 257.54676, mean: 0.11149
[32m[0906 13-58-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01997, current rewards: 263.13134, mean: 0.11150
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01997, current rewards: 268.71521, mean: 0.11150
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01996, current rewards: 274.30157, mean: 0.11150
[32m[0906 13-58-38 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-58-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-58-38 @MBExp.py:227][0m Rewards obtained: [278.7660050803439], Lows: [0], Highs: [0], Total time: 761.657947
[32m[0906 13-59-14 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-14 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 13-59-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01977, current rewards: 1.14181, mean: 0.11418
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01967, current rewards: 6.67994, mean: 0.11133
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01973, current rewards: 12.21749, mean: 0.11107
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01972, current rewards: 17.76003, mean: 0.11100
[32m[0906 13-59-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01968, current rewards: 23.30112, mean: 0.11096
[32m[0906 13-59-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01967, current rewards: 28.83856, mean: 0.11092
[32m[0906 13-59-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01967, current rewards: 34.37786, mean: 0.11090
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01968, current rewards: 39.91808, mean: 0.11088
[32m[0906 13-59-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01968, current rewards: 45.45693, mean: 0.11087
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01969, current rewards: 51.29913, mean: 0.11152
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01969, current rewards: 56.84891, mean: 0.11147
[32m[0906 13-59-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01968, current rewards: 62.39173, mean: 0.11141
[32m[0906 13-59-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01968, current rewards: 67.93959, mean: 0.11138
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01968, current rewards: 73.48735, mean: 0.11134
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01968, current rewards: 79.03498, mean: 0.11132
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01969, current rewards: 84.58315, mean: 0.11129
[32m[0906 13-59-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01973, current rewards: 90.13183, mean: 0.11127
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01975, current rewards: 95.67878, mean: 0.11125
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01977, current rewards: 101.22484, mean: 0.11124
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01979, current rewards: 106.76849, mean: 0.11122
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01980, current rewards: 112.32322, mean: 0.11121
[32m[0906 13-59-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01980, current rewards: 117.86999, mean: 0.11120
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01982, current rewards: 123.42191, mean: 0.11119
[32m[0906 13-59-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01982, current rewards: 128.97089, mean: 0.11118
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01982, current rewards: 134.51824, mean: 0.11117
[32m[0906 13-59-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01982, current rewards: 140.06740, mean: 0.11116
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01981, current rewards: 145.61789, mean: 0.11116
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01981, current rewards: 151.16650, mean: 0.11115
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01983, current rewards: 156.71871, mean: 0.11115
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01984, current rewards: 162.29104, mean: 0.11116
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01984, current rewards: 167.86179, mean: 0.11117
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01985, current rewards: 173.43797, mean: 0.11118
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01986, current rewards: 179.01075, mean: 0.11119
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01987, current rewards: 184.58899, mean: 0.11120
[32m[0906 13-59-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01987, current rewards: 190.15997, mean: 0.11120
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01988, current rewards: 195.72936, mean: 0.11121
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01988, current rewards: 201.32613, mean: 0.11123
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01989, current rewards: 206.89560, mean: 0.11123
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01990, current rewards: 212.44419, mean: 0.11123
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01990, current rewards: 217.99189, mean: 0.11122
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01989, current rewards: 223.54186, mean: 0.11121
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01990, current rewards: 229.09415, mean: 0.11121
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01990, current rewards: 234.64416, mean: 0.11121
[32m[0906 13-59-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01991, current rewards: 240.20328, mean: 0.11121
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01991, current rewards: 245.76716, mean: 0.11121
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01991, current rewards: 251.33439, mean: 0.11121
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01992, current rewards: 256.91033, mean: 0.11122
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01993, current rewards: 262.47463, mean: 0.11122
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01993, current rewards: 268.04442, mean: 0.11122
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01994, current rewards: 272.49239, mean: 0.11077
[32m[0906 14-00-04 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 14-00-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-00-04 @MBExp.py:227][0m Rewards obtained: [277.77897701809354], Lows: [1], Highs: [0], Total time: 812.176671
[32m[0906 14-00-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-00-42 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-00-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: 1.40445, mean: 0.14044
[32m[0906 14-00-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 6.93962, mean: 0.11566
[32m[0906 14-00-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01930, current rewards: 12.42945, mean: 0.11299
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01941, current rewards: 17.96878, mean: 0.11230
[32m[0906 14-00-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01942, current rewards: 23.50778, mean: 0.11194
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01950, current rewards: 29.05283, mean: 0.11174
[32m[0906 14-00-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01953, current rewards: 34.59513, mean: 0.11160
[32m[0906 14-00-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01957, current rewards: 40.14146, mean: 0.11150
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01959, current rewards: 45.68409, mean: 0.11142
[32m[0906 14-00-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01959, current rewards: 51.21976, mean: 0.11135
[32m[0906 14-00-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01960, current rewards: 56.81312, mean: 0.11140
[32m[0906 14-00-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01961, current rewards: 62.38514, mean: 0.11140
[32m[0906 14-00-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01962, current rewards: 67.93145, mean: 0.11136
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01963, current rewards: 73.49706, mean: 0.11136
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01963, current rewards: 79.05944, mean: 0.11135
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01961, current rewards: 84.62457, mean: 0.11135
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01963, current rewards: 90.18510, mean: 0.11134
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01962, current rewards: 95.70392, mean: 0.11128
[32m[0906 14-01-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01962, current rewards: 101.22317, mean: 0.11123
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01962, current rewards: 106.73287, mean: 0.11118
[32m[0906 14-01-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01964, current rewards: 112.25109, mean: 0.11114
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01967, current rewards: 117.77263, mean: 0.11111
[32m[0906 14-01-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01968, current rewards: 123.29783, mean: 0.11108
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01970, current rewards: 128.82128, mean: 0.11105
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01972, current rewards: 134.34343, mean: 0.11103
[32m[0906 14-01-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01974, current rewards: 139.85935, mean: 0.11100
[32m[0906 14-01-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01973, current rewards: 145.38369, mean: 0.11098
[32m[0906 14-01-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01973, current rewards: 150.89975, mean: 0.11096
[32m[0906 14-01-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01972, current rewards: 156.41087, mean: 0.11093
[32m[0906 14-01-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01972, current rewards: 161.92797, mean: 0.11091
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01974, current rewards: 167.44347, mean: 0.11089
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01974, current rewards: 172.96486, mean: 0.11087
[32m[0906 14-01-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01975, current rewards: 178.47807, mean: 0.11086
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01976, current rewards: 183.99848, mean: 0.11084
[32m[0906 14-01-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01978, current rewards: 189.51692, mean: 0.11083
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01979, current rewards: 194.99372, mean: 0.11079
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01979, current rewards: 200.51775, mean: 0.11078
[32m[0906 14-01-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01980, current rewards: 206.02166, mean: 0.11076
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01981, current rewards: 211.52217, mean: 0.11074
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01982, current rewards: 217.01505, mean: 0.11072
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01982, current rewards: 222.51657, mean: 0.11070
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01983, current rewards: 228.01293, mean: 0.11069
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01984, current rewards: 233.51036, mean: 0.11067
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01984, current rewards: 239.00056, mean: 0.11065
[32m[0906 14-01-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01984, current rewards: 244.50254, mean: 0.11063
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01985, current rewards: 250.00044, mean: 0.11062
[32m[0906 14-01-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01986, current rewards: 255.49818, mean: 0.11061
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01986, current rewards: 260.99689, mean: 0.11059
[32m[0906 14-01-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01986, current rewards: 266.49611, mean: 0.11058
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01986, current rewards: 271.98867, mean: 0.11056
[32m[0906 14-01-32 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 14-01-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-01-32 @MBExp.py:227][0m Rewards obtained: [276.38767857792766], Lows: [0], Highs: [0], Total time: 862.504862
[32m[0906 14-02-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-12 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-02-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01955, current rewards: 1.16622, mean: 0.11662
[32m[0906 14-02-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 6.75142, mean: 0.11252
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.29514, mean: 0.11177
[32m[0906 14-02-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.84102, mean: 0.11151
[32m[0906 14-02-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.38444, mean: 0.11135
[32m[0906 14-02-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01927, current rewards: 28.92959, mean: 0.11127
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01932, current rewards: 34.47779, mean: 0.11122
[32m[0906 14-02-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01937, current rewards: 40.01657, mean: 0.11116
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01941, current rewards: 45.56266, mean: 0.11113
[32m[0906 14-02-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01945, current rewards: 51.07190, mean: 0.11103
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01947, current rewards: 56.59010, mean: 0.11096
[32m[0906 14-02-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01949, current rewards: 62.15026, mean: 0.11098
[32m[0906 14-02-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01949, current rewards: 65.59636, mean: 0.10754
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01950, current rewards: 71.15541, mean: 0.10781
[32m[0906 14-02-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01951, current rewards: 76.71396, mean: 0.10805
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01953, current rewards: 82.27042, mean: 0.10825
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01954, current rewards: 87.82724, mean: 0.10843
[32m[0906 14-02-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01954, current rewards: 93.38551, mean: 0.10859
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01955, current rewards: 98.94255, mean: 0.10873
[32m[0906 14-02-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01956, current rewards: 104.49844, mean: 0.10885
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01957, current rewards: 110.05551, mean: 0.10897
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01957, current rewards: 115.61330, mean: 0.10907
[32m[0906 14-02-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01957, current rewards: 121.17045, mean: 0.10916
[32m[0906 14-02-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01958, current rewards: 126.72873, mean: 0.10925
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01960, current rewards: 132.28504, mean: 0.10933
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01961, current rewards: 137.81482, mean: 0.10938
[32m[0906 14-02-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01963, current rewards: 143.37636, mean: 0.10945
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01964, current rewards: 148.94093, mean: 0.10952
[32m[0906 14-02-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01964, current rewards: 154.50649, mean: 0.10958
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01964, current rewards: 160.07274, mean: 0.10964
[32m[0906 14-02-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01965, current rewards: 165.64000, mean: 0.10970
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01966, current rewards: 171.20446, mean: 0.10975
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01967, current rewards: 176.77473, mean: 0.10980
[32m[0906 14-02-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01968, current rewards: 182.31675, mean: 0.10983
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01969, current rewards: 187.99012, mean: 0.10994
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01970, current rewards: 193.53862, mean: 0.10997
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01972, current rewards: 199.09005, mean: 0.10999
[32m[0906 14-02-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01973, current rewards: 204.63820, mean: 0.11002
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01974, current rewards: 210.13778, mean: 0.11002
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01974, current rewards: 215.60244, mean: 0.11000
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01976, current rewards: 221.06797, mean: 0.10998
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01977, current rewards: 226.53126, mean: 0.10997
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01977, current rewards: 232.27161, mean: 0.11008
[32m[0906 14-02-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01978, current rewards: 237.95570, mean: 0.11016
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01979, current rewards: 243.67049, mean: 0.11026
[32m[0906 14-02-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01980, current rewards: 249.38638, mean: 0.11035
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01980, current rewards: 255.09752, mean: 0.11043
[32m[0906 14-03-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01981, current rewards: 260.81146, mean: 0.11051
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01981, current rewards: 266.52674, mean: 0.11059
[32m[0906 14-03-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01982, current rewards: 272.23970, mean: 0.11067
[32m[0906 14-03-02 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 14-03-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-03-02 @MBExp.py:227][0m Rewards obtained: [276.7431354545391], Lows: [1], Highs: [0], Total time: 912.737401
[32m[0906 14-03-45 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-45 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01891, current rewards: 0.07574, mean: 0.00757
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 5.64753, mean: 0.09413
[32m[0906 14-03-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 11.16720, mean: 0.10152
[32m[0906 14-03-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 16.68382, mean: 0.10427
[32m[0906 14-03-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 22.20404, mean: 0.10573
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 27.71828, mean: 0.10661
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01927, current rewards: 29.04067, mean: 0.09368
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01933, current rewards: 34.58107, mean: 0.09606
[32m[0906 14-03-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01935, current rewards: 40.12081, mean: 0.09786
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01939, current rewards: 45.58648, mean: 0.09910
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01941, current rewards: 51.05406, mean: 0.10011
[32m[0906 14-03-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01944, current rewards: 56.55975, mean: 0.10100
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01947, current rewards: 62.06484, mean: 0.10175
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01947, current rewards: 67.56971, mean: 0.10238
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01949, current rewards: 73.04247, mean: 0.10288
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01950, current rewards: 78.53423, mean: 0.10333
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01951, current rewards: 84.02407, mean: 0.10373
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01951, current rewards: 89.51711, mean: 0.10409
[32m[0906 14-04-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01952, current rewards: 95.06864, mean: 0.10447
[32m[0906 14-04-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01953, current rewards: 100.57256, mean: 0.10476
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01954, current rewards: 106.07433, mean: 0.10502
[32m[0906 14-04-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01955, current rewards: 111.59405, mean: 0.10528
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01956, current rewards: 117.09549, mean: 0.10549
[32m[0906 14-04-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01956, current rewards: 122.59959, mean: 0.10569
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01956, current rewards: 128.10427, mean: 0.10587
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01957, current rewards: 133.61094, mean: 0.10604
[32m[0906 14-04-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01957, current rewards: 139.05014, mean: 0.10615
[32m[0906 14-04-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01958, current rewards: 144.53644, mean: 0.10628
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01959, current rewards: 150.02329, mean: 0.10640
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01959, current rewards: 155.50912, mean: 0.10651
[32m[0906 14-04-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01960, current rewards: 160.99847, mean: 0.10662
[32m[0906 14-04-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01960, current rewards: 166.48045, mean: 0.10672
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01960, current rewards: 171.96608, mean: 0.10681
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01961, current rewards: 177.45105, mean: 0.10690
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01963, current rewards: 183.03056, mean: 0.10704
[32m[0906 14-04-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01964, current rewards: 188.50552, mean: 0.10711
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01965, current rewards: 194.02636, mean: 0.10720
[32m[0906 14-04-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01966, current rewards: 199.55073, mean: 0.10729
[32m[0906 14-04-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01968, current rewards: 205.07360, mean: 0.10737
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01969, current rewards: 210.59737, mean: 0.10745
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01970, current rewards: 216.12082, mean: 0.10752
[32m[0906 14-04-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01971, current rewards: 221.64157, mean: 0.10759
[32m[0906 14-04-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01972, current rewards: 227.15889, mean: 0.10766
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01972, current rewards: 232.65309, mean: 0.10771
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01972, current rewards: 238.17254, mean: 0.10777
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01973, current rewards: 243.69694, mean: 0.10783
[32m[0906 14-04-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01974, current rewards: 249.21664, mean: 0.10789
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01975, current rewards: 254.73645, mean: 0.10794
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01976, current rewards: 260.24815, mean: 0.10799
[32m[0906 14-04-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01976, current rewards: 265.72648, mean: 0.10802
[32m[0906 14-04-35 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 14-04-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-04-35 @MBExp.py:227][0m Rewards obtained: [270.10802695094577], Lows: [2], Highs: [1], Total time: 962.836683
[32m[0906 14-05-19 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-19 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-05-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01954, current rewards: 1.05482, mean: 0.10548
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01938, current rewards: 6.60636, mean: 0.11011
[32m[0906 14-05-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01954, current rewards: 12.12243, mean: 0.11020
[32m[0906 14-05-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01945, current rewards: 17.64456, mean: 0.11028
[32m[0906 14-05-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01937, current rewards: 23.16516, mean: 0.11031
[32m[0906 14-05-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01936, current rewards: 28.68727, mean: 0.11034
[32m[0906 14-05-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01935, current rewards: 34.20476, mean: 0.11034
[32m[0906 14-05-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01933, current rewards: 39.72186, mean: 0.11034
[32m[0906 14-05-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01936, current rewards: 45.23955, mean: 0.11034
[32m[0906 14-05-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01940, current rewards: 50.79216, mean: 0.11042
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01944, current rewards: 56.31743, mean: 0.11043
[32m[0906 14-05-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01944, current rewards: 61.83139, mean: 0.11041
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01946, current rewards: 67.37410, mean: 0.11045
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01947, current rewards: 72.91383, mean: 0.11048
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01949, current rewards: 78.45297, mean: 0.11050
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01950, current rewards: 83.99288, mean: 0.11052
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01951, current rewards: 89.53202, mean: 0.11053
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01952, current rewards: 95.00639, mean: 0.11047
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01953, current rewards: 100.53671, mean: 0.11048
[32m[0906 14-05-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01953, current rewards: 106.07004, mean: 0.11049
[32m[0906 14-05-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01953, current rewards: 111.60373, mean: 0.11050
[32m[0906 14-05-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01954, current rewards: 117.13302, mean: 0.11050
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01954, current rewards: 120.54615, mean: 0.10860
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01954, current rewards: 126.07349, mean: 0.10868
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01955, current rewards: 131.60065, mean: 0.10876
[32m[0906 14-05-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01955, current rewards: 137.15630, mean: 0.10885
[32m[0906 14-05-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01956, current rewards: 142.80781, mean: 0.10901
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01956, current rewards: 148.41925, mean: 0.10913
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01956, current rewards: 154.03126, mean: 0.10924
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01956, current rewards: 159.64518, mean: 0.10935
[32m[0906 14-05-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01955, current rewards: 165.25540, mean: 0.10944
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01955, current rewards: 170.87092, mean: 0.10953
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01955, current rewards: 174.82027, mean: 0.10858
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01956, current rewards: 180.99795, mean: 0.10903
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01956, current rewards: 186.33007, mean: 0.10896
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01958, current rewards: 192.00459, mean: 0.10909
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01959, current rewards: 197.68602, mean: 0.10922
[32m[0906 14-05-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01960, current rewards: 203.36882, mean: 0.10934
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01962, current rewards: 209.04749, mean: 0.10945
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01963, current rewards: 214.72154, mean: 0.10955
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01964, current rewards: 220.40352, mean: 0.10965
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01965, current rewards: 226.08247, mean: 0.10975
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01967, current rewards: 231.78794, mean: 0.10985
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01968, current rewards: 237.44986, mean: 0.10993
[32m[0906 14-06-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01969, current rewards: 241.90148, mean: 0.10946
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01970, current rewards: 247.43528, mean: 0.10948
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01971, current rewards: 252.96786, mean: 0.10951
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01972, current rewards: 258.50423, mean: 0.10954
[32m[0906 14-06-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01973, current rewards: 264.03652, mean: 0.10956
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01973, current rewards: 269.57578, mean: 0.10958
[32m[0906 14-06-09 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-06-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-06-09 @MBExp.py:227][0m Rewards obtained: [274.0037374465809], Lows: [2], Highs: [1], Total time: 1012.863037
[32m[0906 14-06-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-06-56 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-06-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01917, current rewards: 0.04096, mean: 0.00410
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 5.59972, mean: 0.09333
[32m[0906 14-06-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 11.15292, mean: 0.10139
[32m[0906 14-06-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 16.71215, mean: 0.10445
[32m[0906 14-07-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 22.26476, mean: 0.10602
[32m[0906 14-07-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 27.82777, mean: 0.10703
[32m[0906 14-07-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01922, current rewards: 33.38270, mean: 0.10769
[32m[0906 14-07-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 38.94231, mean: 0.10817
[32m[0906 14-07-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 44.51506, mean: 0.10857
[32m[0906 14-07-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01921, current rewards: 50.28938, mean: 0.10932
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01927, current rewards: 55.72468, mean: 0.10926
[32m[0906 14-07-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01930, current rewards: 61.15999, mean: 0.10921
[32m[0906 14-07-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01932, current rewards: 66.59415, mean: 0.10917
[32m[0906 14-07-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01936, current rewards: 72.02981, mean: 0.10914
[32m[0906 14-07-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01939, current rewards: 77.46478, mean: 0.10911
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01941, current rewards: 82.90150, mean: 0.10908
[32m[0906 14-07-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01942, current rewards: 88.33551, mean: 0.10906
[32m[0906 14-07-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01943, current rewards: 93.78155, mean: 0.10905
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01944, current rewards: 99.27944, mean: 0.10910
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01945, current rewards: 104.77742, mean: 0.10914
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01945, current rewards: 110.27640, mean: 0.10918
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01946, current rewards: 115.77581, mean: 0.10922
[32m[0906 14-07-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01947, current rewards: 121.27772, mean: 0.10926
[32m[0906 14-07-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01948, current rewards: 126.77676, mean: 0.10929
[32m[0906 14-07-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01949, current rewards: 132.27508, mean: 0.10932
[32m[0906 14-07-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01950, current rewards: 137.72190, mean: 0.10930
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01952, current rewards: 143.20960, mean: 0.10932
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01952, current rewards: 148.69902, mean: 0.10934
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01952, current rewards: 154.18389, mean: 0.10935
[32m[0906 14-07-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01953, current rewards: 159.67760, mean: 0.10937
[32m[0906 14-07-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01953, current rewards: 165.16997, mean: 0.10938
[32m[0906 14-07-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01951, current rewards: 170.65742, mean: 0.10940
[32m[0906 14-07-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01950, current rewards: 176.14453, mean: 0.10941
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01949, current rewards: 181.74208, mean: 0.10948
[32m[0906 14-07-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01949, current rewards: 187.35376, mean: 0.10956
[32m[0906 14-07-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01948, current rewards: 192.91003, mean: 0.10961
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01950, current rewards: 198.47088, mean: 0.10965
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01952, current rewards: 204.02420, mean: 0.10969
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01953, current rewards: 209.58445, mean: 0.10973
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01954, current rewards: 215.14059, mean: 0.10977
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01956, current rewards: 220.70226, mean: 0.10980
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01957, current rewards: 226.25839, mean: 0.10983
[32m[0906 14-07-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01958, current rewards: 231.83423, mean: 0.10987
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01959, current rewards: 237.38911, mean: 0.10990
[32m[0906 14-07-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01960, current rewards: 242.94484, mean: 0.10993
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01962, current rewards: 248.48001, mean: 0.10995
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01963, current rewards: 254.02172, mean: 0.10997
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01965, current rewards: 259.57062, mean: 0.10999
[32m[0906 14-07-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01965, current rewards: 265.11593, mean: 0.11001
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01966, current rewards: 270.66721, mean: 0.11003
[32m[0906 14-07-46 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-07-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-07-46 @MBExp.py:227][0m Rewards obtained: [275.06854241305734], Lows: [0], Highs: [1], Total time: 1062.722399
[32m[0906 14-08-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-34 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01921, current rewards: 1.09815, mean: 0.10982
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01912, current rewards: 6.65598, mean: 0.11093
[32m[0906 14-08-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 12.20937, mean: 0.11099
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.77028, mean: 0.11106
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.32818, mean: 0.11109
[32m[0906 14-08-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 28.88712, mean: 0.11110
[32m[0906 14-08-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 34.44411, mean: 0.11111
[32m[0906 14-08-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: 39.99928, mean: 0.11111
[32m[0906 14-08-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 45.57130, mean: 0.11115
[32m[0906 14-08-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01921, current rewards: 51.12774, mean: 0.11115
[32m[0906 14-08-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.68246, mean: 0.11114
[32m[0906 14-08-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 62.22468, mean: 0.11112
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 67.75147, mean: 0.11107
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 73.27851, mean: 0.11103
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01931, current rewards: 78.80553, mean: 0.11099
[32m[0906 14-08-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01933, current rewards: 84.33389, mean: 0.11097
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01934, current rewards: 89.81390, mean: 0.11088
[32m[0906 14-08-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01936, current rewards: 95.33856, mean: 0.11086
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01937, current rewards: 100.86145, mean: 0.11084
[32m[0906 14-08-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01939, current rewards: 106.37207, mean: 0.11080
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01940, current rewards: 111.88183, mean: 0.11077
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01941, current rewards: 117.39013, mean: 0.11075
[32m[0906 14-08-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01942, current rewards: 122.90037, mean: 0.11072
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01942, current rewards: 128.41145, mean: 0.11070
[32m[0906 14-08-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01944, current rewards: 133.92230, mean: 0.11068
[32m[0906 14-08-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01945, current rewards: 139.49160, mean: 0.11071
[32m[0906 14-09-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01947, current rewards: 145.08559, mean: 0.11075
[32m[0906 14-09-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01947, current rewards: 150.58520, mean: 0.11072
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01948, current rewards: 156.08202, mean: 0.11070
[32m[0906 14-09-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01949, current rewards: 161.58235, mean: 0.11067
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01949, current rewards: 167.08196, mean: 0.11065
[32m[0906 14-09-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01950, current rewards: 172.58151, mean: 0.11063
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01949, current rewards: 178.07986, mean: 0.11061
[32m[0906 14-09-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01948, current rewards: 183.47958, mean: 0.11053
[32m[0906 14-09-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01947, current rewards: 188.94269, mean: 0.11049
[32m[0906 14-09-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01947, current rewards: 194.40798, mean: 0.11046
[32m[0906 14-09-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01946, current rewards: 199.87018, mean: 0.11043
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01945, current rewards: 205.32687, mean: 0.11039
[32m[0906 14-09-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01945, current rewards: 210.82969, mean: 0.11038
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01946, current rewards: 216.34825, mean: 0.11038
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01947, current rewards: 221.87065, mean: 0.11038
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01948, current rewards: 227.43852, mean: 0.11041
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01949, current rewards: 233.01240, mean: 0.11043
[32m[0906 14-09-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01950, current rewards: 238.54044, mean: 0.11044
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01952, current rewards: 244.07192, mean: 0.11044
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01953, current rewards: 249.60148, mean: 0.11044
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01955, current rewards: 255.31041, mean: 0.11052
[32m[0906 14-09-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01956, current rewards: 263.84833, mean: 0.11180
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01956, current rewards: 272.38625, mean: 0.11302
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01957, current rewards: 280.92417, mean: 0.11420
[32m[0906 14-09-24 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-09-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-09-24 @MBExp.py:227][0m Rewards obtained: [284.4548122208712], Lows: [1], Highs: [1], Total time: 1112.359898
[32m[0906 14-10-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-15 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01996, current rewards: -1.04195, mean: -0.10420
[32m[0906 14-10-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01916, current rewards: 4.41685, mean: 0.07361
[32m[0906 14-10-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01925, current rewards: 9.92334, mean: 0.09021
[32m[0906 14-10-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 15.43517, mean: 0.09647
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01920, current rewards: 20.94543, mean: 0.09974
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 26.45088, mean: 0.10173
[32m[0906 14-10-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01922, current rewards: 31.96345, mean: 0.10311
[32m[0906 14-10-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 37.47365, mean: 0.10409
[32m[0906 14-10-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 42.97802, mean: 0.10482
[32m[0906 14-10-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 48.54163, mean: 0.10553
[32m[0906 14-10-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 54.05841, mean: 0.10600
[32m[0906 14-10-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 59.56694, mean: 0.10637
[32m[0906 14-10-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 65.07282, mean: 0.10668
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 70.57486, mean: 0.10693
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 76.07874, mean: 0.10715
[32m[0906 14-10-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 81.58309, mean: 0.10735
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01931, current rewards: 87.08741, mean: 0.10752
[32m[0906 14-10-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01933, current rewards: 94.32208, mean: 0.10968
[32m[0906 14-10-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01935, current rewards: 102.86000, mean: 0.11303
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01937, current rewards: 111.39792, mean: 0.11604
[32m[0906 14-10-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01939, current rewards: 119.93584, mean: 0.11875
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01939, current rewards: 128.47376, mean: 0.12120
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01940, current rewards: 137.01168, mean: 0.12343
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01941, current rewards: 102.23154, mean: 0.08813
[32m[0906 14-10-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01941, current rewards: 52.23154, mean: 0.04317
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01942, current rewards: 2.23154, mean: 0.00177
[32m[0906 14-10-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01943, current rewards: -47.76846, mean: -0.03646
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01944, current rewards: -97.76846, mean: -0.07189
[32m[0906 14-10-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01945, current rewards: -147.76846, mean: -0.10480
[32m[0906 14-10-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01945, current rewards: -197.76846, mean: -0.13546
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01946, current rewards: -247.76846, mean: -0.16409
[32m[0906 14-10-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01947, current rewards: -297.76846, mean: -0.19088
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01947, current rewards: -347.76846, mean: -0.21601
[32m[0906 14-10-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01947, current rewards: -397.76846, mean: -0.23962
[32m[0906 14-10-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01947, current rewards: -447.76846, mean: -0.26185
[32m[0906 14-10-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01946, current rewards: -497.76846, mean: -0.28282
[32m[0906 14-10-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01945, current rewards: -547.76846, mean: -0.30263
[32m[0906 14-10-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01945, current rewards: -597.76846, mean: -0.32138
[32m[0906 14-10-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01944, current rewards: -647.76846, mean: -0.33915
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01944, current rewards: -697.76846, mean: -0.35600
[32m[0906 14-10-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01944, current rewards: -747.76846, mean: -0.37202
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01944, current rewards: -797.76846, mean: -0.38727
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01944, current rewards: -847.76846, mean: -0.40179
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01944, current rewards: -897.76846, mean: -0.41563
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01946, current rewards: -947.76846, mean: -0.42885
[32m[0906 14-11-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01948, current rewards: -997.76846, mean: -0.44149
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01949, current rewards: -1047.76846, mean: -0.45358
[32m[0906 14-11-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01950, current rewards: -1097.76846, mean: -0.46516
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01951, current rewards: -1147.76846, mean: -0.47625
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01952, current rewards: -1197.76846, mean: -0.48690
[32m[0906 14-11-05 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-11-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-11-05 @MBExp.py:227][0m Rewards obtained: [-1237.7684619382364], Lows: [1], Highs: [1377], Total time: 1161.848168
[32m[0906 14-11-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-58 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01937, current rewards: 1.06440, mean: 0.10644
[32m[0906 14-11-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01932, current rewards: 6.60974, mean: 0.11016
[32m[0906 14-12-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.16772, mean: 0.11062
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.73124, mean: 0.11082
[32m[0906 14-12-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 23.29198, mean: 0.11091
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 28.84892, mean: 0.11096
[32m[0906 14-12-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 34.40725, mean: 0.11099
[32m[0906 14-12-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.96979, mean: 0.11103
[32m[0906 14-12-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 45.59973, mean: 0.11122
[32m[0906 14-12-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 49.16983, mean: 0.10689
[32m[0906 14-12-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 54.85874, mean: 0.10757
[32m[0906 14-12-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 60.54697, mean: 0.10812
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 66.24160, mean: 0.10859
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 71.92811, mean: 0.10898
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 77.61918, mean: 0.10932
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 83.31095, mean: 0.10962
[32m[0906 14-12-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01924, current rewards: 89.07671, mean: 0.10997
[32m[0906 14-12-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 94.82313, mean: 0.11026
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01931, current rewards: 100.54779, mean: 0.11049
[32m[0906 14-12-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01932, current rewards: 105.09392, mean: 0.10947
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01934, current rewards: 110.76889, mean: 0.10967
[32m[0906 14-12-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01935, current rewards: 116.45244, mean: 0.10986
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01937, current rewards: 122.13353, mean: 0.11003
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01937, current rewards: 127.81525, mean: 0.11019
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01939, current rewards: 133.49970, mean: 0.11033
[32m[0906 14-12-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01940, current rewards: 139.09303, mean: 0.11039
[32m[0906 14-12-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01941, current rewards: 144.74968, mean: 0.11050
[32m[0906 14-12-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01942, current rewards: 150.39777, mean: 0.11059
[32m[0906 14-12-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01943, current rewards: 156.05147, mean: 0.11067
[32m[0906 14-12-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01945, current rewards: 161.70377, mean: 0.11076
[32m[0906 14-12-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01945, current rewards: 167.45736, mean: 0.11090
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01946, current rewards: 173.16632, mean: 0.11100
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01946, current rewards: 178.87397, mean: 0.11110
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01947, current rewards: 184.64880, mean: 0.11123
[32m[0906 14-12-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01948, current rewards: 190.39053, mean: 0.11134
[32m[0906 14-12-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01947, current rewards: 196.12563, mean: 0.11144
[32m[0906 14-12-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01946, current rewards: 201.85878, mean: 0.11152
[32m[0906 14-12-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01946, current rewards: 207.52360, mean: 0.11157
[32m[0906 14-12-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01945, current rewards: 213.14385, mean: 0.11159
[32m[0906 14-12-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01945, current rewards: 218.76288, mean: 0.11161
[32m[0906 14-12-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01944, current rewards: 224.38113, mean: 0.11163
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01944, current rewards: 229.92083, mean: 0.11161
[32m[0906 14-12-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01944, current rewards: 235.49470, mean: 0.11161
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01944, current rewards: 241.07148, mean: 0.11161
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01944, current rewards: 246.64362, mean: 0.11160
[32m[0906 14-12-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01945, current rewards: 252.26115, mean: 0.11162
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01945, current rewards: 257.88597, mean: 0.11164
[32m[0906 14-12-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01946, current rewards: 263.50868, mean: 0.11166
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01947, current rewards: 269.12770, mean: 0.11167
[32m[0906 14-12-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01948, current rewards: 274.70307, mean: 0.11167
[32m[0906 14-12-47 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-12-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-12-47 @MBExp.py:227][0m Rewards obtained: [279.17367682357803], Lows: [1], Highs: [1], Total time: 1211.258805
[32m[0906 14-13-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-43 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01980, current rewards: 1.14138, mean: 0.11414
[32m[0906 14-13-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01930, current rewards: 6.73405, mean: 0.11223
[32m[0906 14-13-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 12.29965, mean: 0.11181
[32m[0906 14-13-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01935, current rewards: 17.87152, mean: 0.11170
[32m[0906 14-13-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01934, current rewards: 23.44036, mean: 0.11162
[32m[0906 14-13-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01933, current rewards: 29.01017, mean: 0.11158
[32m[0906 14-13-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01938, current rewards: 34.58344, mean: 0.11156
[32m[0906 14-13-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01937, current rewards: 40.15379, mean: 0.11154
[32m[0906 14-13-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01935, current rewards: 45.67700, mean: 0.11141
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01933, current rewards: 51.48382, mean: 0.11192
[32m[0906 14-13-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01931, current rewards: 56.82460, mean: 0.11142
[32m[0906 14-13-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01930, current rewards: 62.16515, mean: 0.11101
[32m[0906 14-13-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01929, current rewards: 67.50521, mean: 0.11066
[32m[0906 14-13-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 72.84473, mean: 0.11037
[32m[0906 14-13-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01929, current rewards: 78.18462, mean: 0.11012
[32m[0906 14-13-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01929, current rewards: 83.52522, mean: 0.10990
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 88.82477, mean: 0.10966
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 94.14099, mean: 0.10947
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01931, current rewards: 99.45854, mean: 0.10930
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01934, current rewards: 104.74313, mean: 0.10911
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01936, current rewards: 110.30299, mean: 0.10921
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01938, current rewards: 115.85634, mean: 0.10930
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01939, current rewards: 121.41590, mean: 0.10938
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01941, current rewards: 126.97615, mean: 0.10946
[32m[0906 14-14-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01942, current rewards: 132.61910, mean: 0.10960
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01942, current rewards: 138.19709, mean: 0.10968
[32m[0906 14-14-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01943, current rewards: 143.74928, mean: 0.10973
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01945, current rewards: 149.30737, mean: 0.10978
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01946, current rewards: 154.86238, mean: 0.10983
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01947, current rewards: 160.42207, mean: 0.10988
[32m[0906 14-14-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01947, current rewards: 166.09003, mean: 0.10999
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01949, current rewards: 171.64606, mean: 0.11003
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01949, current rewards: 177.19872, mean: 0.11006
[32m[0906 14-14-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01949, current rewards: 182.74444, mean: 0.11009
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01950, current rewards: 188.30129, mean: 0.11012
[32m[0906 14-14-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01950, current rewards: 193.84836, mean: 0.11014
[32m[0906 14-14-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01951, current rewards: 199.39463, mean: 0.11016
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01950, current rewards: 204.95236, mean: 0.11019
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01950, current rewards: 210.49521, mean: 0.11021
[32m[0906 14-14-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01949, current rewards: 216.03920, mean: 0.11022
[32m[0906 14-14-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01949, current rewards: 221.58335, mean: 0.11024
[32m[0906 14-14-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01948, current rewards: 227.14423, mean: 0.11026
[32m[0906 14-14-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01948, current rewards: 232.69445, mean: 0.11028
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01948, current rewards: 238.23909, mean: 0.11030
[32m[0906 14-14-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01949, current rewards: 243.78976, mean: 0.11031
[32m[0906 14-14-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01949, current rewards: 249.33419, mean: 0.11032
[32m[0906 14-14-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01949, current rewards: 254.88329, mean: 0.11034
[32m[0906 14-14-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01950, current rewards: 260.37854, mean: 0.11033
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01950, current rewards: 265.87733, mean: 0.11032
[32m[0906 14-14-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01951, current rewards: 271.30941, mean: 0.11029
[32m[0906 14-14-32 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-14-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-14-32 @MBExp.py:227][0m Rewards obtained: [275.7339335984404], Lows: [0], Highs: [0], Total time: 1260.723847
[32m[0906 14-15-30 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-30 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-15-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01964, current rewards: -0.04644, mean: -0.00464
[32m[0906 14-15-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 5.44551, mean: 0.09076
[32m[0906 14-15-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 10.93419, mean: 0.09940
[32m[0906 14-15-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 16.42623, mean: 0.10266
[32m[0906 14-15-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01926, current rewards: 21.91774, mean: 0.10437
[32m[0906 14-15-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 27.41109, mean: 0.10543
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 32.90649, mean: 0.10615
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 38.42821, mean: 0.10675
[32m[0906 14-15-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 43.92781, mean: 0.10714
[32m[0906 14-15-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 49.42821, mean: 0.10745
[32m[0906 14-15-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 54.92815, mean: 0.10770
[32m[0906 14-15-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01924, current rewards: 60.42912, mean: 0.10791
[32m[0906 14-15-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01924, current rewards: 65.93043, mean: 0.10808
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 71.43085, mean: 0.10823
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 76.93060, mean: 0.10835
[32m[0906 14-15-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 82.42952, mean: 0.10846
[32m[0906 14-15-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 88.08455, mean: 0.10875
[32m[0906 14-15-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 93.60125, mean: 0.10884
[32m[0906 14-15-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 99.13305, mean: 0.10894
[32m[0906 14-15-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 104.67027, mean: 0.10903
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01924, current rewards: 110.22248, mean: 0.10913
[32m[0906 14-15-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: 115.74648, mean: 0.10919
[32m[0906 14-15-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01929, current rewards: 121.26707, mean: 0.10925
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01931, current rewards: 126.78485, mean: 0.10930
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01934, current rewards: 132.26090, mean: 0.10931
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01935, current rewards: 137.78862, mean: 0.10936
[32m[0906 14-15-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01936, current rewards: 143.32124, mean: 0.10941
[32m[0906 14-15-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01938, current rewards: 148.85289, mean: 0.10945
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01940, current rewards: 154.39227, mean: 0.10950
[32m[0906 14-15-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01940, current rewards: 159.92277, mean: 0.10954
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01942, current rewards: 165.45203, mean: 0.10957
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01943, current rewards: 170.98601, mean: 0.10961
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01944, current rewards: 176.54290, mean: 0.10965
[32m[0906 14-16-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01944, current rewards: 182.08239, mean: 0.10969
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01945, current rewards: 185.51914, mean: 0.10849
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01946, current rewards: 191.05913, mean: 0.10856
[32m[0906 14-16-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01947, current rewards: 196.60090, mean: 0.10862
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01947, current rewards: 202.14135, mean: 0.10868
[32m[0906 14-16-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01948, current rewards: 207.68192, mean: 0.10873
[32m[0906 14-16-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01948, current rewards: 213.22260, mean: 0.10879
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01947, current rewards: 218.75137, mean: 0.10883
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01947, current rewards: 224.21271, mean: 0.10884
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01947, current rewards: 229.72601, mean: 0.10887
[32m[0906 14-16-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01947, current rewards: 235.23990, mean: 0.10891
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01946, current rewards: 240.75403, mean: 0.10894
[32m[0906 14-16-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01945, current rewards: 246.26879, mean: 0.10897
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01945, current rewards: 251.72171, mean: 0.10897
[32m[0906 14-16-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01946, current rewards: 257.22115, mean: 0.10899
[32m[0906 14-16-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01946, current rewards: 262.72241, mean: 0.10901
[32m[0906 14-16-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01947, current rewards: 268.24447, mean: 0.10904
[32m[0906 14-16-19 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-16-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-16-19 @MBExp.py:227][0m Rewards obtained: [272.6460729296456], Lows: [1], Highs: [1], Total time: 1310.073703
[32m[0906 14-17-20 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-20 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-17-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: 1.21602, mean: 0.12160
[32m[0906 14-17-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.78830, mean: 0.11314
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 12.32380, mean: 0.11203
[32m[0906 14-17-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.85941, mean: 0.11162
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.39726, mean: 0.11142
[32m[0906 14-17-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 28.93600, mean: 0.11129
[32m[0906 14-17-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.47283, mean: 0.11120
[32m[0906 14-17-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 39.95649, mean: 0.11099
[32m[0906 14-17-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.48623, mean: 0.11094
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 51.01788, mean: 0.11091
[32m[0906 14-17-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 56.48803, mean: 0.11076
[32m[0906 14-17-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 61.99363, mean: 0.11070
[32m[0906 14-17-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 67.50400, mean: 0.11066
[32m[0906 14-17-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 73.00337, mean: 0.11061
[32m[0906 14-17-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 78.51322, mean: 0.11058
[32m[0906 14-17-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 84.00259, mean: 0.11053
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 89.50573, mean: 0.11050
[32m[0906 14-17-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 95.00488, mean: 0.11047
[32m[0906 14-17-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01923, current rewards: 100.50497, mean: 0.11045
[32m[0906 14-17-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 106.01290, mean: 0.11043
[32m[0906 14-17-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 111.51376, mean: 0.11041
[32m[0906 14-17-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 117.01795, mean: 0.11039
[32m[0906 14-17-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 122.51444, mean: 0.11037
[32m[0906 14-17-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01927, current rewards: 128.05729, mean: 0.11039
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01930, current rewards: 133.63805, mean: 0.11044
[32m[0906 14-17-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01931, current rewards: 139.15696, mean: 0.11044
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01932, current rewards: 144.67712, mean: 0.11044
[32m[0906 14-17-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01933, current rewards: 150.19552, mean: 0.11044
[32m[0906 14-17-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01934, current rewards: 155.71284, mean: 0.11043
[32m[0906 14-17-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01936, current rewards: 161.22997, mean: 0.11043
[32m[0906 14-17-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01937, current rewards: 166.79774, mean: 0.11046
[32m[0906 14-17-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01938, current rewards: 172.31288, mean: 0.11046
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01939, current rewards: 177.80503, mean: 0.11044
[32m[0906 14-17-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01940, current rewards: 183.32377, mean: 0.11044
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01941, current rewards: 188.83653, mean: 0.11043
[32m[0906 14-17-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01941, current rewards: 194.34856, mean: 0.11043
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01942, current rewards: 199.86697, mean: 0.11042
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01943, current rewards: 205.56508, mean: 0.11052
[32m[0906 14-17-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01944, current rewards: 211.09694, mean: 0.11052
[32m[0906 14-17-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01944, current rewards: 216.62770, mean: 0.11052
[32m[0906 14-17-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01945, current rewards: 222.13565, mean: 0.11052
[32m[0906 14-18-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01945, current rewards: 227.66423, mean: 0.11052
[32m[0906 14-18-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01945, current rewards: 233.19818, mean: 0.11052
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01944, current rewards: 238.73354, mean: 0.11052
[32m[0906 14-18-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01943, current rewards: 244.26718, mean: 0.11053
[32m[0906 14-18-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01943, current rewards: 249.80045, mean: 0.11053
[32m[0906 14-18-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01942, current rewards: 255.33490, mean: 0.11053
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01942, current rewards: 260.86960, mean: 0.11054
[32m[0906 14-18-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01942, current rewards: 266.43280, mean: 0.11055
[32m[0906 14-18-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01943, current rewards: 271.95148, mean: 0.11055
[32m[0906 14-18-09 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-18-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-18-09 @MBExp.py:227][0m Rewards obtained: [276.3666017082696], Lows: [0], Highs: [0], Total time: 1359.344792
[32m[0906 14-19-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-11 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-19-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01978, current rewards: 1.04464, mean: 0.10446
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01923, current rewards: 6.53263, mean: 0.10888
[32m[0906 14-19-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.04599, mean: 0.10951
[32m[0906 14-19-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 17.56009, mean: 0.10975
[32m[0906 14-19-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.06856, mean: 0.10985
[32m[0906 14-19-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 28.58298, mean: 0.10993
[32m[0906 14-19-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.12447, mean: 0.11008
[32m[0906 14-19-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 39.70725, mean: 0.11030
[32m[0906 14-19-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.23760, mean: 0.11034
[32m[0906 14-19-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 50.77045, mean: 0.11037
[32m[0906 14-19-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.33331, mean: 0.11046
[32m[0906 14-19-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 61.88111, mean: 0.11050
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 67.42085, mean: 0.11053
[32m[0906 14-19-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 72.96680, mean: 0.11056
[32m[0906 14-19-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.51438, mean: 0.11058
[32m[0906 14-19-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 83.94135, mean: 0.11045
[32m[0906 14-19-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 89.47792, mean: 0.11047
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 95.01446, mean: 0.11048
[32m[0906 14-19-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 100.55050, mean: 0.11050
[32m[0906 14-19-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 106.08896, mean: 0.11051
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 111.90460, mean: 0.11080
[32m[0906 14-19-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 117.42224, mean: 0.11078
[32m[0906 14-19-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 122.93425, mean: 0.11075
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 128.46793, mean: 0.11075
[32m[0906 14-19-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 134.09802, mean: 0.11082
[32m[0906 14-19-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 139.63316, mean: 0.11082
[32m[0906 14-19-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01926, current rewards: 145.16579, mean: 0.11081
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01928, current rewards: 150.70176, mean: 0.11081
[32m[0906 14-19-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01929, current rewards: 156.23291, mean: 0.11080
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01931, current rewards: 161.77581, mean: 0.11081
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01932, current rewards: 167.32125, mean: 0.11081
[32m[0906 14-19-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01934, current rewards: 172.86519, mean: 0.11081
[32m[0906 14-19-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01935, current rewards: 178.41413, mean: 0.11082
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01936, current rewards: 183.95037, mean: 0.11081
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01937, current rewards: 189.48929, mean: 0.11081
[32m[0906 14-19-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01938, current rewards: 195.02797, mean: 0.11081
[32m[0906 14-19-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01939, current rewards: 200.56670, mean: 0.11081
[32m[0906 14-19-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01940, current rewards: 206.10663, mean: 0.11081
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01940, current rewards: 211.64706, mean: 0.11081
[32m[0906 14-19-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01941, current rewards: 217.18469, mean: 0.11081
[32m[0906 14-19-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01942, current rewards: 222.94429, mean: 0.11092
[32m[0906 14-19-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01943, current rewards: 228.45966, mean: 0.11090
[32m[0906 14-19-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01943, current rewards: 234.00089, mean: 0.11090
[32m[0906 14-19-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01943, current rewards: 239.53922, mean: 0.11090
[32m[0906 14-19-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01942, current rewards: 245.07945, mean: 0.11090
[32m[0906 14-19-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01942, current rewards: 250.61672, mean: 0.11089
[32m[0906 14-19-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01941, current rewards: 256.15638, mean: 0.11089
[32m[0906 14-19-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01941, current rewards: 261.69260, mean: 0.11089
[32m[0906 14-19-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01940, current rewards: 267.23211, mean: 0.11088
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01940, current rewards: 272.84981, mean: 0.11091
[32m[0906 14-20-00 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-20-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-20-00 @MBExp.py:227][0m Rewards obtained: [277.29115221721713], Lows: [0], Highs: [0], Total time: 1408.547458
[32m[0906 14-21-04 @MBExp.py:144][0m ####################################################################
[32m[0906 14-21-04 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-21-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: 1.08999, mean: 0.10900
[32m[0906 14-21-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01931, current rewards: 6.64137, mean: 0.11069
[32m[0906 14-21-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 12.17075, mean: 0.11064
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 17.70561, mean: 0.11066
[32m[0906 14-21-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 23.24058, mean: 0.11067
[32m[0906 14-21-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 28.77096, mean: 0.11066
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.29906, mean: 0.11064
[32m[0906 14-21-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 39.89160, mean: 0.11081
[32m[0906 14-21-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.45687, mean: 0.11087
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 50.92602, mean: 0.11071
[32m[0906 14-21-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01926, current rewards: 56.39828, mean: 0.11058
[32m[0906 14-21-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 61.87459, mean: 0.11049
[32m[0906 14-21-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01924, current rewards: 67.34637, mean: 0.11040
[32m[0906 14-21-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01923, current rewards: 72.81631, mean: 0.11033
[32m[0906 14-21-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.28680, mean: 0.11026
[32m[0906 14-21-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 83.75961, mean: 0.11021
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 89.23336, mean: 0.11016
[32m[0906 14-21-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 94.88322, mean: 0.11033
[32m[0906 14-21-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.50413, mean: 0.11044
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 106.12269, mean: 0.11054
[32m[0906 14-21-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 111.73786, mean: 0.11063
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 117.35788, mean: 0.11071
[32m[0906 14-21-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 123.02006, mean: 0.11083
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 128.60025, mean: 0.11086
[32m[0906 14-21-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 134.11143, mean: 0.11084
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01923, current rewards: 139.64961, mean: 0.11083
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01924, current rewards: 145.18962, mean: 0.11083
[32m[0906 14-21-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01926, current rewards: 150.72726, mean: 0.11083
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01927, current rewards: 156.26717, mean: 0.11083
[32m[0906 14-21-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01928, current rewards: 161.80643, mean: 0.11083
[32m[0906 14-21-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01929, current rewards: 167.34489, mean: 0.11082
[32m[0906 14-21-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01930, current rewards: 172.88574, mean: 0.11082
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01931, current rewards: 178.71112, mean: 0.11100
[32m[0906 14-21-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01932, current rewards: 184.38820, mean: 0.11108
[32m[0906 14-21-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01933, current rewards: 190.06528, mean: 0.11115
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01934, current rewards: 195.74236, mean: 0.11122
[32m[0906 14-21-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01935, current rewards: 201.41943, mean: 0.11128
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01937, current rewards: 207.09651, mean: 0.11134
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01938, current rewards: 202.71301, mean: 0.10613
[32m[0906 14-21-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01938, current rewards: 208.24027, mean: 0.10625
[32m[0906 14-21-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01939, current rewards: 213.75097, mean: 0.10634
[32m[0906 14-21-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01940, current rewards: 219.27697, mean: 0.10645
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01940, current rewards: 224.81204, mean: 0.10655
[32m[0906 14-21-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01941, current rewards: 230.34311, mean: 0.10664
[32m[0906 14-21-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01941, current rewards: 235.83483, mean: 0.10671
[32m[0906 14-21-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01940, current rewards: 241.37174, mean: 0.10680
[32m[0906 14-21-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01940, current rewards: 246.91250, mean: 0.10689
[32m[0906 14-21-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01939, current rewards: 252.45415, mean: 0.10697
[32m[0906 14-21-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01938, current rewards: 257.99062, mean: 0.10705
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01938, current rewards: 263.59413, mean: 0.10715
[32m[0906 14-21-54 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-21-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-21-54 @MBExp.py:227][0m Rewards obtained: [268.0186388521908], Lows: [0], Highs: [9], Total time: 1457.672364
[32m[0906 14-23-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-00 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01890, current rewards: -0.98989, mean: -0.09899
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01901, current rewards: 4.54848, mean: 0.07581
[32m[0906 14-23-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 10.09174, mean: 0.09174
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 15.62936, mean: 0.09768
[32m[0906 14-23-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 21.16657, mean: 0.10079
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 26.70587, mean: 0.10271
[32m[0906 14-23-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 32.24291, mean: 0.10401
[32m[0906 14-23-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 37.78008, mean: 0.10494
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 43.31604, mean: 0.10565
[32m[0906 14-23-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 48.90980, mean: 0.10633
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 54.43435, mean: 0.10673
[32m[0906 14-23-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 59.96040, mean: 0.10707
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 65.48772, mean: 0.10736
[32m[0906 14-23-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 71.01191, mean: 0.10759
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 76.46388, mean: 0.10770
[32m[0906 14-23-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 81.98417, mean: 0.10787
[32m[0906 14-23-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 87.50667, mean: 0.10803
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 93.02767, mean: 0.10817
[32m[0906 14-23-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: 98.55277, mean: 0.10830
[32m[0906 14-23-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 104.07299, mean: 0.10841
[32m[0906 14-23-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 109.59281, mean: 0.10851
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 115.11744, mean: 0.10860
[32m[0906 14-23-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 120.65319, mean: 0.10870
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01923, current rewards: 126.22139, mean: 0.10881
[32m[0906 14-23-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 131.74784, mean: 0.10888
[32m[0906 14-23-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01923, current rewards: 137.27847, mean: 0.10895
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01922, current rewards: 142.80485, mean: 0.10901
[32m[0906 14-23-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01923, current rewards: 148.45350, mean: 0.10916
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01925, current rewards: 153.99689, mean: 0.10922
[32m[0906 14-23-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01927, current rewards: 159.53476, mean: 0.10927
[32m[0906 14-23-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01928, current rewards: 165.07819, mean: 0.10932
[32m[0906 14-23-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01930, current rewards: 170.60525, mean: 0.10936
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01932, current rewards: 176.14520, mean: 0.10941
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01933, current rewards: 181.68944, mean: 0.10945
[32m[0906 14-23-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01934, current rewards: 187.23274, mean: 0.10949
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01935, current rewards: 192.77539, mean: 0.10953
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01936, current rewards: 198.31838, mean: 0.10957
[32m[0906 14-23-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01936, current rewards: 204.44663, mean: 0.10992
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01936, current rewards: 209.98609, mean: 0.10994
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01937, current rewards: 215.56094, mean: 0.10998
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01938, current rewards: 221.09830, mean: 0.11000
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01939, current rewards: 226.63619, mean: 0.11002
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01940, current rewards: 232.17412, mean: 0.11004
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01940, current rewards: 237.71215, mean: 0.11005
[32m[0906 14-23-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01941, current rewards: 243.25011, mean: 0.11007
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01942, current rewards: 248.78734, mean: 0.11008
[32m[0906 14-23-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01942, current rewards: 252.09535, mean: 0.10913
[32m[0906 14-23-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01942, current rewards: 257.61705, mean: 0.10916
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01942, current rewards: 263.17282, mean: 0.10920
[32m[0906 14-23-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01941, current rewards: 268.72403, mean: 0.10924
[32m[0906 14-23-49 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-23-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-23-49 @MBExp.py:227][0m Rewards obtained: [273.1645765763623], Lows: [1], Highs: [2], Total time: 1506.895913
[32m[0906 14-24-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-58 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-24-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01852, current rewards: 1.08796, mean: 0.10880
[32m[0906 14-24-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01923, current rewards: 6.57911, mean: 0.10965
[32m[0906 14-25-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 12.05084, mean: 0.10955
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.52288, mean: 0.10952
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01928, current rewards: 22.99583, mean: 0.10950
[32m[0906 14-25-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 28.45431, mean: 0.10944
[32m[0906 14-25-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 33.89206, mean: 0.10933
[32m[0906 14-25-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 39.36794, mean: 0.10936
[32m[0906 14-25-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 44.84743, mean: 0.10938
[32m[0906 14-25-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 50.32533, mean: 0.10940
[32m[0906 14-25-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: 55.80282, mean: 0.10942
[32m[0906 14-25-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 61.29183, mean: 0.10945
[32m[0906 14-25-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01928, current rewards: 66.82233, mean: 0.10954
[32m[0906 14-25-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: 72.35661, mean: 0.10963
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01928, current rewards: 77.88728, mean: 0.10970
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01929, current rewards: 83.41648, mean: 0.10976
[32m[0906 14-25-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 88.95044, mean: 0.10982
[32m[0906 14-25-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01929, current rewards: 94.48387, mean: 0.10986
[32m[0906 14-25-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01929, current rewards: 100.01364, mean: 0.10991
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01928, current rewards: 105.54578, mean: 0.10994
[32m[0906 14-25-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01929, current rewards: 111.07611, mean: 0.10998
[32m[0906 14-25-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01929, current rewards: 116.60572, mean: 0.11001
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01929, current rewards: 122.38367, mean: 0.11026
[32m[0906 14-25-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01929, current rewards: 128.08739, mean: 0.11042
[32m[0906 14-25-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01930, current rewards: 133.79402, mean: 0.11057
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01929, current rewards: 139.50219, mean: 0.11072
[32m[0906 14-25-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01929, current rewards: 145.20700, mean: 0.11085
[32m[0906 14-25-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01930, current rewards: 150.91199, mean: 0.11096
[32m[0906 14-25-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01929, current rewards: 156.39799, mean: 0.11092
[32m[0906 14-25-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01930, current rewards: 161.92252, mean: 0.11091
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01931, current rewards: 167.42637, mean: 0.11088
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01933, current rewards: 172.95848, mean: 0.11087
[32m[0906 14-25-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01933, current rewards: 178.48803, mean: 0.11086
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01934, current rewards: 184.01411, mean: 0.11085
[32m[0906 14-25-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01935, current rewards: 189.54224, mean: 0.11084
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01936, current rewards: 195.06631, mean: 0.11083
[32m[0906 14-25-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01937, current rewards: 200.59562, mean: 0.11083
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01937, current rewards: 206.12049, mean: 0.11082
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01938, current rewards: 211.86060, mean: 0.11092
[32m[0906 14-25-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01939, current rewards: 217.37376, mean: 0.11090
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01940, current rewards: 222.89059, mean: 0.11089
[32m[0906 14-25-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01941, current rewards: 228.40886, mean: 0.11088
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01942, current rewards: 233.91958, mean: 0.11086
[32m[0906 14-25-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01942, current rewards: 239.43003, mean: 0.11085
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01943, current rewards: 244.94019, mean: 0.11083
[32m[0906 14-25-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01944, current rewards: 250.45625, mean: 0.11082
[32m[0906 14-25-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01944, current rewards: 255.93717, mean: 0.11080
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01945, current rewards: 261.41288, mean: 0.11077
[32m[0906 14-25-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01944, current rewards: 266.91222, mean: 0.11075
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01943, current rewards: 272.40694, mean: 0.11073
[32m[0906 14-25-47 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-25-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-25-47 @MBExp.py:227][0m Rewards obtained: [276.8035925012226], Lows: [0], Highs: [0], Total time: 1556.168063
[32m[0906 14-26-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-58 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01939, current rewards: 1.08560, mean: 0.10856
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01969, current rewards: 6.63067, mean: 0.11051
[32m[0906 14-27-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01939, current rewards: 12.17210, mean: 0.11066
[32m[0906 14-27-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 17.71606, mean: 0.11073
[32m[0906 14-27-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.24303, mean: 0.11068
[32m[0906 14-27-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.73210, mean: 0.11051
[32m[0906 14-27-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 34.26762, mean: 0.11054
[32m[0906 14-27-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 39.80687, mean: 0.11057
[32m[0906 14-27-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01925, current rewards: 45.33822, mean: 0.11058
[32m[0906 14-27-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 48.78266, mean: 0.10605
[32m[0906 14-27-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 54.50523, mean: 0.10687
[32m[0906 14-27-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01923, current rewards: 60.22712, mean: 0.10755
[32m[0906 14-27-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 65.94834, mean: 0.10811
[32m[0906 14-27-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01922, current rewards: 71.72269, mean: 0.10867
[32m[0906 14-27-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 77.42388, mean: 0.10905
[32m[0906 14-27-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 83.12601, mean: 0.10938
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 88.82728, mean: 0.10966
[32m[0906 14-27-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01924, current rewards: 94.52653, mean: 0.10991
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 100.22509, mean: 0.11014
[32m[0906 14-27-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: 105.72106, mean: 0.11013
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 111.24473, mean: 0.11014
[32m[0906 14-27-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01925, current rewards: 116.72074, mean: 0.11011
[32m[0906 14-27-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 122.21943, mean: 0.11011
[32m[0906 14-27-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01924, current rewards: 127.72651, mean: 0.11011
[32m[0906 14-27-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01924, current rewards: 133.23545, mean: 0.11011
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 138.74543, mean: 0.11012
[32m[0906 14-27-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01924, current rewards: 144.24918, mean: 0.11011
[32m[0906 14-27-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01924, current rewards: 149.75206, mean: 0.11011
[32m[0906 14-27-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01924, current rewards: 155.26160, mean: 0.11011
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 160.75223, mean: 0.11010
[32m[0906 14-27-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01924, current rewards: 166.28988, mean: 0.11013
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01926, current rewards: 171.78925, mean: 0.11012
[32m[0906 14-27-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01928, current rewards: 177.28992, mean: 0.11012
[32m[0906 14-27-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01929, current rewards: 182.78884, mean: 0.11011
[32m[0906 14-27-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01930, current rewards: 188.28418, mean: 0.11011
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01931, current rewards: 193.78120, mean: 0.11010
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01932, current rewards: 199.27958, mean: 0.11010
[32m[0906 14-27-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01932, current rewards: 204.77390, mean: 0.11009
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01933, current rewards: 210.27549, mean: 0.11009
[32m[0906 14-27-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01934, current rewards: 215.77178, mean: 0.11009
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01935, current rewards: 221.21119, mean: 0.11006
[32m[0906 14-27-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01936, current rewards: 226.66760, mean: 0.11003
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01936, current rewards: 232.12441, mean: 0.11001
[32m[0906 14-27-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01937, current rewards: 237.58225, mean: 0.10999
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01938, current rewards: 243.03778, mean: 0.10997
[32m[0906 14-27-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01939, current rewards: 248.54903, mean: 0.10998
[32m[0906 14-27-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01939, current rewards: 254.02264, mean: 0.10997
[32m[0906 14-27-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01940, current rewards: 259.49003, mean: 0.10995
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01941, current rewards: 264.96107, mean: 0.10994
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01942, current rewards: 270.42858, mean: 0.10993
[32m[0906 14-27-47 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-27-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-27-47 @MBExp.py:227][0m Rewards obtained: [274.801307127185], Lows: [1], Highs: [0], Total time: 1605.3833940000002
[32m[0906 14-29-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-00 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-29-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01894, current rewards: 0.02546, mean: 0.00255
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01919, current rewards: 5.51977, mean: 0.09200
[32m[0906 14-29-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01930, current rewards: 11.00628, mean: 0.10006
[32m[0906 14-29-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01935, current rewards: 16.49340, mean: 0.10308
[32m[0906 14-29-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01932, current rewards: 21.99774, mean: 0.10475
[32m[0906 14-29-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01931, current rewards: 27.48078, mean: 0.10570
[32m[0906 14-29-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01929, current rewards: 32.96104, mean: 0.10633
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01928, current rewards: 38.44631, mean: 0.10680
[32m[0906 14-29-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01931, current rewards: 43.94869, mean: 0.10719
[32m[0906 14-29-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01931, current rewards: 49.47388, mean: 0.10755
[32m[0906 14-29-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01930, current rewards: 55.00089, mean: 0.10784
[32m[0906 14-29-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: 60.52636, mean: 0.10808
[32m[0906 14-29-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01929, current rewards: 66.12681, mean: 0.10840
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01929, current rewards: 70.07375, mean: 0.10617
[32m[0906 14-29-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01929, current rewards: 78.86241, mean: 0.11107
[32m[0906 14-29-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01929, current rewards: 87.65107, mean: 0.11533
[32m[0906 14-29-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01929, current rewards: 96.43973, mean: 0.11906
[32m[0906 14-29-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01928, current rewards: 105.22840, mean: 0.12236
[32m[0906 14-29-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01927, current rewards: 114.01706, mean: 0.12529
[32m[0906 14-29-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 108.69644, mean: 0.11323
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: 58.69644, mean: 0.05812
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: 8.69644, mean: 0.00820
[32m[0906 14-29-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01926, current rewards: -41.30356, mean: -0.03721
[32m[0906 14-29-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01926, current rewards: -91.30356, mean: -0.07871
[32m[0906 14-29-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01927, current rewards: -141.30356, mean: -0.11678
[32m[0906 14-29-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01927, current rewards: -191.30356, mean: -0.15183
[32m[0906 14-29-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01927, current rewards: -241.30356, mean: -0.18420
[32m[0906 14-29-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01926, current rewards: -291.30356, mean: -0.21419
[32m[0906 14-29-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01926, current rewards: -341.30356, mean: -0.24206
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01925, current rewards: -391.30356, mean: -0.26802
[32m[0906 14-29-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01926, current rewards: -441.30356, mean: -0.29225
[32m[0906 14-29-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01926, current rewards: -491.30356, mean: -0.31494
[32m[0906 14-29-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01926, current rewards: -541.30356, mean: -0.33621
[32m[0906 14-29-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01928, current rewards: -591.30356, mean: -0.35621
[32m[0906 14-29-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01929, current rewards: -641.30356, mean: -0.37503
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01929, current rewards: -691.30356, mean: -0.39279
[32m[0906 14-29-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: -741.30356, mean: -0.40956
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01932, current rewards: -791.30356, mean: -0.42543
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01933, current rewards: -841.30356, mean: -0.44047
[32m[0906 14-29-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01934, current rewards: -891.30356, mean: -0.45475
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01934, current rewards: -941.30356, mean: -0.46831
[32m[0906 14-29-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01935, current rewards: -991.30356, mean: -0.48122
[32m[0906 14-29-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01936, current rewards: -1041.30356, mean: -0.49351
[32m[0906 14-29-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01937, current rewards: -1091.30356, mean: -0.50523
[32m[0906 14-29-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01938, current rewards: -1141.30356, mean: -0.51643
[32m[0906 14-29-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01938, current rewards: -1191.30356, mean: -0.52713
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01939, current rewards: -1241.30356, mean: -0.53736
[32m[0906 14-29-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01939, current rewards: -1291.30356, mean: -0.54716
[32m[0906 14-29-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01940, current rewards: -1341.30356, mean: -0.55656
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01940, current rewards: -1391.30356, mean: -0.56557
[32m[0906 14-29-50 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-29-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-29-50 @MBExp.py:227][0m Rewards obtained: [-1431.3035584553577], Lows: [1], Highs: [1553], Total time: 1654.5939770000002
[32m[0906 14-31-05 @MBExp.py:144][0m ####################################################################
[32m[0906 14-31-05 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-31-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.09735, mean: 0.10974
[32m[0906 14-31-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.61888, mean: 0.11031
[32m[0906 14-31-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 12.11998, mean: 0.11018
[32m[0906 14-31-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.64241, mean: 0.11027
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.16535, mean: 0.11031
[32m[0906 14-31-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 28.66621, mean: 0.11025
[32m[0906 14-31-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 34.17104, mean: 0.11023
[32m[0906 14-31-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 39.67844, mean: 0.11022
[32m[0906 14-31-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 45.18270, mean: 0.11020
[32m[0906 14-31-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.71158, mean: 0.11024
[32m[0906 14-31-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 56.23699, mean: 0.11027
[32m[0906 14-31-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 61.76538, mean: 0.11030
[32m[0906 14-31-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.22539, mean: 0.11021
[32m[0906 14-31-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 72.73927, mean: 0.11021
[32m[0906 14-31-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.25228, mean: 0.11021
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 83.76941, mean: 0.11022
[32m[0906 14-31-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 89.28362, mean: 0.11023
[32m[0906 14-31-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 94.77474, mean: 0.11020
[32m[0906 14-31-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.27859, mean: 0.11020
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01920, current rewards: 105.78185, mean: 0.11019
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 111.28249, mean: 0.11018
[32m[0906 14-31-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 116.78533, mean: 0.11017
[32m[0906 14-31-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 122.28418, mean: 0.11017
[32m[0906 14-31-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: 127.78657, mean: 0.11016
[32m[0906 14-31-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 133.28728, mean: 0.11015
[32m[0906 14-31-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01922, current rewards: 138.78913, mean: 0.11015
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01922, current rewards: 144.29354, mean: 0.11015
[32m[0906 14-31-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01922, current rewards: 149.79866, mean: 0.11015
[32m[0906 14-31-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01922, current rewards: 155.32578, mean: 0.11016
[32m[0906 14-31-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01922, current rewards: 160.84205, mean: 0.11017
[32m[0906 14-31-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01922, current rewards: 166.34503, mean: 0.11016
[32m[0906 14-31-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01922, current rewards: 171.85301, mean: 0.11016
[32m[0906 14-31-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01922, current rewards: 177.35543, mean: 0.11016
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01922, current rewards: 180.74614, mean: 0.10888
[32m[0906 14-31-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01922, current rewards: 186.31335, mean: 0.10896
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01923, current rewards: 191.88226, mean: 0.10902
[32m[0906 14-31-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01924, current rewards: 197.47509, mean: 0.10910
[32m[0906 14-31-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01925, current rewards: 203.04580, mean: 0.10916
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01926, current rewards: 208.61656, mean: 0.10922
[32m[0906 14-31-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01927, current rewards: 211.93385, mean: 0.10813
[32m[0906 14-31-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 217.43420, mean: 0.10818
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01929, current rewards: 222.93712, mean: 0.10822
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01930, current rewards: 228.44496, mean: 0.10827
[32m[0906 14-31-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01930, current rewards: 233.95202, mean: 0.10831
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01931, current rewards: 239.45686, mean: 0.10835
[32m[0906 14-31-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01932, current rewards: 244.96823, mean: 0.10839
[32m[0906 14-31-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01933, current rewards: 250.47262, mean: 0.10843
[32m[0906 14-31-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01934, current rewards: 255.97316, mean: 0.10846
[32m[0906 14-31-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01934, current rewards: 261.47823, mean: 0.10850
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01935, current rewards: 266.99134, mean: 0.10853
[32m[0906 14-31-54 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-31-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-31-54 @MBExp.py:227][0m Rewards obtained: [271.3957014997997], Lows: [1], Highs: [2], Total time: 1703.6683040000003
[32m[0906 14-33-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-33-11 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01883, current rewards: 1.09256, mean: 0.10926
[32m[0906 14-33-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 6.67604, mean: 0.11127
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.21362, mean: 0.11103
[32m[0906 14-33-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 17.75401, mean: 0.11096
[32m[0906 14-33-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.28689, mean: 0.11089
[32m[0906 14-33-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 27.33022, mean: 0.10512
[32m[0906 14-33-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 33.50790, mean: 0.10809
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 39.68558, mean: 0.11024
[32m[0906 14-33-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 45.86327, mean: 0.11186
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 52.04095, mean: 0.11313
[32m[0906 14-33-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 58.21863, mean: 0.11415
[32m[0906 14-33-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 62.19484, mean: 0.11106
[32m[0906 14-33-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 45.44751, mean: 0.07450
[32m[0906 14-33-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: -4.55249, mean: -0.00690
[32m[0906 14-33-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: -54.55249, mean: -0.07683
[32m[0906 14-33-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: -104.55249, mean: -0.13757
[32m[0906 14-33-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: -154.55249, mean: -0.19081
[32m[0906 14-33-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: -204.55249, mean: -0.23785
[32m[0906 14-33-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: -254.55249, mean: -0.27973
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: -304.55249, mean: -0.31724
[32m[0906 14-33-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: -354.55249, mean: -0.35104
[32m[0906 14-33-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: -404.55249, mean: -0.38165
[32m[0906 14-33-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: -454.55249, mean: -0.40951
[32m[0906 14-33-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: -504.55249, mean: -0.43496
[32m[0906 14-33-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: -554.55249, mean: -0.45831
[32m[0906 14-33-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: -604.55249, mean: -0.47980
[32m[0906 14-33-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01920, current rewards: -654.55249, mean: -0.49966
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: -704.55249, mean: -0.51805
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: -754.55249, mean: -0.53514
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: -804.55249, mean: -0.55106
[32m[0906 14-33-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: -854.55249, mean: -0.56593
[32m[0906 14-33-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: -904.55249, mean: -0.57984
[32m[0906 14-33-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: -954.55249, mean: -0.59289
[32m[0906 14-33-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: -1004.55249, mean: -0.60515
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: -1054.55249, mean: -0.61670
[32m[0906 14-33-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: -1104.55249, mean: -0.62759
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01919, current rewards: -1154.55249, mean: -0.63787
[32m[0906 14-33-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01920, current rewards: -1204.55249, mean: -0.64761
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01922, current rewards: -1254.55249, mean: -0.65683
[32m[0906 14-33-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01923, current rewards: -1304.55249, mean: -0.66559
[32m[0906 14-33-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01924, current rewards: -1354.55249, mean: -0.67391
[32m[0906 14-33-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01925, current rewards: -1404.55249, mean: -0.68182
[32m[0906 14-33-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: -1454.55249, mean: -0.68936
[32m[0906 14-33-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01926, current rewards: -1504.55249, mean: -0.69655
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01927, current rewards: -1554.55249, mean: -0.70342
[32m[0906 14-33-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01927, current rewards: -1604.55249, mean: -0.70998
[32m[0906 14-33-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: -1654.55249, mean: -0.71626
[32m[0906 14-33-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01928, current rewards: -1704.55249, mean: -0.72227
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01929, current rewards: -1754.55249, mean: -0.72803
[32m[0906 14-33-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01930, current rewards: -1804.55249, mean: -0.73356
[32m[0906 14-34-00 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-34-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-34-00 @MBExp.py:227][0m Rewards obtained: [-1844.552491774631], Lows: [1], Highs: [1909], Total time: 1752.6150240000002
[32m[0906 14-35-19 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-19 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: -1.06578, mean: -0.10658
[32m[0906 14-35-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 4.37025, mean: 0.07284
[32m[0906 14-35-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 9.95470, mean: 0.09050
[32m[0906 14-35-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 15.58258, mean: 0.09739
[32m[0906 14-35-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 21.20770, mean: 0.10099
[32m[0906 14-35-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 26.82990, mean: 0.10319
[32m[0906 14-35-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01927, current rewards: 32.45253, mean: 0.10469
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 38.07499, mean: 0.10576
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01919, current rewards: 43.69686, mean: 0.10658
[32m[0906 14-35-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 49.32241, mean: 0.10722
[32m[0906 14-35-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 54.97404, mean: 0.10779
[32m[0906 14-35-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 60.93628, mean: 0.10881
[32m[0906 14-35-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 55.77250, mean: 0.09143
[32m[0906 14-35-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 61.28629, mean: 0.09286
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 66.81167, mean: 0.09410
[32m[0906 14-35-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 72.33441, mean: 0.09518
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 77.86289, mean: 0.09613
[32m[0906 14-35-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 83.46098, mean: 0.09705
[32m[0906 14-35-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 88.99019, mean: 0.09779
[32m[0906 14-35-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 94.38329, mean: 0.09832
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 99.90270, mean: 0.09891
[32m[0906 14-35-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 105.42527, mean: 0.09946
[32m[0906 14-35-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 110.95341, mean: 0.09996
[32m[0906 14-35-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 116.47829, mean: 0.10041
[32m[0906 14-35-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 122.00509, mean: 0.10083
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 127.52955, mean: 0.10121
[32m[0906 14-35-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 133.05438, mean: 0.10157
[32m[0906 14-35-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 138.57605, mean: 0.10189
[32m[0906 14-35-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 144.03014, mean: 0.10215
[32m[0906 14-35-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 149.52352, mean: 0.10241
[32m[0906 14-35-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: 155.01923, mean: 0.10266
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01920, current rewards: 160.51181, mean: 0.10289
[32m[0906 14-35-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01920, current rewards: 166.00454, mean: 0.10311
[32m[0906 14-35-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01920, current rewards: 171.49526, mean: 0.10331
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01920, current rewards: 176.98839, mean: 0.10350
[32m[0906 14-35-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01920, current rewards: 182.47827, mean: 0.10368
[32m[0906 14-35-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 187.96956, mean: 0.10385
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01920, current rewards: 193.46013, mean: 0.10401
[32m[0906 14-35-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 198.95977, mean: 0.10417
[32m[0906 14-35-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01923, current rewards: 204.45307, mean: 0.10431
[32m[0906 14-35-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01924, current rewards: 209.94286, mean: 0.10445
[32m[0906 14-36-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01925, current rewards: 215.43254, mean: 0.10458
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: 220.92755, mean: 0.10471
[32m[0906 14-36-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01926, current rewards: 226.42125, mean: 0.10482
[32m[0906 14-36-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01927, current rewards: 231.96294, mean: 0.10496
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01927, current rewards: 237.45944, mean: 0.10507
[32m[0906 14-36-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: 242.95439, mean: 0.10518
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01929, current rewards: 248.47339, mean: 0.10529
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01929, current rewards: 253.98702, mean: 0.10539
[32m[0906 14-36-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01930, current rewards: 259.50209, mean: 0.10549
[32m[0906 14-36-08 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-36-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-36-08 @MBExp.py:227][0m Rewards obtained: [263.9084129359528], Lows: [1], Highs: [10], Total time: 1801.5657500000002
[32m[0906 14-37-30 @MBExp.py:144][0m ####################################################################
[32m[0906 14-37-30 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01924, current rewards: 1.10066, mean: 0.11007
[32m[0906 14-37-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01936, current rewards: 6.65346, mean: 0.11089
[32m[0906 14-37-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01926, current rewards: 12.20490, mean: 0.11095
[32m[0906 14-37-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 17.75436, mean: 0.11096
[32m[0906 14-37-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01923, current rewards: 23.30679, mean: 0.11098
[32m[0906 14-37-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 28.85559, mean: 0.11098
[32m[0906 14-37-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01922, current rewards: 34.40847, mean: 0.11100
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.95971, mean: 0.11100
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.51087, mean: 0.11100
[32m[0906 14-37-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 51.18439, mean: 0.11127
[32m[0906 14-37-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.71270, mean: 0.11120
[32m[0906 14-37-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 62.23305, mean: 0.11113
[32m[0906 14-37-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.75505, mean: 0.11107
[32m[0906 14-37-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 73.28339, mean: 0.11104
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.80887, mean: 0.11100
[32m[0906 14-37-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.33205, mean: 0.11096
[32m[0906 14-37-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 89.86170, mean: 0.11094
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 95.38485, mean: 0.11091
[32m[0906 14-37-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.93559, mean: 0.11092
[32m[0906 14-37-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 106.50559, mean: 0.11094
[32m[0906 14-37-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 112.05427, mean: 0.11094
[32m[0906 14-37-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 117.60156, mean: 0.11094
[32m[0906 14-37-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01920, current rewards: 123.15238, mean: 0.11095
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 128.70123, mean: 0.11095
[32m[0906 14-37-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 134.25380, mean: 0.11095
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 139.80234, mean: 0.11095
[32m[0906 14-37-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 145.38504, mean: 0.11098
[32m[0906 14-37-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: 149.40538, mean: 0.10986
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 155.58306, mean: 0.11034
[32m[0906 14-37-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01917, current rewards: 161.76075, mean: 0.11080
[32m[0906 14-37-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 167.93843, mean: 0.11122
[32m[0906 14-38-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01918, current rewards: 174.11611, mean: 0.11161
[32m[0906 14-38-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 180.29379, mean: 0.11198
[32m[0906 14-38-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 137.03511, mean: 0.08255
[32m[0906 14-38-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01918, current rewards: 87.03511, mean: 0.05090
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 82.52145, mean: 0.04689
[32m[0906 14-38-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 88.05704, mean: 0.04865
[32m[0906 14-38-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 93.58827, mean: 0.05032
[32m[0906 14-38-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01919, current rewards: 99.11653, mean: 0.05189
[32m[0906 14-38-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01918, current rewards: 104.65209, mean: 0.05339
[32m[0906 14-38-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 110.19153, mean: 0.05482
[32m[0906 14-38-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 115.71292, mean: 0.05617
[32m[0906 14-38-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01922, current rewards: 121.23514, mean: 0.05746
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01923, current rewards: 126.73358, mean: 0.05867
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01924, current rewards: 132.25606, mean: 0.05984
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01925, current rewards: 137.77833, mean: 0.06096
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01926, current rewards: 143.30216, mean: 0.06204
[32m[0906 14-38-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01926, current rewards: 148.82276, mean: 0.06306
[32m[0906 14-38-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01927, current rewards: 154.34516, mean: 0.06404
[32m[0906 14-38-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01928, current rewards: 159.89523, mean: 0.06500
[32m[0906 14-38-19 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-38-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-38-19 @MBExp.py:227][0m Rewards obtained: [164.31557384134376], Lows: [1], Highs: [103], Total time: 1850.4783630000002
[32m[0906 14-39-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-43 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-39-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01910, current rewards: 1.20963, mean: 0.12096
[32m[0906 14-39-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 6.74697, mean: 0.11245
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01910, current rewards: 12.32100, mean: 0.11201
[32m[0906 14-39-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 17.89497, mean: 0.11184
[32m[0906 14-39-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.47278, mean: 0.11178
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 29.04782, mean: 0.11172
[32m[0906 14-39-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.61785, mean: 0.11167
[32m[0906 14-39-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 40.18636, mean: 0.11163
[32m[0906 14-39-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.75988, mean: 0.11161
[32m[0906 14-39-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 51.29388, mean: 0.11151
[32m[0906 14-39-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.83696, mean: 0.11145
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.38739, mean: 0.11141
[32m[0906 14-39-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 67.94178, mean: 0.11138
[32m[0906 14-39-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.48656, mean: 0.11134
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 79.03177, mean: 0.11131
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 84.57894, mean: 0.11129
[32m[0906 14-39-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 90.08774, mean: 0.11122
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 95.68771, mean: 0.11126
[32m[0906 14-40-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 101.34183, mean: 0.11136
[32m[0906 14-40-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 106.89486, mean: 0.11135
[32m[0906 14-40-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01917, current rewards: 112.44575, mean: 0.11133
[32m[0906 14-40-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 117.99925, mean: 0.11132
[32m[0906 14-40-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 123.54827, mean: 0.11130
[32m[0906 14-40-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 129.09478, mean: 0.11129
[32m[0906 14-40-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 134.63928, mean: 0.11127
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 140.18893, mean: 0.11126
[32m[0906 14-40-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 145.66742, mean: 0.11120
[32m[0906 14-40-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 151.26480, mean: 0.11122
[32m[0906 14-40-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 156.74731, mean: 0.11117
[32m[0906 14-40-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01920, current rewards: 162.24489, mean: 0.11113
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01920, current rewards: 167.73957, mean: 0.11109
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01921, current rewards: 173.23267, mean: 0.11105
[32m[0906 14-40-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01921, current rewards: 178.72515, mean: 0.11101
[32m[0906 14-40-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01921, current rewards: 184.21861, mean: 0.11098
[32m[0906 14-40-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01921, current rewards: 189.75443, mean: 0.11097
[32m[0906 14-40-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01921, current rewards: 195.32212, mean: 0.11098
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: 200.82957, mean: 0.11096
[32m[0906 14-40-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01921, current rewards: 206.39184, mean: 0.11096
[32m[0906 14-40-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 211.95707, mean: 0.11097
[32m[0906 14-40-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: 217.52218, mean: 0.11098
[32m[0906 14-40-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01921, current rewards: 223.08792, mean: 0.11099
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: 228.65235, mean: 0.11100
[32m[0906 14-40-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01922, current rewards: 234.21645, mean: 0.11100
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01924, current rewards: 239.75593, mean: 0.11100
[32m[0906 14-40-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01925, current rewards: 245.33930, mean: 0.11101
[32m[0906 14-40-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01925, current rewards: 250.92116, mean: 0.11103
[32m[0906 14-40-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01926, current rewards: 256.46215, mean: 0.11102
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01928, current rewards: 262.00481, mean: 0.11102
[32m[0906 14-40-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01929, current rewards: 267.54724, mean: 0.11102
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01929, current rewards: 273.09155, mean: 0.11101
[32m[0906 14-40-32 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-40-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-40-32 @MBExp.py:227][0m Rewards obtained: [277.52500029851643], Lows: [0], Highs: [0], Total time: 1899.4256370000003
[32m[0906 14-41-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-58 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: 1.11341, mean: 0.11134
[32m[0906 14-41-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01923, current rewards: 6.58839, mean: 0.10981
[32m[0906 14-42-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 12.05471, mean: 0.10959
[32m[0906 14-42-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.53601, mean: 0.10960
[32m[0906 14-42-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 23.02528, mean: 0.10964
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 28.50575, mean: 0.10964
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 33.98589, mean: 0.10963
[32m[0906 14-42-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01922, current rewards: 39.46750, mean: 0.10963
[32m[0906 14-42-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01925, current rewards: 44.94834, mean: 0.10963
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 50.43651, mean: 0.10964
[32m[0906 14-42-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 55.89731, mean: 0.10960
[32m[0906 14-42-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 61.38988, mean: 0.10962
[32m[0906 14-42-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 66.87857, mean: 0.10964
[32m[0906 14-42-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 72.37298, mean: 0.10966
[32m[0906 14-42-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 77.86334, mean: 0.10967
[32m[0906 14-42-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 83.35447, mean: 0.10968
[32m[0906 14-42-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 88.84983, mean: 0.10969
[32m[0906 14-42-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 94.34175, mean: 0.10970
[32m[0906 14-42-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 99.83298, mean: 0.10971
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 105.34789, mean: 0.10974
[32m[0906 14-42-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 110.86805, mean: 0.10977
[32m[0906 14-42-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 116.37408, mean: 0.10979
[32m[0906 14-42-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 121.89078, mean: 0.10981
[32m[0906 14-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: 127.40404, mean: 0.10983
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 132.91767, mean: 0.10985
[32m[0906 14-42-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: 138.42863, mean: 0.10986
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 143.97688, mean: 0.10991
[32m[0906 14-42-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: 149.49577, mean: 0.10992
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: 155.01076, mean: 0.10994
[32m[0906 14-42-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 160.52152, mean: 0.10995
[32m[0906 14-42-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01920, current rewards: 166.06874, mean: 0.10998
[32m[0906 14-42-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 171.55726, mean: 0.10997
[32m[0906 14-42-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: 177.04698, mean: 0.10997
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: 182.52818, mean: 0.10996
[32m[0906 14-42-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: 188.01419, mean: 0.10995
[32m[0906 14-42-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01920, current rewards: 193.50170, mean: 0.10994
[32m[0906 14-42-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 198.98290, mean: 0.10994
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01921, current rewards: 202.41566, mean: 0.10883
[32m[0906 14-42-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 207.98181, mean: 0.10889
[32m[0906 14-42-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: 213.54947, mean: 0.10895
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01921, current rewards: 219.11241, mean: 0.10901
[32m[0906 14-42-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: 224.67654, mean: 0.10907
[32m[0906 14-42-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01921, current rewards: 230.24263, mean: 0.10912
[32m[0906 14-42-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01922, current rewards: 235.80440, mean: 0.10917
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01923, current rewards: 241.36793, mean: 0.10922
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01924, current rewards: 246.93116, mean: 0.10926
[32m[0906 14-42-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01925, current rewards: 252.49672, mean: 0.10931
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01925, current rewards: 257.98273, mean: 0.10931
[32m[0906 14-42-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01926, current rewards: 263.48008, mean: 0.10933
[32m[0906 14-42-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: 268.97851, mean: 0.10934
[32m[0906 14-42-46 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-42-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-42-46 @MBExp.py:227][0m Rewards obtained: [273.31298826978974], Lows: [1], Highs: [0], Total time: 1948.2998240000002
[32m[0906 14-44-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-15 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 14-44-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01961, current rewards: 1.11383, mean: 0.11138
[32m[0906 14-44-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01930, current rewards: 6.71135, mean: 0.11186
[32m[0906 14-44-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01922, current rewards: 12.22245, mean: 0.11111
[32m[0906 14-44-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.73661, mean: 0.11085
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.25249, mean: 0.11073
[32m[0906 14-44-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 28.78405, mean: 0.11071
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.30048, mean: 0.11065
[32m[0906 14-44-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.82575, mean: 0.11063
[32m[0906 14-44-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 45.34231, mean: 0.11059
[32m[0906 14-44-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01921, current rewards: 50.87445, mean: 0.11060
[32m[0906 14-44-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.39203, mean: 0.11057
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 61.90234, mean: 0.11054
[32m[0906 14-44-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.42017, mean: 0.11052
[32m[0906 14-44-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 72.94188, mean: 0.11052
[32m[0906 14-44-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.45835, mean: 0.11050
[32m[0906 14-44-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 83.97337, mean: 0.11049
[32m[0906 14-44-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 89.48300, mean: 0.11047
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 94.91446, mean: 0.11037
[32m[0906 14-44-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 100.42779, mean: 0.11036
[32m[0906 14-44-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 105.90325, mean: 0.11032
[32m[0906 14-44-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 111.43088, mean: 0.11033
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 116.95733, mean: 0.11034
[32m[0906 14-44-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 122.48606, mean: 0.11035
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 128.01135, mean: 0.11035
[32m[0906 14-44-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 133.54198, mean: 0.11037
[32m[0906 14-44-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: 139.06827, mean: 0.11037
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 144.59256, mean: 0.11038
[32m[0906 14-44-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: 150.12037, mean: 0.11038
[32m[0906 14-44-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 155.64470, mean: 0.11039
[32m[0906 14-44-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 161.17220, mean: 0.11039
[32m[0906 14-44-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 166.69995, mean: 0.11040
[32m[0906 14-44-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 172.22598, mean: 0.11040
[32m[0906 14-44-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01917, current rewards: 177.75012, mean: 0.11040
[32m[0906 14-44-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01917, current rewards: 183.39611, mean: 0.11048
[32m[0906 14-44-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 189.59109, mean: 0.11087
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01917, current rewards: 197.05128, mean: 0.11196
[32m[0906 14-44-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: 204.51147, mean: 0.11299
[32m[0906 14-44-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01917, current rewards: 211.97166, mean: 0.11396
[32m[0906 14-44-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01917, current rewards: 219.43185, mean: 0.11489
[32m[0906 14-44-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01917, current rewards: 226.89204, mean: 0.11576
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: 234.35223, mean: 0.11659
[32m[0906 14-44-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 241.81242, mean: 0.11738
[32m[0906 14-44-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 217.09491, mean: 0.10289
[32m[0906 14-44-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01918, current rewards: 167.09491, mean: 0.07736
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01917, current rewards: 117.09491, mean: 0.05298
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: 67.09491, mean: 0.02969
[32m[0906 14-45-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: 17.09491, mean: 0.00740
[32m[0906 14-45-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: -32.90509, mean: -0.01394
[32m[0906 14-45-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: -82.90509, mean: -0.03440
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01922, current rewards: -132.90509, mean: -0.05403
[32m[0906 14-45-03 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-45-03 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-45-03 @MBExp.py:227][0m Rewards obtained: [-172.90509220028656], Lows: [0], Highs: [418], Total time: 1997.0629790000003
[32m[0906 14-46-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-46-34 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 14-46-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01902, current rewards: 1.09092, mean: 0.10909
[32m[0906 14-46-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01897, current rewards: 6.51458, mean: 0.10858
[32m[0906 14-46-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.03223, mean: 0.10938
[32m[0906 14-46-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.54889, mean: 0.10968
[32m[0906 14-46-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.06803, mean: 0.10985
[32m[0906 14-46-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 28.58662, mean: 0.10995
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.10347, mean: 0.11001
[32m[0906 14-46-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 39.62336, mean: 0.11006
[32m[0906 14-46-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.14269, mean: 0.11010
[32m[0906 14-46-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 50.68605, mean: 0.11019
[32m[0906 14-46-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 56.20378, mean: 0.11020
[32m[0906 14-46-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 61.72648, mean: 0.11023
[32m[0906 14-46-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 67.24779, mean: 0.11024
[32m[0906 14-46-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 72.76976, mean: 0.11026
[32m[0906 14-46-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 78.28996, mean: 0.11027
[32m[0906 14-46-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 83.81093, mean: 0.11028
[32m[0906 14-46-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 89.33121, mean: 0.11029
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 94.85201, mean: 0.11029
[32m[0906 14-46-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 100.37054, mean: 0.11030
[32m[0906 14-46-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 105.88932, mean: 0.11030
[32m[0906 14-46-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 111.36696, mean: 0.11026
[32m[0906 14-46-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 116.87550, mean: 0.11026
[32m[0906 14-46-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01908, current rewards: 122.38656, mean: 0.11026
[32m[0906 14-46-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 127.89911, mean: 0.11026
[32m[0906 14-46-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 133.41015, mean: 0.11026
[32m[0906 14-46-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 138.95801, mean: 0.11028
[32m[0906 14-46-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 144.52564, mean: 0.11032
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 150.04527, mean: 0.11033
[32m[0906 14-47-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: 155.56108, mean: 0.11033
[32m[0906 14-47-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 161.08720, mean: 0.11033
[32m[0906 14-47-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 166.59594, mean: 0.11033
[32m[0906 14-47-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 172.10633, mean: 0.11032
[32m[0906 14-47-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 177.61190, mean: 0.11032
[32m[0906 14-47-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 183.12356, mean: 0.11032
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 188.61677, mean: 0.11030
[32m[0906 14-47-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: 194.12362, mean: 0.11030
[32m[0906 14-47-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01912, current rewards: 199.62458, mean: 0.11029
[32m[0906 14-47-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: 205.12916, mean: 0.11028
[32m[0906 14-47-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01912, current rewards: 210.63344, mean: 0.11028
[32m[0906 14-47-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01912, current rewards: 216.13591, mean: 0.11027
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: 221.63680, mean: 0.11027
[32m[0906 14-47-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 227.13943, mean: 0.11026
[32m[0906 14-47-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 232.89857, mean: 0.11038
[32m[0906 14-47-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 238.50587, mean: 0.11042
[32m[0906 14-47-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 244.11339, mean: 0.11046
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: 249.72000, mean: 0.11050
[32m[0906 14-47-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 255.32755, mean: 0.11053
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 260.93379, mean: 0.11057
[32m[0906 14-47-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 266.54016, mean: 0.11060
[32m[0906 14-47-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01917, current rewards: 271.03222, mean: 0.11018
[32m[0906 14-47-22 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-47-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-47-22 @MBExp.py:227][0m Rewards obtained: [275.37781036852186], Lows: [0], Highs: [1], Total time: 2045.6906180000003
[32m[0906 14-48-55 @MBExp.py:144][0m ####################################################################
[32m[0906 14-48-55 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 14-48-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01852, current rewards: -0.98193, mean: -0.09819
[32m[0906 14-48-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01896, current rewards: 4.50740, mean: 0.07512
[32m[0906 14-48-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 9.99260, mean: 0.09084
[32m[0906 14-48-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01913, current rewards: 15.47389, mean: 0.09671
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 20.95384, mean: 0.09978
[32m[0906 14-49-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 26.45686, mean: 0.10176
[32m[0906 14-49-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 31.95950, mean: 0.10310
[32m[0906 14-49-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 37.45927, mean: 0.10405
[32m[0906 14-49-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 42.94414, mean: 0.10474
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 48.42994, mean: 0.10528
[32m[0906 14-49-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 53.93202, mean: 0.10575
[32m[0906 14-49-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 59.43218, mean: 0.10613
[32m[0906 14-49-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 64.93047, mean: 0.10644
[32m[0906 14-49-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 70.42620, mean: 0.10671
[32m[0906 14-49-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 75.91755, mean: 0.10693
[32m[0906 14-49-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 81.41184, mean: 0.10712
[32m[0906 14-49-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 86.91391, mean: 0.10730
[32m[0906 14-49-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 92.31962, mean: 0.10735
[32m[0906 14-49-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 97.82491, mean: 0.10750
[32m[0906 14-49-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 103.35489, mean: 0.10766
[32m[0906 14-49-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 108.88900, mean: 0.10781
[32m[0906 14-49-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 114.42249, mean: 0.10795
[32m[0906 14-49-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 119.95084, mean: 0.10806
[32m[0906 14-49-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 125.48194, mean: 0.10817
[32m[0906 14-49-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 131.00975, mean: 0.10827
[32m[0906 14-49-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 136.62567, mean: 0.10843
[32m[0906 14-49-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 142.41068, mean: 0.10871
[32m[0906 14-49-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 148.20591, mean: 0.10897
[32m[0906 14-49-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 154.00114, mean: 0.10922
[32m[0906 14-49-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01914, current rewards: 159.79637, mean: 0.10945
[32m[0906 14-49-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01915, current rewards: 165.59160, mean: 0.10966
[32m[0906 14-49-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 153.29631, mean: 0.09827
[32m[0906 14-49-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01916, current rewards: 158.79162, mean: 0.09863
[32m[0906 14-49-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 164.29315, mean: 0.09897
[32m[0906 14-49-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 169.72864, mean: 0.09926
[32m[0906 14-49-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 175.22930, mean: 0.09956
[32m[0906 14-49-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 180.73089, mean: 0.09985
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01916, current rewards: 186.23417, mean: 0.10013
[32m[0906 14-49-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 191.73450, mean: 0.10038
[32m[0906 14-49-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01916, current rewards: 197.23304, mean: 0.10063
[32m[0906 14-49-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01916, current rewards: 202.73343, mean: 0.10086
[32m[0906 14-49-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01916, current rewards: 208.23430, mean: 0.10108
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 213.78591, mean: 0.10132
[32m[0906 14-49-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 219.29791, mean: 0.10153
[32m[0906 14-49-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01917, current rewards: 224.80967, mean: 0.10172
[32m[0906 14-49-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01917, current rewards: 230.32171, mean: 0.10191
[32m[0906 14-49-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: 235.83632, mean: 0.10209
[32m[0906 14-49-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: 241.32855, mean: 0.10226
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 246.83132, mean: 0.10242
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01919, current rewards: 252.33320, mean: 0.10257
[32m[0906 14-49-43 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-49-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-49-44 @MBExp.py:227][0m Rewards obtained: [256.6792080013031], Lows: [1], Highs: [16], Total time: 2094.385768
[32m[0906 14-51-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-51-18 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 14-51-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01986, current rewards: -1.05992, mean: -0.10599
[32m[0906 14-51-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01928, current rewards: 4.44574, mean: 0.07410
[32m[0906 14-51-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 9.95183, mean: 0.09047
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 15.45322, mean: 0.09658
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 20.95849, mean: 0.09980
[32m[0906 14-51-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 26.46787, mean: 0.10180
[32m[0906 14-51-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 31.97429, mean: 0.10314
[32m[0906 14-51-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 37.47723, mean: 0.10410
[32m[0906 14-51-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 42.98910, mean: 0.10485
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 48.47192, mean: 0.10537
[32m[0906 14-51-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 53.98671, mean: 0.10586
[32m[0906 14-51-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 59.50674, mean: 0.10626
[32m[0906 14-51-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 65.01824, mean: 0.10659
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 70.54869, mean: 0.10689
[32m[0906 14-51-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 76.03722, mean: 0.10709
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 81.52897, mean: 0.10727
[32m[0906 14-51-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 87.02116, mean: 0.10743
[32m[0906 14-51-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 92.50800, mean: 0.10757
[32m[0906 14-51-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 98.02005, mean: 0.10771
[32m[0906 14-51-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 103.56246, mean: 0.10788
[32m[0906 14-51-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 109.10954, mean: 0.10803
[32m[0906 14-51-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 114.65465, mean: 0.10816
[32m[0906 14-51-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 120.19404, mean: 0.10828
[32m[0906 14-51-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 125.74474, mean: 0.10840
[32m[0906 14-51-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 131.28764, mean: 0.10850
[32m[0906 14-51-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 137.35285, mean: 0.10901
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 143.39812, mean: 0.10946
[32m[0906 14-51-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 149.44338, mean: 0.10988
[32m[0906 14-51-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 155.48865, mean: 0.11028
[32m[0906 14-51-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 161.53391, mean: 0.11064
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 167.57918, mean: 0.11098
[32m[0906 14-51-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 173.62445, mean: 0.11130
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 179.66971, mean: 0.11160
[32m[0906 14-51-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 175.95216, mean: 0.10600
[32m[0906 14-51-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01918, current rewards: 125.95216, mean: 0.07366
[32m[0906 14-51-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 75.95216, mean: 0.04315
[32m[0906 14-51-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 25.95216, mean: 0.01434
[32m[0906 14-51-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: -24.04784, mean: -0.01293
[32m[0906 14-51-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01918, current rewards: -74.04784, mean: -0.03877
[32m[0906 14-51-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01919, current rewards: -124.04784, mean: -0.06329
[32m[0906 14-51-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01918, current rewards: -174.04784, mean: -0.08659
[32m[0906 14-51-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01918, current rewards: -224.04784, mean: -0.10876
[32m[0906 14-51-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: -274.04784, mean: -0.12988
[32m[0906 14-52-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01918, current rewards: -324.04784, mean: -0.15002
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01918, current rewards: -374.04784, mean: -0.16925
[32m[0906 14-52-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01919, current rewards: -424.04784, mean: -0.18763
[32m[0906 14-52-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: -474.04784, mean: -0.20522
[32m[0906 14-52-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01919, current rewards: -524.04784, mean: -0.22205
[32m[0906 14-52-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01919, current rewards: -574.04784, mean: -0.23819
[32m[0906 14-52-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01918, current rewards: -624.04784, mean: -0.25368
[32m[0906 14-52-07 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-52-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-52-07 @MBExp.py:227][0m Rewards obtained: [-664.0478421000383], Lows: [1], Highs: [848], Total time: 2143.0500700000002
[32m[0906 14-53-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-53-44 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 14-53-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01933, current rewards: 0.00591, mean: 0.00059
[32m[0906 14-53-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01912, current rewards: 6.44601, mean: 0.10743
[32m[0906 14-53-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 13.21005, mean: 0.12009
[32m[0906 14-53-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 19.97409, mean: 0.12484
[32m[0906 14-53-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 26.73813, mean: 0.12732
[32m[0906 14-53-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 33.50217, mean: 0.12885
[32m[0906 14-53-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 22.10476, mean: 0.07131
[32m[0906 14-53-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 27.59930, mean: 0.07666
[32m[0906 14-53-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 33.10464, mean: 0.08074
[32m[0906 14-53-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 38.61291, mean: 0.08394
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 44.11934, mean: 0.08651
[32m[0906 14-53-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 49.62024, mean: 0.08861
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 55.11968, mean: 0.09036
[32m[0906 14-53-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 60.85636, mean: 0.09221
[32m[0906 14-53-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 66.41002, mean: 0.09354
[32m[0906 14-53-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 71.96907, mean: 0.09470
[32m[0906 14-53-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 77.52776, mean: 0.09571
[32m[0906 14-54-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 83.08218, mean: 0.09661
[32m[0906 14-54-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 88.63758, mean: 0.09740
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 94.18553, mean: 0.09811
[32m[0906 14-54-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 99.69870, mean: 0.09871
[32m[0906 14-54-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01918, current rewards: 105.21725, mean: 0.09926
[32m[0906 14-54-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 110.73827, mean: 0.09976
[32m[0906 14-54-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 116.25527, mean: 0.10022
[32m[0906 14-54-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 121.77899, mean: 0.10064
[32m[0906 14-54-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 127.26181, mean: 0.10100
[32m[0906 14-54-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 132.77648, mean: 0.10136
[32m[0906 14-54-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 138.30083, mean: 0.10169
[32m[0906 14-54-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 143.81987, mean: 0.10200
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 149.36612, mean: 0.10231
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01913, current rewards: 154.87898, mean: 0.10257
[32m[0906 14-54-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01913, current rewards: 160.39504, mean: 0.10282
[32m[0906 14-54-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 165.91002, mean: 0.10305
[32m[0906 14-54-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01914, current rewards: 171.38469, mean: 0.10324
[32m[0906 14-54-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01914, current rewards: 176.90333, mean: 0.10345
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01914, current rewards: 182.45026, mean: 0.10366
[32m[0906 14-54-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01914, current rewards: 187.95902, mean: 0.10384
[32m[0906 14-54-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: 193.45963, mean: 0.10401
[32m[0906 14-54-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 198.96396, mean: 0.10417
[32m[0906 14-54-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 204.47359, mean: 0.10432
[32m[0906 14-54-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 209.97494, mean: 0.10447
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 215.50956, mean: 0.10462
[32m[0906 14-54-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 221.02029, mean: 0.10475
[32m[0906 14-54-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 226.55361, mean: 0.10489
[32m[0906 14-54-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 232.07314, mean: 0.10501
[32m[0906 14-54-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 237.59107, mean: 0.10513
[32m[0906 14-54-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 243.11392, mean: 0.10524
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 248.63140, mean: 0.10535
[32m[0906 14-54-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 254.15495, mean: 0.10546
[32m[0906 14-54-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 259.68722, mean: 0.10556
[32m[0906 14-54-32 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-54-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-54-32 @MBExp.py:227][0m Rewards obtained: [264.10473667453925], Lows: [0], Highs: [17], Total time: 2191.6337710000003
[32m[0906 14-56-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-56-11 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01892, current rewards: 1.06545, mean: 0.10654
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 6.60538, mean: 0.11009
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.14435, mean: 0.11040
[32m[0906 14-56-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 17.68489, mean: 0.11053
[32m[0906 14-56-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.22450, mean: 0.11059
[32m[0906 14-56-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 28.76517, mean: 0.11064
[32m[0906 14-56-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 34.30957, mean: 0.11068
[32m[0906 14-56-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 39.84967, mean: 0.11069
[32m[0906 14-56-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.38269, mean: 0.11069
[32m[0906 14-56-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 50.91613, mean: 0.11069
[32m[0906 14-56-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.45044, mean: 0.11069
[32m[0906 14-56-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 61.98586, mean: 0.11069
[32m[0906 14-56-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 67.51881, mean: 0.11069
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 73.05067, mean: 0.11068
[32m[0906 14-56-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 78.58273, mean: 0.11068
[32m[0906 14-56-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 84.13560, mean: 0.11070
[32m[0906 14-56-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 89.65902, mean: 0.11069
[32m[0906 14-56-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 95.14120, mean: 0.11063
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 100.67618, mean: 0.11063
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 106.20885, mean: 0.11063
[32m[0906 14-56-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 111.74533, mean: 0.11064
[32m[0906 14-56-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 117.27537, mean: 0.11064
[32m[0906 14-56-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 122.80703, mean: 0.11064
[32m[0906 14-56-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 128.33735, mean: 0.11064
[32m[0906 14-56-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 133.82659, mean: 0.11060
[32m[0906 14-56-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 139.39303, mean: 0.11063
[32m[0906 14-56-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 145.00086, mean: 0.11069
[32m[0906 14-56-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 150.50008, mean: 0.11066
[32m[0906 14-56-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 156.00215, mean: 0.11064
[32m[0906 14-56-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 161.49920, mean: 0.11062
[32m[0906 14-56-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 166.99396, mean: 0.11059
[32m[0906 14-56-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 172.49058, mean: 0.11057
[32m[0906 14-56-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: 178.06289, mean: 0.11060
[32m[0906 14-56-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: 183.61986, mean: 0.11061
[32m[0906 14-56-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01913, current rewards: 189.15870, mean: 0.11062
[32m[0906 14-56-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 194.66143, mean: 0.11060
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01914, current rewards: 200.18081, mean: 0.11060
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 205.70117, mean: 0.11059
[32m[0906 14-56-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 211.22118, mean: 0.11059
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 216.74277, mean: 0.11058
[32m[0906 14-56-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 222.26015, mean: 0.11058
[32m[0906 14-56-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 227.74896, mean: 0.11056
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 233.27532, mean: 0.11056
[32m[0906 14-56-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 238.81151, mean: 0.11056
[32m[0906 14-56-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 244.31678, mean: 0.11055
[32m[0906 14-56-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 249.81957, mean: 0.11054
[32m[0906 14-56-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 255.32304, mean: 0.11053
[32m[0906 14-56-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: 260.82605, mean: 0.11052
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 266.32967, mean: 0.11051
[32m[0906 14-56-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 271.78497, mean: 0.11048
[32m[0906 14-57-00 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-57-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-57-00 @MBExp.py:227][0m Rewards obtained: [276.24263372290375], Lows: [0], Highs: [0], Total time: 2240.23095
[32m[0906 14-58-41 @MBExp.py:144][0m ####################################################################
[32m[0906 14-58-41 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 14-58-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01961, current rewards: 1.14129, mean: 0.11413
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01925, current rewards: 6.62592, mean: 0.11043
[32m[0906 14-58-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01924, current rewards: 12.12044, mean: 0.11019
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01922, current rewards: 17.61691, mean: 0.11011
[32m[0906 14-58-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 23.11300, mean: 0.11006
[32m[0906 14-58-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 28.61031, mean: 0.11004
[32m[0906 14-58-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.10694, mean: 0.11002
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.58546, mean: 0.10996
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.08530, mean: 0.10996
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.59161, mean: 0.10998
[32m[0906 14-58-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 56.09579, mean: 0.10999
[32m[0906 14-58-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 61.60605, mean: 0.11001
[32m[0906 14-58-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 67.11477, mean: 0.11002
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 72.62900, mean: 0.11004
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 78.14415, mean: 0.11006
[32m[0906 14-58-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 83.64529, mean: 0.11006
[32m[0906 14-58-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 89.15649, mean: 0.11007
[32m[0906 14-58-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 94.67372, mean: 0.11009
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.19183, mean: 0.11010
[32m[0906 14-58-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 105.71225, mean: 0.11012
[32m[0906 14-59-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 111.19640, mean: 0.11010
[32m[0906 14-59-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01920, current rewards: 116.69610, mean: 0.11009
[32m[0906 14-59-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 122.19457, mean: 0.11009
[32m[0906 14-59-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 127.69762, mean: 0.11008
[32m[0906 14-59-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 133.24840, mean: 0.11012
[32m[0906 14-59-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 139.60741, mean: 0.11080
[32m[0906 14-59-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: 146.53407, mean: 0.11186
[32m[0906 14-59-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 153.46073, mean: 0.11284
[32m[0906 14-59-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 160.38739, mean: 0.11375
[32m[0906 14-59-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01914, current rewards: 118.35712, mean: 0.08107
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01915, current rewards: 68.35712, mean: 0.04527
[32m[0906 14-59-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 18.35712, mean: 0.01177
[32m[0906 14-59-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01915, current rewards: -31.64288, mean: -0.01965
[32m[0906 14-59-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: -81.64288, mean: -0.04918
[32m[0906 14-59-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01916, current rewards: -131.64288, mean: -0.07698
[32m[0906 14-59-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01916, current rewards: -181.64288, mean: -0.10321
[32m[0906 14-59-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: -231.64288, mean: -0.12798
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01917, current rewards: -277.24311, mean: -0.14906
[32m[0906 14-59-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01917, current rewards: -271.75012, mean: -0.14228
[32m[0906 14-59-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01917, current rewards: -266.23855, mean: -0.13584
[32m[0906 14-59-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: -260.72228, mean: -0.12971
[32m[0906 14-59-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: -255.20900, mean: -0.12389
[32m[0906 14-59-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: -249.68901, mean: -0.11834
[32m[0906 14-59-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: -244.17071, mean: -0.11304
[32m[0906 14-59-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01918, current rewards: -238.65574, mean: -0.10799
[32m[0906 14-59-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: -233.14055, mean: -0.10316
[32m[0906 14-59-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: -227.62329, mean: -0.09854
[32m[0906 14-59-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: -222.11138, mean: -0.09411
[32m[0906 14-59-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: -216.63135, mean: -0.08989
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01919, current rewards: -211.12506, mean: -0.08582
[32m[0906 14-59-29 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-59-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-59-29 @MBExp.py:227][0m Rewards obtained: [-206.71648717113007], Lows: [0], Highs: [439], Total time: 2288.924656
[32m[0906 15-01-12 @MBExp.py:144][0m ####################################################################
[32m[0906 15-01-12 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 15-01-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.41614, mean: 0.14161
[32m[0906 15-01-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.87908, mean: 0.11465
[32m[0906 15-01-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.41679, mean: 0.11288
[32m[0906 15-01-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.95826, mean: 0.11224
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.48861, mean: 0.11185
[32m[0906 15-01-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 29.02874, mean: 0.11165
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01929, current rewards: 34.56394, mean: 0.11150
[32m[0906 15-01-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01930, current rewards: 40.13162, mean: 0.11148
[32m[0906 15-01-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01928, current rewards: 45.65985, mean: 0.11137
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01929, current rewards: 51.19349, mean: 0.11129
[32m[0906 15-01-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01929, current rewards: 56.72916, mean: 0.11123
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01929, current rewards: 62.25938, mean: 0.11118
[32m[0906 15-01-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01927, current rewards: 67.78916, mean: 0.11113
[32m[0906 15-01-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: 73.32100, mean: 0.11109
[32m[0906 15-01-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01925, current rewards: 78.85519, mean: 0.11106
[32m[0906 15-01-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01925, current rewards: 84.38867, mean: 0.11104
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 89.90402, mean: 0.11099
[32m[0906 15-01-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01925, current rewards: 95.42873, mean: 0.11096
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 100.95296, mean: 0.11094
[32m[0906 15-01-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: 106.48396, mean: 0.11092
[32m[0906 15-01-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 112.01267, mean: 0.11090
[32m[0906 15-01-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01926, current rewards: 117.53737, mean: 0.11088
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01927, current rewards: 123.09045, mean: 0.11089
[32m[0906 15-01-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01927, current rewards: 128.56611, mean: 0.11083
[32m[0906 15-01-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01926, current rewards: 134.06151, mean: 0.11079
[32m[0906 15-01-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01927, current rewards: 139.56189, mean: 0.11076
[32m[0906 15-01-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01927, current rewards: 145.05230, mean: 0.11073
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01925, current rewards: 150.53806, mean: 0.11069
[32m[0906 15-01-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01923, current rewards: 156.02196, mean: 0.11065
[32m[0906 15-01-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01920, current rewards: 161.52064, mean: 0.11063
[32m[0906 15-01-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 167.00924, mean: 0.11060
[32m[0906 15-01-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 172.52029, mean: 0.11059
[32m[0906 15-01-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: 175.92222, mean: 0.10927
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01920, current rewards: 181.43348, mean: 0.10930
[32m[0906 15-01-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01920, current rewards: 186.94414, mean: 0.10932
[32m[0906 15-01-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01920, current rewards: 192.45761, mean: 0.10935
[32m[0906 15-01-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 197.96795, mean: 0.10937
[32m[0906 15-01-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01920, current rewards: 203.48043, mean: 0.10940
[32m[0906 15-01-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 208.95909, mean: 0.10940
[32m[0906 15-01-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: 214.43980, mean: 0.10941
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01920, current rewards: 219.96996, mean: 0.10944
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 225.49866, mean: 0.10947
[32m[0906 15-01-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01920, current rewards: 231.02684, mean: 0.10949
[32m[0906 15-01-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01920, current rewards: 236.54941, mean: 0.10951
[32m[0906 15-01-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 242.07555, mean: 0.10954
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 247.60598, mean: 0.10956
[32m[0906 15-01-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01921, current rewards: 253.13663, mean: 0.10958
[32m[0906 15-01-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01921, current rewards: 258.67427, mean: 0.10961
[32m[0906 15-01-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: 264.20551, mean: 0.10963
[32m[0906 15-02-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: 269.70846, mean: 0.10964
[32m[0906 15-02-01 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-02-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-02-01 @MBExp.py:227][0m Rewards obtained: [274.1147245349673], Lows: [1], Highs: [0], Total time: 2337.677068
[32m[0906 15-03-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-03-46 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-03-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01906, current rewards: 1.06058, mean: 0.10606
[32m[0906 15-03-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01921, current rewards: 6.57834, mean: 0.10964
[32m[0906 15-03-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 12.09735, mean: 0.10998
[32m[0906 15-03-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01927, current rewards: 17.61268, mean: 0.11008
[32m[0906 15-03-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01924, current rewards: 23.13159, mean: 0.11015
[32m[0906 15-03-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01925, current rewards: 28.64446, mean: 0.11017
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.18632, mean: 0.11028
[32m[0906 15-03-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 39.70310, mean: 0.11029
[32m[0906 15-03-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 45.22100, mean: 0.11030
[32m[0906 15-03-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 49.63075, mean: 0.10789
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 55.16883, mean: 0.10817
[32m[0906 15-03-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 60.70581, mean: 0.10840
[32m[0906 15-03-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 66.23972, mean: 0.10859
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 71.77635, mean: 0.10875
[32m[0906 15-04-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 77.30396, mean: 0.10888
[32m[0906 15-04-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 82.84230, mean: 0.10900
[32m[0906 15-04-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01923, current rewards: 88.38781, mean: 0.10912
[32m[0906 15-04-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01923, current rewards: 93.93044, mean: 0.10922
[32m[0906 15-04-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 99.46971, mean: 0.10931
[32m[0906 15-04-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 105.00709, mean: 0.10938
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 110.55000, mean: 0.10946
[32m[0906 15-04-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 116.08836, mean: 0.10952
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 121.70003, mean: 0.10964
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 127.22786, mean: 0.10968
[32m[0906 15-04-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 132.77485, mean: 0.10973
[32m[0906 15-04-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01922, current rewards: 138.29392, mean: 0.10976
[32m[0906 15-04-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01922, current rewards: 143.81890, mean: 0.10979
[32m[0906 15-04-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01922, current rewards: 149.33826, mean: 0.10981
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01923, current rewards: 154.86291, mean: 0.10983
[32m[0906 15-04-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01921, current rewards: 160.38740, mean: 0.10985
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: 165.92123, mean: 0.10988
[32m[0906 15-04-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 171.44455, mean: 0.10990
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01917, current rewards: 176.96862, mean: 0.10992
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 182.49638, mean: 0.10994
[32m[0906 15-04-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01918, current rewards: 187.99551, mean: 0.10994
[32m[0906 15-04-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 193.51554, mean: 0.10995
[32m[0906 15-04-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: 199.03956, mean: 0.10997
[32m[0906 15-04-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01917, current rewards: 204.56090, mean: 0.10998
[32m[0906 15-04-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01917, current rewards: 210.03259, mean: 0.10996
[32m[0906 15-04-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01918, current rewards: 214.35720, mean: 0.10937
[32m[0906 15-04-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01918, current rewards: 219.87403, mean: 0.10939
[32m[0906 15-04-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01918, current rewards: 225.39404, mean: 0.10941
[32m[0906 15-04-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 230.91142, mean: 0.10944
[32m[0906 15-04-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01918, current rewards: 236.42672, mean: 0.10946
[32m[0906 15-04-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01919, current rewards: 241.94310, mean: 0.10948
[32m[0906 15-04-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01919, current rewards: 247.46485, mean: 0.10950
[32m[0906 15-04-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: 252.97967, mean: 0.10952
[32m[0906 15-04-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: 258.49805, mean: 0.10953
[32m[0906 15-04-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: 264.01758, mean: 0.10955
[32m[0906 15-04-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01920, current rewards: 269.53892, mean: 0.10957
[32m[0906 15-04-35 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-04-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-04-35 @MBExp.py:227][0m Rewards obtained: [273.95506388555356], Lows: [0], Highs: [2], Total time: 2386.401517
[32m[0906 15-06-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-22 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01943, current rewards: 1.08397, mean: 0.10840
[32m[0906 15-06-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01924, current rewards: 6.63178, mean: 0.11053
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01926, current rewards: 12.17362, mean: 0.11067
[32m[0906 15-06-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01925, current rewards: 17.71591, mean: 0.11072
[32m[0906 15-06-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01923, current rewards: 23.25997, mean: 0.11076
[32m[0906 15-06-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 28.85047, mean: 0.11096
[32m[0906 15-06-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 34.40322, mean: 0.11098
[32m[0906 15-06-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01926, current rewards: 39.94720, mean: 0.11096
[32m[0906 15-06-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.49166, mean: 0.11096
[32m[0906 15-06-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01925, current rewards: 51.03160, mean: 0.11094
[32m[0906 15-06-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: 56.57435, mean: 0.11093
[32m[0906 15-06-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 62.11529, mean: 0.11092
[32m[0906 15-06-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 67.66216, mean: 0.11092
[32m[0906 15-06-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 73.16672, mean: 0.11086
[32m[0906 15-06-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: 78.71846, mean: 0.11087
[32m[0906 15-06-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 84.26582, mean: 0.11088
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01926, current rewards: 89.81525, mean: 0.11088
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01926, current rewards: 95.36230, mean: 0.11089
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01926, current rewards: 100.86710, mean: 0.11084
[32m[0906 15-06-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01926, current rewards: 106.42069, mean: 0.11085
[32m[0906 15-06-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01926, current rewards: 111.97299, mean: 0.11086
[32m[0906 15-06-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01925, current rewards: 117.49189, mean: 0.11084
[32m[0906 15-06-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 123.04222, mean: 0.11085
[32m[0906 15-06-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: 128.59178, mean: 0.11085
[32m[0906 15-06-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01925, current rewards: 134.14183, mean: 0.11086
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01925, current rewards: 139.68740, mean: 0.11086
[32m[0906 15-06-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01925, current rewards: 145.23284, mean: 0.11086
[32m[0906 15-06-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01925, current rewards: 150.78152, mean: 0.11087
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01925, current rewards: 156.32984, mean: 0.11087
[32m[0906 15-06-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01925, current rewards: 161.87154, mean: 0.11087
[32m[0906 15-06-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01924, current rewards: 167.41685, mean: 0.11087
[32m[0906 15-06-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01922, current rewards: 172.96413, mean: 0.11087
[32m[0906 15-06-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01921, current rewards: 178.50872, mean: 0.11087
[32m[0906 15-06-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: 184.05150, mean: 0.11087
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: 189.59352, mean: 0.11087
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01919, current rewards: 195.14260, mean: 0.11088
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 200.69017, mean: 0.11088
[32m[0906 15-06-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: 206.21225, mean: 0.11087
[32m[0906 15-06-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01919, current rewards: 211.75889, mean: 0.11087
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01919, current rewards: 217.30828, mean: 0.11087
[32m[0906 15-07-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01920, current rewards: 222.82581, mean: 0.11086
[32m[0906 15-07-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 228.31660, mean: 0.11083
[32m[0906 15-07-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01920, current rewards: 233.80700, mean: 0.11081
[32m[0906 15-07-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01920, current rewards: 239.29913, mean: 0.11079
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 244.78789, mean: 0.11076
[32m[0906 15-07-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: 250.30415, mean: 0.11075
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01920, current rewards: 256.11273, mean: 0.11087
[32m[0906 15-07-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01921, current rewards: 261.83987, mean: 0.11095
[32m[0906 15-07-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: 267.56643, mean: 0.11102
[32m[0906 15-07-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: 273.08298, mean: 0.11101
[32m[0906 15-07-10 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-07-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-07-10 @MBExp.py:227][0m Rewards obtained: [277.53517922286755], Lows: [0], Highs: [0], Total time: 2435.136565
[32m[0906 15-08-59 @MBExp.py:144][0m ####################################################################
[32m[0906 15-08-59 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01853, current rewards: 1.94065, mean: 0.19407
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01907, current rewards: 7.46294, mean: 0.12438
[32m[0906 15-09-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.98620, mean: 0.11806
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 18.50606, mean: 0.11566
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 24.05146, mean: 0.11453
[32m[0906 15-09-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 29.57404, mean: 0.11375
[32m[0906 15-09-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: 35.09799, mean: 0.11322
[32m[0906 15-09-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 40.61988, mean: 0.11283
[32m[0906 15-09-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 46.14185, mean: 0.11254
[32m[0906 15-09-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.74531, mean: 0.11249
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 57.26863, mean: 0.11229
[32m[0906 15-09-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 62.79521, mean: 0.11213
[32m[0906 15-09-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 68.29273, mean: 0.11196
[32m[0906 15-09-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 73.81454, mean: 0.11184
[32m[0906 15-09-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 79.33403, mean: 0.11174
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 84.85452, mean: 0.11165
[32m[0906 15-09-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 90.34067, mean: 0.11153
[32m[0906 15-09-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 95.82308, mean: 0.11142
[32m[0906 15-09-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: 101.30747, mean: 0.11133
[32m[0906 15-09-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 106.79500, mean: 0.11124
[32m[0906 15-09-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 112.32049, mean: 0.11121
[32m[0906 15-09-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 117.81035, mean: 0.11114
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 123.29710, mean: 0.11108
[32m[0906 15-09-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 128.78603, mean: 0.11102
[32m[0906 15-09-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: 134.27478, mean: 0.11097
[32m[0906 15-09-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01921, current rewards: 139.74330, mean: 0.11091
[32m[0906 15-09-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 145.27602, mean: 0.11090
[32m[0906 15-09-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 150.80233, mean: 0.11088
[32m[0906 15-09-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 156.28838, mean: 0.11084
[32m[0906 15-09-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01921, current rewards: 161.74822, mean: 0.11079
[32m[0906 15-09-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01920, current rewards: 167.28273, mean: 0.11078
[32m[0906 15-09-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01920, current rewards: 172.81913, mean: 0.11078
[32m[0906 15-09-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 178.35110, mean: 0.11078
[32m[0906 15-09-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: 183.88305, mean: 0.11077
[32m[0906 15-09-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 189.42535, mean: 0.11078
[32m[0906 15-09-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01914, current rewards: 194.96226, mean: 0.11077
[32m[0906 15-09-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01914, current rewards: 200.49724, mean: 0.11077
[32m[0906 15-09-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: 206.03544, mean: 0.11077
[32m[0906 15-09-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 211.54253, mean: 0.11076
[32m[0906 15-09-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 217.07906, mean: 0.11075
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 222.61538, mean: 0.11075
[32m[0906 15-09-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 228.15272, mean: 0.11075
[32m[0906 15-09-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 233.68463, mean: 0.11075
[32m[0906 15-09-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 239.22099, mean: 0.11075
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 244.75899, mean: 0.11075
[32m[0906 15-09-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 250.26578, mean: 0.11074
[32m[0906 15-09-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 255.75888, mean: 0.11072
[32m[0906 15-09-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: 261.24702, mean: 0.11070
[32m[0906 15-09-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 266.73479, mean: 0.11068
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 272.22237, mean: 0.11066
[32m[0906 15-09-48 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-09-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-09-48 @MBExp.py:227][0m Rewards obtained: [276.6144986305075], Lows: [0], Highs: [0], Total time: 2483.7578449999996
[32m[0906 15-11-39 @MBExp.py:144][0m ####################################################################
[32m[0906 15-11-39 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-11-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.16135, mean: 0.11614
[32m[0906 15-11-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 6.73227, mean: 0.11220
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 12.28153, mean: 0.11165
[32m[0906 15-11-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01919, current rewards: 17.82067, mean: 0.11138
[32m[0906 15-11-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 23.36762, mean: 0.11127
[32m[0906 15-11-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01921, current rewards: 28.91085, mean: 0.11120
[32m[0906 15-11-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.48756, mean: 0.11125
[32m[0906 15-11-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01923, current rewards: 40.05962, mean: 0.11128
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 45.63867, mean: 0.11131
[32m[0906 15-11-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 51.21349, mean: 0.11133
[32m[0906 15-11-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 57.53873, mean: 0.11282
[32m[0906 15-11-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 64.96823, mean: 0.11601
[32m[0906 15-11-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 71.01349, mean: 0.11642
[32m[0906 15-11-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 77.05876, mean: 0.11676
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 83.10402, mean: 0.11705
[32m[0906 15-11-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 34.22493, mean: 0.04503
[32m[0906 15-11-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: -15.77507, mean: -0.01948
[32m[0906 15-11-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: -65.77507, mean: -0.07648
[32m[0906 15-11-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: -115.77507, mean: -0.12723
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01920, current rewards: -165.77507, mean: -0.17268
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: -183.56986, mean: -0.18175
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01918, current rewards: -177.99178, mean: -0.16792
[32m[0906 15-12-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: -172.41103, mean: -0.15533
[32m[0906 15-12-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: -166.83144, mean: -0.14382
[32m[0906 15-12-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: -161.25124, mean: -0.13327
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: -155.66832, mean: -0.12355
[32m[0906 15-12-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: -150.08251, mean: -0.11457
[32m[0906 15-12-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: -144.50288, mean: -0.10625
[32m[0906 15-12-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: -138.84356, mean: -0.09847
[32m[0906 15-12-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: -133.24587, mean: -0.09126
[32m[0906 15-12-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: -127.64721, mean: -0.08453
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: -122.05423, mean: -0.07824
[32m[0906 15-12-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01920, current rewards: -116.45758, mean: -0.07233
[32m[0906 15-12-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: -113.02570, mean: -0.06809
[32m[0906 15-12-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01916, current rewards: -107.48728, mean: -0.06286
[32m[0906 15-12-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: -101.95201, mean: -0.05793
[32m[0906 15-12-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01914, current rewards: -96.42732, mean: -0.05327
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: -90.89040, mean: -0.04887
[32m[0906 15-12-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: -85.35521, mean: -0.04469
[32m[0906 15-12-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: -79.85937, mean: -0.04074
[32m[0906 15-12-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: -74.28648, mean: -0.03696
[32m[0906 15-12-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: -68.70889, mean: -0.03335
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: -63.13418, mean: -0.02992
[32m[0906 15-12-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: -57.55779, mean: -0.02665
[32m[0906 15-12-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: -51.98513, mean: -0.02352
[32m[0906 15-12-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: -46.40914, mean: -0.02054
[32m[0906 15-12-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01916, current rewards: -40.83383, mean: -0.01768
[32m[0906 15-12-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: -35.26218, mean: -0.01494
[32m[0906 15-12-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: -29.68545, mean: -0.01232
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: -24.10022, mean: -0.00980
[32m[0906 15-12-27 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-12-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-12-27 @MBExp.py:227][0m Rewards obtained: [-19.62365060867901], Lows: [1], Highs: [270], Total time: 2532.3855879999996
[32m[0906 15-14-20 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-20 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-14-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01924, current rewards: 1.32011, mean: 0.13201
[32m[0906 15-14-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01923, current rewards: 6.86026, mean: 0.11434
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.39874, mean: 0.11272
[32m[0906 15-14-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.90905, mean: 0.11193
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.45271, mean: 0.11168
[32m[0906 15-14-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 28.99772, mean: 0.11153
[32m[0906 15-14-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.63244, mean: 0.11172
[32m[0906 15-14-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 40.13368, mean: 0.11148
[32m[0906 15-14-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.63392, mean: 0.11130
[32m[0906 15-14-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.13198, mean: 0.11116
[32m[0906 15-14-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.63286, mean: 0.11104
[32m[0906 15-14-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 62.10232, mean: 0.11090
[32m[0906 15-14-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 67.59642, mean: 0.11081
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 72.02568, mean: 0.10913
[32m[0906 15-14-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 77.55999, mean: 0.10924
[32m[0906 15-14-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 83.09585, mean: 0.10934
[32m[0906 15-14-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 88.62849, mean: 0.10942
[32m[0906 15-14-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 94.16587, mean: 0.10950
[32m[0906 15-14-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 99.69912, mean: 0.10956
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 105.26316, mean: 0.10965
[32m[0906 15-14-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01917, current rewards: 110.79360, mean: 0.10970
[32m[0906 15-14-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 116.33016, mean: 0.10975
[32m[0906 15-14-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 121.86556, mean: 0.10979
[32m[0906 15-14-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: 127.35608, mean: 0.10979
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 132.89442, mean: 0.10983
[32m[0906 15-14-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: 138.43439, mean: 0.10987
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 143.97759, mean: 0.10991
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: 149.46653, mean: 0.10990
[32m[0906 15-14-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 154.98861, mean: 0.10992
[32m[0906 15-14-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 160.50809, mean: 0.10994
[32m[0906 15-14-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 166.02679, mean: 0.10995
[32m[0906 15-14-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 171.54985, mean: 0.10997
[32m[0906 15-14-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: 177.07103, mean: 0.10998
[32m[0906 15-14-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: 182.60357, mean: 0.11000
[32m[0906 15-14-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: 188.14455, mean: 0.11003
[32m[0906 15-14-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 193.73235, mean: 0.11008
[32m[0906 15-14-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01916, current rewards: 199.26149, mean: 0.11009
[32m[0906 15-14-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: 204.78817, mean: 0.11010
[32m[0906 15-14-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 210.31535, mean: 0.11011
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01912, current rewards: 215.84035, mean: 0.11012
[32m[0906 15-14-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01911, current rewards: 221.38975, mean: 0.11014
[32m[0906 15-15-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 226.93670, mean: 0.11016
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: 232.48208, mean: 0.11018
[32m[0906 15-15-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01913, current rewards: 238.00955, mean: 0.11019
[32m[0906 15-15-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 243.51894, mean: 0.11019
[32m[0906 15-15-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: 249.06807, mean: 0.11021
[32m[0906 15-15-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 254.62067, mean: 0.11023
[32m[0906 15-15-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 260.17809, mean: 0.11024
[32m[0906 15-15-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 265.73191, mean: 0.11026
[32m[0906 15-15-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 271.28795, mean: 0.11028
[32m[0906 15-15-09 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-15-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-15-09 @MBExp.py:227][0m Rewards obtained: [275.7331403601039], Lows: [0], Highs: [1], Total time: 2580.960428
[32m[0906 15-17-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-17-03 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-17-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01956, current rewards: 1.22103, mean: 0.12210
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01941, current rewards: 6.80731, mean: 0.11346
[32m[0906 15-17-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01934, current rewards: 12.29299, mean: 0.11175
[32m[0906 15-17-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 17.84080, mean: 0.11150
[32m[0906 15-17-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01926, current rewards: 23.39283, mean: 0.11139
[32m[0906 15-17-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01924, current rewards: 28.94499, mean: 0.11133
[32m[0906 15-17-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 34.48303, mean: 0.11124
[32m[0906 15-17-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01927, current rewards: 40.03968, mean: 0.11122
[32m[0906 15-17-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01927, current rewards: 45.58945, mean: 0.11119
[32m[0906 15-17-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01927, current rewards: 51.14528, mean: 0.11119
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01927, current rewards: 56.69773, mean: 0.11117
[32m[0906 15-17-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: 62.28473, mean: 0.11122
[32m[0906 15-17-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 67.90116, mean: 0.11131
[32m[0906 15-17-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01927, current rewards: 73.49636, mean: 0.11136
[32m[0906 15-17-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01927, current rewards: 79.09295, mean: 0.11140
[32m[0906 15-17-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01926, current rewards: 84.68847, mean: 0.11143
[32m[0906 15-17-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01925, current rewards: 90.28567, mean: 0.11146
[32m[0906 15-17-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01924, current rewards: 95.88415, mean: 0.11149
[32m[0906 15-17-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01924, current rewards: 101.47833, mean: 0.11151
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01925, current rewards: 107.01011, mean: 0.11147
[32m[0906 15-17-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 112.57218, mean: 0.11146
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01925, current rewards: 118.13945, mean: 0.11145
[32m[0906 15-17-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01925, current rewards: 123.70219, mean: 0.11144
[32m[0906 15-17-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: 129.27049, mean: 0.11144
[32m[0906 15-17-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01925, current rewards: 134.83793, mean: 0.11144
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01925, current rewards: 140.34710, mean: 0.11139
[32m[0906 15-17-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01925, current rewards: 145.88228, mean: 0.11136
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01925, current rewards: 151.34669, mean: 0.11128
[32m[0906 15-17-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01924, current rewards: 156.85105, mean: 0.11124
[32m[0906 15-17-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 162.36567, mean: 0.11121
[32m[0906 15-17-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01925, current rewards: 167.87776, mean: 0.11118
[32m[0906 15-17-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01925, current rewards: 173.39097, mean: 0.11115
[32m[0906 15-17-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01925, current rewards: 178.90560, mean: 0.11112
[32m[0906 15-17-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01926, current rewards: 184.41931, mean: 0.11110
[32m[0906 15-17-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01926, current rewards: 189.93025, mean: 0.11107
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01926, current rewards: 195.49448, mean: 0.11108
[32m[0906 15-17-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01926, current rewards: 201.02533, mean: 0.11106
[32m[0906 15-17-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01925, current rewards: 206.56828, mean: 0.11106
[32m[0906 15-17-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01924, current rewards: 212.12593, mean: 0.11106
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01923, current rewards: 217.67646, mean: 0.11106
[32m[0906 15-17-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01921, current rewards: 223.22959, mean: 0.11106
[32m[0906 15-17-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 228.78237, mean: 0.11106
[32m[0906 15-17-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01920, current rewards: 234.33599, mean: 0.11106
[32m[0906 15-17-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01920, current rewards: 239.92994, mean: 0.11108
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 245.48839, mean: 0.11108
[32m[0906 15-17-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: 251.04801, mean: 0.11108
[32m[0906 15-17-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: 256.60423, mean: 0.11108
[32m[0906 15-17-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: 262.17079, mean: 0.11109
[32m[0906 15-17-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01919, current rewards: 267.73090, mean: 0.11109
[32m[0906 15-17-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01920, current rewards: 273.29440, mean: 0.11110
[32m[0906 15-17-52 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-17-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-17-52 @MBExp.py:227][0m Rewards obtained: [277.7443606554162], Lows: [0], Highs: [0], Total time: 2629.67638
[32m[0906 15-19-48 @MBExp.py:144][0m ####################################################################
[32m[0906 15-19-48 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: -1.04626, mean: -0.10463
[32m[0906 15-19-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 4.47651, mean: 0.07461
[32m[0906 15-19-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01922, current rewards: 9.97303, mean: 0.09066
[32m[0906 15-19-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01922, current rewards: 15.50984, mean: 0.09694
[32m[0906 15-19-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01922, current rewards: 21.05147, mean: 0.10025
[32m[0906 15-19-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 26.55143, mean: 0.10212
[32m[0906 15-19-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 32.08242, mean: 0.10349
[32m[0906 15-19-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 37.61224, mean: 0.10448
[32m[0906 15-19-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 43.14712, mean: 0.10524
[32m[0906 15-19-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 48.68507, mean: 0.10584
[32m[0906 15-19-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 54.20143, mean: 0.10628
[32m[0906 15-19-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 59.73450, mean: 0.10667
[32m[0906 15-20-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 65.26811, mean: 0.10700
[32m[0906 15-20-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 70.80532, mean: 0.10728
[32m[0906 15-20-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 76.34016, mean: 0.10752
[32m[0906 15-20-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 81.87872, mean: 0.10774
[32m[0906 15-20-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 87.41399, mean: 0.10792
[32m[0906 15-20-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 92.94883, mean: 0.10808
[32m[0906 15-20-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 98.50515, mean: 0.10825
[32m[0906 15-20-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 104.04442, mean: 0.10838
[32m[0906 15-20-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 109.58964, mean: 0.10850
[32m[0906 15-20-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 115.13202, mean: 0.10862
[32m[0906 15-20-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 120.67575, mean: 0.10872
[32m[0906 15-20-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 126.22056, mean: 0.10881
[32m[0906 15-20-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 131.75535, mean: 0.10889
[32m[0906 15-20-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 137.30147, mean: 0.10897
[32m[0906 15-20-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 142.90079, mean: 0.10908
[32m[0906 15-20-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 148.44817, mean: 0.10915
[32m[0906 15-20-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 153.98206, mean: 0.10921
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 159.41132, mean: 0.10919
[32m[0906 15-20-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 164.83174, mean: 0.10916
[32m[0906 15-20-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 170.26400, mean: 0.10914
[32m[0906 15-20-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01917, current rewards: 175.69162, mean: 0.10913
[32m[0906 15-20-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01917, current rewards: 181.50798, mean: 0.10934
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01916, current rewards: 188.85013, mean: 0.11044
[32m[0906 15-20-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01916, current rewards: 193.52159, mean: 0.10996
[32m[0906 15-20-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01916, current rewards: 198.85687, mean: 0.10987
[32m[0906 15-20-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01916, current rewards: 204.19089, mean: 0.10978
[32m[0906 15-20-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 209.52353, mean: 0.10970
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 214.86054, mean: 0.10962
[32m[0906 15-20-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 220.19205, mean: 0.10955
[32m[0906 15-20-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01911, current rewards: 225.52830, mean: 0.10948
[32m[0906 15-20-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01910, current rewards: 230.86362, mean: 0.10941
[32m[0906 15-20-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 236.36988, mean: 0.10943
[32m[0906 15-20-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 241.77949, mean: 0.10940
[32m[0906 15-20-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 244.99189, mean: 0.10840
[32m[0906 15-20-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: 250.47419, mean: 0.10843
[32m[0906 15-20-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 255.95315, mean: 0.10845
[32m[0906 15-20-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 261.43424, mean: 0.10848
[32m[0906 15-20-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: 266.91495, mean: 0.10850
[32m[0906 15-20-37 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-20-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-20-37 @MBExp.py:227][0m Rewards obtained: [271.297922387823], Lows: [2], Highs: [2], Total time: 2678.1648929999997
[32m[0906 15-22-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-22-36 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-22-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01898, current rewards: 1.15169, mean: 0.11517
[32m[0906 15-22-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01924, current rewards: 6.68259, mean: 0.11138
[32m[0906 15-22-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.23643, mean: 0.11124
[32m[0906 15-22-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.75914, mean: 0.11099
[32m[0906 15-22-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.28141, mean: 0.11086
[32m[0906 15-22-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 28.79922, mean: 0.11077
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 34.32413, mean: 0.11072
[32m[0906 15-22-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 39.84708, mean: 0.11069
[32m[0906 15-22-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 45.36945, mean: 0.11066
[32m[0906 15-22-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 51.19854, mean: 0.11130
[32m[0906 15-22-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.70046, mean: 0.11118
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.37942, mean: 0.11139
[32m[0906 15-22-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 68.05877, mean: 0.11157
[32m[0906 15-22-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 73.73884, mean: 0.11173
[32m[0906 15-22-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 79.42102, mean: 0.11186
[32m[0906 15-22-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 85.09959, mean: 0.11197
[32m[0906 15-22-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 90.78066, mean: 0.11207
[32m[0906 15-22-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 96.45992, mean: 0.11216
[32m[0906 15-22-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 101.02683, mean: 0.11102
[32m[0906 15-22-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 106.64059, mean: 0.11108
[32m[0906 15-22-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 112.26179, mean: 0.11115
[32m[0906 15-22-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 117.89161, mean: 0.11122
[32m[0906 15-22-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 123.62523, mean: 0.11137
[32m[0906 15-22-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: 129.10930, mean: 0.11130
[32m[0906 15-22-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 134.59180, mean: 0.11123
[32m[0906 15-23-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 140.07846, mean: 0.11117
[32m[0906 15-23-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 145.49123, mean: 0.11106
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 151.03236, mean: 0.11105
[32m[0906 15-23-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 156.57827, mean: 0.11105
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 162.12140, mean: 0.11104
[32m[0906 15-23-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 167.66481, mean: 0.11104
[32m[0906 15-23-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 173.22538, mean: 0.11104
[32m[0906 15-23-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01917, current rewards: 178.77745, mean: 0.11104
[32m[0906 15-23-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01917, current rewards: 184.33183, mean: 0.11104
[32m[0906 15-23-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 189.94104, mean: 0.11108
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01917, current rewards: 195.45783, mean: 0.11106
[32m[0906 15-23-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: 200.94553, mean: 0.11102
[32m[0906 15-23-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 206.43928, mean: 0.11099
[32m[0906 15-23-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01918, current rewards: 211.92607, mean: 0.11096
[32m[0906 15-23-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01918, current rewards: 217.41342, mean: 0.11093
[32m[0906 15-23-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 222.90009, mean: 0.11090
[32m[0906 15-23-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 228.38923, mean: 0.11087
[32m[0906 15-23-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01916, current rewards: 233.87259, mean: 0.11084
[32m[0906 15-23-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 239.43115, mean: 0.11085
[32m[0906 15-23-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01913, current rewards: 244.95575, mean: 0.11084
[32m[0906 15-23-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 250.47702, mean: 0.11083
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01911, current rewards: 256.00481, mean: 0.11082
[32m[0906 15-23-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 261.52947, mean: 0.11082
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 267.05559, mean: 0.11081
[32m[0906 15-23-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 272.58426, mean: 0.11081
[32m[0906 15-23-24 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-23-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-23-24 @MBExp.py:227][0m Rewards obtained: [277.0077906269238], Lows: [0], Highs: [1], Total time: 2726.6875569999997
[32m[0906 15-25-25 @MBExp.py:144][0m ####################################################################
[32m[0906 15-25-25 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-25-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.08839, mean: 0.10884
[32m[0906 15-25-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 6.59217, mean: 0.10987
[32m[0906 15-25-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 12.15438, mean: 0.11049
[32m[0906 15-25-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.71674, mean: 0.11073
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 23.27957, mean: 0.11086
[32m[0906 15-25-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 28.84993, mean: 0.11096
[32m[0906 15-25-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.41677, mean: 0.11102
[32m[0906 15-25-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 39.97764, mean: 0.11105
[32m[0906 15-25-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.53691, mean: 0.11107
[32m[0906 15-25-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.19881, mean: 0.11130
[32m[0906 15-25-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 57.02054, mean: 0.11180
[32m[0906 15-25-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 62.60868, mean: 0.11180
[32m[0906 15-25-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 68.19665, mean: 0.11180
[32m[0906 15-25-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 72.56073, mean: 0.10994
[32m[0906 15-25-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.03934, mean: 0.10991
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 83.52287, mean: 0.10990
[32m[0906 15-25-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 89.00567, mean: 0.10988
[32m[0906 15-25-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 94.48501, mean: 0.10987
[32m[0906 15-25-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 99.90555, mean: 0.10979
[32m[0906 15-25-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 105.36784, mean: 0.10976
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 110.83219, mean: 0.10973
[32m[0906 15-25-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01918, current rewards: 116.29833, mean: 0.10972
[32m[0906 15-25-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01918, current rewards: 121.79945, mean: 0.10973
[32m[0906 15-25-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 127.35885, mean: 0.10979
[32m[0906 15-25-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: 132.91631, mean: 0.10985
[32m[0906 15-25-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: 138.48170, mean: 0.10991
[32m[0906 15-25-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 144.01970, mean: 0.10994
[32m[0906 15-25-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: 149.58388, mean: 0.10999
[32m[0906 15-25-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 155.14784, mean: 0.11003
[32m[0906 15-25-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 160.71227, mean: 0.11008
[32m[0906 15-25-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: 166.28039, mean: 0.11012
[32m[0906 15-25-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 171.84321, mean: 0.11016
[32m[0906 15-25-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01919, current rewards: 177.41163, mean: 0.11019
[32m[0906 15-25-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: 182.96774, mean: 0.11022
[32m[0906 15-25-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01920, current rewards: 188.62064, mean: 0.11030
[32m[0906 15-25-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01920, current rewards: 194.18012, mean: 0.11033
[32m[0906 15-26-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: 199.74265, mean: 0.11036
[32m[0906 15-26-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01920, current rewards: 205.29720, mean: 0.11037
[32m[0906 15-26-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 210.86156, mean: 0.11040
[32m[0906 15-26-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: 216.42562, mean: 0.11042
[32m[0906 15-26-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01921, current rewards: 221.98486, mean: 0.11044
[32m[0906 15-26-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: 227.55080, mean: 0.11046
[32m[0906 15-26-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01921, current rewards: 233.07501, mean: 0.11046
[32m[0906 15-26-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: 238.52130, mean: 0.11043
[32m[0906 15-26-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01918, current rewards: 244.03271, mean: 0.11042
[32m[0906 15-26-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01917, current rewards: 249.55546, mean: 0.11042
[32m[0906 15-26-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01916, current rewards: 255.06900, mean: 0.11042
[32m[0906 15-26-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 260.58589, mean: 0.11042
[32m[0906 15-26-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 266.08832, mean: 0.11041
[32m[0906 15-26-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 271.54432, mean: 0.11038
[32m[0906 15-26-13 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-26-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-26-13 @MBExp.py:227][0m Rewards obtained: [275.91284819212837], Lows: [0], Highs: [1], Total time: 2775.26471
[32m[0906 15-28-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-28-16 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-28-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01873, current rewards: 1.73057, mean: 0.17306
[32m[0906 15-28-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 9.79258, mean: 0.16321
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 17.86687, mean: 0.16243
[32m[0906 15-28-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 25.94115, mean: 0.16213
[32m[0906 15-28-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 18.49990, mean: 0.08809
[32m[0906 15-28-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 24.02477, mean: 0.09240
[32m[0906 15-28-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 29.55332, mean: 0.09533
[32m[0906 15-28-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: 35.08104, mean: 0.09745
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 40.60683, mean: 0.09904
[32m[0906 15-28-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 46.01932, mean: 0.10004
[32m[0906 15-28-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 51.47888, mean: 0.10094
[32m[0906 15-28-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 56.98588, mean: 0.10176
[32m[0906 15-28-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 62.48576, mean: 0.10244
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 67.99728, mean: 0.10303
[32m[0906 15-28-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 73.50575, mean: 0.10353
[32m[0906 15-28-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 79.00824, mean: 0.10396
[32m[0906 15-28-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 84.48560, mean: 0.10430
[32m[0906 15-28-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 89.99786, mean: 0.10465
[32m[0906 15-28-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 95.58233, mean: 0.10504
[32m[0906 15-28-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01920, current rewards: 101.10170, mean: 0.10531
[32m[0906 15-28-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 106.62542, mean: 0.10557
[32m[0906 15-28-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 112.14627, mean: 0.10580
[32m[0906 15-28-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 117.67108, mean: 0.10601
[32m[0906 15-28-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 123.19382, mean: 0.10620
[32m[0906 15-28-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 128.72015, mean: 0.10638
[32m[0906 15-28-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 134.23729, mean: 0.10654
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01920, current rewards: 139.69033, mean: 0.10663
[32m[0906 15-28-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 145.20077, mean: 0.10677
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 148.59298, mean: 0.10539
[32m[0906 15-28-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01920, current rewards: 154.10607, mean: 0.10555
[32m[0906 15-28-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01921, current rewards: 159.62571, mean: 0.10571
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01921, current rewards: 165.14073, mean: 0.10586
[32m[0906 15-28-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01921, current rewards: 170.66147, mean: 0.10600
[32m[0906 15-28-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01921, current rewards: 176.17481, mean: 0.10613
[32m[0906 15-28-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01921, current rewards: 181.72804, mean: 0.10627
[32m[0906 15-28-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01921, current rewards: 187.24303, mean: 0.10639
[32m[0906 15-28-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01922, current rewards: 192.76043, mean: 0.10650
[32m[0906 15-28-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01922, current rewards: 198.27706, mean: 0.10660
[32m[0906 15-28-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01923, current rewards: 203.80137, mean: 0.10670
[32m[0906 15-28-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01922, current rewards: 209.31936, mean: 0.10680
[32m[0906 15-28-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01922, current rewards: 214.83557, mean: 0.10688
[32m[0906 15-28-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01922, current rewards: 220.35343, mean: 0.10697
[32m[0906 15-28-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01922, current rewards: 225.87549, mean: 0.10705
[32m[0906 15-28-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01922, current rewards: 231.39737, mean: 0.10713
[32m[0906 15-28-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01922, current rewards: 236.91610, mean: 0.10720
[32m[0906 15-29-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: 242.43033, mean: 0.10727
[32m[0906 15-29-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: 247.97634, mean: 0.10735
[32m[0906 15-29-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: 253.52451, mean: 0.10743
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01917, current rewards: 259.07140, mean: 0.10750
[32m[0906 15-29-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 264.61658, mean: 0.10757
[32m[0906 15-29-04 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-29-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-29-04 @MBExp.py:227][0m Rewards obtained: [269.0556453856057], Lows: [1], Highs: [13], Total time: 2823.879556
[32m[0906 15-31-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-31-09 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: 1.70620, mean: 0.17062
[32m[0906 15-31-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 7.13719, mean: 0.11895
[32m[0906 15-31-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.67258, mean: 0.11521
[32m[0906 15-31-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 18.21354, mean: 0.11383
[32m[0906 15-31-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01911, current rewards: 23.75699, mean: 0.11313
[32m[0906 15-31-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 29.29536, mean: 0.11267
[32m[0906 15-31-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.83614, mean: 0.11237
[32m[0906 15-31-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 40.37668, mean: 0.11216
[32m[0906 15-31-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.91556, mean: 0.11199
[32m[0906 15-31-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.64798, mean: 0.11228
[32m[0906 15-31-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 57.20132, mean: 0.11216
[32m[0906 15-31-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 62.75342, mean: 0.11206
[32m[0906 15-31-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 68.30478, mean: 0.11198
[32m[0906 15-31-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 73.86038, mean: 0.11191
[32m[0906 15-31-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 79.41056, mean: 0.11185
[32m[0906 15-31-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 84.96563, mean: 0.11180
[32m[0906 15-31-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 90.52290, mean: 0.11176
[32m[0906 15-31-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 96.07569, mean: 0.11172
[32m[0906 15-31-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01922, current rewards: 101.54788, mean: 0.11159
[32m[0906 15-31-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 107.67974, mean: 0.11217
[32m[0906 15-31-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 113.25753, mean: 0.11214
[32m[0906 15-31-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 118.83274, mean: 0.11211
[32m[0906 15-31-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01920, current rewards: 124.41412, mean: 0.11208
[32m[0906 15-31-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 129.99603, mean: 0.11207
[32m[0906 15-31-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: 135.57214, mean: 0.11204
[32m[0906 15-31-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 141.15040, mean: 0.11202
[32m[0906 15-31-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01920, current rewards: 146.77369, mean: 0.11204
[32m[0906 15-31-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 152.33966, mean: 0.11201
[32m[0906 15-31-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01921, current rewards: 157.90563, mean: 0.11199
[32m[0906 15-31-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01921, current rewards: 163.44555, mean: 0.11195
[32m[0906 15-31-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01922, current rewards: 168.98223, mean: 0.11191
[32m[0906 15-31-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01922, current rewards: 174.51237, mean: 0.11187
[32m[0906 15-31-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01922, current rewards: 180.04178, mean: 0.11183
[32m[0906 15-31-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01923, current rewards: 185.57523, mean: 0.11179
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01923, current rewards: 191.12645, mean: 0.11177
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01923, current rewards: 196.65640, mean: 0.11174
[32m[0906 15-31-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01923, current rewards: 202.18916, mean: 0.11171
[32m[0906 15-31-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01924, current rewards: 208.50980, mean: 0.11210
[32m[0906 15-31-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01923, current rewards: 213.98301, mean: 0.11203
[32m[0906 15-31-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01923, current rewards: 219.45640, mean: 0.11197
[32m[0906 15-31-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01922, current rewards: 224.92977, mean: 0.11191
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01922, current rewards: 230.40304, mean: 0.11185
[32m[0906 15-31-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01922, current rewards: 235.78710, mean: 0.11175
[32m[0906 15-31-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01922, current rewards: 241.28557, mean: 0.11171
[32m[0906 15-31-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01922, current rewards: 246.79720, mean: 0.11167
[32m[0906 15-31-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 252.30737, mean: 0.11164
[32m[0906 15-31-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01922, current rewards: 257.81690, mean: 0.11161
[32m[0906 15-31-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01919, current rewards: 263.32816, mean: 0.11158
[32m[0906 15-31-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 267.81402, mean: 0.11113
[32m[0906 15-31-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01917, current rewards: 273.37136, mean: 0.11113
[32m[0906 15-31-58 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-31-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-31-58 @MBExp.py:227][0m Rewards obtained: [277.8334351615659], Lows: [0], Highs: [1], Total time: 2872.495125
[32m[0906 15-34-04 @MBExp.py:144][0m ####################################################################
[32m[0906 15-34-04 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 15-34-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01916, current rewards: 1.11337, mean: 0.11134
[32m[0906 15-34-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.55981, mean: 0.10933
[32m[0906 15-34-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01902, current rewards: 12.09233, mean: 0.10993
[32m[0906 15-34-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01905, current rewards: 17.62622, mean: 0.11016
[32m[0906 15-34-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.15392, mean: 0.11026
[32m[0906 15-34-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 28.68854, mean: 0.11034
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.21537, mean: 0.11037
[32m[0906 15-34-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 39.76013, mean: 0.11044
[32m[0906 15-34-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.30216, mean: 0.11049
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 50.86920, mean: 0.11059
[32m[0906 15-34-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.40654, mean: 0.11060
[32m[0906 15-34-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 61.94284, mean: 0.11061
[32m[0906 15-34-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 67.48477, mean: 0.11063
[32m[0906 15-34-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 73.03274, mean: 0.11066
[32m[0906 15-34-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 78.57396, mean: 0.11067
[32m[0906 15-34-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.11188, mean: 0.11067
[32m[0906 15-34-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 89.65992, mean: 0.11069
[32m[0906 15-34-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 95.21589, mean: 0.11072
[32m[0906 15-34-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 100.79222, mean: 0.11076
[32m[0906 15-34-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 106.33318, mean: 0.11076
[32m[0906 15-34-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01917, current rewards: 111.87643, mean: 0.11077
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 117.42126, mean: 0.11077
[32m[0906 15-34-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 120.86047, mean: 0.10888
[32m[0906 15-34-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 126.43290, mean: 0.10899
[32m[0906 15-34-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 132.00450, mean: 0.10909
[32m[0906 15-34-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 137.57557, mean: 0.10919
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 143.16502, mean: 0.10929
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 148.73892, mean: 0.10937
[32m[0906 15-34-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 154.31148, mean: 0.10944
[32m[0906 15-34-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 159.88354, mean: 0.10951
[32m[0906 15-34-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 165.45706, mean: 0.10957
[32m[0906 15-34-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 171.02777, mean: 0.10963
[32m[0906 15-34-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 175.45675, mean: 0.10898
[32m[0906 15-34-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01917, current rewards: 180.99850, mean: 0.10904
[32m[0906 15-34-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 186.49683, mean: 0.10906
[32m[0906 15-34-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01917, current rewards: 192.03322, mean: 0.10911
[32m[0906 15-34-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: 197.57110, mean: 0.10916
[32m[0906 15-34-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 203.11038, mean: 0.10920
[32m[0906 15-34-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01918, current rewards: 208.65118, mean: 0.10924
[32m[0906 15-34-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01918, current rewards: 214.18458, mean: 0.10928
[32m[0906 15-34-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 219.72232, mean: 0.10931
[32m[0906 15-34-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01919, current rewards: 225.25467, mean: 0.10935
[32m[0906 15-34-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 230.88533, mean: 0.10942
[32m[0906 15-34-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01918, current rewards: 236.41507, mean: 0.10945
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01918, current rewards: 241.95176, mean: 0.10948
[32m[0906 15-34-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: 247.49611, mean: 0.10951
[32m[0906 15-34-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: 253.03405, mean: 0.10954
[32m[0906 15-34-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: 258.57162, mean: 0.10956
[32m[0906 15-34-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 264.10790, mean: 0.10959
[32m[0906 15-34-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 269.64488, mean: 0.10961
[32m[0906 15-34-53 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-34-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-34-53 @MBExp.py:227][0m Rewards obtained: [274.11363684736796], Lows: [1], Highs: [1], Total time: 2921.091973
[32m[0906 15-37-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-37-01 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 15-37-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01915, current rewards: 1.14561, mean: 0.11456
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01890, current rewards: 6.82594, mean: 0.11377
[32m[0906 15-37-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.48661, mean: 0.11351
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 18.14359, mean: 0.11340
[32m[0906 15-37-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.80487, mean: 0.11336
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 29.46565, mean: 0.11333
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 35.12385, mean: 0.11330
[32m[0906 15-37-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 40.80311, mean: 0.11334
[32m[0906 15-37-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 46.42215, mean: 0.11322
[32m[0906 15-37-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 51.92379, mean: 0.11288
[32m[0906 15-37-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 57.51267, mean: 0.11277
[32m[0906 15-37-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 63.10407, mean: 0.11269
[32m[0906 15-37-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 68.69868, mean: 0.11262
[32m[0906 15-37-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 71.88431, mean: 0.10892
[32m[0906 15-37-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 76.91653, mean: 0.10833
[32m[0906 15-37-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 81.94704, mean: 0.10783
[32m[0906 15-37-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 86.97625, mean: 0.10738
[32m[0906 15-37-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 92.12082, mean: 0.10712
[32m[0906 15-37-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 97.08567, mean: 0.10669
[32m[0906 15-37-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 99.13712, mean: 0.10327
[32m[0906 15-37-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 104.73750, mean: 0.10370
[32m[0906 15-37-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 110.33750, mean: 0.10409
[32m[0906 15-37-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 115.93497, mean: 0.10445
[32m[0906 15-37-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 121.53483, mean: 0.10477
[32m[0906 15-37-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 127.14541, mean: 0.10508
[32m[0906 15-37-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 132.59024, mean: 0.10523
[32m[0906 15-37-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 138.02163, mean: 0.10536
[32m[0906 15-37-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 143.46518, mean: 0.10549
[32m[0906 15-37-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 148.90764, mean: 0.10561
[32m[0906 15-37-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01915, current rewards: 154.34463, mean: 0.10572
[32m[0906 15-37-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 159.78290, mean: 0.10582
[32m[0906 15-37-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01915, current rewards: 165.22530, mean: 0.10591
[32m[0906 15-37-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01916, current rewards: 170.77697, mean: 0.10607
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: 176.44189, mean: 0.10629
[32m[0906 15-37-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01916, current rewards: 182.02677, mean: 0.10645
[32m[0906 15-37-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01916, current rewards: 187.66503, mean: 0.10663
[32m[0906 15-37-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01916, current rewards: 193.29723, mean: 0.10679
[32m[0906 15-37-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01917, current rewards: 198.92782, mean: 0.10695
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 204.56569, mean: 0.10710
[32m[0906 15-37-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01917, current rewards: 210.20193, mean: 0.10725
[32m[0906 15-37-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: 215.83813, mean: 0.10738
[32m[0906 15-37-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 221.47640, mean: 0.10751
[32m[0906 15-37-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 226.99790, mean: 0.10758
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 232.58041, mean: 0.10768
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01917, current rewards: 238.16777, mean: 0.10777
[32m[0906 15-37-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: 243.75691, mean: 0.10786
[32m[0906 15-37-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01917, current rewards: 249.33535, mean: 0.10794
[32m[0906 15-37-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01917, current rewards: 254.91364, mean: 0.10801
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01917, current rewards: 260.49901, mean: 0.10809
[32m[0906 15-37-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01918, current rewards: 266.08206, mean: 0.10816
[32m[0906 15-37-49 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-37-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-37-49 @MBExp.py:227][0m Rewards obtained: [270.60162122336146], Lows: [1], Highs: [3], Total time: 2969.779493
[32m[0906 15-40-00 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-00 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 15-40-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01836, current rewards: 1.07775, mean: 0.10778
[32m[0906 15-40-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01835, current rewards: 6.66526, mean: 0.11109
[32m[0906 15-40-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01839, current rewards: 12.25700, mean: 0.11143
[32m[0906 15-40-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.83994, mean: 0.11150
[32m[0906 15-40-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01871, current rewards: 23.42978, mean: 0.11157
[32m[0906 15-40-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01880, current rewards: 29.01323, mean: 0.11159
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01885, current rewards: 34.60302, mean: 0.11162
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01891, current rewards: 40.36327, mean: 0.11212
[32m[0906 15-40-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01896, current rewards: 45.99362, mean: 0.11218
[32m[0906 15-40-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01898, current rewards: 51.63230, mean: 0.11224
[32m[0906 15-40-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01900, current rewards: 57.27020, mean: 0.11229
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01902, current rewards: 62.90187, mean: 0.11232
[32m[0906 15-40-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01902, current rewards: 68.54509, mean: 0.11237
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01903, current rewards: 74.18447, mean: 0.11240
[32m[0906 15-40-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01904, current rewards: 79.81628, mean: 0.11242
[32m[0906 15-40-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01906, current rewards: 85.45527, mean: 0.11244
[32m[0906 15-40-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 91.09156, mean: 0.11246
[32m[0906 15-40-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: 94.52992, mean: 0.10992
[32m[0906 15-40-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: 100.09895, mean: 0.11000
[32m[0906 15-40-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01908, current rewards: 105.66771, mean: 0.11007
[32m[0906 15-40-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01909, current rewards: 111.23745, mean: 0.11014
[32m[0906 15-40-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01910, current rewards: 116.80407, mean: 0.11019
[32m[0906 15-40-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01911, current rewards: 122.36975, mean: 0.11024
[32m[0906 15-40-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 127.93488, mean: 0.11029
[32m[0906 15-40-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 133.48413, mean: 0.11032
[32m[0906 15-40-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 139.23618, mean: 0.11050
[32m[0906 15-40-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 144.87294, mean: 0.11059
[32m[0906 15-40-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 150.51193, mean: 0.11067
[32m[0906 15-40-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 156.14776, mean: 0.11074
[32m[0906 15-40-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: 161.78462, mean: 0.11081
[32m[0906 15-40-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 167.42164, mean: 0.11088
[32m[0906 15-40-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01915, current rewards: 173.05899, mean: 0.11094
[32m[0906 15-40-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01915, current rewards: 178.64826, mean: 0.11096
[32m[0906 15-40-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 184.15689, mean: 0.11094
[32m[0906 15-40-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 189.65946, mean: 0.11091
[32m[0906 15-40-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 195.23014, mean: 0.11093
[32m[0906 15-40-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 200.80743, mean: 0.11094
[32m[0906 15-40-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01915, current rewards: 206.37539, mean: 0.11095
[32m[0906 15-40-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01915, current rewards: 211.95296, mean: 0.11097
[32m[0906 15-40-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 217.53866, mean: 0.11099
[32m[0906 15-40-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 223.12330, mean: 0.11101
[32m[0906 15-40-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 228.70223, mean: 0.11102
[32m[0906 15-40-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 234.44653, mean: 0.11111
[32m[0906 15-40-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 240.04309, mean: 0.11113
[32m[0906 15-40-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 245.65698, mean: 0.11116
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 251.26144, mean: 0.11118
[32m[0906 15-40-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 256.87354, mean: 0.11120
[32m[0906 15-40-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 262.48672, mean: 0.11122
[32m[0906 15-40-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 268.09502, mean: 0.11124
[32m[0906 15-40-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 273.68839, mean: 0.11126
[32m[0906 15-40-48 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-40-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-40-48 @MBExp.py:227][0m Rewards obtained: [278.1730495213132], Lows: [1], Highs: [0], Total time: 3018.399031
[32m[0906 15-43-00 @MBExp.py:144][0m ####################################################################
[32m[0906 15-43-00 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 15-43-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01901, current rewards: 1.05070, mean: 0.10507
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01875, current rewards: 6.67465, mean: 0.11124
[32m[0906 15-43-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01867, current rewards: 12.15305, mean: 0.11048
[32m[0906 15-43-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01862, current rewards: 17.63139, mean: 0.11020
[32m[0906 15-43-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01864, current rewards: 23.10927, mean: 0.11004
[32m[0906 15-43-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01870, current rewards: 28.58807, mean: 0.10995
[32m[0906 15-43-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01877, current rewards: 34.06704, mean: 0.10989
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01882, current rewards: 39.54633, mean: 0.10985
[32m[0906 15-43-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01885, current rewards: 45.02544, mean: 0.10982
[32m[0906 15-43-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01888, current rewards: 49.31551, mean: 0.10721
[32m[0906 15-43-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01891, current rewards: 54.67637, mean: 0.10721
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01893, current rewards: 60.04408, mean: 0.10722
[32m[0906 15-43-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01896, current rewards: 65.39591, mean: 0.10721
[32m[0906 15-43-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01898, current rewards: 70.75662, mean: 0.10721
[32m[0906 15-43-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01899, current rewards: 76.12262, mean: 0.10721
[32m[0906 15-43-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01902, current rewards: 81.49150, mean: 0.10723
[32m[0906 15-43-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01902, current rewards: 86.85591, mean: 0.10723
[32m[0906 15-43-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01904, current rewards: 92.38811, mean: 0.10743
[32m[0906 15-43-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01905, current rewards: 97.91886, mean: 0.10760
[32m[0906 15-43-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01906, current rewards: 103.45121, mean: 0.10776
[32m[0906 15-43-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01906, current rewards: 108.98540, mean: 0.10791
[32m[0906 15-43-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 114.51694, mean: 0.10803
[32m[0906 15-43-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01907, current rewards: 120.04736, mean: 0.10815
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 125.58402, mean: 0.10826
[32m[0906 15-43-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 131.12535, mean: 0.10837
[32m[0906 15-43-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01908, current rewards: 136.68174, mean: 0.10848
[32m[0906 15-43-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 142.24408, mean: 0.10858
[32m[0906 15-43-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 147.77638, mean: 0.10866
[32m[0906 15-43-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 153.30650, mean: 0.10873
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 158.84591, mean: 0.10880
[32m[0906 15-43-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 164.37641, mean: 0.10886
[32m[0906 15-43-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 169.90944, mean: 0.10892
[32m[0906 15-43-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 175.44345, mean: 0.10897
[32m[0906 15-43-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 180.97327, mean: 0.10902
[32m[0906 15-43-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: 186.59321, mean: 0.10912
[32m[0906 15-43-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 192.17709, mean: 0.10919
[32m[0906 15-43-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 197.75557, mean: 0.10926
[32m[0906 15-43-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 203.33570, mean: 0.10932
[32m[0906 15-43-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 208.91703, mean: 0.10938
[32m[0906 15-43-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 214.49881, mean: 0.10944
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 220.07987, mean: 0.10949
[32m[0906 15-43-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 225.65815, mean: 0.10954
[32m[0906 15-43-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 231.11376, mean: 0.10953
[32m[0906 15-43-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 236.46151, mean: 0.10947
[32m[0906 15-43-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: 241.81235, mean: 0.10942
[32m[0906 15-43-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 247.15987, mean: 0.10936
[32m[0906 15-43-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 252.50784, mean: 0.10931
[32m[0906 15-43-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 257.85500, mean: 0.10926
[32m[0906 15-43-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 263.20457, mean: 0.10921
[32m[0906 15-43-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 268.55242, mean: 0.10917
[32m[0906 15-43-49 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-43-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-43-49 @MBExp.py:227][0m Rewards obtained: [272.82936712338676], Lows: [0], Highs: [1], Total time: 3066.996855
[32m[0906 15-46-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-46-03 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 15-46-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01849, current rewards: 1.34879, mean: 0.13488
[32m[0906 15-46-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01850, current rewards: 7.45366, mean: 0.12423
[32m[0906 15-46-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 13.60340, mean: 0.12367
[32m[0906 15-46-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 19.75190, mean: 0.12345
[32m[0906 15-46-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01857, current rewards: 25.90511, mean: 0.12336
[32m[0906 15-46-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01853, current rewards: 32.05797, mean: 0.12330
[32m[0906 15-46-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01852, current rewards: 38.20831, mean: 0.12325
[32m[0906 15-46-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 44.48656, mean: 0.12357
[32m[0906 15-46-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01865, current rewards: 50.08224, mean: 0.12215
[32m[0906 15-46-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01871, current rewards: 55.69841, mean: 0.12108
[32m[0906 15-46-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01877, current rewards: 61.22003, mean: 0.12004
[32m[0906 15-46-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01883, current rewards: 66.74321, mean: 0.11918
[32m[0906 15-46-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01887, current rewards: 72.72686, mean: 0.11922
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01891, current rewards: 78.20871, mean: 0.11850
[32m[0906 15-46-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01893, current rewards: 83.69236, mean: 0.11788
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01896, current rewards: 89.17809, mean: 0.11734
[32m[0906 15-46-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01899, current rewards: 94.66010, mean: 0.11686
[32m[0906 15-46-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01900, current rewards: 98.03272, mean: 0.11399
[32m[0906 15-46-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01902, current rewards: 103.66417, mean: 0.11392
[32m[0906 15-46-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01903, current rewards: 109.29339, mean: 0.11385
[32m[0906 15-46-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01903, current rewards: 114.90856, mean: 0.11377
[32m[0906 15-46-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01905, current rewards: 120.53613, mean: 0.11371
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01905, current rewards: 126.16845, mean: 0.11367
[32m[0906 15-46-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01906, current rewards: 131.79422, mean: 0.11362
[32m[0906 15-46-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01906, current rewards: 137.41732, mean: 0.11357
[32m[0906 15-46-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01907, current rewards: 143.06111, mean: 0.11354
[32m[0906 15-46-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01908, current rewards: 146.56010, mean: 0.11188
[32m[0906 15-46-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 152.14800, mean: 0.11187
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 157.73357, mean: 0.11187
[32m[0906 15-46-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 163.32234, mean: 0.11186
[32m[0906 15-46-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 166.75275, mean: 0.11043
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 172.30352, mean: 0.11045
[32m[0906 15-46-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 177.85478, mean: 0.11047
[32m[0906 15-46-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01912, current rewards: 183.40615, mean: 0.11049
[32m[0906 15-46-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: 188.97657, mean: 0.11051
[32m[0906 15-46-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 194.53786, mean: 0.11053
[32m[0906 15-46-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 200.09901, mean: 0.11055
[32m[0906 15-46-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 205.65966, mean: 0.11057
[32m[0906 15-46-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 208.99794, mean: 0.10942
[32m[0906 15-46-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: 214.90684, mean: 0.10965
[32m[0906 15-46-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: 220.84475, mean: 0.10987
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 226.78081, mean: 0.11009
[32m[0906 15-46-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 232.83458, mean: 0.11035
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 239.04146, mean: 0.11067
[32m[0906 15-46-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01914, current rewards: 245.24488, mean: 0.11097
[32m[0906 15-46-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 251.44489, mean: 0.11126
[32m[0906 15-46-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 257.64005, mean: 0.11153
[32m[0906 15-46-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 261.60496, mean: 0.11085
[32m[0906 15-46-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 267.10733, mean: 0.11083
[32m[0906 15-46-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 272.60709, mean: 0.11082
[32m[0906 15-46-52 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-46-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-46-52 @MBExp.py:227][0m Rewards obtained: [277.0092795614272], Lows: [4], Highs: [2], Total time: 3115.6390779999997
[32m[0906 15-49-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-49-08 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 15-49-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 0.07138, mean: 0.00714
[32m[0906 15-49-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01866, current rewards: 5.59382, mean: 0.09323
[32m[0906 15-49-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: 11.06295, mean: 0.10057
[32m[0906 15-49-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 16.53005, mean: 0.10331
[32m[0906 15-49-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 21.99710, mean: 0.10475
[32m[0906 15-49-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 27.67326, mean: 0.10644
[32m[0906 15-49-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 33.21869, mean: 0.10716
[32m[0906 15-49-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 38.76336, mean: 0.10768
[32m[0906 15-49-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 44.34375, mean: 0.10816
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01859, current rewards: 49.87714, mean: 0.10843
[32m[0906 15-49-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01864, current rewards: 55.40724, mean: 0.10864
[32m[0906 15-49-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01871, current rewards: 60.93813, mean: 0.10882
[32m[0906 15-49-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01875, current rewards: 66.46901, mean: 0.10897
[32m[0906 15-49-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01879, current rewards: 72.04533, mean: 0.10916
[32m[0906 15-49-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01883, current rewards: 77.58965, mean: 0.10928
[32m[0906 15-49-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01886, current rewards: 83.12925, mean: 0.10938
[32m[0906 15-49-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01889, current rewards: 88.66918, mean: 0.10947
[32m[0906 15-49-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01890, current rewards: 94.19056, mean: 0.10952
[32m[0906 15-49-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01891, current rewards: 99.68629, mean: 0.10955
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01894, current rewards: 105.18774, mean: 0.10957
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01895, current rewards: 110.68656, mean: 0.10959
[32m[0906 15-49-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01897, current rewards: 116.30450, mean: 0.10972
[32m[0906 15-49-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01898, current rewards: 121.83560, mean: 0.10976
[32m[0906 15-49-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01899, current rewards: 127.36849, mean: 0.10980
[32m[0906 15-49-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01901, current rewards: 132.90138, mean: 0.10984
[32m[0906 15-49-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01902, current rewards: 138.32177, mean: 0.10978
[32m[0906 15-49-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 143.79427, mean: 0.10977
[32m[0906 15-49-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01903, current rewards: 149.27272, mean: 0.10976
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: 152.65999, mean: 0.10827
[32m[0906 15-49-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 158.23480, mean: 0.10838
[32m[0906 15-49-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01905, current rewards: 163.81162, mean: 0.10848
[32m[0906 15-49-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 169.38623, mean: 0.10858
[32m[0906 15-49-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 174.96340, mean: 0.10867
[32m[0906 15-49-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 180.53802, mean: 0.10876
[32m[0906 15-49-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 186.11620, mean: 0.10884
[32m[0906 15-49-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 191.69155, mean: 0.10892
[32m[0906 15-49-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 197.26875, mean: 0.10899
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 202.84481, mean: 0.10906
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 208.42162, mean: 0.10912
[32m[0906 15-49-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01910, current rewards: 213.99947, mean: 0.10918
[32m[0906 15-49-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 218.53267, mean: 0.10872
[32m[0906 15-49-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 224.10891, mean: 0.10879
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 229.65276, mean: 0.10884
[32m[0906 15-49-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 235.19189, mean: 0.10889
[32m[0906 15-49-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: 240.72501, mean: 0.10893
[32m[0906 15-49-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 246.20367, mean: 0.10894
[32m[0906 15-49-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 251.69523, mean: 0.10896
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: 257.17987, mean: 0.10897
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: 262.66999, mean: 0.10899
[32m[0906 15-49-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01914, current rewards: 268.06985, mean: 0.10897
[32m[0906 15-49-57 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-49-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-49-57 @MBExp.py:227][0m Rewards obtained: [272.4042199112689], Lows: [1], Highs: [2], Total time: 3164.2293579999996
[32m[0906 15-52-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-52-16 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 15-52-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.33977, mean: 0.13398
[32m[0906 15-52-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01839, current rewards: 6.87278, mean: 0.11455
[32m[0906 15-52-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 12.41215, mean: 0.11284
[32m[0906 15-52-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01843, current rewards: 17.95364, mean: 0.11221
[32m[0906 15-52-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01842, current rewards: 23.49712, mean: 0.11189
[32m[0906 15-52-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01841, current rewards: 29.04050, mean: 0.11169
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.57930, mean: 0.11155
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.12317, mean: 0.11145
[32m[0906 15-52-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.76585, mean: 0.11162
[32m[0906 15-52-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 51.31648, mean: 0.11156
[32m[0906 15-52-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.86231, mean: 0.11149
[32m[0906 15-52-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 62.40158, mean: 0.11143
[32m[0906 15-52-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01859, current rewards: 67.94978, mean: 0.11139
[32m[0906 15-52-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01864, current rewards: 73.48345, mean: 0.11134
[32m[0906 15-52-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01869, current rewards: 79.02772, mean: 0.11131
[32m[0906 15-52-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01873, current rewards: 84.57452, mean: 0.11128
[32m[0906 15-52-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01877, current rewards: 90.07799, mean: 0.11121
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01880, current rewards: 95.62204, mean: 0.11119
[32m[0906 15-52-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01882, current rewards: 101.16927, mean: 0.11118
[32m[0906 15-52-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01883, current rewards: 106.71037, mean: 0.11116
[32m[0906 15-52-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01885, current rewards: 112.25966, mean: 0.11115
[32m[0906 15-52-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01886, current rewards: 117.81638, mean: 0.11115
[32m[0906 15-52-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01887, current rewards: 123.37243, mean: 0.11115
[32m[0906 15-52-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01889, current rewards: 128.93147, mean: 0.11115
[32m[0906 15-52-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01891, current rewards: 134.49308, mean: 0.11115
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01892, current rewards: 139.94874, mean: 0.11107
[32m[0906 15-52-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01894, current rewards: 145.48755, mean: 0.11106
[32m[0906 15-52-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01894, current rewards: 151.02071, mean: 0.11104
[32m[0906 15-52-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01896, current rewards: 156.55843, mean: 0.11103
[32m[0906 15-52-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01898, current rewards: 162.09879, mean: 0.11103
[32m[0906 15-52-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01898, current rewards: 167.63749, mean: 0.11102
[32m[0906 15-52-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01899, current rewards: 173.17510, mean: 0.11101
[32m[0906 15-52-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01899, current rewards: 178.71270, mean: 0.11100
[32m[0906 15-52-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01901, current rewards: 184.42429, mean: 0.11110
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: 189.97778, mean: 0.11110
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01901, current rewards: 195.53209, mean: 0.11110
[32m[0906 15-52-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01901, current rewards: 199.91941, mean: 0.11045
[32m[0906 15-52-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: 205.47992, mean: 0.11047
[32m[0906 15-52-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01903, current rewards: 211.04120, mean: 0.11049
[32m[0906 15-52-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01903, current rewards: 216.60552, mean: 0.11051
[32m[0906 15-52-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01904, current rewards: 222.11957, mean: 0.11051
[32m[0906 15-52-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01905, current rewards: 227.65194, mean: 0.11051
[32m[0906 15-52-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01905, current rewards: 233.10691, mean: 0.11048
[32m[0906 15-52-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01906, current rewards: 238.64126, mean: 0.11048
[32m[0906 15-52-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01907, current rewards: 244.17325, mean: 0.11049
[32m[0906 15-52-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: 249.71244, mean: 0.11049
[32m[0906 15-53-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01908, current rewards: 255.24103, mean: 0.11049
[32m[0906 15-53-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01908, current rewards: 260.76994, mean: 0.11050
[32m[0906 15-53-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01908, current rewards: 266.30185, mean: 0.11050
[32m[0906 15-53-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 271.83929, mean: 0.11050
[32m[0906 15-53-04 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-53-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-53-04 @MBExp.py:227][0m Rewards obtained: [276.26873079682565], Lows: [0], Highs: [1], Total time: 3212.7058169999996
[32m[0906 15-55-25 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-25 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.03682, mean: 0.10368
[32m[0906 15-55-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01849, current rewards: 6.57413, mean: 0.10957
[32m[0906 15-55-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 12.12514, mean: 0.11023
[32m[0906 15-55-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 17.66041, mean: 0.11038
[32m[0906 15-55-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 23.20630, mean: 0.11051
[32m[0906 15-55-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 28.74752, mean: 0.11057
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 34.28661, mean: 0.11060
[32m[0906 15-55-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.83112, mean: 0.11064
[32m[0906 15-55-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 45.40857, mean: 0.11075
[32m[0906 15-55-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01858, current rewards: 50.95446, mean: 0.11077
[32m[0906 15-55-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01857, current rewards: 56.49818, mean: 0.11078
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 62.05353, mean: 0.11081
[32m[0906 15-55-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 67.61464, mean: 0.11084
[32m[0906 15-55-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01862, current rewards: 73.17829, mean: 0.11088
[32m[0906 15-55-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01867, current rewards: 78.74086, mean: 0.11090
[32m[0906 15-55-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01872, current rewards: 84.29888, mean: 0.11092
[32m[0906 15-55-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01874, current rewards: 89.87485, mean: 0.11096
[32m[0906 15-55-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01876, current rewards: 95.43430, mean: 0.11097
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01879, current rewards: 100.99827, mean: 0.11099
[32m[0906 15-55-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01882, current rewards: 106.56092, mean: 0.11100
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01884, current rewards: 112.11895, mean: 0.11101
[32m[0906 15-55-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01885, current rewards: 117.72048, mean: 0.11106
[32m[0906 15-55-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01887, current rewards: 123.25129, mean: 0.11104
[32m[0906 15-55-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01888, current rewards: 128.79141, mean: 0.11103
[32m[0906 15-55-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01888, current rewards: 134.30662, mean: 0.11100
[32m[0906 15-55-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01889, current rewards: 139.83719, mean: 0.11098
[32m[0906 15-55-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01890, current rewards: 145.36871, mean: 0.11097
[32m[0906 15-55-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01891, current rewards: 150.90453, mean: 0.11096
[32m[0906 15-55-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01892, current rewards: 156.44315, mean: 0.11095
[32m[0906 15-55-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01893, current rewards: 161.97144, mean: 0.11094
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01893, current rewards: 167.50422, mean: 0.11093
[32m[0906 15-55-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01894, current rewards: 173.15446, mean: 0.11100
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01895, current rewards: 178.74098, mean: 0.11102
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 184.30253, mean: 0.11103
[32m[0906 15-55-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01896, current rewards: 186.53401, mean: 0.10908
[32m[0906 15-55-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01896, current rewards: 192.06799, mean: 0.10913
[32m[0906 15-55-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: 197.61230, mean: 0.10918
[32m[0906 15-56-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: 203.15451, mean: 0.10922
[32m[0906 15-56-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01897, current rewards: 208.69307, mean: 0.10926
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01898, current rewards: 214.39896, mean: 0.10939
[32m[0906 15-56-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01899, current rewards: 219.93673, mean: 0.10942
[32m[0906 15-56-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: 225.38234, mean: 0.10941
[32m[0906 15-56-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01900, current rewards: 230.92863, mean: 0.10944
[32m[0906 15-56-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01900, current rewards: 236.48201, mean: 0.10948
[32m[0906 15-56-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01900, current rewards: 242.04088, mean: 0.10952
[32m[0906 15-56-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 247.58400, mean: 0.10955
[32m[0906 15-56-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01901, current rewards: 253.12783, mean: 0.10958
[32m[0906 15-56-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01901, current rewards: 258.67609, mean: 0.10961
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01901, current rewards: 264.22945, mean: 0.10964
[32m[0906 15-56-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01902, current rewards: 269.90645, mean: 0.10972
[32m[0906 15-56-13 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-56-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-56-13 @MBExp.py:227][0m Rewards obtained: [274.34455770795773], Lows: [0], Highs: [3], Total time: 3261.0192809999994
[32m[0906 15-58-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-58-36 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 15-58-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01853, current rewards: 1.34475, mean: 0.13448
[32m[0906 15-58-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01844, current rewards: 6.89147, mean: 0.11486
[32m[0906 15-58-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01844, current rewards: 12.43577, mean: 0.11305
[32m[0906 15-58-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01838, current rewards: 17.98127, mean: 0.11238
[32m[0906 15-58-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01838, current rewards: 23.53031, mean: 0.11205
[32m[0906 15-58-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01841, current rewards: 29.04674, mean: 0.11172
[32m[0906 15-58-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01843, current rewards: 34.58738, mean: 0.11157
[32m[0906 15-58-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01843, current rewards: 40.12669, mean: 0.11146
[32m[0906 15-58-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.62941, mean: 0.11129
[32m[0906 15-58-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 51.16618, mean: 0.11123
[32m[0906 15-58-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 56.70769, mean: 0.11119
[32m[0906 15-58-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 62.24767, mean: 0.11116
[32m[0906 15-58-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 67.78789, mean: 0.11113
[32m[0906 15-58-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.54660, mean: 0.11143
[32m[0906 15-58-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 79.10689, mean: 0.11142
[32m[0906 15-58-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01856, current rewards: 84.66444, mean: 0.11140
[32m[0906 15-58-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01860, current rewards: 90.34241, mean: 0.11153
[32m[0906 15-58-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01865, current rewards: 95.91988, mean: 0.11153
[32m[0906 15-58-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01867, current rewards: 101.49679, mean: 0.11153
[32m[0906 15-58-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01871, current rewards: 107.07525, mean: 0.11154
[32m[0906 15-58-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01874, current rewards: 110.42705, mean: 0.10933
[32m[0906 15-58-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01877, current rewards: 115.97096, mean: 0.10941
[32m[0906 15-58-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01878, current rewards: 121.51947, mean: 0.10948
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01879, current rewards: 127.06696, mean: 0.10954
[32m[0906 15-58-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01880, current rewards: 132.61604, mean: 0.10960
[32m[0906 15-59-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01882, current rewards: 138.16878, mean: 0.10966
[32m[0906 15-59-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01883, current rewards: 143.72551, mean: 0.10971
[32m[0906 15-59-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01884, current rewards: 149.28029, mean: 0.10976
[32m[0906 15-59-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01884, current rewards: 154.83245, mean: 0.10981
[32m[0906 15-59-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01885, current rewards: 160.38534, mean: 0.10985
[32m[0906 15-59-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01886, current rewards: 165.98645, mean: 0.10992
[32m[0906 15-59-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01888, current rewards: 171.53419, mean: 0.10996
[32m[0906 15-59-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01888, current rewards: 177.11357, mean: 0.11001
[32m[0906 15-59-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01890, current rewards: 182.67302, mean: 0.11004
[32m[0906 15-59-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01891, current rewards: 188.22683, mean: 0.11007
[32m[0906 15-59-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01892, current rewards: 193.77250, mean: 0.11010
[32m[0906 15-59-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01893, current rewards: 199.31264, mean: 0.11012
[32m[0906 15-59-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01893, current rewards: 204.86437, mean: 0.11014
[32m[0906 15-59-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 210.41853, mean: 0.11017
[32m[0906 15-59-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01895, current rewards: 215.96778, mean: 0.11019
[32m[0906 15-59-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01895, current rewards: 221.50950, mean: 0.11020
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01896, current rewards: 227.06281, mean: 0.11022
[32m[0906 15-59-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: 232.62970, mean: 0.11025
[32m[0906 15-59-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01897, current rewards: 238.18076, mean: 0.11027
[32m[0906 15-59-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01898, current rewards: 243.73400, mean: 0.11029
[32m[0906 15-59-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01898, current rewards: 249.28144, mean: 0.11030
[32m[0906 15-59-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01899, current rewards: 254.95857, mean: 0.11037
[32m[0906 15-59-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01899, current rewards: 260.52104, mean: 0.11039
[32m[0906 15-59-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01900, current rewards: 265.97240, mean: 0.11036
[32m[0906 15-59-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01900, current rewards: 271.45705, mean: 0.11035
[32m[0906 15-59-24 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-59-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-59-24 @MBExp.py:227][0m Rewards obtained: [275.8868849415284], Lows: [0], Highs: [2], Total time: 3309.3068879999996
[32m[0906 16-01-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-01-49 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-01-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01940, current rewards: 1.04054, mean: 0.10405
[32m[0906 16-01-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01859, current rewards: 6.56245, mean: 0.10937
[32m[0906 16-01-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01857, current rewards: 12.09784, mean: 0.10998
[32m[0906 16-01-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01851, current rewards: 17.63132, mean: 0.11020
[32m[0906 16-01-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.16886, mean: 0.11033
[32m[0906 16-01-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.70520, mean: 0.11040
[32m[0906 16-01-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01852, current rewards: 34.23801, mean: 0.11045
[32m[0906 16-01-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.73730, mean: 0.11038
[32m[0906 16-01-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.26095, mean: 0.11039
[32m[0906 16-01-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 50.85979, mean: 0.11056
[32m[0906 16-01-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.39195, mean: 0.11057
[32m[0906 16-01-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 61.92048, mean: 0.11057
[32m[0906 16-02-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.45298, mean: 0.11058
[32m[0906 16-02-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 72.97427, mean: 0.11057
[32m[0906 16-02-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 78.50149, mean: 0.11057
[32m[0906 16-02-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.10800, mean: 0.11067
[32m[0906 16-02-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 89.64289, mean: 0.11067
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 95.18122, mean: 0.11068
[32m[0906 16-02-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 100.71558, mean: 0.11068
[32m[0906 16-02-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01861, current rewards: 106.25383, mean: 0.11068
[32m[0906 16-02-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01865, current rewards: 111.78405, mean: 0.11068
[32m[0906 16-02-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01867, current rewards: 117.32543, mean: 0.11068
[32m[0906 16-02-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01870, current rewards: 122.86038, mean: 0.11069
[32m[0906 16-02-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01871, current rewards: 128.39732, mean: 0.11069
[32m[0906 16-02-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01873, current rewards: 133.93130, mean: 0.11069
[32m[0906 16-02-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01875, current rewards: 139.46010, mean: 0.11068
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01877, current rewards: 144.98107, mean: 0.11067
[32m[0906 16-02-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01878, current rewards: 150.50629, mean: 0.11067
[32m[0906 16-02-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01879, current rewards: 156.04414, mean: 0.11067
[32m[0906 16-02-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01880, current rewards: 161.58883, mean: 0.11068
[32m[0906 16-02-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01882, current rewards: 167.13807, mean: 0.11069
[32m[0906 16-02-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01883, current rewards: 172.64332, mean: 0.11067
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01884, current rewards: 178.13528, mean: 0.11064
[32m[0906 16-02-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01885, current rewards: 183.67173, mean: 0.11065
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01886, current rewards: 189.20431, mean: 0.11065
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01887, current rewards: 194.73599, mean: 0.11065
[32m[0906 16-02-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01887, current rewards: 200.26716, mean: 0.11064
[32m[0906 16-02-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01888, current rewards: 205.79535, mean: 0.11064
[32m[0906 16-02-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01889, current rewards: 211.33940, mean: 0.11065
[32m[0906 16-02-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01890, current rewards: 216.88367, mean: 0.11065
[32m[0906 16-02-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01891, current rewards: 222.55068, mean: 0.11072
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01891, current rewards: 228.10320, mean: 0.11073
[32m[0906 16-02-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 233.65438, mean: 0.11074
[32m[0906 16-02-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01892, current rewards: 239.21287, mean: 0.11075
[32m[0906 16-02-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01893, current rewards: 245.23711, mean: 0.11097
[32m[0906 16-02-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: 250.79424, mean: 0.11097
[32m[0906 16-02-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01894, current rewards: 256.34984, mean: 0.11097
[32m[0906 16-02-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01895, current rewards: 261.90553, mean: 0.11098
[32m[0906 16-02-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01895, current rewards: 267.43061, mean: 0.11097
[32m[0906 16-02-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01896, current rewards: 272.97500, mean: 0.11097
[32m[0906 16-02-37 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 16-02-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-02-37 @MBExp.py:227][0m Rewards obtained: [277.40986545187377], Lows: [0], Highs: [0], Total time: 3357.4650779999997
[32m[0906 16-05-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-04 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-05-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01860, current rewards: 1.12017, mean: 0.11202
[32m[0906 16-05-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01856, current rewards: 6.67509, mean: 0.11125
[32m[0906 16-05-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 12.22918, mean: 0.11117
[32m[0906 16-05-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 17.78791, mean: 0.11117
[32m[0906 16-05-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.34227, mean: 0.11115
[32m[0906 16-05-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 28.89529, mean: 0.11114
[32m[0906 16-05-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01852, current rewards: 34.44187, mean: 0.11110
[32m[0906 16-05-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 39.99655, mean: 0.11110
[32m[0906 16-05-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 45.54760, mean: 0.11109
[32m[0906 16-05-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01856, current rewards: 51.10373, mean: 0.11110
[32m[0906 16-05-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 56.65504, mean: 0.11109
[32m[0906 16-05-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 62.22135, mean: 0.11111
[32m[0906 16-05-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 67.75958, mean: 0.11108
[32m[0906 16-05-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 73.29014, mean: 0.11105
[32m[0906 16-05-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: 78.81383, mean: 0.11101
[32m[0906 16-05-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 84.35123, mean: 0.11099
[32m[0906 16-05-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 89.89069, mean: 0.11098
[32m[0906 16-05-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 95.42322, mean: 0.11096
[32m[0906 16-05-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 100.95457, mean: 0.11094
[32m[0906 16-05-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 106.49320, mean: 0.11093
[32m[0906 16-05-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01861, current rewards: 112.12750, mean: 0.11102
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01864, current rewards: 117.76782, mean: 0.11110
[32m[0906 16-05-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01866, current rewards: 123.42436, mean: 0.11119
[32m[0906 16-05-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01869, current rewards: 131.03538, mean: 0.11296
[32m[0906 16-05-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01871, current rewards: 139.57330, mean: 0.11535
[32m[0906 16-05-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01873, current rewards: 148.11123, mean: 0.11755
[32m[0906 16-05-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01875, current rewards: 156.64915, mean: 0.11958
[32m[0906 16-05-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01876, current rewards: 165.18707, mean: 0.12146
[32m[0906 16-05-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01878, current rewards: 166.70044, mean: 0.11823
[32m[0906 16-05-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01879, current rewards: 164.48800, mean: 0.11266
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01880, current rewards: 170.06150, mean: 0.11262
[32m[0906 16-05-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01881, current rewards: 175.52282, mean: 0.11251
[32m[0906 16-05-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01882, current rewards: 181.09725, mean: 0.11248
[32m[0906 16-05-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01882, current rewards: 186.68219, mean: 0.11246
[32m[0906 16-05-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01883, current rewards: 192.26235, mean: 0.11243
[32m[0906 16-05-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01884, current rewards: 197.83411, mean: 0.11241
[32m[0906 16-05-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01885, current rewards: 203.40925, mean: 0.11238
[32m[0906 16-05-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01886, current rewards: 208.98202, mean: 0.11236
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01887, current rewards: 214.55461, mean: 0.11233
[32m[0906 16-05-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01888, current rewards: 220.13535, mean: 0.11231
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01888, current rewards: 225.80547, mean: 0.11234
[32m[0906 16-05-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 231.38756, mean: 0.11232
[32m[0906 16-05-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01890, current rewards: 237.05834, mean: 0.11235
[32m[0906 16-05-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 242.72786, mean: 0.11237
[32m[0906 16-05-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 248.39981, mean: 0.11240
[32m[0906 16-05-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01892, current rewards: 254.06958, mean: 0.11242
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: 259.73917, mean: 0.11244
[32m[0906 16-05-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 265.41038, mean: 0.11246
[32m[0906 16-05-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01894, current rewards: 271.04752, mean: 0.11247
[32m[0906 16-05-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 276.68025, mean: 0.11247
[32m[0906 16-05-52 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-05-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-05-52 @MBExp.py:227][0m Rewards obtained: [281.1074389604267], Lows: [0], Highs: [13], Total time: 3405.613641
[32m[0906 16-08-21 @MBExp.py:144][0m ####################################################################
[32m[0906 16-08-21 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-08-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01915, current rewards: 1.08461, mean: 0.10846
[32m[0906 16-08-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01877, current rewards: 6.60535, mean: 0.11009
[32m[0906 16-08-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01874, current rewards: 12.12681, mean: 0.11024
[32m[0906 16-08-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01867, current rewards: 17.64862, mean: 0.11030
[32m[0906 16-08-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01866, current rewards: 23.18186, mean: 0.11039
[32m[0906 16-08-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01862, current rewards: 28.82181, mean: 0.11085
[32m[0906 16-08-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01860, current rewards: 34.34668, mean: 0.11080
[32m[0906 16-08-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01860, current rewards: 39.92444, mean: 0.11090
[32m[0906 16-08-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 45.50400, mean: 0.11099
[32m[0906 16-08-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 51.08501, mean: 0.11105
[32m[0906 16-08-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01859, current rewards: 56.66722, mean: 0.11111
[32m[0906 16-08-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 62.25129, mean: 0.11116
[32m[0906 16-08-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 67.83318, mean: 0.11120
[32m[0906 16-08-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 73.41719, mean: 0.11124
[32m[0906 16-08-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 79.05247, mean: 0.11134
[32m[0906 16-08-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 84.61441, mean: 0.11133
[32m[0906 16-08-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 90.19508, mean: 0.11135
[32m[0906 16-08-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 95.78571, mean: 0.11138
[32m[0906 16-08-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 101.37547, mean: 0.11140
[32m[0906 16-08-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 106.96255, mean: 0.11142
[32m[0906 16-08-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 112.54901, mean: 0.11143
[32m[0906 16-08-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 118.13685, mean: 0.11145
[32m[0906 16-08-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: 123.72720, mean: 0.11147
[32m[0906 16-08-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 129.46135, mean: 0.11160
[32m[0906 16-08-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: 135.07085, mean: 0.11163
[32m[0906 16-08-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01866, current rewards: 140.68286, mean: 0.11165
[32m[0906 16-08-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01868, current rewards: 144.27108, mean: 0.11013
[32m[0906 16-08-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: 149.99647, mean: 0.11029
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01872, current rewards: 155.72560, mean: 0.11044
[32m[0906 16-08-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01872, current rewards: 161.42061, mean: 0.11056
[32m[0906 16-08-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 167.10377, mean: 0.11066
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01875, current rewards: 172.77543, mean: 0.11075
[32m[0906 16-08-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: 178.46905, mean: 0.11085
[32m[0906 16-08-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 184.15985, mean: 0.11094
[32m[0906 16-08-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: 189.85516, mean: 0.11103
[32m[0906 16-08-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 195.54702, mean: 0.11111
[32m[0906 16-08-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 199.08733, mean: 0.10999
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01881, current rewards: 204.62245, mean: 0.11001
[32m[0906 16-08-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 210.15761, mean: 0.11003
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 215.78264, mean: 0.11009
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 223.05685, mean: 0.11097
[32m[0906 16-09-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 230.33107, mean: 0.11181
[32m[0906 16-09-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 237.60528, mean: 0.11261
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 244.87949, mean: 0.11337
[32m[0906 16-09-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 252.15371, mean: 0.11410
[32m[0906 16-09-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 259.42792, mean: 0.11479
[32m[0906 16-09-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 217.44631, mean: 0.09413
[32m[0906 16-09-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 167.44631, mean: 0.07095
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 117.44631, mean: 0.04873
[32m[0906 16-09-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 67.44631, mean: 0.02742
[32m[0906 16-09-09 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-09-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-09-09 @MBExp.py:227][0m Rewards obtained: [27.446308824043058], Lows: [2], Highs: [233], Total time: 3453.615107
[32m[0906 16-11-40 @MBExp.py:144][0m ####################################################################
[32m[0906 16-11-40 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-11-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01903, current rewards: -0.96415, mean: -0.09641
[32m[0906 16-11-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 4.53012, mean: 0.07550
[32m[0906 16-11-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 10.08807, mean: 0.09171
[32m[0906 16-11-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 15.64085, mean: 0.09776
[32m[0906 16-11-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 21.19639, mean: 0.10094
[32m[0906 16-11-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 26.75213, mean: 0.10289
[32m[0906 16-11-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 32.41548, mean: 0.10457
[32m[0906 16-11-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 37.97689, mean: 0.10549
[32m[0906 16-11-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: 43.54215, mean: 0.10620
[32m[0906 16-11-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01856, current rewards: 48.98830, mean: 0.10650
[32m[0906 16-11-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 54.47091, mean: 0.10681
[32m[0906 16-11-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 59.95296, mean: 0.10706
[32m[0906 16-11-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 65.43889, mean: 0.10728
[32m[0906 16-11-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 70.97281, mean: 0.10753
[32m[0906 16-11-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 76.56470, mean: 0.10784
[32m[0906 16-11-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 82.16296, mean: 0.10811
[32m[0906 16-11-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 87.76214, mean: 0.10835
[32m[0906 16-11-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 93.35716, mean: 0.10855
[32m[0906 16-11-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 98.92126, mean: 0.10870
[32m[0906 16-11-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 104.45160, mean: 0.10880
[32m[0906 16-11-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 109.97885, mean: 0.10889
[32m[0906 16-12-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 115.50281, mean: 0.10896
[32m[0906 16-12-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 121.03157, mean: 0.10904
[32m[0906 16-12-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 126.55936, mean: 0.10910
[32m[0906 16-12-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 132.08951, mean: 0.10916
[32m[0906 16-12-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 137.61458, mean: 0.10922
[32m[0906 16-12-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01866, current rewards: 143.14435, mean: 0.10927
[32m[0906 16-12-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01868, current rewards: 148.67556, mean: 0.10932
[32m[0906 16-12-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01870, current rewards: 154.16924, mean: 0.10934
[32m[0906 16-12-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01872, current rewards: 159.65256, mean: 0.10935
[32m[0906 16-12-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01873, current rewards: 165.12792, mean: 0.10936
[32m[0906 16-12-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 170.54184, mean: 0.10932
[32m[0906 16-12-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: 176.03221, mean: 0.10934
[32m[0906 16-12-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01877, current rewards: 181.51490, mean: 0.10935
[32m[0906 16-12-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: 187.00264, mean: 0.10936
[32m[0906 16-12-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 192.48768, mean: 0.10937
[32m[0906 16-12-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 197.97057, mean: 0.10938
[32m[0906 16-12-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01881, current rewards: 203.45844, mean: 0.10939
[32m[0906 16-12-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: 208.94156, mean: 0.10939
[32m[0906 16-12-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: 214.36267, mean: 0.10937
[32m[0906 16-12-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01883, current rewards: 219.84270, mean: 0.10937
[32m[0906 16-12-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 225.31472, mean: 0.10938
[32m[0906 16-12-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 230.79036, mean: 0.10938
[32m[0906 16-12-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 236.26932, mean: 0.10938
[32m[0906 16-12-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 241.74358, mean: 0.10939
[32m[0906 16-12-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 247.21796, mean: 0.10939
[32m[0906 16-12-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 252.69305, mean: 0.10939
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 258.29400, mean: 0.10945
[32m[0906 16-12-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 262.68485, mean: 0.10900
[32m[0906 16-12-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 268.25174, mean: 0.10905
[32m[0906 16-12-28 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-12-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-12-28 @MBExp.py:227][0m Rewards obtained: [272.70377474168606], Lows: [1], Highs: [1], Total time: 3501.623497
[32m[0906 16-15-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-15-01 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-15-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: 1.07082, mean: 0.10708
[32m[0906 16-15-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01865, current rewards: 6.62051, mean: 0.11034
[32m[0906 16-15-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: 12.17141, mean: 0.11065
[32m[0906 16-15-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.72612, mean: 0.11079
[32m[0906 16-15-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 23.27399, mean: 0.11083
[32m[0906 16-15-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 28.82490, mean: 0.11086
[32m[0906 16-15-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 34.50740, mean: 0.11131
[32m[0906 16-15-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.07081, mean: 0.11131
[32m[0906 16-15-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.63110, mean: 0.11130
[32m[0906 16-15-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 51.19308, mean: 0.11129
[32m[0906 16-15-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.75772, mean: 0.11129
[32m[0906 16-15-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01846, current rewards: 62.38128, mean: 0.11140
[32m[0906 16-15-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 67.96056, mean: 0.11141
[32m[0906 16-15-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 73.54080, mean: 0.11143
[32m[0906 16-15-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 79.12192, mean: 0.11144
[32m[0906 16-15-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 84.70584, mean: 0.11146
[32m[0906 16-15-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 90.28919, mean: 0.11147
[32m[0906 16-15-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01848, current rewards: 95.86986, mean: 0.11148
[32m[0906 16-15-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01848, current rewards: 101.45040, mean: 0.11148
[32m[0906 16-15-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 107.02816, mean: 0.11149
[32m[0906 16-15-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 112.57069, mean: 0.11146
[32m[0906 16-15-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01848, current rewards: 118.12850, mean: 0.11144
[32m[0906 16-15-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01848, current rewards: 123.60260, mean: 0.11135
[32m[0906 16-15-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01848, current rewards: 129.14519, mean: 0.11133
[32m[0906 16-15-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01849, current rewards: 134.69520, mean: 0.11132
[32m[0906 16-15-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 140.25200, mean: 0.11131
[32m[0906 16-15-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 145.80929, mean: 0.11130
[32m[0906 16-15-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 151.36652, mean: 0.11130
[32m[0906 16-15-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01859, current rewards: 156.92368, mean: 0.11129
[32m[0906 16-15-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 162.47828, mean: 0.11129
[32m[0906 16-15-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01863, current rewards: 168.03388, mean: 0.11128
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01865, current rewards: 173.58981, mean: 0.11128
[32m[0906 16-15-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01866, current rewards: 179.14507, mean: 0.11127
[32m[0906 16-15-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01867, current rewards: 184.70156, mean: 0.11127
[32m[0906 16-15-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01869, current rewards: 190.25682, mean: 0.11126
[32m[0906 16-15-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01870, current rewards: 195.82108, mean: 0.11126
[32m[0906 16-15-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01871, current rewards: 201.37581, mean: 0.11126
[32m[0906 16-15-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01872, current rewards: 206.93267, mean: 0.11125
[32m[0906 16-15-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01873, current rewards: 212.44385, mean: 0.11123
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01874, current rewards: 218.09211, mean: 0.11127
[32m[0906 16-15-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01875, current rewards: 223.65248, mean: 0.11127
[32m[0906 16-15-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01876, current rewards: 229.21271, mean: 0.11127
[32m[0906 16-15-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01877, current rewards: 234.77014, mean: 0.11127
[32m[0906 16-15-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01878, current rewards: 240.32740, mean: 0.11126
[32m[0906 16-15-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01878, current rewards: 246.78307, mean: 0.11167
[32m[0906 16-15-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01879, current rewards: 252.96075, mean: 0.11193
[32m[0906 16-15-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01880, current rewards: 259.13844, mean: 0.11218
[32m[0906 16-15-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 254.16072, mean: 0.10770
[32m[0906 16-15-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01881, current rewards: 255.25800, mean: 0.10592
[32m[0906 16-15-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: 260.78730, mean: 0.10601
[32m[0906 16-15-49 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-15-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-15-49 @MBExp.py:227][0m Rewards obtained: [265.2241266026676], Lows: [0], Highs: [13], Total time: 3549.451372
[32m[0906 16-18-25 @MBExp.py:144][0m ####################################################################
[32m[0906 16-18-25 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-18-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.59068, mean: 0.15907
[32m[0906 16-18-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 8.68723, mean: 0.14479
[32m[0906 16-18-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 15.78378, mean: 0.14349
[32m[0906 16-18-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01835, current rewards: 22.88033, mean: 0.14300
[32m[0906 16-18-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01840, current rewards: 29.97688, mean: 0.14275
[32m[0906 16-18-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 37.07343, mean: 0.14259
[32m[0906 16-18-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 43.33323, mean: 0.13978
[32m[0906 16-18-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 49.51092, mean: 0.13753
[32m[0906 16-18-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 55.68860, mean: 0.13583
[32m[0906 16-18-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 61.86628, mean: 0.13449
[32m[0906 16-18-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 35.46090, mean: 0.06953
[32m[0906 16-18-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: -14.53910, mean: -0.02596
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: -64.53910, mean: -0.10580
[32m[0906 16-18-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: -114.53910, mean: -0.17354
[32m[0906 16-18-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: -164.53910, mean: -0.23175
[32m[0906 16-18-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: -214.53910, mean: -0.28229
[32m[0906 16-18-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: -264.53910, mean: -0.32659
[32m[0906 16-18-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: -314.53910, mean: -0.36574
[32m[0906 16-18-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: -364.53910, mean: -0.40059
[32m[0906 16-18-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: -414.53910, mean: -0.43181
[32m[0906 16-18-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: -464.53910, mean: -0.45994
[32m[0906 16-18-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: -514.53910, mean: -0.48541
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01850, current rewards: -564.53910, mean: -0.50859
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: -614.53910, mean: -0.52978
[32m[0906 16-18-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01850, current rewards: -664.53910, mean: -0.54921
[32m[0906 16-18-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01850, current rewards: -714.53910, mean: -0.56709
[32m[0906 16-18-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: -764.53910, mean: -0.58362
[32m[0906 16-18-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: -814.53910, mean: -0.59893
[32m[0906 16-18-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: -864.53910, mean: -0.61315
[32m[0906 16-18-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: -914.53910, mean: -0.62640
[32m[0906 16-18-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01862, current rewards: -964.53910, mean: -0.63877
[32m[0906 16-18-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01863, current rewards: -1014.53910, mean: -0.65035
[32m[0906 16-18-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01865, current rewards: -1064.53910, mean: -0.66120
[32m[0906 16-18-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01866, current rewards: -1114.53910, mean: -0.67141
[32m[0906 16-18-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01868, current rewards: -1164.53910, mean: -0.68102
[32m[0906 16-18-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01869, current rewards: -1214.53910, mean: -0.69008
[32m[0906 16-18-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01870, current rewards: -1264.53910, mean: -0.69864
[32m[0906 16-19-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01871, current rewards: -1314.53910, mean: -0.70674
[32m[0906 16-19-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01872, current rewards: -1364.53910, mean: -0.71442
[32m[0906 16-19-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01873, current rewards: -1414.53910, mean: -0.72170
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01874, current rewards: -1464.53910, mean: -0.72863
[32m[0906 16-19-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01875, current rewards: -1514.53910, mean: -0.73521
[32m[0906 16-19-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01876, current rewards: -1564.53910, mean: -0.74149
[32m[0906 16-19-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01877, current rewards: -1614.53910, mean: -0.74747
[32m[0906 16-19-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01878, current rewards: -1664.53910, mean: -0.75319
[32m[0906 16-19-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01879, current rewards: -1714.53910, mean: -0.75865
[32m[0906 16-19-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: -1764.53910, mean: -0.76387
[32m[0906 16-19-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: -1814.53910, mean: -0.76887
[32m[0906 16-19-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01881, current rewards: -1864.53910, mean: -0.77367
[32m[0906 16-19-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: -1914.53910, mean: -0.77827
[32m[0906 16-19-12 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-19-12 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-19-13 @MBExp.py:227][0m Rewards obtained: [-1954.5390955558426], Lows: [0], Highs: [2019], Total time: 3597.277212
[32m[0906 16-21-50 @MBExp.py:144][0m ####################################################################
[32m[0906 16-21-50 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-21-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01881, current rewards: 1.09476, mean: 0.10948
[32m[0906 16-21-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01853, current rewards: 6.67880, mean: 0.11131
[32m[0906 16-21-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: 12.26403, mean: 0.11149
[32m[0906 16-21-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 17.85134, mean: 0.11157
[32m[0906 16-21-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01852, current rewards: 23.43773, mean: 0.11161
[32m[0906 16-21-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01853, current rewards: 29.84260, mean: 0.11478
[32m[0906 16-21-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 36.45083, mean: 0.11758
[32m[0906 16-21-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 28.34093, mean: 0.07872
[32m[0906 16-21-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: -21.65907, mean: -0.05283
[32m[0906 16-21-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01856, current rewards: -71.65907, mean: -0.15578
[32m[0906 16-22-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: -121.65907, mean: -0.23855
[32m[0906 16-22-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: -171.65907, mean: -0.30653
[32m[0906 16-22-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: -221.65907, mean: -0.36338
[32m[0906 16-22-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: -271.65907, mean: -0.41160
[32m[0906 16-22-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: -321.65907, mean: -0.45304
[32m[0906 16-22-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: -371.65907, mean: -0.48903
[32m[0906 16-22-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: -421.65907, mean: -0.52057
[32m[0906 16-22-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: -471.65907, mean: -0.54844
[32m[0906 16-22-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: -521.65907, mean: -0.57325
[32m[0906 16-22-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: -571.65907, mean: -0.59548
[32m[0906 16-22-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: -621.65907, mean: -0.61550
[32m[0906 16-22-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: -671.65907, mean: -0.63364
[32m[0906 16-22-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: -721.65907, mean: -0.65014
[32m[0906 16-22-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: -771.65907, mean: -0.66522
[32m[0906 16-22-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: -821.65907, mean: -0.67906
[32m[0906 16-22-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: -871.65907, mean: -0.69179
[32m[0906 16-22-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: -921.65907, mean: -0.70356
[32m[0906 16-22-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: -971.65907, mean: -0.71446
[32m[0906 16-22-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: -1021.65907, mean: -0.72458
[32m[0906 16-22-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: -1071.65907, mean: -0.73401
[32m[0906 16-22-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01859, current rewards: -1121.65907, mean: -0.74282
[32m[0906 16-22-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01860, current rewards: -1171.65907, mean: -0.75106
[32m[0906 16-22-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01862, current rewards: -1221.65907, mean: -0.75879
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01863, current rewards: -1271.65907, mean: -0.76606
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01865, current rewards: -1321.65907, mean: -0.77290
[32m[0906 16-22-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01867, current rewards: -1371.65907, mean: -0.77935
[32m[0906 16-22-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01868, current rewards: -1421.65907, mean: -0.78545
[32m[0906 16-22-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01870, current rewards: -1471.65907, mean: -0.79121
[32m[0906 16-22-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01871, current rewards: -1521.65907, mean: -0.79668
[32m[0906 16-22-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01872, current rewards: -1571.65907, mean: -0.80187
[32m[0906 16-22-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01873, current rewards: -1621.65907, mean: -0.80680
[32m[0906 16-22-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01874, current rewards: -1671.65907, mean: -0.81148
[32m[0906 16-22-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01875, current rewards: -1721.65907, mean: -0.81595
[32m[0906 16-22-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01876, current rewards: -1771.65907, mean: -0.82021
[32m[0906 16-22-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01877, current rewards: -1821.65907, mean: -0.82428
[32m[0906 16-22-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01877, current rewards: -1871.65907, mean: -0.82817
[32m[0906 16-22-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01878, current rewards: -1921.65907, mean: -0.83189
[32m[0906 16-22-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01879, current rewards: -1971.65907, mean: -0.83545
[32m[0906 16-22-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: -1988.89197, mean: -0.82527
[32m[0906 16-22-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: -1986.04180, mean: -0.80733
[32m[0906 16-22-38 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-22-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-22-38 @MBExp.py:227][0m Rewards obtained: [-1983.7616581497216], Lows: [0], Highs: [2032], Total time: 3645.08705
[32m[0906 16-25-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-25-18 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 16-25-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01826, current rewards: -0.03657, mean: -0.00366
[32m[0906 16-25-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 5.45332, mean: 0.09089
[32m[0906 16-25-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01836, current rewards: 10.94626, mean: 0.09951
[32m[0906 16-25-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01839, current rewards: 16.43460, mean: 0.10272
[32m[0906 16-25-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01837, current rewards: 22.05384, mean: 0.10502
[32m[0906 16-25-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01838, current rewards: 27.57933, mean: 0.10607
[32m[0906 16-25-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01840, current rewards: 33.11006, mean: 0.10681
[32m[0906 16-25-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01842, current rewards: 38.60567, mean: 0.10724
[32m[0906 16-25-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01843, current rewards: 44.13862, mean: 0.10766
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01845, current rewards: 49.67355, mean: 0.10799
[32m[0906 16-25-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01845, current rewards: 55.21419, mean: 0.10826
[32m[0906 16-25-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 60.75417, mean: 0.10849
[32m[0906 16-25-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 66.29331, mean: 0.10868
[32m[0906 16-25-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 71.83344, mean: 0.10884
[32m[0906 16-25-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 77.34988, mean: 0.10894
[32m[0906 16-25-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 82.89927, mean: 0.10908
[32m[0906 16-25-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 88.45007, mean: 0.10920
[32m[0906 16-25-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 93.99946, mean: 0.10930
[32m[0906 16-25-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 99.54957, mean: 0.10940
[32m[0906 16-25-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 105.09877, mean: 0.10948
[32m[0906 16-25-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 110.54604, mean: 0.10945
[32m[0906 16-25-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 116.08925, mean: 0.10952
[32m[0906 16-25-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: 121.64600, mean: 0.10959
[32m[0906 16-25-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 127.17015, mean: 0.10963
[32m[0906 16-25-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 132.70099, mean: 0.10967
[32m[0906 16-25-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: 138.22770, mean: 0.10970
[32m[0906 16-25-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 143.75407, mean: 0.10974
[32m[0906 16-25-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: 149.28567, mean: 0.10977
[32m[0906 16-25-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: 154.83287, mean: 0.10981
[32m[0906 16-25-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 160.44585, mean: 0.10989
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 166.00756, mean: 0.10994
[32m[0906 16-25-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 171.57344, mean: 0.10998
[32m[0906 16-25-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01859, current rewards: 177.13844, mean: 0.11002
[32m[0906 16-25-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 182.70632, mean: 0.11006
[32m[0906 16-25-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01863, current rewards: 188.24302, mean: 0.11008
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01865, current rewards: 193.77526, mean: 0.11010
[32m[0906 16-25-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01866, current rewards: 199.30306, mean: 0.11011
[32m[0906 16-25-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01868, current rewards: 204.92064, mean: 0.11017
[32m[0906 16-25-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01870, current rewards: 210.43179, mean: 0.11017
[32m[0906 16-25-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01870, current rewards: 215.92942, mean: 0.11017
[32m[0906 16-25-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01871, current rewards: 221.42420, mean: 0.11016
[32m[0906 16-25-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01873, current rewards: 226.92455, mean: 0.11016
[32m[0906 16-25-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01873, current rewards: 232.41937, mean: 0.11015
[32m[0906 16-25-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01874, current rewards: 237.91871, mean: 0.11015
[32m[0906 16-26-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01876, current rewards: 243.41171, mean: 0.11014
[32m[0906 16-26-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01877, current rewards: 248.87158, mean: 0.11012
[32m[0906 16-26-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01878, current rewards: 254.34667, mean: 0.11011
[32m[0906 16-26-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01878, current rewards: 259.82512, mean: 0.11010
[32m[0906 16-26-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01879, current rewards: 265.30676, mean: 0.11009
[32m[0906 16-26-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: 270.79389, mean: 0.11008
[32m[0906 16-26-05 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-26-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-26-05 @MBExp.py:227][0m Rewards obtained: [273.0767302663366], Lows: [1], Highs: [1], Total time: 3692.881661
[32m[0906 16-28-47 @MBExp.py:144][0m ####################################################################
[32m[0906 16-28-47 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 16-28-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01837, current rewards: -0.01869, mean: -0.00187
[32m[0906 16-28-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01842, current rewards: 5.52302, mean: 0.09205
[32m[0906 16-28-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 11.06487, mean: 0.10059
[32m[0906 16-28-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 16.61074, mean: 0.10382
[32m[0906 16-28-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01847, current rewards: 22.15970, mean: 0.10552
[32m[0906 16-28-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01846, current rewards: 27.70837, mean: 0.10657
[32m[0906 16-28-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 33.25479, mean: 0.10727
[32m[0906 16-28-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 38.80550, mean: 0.10779
[32m[0906 16-28-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 44.34511, mean: 0.10816
[32m[0906 16-28-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 49.89282, mean: 0.10846
[32m[0906 16-28-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 55.43796, mean: 0.10870
[32m[0906 16-28-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 61.03425, mean: 0.10899
[32m[0906 16-28-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 66.65652, mean: 0.10927
[32m[0906 16-29-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 72.21243, mean: 0.10941
[32m[0906 16-29-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 77.73738, mean: 0.10949
[32m[0906 16-29-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 83.27405, mean: 0.10957
[32m[0906 16-29-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 88.81049, mean: 0.10964
[32m[0906 16-29-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 94.35105, mean: 0.10971
[32m[0906 16-29-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 99.89447, mean: 0.10977
[32m[0906 16-29-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 105.43872, mean: 0.10983
[32m[0906 16-29-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 110.94938, mean: 0.10985
[32m[0906 16-29-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 116.52355, mean: 0.10993
[32m[0906 16-29-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 122.06684, mean: 0.10997
[32m[0906 16-29-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 127.61172, mean: 0.11001
[32m[0906 16-29-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 133.15243, mean: 0.11004
[32m[0906 16-29-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 138.69642, mean: 0.11008
[32m[0906 16-29-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: 144.24580, mean: 0.11011
[32m[0906 16-29-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 149.78903, mean: 0.11014
[32m[0906 16-29-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: 155.36656, mean: 0.11019
[32m[0906 16-29-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 160.91727, mean: 0.11022
[32m[0906 16-29-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01853, current rewards: 166.46519, mean: 0.11024
[32m[0906 16-29-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: 172.01132, mean: 0.11026
[32m[0906 16-29-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 177.76511, mean: 0.11041
[32m[0906 16-29-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01857, current rewards: 183.30796, mean: 0.11043
[32m[0906 16-29-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01859, current rewards: 188.85128, mean: 0.11044
[32m[0906 16-29-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 194.39533, mean: 0.11045
[32m[0906 16-29-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01863, current rewards: 199.82460, mean: 0.11040
[32m[0906 16-29-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01864, current rewards: 205.34957, mean: 0.11040
[32m[0906 16-29-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01865, current rewards: 210.87788, mean: 0.11041
[32m[0906 16-29-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01866, current rewards: 216.40459, mean: 0.11041
[32m[0906 16-29-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01867, current rewards: 221.92841, mean: 0.11041
[32m[0906 16-29-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01868, current rewards: 227.45431, mean: 0.11041
[32m[0906 16-29-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01870, current rewards: 232.97652, mean: 0.11042
[32m[0906 16-29-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01871, current rewards: 238.50163, mean: 0.11042
[32m[0906 16-29-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01873, current rewards: 244.04963, mean: 0.11043
[32m[0906 16-29-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01873, current rewards: 249.79885, mean: 0.11053
[32m[0906 16-29-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01874, current rewards: 243.09165, mean: 0.10523
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01875, current rewards: 248.57765, mean: 0.10533
[32m[0906 16-29-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01876, current rewards: 254.06318, mean: 0.10542
[32m[0906 16-29-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01877, current rewards: 259.54522, mean: 0.10551
[32m[0906 16-29-35 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-29-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-29-35 @MBExp.py:227][0m Rewards obtained: [263.93857425295454], Lows: [0], Highs: [12], Total time: 3740.611896
[32m[0906 16-32-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-32-19 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 16-32-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01883, current rewards: 1.24316, mean: 0.12432
[32m[0906 16-32-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01853, current rewards: 10.56069, mean: 0.17601
[32m[0906 16-32-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 19.89413, mean: 0.18086
[32m[0906 16-32-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 27.97979, mean: 0.17487
[32m[0906 16-32-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 30.62666, mean: 0.14584
[32m[0906 16-32-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 33.21388, mean: 0.12775
[32m[0906 16-32-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 35.80110, mean: 0.11549
[32m[0906 16-32-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01853, current rewards: 38.38833, mean: 0.10663
[32m[0906 16-32-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 39.92381, mean: 0.09738
[32m[0906 16-32-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: -10.07619, mean: -0.02190
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: -60.07619, mean: -0.11780
[32m[0906 16-32-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: -110.07619, mean: -0.19656
[32m[0906 16-32-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: -160.07619, mean: -0.26242
[32m[0906 16-32-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: -210.07619, mean: -0.31830
[32m[0906 16-32-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: -260.07619, mean: -0.36630
[32m[0906 16-32-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: -310.07619, mean: -0.40799
[32m[0906 16-32-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: -360.07619, mean: -0.44454
[32m[0906 16-32-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: -410.07619, mean: -0.47683
[32m[0906 16-32-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: -460.07619, mean: -0.50558
[32m[0906 16-32-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: -510.07619, mean: -0.53133
[32m[0906 16-32-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: -560.07619, mean: -0.55453
[32m[0906 16-32-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: -610.07619, mean: -0.57554
[32m[0906 16-32-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: -660.07619, mean: -0.59466
[32m[0906 16-32-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01854, current rewards: -710.07619, mean: -0.61213
[32m[0906 16-32-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: -760.07619, mean: -0.62816
[32m[0906 16-32-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: -810.07619, mean: -0.64292
[32m[0906 16-32-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: -860.07619, mean: -0.65655
[32m[0906 16-32-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: -910.07619, mean: -0.66917
[32m[0906 16-32-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: -960.07619, mean: -0.68091
[32m[0906 16-32-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: -1010.07619, mean: -0.69183
[32m[0906 16-32-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01853, current rewards: -1060.07619, mean: -0.70204
[32m[0906 16-32-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01853, current rewards: -1110.07619, mean: -0.71159
[32m[0906 16-32-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01852, current rewards: -1160.07619, mean: -0.72054
[32m[0906 16-32-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01852, current rewards: -1210.07619, mean: -0.72896
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: -1260.07619, mean: -0.73689
[32m[0906 16-32-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01856, current rewards: -1310.07619, mean: -0.74436
[32m[0906 16-32-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01858, current rewards: -1360.07619, mean: -0.75142
[32m[0906 16-32-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01860, current rewards: -1410.07619, mean: -0.75811
[32m[0906 16-32-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: -1460.07619, mean: -0.76444
[32m[0906 16-32-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01864, current rewards: -1510.07619, mean: -0.77045
[32m[0906 16-32-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01865, current rewards: -1560.07619, mean: -0.77616
[32m[0906 16-32-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01866, current rewards: -1610.07619, mean: -0.78159
[32m[0906 16-32-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01867, current rewards: -1660.07619, mean: -0.78677
[32m[0906 16-33-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01869, current rewards: -1710.07619, mean: -0.79170
[32m[0906 16-33-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01870, current rewards: -1760.07619, mean: -0.79641
[32m[0906 16-33-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01871, current rewards: -1810.07619, mean: -0.80092
[32m[0906 16-33-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01872, current rewards: -1860.07619, mean: -0.80523
[32m[0906 16-33-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01873, current rewards: -1910.07619, mean: -0.80935
[32m[0906 16-33-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01874, current rewards: -1960.07619, mean: -0.81331
[32m[0906 16-33-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01875, current rewards: -2010.07619, mean: -0.81710
[32m[0906 16-33-06 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-33-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-33-07 @MBExp.py:227][0m Rewards obtained: [-2050.076190561721], Lows: [0], Highs: [2091], Total time: 3788.2822699999997
[32m[0906 16-35-52 @MBExp.py:144][0m ####################################################################
[32m[0906 16-35-52 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 16-35-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01818, current rewards: 1.45004, mean: 0.14500
[32m[0906 16-35-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01834, current rewards: 8.54659, mean: 0.14244
[32m[0906 16-35-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01839, current rewards: 15.50641, mean: 0.14097
[32m[0906 16-35-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01840, current rewards: 22.11465, mean: 0.13822
[32m[0906 16-35-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 28.72288, mean: 0.13678
[32m[0906 16-35-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01838, current rewards: 35.33111, mean: 0.13589
[32m[0906 16-35-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01839, current rewards: 4.57791, mean: 0.01477
[32m[0906 16-35-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01842, current rewards: -45.42209, mean: -0.12617
[32m[0906 16-36-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01843, current rewards: -95.42209, mean: -0.23274
[32m[0906 16-36-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01842, current rewards: -145.42209, mean: -0.31613
[32m[0906 16-36-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01842, current rewards: -195.42209, mean: -0.38318
[32m[0906 16-36-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01843, current rewards: -245.42209, mean: -0.43825
[32m[0906 16-36-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01843, current rewards: -295.42209, mean: -0.48430
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01842, current rewards: -345.42209, mean: -0.52337
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01844, current rewards: -395.42209, mean: -0.55693
[32m[0906 16-36-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01843, current rewards: -445.42209, mean: -0.58608
[32m[0906 16-36-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01844, current rewards: -495.42209, mean: -0.61163
[32m[0906 16-36-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01844, current rewards: -545.42209, mean: -0.63421
[32m[0906 16-36-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01845, current rewards: -595.42209, mean: -0.65431
[32m[0906 16-36-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01845, current rewards: -645.42209, mean: -0.67231
[32m[0906 16-36-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01846, current rewards: -695.42209, mean: -0.68854
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01846, current rewards: -745.42209, mean: -0.70323
[32m[0906 16-36-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01846, current rewards: -795.42209, mean: -0.71660
[32m[0906 16-36-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01846, current rewards: -845.42209, mean: -0.72881
[32m[0906 16-36-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01846, current rewards: -895.42209, mean: -0.74002
[32m[0906 16-36-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01848, current rewards: -945.42209, mean: -0.75033
[32m[0906 16-36-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01848, current rewards: -995.42209, mean: -0.75986
[32m[0906 16-36-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01848, current rewards: -1045.42209, mean: -0.76869
[32m[0906 16-36-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01848, current rewards: -1095.42209, mean: -0.77690
[32m[0906 16-36-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01849, current rewards: -1145.42209, mean: -0.78454
[32m[0906 16-36-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01849, current rewards: -1195.42209, mean: -0.79167
[32m[0906 16-36-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01849, current rewards: -1245.42209, mean: -0.79835
[32m[0906 16-36-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01850, current rewards: -1295.42209, mean: -0.80461
[32m[0906 16-36-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01849, current rewards: -1345.42209, mean: -0.81050
[32m[0906 16-36-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01850, current rewards: -1395.42209, mean: -0.81604
[32m[0906 16-36-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01851, current rewards: -1445.42209, mean: -0.82126
[32m[0906 16-36-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01852, current rewards: -1495.42209, mean: -0.82620
[32m[0906 16-36-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01854, current rewards: -1545.42209, mean: -0.83087
[32m[0906 16-36-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: -1595.42209, mean: -0.83530
[32m[0906 16-36-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: -1645.42209, mean: -0.83950
[32m[0906 16-36-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01859, current rewards: -1695.42209, mean: -0.84349
[32m[0906 16-36-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01860, current rewards: -1745.42209, mean: -0.84729
[32m[0906 16-36-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: -1795.42209, mean: -0.85091
[32m[0906 16-36-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01862, current rewards: -1845.42209, mean: -0.85436
[32m[0906 16-36-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01863, current rewards: -1895.42209, mean: -0.85766
[32m[0906 16-36-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01864, current rewards: -1945.42209, mean: -0.86081
[32m[0906 16-36-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: -1995.42209, mean: -0.86382
[32m[0906 16-36-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01867, current rewards: -2045.42209, mean: -0.86670
[32m[0906 16-36-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01868, current rewards: -2095.42209, mean: -0.86947
[32m[0906 16-36-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01869, current rewards: -2145.42209, mean: -0.87212
[32m[0906 16-36-40 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 16-36-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-36-40 @MBExp.py:227][0m Rewards obtained: [-2185.422089453606], Lows: [0], Highs: [2223], Total time: 3835.809246
[32m[0906 16-39-28 @MBExp.py:144][0m ####################################################################
[32m[0906 16-39-28 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 16-39-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01771, current rewards: -2.00260, mean: -0.20026
[32m[0906 16-39-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01855, current rewards: 3.60841, mean: 0.06014
[32m[0906 16-39-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 9.14818, mean: 0.08317
[32m[0906 16-39-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 14.73555, mean: 0.09210
[32m[0906 16-39-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 20.33191, mean: 0.09682
[32m[0906 16-39-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01859, current rewards: 25.92954, mean: 0.09973
[32m[0906 16-39-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 31.52460, mean: 0.10169
[32m[0906 16-39-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 37.12011, mean: 0.10311
[32m[0906 16-39-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 42.71018, mean: 0.10417
[32m[0906 16-39-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01859, current rewards: 48.30941, mean: 0.10502
[32m[0906 16-39-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 53.90626, mean: 0.10570
[32m[0906 16-39-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 59.53395, mean: 0.10631
[32m[0906 16-39-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 65.13519, mean: 0.10678
[32m[0906 16-39-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 70.74199, mean: 0.10718
[32m[0906 16-39-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 76.30948, mean: 0.10748
[32m[0906 16-39-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 81.87506, mean: 0.10773
[32m[0906 16-39-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: 87.44568, mean: 0.10796
[32m[0906 16-39-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01859, current rewards: 93.01556, mean: 0.10816
[32m[0906 16-39-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01860, current rewards: 98.58004, mean: 0.10833
[32m[0906 16-39-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01859, current rewards: 104.17480, mean: 0.10852
[32m[0906 16-39-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01859, current rewards: 109.73935, mean: 0.10865
[32m[0906 16-39-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 115.30066, mean: 0.10877
[32m[0906 16-39-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: 120.97378, mean: 0.10899
[32m[0906 16-39-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: 126.55561, mean: 0.10910
[32m[0906 16-39-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01859, current rewards: 132.13459, mean: 0.10920
[32m[0906 16-39-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: 137.71669, mean: 0.10930
[32m[0906 16-39-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: 143.30226, mean: 0.10939
[32m[0906 16-39-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: 148.88103, mean: 0.10947
[32m[0906 16-39-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 154.46101, mean: 0.10955
[32m[0906 16-39-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01857, current rewards: 160.04153, mean: 0.10962
[32m[0906 16-39-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 165.62009, mean: 0.10968
[32m[0906 16-39-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 171.29905, mean: 0.10981
[32m[0906 16-39-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 176.77980, mean: 0.10980
[32m[0906 16-39-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 182.26354, mean: 0.10980
[32m[0906 16-40-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 187.74809, mean: 0.10979
[32m[0906 16-40-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 193.22996, mean: 0.10979
[32m[0906 16-40-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01858, current rewards: 198.71166, mean: 0.10979
[32m[0906 16-40-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: 204.19414, mean: 0.10978
[32m[0906 16-40-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 209.67547, mean: 0.10978
[32m[0906 16-40-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 215.15823, mean: 0.10977
[32m[0906 16-40-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 220.63773, mean: 0.10977
[32m[0906 16-40-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01863, current rewards: 225.15377, mean: 0.10930
[32m[0906 16-40-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01864, current rewards: 230.76250, mean: 0.10937
[32m[0906 16-40-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01865, current rewards: 236.37109, mean: 0.10943
[32m[0906 16-40-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: 241.97992, mean: 0.10949
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01868, current rewards: 247.58722, mean: 0.10955
[32m[0906 16-40-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01869, current rewards: 253.19516, mean: 0.10961
[32m[0906 16-40-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01870, current rewards: 258.79925, mean: 0.10966
[32m[0906 16-40-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01872, current rewards: 264.40944, mean: 0.10971
[32m[0906 16-40-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01873, current rewards: 270.03810, mean: 0.10977
[32m[0906 16-40-15 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 16-40-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-40-15 @MBExp.py:227][0m Rewards obtained: [274.49929380298045], Lows: [1], Highs: [2], Total time: 3883.4353969999997
[32m[0906 16-43-05 @MBExp.py:144][0m ####################################################################
[32m[0906 16-43-05 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 16-43-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01786, current rewards: 1.12326, mean: 0.11233
[32m[0906 16-43-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01844, current rewards: 6.54163, mean: 0.10903
[32m[0906 16-43-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.08862, mean: 0.10990
[32m[0906 16-43-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01843, current rewards: 17.63065, mean: 0.11019
[32m[0906 16-43-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 23.17030, mean: 0.11033
[32m[0906 16-43-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01843, current rewards: 28.71601, mean: 0.11045
[32m[0906 16-43-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 34.73968, mean: 0.11206
[32m[0906 16-43-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.29040, mean: 0.11192
[32m[0906 16-43-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 45.84267, mean: 0.11181
[32m[0906 16-43-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01856, current rewards: 51.40724, mean: 0.11175
[32m[0906 16-43-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 57.00558, mean: 0.11178
[32m[0906 16-43-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: 62.55992, mean: 0.11171
[32m[0906 16-43-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 68.11498, mean: 0.11166
[32m[0906 16-43-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 73.66832, mean: 0.11162
[32m[0906 16-43-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 79.22147, mean: 0.11158
[32m[0906 16-43-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.77732, mean: 0.11155
[32m[0906 16-43-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 90.33302, mean: 0.11152
[32m[0906 16-43-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 94.77873, mean: 0.11021
[32m[0906 16-43-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 100.31986, mean: 0.11024
[32m[0906 16-43-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 105.85627, mean: 0.11027
[32m[0906 16-43-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 111.40145, mean: 0.11030
[32m[0906 16-43-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 116.93317, mean: 0.11031
[32m[0906 16-43-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 122.49250, mean: 0.11035
[32m[0906 16-43-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 128.02524, mean: 0.11037
[32m[0906 16-43-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 133.55964, mean: 0.11038
[32m[0906 16-43-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 139.10180, mean: 0.11040
[32m[0906 16-43-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 144.62854, mean: 0.11040
[32m[0906 16-43-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: 150.23919, mean: 0.11047
[32m[0906 16-43-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 155.78857, mean: 0.11049
[32m[0906 16-43-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01852, current rewards: 161.34533, mean: 0.11051
[32m[0906 16-43-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01852, current rewards: 166.90939, mean: 0.11054
[32m[0906 16-43-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01852, current rewards: 172.46725, mean: 0.11056
[32m[0906 16-43-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01852, current rewards: 178.02515, mean: 0.11057
[32m[0906 16-43-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01852, current rewards: 183.59312, mean: 0.11060
[32m[0906 16-43-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: 189.15268, mean: 0.11062
[32m[0906 16-43-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01852, current rewards: 194.71304, mean: 0.11063
[32m[0906 16-43-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01852, current rewards: 200.27177, mean: 0.11065
[32m[0906 16-43-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: 205.83942, mean: 0.11067
[32m[0906 16-43-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01852, current rewards: 211.39870, mean: 0.11068
[32m[0906 16-43-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01851, current rewards: 216.95414, mean: 0.11069
[32m[0906 16-43-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01853, current rewards: 222.51077, mean: 0.11070
[32m[0906 16-43-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 228.07210, mean: 0.11071
[32m[0906 16-43-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01856, current rewards: 233.59105, mean: 0.11071
[32m[0906 16-43-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01858, current rewards: 239.14339, mean: 0.11071
[32m[0906 16-43-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01859, current rewards: 244.69731, mean: 0.11072
[32m[0906 16-43-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 250.24960, mean: 0.11073
[32m[0906 16-43-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01861, current rewards: 255.80018, mean: 0.11074
[32m[0906 16-43-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01862, current rewards: 261.35856, mean: 0.11075
[32m[0906 16-43-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01864, current rewards: 266.91028, mean: 0.11075
[32m[0906 16-43-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01865, current rewards: 272.46304, mean: 0.11076
[32m[0906 16-43-53 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 16-43-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-43-53 @MBExp.py:227][0m Rewards obtained: [277.00384442724743], Lows: [0], Highs: [1], Total time: 3930.8552
[32m[0906 16-46-45 @MBExp.py:144][0m ####################################################################
[32m[0906 16-46-45 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 16-46-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01842, current rewards: 1.12050, mean: 0.11205
[32m[0906 16-46-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01850, current rewards: 7.70541, mean: 0.12842
[32m[0906 16-46-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 14.46944, mean: 0.13154
[32m[0906 16-46-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 21.23348, mean: 0.13271
[32m[0906 16-46-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 27.99752, mean: 0.13332
[32m[0906 16-46-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: -8.37911, mean: -0.03223
[32m[0906 16-46-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: -58.37911, mean: -0.18832
[32m[0906 16-46-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: -108.37911, mean: -0.30105
[32m[0906 16-46-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: -158.37911, mean: -0.38629
[32m[0906 16-46-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: -208.37911, mean: -0.45300
[32m[0906 16-46-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: -258.37911, mean: -0.50663
[32m[0906 16-46-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: -308.37911, mean: -0.55068
[32m[0906 16-46-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: -358.37911, mean: -0.58751
[32m[0906 16-46-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: -408.37911, mean: -0.61876
[32m[0906 16-46-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: -458.37911, mean: -0.64560
[32m[0906 16-46-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: -508.37911, mean: -0.66892
[32m[0906 16-47-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: -558.37911, mean: -0.68936
[32m[0906 16-47-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: -608.37911, mean: -0.70742
[32m[0906 16-47-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: -658.37911, mean: -0.72349
[32m[0906 16-47-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: -708.37911, mean: -0.73789
[32m[0906 16-47-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: -758.37911, mean: -0.75087
[32m[0906 16-47-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: -808.37911, mean: -0.76262
[32m[0906 16-47-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: -858.37911, mean: -0.77331
[32m[0906 16-47-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01854, current rewards: -908.37911, mean: -0.78309
[32m[0906 16-47-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01854, current rewards: -958.37911, mean: -0.79205
[32m[0906 16-47-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: -1008.37911, mean: -0.80030
[32m[0906 16-47-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: -1058.37911, mean: -0.80792
[32m[0906 16-47-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: -1108.37911, mean: -0.81498
[32m[0906 16-47-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: -1158.37911, mean: -0.82155
[32m[0906 16-47-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01854, current rewards: -1208.37911, mean: -0.82766
[32m[0906 16-47-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: -1258.37911, mean: -0.83336
[32m[0906 16-47-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: -1308.37911, mean: -0.83870
[32m[0906 16-47-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: -1358.37911, mean: -0.84371
[32m[0906 16-47-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01853, current rewards: -1408.37911, mean: -0.84842
[32m[0906 16-47-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01853, current rewards: -1458.37911, mean: -0.85285
[32m[0906 16-47-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01853, current rewards: -1508.37911, mean: -0.85703
[32m[0906 16-47-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01853, current rewards: -1558.37911, mean: -0.86098
[32m[0906 16-47-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01853, current rewards: -1608.37911, mean: -0.86472
[32m[0906 16-47-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01853, current rewards: -1658.37911, mean: -0.86826
[32m[0906 16-47-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01853, current rewards: -1708.37911, mean: -0.87162
[32m[0906 16-47-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01853, current rewards: -1758.37911, mean: -0.87482
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01854, current rewards: -1808.37911, mean: -0.87785
[32m[0906 16-47-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01854, current rewards: -1858.37911, mean: -0.88075
[32m[0906 16-47-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: -1908.37911, mean: -0.88351
[32m[0906 16-47-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01858, current rewards: -1958.37911, mean: -0.88614
[32m[0906 16-47-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: -2008.37911, mean: -0.88866
[32m[0906 16-47-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01860, current rewards: -2058.37911, mean: -0.89107
[32m[0906 16-47-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: -2108.37911, mean: -0.89338
[32m[0906 16-47-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01862, current rewards: -2158.37911, mean: -0.89559
[32m[0906 16-47-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01863, current rewards: -2208.37911, mean: -0.89772
[32m[0906 16-47-32 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-47-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-47-32 @MBExp.py:227][0m Rewards obtained: [-2248.3791100366734], Lows: [0], Highs: [2278], Total time: 3978.240425
[32m[0906 16-50-27 @MBExp.py:144][0m ####################################################################
[32m[0906 16-50-27 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 16-50-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01867, current rewards: 1.06445, mean: 0.10645
[32m[0906 16-50-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01851, current rewards: 6.60939, mean: 0.11016
[32m[0906 16-50-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01855, current rewards: 12.15132, mean: 0.11047
[32m[0906 16-50-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01851, current rewards: 17.69848, mean: 0.11062
[32m[0906 16-50-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.24539, mean: 0.11069
[32m[0906 16-50-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.78896, mean: 0.11073
[32m[0906 16-50-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.33100, mean: 0.11075
[32m[0906 16-50-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 39.87246, mean: 0.11076
[32m[0906 16-50-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.36700, mean: 0.11065
[32m[0906 16-50-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 50.90234, mean: 0.11066
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 56.44989, mean: 0.11069
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 61.99082, mean: 0.11070
[32m[0906 16-50-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01847, current rewards: 67.53257, mean: 0.11071
[32m[0906 16-50-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: 73.06823, mean: 0.11071
[32m[0906 16-50-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01847, current rewards: 78.60334, mean: 0.11071
[32m[0906 16-50-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 84.14409, mean: 0.11072
[32m[0906 16-50-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01849, current rewards: 89.63695, mean: 0.11066
[32m[0906 16-50-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01848, current rewards: 95.16999, mean: 0.11066
[32m[0906 16-50-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 100.69862, mean: 0.11066
[32m[0906 16-50-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 106.23481, mean: 0.11066
[32m[0906 16-50-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 111.76482, mean: 0.11066
[32m[0906 16-50-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 117.30150, mean: 0.11066
[32m[0906 16-50-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 122.82873, mean: 0.11066
[32m[0906 16-50-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 126.22840, mean: 0.10882
[32m[0906 16-50-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 131.78875, mean: 0.10892
[32m[0906 16-50-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 137.40321, mean: 0.10905
[32m[0906 16-50-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01851, current rewards: 142.93147, mean: 0.10911
[32m[0906 16-50-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01851, current rewards: 148.46905, mean: 0.10917
[32m[0906 16-50-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01851, current rewards: 154.00030, mean: 0.10922
[32m[0906 16-50-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01851, current rewards: 159.53454, mean: 0.10927
[32m[0906 16-50-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 165.06355, mean: 0.10931
[32m[0906 16-50-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01851, current rewards: 170.59970, mean: 0.10936
[32m[0906 16-50-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01852, current rewards: 176.13874, mean: 0.10940
[32m[0906 16-50-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01852, current rewards: 181.65945, mean: 0.10943
[32m[0906 16-50-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: 187.18336, mean: 0.10946
[32m[0906 16-51-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01851, current rewards: 192.71950, mean: 0.10950
[32m[0906 16-51-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01851, current rewards: 198.26461, mean: 0.10954
[32m[0906 16-51-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: 203.80132, mean: 0.10957
[32m[0906 16-51-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01851, current rewards: 209.34972, mean: 0.10961
[32m[0906 16-51-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01851, current rewards: 214.88911, mean: 0.10964
[32m[0906 16-51-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01851, current rewards: 220.43191, mean: 0.10967
[32m[0906 16-51-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01850, current rewards: 225.87629, mean: 0.10965
[32m[0906 16-51-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01851, current rewards: 231.41278, mean: 0.10967
[32m[0906 16-51-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01851, current rewards: 236.95679, mean: 0.10970
[32m[0906 16-51-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01853, current rewards: 242.49799, mean: 0.10973
[32m[0906 16-51-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01854, current rewards: 248.03576, mean: 0.10975
[32m[0906 16-51-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: 253.58559, mean: 0.10978
[32m[0906 16-51-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01857, current rewards: 259.12901, mean: 0.10980
[32m[0906 16-51-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01859, current rewards: 264.63843, mean: 0.10981
[32m[0906 16-51-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: 270.18189, mean: 0.10983
[32m[0906 16-51-14 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-51-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-51-14 @MBExp.py:227][0m Rewards obtained: [274.6011392685537], Lows: [1], Highs: [0], Total time: 4025.552643
[32m[0906 16-54-11 @MBExp.py:144][0m ####################################################################
[32m[0906 16-54-11 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 16-54-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01826, current rewards: 0.01325, mean: 0.00132
[32m[0906 16-54-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 5.62825, mean: 0.09380
[32m[0906 16-54-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01857, current rewards: 11.22906, mean: 0.10208
[32m[0906 16-54-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 16.84002, mean: 0.10525
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01848, current rewards: 22.45039, mean: 0.10691
[32m[0906 16-54-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.05995, mean: 0.10792
[32m[0906 16-54-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 33.66698, mean: 0.10860
[32m[0906 16-54-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 39.27631, mean: 0.10910
[32m[0906 16-54-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.05594, mean: 0.10989
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 50.76170, mean: 0.11035
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 56.46785, mean: 0.11072
[32m[0906 16-54-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 62.17295, mean: 0.11102
[32m[0906 16-54-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 67.84973, mean: 0.11123
[32m[0906 16-54-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.45665, mean: 0.11130
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 79.06025, mean: 0.11135
[32m[0906 16-54-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.66541, mean: 0.11140
[32m[0906 16-54-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 90.19544, mean: 0.11135
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 95.72037, mean: 0.11130
[32m[0906 16-54-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 101.29122, mean: 0.11131
[32m[0906 16-54-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 106.77198, mean: 0.11122
[32m[0906 16-54-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 112.26234, mean: 0.11115
[32m[0906 16-54-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 117.75250, mean: 0.11109
[32m[0906 16-54-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 123.23975, mean: 0.11103
[32m[0906 16-54-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 128.73080, mean: 0.11097
[32m[0906 16-54-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 134.25303, mean: 0.11095
[32m[0906 16-54-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 140.33694, mean: 0.11138
[32m[0906 16-54-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: 146.51462, mean: 0.11184
[32m[0906 16-54-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 102.13239, mean: 0.07510
[32m[0906 16-54-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 52.13239, mean: 0.03697
[32m[0906 16-54-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 2.13239, mean: 0.00146
[32m[0906 16-54-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01852, current rewards: -47.86761, mean: -0.03170
[32m[0906 16-54-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01852, current rewards: -97.86761, mean: -0.06274
[32m[0906 16-54-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01852, current rewards: -133.44820, mean: -0.08289
[32m[0906 16-54-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01852, current rewards: -128.01485, mean: -0.07712
[32m[0906 16-54-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: -122.57802, mean: -0.07168
[32m[0906 16-54-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01852, current rewards: -117.14804, mean: -0.06656
[32m[0906 16-54-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01853, current rewards: -111.66512, mean: -0.06169
[32m[0906 16-54-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01853, current rewards: -106.07935, mean: -0.05703
[32m[0906 16-54-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01853, current rewards: -100.49836, mean: -0.05262
[32m[0906 16-54-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01853, current rewards: -94.91554, mean: -0.04843
[32m[0906 16-54-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01854, current rewards: -89.33292, mean: -0.04444
[32m[0906 16-54-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01854, current rewards: -83.91094, mean: -0.04073
[32m[0906 16-54-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: -78.42317, mean: -0.03717
[32m[0906 16-54-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01855, current rewards: -72.93531, mean: -0.03377
[32m[0906 16-54-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: -67.44417, mean: -0.03052
[32m[0906 16-54-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01855, current rewards: -61.95262, mean: -0.02741
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: -56.46518, mean: -0.02444
[32m[0906 16-54-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01858, current rewards: -51.02425, mean: -0.02162
[32m[0906 16-54-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01859, current rewards: -45.61371, mean: -0.01893
[32m[0906 16-54-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: -40.15927, mean: -0.01632
[32m[0906 16-54-58 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-54-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-54-58 @MBExp.py:227][0m Rewards obtained: [-35.764310041465855], Lows: [0], Highs: [283], Total time: 4072.876584
[32m[0906 16-57-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-57-57 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 16-57-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01832, current rewards: 0.01929, mean: 0.00193
[32m[0906 16-57-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01846, current rewards: 5.67940, mean: 0.09466
[32m[0906 16-57-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01858, current rewards: 11.24914, mean: 0.10226
[32m[0906 16-58-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: 16.82576, mean: 0.10516
[32m[0906 16-58-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 22.39507, mean: 0.10664
[32m[0906 16-58-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 27.96290, mean: 0.10755
[32m[0906 16-58-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 33.53293, mean: 0.10817
[32m[0906 16-58-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.10515, mean: 0.10863
[32m[0906 16-58-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 44.62981, mean: 0.10885
[32m[0906 16-58-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 50.11847, mean: 0.10895
[32m[0906 16-58-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 55.61144, mean: 0.10904
[32m[0906 16-58-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 61.09848, mean: 0.10910
[32m[0906 16-58-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 66.59021, mean: 0.10916
[32m[0906 16-58-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 72.07570, mean: 0.10921
[32m[0906 16-58-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 77.56746, mean: 0.10925
[32m[0906 16-58-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 83.06093, mean: 0.10929
[32m[0906 16-58-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 88.53206, mean: 0.10930
[32m[0906 16-58-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 93.94934, mean: 0.10924
[32m[0906 16-58-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 99.43679, mean: 0.10927
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 104.92816, mean: 0.10930
[32m[0906 16-58-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 110.41713, mean: 0.10932
[32m[0906 16-58-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 115.91660, mean: 0.10936
[32m[0906 16-58-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 121.39569, mean: 0.10937
[32m[0906 16-58-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01849, current rewards: 126.88574, mean: 0.10938
[32m[0906 16-58-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 132.37657, mean: 0.10940
[32m[0906 16-58-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01851, current rewards: 137.87726, mean: 0.10943
[32m[0906 16-58-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01851, current rewards: 143.35829, mean: 0.10943
[32m[0906 16-58-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 148.82368, mean: 0.10943
[32m[0906 16-58-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 154.34979, mean: 0.10947
[32m[0906 16-58-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01851, current rewards: 159.87607, mean: 0.10950
[32m[0906 16-58-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 165.40474, mean: 0.10954
[32m[0906 16-58-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01851, current rewards: 170.92957, mean: 0.10957
[32m[0906 16-58-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01851, current rewards: 176.45383, mean: 0.10960
[32m[0906 16-58-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: 181.94160, mean: 0.10960
[32m[0906 16-58-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: 187.45773, mean: 0.10962
[32m[0906 16-58-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01851, current rewards: 192.97311, mean: 0.10964
[32m[0906 16-58-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01852, current rewards: 198.48945, mean: 0.10966
[32m[0906 16-58-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01852, current rewards: 204.00208, mean: 0.10968
[32m[0906 16-58-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01852, current rewards: 209.52393, mean: 0.10970
[32m[0906 16-58-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01851, current rewards: 215.03853, mean: 0.10971
[32m[0906 16-58-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01851, current rewards: 220.55695, mean: 0.10973
[32m[0906 16-58-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01852, current rewards: 226.13330, mean: 0.10977
[32m[0906 16-58-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01852, current rewards: 231.90166, mean: 0.10991
[32m[0906 16-58-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01852, current rewards: 237.43893, mean: 0.10993
[32m[0906 16-58-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01851, current rewards: 242.97532, mean: 0.10994
[32m[0906 16-58-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01852, current rewards: 248.51203, mean: 0.10996
[32m[0906 16-58-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01851, current rewards: 254.04982, mean: 0.10998
[32m[0906 16-58-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01851, current rewards: 259.58658, mean: 0.10999
[32m[0906 16-58-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01853, current rewards: 265.12442, mean: 0.11001
[32m[0906 16-58-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01854, current rewards: 269.44968, mean: 0.10953
[32m[0906 16-58-44 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 16-58-44 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-58-45 @MBExp.py:227][0m Rewards obtained: [273.77821838244984], Lows: [0], Highs: [2], Total time: 4120.044073
[32m[0906 17-01-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-01-45 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-01-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01811, current rewards: 0.49109, mean: 0.04911
[32m[0906 17-01-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01855, current rewards: 5.98038, mean: 0.09967
[32m[0906 17-01-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01838, current rewards: 11.45564, mean: 0.10414
[32m[0906 17-01-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01833, current rewards: 16.93007, mean: 0.10581
[32m[0906 17-01-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01834, current rewards: 22.40753, mean: 0.10670
[32m[0906 17-01-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01837, current rewards: 27.88270, mean: 0.10724
[32m[0906 17-01-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01841, current rewards: 33.36578, mean: 0.10763
[32m[0906 17-01-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01843, current rewards: 38.82986, mean: 0.10786
[32m[0906 17-01-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01845, current rewards: 44.29513, mean: 0.10804
[32m[0906 17-01-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 49.76961, mean: 0.10819
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01843, current rewards: 55.23902, mean: 0.10831
[32m[0906 17-01-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01844, current rewards: 60.71526, mean: 0.10842
[32m[0906 17-01-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01844, current rewards: 66.18916, mean: 0.10851
[32m[0906 17-01-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01844, current rewards: 71.66355, mean: 0.10858
[32m[0906 17-01-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01844, current rewards: 77.14132, mean: 0.10865
[32m[0906 17-02-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01844, current rewards: 82.62078, mean: 0.10871
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01843, current rewards: 88.05223, mean: 0.10871
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01842, current rewards: 93.51836, mean: 0.10874
[32m[0906 17-02-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01841, current rewards: 98.98609, mean: 0.10878
[32m[0906 17-02-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01841, current rewards: 104.45263, mean: 0.10880
[32m[0906 17-02-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01842, current rewards: 109.92220, mean: 0.10883
[32m[0906 17-02-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01842, current rewards: 115.39050, mean: 0.10886
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01843, current rewards: 120.85949, mean: 0.10888
[32m[0906 17-02-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01843, current rewards: 126.36049, mean: 0.10893
[32m[0906 17-02-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01844, current rewards: 131.88123, mean: 0.10899
[32m[0906 17-02-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01845, current rewards: 137.40369, mean: 0.10905
[32m[0906 17-02-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01845, current rewards: 142.92416, mean: 0.10910
[32m[0906 17-02-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01845, current rewards: 148.44685, mean: 0.10915
[32m[0906 17-02-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01845, current rewards: 153.96743, mean: 0.10920
[32m[0906 17-02-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01845, current rewards: 159.49297, mean: 0.10924
[32m[0906 17-02-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01846, current rewards: 165.02144, mean: 0.10929
[32m[0906 17-02-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01846, current rewards: 170.54440, mean: 0.10932
[32m[0906 17-02-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01847, current rewards: 176.08930, mean: 0.10937
[32m[0906 17-02-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01847, current rewards: 181.58420, mean: 0.10939
[32m[0906 17-02-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01847, current rewards: 187.08750, mean: 0.10941
[32m[0906 17-02-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01847, current rewards: 192.58969, mean: 0.10943
[32m[0906 17-02-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01847, current rewards: 198.09437, mean: 0.10944
[32m[0906 17-02-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01847, current rewards: 203.59035, mean: 0.10946
[32m[0906 17-02-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01848, current rewards: 209.09399, mean: 0.10947
[32m[0906 17-02-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01848, current rewards: 214.59825, mean: 0.10949
[32m[0906 17-02-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01848, current rewards: 220.15141, mean: 0.10953
[32m[0906 17-02-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01848, current rewards: 225.74318, mean: 0.10958
[32m[0906 17-02-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01848, current rewards: 231.27299, mean: 0.10961
[32m[0906 17-02-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01848, current rewards: 234.78261, mean: 0.10870
[32m[0906 17-02-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01848, current rewards: 240.34620, mean: 0.10875
[32m[0906 17-02-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01848, current rewards: 245.90851, mean: 0.10881
[32m[0906 17-02-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: 251.47168, mean: 0.10886
[32m[0906 17-02-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01849, current rewards: 257.03413, mean: 0.10891
[32m[0906 17-02-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01849, current rewards: 262.59660, mean: 0.10896
[32m[0906 17-02-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: 270.19380, mean: 0.10983
[32m[0906 17-02-32 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-02-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-02-32 @MBExp.py:227][0m Rewards obtained: [243.12730773003022], Lows: [1], Highs: [30], Total time: 4167.07408
[32m[0906 17-05-36 @MBExp.py:144][0m ####################################################################
[32m[0906 17-05-36 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-05-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01836, current rewards: 1.10601, mean: 0.11060
[32m[0906 17-05-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01846, current rewards: 6.69593, mean: 0.11160
[32m[0906 17-05-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: 12.27347, mean: 0.11158
[32m[0906 17-05-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01859, current rewards: 17.85516, mean: 0.11159
[32m[0906 17-05-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 23.43609, mean: 0.11160
[32m[0906 17-05-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 29.02889, mean: 0.11165
[32m[0906 17-05-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01860, current rewards: 34.60084, mean: 0.11162
[32m[0906 17-05-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01860, current rewards: 40.15558, mean: 0.11154
[32m[0906 17-05-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 45.72707, mean: 0.11153
[32m[0906 17-05-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01858, current rewards: 51.30072, mean: 0.11152
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01860, current rewards: 56.87270, mean: 0.11152
[32m[0906 17-05-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 62.43789, mean: 0.11150
[32m[0906 17-05-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 68.00799, mean: 0.11149
[32m[0906 17-05-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 73.57779, mean: 0.11148
[32m[0906 17-05-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 79.11419, mean: 0.11143
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: 84.66754, mean: 0.11140
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: 90.22338, mean: 0.11139
[32m[0906 17-05-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 95.77652, mean: 0.11137
[32m[0906 17-05-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01858, current rewards: 101.32948, mean: 0.11135
[32m[0906 17-05-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01859, current rewards: 106.88359, mean: 0.11134
[32m[0906 17-05-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01859, current rewards: 112.43938, mean: 0.11133
[32m[0906 17-05-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01859, current rewards: 117.99444, mean: 0.11132
[32m[0906 17-05-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: 123.54553, mean: 0.11130
[32m[0906 17-05-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: 129.04005, mean: 0.11124
[32m[0906 17-05-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01859, current rewards: 134.58512, mean: 0.11123
[32m[0906 17-06-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: 140.15001, mean: 0.11123
[32m[0906 17-06-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 145.71132, mean: 0.11123
[32m[0906 17-06-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: 151.27425, mean: 0.11123
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01860, current rewards: 156.83472, mean: 0.11123
[32m[0906 17-06-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01859, current rewards: 162.39411, mean: 0.11123
[32m[0906 17-06-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01859, current rewards: 167.95061, mean: 0.11123
[32m[0906 17-06-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01859, current rewards: 173.51013, mean: 0.11122
[32m[0906 17-06-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 179.09229, mean: 0.11124
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 184.65164, mean: 0.11124
[32m[0906 17-06-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 190.21254, mean: 0.11124
[32m[0906 17-06-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 195.77968, mean: 0.11124
[32m[0906 17-06-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01857, current rewards: 201.33468, mean: 0.11123
[32m[0906 17-06-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: 206.89912, mean: 0.11124
[32m[0906 17-06-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01858, current rewards: 212.51007, mean: 0.11126
[32m[0906 17-06-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01857, current rewards: 218.06913, mean: 0.11126
[32m[0906 17-06-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01857, current rewards: 223.63764, mean: 0.11126
[32m[0906 17-06-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01857, current rewards: 229.19863, mean: 0.11126
[32m[0906 17-06-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01857, current rewards: 234.75845, mean: 0.11126
[32m[0906 17-06-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: 240.31991, mean: 0.11126
[32m[0906 17-06-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01857, current rewards: 245.88034, mean: 0.11126
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01857, current rewards: 251.43584, mean: 0.11125
[32m[0906 17-06-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: 256.99647, mean: 0.11125
[32m[0906 17-06-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01856, current rewards: 262.55529, mean: 0.11125
[32m[0906 17-06-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 268.91704, mean: 0.11158
[32m[0906 17-06-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 240.82597, mean: 0.09790
[32m[0906 17-06-23 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-06-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-06-23 @MBExp.py:227][0m Rewards obtained: [200.8259721689219], Lows: [0], Highs: [71], Total time: 4214.2438250000005
[32m[0906 17-09-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-09-28 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-09-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01841, current rewards: 0.26082, mean: 0.02608
[32m[0906 17-09-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01850, current rewards: 5.80182, mean: 0.09670
[32m[0906 17-09-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01848, current rewards: 11.33679, mean: 0.10306
[32m[0906 17-09-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 16.87827, mean: 0.10549
[32m[0906 17-09-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 22.41700, mean: 0.10675
[32m[0906 17-09-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 27.95835, mean: 0.10753
[32m[0906 17-09-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 33.55301, mean: 0.10824
[32m[0906 17-09-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 39.21955, mean: 0.10894
[32m[0906 17-09-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 44.80348, mean: 0.10928
[32m[0906 17-09-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.38864, mean: 0.10954
[32m[0906 17-09-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 55.96942, mean: 0.10974
[32m[0906 17-09-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 61.55342, mean: 0.10992
[32m[0906 17-09-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01847, current rewards: 67.13596, mean: 0.11006
[32m[0906 17-09-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: 72.97990, mean: 0.11058
[32m[0906 17-09-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 78.61617, mean: 0.11073
[32m[0906 17-09-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.23955, mean: 0.11084
[32m[0906 17-09-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.86763, mean: 0.11095
[32m[0906 17-09-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 95.50057, mean: 0.11105
[32m[0906 17-09-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 101.13212, mean: 0.11113
[32m[0906 17-09-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 107.36959, mean: 0.11184
[32m[0906 17-09-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 113.16483, mean: 0.11204
[32m[0906 17-09-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 118.96007, mean: 0.11223
[32m[0906 17-09-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 124.75530, mean: 0.11239
[32m[0906 17-09-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 130.34468, mean: 0.11237
[32m[0906 17-09-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 134.81744, mean: 0.11142
[32m[0906 17-09-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01851, current rewards: 140.40337, mean: 0.11143
[32m[0906 17-09-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: 145.98490, mean: 0.11144
[32m[0906 17-09-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 151.57203, mean: 0.11145
[32m[0906 17-09-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 157.15738, mean: 0.11146
[32m[0906 17-09-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01852, current rewards: 162.73922, mean: 0.11147
[32m[0906 17-09-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01852, current rewards: 168.34688, mean: 0.11149
[32m[0906 17-09-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: 173.92355, mean: 0.11149
[32m[0906 17-09-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 179.51788, mean: 0.11150
[32m[0906 17-09-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01853, current rewards: 185.10862, mean: 0.11151
[32m[0906 17-10-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: 190.69620, mean: 0.11152
[32m[0906 17-10-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 196.28956, mean: 0.11153
[32m[0906 17-10-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 201.87819, mean: 0.11153
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: 207.48525, mean: 0.11155
[32m[0906 17-10-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: 213.08371, mean: 0.11156
[32m[0906 17-10-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: 218.68573, mean: 0.11157
[32m[0906 17-10-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: 224.29112, mean: 0.11159
[32m[0906 17-10-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 229.89352, mean: 0.11160
[32m[0906 17-10-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: 235.49420, mean: 0.11161
[32m[0906 17-10-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01855, current rewards: 241.09262, mean: 0.11162
[32m[0906 17-10-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: 246.69558, mean: 0.11163
[32m[0906 17-10-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01855, current rewards: 252.29561, mean: 0.11164
[32m[0906 17-10-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01855, current rewards: 257.89786, mean: 0.11164
[32m[0906 17-10-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01855, current rewards: 263.46387, mean: 0.11164
[32m[0906 17-10-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01855, current rewards: 269.07236, mean: 0.11165
[32m[0906 17-10-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01855, current rewards: 274.68133, mean: 0.11166
[32m[0906 17-10-15 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-10-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-10-15 @MBExp.py:227][0m Rewards obtained: [279.1675961471773], Lows: [0], Highs: [2], Total time: 4261.399855000001
[32m[0906 17-13-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-13-23 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-13-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01817, current rewards: 1.10432, mean: 0.11043
[32m[0906 17-13-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.63983, mean: 0.11066
[32m[0906 17-13-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01840, current rewards: 12.16983, mean: 0.11063
[32m[0906 17-13-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01837, current rewards: 17.69853, mean: 0.11062
[32m[0906 17-13-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01840, current rewards: 23.23210, mean: 0.11063
[32m[0906 17-13-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01842, current rewards: 28.76480, mean: 0.11063
[32m[0906 17-13-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.23044, mean: 0.11042
[32m[0906 17-13-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01845, current rewards: 39.76188, mean: 0.11045
[32m[0906 17-13-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.44490, mean: 0.11084
[32m[0906 17-13-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 51.00710, mean: 0.11089
[32m[0906 17-13-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.57424, mean: 0.11093
[32m[0906 17-13-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 62.14260, mean: 0.11097
[32m[0906 17-13-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 67.70852, mean: 0.11100
[32m[0906 17-13-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.27647, mean: 0.11102
[32m[0906 17-13-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 78.84590, mean: 0.11105
[32m[0906 17-13-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.40811, mean: 0.11106
[32m[0906 17-13-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.97403, mean: 0.11108
[32m[0906 17-13-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 93.41521, mean: 0.10862
[32m[0906 17-13-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 98.93808, mean: 0.10872
[32m[0906 17-13-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 104.46007, mean: 0.10881
[32m[0906 17-13-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 109.98130, mean: 0.10889
[32m[0906 17-13-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 115.50332, mean: 0.10897
[32m[0906 17-13-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: 120.97230, mean: 0.10898
[32m[0906 17-13-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 126.49980, mean: 0.10905
[32m[0906 17-13-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 132.02613, mean: 0.10911
[32m[0906 17-13-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: 137.55403, mean: 0.10917
[32m[0906 17-13-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 143.08033, mean: 0.10922
[32m[0906 17-13-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 148.60483, mean: 0.10927
[32m[0906 17-13-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: 154.12970, mean: 0.10931
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01854, current rewards: 159.61772, mean: 0.10933
[32m[0906 17-13-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: 165.16002, mean: 0.10938
[32m[0906 17-13-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: 170.70260, mean: 0.10942
[32m[0906 17-13-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 176.24610, mean: 0.10947
[32m[0906 17-13-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: 181.79076, mean: 0.10951
[32m[0906 17-13-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01853, current rewards: 187.32973, mean: 0.10955
[32m[0906 17-13-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 192.87368, mean: 0.10959
[32m[0906 17-13-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01854, current rewards: 198.41300, mean: 0.10962
[32m[0906 17-13-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01854, current rewards: 203.95670, mean: 0.10965
[32m[0906 17-13-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01854, current rewards: 209.59476, mean: 0.10974
[32m[0906 17-13-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01854, current rewards: 215.14652, mean: 0.10977
[32m[0906 17-14-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01854, current rewards: 220.66249, mean: 0.10978
[32m[0906 17-14-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 226.21676, mean: 0.10981
[32m[0906 17-14-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: 231.76669, mean: 0.10984
[32m[0906 17-14-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01855, current rewards: 237.31937, mean: 0.10987
[32m[0906 17-14-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: 242.86925, mean: 0.10990
[32m[0906 17-14-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01855, current rewards: 248.41906, mean: 0.10992
[32m[0906 17-14-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01855, current rewards: 253.96685, mean: 0.10994
[32m[0906 17-14-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01855, current rewards: 259.44393, mean: 0.10993
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01855, current rewards: 264.99202, mean: 0.10996
[32m[0906 17-14-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 270.51842, mean: 0.10997
[32m[0906 17-14-10 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-14-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-14-10 @MBExp.py:227][0m Rewards obtained: [274.9590299945476], Lows: [1], Highs: [0], Total time: 4308.588803000001
[32m[0906 17-17-19 @MBExp.py:144][0m ####################################################################
[32m[0906 17-17-19 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 17-17-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01813, current rewards: -0.94871, mean: -0.09487
[32m[0906 17-17-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01835, current rewards: 4.62763, mean: 0.07713
[32m[0906 17-17-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 10.20827, mean: 0.09280
[32m[0906 17-17-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 15.78070, mean: 0.09863
[32m[0906 17-17-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01847, current rewards: 21.35797, mean: 0.10170
[32m[0906 17-17-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 26.88047, mean: 0.10339
[32m[0906 17-17-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 32.45095, mean: 0.10468
[32m[0906 17-17-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 35.87954, mean: 0.09967
[32m[0906 17-17-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 41.41214, mean: 0.10101
[32m[0906 17-17-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 46.94396, mean: 0.10205
[32m[0906 17-17-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 52.47570, mean: 0.10289
[32m[0906 17-17-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 58.00235, mean: 0.10358
[32m[0906 17-17-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 63.53766, mean: 0.10416
[32m[0906 17-17-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 69.12195, mean: 0.10473
[32m[0906 17-17-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 74.68787, mean: 0.10519
[32m[0906 17-17-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: 80.24743, mean: 0.10559
[32m[0906 17-17-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: 85.81156, mean: 0.10594
[32m[0906 17-17-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01859, current rewards: 91.36522, mean: 0.10624
[32m[0906 17-17-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01860, current rewards: 96.92295, mean: 0.10651
[32m[0906 17-17-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01860, current rewards: 102.48347, mean: 0.10675
[32m[0906 17-17-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 108.03927, mean: 0.10697
[32m[0906 17-17-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01861, current rewards: 111.49193, mean: 0.10518
[32m[0906 17-17-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01861, current rewards: 116.86282, mean: 0.10528
[32m[0906 17-17-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 122.39737, mean: 0.10551
[32m[0906 17-17-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 127.93631, mean: 0.10573
[32m[0906 17-17-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 133.46809, mean: 0.10593
[32m[0906 17-17-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 139.00055, mean: 0.10611
[32m[0906 17-17-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: 144.54178, mean: 0.10628
[32m[0906 17-17-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 150.07347, mean: 0.10644
[32m[0906 17-17-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: 155.60759, mean: 0.10658
[32m[0906 17-17-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01860, current rewards: 159.14173, mean: 0.10539
[32m[0906 17-17-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 164.79617, mean: 0.10564
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 170.36556, mean: 0.10582
[32m[0906 17-17-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 175.93779, mean: 0.10599
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01860, current rewards: 181.50838, mean: 0.10615
[32m[0906 17-17-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 187.08113, mean: 0.10630
[32m[0906 17-17-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01860, current rewards: 192.65327, mean: 0.10644
[32m[0906 17-17-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01860, current rewards: 198.22459, mean: 0.10657
[32m[0906 17-17-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01861, current rewards: 201.89957, mean: 0.10571
[32m[0906 17-17-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 208.80836, mean: 0.10653
[32m[0906 17-17-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: 216.66789, mean: 0.10779
[32m[0906 17-17-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01860, current rewards: 224.52743, mean: 0.10899
[32m[0906 17-17-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: 232.38697, mean: 0.11014
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01860, current rewards: 240.24651, mean: 0.11123
[32m[0906 17-18-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01859, current rewards: 194.87527, mean: 0.08818
[32m[0906 17-18-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: 144.87527, mean: 0.06410
[32m[0906 17-18-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01859, current rewards: 94.87527, mean: 0.04107
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01859, current rewards: 44.87527, mean: 0.01901
[32m[0906 17-18-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01858, current rewards: -5.12473, mean: -0.00213
[32m[0906 17-18-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01858, current rewards: -55.12473, mean: -0.02241
[32m[0906 17-18-06 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-18-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-18-06 @MBExp.py:227][0m Rewards obtained: [-95.12472651527753], Lows: [5], Highs: [336], Total time: 4355.828409000001
[32m[0906 17-21-17 @MBExp.py:144][0m ####################################################################
[32m[0906 17-21-17 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01813, current rewards: 0.00733, mean: 0.00073
[32m[0906 17-21-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01833, current rewards: 5.60108, mean: 0.09335
[32m[0906 17-21-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01837, current rewards: 11.13206, mean: 0.10120
[32m[0906 17-21-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01838, current rewards: 16.66272, mean: 0.10414
[32m[0906 17-21-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01840, current rewards: 22.19663, mean: 0.10570
[32m[0906 17-21-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01840, current rewards: 27.72864, mean: 0.10665
[32m[0906 17-21-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01837, current rewards: 33.23798, mean: 0.10722
[32m[0906 17-21-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01840, current rewards: 38.73020, mean: 0.10758
[32m[0906 17-21-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01843, current rewards: 44.22010, mean: 0.10785
[32m[0906 17-21-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01842, current rewards: 49.71742, mean: 0.10808
[32m[0906 17-21-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01843, current rewards: 55.21259, mean: 0.10826
[32m[0906 17-21-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01843, current rewards: 58.94217, mean: 0.10525
[32m[0906 17-21-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01844, current rewards: 64.86005, mean: 0.10633
[32m[0906 17-21-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01844, current rewards: 70.77793, mean: 0.10724
[32m[0906 17-21-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01843, current rewards: 53.41891, mean: 0.07524
[32m[0906 17-21-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01843, current rewards: 3.41891, mean: 0.00450
[32m[0906 17-21-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01842, current rewards: -46.58109, mean: -0.05751
[32m[0906 17-21-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01843, current rewards: -96.58109, mean: -0.11230
[32m[0906 17-21-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01842, current rewards: -97.74868, mean: -0.10742
[32m[0906 17-21-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01843, current rewards: -92.25491, mean: -0.09610
[32m[0906 17-21-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01844, current rewards: -86.75967, mean: -0.08590
[32m[0906 17-21-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01843, current rewards: -81.26643, mean: -0.07667
[32m[0906 17-21-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01844, current rewards: -75.72539, mean: -0.06822
[32m[0906 17-21-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01845, current rewards: -70.22803, mean: -0.06054
[32m[0906 17-21-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01846, current rewards: -64.72717, mean: -0.05349
[32m[0906 17-21-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01846, current rewards: -59.22610, mean: -0.04700
[32m[0906 17-21-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01845, current rewards: -53.72635, mean: -0.04101
[32m[0906 17-21-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01846, current rewards: -48.22552, mean: -0.03546
[32m[0906 17-21-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01846, current rewards: -42.72637, mean: -0.03030
[32m[0906 17-21-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01846, current rewards: -37.22827, mean: -0.02550
[32m[0906 17-21-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01847, current rewards: -30.93159, mean: -0.02048
[32m[0906 17-21-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01847, current rewards: -25.44925, mean: -0.01631
[32m[0906 17-21-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01847, current rewards: -19.96321, mean: -0.01240
[32m[0906 17-21-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01848, current rewards: -14.48517, mean: -0.00873
[32m[0906 17-21-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01848, current rewards: -8.99884, mean: -0.00526
[32m[0906 17-21-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01848, current rewards: -3.51350, mean: -0.00200
[32m[0906 17-21-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01848, current rewards: 1.97233, mean: 0.00109
[32m[0906 17-21-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01848, current rewards: 7.45614, mean: 0.00401
[32m[0906 17-21-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01848, current rewards: 12.94135, mean: 0.00678
[32m[0906 17-21-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01849, current rewards: 18.40168, mean: 0.00939
[32m[0906 17-21-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01849, current rewards: 24.08583, mean: 0.01198
[32m[0906 17-21-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01849, current rewards: 29.59726, mean: 0.01437
[32m[0906 17-21-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01849, current rewards: 35.10899, mean: 0.01664
[32m[0906 17-21-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01849, current rewards: 40.61645, mean: 0.01880
[32m[0906 17-21-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01849, current rewards: 46.12431, mean: 0.02087
[32m[0906 17-21-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01849, current rewards: 51.62991, mean: 0.02285
[32m[0906 17-22-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: 57.13931, mean: 0.02474
[32m[0906 17-22-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01849, current rewards: 62.57573, mean: 0.02652
[32m[0906 17-22-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01849, current rewards: 68.06924, mean: 0.02824
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01850, current rewards: 73.55628, mean: 0.02990
[32m[0906 17-22-04 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-22-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-22-04 @MBExp.py:227][0m Rewards obtained: [77.94561348005016], Lows: [1], Highs: [177], Total time: 4402.862482
[32m[0906 17-25-17 @MBExp.py:144][0m ####################################################################
[32m[0906 17-25-17 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 17-25-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01913, current rewards: -20.00000, mean: -2.00000
[32m[0906 17-25-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01873, current rewards: -120.00000, mean: -2.00000
[32m[0906 17-25-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01866, current rewards: -220.00000, mean: -2.00000
[32m[0906 17-25-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: -320.00000, mean: -2.00000
[32m[0906 17-25-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01857, current rewards: -420.00000, mean: -2.00000
[32m[0906 17-25-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: -520.00000, mean: -2.00000
[32m[0906 17-25-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01858, current rewards: -620.00000, mean: -2.00000
[32m[0906 17-25-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01859, current rewards: -639.74887, mean: -1.77708
[32m[0906 17-25-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01858, current rewards: -634.15745, mean: -1.54673
[32m[0906 17-25-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: -628.56869, mean: -1.36645
[32m[0906 17-25-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: -622.97507, mean: -1.22152
[32m[0906 17-25-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01859, current rewards: -617.39913, mean: -1.10250
[32m[0906 17-25-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: -611.81909, mean: -1.00298
[32m[0906 17-25-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: -606.23269, mean: -0.91853
[32m[0906 17-25-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: -600.70359, mean: -0.84606
[32m[0906 17-25-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: -595.09441, mean: -0.78302
[32m[0906 17-25-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: -589.49274, mean: -0.72777
[32m[0906 17-25-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: -583.90886, mean: -0.67896
[32m[0906 17-25-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: -578.31264, mean: -0.63551
[32m[0906 17-25-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: -572.70546, mean: -0.59657
[32m[0906 17-25-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: -567.12034, mean: -0.56151
[32m[0906 17-25-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: -561.51999, mean: -0.52974
[32m[0906 17-25-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: -555.97990, mean: -0.50088
[32m[0906 17-25-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: -550.48156, mean: -0.47455
[32m[0906 17-25-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: -544.98938, mean: -0.45040
[32m[0906 17-25-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: -539.49294, mean: -0.42817
[32m[0906 17-25-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: -534.00018, mean: -0.40763
[32m[0906 17-25-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01856, current rewards: -528.50702, mean: -0.38861
[32m[0906 17-25-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: -523.01695, mean: -0.37093
[32m[0906 17-25-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01857, current rewards: -517.52522, mean: -0.35447
[32m[0906 17-25-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01857, current rewards: -512.05260, mean: -0.33911
[32m[0906 17-25-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01857, current rewards: -506.57186, mean: -0.32473
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01857, current rewards: -501.08299, mean: -0.31123
[32m[0906 17-25-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01857, current rewards: -544.12285, mean: -0.32778
[32m[0906 17-25-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01857, current rewards: -644.12285, mean: -0.37668
[32m[0906 17-25-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: -744.12285, mean: -0.42280
[32m[0906 17-25-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01858, current rewards: -844.12285, mean: -0.46637
[32m[0906 17-25-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: -944.12285, mean: -0.50759
[32m[0906 17-25-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01857, current rewards: -1044.12285, mean: -0.54666
[32m[0906 17-25-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01857, current rewards: -1144.12285, mean: -0.58374
[32m[0906 17-25-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01857, current rewards: -1244.12285, mean: -0.61897
[32m[0906 17-25-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01857, current rewards: -1344.12285, mean: -0.65249
[32m[0906 17-25-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01857, current rewards: -1444.12285, mean: -0.68442
[32m[0906 17-25-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: -1544.12285, mean: -0.71487
[32m[0906 17-25-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01856, current rewards: -1644.12285, mean: -0.74395
[32m[0906 17-26-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01857, current rewards: -1744.12285, mean: -0.77174
[32m[0906 17-26-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01857, current rewards: -1844.12285, mean: -0.79832
[32m[0906 17-26-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01857, current rewards: -1944.12285, mean: -0.82378
[32m[0906 17-26-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: -2044.12285, mean: -0.84818
[32m[0906 17-26-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: -2144.12285, mean: -0.87159
[32m[0906 17-26-04 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-26-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-26-05 @MBExp.py:227][0m Rewards obtained: [-2224.1228464841633], Lows: [1185], Highs: [0], Total time: 4450.061257
[32m[0906 17-29-20 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-20 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 17-29-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.05812, mean: 0.10581
[32m[0906 17-29-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01852, current rewards: 6.60548, mean: 0.11009
[32m[0906 17-29-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01857, current rewards: 12.15199, mean: 0.11047
[32m[0906 17-29-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 17.69831, mean: 0.11061
[32m[0906 17-29-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01855, current rewards: 23.24559, mean: 0.11069
[32m[0906 17-29-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01858, current rewards: 28.76331, mean: 0.11063
[32m[0906 17-29-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 34.30503, mean: 0.11066
[32m[0906 17-29-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 39.86227, mean: 0.11073
[32m[0906 17-29-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01857, current rewards: 45.42295, mean: 0.11079
[32m[0906 17-29-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 50.98542, mean: 0.11084
[32m[0906 17-29-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 56.54587, mean: 0.11087
[32m[0906 17-29-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01859, current rewards: 62.10974, mean: 0.11091
[32m[0906 17-29-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 67.67031, mean: 0.11093
[32m[0906 17-29-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 73.30928, mean: 0.11107
[32m[0906 17-29-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 78.88493, mean: 0.11111
[32m[0906 17-29-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 84.46175, mean: 0.11113
[32m[0906 17-29-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01856, current rewards: 90.03502, mean: 0.11115
[32m[0906 17-29-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 95.61976, mean: 0.11119
[32m[0906 17-29-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 101.16311, mean: 0.11117
[32m[0906 17-29-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 106.71190, mean: 0.11116
[32m[0906 17-29-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 112.25731, mean: 0.11115
[32m[0906 17-29-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 117.82729, mean: 0.11116
[32m[0906 17-29-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 123.37014, mean: 0.11114
[32m[0906 17-29-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 128.92153, mean: 0.11114
[32m[0906 17-29-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 133.68144, mean: 0.11048
[32m[0906 17-29-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 141.14163, mean: 0.11202
[32m[0906 17-29-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 148.60182, mean: 0.11344
[32m[0906 17-29-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 156.06201, mean: 0.11475
[32m[0906 17-29-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: 163.52221, mean: 0.11597
[32m[0906 17-29-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01854, current rewards: 169.61845, mean: 0.11618
[32m[0906 17-29-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: 121.71784, mean: 0.08061
[32m[0906 17-29-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: 71.71784, mean: 0.04597
[32m[0906 17-29-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01853, current rewards: 21.71784, mean: 0.01349
[32m[0906 17-29-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: -28.28216, mean: -0.01704
[32m[0906 17-29-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: -78.28216, mean: -0.04578
[32m[0906 17-29-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: -128.28216, mean: -0.07289
[32m[0906 17-29-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: -178.28216, mean: -0.09850
[32m[0906 17-29-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: -228.28216, mean: -0.12273
[32m[0906 17-29-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: -278.28216, mean: -0.14570
[32m[0906 17-29-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: -328.28216, mean: -0.16749
[32m[0906 17-29-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: -378.28216, mean: -0.18820
[32m[0906 17-29-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01856, current rewards: -428.28216, mean: -0.20790
[32m[0906 17-29-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01857, current rewards: -478.28216, mean: -0.22667
[32m[0906 17-30-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01857, current rewards: -528.28216, mean: -0.24458
[32m[0906 17-30-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01856, current rewards: -578.28216, mean: -0.26167
[32m[0906 17-30-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: -628.28216, mean: -0.27800
[32m[0906 17-30-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: -678.28216, mean: -0.29363
[32m[0906 17-30-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01857, current rewards: -728.28216, mean: -0.30859
[32m[0906 17-30-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01857, current rewards: -778.28216, mean: -0.32294
[32m[0906 17-30-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01857, current rewards: -828.28216, mean: -0.33670
[32m[0906 17-30-07 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-30-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-30-07 @MBExp.py:227][0m Rewards obtained: [-868.2821556557847], Lows: [1], Highs: [1038], Total time: 4497.2830890000005
[32m[0906 17-33-24 @MBExp.py:144][0m ####################################################################
[32m[0906 17-33-24 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 17-33-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01803, current rewards: 1.06846, mean: 0.10685
[32m[0906 17-33-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01840, current rewards: 6.60129, mean: 0.11002
[32m[0906 17-33-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01848, current rewards: 12.18631, mean: 0.11078
[32m[0906 17-33-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01845, current rewards: 17.76124, mean: 0.11101
[32m[0906 17-33-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01847, current rewards: 23.39194, mean: 0.11139
[32m[0906 17-33-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01846, current rewards: 28.95685, mean: 0.11137
[32m[0906 17-33-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01843, current rewards: 34.53870, mean: 0.11142
[32m[0906 17-33-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01845, current rewards: 40.12581, mean: 0.11146
[32m[0906 17-33-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.70634, mean: 0.11148
[32m[0906 17-33-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 51.28553, mean: 0.11149
[32m[0906 17-33-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 56.86510, mean: 0.11150
[32m[0906 17-33-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 62.44441, mean: 0.11151
[32m[0906 17-33-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 68.01672, mean: 0.11150
[32m[0906 17-33-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 73.62103, mean: 0.11155
[32m[0906 17-33-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 79.19334, mean: 0.11154
[32m[0906 17-33-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.76998, mean: 0.11154
[32m[0906 17-33-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 90.34383, mean: 0.11154
[32m[0906 17-33-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 95.91847, mean: 0.11153
[32m[0906 17-33-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 101.49601, mean: 0.11153
[32m[0906 17-33-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 107.06511, mean: 0.11153
[32m[0906 17-33-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 112.63783, mean: 0.11152
[32m[0906 17-33-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 118.20775, mean: 0.11152
[32m[0906 17-33-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 123.77597, mean: 0.11151
[32m[0906 17-33-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 129.25383, mean: 0.11143
[32m[0906 17-33-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 136.90891, mean: 0.11315
[32m[0906 17-33-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01850, current rewards: 144.56399, mean: 0.11473
[32m[0906 17-33-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01850, current rewards: 152.21907, mean: 0.11620
[32m[0906 17-33-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01850, current rewards: 159.87415, mean: 0.11755
[32m[0906 17-33-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01850, current rewards: 167.52923, mean: 0.11882
[32m[0906 17-33-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01851, current rewards: 148.92457, mean: 0.10200
[32m[0906 17-33-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 98.92457, mean: 0.06551
[32m[0906 17-33-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01850, current rewards: 48.92457, mean: 0.03136
[32m[0906 17-33-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01851, current rewards: -1.07543, mean: -0.00067
[32m[0906 17-33-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: -51.07543, mean: -0.03077
[32m[0906 17-33-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: -101.07543, mean: -0.05911
[32m[0906 17-33-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01851, current rewards: -151.07543, mean: -0.08584
[32m[0906 17-33-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01851, current rewards: -201.07543, mean: -0.11109
[32m[0906 17-33-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: -251.07543, mean: -0.13499
[32m[0906 17-34-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01850, current rewards: -301.07543, mean: -0.15763
[32m[0906 17-34-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01850, current rewards: -351.07543, mean: -0.17912
[32m[0906 17-34-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01849, current rewards: -401.07543, mean: -0.19954
[32m[0906 17-34-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01850, current rewards: -451.07543, mean: -0.21897
[32m[0906 17-34-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01850, current rewards: -501.07543, mean: -0.23748
[32m[0906 17-34-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01850, current rewards: -545.56087, mean: -0.25257
[32m[0906 17-34-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01850, current rewards: -540.41522, mean: -0.24453
[32m[0906 17-34-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01850, current rewards: -535.48096, mean: -0.23694
[32m[0906 17-34-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01851, current rewards: -530.61346, mean: -0.22970
[32m[0906 17-34-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01851, current rewards: -525.74596, mean: -0.22277
[32m[0906 17-34-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01851, current rewards: -520.87846, mean: -0.21613
[32m[0906 17-34-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01851, current rewards: -516.01096, mean: -0.20976
[32m[0906 17-34-11 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-34-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-34-11 @MBExp.py:227][0m Rewards obtained: [-512.1169586498486], Lows: [1], Highs: [717], Total time: 4544.343925
[32m[0906 17-37-30 @MBExp.py:144][0m ####################################################################
[32m[0906 17-37-30 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 17-37-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.22585, mean: 0.12258
[32m[0906 17-37-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01835, current rewards: 6.76970, mean: 0.11283
[32m[0906 17-37-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01838, current rewards: 12.31454, mean: 0.11195
[32m[0906 17-37-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01841, current rewards: 17.81390, mean: 0.11134
[32m[0906 17-37-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 23.35781, mean: 0.11123
[32m[0906 17-37-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 27.75939, mean: 0.10677
[32m[0906 17-37-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 33.32156, mean: 0.10749
[32m[0906 17-37-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01852, current rewards: 38.88442, mean: 0.10801
[32m[0906 17-37-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 44.45047, mean: 0.10842
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 50.01670, mean: 0.10873
[32m[0906 17-37-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 55.58150, mean: 0.10898
[32m[0906 17-37-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 61.08425, mean: 0.10908
[32m[0906 17-37-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 66.64090, mean: 0.10925
[32m[0906 17-37-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 72.19318, mean: 0.10938
[32m[0906 17-37-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 77.74885, mean: 0.10951
[32m[0906 17-37-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 83.30722, mean: 0.10961
[32m[0906 17-37-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 88.85688, mean: 0.10970
[32m[0906 17-37-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 94.41563, mean: 0.10979
[32m[0906 17-37-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 99.97269, mean: 0.10986
[32m[0906 17-37-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 105.56639, mean: 0.10996
[32m[0906 17-37-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 111.14455, mean: 0.11004
[32m[0906 17-37-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 116.65207, mean: 0.11005
[32m[0906 17-37-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 122.22543, mean: 0.11011
[32m[0906 17-37-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 127.79198, mean: 0.11017
[32m[0906 17-37-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01854, current rewards: 133.36345, mean: 0.11022
[32m[0906 17-37-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 138.93420, mean: 0.11027
[32m[0906 17-37-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 144.50806, mean: 0.11031
[32m[0906 17-37-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01855, current rewards: 150.08139, mean: 0.11035
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 155.70486, mean: 0.11043
[32m[0906 17-37-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 161.22155, mean: 0.11043
[32m[0906 17-37-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01856, current rewards: 166.77536, mean: 0.11045
[32m[0906 17-37-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 172.32917, mean: 0.11047
[32m[0906 17-38-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 177.88525, mean: 0.11049
[32m[0906 17-38-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01856, current rewards: 183.43432, mean: 0.11050
[32m[0906 17-38-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01856, current rewards: 188.98592, mean: 0.11052
[32m[0906 17-38-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01856, current rewards: 194.57806, mean: 0.11056
[32m[0906 17-38-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01856, current rewards: 200.03756, mean: 0.11052
[32m[0906 17-38-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01856, current rewards: 205.61111, mean: 0.11054
[32m[0906 17-38-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01856, current rewards: 211.18514, mean: 0.11057
[32m[0906 17-38-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01856, current rewards: 216.76191, mean: 0.11059
[32m[0906 17-38-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01856, current rewards: 222.33500, mean: 0.11061
[32m[0906 17-38-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01857, current rewards: 227.90725, mean: 0.11063
[32m[0906 17-38-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01856, current rewards: 233.48248, mean: 0.11066
[32m[0906 17-38-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: 239.05556, mean: 0.11067
[32m[0906 17-38-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01856, current rewards: 244.66847, mean: 0.11071
[32m[0906 17-38-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: 250.35108, mean: 0.11077
[32m[0906 17-38-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01857, current rewards: 255.92405, mean: 0.11079
[32m[0906 17-38-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01857, current rewards: 261.56674, mean: 0.11083
[32m[0906 17-38-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01857, current rewards: 267.14473, mean: 0.11085
[32m[0906 17-38-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01857, current rewards: 272.72161, mean: 0.11086
[32m[0906 17-38-17 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-38-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-38-17 @MBExp.py:227][0m Rewards obtained: [277.1846155022504], Lows: [0], Highs: [1], Total time: 4591.5635330000005
[32m[0906 17-41-38 @MBExp.py:144][0m ####################################################################
[32m[0906 17-41-38 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 17-41-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02262, current rewards: -14.00000, mean: -1.40000
[32m[0906 17-41-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02209, current rewards: -114.00000, mean: -1.90000
[32m[0906 17-41-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02197, current rewards: -214.00000, mean: -1.94545
[32m[0906 17-41-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02223, current rewards: -314.00000, mean: -1.96250
[32m[0906 17-41-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02326, current rewards: -414.00000, mean: -1.97143
[32m[0906 17-41-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02370, current rewards: -514.00000, mean: -1.97692
[32m[0906 17-41-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02423, current rewards: -614.00000, mean: -1.98065
[32m[0906 17-41-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02450, current rewards: -714.00000, mean: -1.98333
[32m[0906 17-41-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02474, current rewards: -814.00000, mean: -1.98537
[32m[0906 17-41-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02482, current rewards: -914.00000, mean: -1.98696
[32m[0906 17-41-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02499, current rewards: -1014.00000, mean: -1.98824
[32m[0906 17-41-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02512, current rewards: -1114.00000, mean: -1.98929
[32m[0906 17-41-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02494, current rewards: -1168.92327, mean: -1.91627
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02445, current rewards: -1163.02308, mean: -1.76216
[32m[0906 17-41-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02404, current rewards: -1157.11705, mean: -1.62974
[32m[0906 17-41-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02368, current rewards: -1151.21523, mean: -1.51476
[32m[0906 17-41-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02334, current rewards: -1145.29611, mean: -1.41395
[32m[0906 17-41-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02306, current rewards: -1139.39814, mean: -1.32488
[32m[0906 17-41-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02282, current rewards: -1148.02854, mean: -1.26157
[32m[0906 17-42-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02261, current rewards: -1240.02854, mean: -1.29170
[32m[0906 17-42-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02241, current rewards: -1340.02854, mean: -1.32676
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02223, current rewards: -1440.02854, mean: -1.35852
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02205, current rewards: -1540.02854, mean: -1.38741
[32m[0906 17-42-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02190, current rewards: -1640.02854, mean: -1.41382
[32m[0906 17-42-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02176, current rewards: -1740.02854, mean: -1.43804
[32m[0906 17-42-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02164, current rewards: -1840.02854, mean: -1.46034
[32m[0906 17-42-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02152, current rewards: -1940.02854, mean: -1.48094
[32m[0906 17-42-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02141, current rewards: -2040.02854, mean: -1.50002
[32m[0906 17-42-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02130, current rewards: -2140.02854, mean: -1.51775
[32m[0906 17-42-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02121, current rewards: -2240.02854, mean: -1.53427
[32m[0906 17-42-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02112, current rewards: -2340.02854, mean: -1.54969
[32m[0906 17-42-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02103, current rewards: -2440.02854, mean: -1.56412
[32m[0906 17-42-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02096, current rewards: -2540.02854, mean: -1.57766
[32m[0906 17-42-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02089, current rewards: -2640.02854, mean: -1.59038
[32m[0906 17-42-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02084, current rewards: -2678.39672, mean: -1.56631
[32m[0906 17-42-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02077, current rewards: -2672.73987, mean: -1.51860
[32m[0906 17-42-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02072, current rewards: -2667.34182, mean: -1.47367
[32m[0906 17-42-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02066, current rewards: -2661.73133, mean: -1.43104
[32m[0906 17-42-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02060, current rewards: -2656.11657, mean: -1.39064
[32m[0906 17-42-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02055, current rewards: -2650.51359, mean: -1.35230
[32m[0906 17-42-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02050, current rewards: -2644.90147, mean: -1.31587
[32m[0906 17-42-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02045, current rewards: -2639.29932, mean: -1.28121
[32m[0906 17-42-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02041, current rewards: -2633.68228, mean: -1.24819
[32m[0906 17-42-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02038, current rewards: -2683.21608, mean: -1.24223
[32m[0906 17-42-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02035, current rewards: -2783.21608, mean: -1.25937
[32m[0906 17-42-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02030, current rewards: -2883.21608, mean: -1.27576
[32m[0906 17-42-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02026, current rewards: -2983.21608, mean: -1.29144
[32m[0906 17-42-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02022, current rewards: -3083.21608, mean: -1.30645
[32m[0906 17-42-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02019, current rewards: -3183.21608, mean: -1.32084
[32m[0906 17-42-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02015, current rewards: -3283.21608, mean: -1.33464
[32m[0906 17-42-29 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 17-42-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-42-29 @MBExp.py:227][0m Rewards obtained: [-3363.21608245273], Lows: [1710], Highs: [31], Total time: 4642.68054
[32m[0906 17-45-52 @MBExp.py:144][0m ####################################################################
[32m[0906 17-45-52 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 17-45-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01836, current rewards: 0.05143, mean: 0.00514
[32m[0906 17-45-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 5.57452, mean: 0.09291
[32m[0906 17-45-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01839, current rewards: 11.09814, mean: 0.10089
[32m[0906 17-45-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 16.62179, mean: 0.10389
[32m[0906 17-45-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 22.14513, mean: 0.10545
[32m[0906 17-45-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 27.67170, mean: 0.10643
[32m[0906 17-45-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 33.23347, mean: 0.10720
[32m[0906 17-45-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 38.78951, mean: 0.10775
[32m[0906 17-45-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01858, current rewards: 44.34430, mean: 0.10816
[32m[0906 17-46-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01858, current rewards: 49.90408, mean: 0.10849
[32m[0906 17-46-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 55.45892, mean: 0.10874
[32m[0906 17-46-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01860, current rewards: 60.96645, mean: 0.10887
[32m[0906 17-46-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01864, current rewards: 66.52297, mean: 0.10905
[32m[0906 17-46-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01864, current rewards: 72.08005, mean: 0.10921
[32m[0906 17-46-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01863, current rewards: 77.63863, mean: 0.10935
[32m[0906 17-46-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01864, current rewards: 83.19124, mean: 0.10946
[32m[0906 17-46-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01862, current rewards: 88.77839, mean: 0.10960
[32m[0906 17-46-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01862, current rewards: 94.28868, mean: 0.10964
[32m[0906 17-46-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01862, current rewards: 99.80195, mean: 0.10967
[32m[0906 17-46-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01862, current rewards: 105.36305, mean: 0.10975
[32m[0906 17-46-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01863, current rewards: 110.87654, mean: 0.10978
[32m[0906 17-46-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 116.39852, mean: 0.10981
[32m[0906 17-46-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 121.91730, mean: 0.10984
[32m[0906 17-46-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 125.38960, mean: 0.10809
[32m[0906 17-46-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01862, current rewards: 130.97100, mean: 0.10824
[32m[0906 17-46-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 136.55182, mean: 0.10837
[32m[0906 17-46-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01862, current rewards: 142.13208, mean: 0.10850
[32m[0906 17-46-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 147.72188, mean: 0.10862
[32m[0906 17-46-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01862, current rewards: 152.16320, mean: 0.10792
[32m[0906 17-46-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01862, current rewards: 157.69554, mean: 0.10801
[32m[0906 17-46-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01862, current rewards: 163.23055, mean: 0.10810
[32m[0906 17-46-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01862, current rewards: 168.76422, mean: 0.10818
[32m[0906 17-46-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 174.29828, mean: 0.10826
[32m[0906 17-46-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 179.83069, mean: 0.10833
[32m[0906 17-46-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01861, current rewards: 185.36121, mean: 0.10840
[32m[0906 17-46-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 191.17994, mean: 0.10862
[32m[0906 17-46-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01861, current rewards: 196.72288, mean: 0.10869
[32m[0906 17-46-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 202.27063, mean: 0.10875
[32m[0906 17-46-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01861, current rewards: 207.81038, mean: 0.10880
[32m[0906 17-46-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 213.35428, mean: 0.10885
[32m[0906 17-46-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: 218.89873, mean: 0.10890
[32m[0906 17-46-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: 224.44315, mean: 0.10895
[32m[0906 17-46-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01862, current rewards: 229.99010, mean: 0.10900
[32m[0906 17-46-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01862, current rewards: 235.51149, mean: 0.10903
[32m[0906 17-46-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01861, current rewards: 241.05701, mean: 0.10908
[32m[0906 17-46-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01862, current rewards: 246.60229, mean: 0.10912
[32m[0906 17-46-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01861, current rewards: 252.15010, mean: 0.10916
[32m[0906 17-46-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: 257.69723, mean: 0.10919
[32m[0906 17-46-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01860, current rewards: 263.24161, mean: 0.10923
[32m[0906 17-46-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: 268.77782, mean: 0.10926
[32m[0906 17-46-39 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-46-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-46-39 @MBExp.py:227][0m Rewards obtained: [273.22404432025695], Lows: [1], Highs: [2], Total time: 4689.989351
[32m[0906 17-50-06 @MBExp.py:144][0m ####################################################################
[32m[0906 17-50-06 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 17-50-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01887, current rewards: 1.11572, mean: 0.11157
[32m[0906 17-50-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01859, current rewards: 6.63769, mean: 0.11063
[32m[0906 17-50-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01859, current rewards: 12.16685, mean: 0.11061
[32m[0906 17-50-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 17.68696, mean: 0.11054
[32m[0906 17-50-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 21.62371, mean: 0.10297
[32m[0906 17-50-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 30.41238, mean: 0.11697
[32m[0906 17-50-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 39.20104, mean: 0.12645
[32m[0906 17-50-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 47.98970, mean: 0.13330
[32m[0906 17-50-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 56.77837, mean: 0.13848
[32m[0906 17-50-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 65.56703, mean: 0.14254
[32m[0906 17-50-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 70.99804, mean: 0.13921
[32m[0906 17-50-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: 61.35438, mean: 0.10956
[32m[0906 17-50-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 66.94176, mean: 0.10974
[32m[0906 17-50-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 72.56854, mean: 0.10995
[32m[0906 17-50-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: 78.19540, mean: 0.11013
[32m[0906 17-50-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 83.82082, mean: 0.11029
[32m[0906 17-50-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 89.73127, mean: 0.11078
[32m[0906 17-50-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 95.28110, mean: 0.11079
[32m[0906 17-50-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 100.74344, mean: 0.11071
[32m[0906 17-50-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 106.28731, mean: 0.11072
[32m[0906 17-50-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 111.82916, mean: 0.11072
[32m[0906 17-50-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 117.37407, mean: 0.11073
[32m[0906 17-50-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 122.91930, mean: 0.11074
[32m[0906 17-50-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 128.46169, mean: 0.11074
[32m[0906 17-50-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 134.00596, mean: 0.11075
[32m[0906 17-50-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 139.64229, mean: 0.11083
[32m[0906 17-50-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 145.22184, mean: 0.11086
[32m[0906 17-50-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 150.80309, mean: 0.11088
[32m[0906 17-50-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 156.37752, mean: 0.11091
[32m[0906 17-50-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 161.96012, mean: 0.11093
[32m[0906 17-50-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 167.54091, mean: 0.11095
[32m[0906 17-50-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 173.11888, mean: 0.11097
[32m[0906 17-50-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 178.68917, mean: 0.11099
[32m[0906 17-50-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: 184.21102, mean: 0.11097
[32m[0906 17-50-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: 189.76159, mean: 0.11097
[32m[0906 17-50-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: 195.27196, mean: 0.11095
[32m[0906 17-50-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 200.78440, mean: 0.11093
[32m[0906 17-50-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01856, current rewards: 206.29601, mean: 0.11091
[32m[0906 17-50-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01856, current rewards: 211.80792, mean: 0.11089
[32m[0906 17-50-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01856, current rewards: 217.31680, mean: 0.11088
[32m[0906 17-50-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01856, current rewards: 222.82997, mean: 0.11086
[32m[0906 17-50-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 228.37718, mean: 0.11086
[32m[0906 17-50-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01854, current rewards: 233.95068, mean: 0.11088
[32m[0906 17-50-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01854, current rewards: 239.51900, mean: 0.11089
[32m[0906 17-50-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: 245.03923, mean: 0.11088
[32m[0906 17-50-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01855, current rewards: 250.56284, mean: 0.11087
[32m[0906 17-50-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01854, current rewards: 256.08136, mean: 0.11086
[32m[0906 17-50-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01855, current rewards: 261.60590, mean: 0.11085
[32m[0906 17-50-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01855, current rewards: 267.12789, mean: 0.11084
[32m[0906 17-50-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01855, current rewards: 272.65152, mean: 0.11083
[32m[0906 17-50-53 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-50-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-50-53 @MBExp.py:227][0m Rewards obtained: [276.4951428627205], Lows: [2], Highs: [13], Total time: 4737.152108
[32m[0906 17-54-21 @MBExp.py:144][0m ####################################################################
[32m[0906 17-54-21 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 17-54-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01809, current rewards: 1.16943, mean: 0.11694
[32m[0906 17-54-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01839, current rewards: 6.78170, mean: 0.11303
[32m[0906 17-54-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01843, current rewards: 12.36004, mean: 0.11236
[32m[0906 17-54-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01851, current rewards: 17.94054, mean: 0.11213
[32m[0906 17-54-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.51749, mean: 0.11199
[32m[0906 17-54-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 29.09890, mean: 0.11192
[32m[0906 17-54-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 34.67558, mean: 0.11186
[32m[0906 17-54-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01853, current rewards: 40.24980, mean: 0.11181
[32m[0906 17-54-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.83357, mean: 0.11179
[32m[0906 17-54-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 51.41263, mean: 0.11177
[32m[0906 17-54-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 56.94829, mean: 0.11166
[32m[0906 17-54-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 62.55197, mean: 0.11170
[32m[0906 17-54-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 68.10447, mean: 0.11165
[32m[0906 17-54-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01859, current rewards: 73.65617, mean: 0.11160
[32m[0906 17-54-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01860, current rewards: 79.20888, mean: 0.11156
[32m[0906 17-54-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01861, current rewards: 84.76144, mean: 0.11153
[32m[0906 17-54-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01861, current rewards: 90.31372, mean: 0.11150
[32m[0906 17-54-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01860, current rewards: 95.86736, mean: 0.11147
[32m[0906 17-54-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01861, current rewards: 101.47444, mean: 0.11151
[32m[0906 17-54-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01860, current rewards: 107.03701, mean: 0.11150
[32m[0906 17-54-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01859, current rewards: 112.60095, mean: 0.11149
[32m[0906 17-54-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01861, current rewards: 118.16509, mean: 0.11148
[32m[0906 17-54-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01861, current rewards: 123.83485, mean: 0.11156
[32m[0906 17-54-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 129.40046, mean: 0.11155
[32m[0906 17-54-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 134.97248, mean: 0.11155
[32m[0906 17-54-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 140.54458, mean: 0.11154
[32m[0906 17-54-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01862, current rewards: 146.13973, mean: 0.11156
[32m[0906 17-54-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 151.71184, mean: 0.11155
[32m[0906 17-54-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01862, current rewards: 157.28513, mean: 0.11155
[32m[0906 17-54-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 162.86139, mean: 0.11155
[32m[0906 17-54-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01861, current rewards: 168.43494, mean: 0.11155
[32m[0906 17-54-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 174.00907, mean: 0.11154
[32m[0906 17-54-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 179.57865, mean: 0.11154
[32m[0906 17-54-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 185.16724, mean: 0.11155
[32m[0906 17-54-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01861, current rewards: 190.75297, mean: 0.11155
[32m[0906 17-54-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 196.33213, mean: 0.11155
[32m[0906 17-54-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01860, current rewards: 201.90941, mean: 0.11155
[32m[0906 17-54-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 205.41221, mean: 0.11044
[32m[0906 17-54-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01861, current rewards: 210.98486, mean: 0.11046
[32m[0906 17-54-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 216.55956, mean: 0.11049
[32m[0906 17-54-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01861, current rewards: 222.13301, mean: 0.11051
[32m[0906 17-55-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: 223.22401, mean: 0.10836
[32m[0906 17-55-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: 228.83052, mean: 0.10845
[32m[0906 17-55-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 234.39751, mean: 0.10852
[32m[0906 17-55-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01861, current rewards: 239.96658, mean: 0.10858
[32m[0906 17-55-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 245.53990, mean: 0.10865
[32m[0906 17-55-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01860, current rewards: 251.11652, mean: 0.10871
[32m[0906 17-55-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01859, current rewards: 256.69862, mean: 0.10877
[32m[0906 17-55-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01859, current rewards: 262.28348, mean: 0.10883
[32m[0906 17-55-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01859, current rewards: 267.87024, mean: 0.10889
[32m[0906 17-55-08 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-55-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-55-08 @MBExp.py:227][0m Rewards obtained: [272.2970259253292], Lows: [1], Highs: [4], Total time: 4784.434525000001
[32m[0906 17-58-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-58-39 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 17-58-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01942, current rewards: -1.11646, mean: -0.11165
[32m[0906 17-58-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01855, current rewards: 4.43462, mean: 0.07391
[32m[0906 17-58-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01852, current rewards: 9.98226, mean: 0.09075
[32m[0906 17-58-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 15.53139, mean: 0.09707
[32m[0906 17-58-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 21.08145, mean: 0.10039
[32m[0906 17-58-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01858, current rewards: 26.62729, mean: 0.10241
[32m[0906 17-58-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 32.17495, mean: 0.10379
[32m[0906 17-58-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 37.72514, mean: 0.10479
[32m[0906 17-58-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 43.32917, mean: 0.10568
[32m[0906 17-58-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 50.32995, mean: 0.10941
[32m[0906 17-58-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 58.18950, mean: 0.11410
[32m[0906 17-58-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 66.04904, mean: 0.11794
[32m[0906 17-58-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 69.27982, mean: 0.11357
[32m[0906 17-58-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 68.07316, mean: 0.10314
[32m[0906 17-58-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 73.60213, mean: 0.10366
[32m[0906 17-58-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 79.12408, mean: 0.10411
[32m[0906 17-58-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 84.65507, mean: 0.10451
[32m[0906 17-58-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 90.07550, mean: 0.10474
[32m[0906 17-58-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 95.59419, mean: 0.10505
[32m[0906 17-58-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 101.13466, mean: 0.10535
[32m[0906 17-58-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 106.67030, mean: 0.10561
[32m[0906 17-58-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 112.20638, mean: 0.10586
[32m[0906 17-58-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 117.74384, mean: 0.10608
[32m[0906 17-59-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 123.27715, mean: 0.10627
[32m[0906 17-59-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 128.80818, mean: 0.10645
[32m[0906 17-59-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 134.34963, mean: 0.10663
[32m[0906 17-59-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 139.93878, mean: 0.10682
[32m[0906 17-59-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 145.47993, mean: 0.10697
[32m[0906 17-59-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 151.01868, mean: 0.10711
[32m[0906 17-59-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 156.55922, mean: 0.10723
[32m[0906 17-59-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01857, current rewards: 162.10361, mean: 0.10735
[32m[0906 17-59-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 167.64449, mean: 0.10746
[32m[0906 17-59-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 173.21335, mean: 0.10759
[32m[0906 17-59-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 178.77561, mean: 0.10770
[32m[0906 17-59-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01857, current rewards: 184.34106, mean: 0.10780
[32m[0906 17-59-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01856, current rewards: 189.90428, mean: 0.10790
[32m[0906 17-59-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01857, current rewards: 195.46977, mean: 0.10799
[32m[0906 17-59-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01857, current rewards: 201.03979, mean: 0.10809
[32m[0906 17-59-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01857, current rewards: 206.60413, mean: 0.10817
[32m[0906 17-59-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: 212.59176, mean: 0.10847
[32m[0906 17-59-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01858, current rewards: 218.14231, mean: 0.10853
[32m[0906 17-59-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01858, current rewards: 223.69348, mean: 0.10859
[32m[0906 17-59-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01859, current rewards: 229.18994, mean: 0.10862
[32m[0906 17-59-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01858, current rewards: 234.74476, mean: 0.10868
[32m[0906 17-59-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01859, current rewards: 240.29385, mean: 0.10873
[32m[0906 17-59-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: 245.84346, mean: 0.10878
[32m[0906 17-59-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01859, current rewards: 251.35328, mean: 0.10881
[32m[0906 17-59-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01859, current rewards: 256.88383, mean: 0.10885
[32m[0906 17-59-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01859, current rewards: 262.41777, mean: 0.10889
[32m[0906 17-59-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01859, current rewards: 267.94929, mean: 0.10892
[32m[0906 17-59-26 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-59-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-59-26 @MBExp.py:227][0m Rewards obtained: [272.37911872002627], Lows: [0], Highs: [12], Total time: 4831.7109820000005
[32m[0906 18-02-57 @MBExp.py:144][0m ####################################################################
[32m[0906 18-02-57 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-02-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: -1.11949, mean: -0.11195
[32m[0906 18-02-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01850, current rewards: 3.96763, mean: 0.06613
[32m[0906 18-02-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 9.05796, mean: 0.08235
[32m[0906 18-03-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 14.14436, mean: 0.08840
[32m[0906 18-03-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 19.23170, mean: 0.09158
[32m[0906 18-03-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 24.32082, mean: 0.09354
[32m[0906 18-03-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 29.40928, mean: 0.09487
[32m[0906 18-03-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01852, current rewards: 34.49664, mean: 0.09582
[32m[0906 18-03-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 39.66203, mean: 0.09674
[32m[0906 18-03-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 44.91107, mean: 0.09763
[32m[0906 18-03-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 50.57959, mean: 0.09918
[32m[0906 18-03-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 56.24938, mean: 0.10045
[32m[0906 18-03-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 61.91615, mean: 0.10150
[32m[0906 18-03-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 67.58512, mean: 0.10240
[32m[0906 18-03-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 73.25641, mean: 0.10318
[32m[0906 18-03-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 78.92875, mean: 0.10385
[32m[0906 18-03-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 84.61058, mean: 0.10446
[32m[0906 18-03-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 90.33467, mean: 0.10504
[32m[0906 18-03-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 96.03908, mean: 0.10554
[32m[0906 18-03-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 101.74513, mean: 0.10598
[32m[0906 18-03-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 107.45219, mean: 0.10639
[32m[0906 18-03-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 112.81286, mean: 0.10643
[32m[0906 18-03-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 118.08962, mean: 0.10639
[32m[0906 18-03-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 123.36634, mean: 0.10635
[32m[0906 18-03-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 128.64128, mean: 0.10632
[32m[0906 18-03-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 134.33803, mean: 0.10662
[32m[0906 18-03-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01851, current rewards: 140.13939, mean: 0.10698
[32m[0906 18-03-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 145.94519, mean: 0.10731
[32m[0906 18-03-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 151.74786, mean: 0.10762
[32m[0906 18-03-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01851, current rewards: 157.55768, mean: 0.10792
[32m[0906 18-03-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 163.36526, mean: 0.10819
[32m[0906 18-03-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01852, current rewards: 169.17146, mean: 0.10844
[32m[0906 18-03-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01851, current rewards: 174.97941, mean: 0.10868
[32m[0906 18-03-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: 181.19276, mean: 0.10915
[32m[0906 18-03-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: 187.51469, mean: 0.10966
[32m[0906 18-03-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01852, current rewards: 193.83561, mean: 0.11013
[32m[0906 18-03-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01851, current rewards: 200.16029, mean: 0.11059
[32m[0906 18-03-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: 206.48291, mean: 0.11101
[32m[0906 18-03-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01852, current rewards: 212.80756, mean: 0.11142
[32m[0906 18-03-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01852, current rewards: 219.12829, mean: 0.11180
[32m[0906 18-03-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01852, current rewards: 225.45038, mean: 0.11216
[32m[0906 18-03-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01852, current rewards: 230.32191, mean: 0.11181
[32m[0906 18-03-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01852, current rewards: 235.95788, mean: 0.11183
[32m[0906 18-03-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01852, current rewards: 241.59865, mean: 0.11185
[32m[0906 18-03-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01852, current rewards: 247.23837, mean: 0.11187
[32m[0906 18-03-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01852, current rewards: 252.61722, mean: 0.11178
[32m[0906 18-03-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01852, current rewards: 257.91567, mean: 0.11165
[32m[0906 18-03-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01853, current rewards: 263.21644, mean: 0.11153
[32m[0906 18-03-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01853, current rewards: 268.51942, mean: 0.11142
[32m[0906 18-03-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01853, current rewards: 273.71517, mean: 0.11127
[32m[0906 18-03-44 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-03-44 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-03-45 @MBExp.py:227][0m Rewards obtained: [277.80351045694414], Lows: [0], Highs: [3], Total time: 4878.862363
[32m[0906 18-07-18 @MBExp.py:144][0m ####################################################################
[32m[0906 18-07-18 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-07-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01830, current rewards: 1.14940, mean: 0.11494
[32m[0906 18-07-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01848, current rewards: 6.71326, mean: 0.11189
[32m[0906 18-07-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01845, current rewards: 12.28246, mean: 0.11166
[32m[0906 18-07-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 17.85149, mean: 0.11157
[32m[0906 18-07-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.41488, mean: 0.11150
[32m[0906 18-07-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.98524, mean: 0.11148
[32m[0906 18-07-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.55798, mean: 0.11148
[32m[0906 18-07-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.12659, mean: 0.11146
[32m[0906 18-07-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 45.69352, mean: 0.11145
[32m[0906 18-07-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 51.37625, mean: 0.11169
[32m[0906 18-07-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.94310, mean: 0.11165
[32m[0906 18-07-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.51461, mean: 0.11163
[32m[0906 18-07-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 68.08311, mean: 0.11161
[32m[0906 18-07-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 73.64975, mean: 0.11159
[32m[0906 18-07-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 79.21541, mean: 0.11157
[32m[0906 18-07-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.78228, mean: 0.11156
[32m[0906 18-07-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01849, current rewards: 90.31203, mean: 0.11150
[32m[0906 18-07-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: 95.87012, mean: 0.11148
[32m[0906 18-07-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 101.42673, mean: 0.11146
[32m[0906 18-07-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01848, current rewards: 106.98959, mean: 0.11145
[32m[0906 18-07-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 112.54589, mean: 0.11143
[32m[0906 18-07-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 118.10109, mean: 0.11142
[32m[0906 18-07-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 123.65777, mean: 0.11140
[32m[0906 18-07-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 129.21644, mean: 0.11139
[32m[0906 18-07-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 134.74730, mean: 0.11136
[32m[0906 18-07-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 140.30485, mean: 0.11135
[32m[0906 18-07-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 145.86245, mean: 0.11135
[32m[0906 18-07-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 151.42387, mean: 0.11134
[32m[0906 18-07-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: 156.98164, mean: 0.11133
[32m[0906 18-07-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01854, current rewards: 162.53616, mean: 0.11133
[32m[0906 18-07-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01853, current rewards: 168.09528, mean: 0.11132
[32m[0906 18-07-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01853, current rewards: 173.65447, mean: 0.11132
[32m[0906 18-07-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 179.24629, mean: 0.11133
[32m[0906 18-07-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: 184.81907, mean: 0.11134
[32m[0906 18-07-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: 190.38092, mean: 0.11133
[32m[0906 18-07-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: 195.93738, mean: 0.11133
[32m[0906 18-07-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 201.49971, mean: 0.11133
[32m[0906 18-07-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: 207.05761, mean: 0.11132
[32m[0906 18-07-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01854, current rewards: 212.61316, mean: 0.11132
[32m[0906 18-07-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01854, current rewards: 218.17120, mean: 0.11131
[32m[0906 18-07-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: 223.71292, mean: 0.11130
[32m[0906 18-07-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 229.27374, mean: 0.11130
[32m[0906 18-07-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01856, current rewards: 234.83397, mean: 0.11130
[32m[0906 18-07-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01857, current rewards: 240.39281, mean: 0.11129
[32m[0906 18-08-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01856, current rewards: 245.94880, mean: 0.11129
[32m[0906 18-08-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: 249.39658, mean: 0.11035
[32m[0906 18-08-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: 254.95789, mean: 0.11037
[32m[0906 18-08-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01856, current rewards: 260.51910, mean: 0.11039
[32m[0906 18-08-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 266.11095, mean: 0.11042
[32m[0906 18-08-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 271.86603, mean: 0.11051
[32m[0906 18-08-05 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-08-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-08-05 @MBExp.py:227][0m Rewards obtained: [276.40769123873946], Lows: [1], Highs: [0], Total time: 4926.069668
[32m[0906 18-11-41 @MBExp.py:144][0m ####################################################################
[32m[0906 18-11-41 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 18-11-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01883, current rewards: 1.14058, mean: 0.11406
[32m[0906 18-11-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01862, current rewards: 6.69444, mean: 0.11157
[32m[0906 18-11-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01862, current rewards: 12.22381, mean: 0.11113
[32m[0906 18-11-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01859, current rewards: 17.75938, mean: 0.11100
[32m[0906 18-11-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 23.29328, mean: 0.11092
[32m[0906 18-11-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01858, current rewards: 28.82598, mean: 0.11087
[32m[0906 18-11-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01856, current rewards: 34.36107, mean: 0.11084
[32m[0906 18-11-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 39.86940, mean: 0.11075
[32m[0906 18-11-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01857, current rewards: 45.40470, mean: 0.11074
[32m[0906 18-11-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 50.93866, mean: 0.11074
[32m[0906 18-11-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 56.47327, mean: 0.11073
[32m[0906 18-11-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 62.00682, mean: 0.11073
[32m[0906 18-11-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 67.54256, mean: 0.11073
[32m[0906 18-11-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01859, current rewards: 73.08024, mean: 0.11073
[32m[0906 18-11-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 78.59328, mean: 0.11069
[32m[0906 18-11-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: 84.10531, mean: 0.11066
[32m[0906 18-11-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: 89.63458, mean: 0.11066
[32m[0906 18-11-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 95.16267, mean: 0.11065
[32m[0906 18-11-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 100.68950, mean: 0.11065
[32m[0906 18-11-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 106.21745, mean: 0.11064
[32m[0906 18-12-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 111.74222, mean: 0.11064
[32m[0906 18-12-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 117.27024, mean: 0.11063
[32m[0906 18-12-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 122.88327, mean: 0.11071
[32m[0906 18-12-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 128.40196, mean: 0.11069
[32m[0906 18-12-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 133.91772, mean: 0.11068
[32m[0906 18-12-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 139.41716, mean: 0.11065
[32m[0906 18-12-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01856, current rewards: 144.91859, mean: 0.11062
[32m[0906 18-12-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 150.42401, mean: 0.11061
[32m[0906 18-12-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: 155.92747, mean: 0.11059
[32m[0906 18-12-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01857, current rewards: 161.42995, mean: 0.11057
[32m[0906 18-12-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01857, current rewards: 166.93768, mean: 0.11055
[32m[0906 18-12-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 172.46517, mean: 0.11055
[32m[0906 18-12-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01857, current rewards: 177.94682, mean: 0.11053
[32m[0906 18-12-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 183.47454, mean: 0.11053
[32m[0906 18-12-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 188.99716, mean: 0.11052
[32m[0906 18-12-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01858, current rewards: 194.51799, mean: 0.11052
[32m[0906 18-12-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01858, current rewards: 200.04030, mean: 0.11052
[32m[0906 18-12-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: 205.56588, mean: 0.11052
[32m[0906 18-12-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 211.19288, mean: 0.11057
[32m[0906 18-12-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: 216.72202, mean: 0.11057
[32m[0906 18-12-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01858, current rewards: 222.32936, mean: 0.11061
[32m[0906 18-12-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01859, current rewards: 227.86067, mean: 0.11061
[32m[0906 18-12-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01859, current rewards: 233.39200, mean: 0.11061
[32m[0906 18-12-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01859, current rewards: 238.18059, mean: 0.11027
[32m[0906 18-12-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01859, current rewards: 243.71611, mean: 0.11028
[32m[0906 18-12-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: 249.25476, mean: 0.11029
[32m[0906 18-12-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01859, current rewards: 254.79090, mean: 0.11030
[32m[0906 18-12-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01859, current rewards: 254.02950, mean: 0.10764
[32m[0906 18-12-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01860, current rewards: 259.60206, mean: 0.10772
[32m[0906 18-12-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: 265.14541, mean: 0.10778
[32m[0906 18-12-28 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-12-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-12-28 @MBExp.py:227][0m Rewards obtained: [269.5800427488008], Lows: [3], Highs: [1], Total time: 4973.376647
[32m[0906 18-16-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-16-07 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 18-16-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01831, current rewards: 1.08119, mean: 0.10812
[32m[0906 18-16-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01823, current rewards: 6.61948, mean: 0.11032
[32m[0906 18-16-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01833, current rewards: 12.11672, mean: 0.11015
[32m[0906 18-16-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 17.62297, mean: 0.11014
[32m[0906 18-16-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.12654, mean: 0.11013
[32m[0906 18-16-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 28.63108, mean: 0.11012
[32m[0906 18-16-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 34.13559, mean: 0.11011
[32m[0906 18-16-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 39.62420, mean: 0.11007
[32m[0906 18-16-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 45.12799, mean: 0.11007
[32m[0906 18-16-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 50.71016, mean: 0.11024
[32m[0906 18-16-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 56.23852, mean: 0.11027
[32m[0906 18-16-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 61.76469, mean: 0.11029
[32m[0906 18-16-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 67.29448, mean: 0.11032
[32m[0906 18-16-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 72.82287, mean: 0.11034
[32m[0906 18-16-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 78.35024, mean: 0.11035
[32m[0906 18-16-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 79.43502, mean: 0.10452
[32m[0906 18-16-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 84.92758, mean: 0.10485
[32m[0906 18-16-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 90.44163, mean: 0.10516
[32m[0906 18-16-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 95.95473, mean: 0.10544
[32m[0906 18-16-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 101.46546, mean: 0.10569
[32m[0906 18-16-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 106.98096, mean: 0.10592
[32m[0906 18-16-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 112.47280, mean: 0.10611
[32m[0906 18-16-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 118.00418, mean: 0.10631
[32m[0906 18-16-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 123.45986, mean: 0.10643
[32m[0906 18-16-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 128.99371, mean: 0.10661
[32m[0906 18-16-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 134.52552, mean: 0.10677
[32m[0906 18-16-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 140.05795, mean: 0.10691
[32m[0906 18-16-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01856, current rewards: 145.59151, mean: 0.10705
[32m[0906 18-16-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01856, current rewards: 151.11466, mean: 0.10717
[32m[0906 18-16-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 156.63102, mean: 0.10728
[32m[0906 18-16-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 162.14789, mean: 0.10738
[32m[0906 18-16-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 167.66958, mean: 0.10748
[32m[0906 18-16-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 173.19042, mean: 0.10757
[32m[0906 18-16-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01855, current rewards: 178.71373, mean: 0.10766
[32m[0906 18-16-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: 184.23847, mean: 0.10774
[32m[0906 18-16-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: 189.75717, mean: 0.10782
[32m[0906 18-16-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 195.27883, mean: 0.10789
[32m[0906 18-16-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: 200.80039, mean: 0.10796
[32m[0906 18-16-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01856, current rewards: 206.31994, mean: 0.10802
[32m[0906 18-16-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01856, current rewards: 211.87886, mean: 0.10810
[32m[0906 18-16-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01856, current rewards: 217.44718, mean: 0.10818
[32m[0906 18-16-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01856, current rewards: 222.96563, mean: 0.10824
[32m[0906 18-16-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: 228.51275, mean: 0.10830
[32m[0906 18-16-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: 234.03735, mean: 0.10835
[32m[0906 18-16-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: 239.55836, mean: 0.10840
[32m[0906 18-16-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: 245.07084, mean: 0.10844
[32m[0906 18-16-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: 250.58635, mean: 0.10848
[32m[0906 18-16-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01856, current rewards: 256.10501, mean: 0.10852
[32m[0906 18-16-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 261.48903, mean: 0.10850
[32m[0906 18-16-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 267.00408, mean: 0.10854
[32m[0906 18-16-54 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-16-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-16-54 @MBExp.py:227][0m Rewards obtained: [271.4124811686592], Lows: [0], Highs: [4], Total time: 5020.591461
[32m[0906 18-20-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-20-34 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 18-20-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01807, current rewards: 1.11275, mean: 0.11127
[32m[0906 18-20-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01867, current rewards: 6.68759, mean: 0.11146
[32m[0906 18-20-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 12.23894, mean: 0.11126
[32m[0906 18-20-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.78546, mean: 0.11116
[32m[0906 18-20-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.33716, mean: 0.11113
[32m[0906 18-20-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 28.88871, mean: 0.11111
[32m[0906 18-20-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 34.43776, mean: 0.11109
[32m[0906 18-20-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 39.89536, mean: 0.11082
[32m[0906 18-20-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: 45.47580, mean: 0.11092
[32m[0906 18-20-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01856, current rewards: 51.05685, mean: 0.11099
[32m[0906 18-20-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01857, current rewards: 56.63856, mean: 0.11106
[32m[0906 18-20-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 62.16200, mean: 0.11100
[32m[0906 18-20-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01859, current rewards: 67.71980, mean: 0.11102
[32m[0906 18-20-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 73.27898, mean: 0.11103
[32m[0906 18-20-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 78.83986, mean: 0.11104
[32m[0906 18-20-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 84.47891, mean: 0.11116
[32m[0906 18-20-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: 90.09511, mean: 0.11123
[32m[0906 18-20-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01860, current rewards: 95.68402, mean: 0.11126
[32m[0906 18-20-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01860, current rewards: 101.28246, mean: 0.11130
[32m[0906 18-20-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01860, current rewards: 106.87821, mean: 0.11133
[32m[0906 18-20-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 112.47107, mean: 0.11136
[32m[0906 18-20-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01861, current rewards: 118.06958, mean: 0.11139
[32m[0906 18-20-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01862, current rewards: 123.71771, mean: 0.11146
[32m[0906 18-20-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01862, current rewards: 129.26960, mean: 0.11144
[32m[0906 18-20-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01862, current rewards: 134.70609, mean: 0.11133
[32m[0906 18-20-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 140.24030, mean: 0.11130
[32m[0906 18-20-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 145.77185, mean: 0.11128
[32m[0906 18-20-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: 151.30274, mean: 0.11125
[32m[0906 18-21-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 156.83415, mean: 0.11123
[32m[0906 18-21-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 162.37077, mean: 0.11121
[32m[0906 18-21-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01861, current rewards: 167.90153, mean: 0.11119
[32m[0906 18-21-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 171.32337, mean: 0.10982
[32m[0906 18-21-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 176.89080, mean: 0.10987
[32m[0906 18-21-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 182.44721, mean: 0.10991
[32m[0906 18-21-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01862, current rewards: 188.00342, mean: 0.10994
[32m[0906 18-21-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 193.56274, mean: 0.10998
[32m[0906 18-21-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01861, current rewards: 199.11941, mean: 0.11001
[32m[0906 18-21-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 204.67644, mean: 0.11004
[32m[0906 18-21-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01860, current rewards: 210.22864, mean: 0.11007
[32m[0906 18-21-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 215.78337, mean: 0.11009
[32m[0906 18-21-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01861, current rewards: 221.33643, mean: 0.11012
[32m[0906 18-21-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: 226.89045, mean: 0.11014
[32m[0906 18-21-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 232.44840, mean: 0.11017
[32m[0906 18-21-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 238.00606, mean: 0.11019
[32m[0906 18-21-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01861, current rewards: 242.45815, mean: 0.10971
[32m[0906 18-21-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01861, current rewards: 248.01460, mean: 0.10974
[32m[0906 18-21-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01861, current rewards: 253.57530, mean: 0.10977
[32m[0906 18-21-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: 259.13787, mean: 0.10980
[32m[0906 18-21-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01861, current rewards: 264.68826, mean: 0.10983
[32m[0906 18-21-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01861, current rewards: 270.24973, mean: 0.10986
[32m[0906 18-21-21 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-21-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-21-21 @MBExp.py:227][0m Rewards obtained: [274.69169950504676], Lows: [1], Highs: [1], Total time: 5067.942117
[32m[0906 18-25-03 @MBExp.py:144][0m ####################################################################
[32m[0906 18-25-03 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 18-25-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01907, current rewards: -0.00703, mean: -0.00070
[32m[0906 18-25-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01857, current rewards: 5.48613, mean: 0.09144
[32m[0906 18-25-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01862, current rewards: 10.98623, mean: 0.09987
[32m[0906 18-25-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01856, current rewards: 16.48601, mean: 0.10304
[32m[0906 18-25-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01852, current rewards: 21.97549, mean: 0.10465
[32m[0906 18-25-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01858, current rewards: 27.47570, mean: 0.10568
[32m[0906 18-25-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 32.97664, mean: 0.10638
[32m[0906 18-25-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 38.53957, mean: 0.10705
[32m[0906 18-25-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: 44.04041, mean: 0.10742
[32m[0906 18-25-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 49.54087, mean: 0.10770
[32m[0906 18-25-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 55.04549, mean: 0.10793
[32m[0906 18-25-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 60.54478, mean: 0.10812
[32m[0906 18-25-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 66.04750, mean: 0.10827
[32m[0906 18-25-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 71.54918, mean: 0.10841
[32m[0906 18-25-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 77.08071, mean: 0.10856
[32m[0906 18-25-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 82.59210, mean: 0.10867
[32m[0906 18-25-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: 88.12631, mean: 0.10880
[32m[0906 18-25-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 93.66113, mean: 0.10891
[32m[0906 18-25-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01858, current rewards: 99.19090, mean: 0.10900
[32m[0906 18-25-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 104.72932, mean: 0.10909
[32m[0906 18-25-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 110.26096, mean: 0.10917
[32m[0906 18-25-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 115.79858, mean: 0.10924
[32m[0906 18-25-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: 121.33325, mean: 0.10931
[32m[0906 18-25-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: 126.98204, mean: 0.10947
[32m[0906 18-25-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 132.50790, mean: 0.10951
[32m[0906 18-25-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01861, current rewards: 138.03243, mean: 0.10955
[32m[0906 18-25-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 143.55990, mean: 0.10959
[32m[0906 18-25-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: 149.09149, mean: 0.10963
[32m[0906 18-25-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 154.62376, mean: 0.10966
[32m[0906 18-25-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 160.15488, mean: 0.10970
[32m[0906 18-25-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01861, current rewards: 165.68419, mean: 0.10972
[32m[0906 18-25-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 171.23448, mean: 0.10977
[32m[0906 18-25-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 176.80399, mean: 0.10982
[32m[0906 18-25-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 182.33642, mean: 0.10984
[32m[0906 18-25-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01861, current rewards: 187.86799, mean: 0.10986
[32m[0906 18-25-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01860, current rewards: 193.40276, mean: 0.10989
[32m[0906 18-25-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01861, current rewards: 198.93392, mean: 0.10991
[32m[0906 18-25-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 204.47518, mean: 0.10993
[32m[0906 18-25-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01860, current rewards: 210.00467, mean: 0.10995
[32m[0906 18-25-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01860, current rewards: 215.54016, mean: 0.10997
[32m[0906 18-25-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01861, current rewards: 221.04747, mean: 0.10997
[32m[0906 18-25-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: 226.58054, mean: 0.10999
[32m[0906 18-25-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 232.29154, mean: 0.11009
[32m[0906 18-25-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 237.83096, mean: 0.11011
[32m[0906 18-25-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01860, current rewards: 243.37015, mean: 0.11012
[32m[0906 18-25-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 248.90985, mean: 0.11014
[32m[0906 18-25-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01860, current rewards: 254.44894, mean: 0.11015
[32m[0906 18-25-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: 259.98794, mean: 0.11016
[32m[0906 18-25-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01861, current rewards: 265.52678, mean: 0.11018
[32m[0906 18-25-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01861, current rewards: 271.06596, mean: 0.11019
[32m[0906 18-25-51 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-25-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-25-51 @MBExp.py:227][0m Rewards obtained: [275.49476953226355], Lows: [0], Highs: [1], Total time: 5115.269789999999
[32m[0906 18-29-35 @MBExp.py:144][0m ####################################################################
[32m[0906 18-29-35 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 18-29-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02337, current rewards: -7.78468, mean: -0.77847
[32m[0906 18-29-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02316, current rewards: -71.90821, mean: -1.19847
[32m[0906 18-29-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02341, current rewards: -130.91110, mean: -1.19010
[32m[0906 18-29-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02321, current rewards: -194.43915, mean: -1.21524
[32m[0906 18-29-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02328, current rewards: -249.35811, mean: -1.18742
[32m[0906 18-29-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02310, current rewards: -316.11334, mean: -1.21582
[32m[0906 18-29-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02307, current rewards: -376.47307, mean: -1.21443
[32m[0906 18-29-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02302, current rewards: -434.61040, mean: -1.20725
[32m[0906 18-29-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02303, current rewards: -486.27817, mean: -1.18604
[32m[0906 18-29-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02293, current rewards: -552.23999, mean: -1.20052
[32m[0906 18-29-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02282, current rewards: -621.54233, mean: -1.21871
[32m[0906 18-29-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02267, current rewards: -693.47347, mean: -1.23835
[32m[0906 18-29-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02252, current rewards: -770.87387, mean: -1.26373
[32m[0906 18-29-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02238, current rewards: -839.70943, mean: -1.27229
[32m[0906 18-29-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02227, current rewards: -904.35509, mean: -1.27374
[32m[0906 18-29-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02215, current rewards: -961.26582, mean: -1.26482
[32m[0906 18-29-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02207, current rewards: -1015.82628, mean: -1.25411
[32m[0906 18-29-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02201, current rewards: -1073.05118, mean: -1.24773
[32m[0906 18-29-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02196, current rewards: -1130.63197, mean: -1.24245
[32m[0906 18-29-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02188, current rewards: -1184.60795, mean: -1.23397
[32m[0906 18-29-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02183, current rewards: -1241.82786, mean: -1.22953
[32m[0906 18-29-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02181, current rewards: -1305.08742, mean: -1.23121
[32m[0906 18-30-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02178, current rewards: -1381.62053, mean: -1.24470
[32m[0906 18-30-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02181, current rewards: -1453.13869, mean: -1.25271
[32m[0906 18-30-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02182, current rewards: -1525.19827, mean: -1.26049
[32m[0906 18-30-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02183, current rewards: -1598.78892, mean: -1.26888
[32m[0906 18-30-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02181, current rewards: -1672.65348, mean: -1.27683
[32m[0906 18-30-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02177, current rewards: -1746.38402, mean: -1.28411
[32m[0906 18-30-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02176, current rewards: -1815.20819, mean: -1.28738
[32m[0906 18-30-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02175, current rewards: -1894.10074, mean: -1.29733
[32m[0906 18-30-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02177, current rewards: -1972.96365, mean: -1.30660
[32m[0906 18-30-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02177, current rewards: -2054.36763, mean: -1.31690
[32m[0906 18-30-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02177, current rewards: -2133.53729, mean: -1.32518
[32m[0906 18-30-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02175, current rewards: -2209.84709, mean: -1.33123
[32m[0906 18-30-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02175, current rewards: -2293.91838, mean: -1.34147
[32m[0906 18-30-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02172, current rewards: -2369.79483, mean: -1.34647
[32m[0906 18-30-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02169, current rewards: -2444.05175, mean: -1.35030
[32m[0906 18-30-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02165, current rewards: -2523.86093, mean: -1.35691
[32m[0906 18-30-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02162, current rewards: -2600.86814, mean: -1.36171
[32m[0906 18-30-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02160, current rewards: -2668.07214, mean: -1.36126
[32m[0906 18-30-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02160, current rewards: -2736.58775, mean: -1.36149
[32m[0906 18-30-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02153, current rewards: -2836.58775, mean: -1.37698
[32m[0906 18-30-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02145, current rewards: -2936.58775, mean: -1.39175
[32m[0906 18-30-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02139, current rewards: -3036.58775, mean: -1.40583
[32m[0906 18-30-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02132, current rewards: -3136.58775, mean: -1.41927
[32m[0906 18-30-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02127, current rewards: -3236.58775, mean: -1.43212
[32m[0906 18-30-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02120, current rewards: -3336.58775, mean: -1.44441
[32m[0906 18-30-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02115, current rewards: -3436.58775, mean: -1.45618
[32m[0906 18-30-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02110, current rewards: -3536.58775, mean: -1.46746
[32m[0906 18-30-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02104, current rewards: -3636.58775, mean: -1.47829
[32m[0906 18-30-28 @Agent.py:117][0m Average action selection time: 0.0210
[32m[0906 18-30-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-30-28 @MBExp.py:227][0m Rewards obtained: [-3716.5877533193084], Lows: [2017], Highs: [0], Total time: 5168.584961
[32m[0906 18-34-15 @MBExp.py:144][0m ####################################################################
[32m[0906 18-34-15 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 18-34-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01908, current rewards: -0.84112, mean: -0.08411
[32m[0906 18-34-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 4.71329, mean: 0.07855
[32m[0906 18-34-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01856, current rewards: 10.27262, mean: 0.09339
[32m[0906 18-34-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 15.82780, mean: 0.09892
[32m[0906 18-34-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 21.38844, mean: 0.10185
[32m[0906 18-34-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 25.73523, mean: 0.09898
[32m[0906 18-34-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 30.83939, mean: 0.09948
[32m[0906 18-34-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 36.37871, mean: 0.10105
[32m[0906 18-34-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 41.91730, mean: 0.10224
[32m[0906 18-34-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 47.45563, mean: 0.10316
[32m[0906 18-34-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 52.99382, mean: 0.10391
[32m[0906 18-34-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 58.53258, mean: 0.10452
[32m[0906 18-34-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 64.07178, mean: 0.10504
[32m[0906 18-34-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 67.42323, mean: 0.10216
[32m[0906 18-34-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 73.00153, mean: 0.10282
[32m[0906 18-34-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 78.54007, mean: 0.10334
[32m[0906 18-34-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01856, current rewards: 84.08318, mean: 0.10381
[32m[0906 18-34-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 89.62160, mean: 0.10421
[32m[0906 18-34-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 95.15688, mean: 0.10457
[32m[0906 18-34-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 101.11152, mean: 0.10532
[32m[0906 18-34-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 106.65170, mean: 0.10560
[32m[0906 18-34-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 112.19033, mean: 0.10584
[32m[0906 18-34-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 117.70617, mean: 0.10604
[32m[0906 18-34-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 123.24614, mean: 0.10625
[32m[0906 18-34-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: 128.78845, mean: 0.10644
[32m[0906 18-34-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: 134.30244, mean: 0.10659
[32m[0906 18-34-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 139.82926, mean: 0.10674
[32m[0906 18-34-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 145.36389, mean: 0.10689
[32m[0906 18-34-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 150.89658, mean: 0.10702
[32m[0906 18-34-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 156.42736, mean: 0.10714
[32m[0906 18-34-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 161.97201, mean: 0.10727
[32m[0906 18-34-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 167.50453, mean: 0.10737
[32m[0906 18-34-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01857, current rewards: 173.03503, mean: 0.10748
[32m[0906 18-34-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 178.57092, mean: 0.10757
[32m[0906 18-34-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 184.10309, mean: 0.10766
[32m[0906 18-34-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 189.65048, mean: 0.10776
[32m[0906 18-34-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01858, current rewards: 195.19214, mean: 0.10784
[32m[0906 18-34-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: 200.74175, mean: 0.10793
[32m[0906 18-34-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 206.28716, mean: 0.10800
[32m[0906 18-34-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: 211.95956, mean: 0.10814
[32m[0906 18-34-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01859, current rewards: 217.49078, mean: 0.10820
[32m[0906 18-34-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01858, current rewards: 223.02333, mean: 0.10826
[32m[0906 18-34-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01858, current rewards: 228.55747, mean: 0.10832
[32m[0906 18-34-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01858, current rewards: 234.09744, mean: 0.10838
[32m[0906 18-34-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01858, current rewards: 239.64589, mean: 0.10844
[32m[0906 18-34-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: 245.18807, mean: 0.10849
[32m[0906 18-34-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01859, current rewards: 250.70141, mean: 0.10853
[32m[0906 18-34-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01859, current rewards: 256.25037, mean: 0.10858
[32m[0906 18-35-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01858, current rewards: 261.79225, mean: 0.10863
[32m[0906 18-35-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01858, current rewards: 267.34708, mean: 0.10868
[32m[0906 18-35-02 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-35-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-35-02 @MBExp.py:227][0m Rewards obtained: [271.77501104706647], Lows: [2], Highs: [2], Total time: 5215.873366
[32m[0906 18-38-50 @MBExp.py:144][0m ####################################################################
[32m[0906 18-38-50 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 18-38-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01815, current rewards: 1.11145, mean: 0.11115
[32m[0906 18-38-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01840, current rewards: 3.75423, mean: 0.06257
[32m[0906 18-38-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01850, current rewards: 6.22430, mean: 0.05658
[32m[0906 18-38-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01856, current rewards: 8.69438, mean: 0.05434
[32m[0906 18-38-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01859, current rewards: 11.16446, mean: 0.05316
[32m[0906 18-38-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01859, current rewards: 17.30550, mean: 0.06656
[32m[0906 18-38-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01858, current rewards: 25.60562, mean: 0.08260
[32m[0906 18-38-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 33.90574, mean: 0.09418
[32m[0906 18-38-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 42.20586, mean: 0.10294
[32m[0906 18-38-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 33.01594, mean: 0.07177
[32m[0906 18-39-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: -16.98406, mean: -0.03330
[32m[0906 18-39-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: -66.98406, mean: -0.11961
[32m[0906 18-39-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: -116.98406, mean: -0.19178
[32m[0906 18-39-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: -166.98406, mean: -0.25301
[32m[0906 18-39-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: -216.98406, mean: -0.30561
[32m[0906 18-39-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01856, current rewards: -266.98406, mean: -0.35129
[32m[0906 18-39-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: -316.98406, mean: -0.39134
[32m[0906 18-39-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: -366.98406, mean: -0.42673
[32m[0906 18-39-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: -416.98406, mean: -0.45822
[32m[0906 18-39-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: -466.98406, mean: -0.48644
[32m[0906 18-39-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: -516.98406, mean: -0.51187
[32m[0906 18-39-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: -566.98406, mean: -0.53489
[32m[0906 18-39-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: -616.98406, mean: -0.55584
[32m[0906 18-39-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: -666.98406, mean: -0.57499
[32m[0906 18-39-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: -716.98406, mean: -0.59255
[32m[0906 18-39-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01854, current rewards: -766.98406, mean: -0.60872
[32m[0906 18-39-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: -816.98406, mean: -0.62365
[32m[0906 18-39-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: -866.98406, mean: -0.63749
[32m[0906 18-39-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: -916.98406, mean: -0.65034
[32m[0906 18-39-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01852, current rewards: -966.98406, mean: -0.66232
[32m[0906 18-39-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01853, current rewards: -1016.98406, mean: -0.67350
[32m[0906 18-39-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01853, current rewards: -1066.98406, mean: -0.68396
[32m[0906 18-39-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01853, current rewards: -1116.98406, mean: -0.69378
[32m[0906 18-39-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: -1166.98406, mean: -0.70300
[32m[0906 18-39-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: -1216.98406, mean: -0.71169
[32m[0906 18-39-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: -1266.98406, mean: -0.71988
[32m[0906 18-39-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: -1316.98406, mean: -0.72762
[32m[0906 18-39-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01856, current rewards: -1366.98406, mean: -0.73494
[32m[0906 18-39-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: -1416.98406, mean: -0.74188
[32m[0906 18-39-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: -1466.98406, mean: -0.74846
[32m[0906 18-39-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: -1516.98406, mean: -0.75472
[32m[0906 18-39-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: -1566.98406, mean: -0.76067
[32m[0906 18-39-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: -1616.98406, mean: -0.76634
[32m[0906 18-39-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01855, current rewards: -1666.98406, mean: -0.77175
[32m[0906 18-39-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: -1716.98406, mean: -0.77692
[32m[0906 18-39-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01855, current rewards: -1766.98406, mean: -0.78185
[32m[0906 18-39-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01855, current rewards: -1816.98406, mean: -0.78657
[32m[0906 18-39-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01855, current rewards: -1866.98406, mean: -0.79109
[32m[0906 18-39-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01855, current rewards: -1916.98406, mean: -0.79543
[32m[0906 18-39-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01855, current rewards: -1966.98406, mean: -0.79959
[32m[0906 18-39-37 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-39-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-39-37 @MBExp.py:227][0m Rewards obtained: [-2006.9840590862782], Lows: [0], Highs: [2055], Total time: 5263.0596749999995
[32m[0906 18-43-28 @MBExp.py:144][0m ####################################################################
[32m[0906 18-43-28 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 18-43-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01708, current rewards: 1.13738, mean: 0.11374
[32m[0906 18-43-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.64977, mean: 0.11083
[32m[0906 18-43-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01848, current rewards: 12.15922, mean: 0.11054
[32m[0906 18-43-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 17.66944, mean: 0.11043
[32m[0906 18-43-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.16753, mean: 0.11032
[32m[0906 18-43-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 28.67803, mean: 0.11030
[32m[0906 18-43-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 34.18603, mean: 0.11028
[32m[0906 18-43-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.69825, mean: 0.11027
[32m[0906 18-43-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.24420, mean: 0.11035
[32m[0906 18-43-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 50.77044, mean: 0.11037
[32m[0906 18-43-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 56.29830, mean: 0.11039
[32m[0906 18-43-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 61.82680, mean: 0.11041
[32m[0906 18-43-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 67.42153, mean: 0.11053
[32m[0906 18-43-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 70.87690, mean: 0.10739
[32m[0906 18-43-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: 76.47503, mean: 0.10771
[32m[0906 18-43-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 82.07221, mean: 0.10799
[32m[0906 18-43-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 87.67100, mean: 0.10824
[32m[0906 18-43-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 93.27083, mean: 0.10845
[32m[0906 18-43-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 96.59861, mean: 0.10615
[32m[0906 18-43-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 102.16799, mean: 0.10642
[32m[0906 18-43-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 107.66861, mean: 0.10660
[32m[0906 18-43-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 113.21648, mean: 0.10681
[32m[0906 18-43-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 118.75956, mean: 0.10699
[32m[0906 18-43-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 124.30464, mean: 0.10716
[32m[0906 18-43-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: 129.84727, mean: 0.10731
[32m[0906 18-43-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 135.38661, mean: 0.10745
[32m[0906 18-43-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 140.93250, mean: 0.10758
[32m[0906 18-43-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 146.47700, mean: 0.10770
[32m[0906 18-43-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 152.06246, mean: 0.10785
[32m[0906 18-43-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 157.70463, mean: 0.10802
[32m[0906 18-43-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 163.22878, mean: 0.10810
[32m[0906 18-43-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 168.77092, mean: 0.10819
[32m[0906 18-43-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 174.31825, mean: 0.10827
[32m[0906 18-43-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01859, current rewards: 179.86470, mean: 0.10835
[32m[0906 18-44-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01859, current rewards: 185.40945, mean: 0.10843
[32m[0906 18-44-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01859, current rewards: 190.94873, mean: 0.10849
[32m[0906 18-44-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01859, current rewards: 196.49347, mean: 0.10856
[32m[0906 18-44-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01859, current rewards: 201.93221, mean: 0.10857
[32m[0906 18-44-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 207.45894, mean: 0.10862
[32m[0906 18-44-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01859, current rewards: 212.98779, mean: 0.10867
[32m[0906 18-44-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01859, current rewards: 218.55276, mean: 0.10873
[32m[0906 18-44-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01859, current rewards: 224.06918, mean: 0.10877
[32m[0906 18-44-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01859, current rewards: 229.58322, mean: 0.10881
[32m[0906 18-44-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01859, current rewards: 235.09876, mean: 0.10884
[32m[0906 18-44-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01859, current rewards: 240.61428, mean: 0.10888
[32m[0906 18-44-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 246.23270, mean: 0.10895
[32m[0906 18-44-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01860, current rewards: 251.78091, mean: 0.10900
[32m[0906 18-44-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01860, current rewards: 257.33172, mean: 0.10904
[32m[0906 18-44-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01861, current rewards: 262.88541, mean: 0.10908
[32m[0906 18-44-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: 268.43494, mean: 0.10912
[32m[0906 18-44-15 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-44-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-44-15 @MBExp.py:227][0m Rewards obtained: [272.87376151483625], Lows: [1], Highs: [2], Total time: 5310.387201
[32m[0906 18-48-08 @MBExp.py:144][0m ####################################################################
[32m[0906 18-48-08 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 18-48-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 0.53237, mean: 0.05324
[32m[0906 18-48-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 6.10000, mean: 0.10167
[32m[0906 18-48-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01836, current rewards: 11.68115, mean: 0.10619
[32m[0906 18-48-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 17.25834, mean: 0.10786
[32m[0906 18-48-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 22.92952, mean: 0.10919
[32m[0906 18-48-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01853, current rewards: 28.51492, mean: 0.10967
[32m[0906 18-48-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 34.09760, mean: 0.10999
[32m[0906 18-48-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 39.68335, mean: 0.11023
[32m[0906 18-48-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 43.26916, mean: 0.10553
[32m[0906 18-48-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 48.93187, mean: 0.10637
[32m[0906 18-48-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 54.59489, mean: 0.10705
[32m[0906 18-48-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 60.25818, mean: 0.10760
[32m[0906 18-48-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 65.83839, mean: 0.10793
[32m[0906 18-48-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 71.47775, mean: 0.10830
[32m[0906 18-48-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 77.12850, mean: 0.10863
[32m[0906 18-48-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 82.76774, mean: 0.10890
[32m[0906 18-48-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 88.35301, mean: 0.10908
[32m[0906 18-48-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 93.93312, mean: 0.10922
[32m[0906 18-48-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 99.51839, mean: 0.10936
[32m[0906 18-48-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 105.10169, mean: 0.10948
[32m[0906 18-48-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 110.68919, mean: 0.10959
[32m[0906 18-48-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 116.31902, mean: 0.10973
[32m[0906 18-48-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 121.90831, mean: 0.10983
[32m[0906 18-48-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 127.49396, mean: 0.10991
[32m[0906 18-48-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: 133.07917, mean: 0.10998
[32m[0906 18-48-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 138.67351, mean: 0.11006
[32m[0906 18-48-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 142.16168, mean: 0.10852
[32m[0906 18-48-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01856, current rewards: 147.73825, mean: 0.10863
[32m[0906 18-48-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: 153.31344, mean: 0.10873
[32m[0906 18-48-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01857, current rewards: 158.87329, mean: 0.10882
[32m[0906 18-48-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01857, current rewards: 164.44447, mean: 0.10890
[32m[0906 18-48-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01857, current rewards: 170.02230, mean: 0.10899
[32m[0906 18-48-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01857, current rewards: 175.59723, mean: 0.10907
[32m[0906 18-48-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01857, current rewards: 181.17809, mean: 0.10914
[32m[0906 18-48-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 186.75550, mean: 0.10921
[32m[0906 18-48-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01859, current rewards: 190.24653, mean: 0.10809
[32m[0906 18-48-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01858, current rewards: 195.82494, mean: 0.10819
[32m[0906 18-48-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: 201.47201, mean: 0.10832
[32m[0906 18-48-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 207.04399, mean: 0.10840
[32m[0906 18-48-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01859, current rewards: 212.61647, mean: 0.10848
[32m[0906 18-48-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01859, current rewards: 218.18610, mean: 0.10855
[32m[0906 18-48-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01859, current rewards: 223.75448, mean: 0.10862
[32m[0906 18-48-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01859, current rewards: 229.33750, mean: 0.10869
[32m[0906 18-48-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01859, current rewards: 234.93547, mean: 0.10877
[32m[0906 18-48-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01859, current rewards: 240.53438, mean: 0.10884
[32m[0906 18-48-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: 246.11245, mean: 0.10890
[32m[0906 18-48-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01858, current rewards: 251.70666, mean: 0.10896
[32m[0906 18-48-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01858, current rewards: 257.29893, mean: 0.10902
[32m[0906 18-48-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01858, current rewards: 262.89532, mean: 0.10909
[32m[0906 18-48-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01859, current rewards: 268.49153, mean: 0.10914
[32m[0906 18-48-55 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-48-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-48-55 @MBExp.py:227][0m Rewards obtained: [272.96762478781767], Lows: [3], Highs: [1], Total time: 5357.686417999999
[32m[0906 18-52-49 @MBExp.py:144][0m ####################################################################
[32m[0906 18-52-49 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 18-52-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01845, current rewards: 0.02225, mean: 0.00222
[32m[0906 18-52-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01866, current rewards: 5.52948, mean: 0.09216
[32m[0906 18-52-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01845, current rewards: 11.03999, mean: 0.10036
[32m[0906 18-52-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01836, current rewards: 16.53581, mean: 0.10335
[32m[0906 18-52-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01842, current rewards: 22.04260, mean: 0.10496
[32m[0906 18-52-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 27.54904, mean: 0.10596
[32m[0906 18-52-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 33.05551, mean: 0.10663
[32m[0906 18-52-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01852, current rewards: 38.55397, mean: 0.10709
[32m[0906 18-52-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 44.05762, mean: 0.10746
[32m[0906 18-52-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 49.56577, mean: 0.10775
[32m[0906 18-52-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 51.80366, mean: 0.10158
[32m[0906 18-53-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 57.31970, mean: 0.10236
[32m[0906 18-53-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01859, current rewards: 62.76946, mean: 0.10290
[32m[0906 18-53-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01860, current rewards: 68.25111, mean: 0.10341
[32m[0906 18-53-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01861, current rewards: 73.73568, mean: 0.10385
[32m[0906 18-53-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01861, current rewards: 79.21277, mean: 0.10423
[32m[0906 18-53-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01862, current rewards: 84.69505, mean: 0.10456
[32m[0906 18-53-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01862, current rewards: 90.17313, mean: 0.10485
[32m[0906 18-53-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01862, current rewards: 95.65913, mean: 0.10512
[32m[0906 18-53-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01862, current rewards: 101.14102, mean: 0.10536
[32m[0906 18-53-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01862, current rewards: 106.73953, mean: 0.10568
[32m[0906 18-53-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 112.30643, mean: 0.10595
[32m[0906 18-53-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 117.76170, mean: 0.10609
[32m[0906 18-53-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 123.17418, mean: 0.10618
[32m[0906 18-53-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: 128.58899, mean: 0.10627
[32m[0906 18-53-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 134.00145, mean: 0.10635
[32m[0906 18-53-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: 139.41640, mean: 0.10642
[32m[0906 18-53-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 144.83110, mean: 0.10649
[32m[0906 18-53-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: 150.18639, mean: 0.10652
[32m[0906 18-53-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 155.52699, mean: 0.10653
[32m[0906 18-53-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01864, current rewards: 160.89341, mean: 0.10655
[32m[0906 18-53-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01864, current rewards: 163.38475, mean: 0.10473
[32m[0906 18-53-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01864, current rewards: 168.77770, mean: 0.10483
[32m[0906 18-53-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01865, current rewards: 174.18198, mean: 0.10493
[32m[0906 18-53-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01864, current rewards: 179.58305, mean: 0.10502
[32m[0906 18-53-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01865, current rewards: 184.98277, mean: 0.10510
[32m[0906 18-53-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01864, current rewards: 190.38141, mean: 0.10518
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01864, current rewards: 195.77210, mean: 0.10525
[32m[0906 18-53-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01864, current rewards: 201.17228, mean: 0.10533
[32m[0906 18-53-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01864, current rewards: 206.57297, mean: 0.10539
[32m[0906 18-53-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01864, current rewards: 211.97259, mean: 0.10546
[32m[0906 18-53-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01864, current rewards: 213.01889, mean: 0.10341
[32m[0906 18-53-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01864, current rewards: 218.41581, mean: 0.10351
[32m[0906 18-53-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01863, current rewards: 223.78785, mean: 0.10361
[32m[0906 18-53-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01863, current rewards: 229.15625, mean: 0.10369
[32m[0906 18-53-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01863, current rewards: 234.64157, mean: 0.10382
[32m[0906 18-53-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01863, current rewards: 240.07044, mean: 0.10393
[32m[0906 18-53-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01863, current rewards: 245.50098, mean: 0.10403
[32m[0906 18-53-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01863, current rewards: 250.94974, mean: 0.10413
[32m[0906 18-53-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01864, current rewards: 256.38058, mean: 0.10422
[32m[0906 18-53-36 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-53-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-53-37 @MBExp.py:227][0m Rewards obtained: [260.72670076545927], Lows: [3], Highs: [5], Total time: 5405.114097
[32m[0906 18-57-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-57-34 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 18-57-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01879, current rewards: -2.28578, mean: -0.22858
[32m[0906 18-57-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01871, current rewards: 2.97854, mean: 0.04964
[32m[0906 18-57-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01875, current rewards: 8.23241, mean: 0.07484
[32m[0906 18-57-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: 13.42771, mean: 0.08392
[32m[0906 18-57-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01865, current rewards: 18.59898, mean: 0.08857
[32m[0906 18-57-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01869, current rewards: 23.79923, mean: 0.09154
[32m[0906 18-57-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01866, current rewards: 28.99707, mean: 0.09354
[32m[0906 18-57-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01865, current rewards: 34.19734, mean: 0.09499
[32m[0906 18-57-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01865, current rewards: 39.38962, mean: 0.09607
[32m[0906 18-57-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01865, current rewards: 44.58429, mean: 0.09692
[32m[0906 18-57-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01865, current rewards: 49.78345, mean: 0.09761
[32m[0906 18-57-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01866, current rewards: 54.98019, mean: 0.09818
[32m[0906 18-57-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01866, current rewards: 60.19125, mean: 0.09867
[32m[0906 18-57-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01866, current rewards: 65.39689, mean: 0.09909
[32m[0906 18-57-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01864, current rewards: 70.60666, mean: 0.09945
[32m[0906 18-57-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01864, current rewards: 75.81384, mean: 0.09976
[32m[0906 18-57-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01864, current rewards: 81.08548, mean: 0.10011
[32m[0906 18-57-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01865, current rewards: 86.41365, mean: 0.10048
[32m[0906 18-57-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01864, current rewards: 91.74010, mean: 0.10081
[32m[0906 18-57-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01864, current rewards: 97.06533, mean: 0.10111
[32m[0906 18-57-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01864, current rewards: 102.39299, mean: 0.10138
[32m[0906 18-57-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 107.71542, mean: 0.10162
[32m[0906 18-57-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01864, current rewards: 113.03386, mean: 0.10183
[32m[0906 18-57-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 118.35416, mean: 0.10203
[32m[0906 18-57-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: 123.67559, mean: 0.10221
[32m[0906 18-57-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 128.99596, mean: 0.10238
[32m[0906 18-57-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01864, current rewards: 134.31526, mean: 0.10253
[32m[0906 18-58-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 139.64081, mean: 0.10268
[32m[0906 18-58-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: 144.93358, mean: 0.10279
[32m[0906 18-58-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01862, current rewards: 150.25562, mean: 0.10291
[32m[0906 18-58-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01862, current rewards: 155.57274, mean: 0.10303
[32m[0906 18-58-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01862, current rewards: 160.91847, mean: 0.10315
[32m[0906 18-58-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 166.13689, mean: 0.10319
[32m[0906 18-58-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01862, current rewards: 171.34733, mean: 0.10322
[32m[0906 18-58-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01862, current rewards: 176.55522, mean: 0.10325
[32m[0906 18-58-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: 181.76566, mean: 0.10328
[32m[0906 18-58-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01862, current rewards: 186.99028, mean: 0.10331
[32m[0906 18-58-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01862, current rewards: 192.19780, mean: 0.10333
[32m[0906 18-58-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: 197.41486, mean: 0.10336
[32m[0906 18-58-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01863, current rewards: 202.63186, mean: 0.10338
[32m[0906 18-58-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 207.84544, mean: 0.10341
[32m[0906 18-58-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: 213.05329, mean: 0.10342
[32m[0906 18-58-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 218.26735, mean: 0.10344
[32m[0906 18-58-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 223.47886, mean: 0.10346
[32m[0906 18-58-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01861, current rewards: 228.68386, mean: 0.10348
[32m[0906 18-58-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 233.89839, mean: 0.10349
[32m[0906 18-58-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01861, current rewards: 239.10705, mean: 0.10351
[32m[0906 18-58-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: 244.06055, mean: 0.10342
[32m[0906 18-58-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01860, current rewards: 249.01745, mean: 0.10333
[32m[0906 18-58-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: 253.96809, mean: 0.10324
[32m[0906 18-58-21 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-58-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-58-22 @MBExp.py:227][0m Rewards obtained: [257.92625765428176], Lows: [0], Highs: [3], Total time: 5452.466477
[32m[0906 19-02-20 @MBExp.py:144][0m ####################################################################
[32m[0906 19-02-20 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 19-02-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01834, current rewards: 1.12481, mean: 0.11248
[32m[0906 19-02-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01847, current rewards: 6.62248, mean: 0.11037
[32m[0906 19-02-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01844, current rewards: 12.26535, mean: 0.11150
[32m[0906 19-02-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.86450, mean: 0.11165
[32m[0906 19-02-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01838, current rewards: 23.40188, mean: 0.11144
[32m[0906 19-02-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.93628, mean: 0.11129
[32m[0906 19-02-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.43003, mean: 0.11106
[32m[0906 19-02-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 40.01125, mean: 0.11114
[32m[0906 19-02-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.59228, mean: 0.11120
[32m[0906 19-02-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 51.17560, mean: 0.11125
[32m[0906 19-02-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.74871, mean: 0.11127
[32m[0906 19-02-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.33537, mean: 0.11131
[32m[0906 19-02-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 67.89850, mean: 0.11131
[32m[0906 19-02-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.45912, mean: 0.11130
[32m[0906 19-02-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 79.02302, mean: 0.11130
[32m[0906 19-02-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 84.58937, mean: 0.11130
[32m[0906 19-02-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 90.15190, mean: 0.11130
[32m[0906 19-02-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 95.71867, mean: 0.11130
[32m[0906 19-02-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 101.28129, mean: 0.11130
[32m[0906 19-02-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 106.81640, mean: 0.11127
[32m[0906 19-02-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 112.40345, mean: 0.11129
[32m[0906 19-02-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 117.96448, mean: 0.11129
[32m[0906 19-02-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 123.52894, mean: 0.11129
[32m[0906 19-02-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01854, current rewards: 129.09472, mean: 0.11129
[32m[0906 19-02-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 134.65861, mean: 0.11129
[32m[0906 19-02-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 140.22403, mean: 0.11129
[32m[0906 19-02-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01854, current rewards: 145.78500, mean: 0.11129
[32m[0906 19-02-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 151.26178, mean: 0.11122
[32m[0906 19-02-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: 156.82027, mean: 0.11122
[32m[0906 19-02-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 162.37951, mean: 0.11122
[32m[0906 19-02-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: 167.93869, mean: 0.11122
[32m[0906 19-02-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 173.49876, mean: 0.11122
[32m[0906 19-02-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01856, current rewards: 179.05862, mean: 0.11122
[32m[0906 19-02-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01856, current rewards: 184.61338, mean: 0.11121
[32m[0906 19-02-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01856, current rewards: 190.21152, mean: 0.11123
[32m[0906 19-02-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01856, current rewards: 195.84827, mean: 0.11128
[32m[0906 19-02-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01856, current rewards: 201.51006, mean: 0.11133
[32m[0906 19-02-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01856, current rewards: 207.08101, mean: 0.11133
[32m[0906 19-02-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: 212.65408, mean: 0.11134
[32m[0906 19-02-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: 218.22789, mean: 0.11134
[32m[0906 19-02-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: 223.80251, mean: 0.11134
[32m[0906 19-02-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 229.37470, mean: 0.11135
[32m[0906 19-02-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: 234.94482, mean: 0.11135
[32m[0906 19-03-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: 240.57213, mean: 0.11138
[32m[0906 19-03-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01856, current rewards: 246.04468, mean: 0.11133
[32m[0906 19-03-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: 251.60793, mean: 0.11133
[32m[0906 19-03-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: 257.17109, mean: 0.11133
[32m[0906 19-03-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01856, current rewards: 262.72918, mean: 0.11133
[32m[0906 19-03-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 268.28618, mean: 0.11132
[32m[0906 19-03-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 273.84486, mean: 0.11132
[32m[0906 19-03-07 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-03-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-03-07 @MBExp.py:227][0m Rewards obtained: [278.30090690743424], Lows: [0], Highs: [0], Total time: 5499.709665
[32m[0906 19-07-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-07-08 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 19-07-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02506, current rewards: -3.62484, mean: -0.36248
[32m[0906 19-07-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02791, current rewards: -5.81596, mean: -0.09693
[32m[0906 19-07-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02826, current rewards: -6.92078, mean: -0.06292
[32m[0906 19-07-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02802, current rewards: -13.23376, mean: -0.08271
[32m[0906 19-07-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02786, current rewards: -19.54678, mean: -0.09308
[32m[0906 19-07-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02775, current rewards: -26.90212, mean: -0.10347
[32m[0906 19-07-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02787, current rewards: -31.05721, mean: -0.10018
[32m[0906 19-07-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02779, current rewards: -38.38441, mean: -0.10662
[32m[0906 19-07-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02803, current rewards: -36.52863, mean: -0.08909
[32m[0906 19-07-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02825, current rewards: -33.86980, mean: -0.07363
[32m[0906 19-07-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02844, current rewards: -31.19684, mean: -0.06117
[32m[0906 19-07-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02851, current rewards: -28.43449, mean: -0.05078
[32m[0906 19-07-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02862, current rewards: -25.68118, mean: -0.04210
[32m[0906 19-07-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02867, current rewards: -22.93335, mean: -0.03475
[32m[0906 19-07-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02870, current rewards: -20.14827, mean: -0.02838
[32m[0906 19-07-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02874, current rewards: -17.42542, mean: -0.02293
[32m[0906 19-07-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02873, current rewards: -16.43791, mean: -0.02029
[32m[0906 19-07-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02832, current rewards: -10.87362, mean: -0.01264
[32m[0906 19-07-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02789, current rewards: -5.49862, mean: -0.00604
[32m[0906 19-07-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02746, current rewards: -0.25213, mean: -0.00026
[32m[0906 19-07-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02710, current rewards: 5.04913, mean: 0.00500
[32m[0906 19-07-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02675, current rewards: 10.30120, mean: 0.00972
[32m[0906 19-07-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02646, current rewards: 15.58764, mean: 0.01404
[32m[0906 19-07-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02615, current rewards: 20.79260, mean: 0.01792
[32m[0906 19-07-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02588, current rewards: 26.05980, mean: 0.02154
[32m[0906 19-07-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02566, current rewards: 31.36537, mean: 0.02489
[32m[0906 19-07-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02545, current rewards: 36.70058, mean: 0.02802
[32m[0906 19-07-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02529, current rewards: 41.83757, mean: 0.03076
[32m[0906 19-07-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02523, current rewards: 42.80709, mean: 0.03036
[32m[0906 19-07-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02539, current rewards: 45.46958, mean: 0.03114
[32m[0906 19-07-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02554, current rewards: 48.15409, mean: 0.03189
[32m[0906 19-07-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02568, current rewards: 50.82487, mean: 0.03258
[32m[0906 19-07-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02579, current rewards: 51.45173, mean: 0.03196
[32m[0906 19-07-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02590, current rewards: 51.02246, mean: 0.03074
[32m[0906 19-07-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02599, current rewards: 52.51028, mean: 0.03071
[32m[0906 19-07-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02609, current rewards: 56.66997, mean: 0.03220
[32m[0906 19-07-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02617, current rewards: 60.80767, mean: 0.03360
[32m[0906 19-07-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02624, current rewards: 64.92212, mean: 0.03490
[32m[0906 19-07-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02631, current rewards: 69.12548, mean: 0.03619
[32m[0906 19-08-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02636, current rewards: 73.17855, mean: 0.03734
[32m[0906 19-08-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02643, current rewards: 77.27196, mean: 0.03844
[32m[0906 19-08-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02648, current rewards: 81.38091, mean: 0.03951
[32m[0906 19-08-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02653, current rewards: 85.37489, mean: 0.04046
[32m[0906 19-08-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02658, current rewards: 89.42015, mean: 0.04140
[32m[0906 19-08-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02664, current rewards: 89.49571, mean: 0.04050
[32m[0906 19-08-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02671, current rewards: 92.71871, mean: 0.04103
[32m[0906 19-08-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02678, current rewards: 95.92866, mean: 0.04153
[32m[0906 19-08-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02686, current rewards: 99.15263, mean: 0.04201
[32m[0906 19-08-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02692, current rewards: 102.37373, mean: 0.04248
[32m[0906 19-08-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02700, current rewards: 105.64799, mean: 0.04295
[32m[0906 19-08-16 @Agent.py:117][0m Average action selection time: 0.0270
[32m[0906 19-08-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-08-17 @MBExp.py:227][0m Rewards obtained: [108.27427102023924], Lows: [2], Highs: [70], Total time: 5568.173047
[32m[0906 19-12-19 @MBExp.py:144][0m ####################################################################
[32m[0906 19-12-19 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 19-12-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01817, current rewards: -5.72772, mean: -0.57277
[32m[0906 19-12-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01844, current rewards: -1.47852, mean: -0.02464
[32m[0906 19-12-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01847, current rewards: 3.33876, mean: 0.03035
[32m[0906 19-12-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01856, current rewards: 7.87752, mean: 0.04923
[32m[0906 19-12-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 12.42192, mean: 0.05915
[32m[0906 19-12-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 14.76653, mean: 0.05679
[32m[0906 19-12-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 20.32178, mean: 0.06555
[32m[0906 19-12-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01859, current rewards: 25.92715, mean: 0.07202
[32m[0906 19-12-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01861, current rewards: 31.53322, mean: 0.07691
[32m[0906 19-12-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01862, current rewards: 37.15291, mean: 0.08077
[32m[0906 19-12-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01864, current rewards: 38.69786, mean: 0.07588
[32m[0906 19-12-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01866, current rewards: 45.60242, mean: 0.08143
[32m[0906 19-12-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01865, current rewards: 52.51351, mean: 0.08609
[32m[0906 19-12-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01866, current rewards: 59.45586, mean: 0.09008
[32m[0906 19-12-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01865, current rewards: 66.38591, mean: 0.09350
[32m[0906 19-12-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01864, current rewards: 73.30062, mean: 0.09645
[32m[0906 19-12-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01864, current rewards: 80.25147, mean: 0.09908
[32m[0906 19-12-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01864, current rewards: 87.18055, mean: 0.10137
[32m[0906 19-12-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01862, current rewards: 94.26506, mean: 0.10359
[32m[0906 19-12-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01862, current rewards: 89.17737, mean: 0.09289
[32m[0906 19-12-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01863, current rewards: 94.64641, mean: 0.09371
[32m[0906 19-12-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 100.10541, mean: 0.09444
[32m[0906 19-12-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 103.22615, mean: 0.09300
[32m[0906 19-12-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01863, current rewards: 108.75078, mean: 0.09375
[32m[0906 19-12-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01863, current rewards: 114.27383, mean: 0.09444
[32m[0906 19-12-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 119.79059, mean: 0.09507
[32m[0906 19-12-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: 125.32375, mean: 0.09567
[32m[0906 19-12-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 130.70326, mean: 0.09611
[32m[0906 19-12-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: 134.96776, mean: 0.09572
[32m[0906 19-12-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01863, current rewards: 140.37636, mean: 0.09615
[32m[0906 19-12-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01864, current rewards: 145.81745, mean: 0.09657
[32m[0906 19-12-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01864, current rewards: 151.25268, mean: 0.09696
[32m[0906 19-12-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01864, current rewards: 156.66634, mean: 0.09731
[32m[0906 19-12-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01864, current rewards: 162.10560, mean: 0.09765
[32m[0906 19-12-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01864, current rewards: 167.55410, mean: 0.09798
[32m[0906 19-12-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01865, current rewards: 172.96463, mean: 0.09828
[32m[0906 19-12-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01865, current rewards: 178.35701, mean: 0.09854
[32m[0906 19-12-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01864, current rewards: 183.75640, mean: 0.09879
[32m[0906 19-12-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01864, current rewards: 189.13663, mean: 0.09902
[32m[0906 19-12-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01863, current rewards: 194.50334, mean: 0.09924
[32m[0906 19-12-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01864, current rewards: 199.89034, mean: 0.09945
[32m[0906 19-12-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01863, current rewards: 205.28138, mean: 0.09965
[32m[0906 19-12-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01864, current rewards: 210.65859, mean: 0.09984
[32m[0906 19-13-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01864, current rewards: 213.01932, mean: 0.09862
[32m[0906 19-13-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01864, current rewards: 217.29445, mean: 0.09832
[32m[0906 19-13-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01865, current rewards: 221.54829, mean: 0.09803
[32m[0906 19-13-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01865, current rewards: 225.81297, mean: 0.09775
[32m[0906 19-13-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01865, current rewards: 230.06277, mean: 0.09748
[32m[0906 19-13-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01865, current rewards: 234.33537, mean: 0.09723
[32m[0906 19-13-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01865, current rewards: 238.60547, mean: 0.09699
[32m[0906 19-13-07 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-13-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-13-07 @MBExp.py:227][0m Rewards obtained: [242.0009074412592], Lows: [3], Highs: [21], Total time: 5615.647744
[32m[0906 19-17-12 @MBExp.py:144][0m ####################################################################
[32m[0906 19-17-12 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 19-17-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01836, current rewards: 1.10167, mean: 0.11017
[32m[0906 19-17-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 6.66738, mean: 0.11112
[32m[0906 19-17-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01860, current rewards: 11.99099, mean: 0.10901
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01863, current rewards: 17.52042, mean: 0.10950
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01859, current rewards: 23.04707, mean: 0.10975
[32m[0906 19-17-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01863, current rewards: 28.57102, mean: 0.10989
[32m[0906 19-17-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01863, current rewards: 34.50465, mean: 0.11131
[32m[0906 19-17-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01862, current rewards: 40.06853, mean: 0.11130
[32m[0906 19-17-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01862, current rewards: 45.62693, mean: 0.11129
[32m[0906 19-17-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01863, current rewards: 51.18653, mean: 0.11128
[32m[0906 19-17-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01864, current rewards: 56.77472, mean: 0.11132
[32m[0906 19-17-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01864, current rewards: 62.38924, mean: 0.11141
[32m[0906 19-17-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01865, current rewards: 67.96122, mean: 0.11141
[32m[0906 19-17-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01864, current rewards: 73.53106, mean: 0.11141
[32m[0906 19-17-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01864, current rewards: 79.10246, mean: 0.11141
[32m[0906 19-17-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01864, current rewards: 84.67242, mean: 0.11141
[32m[0906 19-17-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01864, current rewards: 90.23771, mean: 0.11140
[32m[0906 19-17-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01863, current rewards: 95.80730, mean: 0.11140
[32m[0906 19-17-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01864, current rewards: 100.56865, mean: 0.11052
[32m[0906 19-17-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01863, current rewards: 106.04310, mean: 0.11046
[32m[0906 19-17-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01862, current rewards: 111.54791, mean: 0.11044
[32m[0906 19-17-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 117.05794, mean: 0.11043
[32m[0906 19-17-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01865, current rewards: 122.56438, mean: 0.11042
[32m[0906 19-17-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 128.07267, mean: 0.11041
[32m[0906 19-17-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01865, current rewards: 133.57353, mean: 0.11039
[32m[0906 19-17-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01865, current rewards: 139.08844, mean: 0.11039
[32m[0906 19-17-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 144.59985, mean: 0.11038
[32m[0906 19-17-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 150.24525, mean: 0.11047
[32m[0906 19-17-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01864, current rewards: 155.77469, mean: 0.11048
[32m[0906 19-17-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 161.30414, mean: 0.11048
[32m[0906 19-17-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01864, current rewards: 166.83421, mean: 0.11049
[32m[0906 19-17-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01865, current rewards: 172.36119, mean: 0.11049
[32m[0906 19-17-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01866, current rewards: 177.94966, mean: 0.11053
[32m[0906 19-17-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01866, current rewards: 183.48733, mean: 0.11053
[32m[0906 19-17-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01866, current rewards: 189.02411, mean: 0.11054
[32m[0906 19-17-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01866, current rewards: 194.53991, mean: 0.11053
[32m[0906 19-17-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01866, current rewards: 199.90425, mean: 0.11044
[32m[0906 19-17-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01866, current rewards: 205.40603, mean: 0.11043
[32m[0906 19-17-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01866, current rewards: 210.90409, mean: 0.11042
[32m[0906 19-17-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01865, current rewards: 216.40223, mean: 0.11041
[32m[0906 19-17-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01865, current rewards: 221.89912, mean: 0.11040
[32m[0906 19-17-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01865, current rewards: 227.39815, mean: 0.11039
[32m[0906 19-17-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01866, current rewards: 232.89367, mean: 0.11038
[32m[0906 19-17-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01865, current rewards: 238.39233, mean: 0.11037
[32m[0906 19-17-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01864, current rewards: 243.98841, mean: 0.11040
[32m[0906 19-17-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01864, current rewards: 249.49630, mean: 0.11040
[32m[0906 19-17-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01864, current rewards: 255.01387, mean: 0.11040
[32m[0906 19-17-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01864, current rewards: 260.52717, mean: 0.11039
[32m[0906 19-17-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01864, current rewards: 266.04075, mean: 0.11039
[32m[0906 19-17-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01864, current rewards: 271.54929, mean: 0.11039
[32m[0906 19-17-59 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-17-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-17-59 @MBExp.py:227][0m Rewards obtained: [275.95226033508084], Lows: [0], Highs: [1], Total time: 5663.081884
[32m[0906 19-22-06 @MBExp.py:144][0m ####################################################################
[32m[0906 19-22-06 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 19-22-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01961, current rewards: -1.13281, mean: -0.11328
[32m[0906 19-22-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01871, current rewards: 4.40893, mean: 0.07348
[32m[0906 19-22-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01873, current rewards: 9.93962, mean: 0.09036
[32m[0906 19-22-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01863, current rewards: 15.47139, mean: 0.09670
[32m[0906 19-22-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01859, current rewards: 21.01005, mean: 0.10005
[32m[0906 19-22-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 26.54839, mean: 0.10211
[32m[0906 19-22-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01856, current rewards: 32.08060, mean: 0.10349
[32m[0906 19-22-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 37.62005, mean: 0.10450
[32m[0906 19-22-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 43.15867, mean: 0.10527
[32m[0906 19-22-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01862, current rewards: 48.69604, mean: 0.10586
[32m[0906 19-22-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01860, current rewards: 54.23384, mean: 0.10634
[32m[0906 19-22-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01859, current rewards: 59.76931, mean: 0.10673
[32m[0906 19-22-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 65.30860, mean: 0.10706
[32m[0906 19-22-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 70.84514, mean: 0.10734
[32m[0906 19-22-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 76.38439, mean: 0.10758
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 81.91783, mean: 0.10779
[32m[0906 19-22-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: 87.45083, mean: 0.10796
[32m[0906 19-22-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01859, current rewards: 92.97633, mean: 0.10811
[32m[0906 19-22-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01859, current rewards: 98.49321, mean: 0.10823
[32m[0906 19-22-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01860, current rewards: 101.97727, mean: 0.10623
[32m[0906 19-22-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 107.53272, mean: 0.10647
[32m[0906 19-22-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 113.08999, mean: 0.10669
[32m[0906 19-22-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: 118.64737, mean: 0.10689
[32m[0906 19-22-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: 124.20471, mean: 0.10707
[32m[0906 19-22-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: 129.76209, mean: 0.10724
[32m[0906 19-22-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: 135.31932, mean: 0.10740
[32m[0906 19-22-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01859, current rewards: 140.87655, mean: 0.10754
[32m[0906 19-22-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01859, current rewards: 146.43388, mean: 0.10767
[32m[0906 19-22-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01859, current rewards: 148.62514, mean: 0.10541
[32m[0906 19-22-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: 154.14231, mean: 0.10558
[32m[0906 19-22-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01860, current rewards: 159.66171, mean: 0.10574
[32m[0906 19-22-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01859, current rewards: 165.18203, mean: 0.10589
[32m[0906 19-22-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01859, current rewards: 170.70358, mean: 0.10603
[32m[0906 19-22-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01859, current rewards: 176.22123, mean: 0.10616
[32m[0906 19-22-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01860, current rewards: 181.74424, mean: 0.10628
[32m[0906 19-22-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01860, current rewards: 187.34458, mean: 0.10645
[32m[0906 19-22-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01860, current rewards: 192.87002, mean: 0.10656
[32m[0906 19-22-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01860, current rewards: 198.39350, mean: 0.10666
[32m[0906 19-22-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01860, current rewards: 203.91383, mean: 0.10676
[32m[0906 19-22-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01860, current rewards: 209.43917, mean: 0.10686
[32m[0906 19-22-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: 214.96456, mean: 0.10695
[32m[0906 19-22-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01859, current rewards: 220.48676, mean: 0.10703
[32m[0906 19-22-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01859, current rewards: 223.93482, mean: 0.10613
[32m[0906 19-22-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01860, current rewards: 229.44600, mean: 0.10623
[32m[0906 19-22-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01860, current rewards: 234.98481, mean: 0.10633
[32m[0906 19-22-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01859, current rewards: 240.52033, mean: 0.10642
[32m[0906 19-22-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01859, current rewards: 246.05963, mean: 0.10652
[32m[0906 19-22-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01860, current rewards: 251.59954, mean: 0.10661
[32m[0906 19-22-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01860, current rewards: 257.13609, mean: 0.10670
[32m[0906 19-22-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01860, current rewards: 262.67243, mean: 0.10678
[32m[0906 19-22-53 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-22-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-22-54 @MBExp.py:227][0m Rewards obtained: [267.10414529847793], Lows: [2], Highs: [5], Total time: 5710.418068
[32m[0906 19-27-05 @MBExp.py:144][0m ####################################################################
[32m[0906 19-27-05 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 19-27-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01828, current rewards: 1.03445, mean: 0.10344
[32m[0906 19-27-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01856, current rewards: 6.52986, mean: 0.10883
[32m[0906 19-27-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01861, current rewards: 12.05955, mean: 0.10963
[32m[0906 19-27-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 17.58504, mean: 0.10991
[32m[0906 19-27-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 23.12359, mean: 0.11011
[32m[0906 19-27-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01860, current rewards: 28.65277, mean: 0.11020
[32m[0906 19-27-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01861, current rewards: 34.18524, mean: 0.11027
[32m[0906 19-27-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01862, current rewards: 39.71656, mean: 0.11032
[32m[0906 19-27-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01862, current rewards: 45.24718, mean: 0.11036
[32m[0906 19-27-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01860, current rewards: 50.80742, mean: 0.11045
[32m[0906 19-27-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01861, current rewards: 56.33421, mean: 0.11046
[32m[0906 19-27-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01861, current rewards: 62.13728, mean: 0.11096
[32m[0906 19-27-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01862, current rewards: 67.69299, mean: 0.11097
[32m[0906 19-27-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01863, current rewards: 73.24174, mean: 0.11097
[32m[0906 19-27-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01863, current rewards: 78.79487, mean: 0.11098
[32m[0906 19-27-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01863, current rewards: 84.35005, mean: 0.11099
[32m[0906 19-27-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01863, current rewards: 89.90567, mean: 0.11099
[32m[0906 19-27-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01864, current rewards: 95.48202, mean: 0.11103
[32m[0906 19-27-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01863, current rewards: 101.82360, mean: 0.11189
[32m[0906 19-27-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01862, current rewards: 107.36484, mean: 0.11184
[32m[0906 19-27-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01861, current rewards: 112.90633, mean: 0.11179
[32m[0906 19-27-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 118.44724, mean: 0.11174
[32m[0906 19-27-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01862, current rewards: 123.98919, mean: 0.11170
[32m[0906 19-27-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01862, current rewards: 117.31370, mean: 0.10113
[32m[0906 19-27-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01862, current rewards: 67.31370, mean: 0.05563
[32m[0906 19-27-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01861, current rewards: 17.31370, mean: 0.01374
[32m[0906 19-27-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: -32.68630, mean: -0.02495
[32m[0906 19-27-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: -82.68630, mean: -0.06080
[32m[0906 19-27-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01860, current rewards: -132.68630, mean: -0.09410
[32m[0906 19-27-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: -182.68630, mean: -0.12513
[32m[0906 19-27-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01861, current rewards: -232.68630, mean: -0.15410
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: -282.68630, mean: -0.18121
[32m[0906 19-27-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01862, current rewards: -332.68630, mean: -0.20664
[32m[0906 19-27-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01862, current rewards: -382.68630, mean: -0.23053
[32m[0906 19-27-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01862, current rewards: -432.68630, mean: -0.25303
[32m[0906 19-27-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: -482.68630, mean: -0.27425
[32m[0906 19-27-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01863, current rewards: -532.68630, mean: -0.29430
[32m[0906 19-27-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01862, current rewards: -582.68630, mean: -0.31327
[32m[0906 19-27-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: -632.68630, mean: -0.33125
[32m[0906 19-27-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01863, current rewards: -682.68630, mean: -0.34831
[32m[0906 19-27-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: -732.68630, mean: -0.36452
[32m[0906 19-27-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: -782.68630, mean: -0.37994
[32m[0906 19-27-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: -832.68630, mean: -0.39464
[32m[0906 19-27-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: -882.68630, mean: -0.40865
[32m[0906 19-27-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01862, current rewards: -932.68630, mean: -0.42203
[32m[0906 19-27-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01862, current rewards: -982.68630, mean: -0.43482
[32m[0906 19-27-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01862, current rewards: -1032.68630, mean: -0.44705
[32m[0906 19-27-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: -1082.68630, mean: -0.45877
[32m[0906 19-27-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01861, current rewards: -1132.68630, mean: -0.46999
[32m[0906 19-27-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01861, current rewards: -1182.68630, mean: -0.48077
[32m[0906 19-27-52 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-27-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-27-52 @MBExp.py:227][0m Rewards obtained: [-1181.758401297594], Lows: [0], Highs: [1314], Total time: 5757.7848619999995
[32m[0906 19-32-04 @MBExp.py:144][0m ####################################################################
[32m[0906 19-32-04 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 19-32-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: -0.01136, mean: -0.00114
[32m[0906 19-32-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01873, current rewards: 5.49610, mean: 0.09160
[32m[0906 19-32-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01873, current rewards: 10.99722, mean: 0.09997
[32m[0906 19-32-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01864, current rewards: 16.50109, mean: 0.10313
[32m[0906 19-32-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 22.00192, mean: 0.10477
[32m[0906 19-32-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 27.50291, mean: 0.10578
[32m[0906 19-32-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 33.00592, mean: 0.10647
[32m[0906 19-32-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 38.51664, mean: 0.10699
[32m[0906 19-32-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 44.00404, mean: 0.10733
[32m[0906 19-32-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 49.51049, mean: 0.10763
[32m[0906 19-32-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 54.95759, mean: 0.10776
[32m[0906 19-32-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 60.28404, mean: 0.10765
[32m[0906 19-32-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 65.60750, mean: 0.10755
[32m[0906 19-32-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 70.91572, mean: 0.10745
[32m[0906 19-32-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 74.13105, mean: 0.10441
[32m[0906 19-32-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 79.62615, mean: 0.10477
[32m[0906 19-32-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01860, current rewards: 85.15236, mean: 0.10513
[32m[0906 19-32-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01861, current rewards: 91.07025, mean: 0.10590
[32m[0906 19-32-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01861, current rewards: 96.98814, mean: 0.10658
[32m[0906 19-32-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01861, current rewards: 102.90602, mean: 0.10719
[32m[0906 19-32-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 62.97124, mean: 0.06235
[32m[0906 19-32-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 12.97124, mean: 0.01224
[32m[0906 19-32-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: -37.02876, mean: -0.03336
[32m[0906 19-32-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: -87.02876, mean: -0.07502
[32m[0906 19-32-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: -137.02876, mean: -0.11325
[32m[0906 19-32-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: -148.07186, mean: -0.11752
[32m[0906 19-32-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01859, current rewards: -142.49687, mean: -0.10878
[32m[0906 19-32-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: -136.96650, mean: -0.10071
[32m[0906 19-32-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01859, current rewards: -131.43589, mean: -0.09322
[32m[0906 19-32-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: -125.89923, mean: -0.08623
[32m[0906 19-32-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01860, current rewards: -120.36784, mean: -0.07971
[32m[0906 19-32-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01860, current rewards: -114.79568, mean: -0.07359
[32m[0906 19-32-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: -109.25775, mean: -0.06786
[32m[0906 19-32-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: -103.76426, mean: -0.06251
[32m[0906 19-32-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01861, current rewards: -98.19822, mean: -0.05743
[32m[0906 19-32-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: -92.63049, mean: -0.05263
[32m[0906 19-32-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01862, current rewards: -87.06452, mean: -0.04810
[32m[0906 19-32-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01862, current rewards: -81.50426, mean: -0.04382
[32m[0906 19-32-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: -75.93839, mean: -0.03976
[32m[0906 19-32-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01862, current rewards: -70.37227, mean: -0.03590
[32m[0906 19-32-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: -64.80630, mean: -0.03224
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01862, current rewards: -59.19721, mean: -0.02874
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01862, current rewards: -53.65997, mean: -0.02543
[32m[0906 19-32-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: -48.11317, mean: -0.02227
[32m[0906 19-32-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01861, current rewards: -42.57200, mean: -0.01926
[32m[0906 19-32-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01861, current rewards: -37.02513, mean: -0.01638
[32m[0906 19-32-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01861, current rewards: -31.49172, mean: -0.01363
[32m[0906 19-32-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01861, current rewards: -25.95599, mean: -0.01100
[32m[0906 19-32-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01861, current rewards: -20.41253, mean: -0.00847
[32m[0906 19-32-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01861, current rewards: -14.76591, mean: -0.00600
[32m[0906 19-32-51 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-32-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-32-51 @MBExp.py:227][0m Rewards obtained: [-10.340493958928803], Lows: [2], Highs: [255], Total time: 5805.159503
[32m[0906 19-36-37 @MBExp.py:144][0m ####################################################################
[32m[0906 19-36-37 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01312, current rewards: -7.91789, mean: -0.79179
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01319, current rewards: -37.04771, mean: -0.61746
[32m[0906 19-36-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01317, current rewards: -67.22254, mean: -0.61111
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01322, current rewards: -95.71545, mean: -0.59822
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01321, current rewards: -125.66940, mean: -0.59843
[32m[0906 19-36-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01316, current rewards: -154.57635, mean: -0.59452
[32m[0906 19-36-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01315, current rewards: -184.81840, mean: -0.59619
[32m[0906 19-36-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01314, current rewards: -213.53319, mean: -0.59315
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01312, current rewards: -260.60888, mean: -0.63563
[32m[0906 19-36-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01299, current rewards: -331.31855, mean: -0.72026
[32m[0906 19-36-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01287, current rewards: -325.65418, mean: -0.63854
[32m[0906 19-36-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01278, current rewards: -320.76084, mean: -0.57279
[32m[0906 19-36-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01269, current rewards: -314.51539, mean: -0.51560
[32m[0906 19-36-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01261, current rewards: -308.29336, mean: -0.46711
[32m[0906 19-36-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01254, current rewards: -302.03259, mean: -0.42540
[32m[0906 19-36-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01249, current rewards: -295.86559, mean: -0.38930
[32m[0906 19-36-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01245, current rewards: -289.66756, mean: -0.35761
[32m[0906 19-36-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01240, current rewards: -283.42392, mean: -0.32956
[32m[0906 19-36-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01237, current rewards: -277.22048, mean: -0.30464
[32m[0906 19-36-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01233, current rewards: -271.00292, mean: -0.28229
[32m[0906 19-36-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01230, current rewards: -264.82700, mean: -0.26220
[32m[0906 19-36-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01227, current rewards: -258.63896, mean: -0.24400
[32m[0906 19-36-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01224, current rewards: -252.38482, mean: -0.22737
[32m[0906 19-36-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01222, current rewards: -246.14301, mean: -0.21219
[32m[0906 19-36-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01220, current rewards: -239.70906, mean: -0.19811
[32m[0906 19-36-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01217, current rewards: -233.04757, mean: -0.18496
[32m[0906 19-36-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01218, current rewards: -231.55787, mean: -0.17676
[32m[0906 19-36-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01228, current rewards: -250.21721, mean: -0.18398
[32m[0906 19-36-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01238, current rewards: -268.95267, mean: -0.19075
[32m[0906 19-36-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01248, current rewards: -287.60250, mean: -0.19699
[32m[0906 19-36-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01256, current rewards: -306.28263, mean: -0.20284
[32m[0906 19-36-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01265, current rewards: -324.86430, mean: -0.20825
[32m[0906 19-36-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01272, current rewards: -343.58625, mean: -0.21341
[32m[0906 19-36-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01275, current rewards: -376.22305, mean: -0.22664
[32m[0906 19-36-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01276, current rewards: -386.22543, mean: -0.22586
[32m[0906 19-36-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01275, current rewards: -377.49109, mean: -0.21448
[32m[0906 19-37-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01273, current rewards: -368.80225, mean: -0.20376
[32m[0906 19-37-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01271, current rewards: -360.11090, mean: -0.19361
[32m[0906 19-37-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01269, current rewards: -351.42785, mean: -0.18399
[32m[0906 19-37-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01267, current rewards: -347.67530, mean: -0.17739
[32m[0906 19-37-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01265, current rewards: -342.25816, mean: -0.17028
[32m[0906 19-37-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01262, current rewards: -336.80516, mean: -0.16350
[32m[0906 19-37-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01260, current rewards: -331.37121, mean: -0.15705
[32m[0906 19-37-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01258, current rewards: -325.93448, mean: -0.15090
[32m[0906 19-37-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01257, current rewards: -319.17156, mean: -0.14442
[32m[0906 19-37-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01257, current rewards: -311.62758, mean: -0.13789
[32m[0906 19-37-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01256, current rewards: -304.05977, mean: -0.13163
[32m[0906 19-37-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01257, current rewards: -296.62454, mean: -0.12569
[32m[0906 19-37-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01256, current rewards: -289.12620, mean: -0.11997
[32m[0906 19-37-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01256, current rewards: -284.05200, mean: -0.11547
[32m[0906 19-37-08 @Agent.py:117][0m Average action selection time: 0.0126
[32m[0906 19-37-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-37-09 @MBExp.py:227][0m Rewards obtained: [-278.1970958609002], Lows: [135], Highs: [371], Total time: 5837.218508
