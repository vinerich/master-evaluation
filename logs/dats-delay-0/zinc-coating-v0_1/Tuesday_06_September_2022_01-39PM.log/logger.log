[32m[0906 13-39-56 @logger.py:99][0m Log file set to /app/logs/dats-delay-0/zinc-coating-v0_1/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-56 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: -13.95163, mean: -1.39516
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -64.00873, mean: -1.06681
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -122.80004, mean: -1.11636
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -180.82282, mean: -1.13014
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -245.35959, mean: -1.16838
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -300.28257, mean: -1.15493
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -352.02592, mean: -1.13557
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -414.85305, mean: -1.15237
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -480.31651, mean: -1.17150
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -543.10900, mean: -1.18067
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -606.03433, mean: -1.18830
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -674.45703, mean: -1.20439
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -737.22250, mean: -1.20856
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -814.13096, mean: -1.23353
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -885.37081, mean: -1.24700
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -959.49833, mean: -1.26250
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -1032.00408, mean: -1.27408
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -1100.16866, mean: -1.27927
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1179.14292, mean: -1.29576
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1241.74555, mean: -1.29348
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1296.70704, mean: -1.28387
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1355.66934, mean: -1.27893
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1420.89996, mean: -1.28009
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1479.11334, mean: -1.27510
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1543.92373, mean: -1.27597
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1598.68822, mean: -1.26880
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1643.56784, mean: -1.25463
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1709.16666, mean: -1.25674
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1765.86460, mean: -1.25239
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1819.68588, mean: -1.24636
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1880.74812, mean: -1.24553
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1944.67605, mean: -1.24659
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -2010.29351, mean: -1.24863
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -2078.28791, mean: -1.25198
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -2140.85629, mean: -1.25196
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2195.96878, mean: -1.24771
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2248.37417, mean: -1.24220
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2290.27220, mean: -1.23133
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2341.46914, mean: -1.22590
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2398.55013, mean: -1.22375
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2449.35611, mean: -1.21859
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2508.89196, mean: -1.21791
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2562.59344, mean: -1.21450
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2619.84879, mean: -1.21289
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2678.59329, mean: -1.21203
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2718.90706, mean: -1.20306
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2771.39325, mean: -1.19974
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2818.76952, mean: -1.19439
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2873.78264, mean: -1.19244
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -2929.33253, mean: -1.19079
[32m[0906 13-39-56 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-39-58 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-58 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02473, current rewards: 0.34636, mean: 0.03464
[32m[0906 13-39-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01528, current rewards: 8.01500, mean: 0.13358
[32m[0906 13-40-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01477, current rewards: 15.67540, mean: 0.14250
[32m[0906 13-40-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01459, current rewards: 23.34152, mean: 0.14588
[32m[0906 13-40-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01450, current rewards: 31.00379, mean: 0.14764
[32m[0906 13-40-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01445, current rewards: 38.67551, mean: 0.14875
[32m[0906 13-40-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01439, current rewards: 46.34672, mean: 0.14951
[32m[0906 13-40-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01438, current rewards: 53.77841, mean: 0.14938
[32m[0906 13-40-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01437, current rewards: 60.89948, mean: 0.14854
[32m[0906 13-40-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01436, current rewards: 68.01667, mean: 0.14786
[32m[0906 13-40-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01437, current rewards: 75.13813, mean: 0.14733
[32m[0906 13-40-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01435, current rewards: 81.22659, mean: 0.14505
[32m[0906 13-40-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01435, current rewards: 91.33085, mean: 0.14972
[32m[0906 13-40-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01444, current rewards: 101.40954, mean: 0.15365
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01444, current rewards: 111.50936, mean: 0.15706
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01443, current rewards: 120.61562, mean: 0.15870
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01442, current rewards: 128.00601, mean: 0.15803
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01443, current rewards: 135.39818, mean: 0.15744
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01441, current rewards: 142.79410, mean: 0.15692
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01442, current rewards: 150.18901, mean: 0.15645
[32m[0906 13-40-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01444, current rewards: 157.58539, mean: 0.15603
[32m[0906 13-40-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01450, current rewards: 164.97423, mean: 0.15564
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01455, current rewards: 172.36744, mean: 0.15529
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01462, current rewards: 179.88869, mean: 0.15508
[32m[0906 13-40-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01469, current rewards: 186.21823, mean: 0.15390
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01476, current rewards: 192.55450, mean: 0.15282
[32m[0906 13-40-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01481, current rewards: 198.88788, mean: 0.15182
[32m[0906 13-40-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01487, current rewards: 205.21259, mean: 0.15089
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01492, current rewards: 209.33447, mean: 0.14846
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01497, current rewards: 215.28601, mean: 0.14746
[32m[0906 13-40-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01502, current rewards: 221.23983, mean: 0.14652
[32m[0906 13-40-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01506, current rewards: 227.08491, mean: 0.14557
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01510, current rewards: 232.06401, mean: 0.14414
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01513, current rewards: 237.03833, mean: 0.14279
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01517, current rewards: 242.01206, mean: 0.14153
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01520, current rewards: 245.87050, mean: 0.13970
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01523, current rewards: 195.87050, mean: 0.10822
[32m[0906 13-40-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01526, current rewards: 145.87050, mean: 0.07843
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01529, current rewards: 95.87050, mean: 0.05019
[32m[0906 13-40-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01532, current rewards: 45.87050, mean: 0.02340
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01537, current rewards: -4.12950, mean: -0.00205
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01540, current rewards: -54.12950, mean: -0.02628
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01542, current rewards: -59.62117, mean: -0.02826
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01544, current rewards: -55.32192, mean: -0.02561
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01547, current rewards: -51.01538, mean: -0.02308
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01549, current rewards: -46.71693, mean: -0.02067
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01551, current rewards: -42.41576, mean: -0.01836
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01555, current rewards: -38.11135, mean: -0.01615
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01560, current rewards: -33.15217, mean: -0.01376
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01565, current rewards: -28.07989, mean: -0.01141
[32m[0906 13-40-38 @Agent.py:117][0m Average action selection time: 0.0157
[32m[0906 13-40-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-40-38 @MBExp.py:227][0m Rewards obtained: [-24.008275875110623], Lows: [2], Highs: [311], Total time: 39.83584
[32m[0906 13-40-42 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-42 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01877, current rewards: 0.48268, mean: 0.04827
[32m[0906 13-40-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01791, current rewards: 6.74794, mean: 0.11247
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01792, current rewards: 12.90819, mean: 0.11735
[32m[0906 13-40-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01796, current rewards: 19.05886, mean: 0.11912
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01806, current rewards: 25.19901, mean: 0.12000
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01810, current rewards: 31.35398, mean: 0.12059
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01813, current rewards: 38.01754, mean: 0.12264
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01814, current rewards: 45.92560, mean: 0.12757
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01817, current rewards: 53.84347, mean: 0.13133
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01817, current rewards: 61.73976, mean: 0.13422
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01819, current rewards: 69.63951, mean: 0.13655
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01818, current rewards: 74.47341, mean: 0.13299
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01819, current rewards: 79.83857, mean: 0.13088
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01820, current rewards: 85.20486, mean: 0.12910
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01821, current rewards: 90.58981, mean: 0.12759
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01821, current rewards: 96.07648, mean: 0.12642
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01822, current rewards: 101.56354, mean: 0.12539
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01824, current rewards: 107.05205, mean: 0.12448
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01823, current rewards: 112.54206, mean: 0.12367
[32m[0906 13-41-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01821, current rewards: 118.03233, mean: 0.12295
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01820, current rewards: 123.51445, mean: 0.12229
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01818, current rewards: 129.00363, mean: 0.12170
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01816, current rewards: 134.93174, mean: 0.12156
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01816, current rewards: 139.34298, mean: 0.12012
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01816, current rewards: 143.73288, mean: 0.11879
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01817, current rewards: 148.12197, mean: 0.11756
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01818, current rewards: 152.51160, mean: 0.11642
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01819, current rewards: 156.89970, mean: 0.11537
[32m[0906 13-41-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01819, current rewards: 161.28645, mean: 0.11439
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01820, current rewards: 165.67812, mean: 0.11348
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01820, current rewards: 170.06824, mean: 0.11263
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01820, current rewards: 174.62808, mean: 0.11194
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01822, current rewards: 179.20741, mean: 0.11131
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01822, current rewards: 183.78501, mean: 0.11071
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01822, current rewards: 188.36493, mean: 0.11015
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01823, current rewards: 192.94589, mean: 0.10963
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01823, current rewards: 197.52304, mean: 0.10913
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01823, current rewards: 203.14693, mean: 0.10922
[32m[0906 13-41-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01824, current rewards: 211.78703, mean: 0.11088
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01824, current rewards: 232.79817, mean: 0.11877
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01824, current rewards: 268.80481, mean: 0.13373
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01826, current rewards: 304.28987, mean: 0.14771
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01827, current rewards: 340.16533, mean: 0.16122
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01827, current rewards: 375.97315, mean: 0.17406
[32m[0906 13-41-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01828, current rewards: 411.81586, mean: 0.18634
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01828, current rewards: 447.83381, mean: 0.19816
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01827, current rewards: 472.15450, mean: 0.20440
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01827, current rewards: 484.43987, mean: 0.20527
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01828, current rewards: 493.63997, mean: 0.20483
[32m[0906 13-41-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01832, current rewards: 502.83916, mean: 0.20441
[32m[0906 13-41-29 @Agent.py:117][0m Average action selection time: 0.0183
[32m[0906 13-41-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-41-29 @MBExp.py:227][0m Rewards obtained: [510.20116707524335], Lows: [3], Highs: [2], Total time: 86.341215
[32m[0906 13-41-36 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-36 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-41-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02112, current rewards: -1.13033, mean: -0.11303
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02012, current rewards: 4.66001, mean: 0.07767
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02015, current rewards: 10.45213, mean: 0.09502
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02014, current rewards: 16.24006, mean: 0.10150
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02012, current rewards: 22.02663, mean: 0.10489
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02012, current rewards: 27.81230, mean: 0.10697
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02015, current rewards: 33.15336, mean: 0.10695
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02016, current rewards: 38.45827, mean: 0.10683
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02020, current rewards: 43.76171, mean: 0.10674
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02023, current rewards: 49.06541, mean: 0.10666
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02025, current rewards: 54.37288, mean: 0.10661
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02027, current rewards: 59.67273, mean: 0.10656
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02028, current rewards: 64.97901, mean: 0.10652
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02029, current rewards: 70.28830, mean: 0.10650
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02030, current rewards: 76.24859, mean: 0.10739
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02030, current rewards: 83.34191, mean: 0.10966
[32m[0906 13-41-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02029, current rewards: 91.31021, mean: 0.11273
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02027, current rewards: 99.27975, mean: 0.11544
[32m[0906 13-41-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02026, current rewards: 107.24579, mean: 0.11785
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02026, current rewards: 115.21024, mean: 0.12001
[32m[0906 13-41-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02025, current rewards: 123.17859, mean: 0.12196
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02023, current rewards: 131.15006, mean: 0.12373
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02022, current rewards: 139.11200, mean: 0.12533
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02022, current rewards: 145.81999, mean: 0.12571
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02023, current rewards: 151.07434, mean: 0.12485
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02023, current rewards: 157.16061, mean: 0.12473
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02023, current rewards: 163.25168, mean: 0.12462
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02023, current rewards: 169.33417, mean: 0.12451
[32m[0906 13-42-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02025, current rewards: 175.42787, mean: 0.12442
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02025, current rewards: 181.52962, mean: 0.12434
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02025, current rewards: 187.61797, mean: 0.12425
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02026, current rewards: 193.56121, mean: 0.12408
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02026, current rewards: 199.43553, mean: 0.12387
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02026, current rewards: 205.32286, mean: 0.12369
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02026, current rewards: 211.20350, mean: 0.12351
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02026, current rewards: 217.07672, mean: 0.12334
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02027, current rewards: 222.81379, mean: 0.12310
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02027, current rewards: 228.30004, mean: 0.12274
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02027, current rewards: 233.79721, mean: 0.12241
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02028, current rewards: 239.12672, mean: 0.12200
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02028, current rewards: 244.34328, mean: 0.12156
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02029, current rewards: 250.11062, mean: 0.12141
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02029, current rewards: 256.09361, mean: 0.12137
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02029, current rewards: 262.08239, mean: 0.12133
[32m[0906 13-42-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02028, current rewards: 268.06832, mean: 0.12130
[32m[0906 13-42-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02027, current rewards: 274.04731, mean: 0.12126
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02026, current rewards: 280.03479, mean: 0.12123
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02025, current rewards: 286.07331, mean: 0.12122
[32m[0906 13-42-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02024, current rewards: 292.17107, mean: 0.12123
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02024, current rewards: 298.25938, mean: 0.12124
[32m[0906 13-42-27 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-42-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-42-27 @MBExp.py:227][0m Rewards obtained: [303.13317306993935], Lows: [0], Highs: [3], Total time: 137.64381
[32m[0906 13-42-36 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-36 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01995, current rewards: 1.03966, mean: 0.10397
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02026, current rewards: 6.60232, mean: 0.11004
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02019, current rewards: 12.22051, mean: 0.11110
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02016, current rewards: 17.83553, mean: 0.11147
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02015, current rewards: 23.45146, mean: 0.11167
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02018, current rewards: 29.07361, mean: 0.11182
[32m[0906 13-42-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02017, current rewards: 34.73059, mean: 0.11203
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02017, current rewards: 40.31548, mean: 0.11199
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02018, current rewards: 45.97830, mean: 0.11214
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02021, current rewards: 51.64077, mean: 0.11226
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02023, current rewards: 57.29844, mean: 0.11235
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02024, current rewards: 62.96347, mean: 0.11243
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02023, current rewards: 68.62144, mean: 0.11249
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02024, current rewards: 73.25685, mean: 0.11100
[32m[0906 13-42-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02021, current rewards: 78.70932, mean: 0.11086
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02022, current rewards: 84.15848, mean: 0.11073
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02021, current rewards: 89.61263, mean: 0.11063
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02022, current rewards: 95.06052, mean: 0.11054
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02021, current rewards: 100.50439, mean: 0.11044
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02021, current rewards: 105.95191, mean: 0.11037
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02021, current rewards: 111.39717, mean: 0.11029
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02020, current rewards: 116.84104, mean: 0.11023
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02020, current rewards: 122.82291, mean: 0.11065
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02022, current rewards: 129.08816, mean: 0.11128
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02023, current rewards: 135.35585, mean: 0.11186
[32m[0906 13-43-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02024, current rewards: 141.72401, mean: 0.11248
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02025, current rewards: 147.92559, mean: 0.11292
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02025, current rewards: 154.12489, mean: 0.11333
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02026, current rewards: 160.33308, mean: 0.11371
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02026, current rewards: 166.52679, mean: 0.11406
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02027, current rewards: 172.67834, mean: 0.11436
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02028, current rewards: 178.97813, mean: 0.11473
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02028, current rewards: 185.02877, mean: 0.11492
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02029, current rewards: 191.07237, mean: 0.11510
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02029, current rewards: 197.11881, mean: 0.11527
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02029, current rewards: 202.16224, mean: 0.11486
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02029, current rewards: 208.48282, mean: 0.11518
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02030, current rewards: 214.80142, mean: 0.11548
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02030, current rewards: 221.02996, mean: 0.11572
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02029, current rewards: 226.83466, mean: 0.11573
[32m[0906 13-43-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02028, current rewards: 232.65721, mean: 0.11575
[32m[0906 13-43-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02027, current rewards: 238.46927, mean: 0.11576
[32m[0906 13-43-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02025, current rewards: 244.28389, mean: 0.11577
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02024, current rewards: 250.10293, mean: 0.11579
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02023, current rewards: 255.92131, mean: 0.11580
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02022, current rewards: 261.73054, mean: 0.11581
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02021, current rewards: 267.52540, mean: 0.11581
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02020, current rewards: 273.02051, mean: 0.11569
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02020, current rewards: 278.51978, mean: 0.11557
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02019, current rewards: 284.02119, mean: 0.11546
[32m[0906 13-43-27 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-43-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-43-27 @MBExp.py:227][0m Rewards obtained: [288.42174595149254], Lows: [0], Highs: [2], Total time: 188.783178
[32m[0906 13-43-39 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-39 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02088, current rewards: 0.16450, mean: 0.01645
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02017, current rewards: 6.65548, mean: 0.11092
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02012, current rewards: 13.13623, mean: 0.11942
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02009, current rewards: 19.62351, mean: 0.12265
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02007, current rewards: 26.11078, mean: 0.12434
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02005, current rewards: 32.36350, mean: 0.12448
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02006, current rewards: 38.52525, mean: 0.12427
[32m[0906 13-43-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02009, current rewards: 44.69505, mean: 0.12415
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02007, current rewards: 50.87291, mean: 0.12408
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02007, current rewards: 57.06310, mean: 0.12405
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02012, current rewards: 63.23501, mean: 0.12399
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02013, current rewards: 69.40902, mean: 0.12394
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02013, current rewards: 73.49812, mean: 0.12049
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02013, current rewards: 80.00724, mean: 0.12122
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02013, current rewards: 86.50334, mean: 0.12184
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02012, current rewards: 92.99823, mean: 0.12237
[32m[0906 13-43-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02012, current rewards: 99.49104, mean: 0.12283
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02014, current rewards: 105.98612, mean: 0.12324
[32m[0906 13-43-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02013, current rewards: 112.48249, mean: 0.12361
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02012, current rewards: 118.98163, mean: 0.12394
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02014, current rewards: 125.47534, mean: 0.12423
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02014, current rewards: 132.12547, mean: 0.12465
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02016, current rewards: 138.66152, mean: 0.12492
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02017, current rewards: 145.19869, mean: 0.12517
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02019, current rewards: 151.73272, mean: 0.12540
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02020, current rewards: 158.27450, mean: 0.12561
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02020, current rewards: 164.81085, mean: 0.12581
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02021, current rewards: 171.34599, mean: 0.12599
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02022, current rewards: 177.88072, mean: 0.12616
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02023, current rewards: 184.41219, mean: 0.12631
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02024, current rewards: 190.59895, mean: 0.12622
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02025, current rewards: 196.85332, mean: 0.12619
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02026, current rewards: 203.20058, mean: 0.12621
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02026, current rewards: 209.72320, mean: 0.12634
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02028, current rewards: 216.25046, mean: 0.12646
[32m[0906 13-44-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02027, current rewards: 222.77649, mean: 0.12658
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02027, current rewards: 229.30373, mean: 0.12669
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02027, current rewards: 235.82947, mean: 0.12679
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02026, current rewards: 242.21511, mean: 0.12681
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02025, current rewards: 248.60190, mean: 0.12684
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02024, current rewards: 254.99538, mean: 0.12686
[32m[0906 13-44-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02022, current rewards: 261.37055, mean: 0.12688
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02020, current rewards: 267.75445, mean: 0.12690
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02019, current rewards: 274.13779, mean: 0.12692
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02018, current rewards: 280.52270, mean: 0.12693
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02018, current rewards: 286.91779, mean: 0.12695
[32m[0906 13-44-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02018, current rewards: 293.32390, mean: 0.12698
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02018, current rewards: 299.73213, mean: 0.12701
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02017, current rewards: 306.15485, mean: 0.12704
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02017, current rewards: 312.51217, mean: 0.12704
[32m[0906 13-44-30 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-44-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-44-30 @MBExp.py:227][0m Rewards obtained: [317.38014817031075], Lows: [1], Highs: [1], Total time: 239.885269
[32m[0906 13-44-43 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-43 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-44-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02096, current rewards: 1.06125, mean: 0.10612
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02020, current rewards: 6.82375, mean: 0.11373
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02005, current rewards: 12.58528, mean: 0.11441
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02001, current rewards: 18.34932, mean: 0.11468
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02004, current rewards: 24.08481, mean: 0.11469
[32m[0906 13-44-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02003, current rewards: 29.82525, mean: 0.11471
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02004, current rewards: 35.57081, mean: 0.11474
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02002, current rewards: 41.31580, mean: 0.11477
[32m[0906 13-44-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02003, current rewards: 47.05933, mean: 0.11478
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01999, current rewards: 52.80461, mean: 0.11479
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01996, current rewards: 58.54876, mean: 0.11480
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01992, current rewards: 64.15911, mean: 0.11457
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01993, current rewards: 69.73284, mean: 0.11432
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01993, current rewards: 75.39980, mean: 0.11424
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01994, current rewards: 81.07419, mean: 0.11419
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01997, current rewards: 86.74809, mean: 0.11414
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01997, current rewards: 92.41981, mean: 0.11410
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01997, current rewards: 98.08191, mean: 0.11405
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01998, current rewards: 103.74690, mean: 0.11401
[32m[0906 13-45-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01998, current rewards: 109.41402, mean: 0.11397
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01998, current rewards: 115.12846, mean: 0.11399
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01998, current rewards: 120.79929, mean: 0.11396
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01999, current rewards: 126.40383, mean: 0.11388
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02001, current rewards: 131.99452, mean: 0.11379
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02001, current rewards: 137.64598, mean: 0.11376
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02002, current rewards: 143.30384, mean: 0.11373
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02003, current rewards: 148.96433, mean: 0.11371
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02005, current rewards: 154.62580, mean: 0.11370
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02007, current rewards: 160.27956, mean: 0.11367
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02007, current rewards: 166.08155, mean: 0.11375
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02008, current rewards: 171.83204, mean: 0.11380
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02008, current rewards: 177.58457, mean: 0.11384
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02008, current rewards: 183.33236, mean: 0.11387
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02008, current rewards: 189.08315, mean: 0.11391
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02008, current rewards: 194.83126, mean: 0.11394
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02008, current rewards: 200.58339, mean: 0.11397
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02007, current rewards: 206.33385, mean: 0.11400
[32m[0906 13-45-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02007, current rewards: 211.98688, mean: 0.11397
[32m[0906 13-45-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02005, current rewards: 217.72524, mean: 0.11399
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02003, current rewards: 223.45952, mean: 0.11401
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02003, current rewards: 229.18193, mean: 0.11402
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02003, current rewards: 234.89672, mean: 0.11403
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02002, current rewards: 240.60066, mean: 0.11403
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02002, current rewards: 246.31718, mean: 0.11404
[32m[0906 13-45-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02002, current rewards: 252.03638, mean: 0.11404
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02002, current rewards: 257.77976, mean: 0.11406
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02002, current rewards: 263.63436, mean: 0.11413
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02002, current rewards: 269.42327, mean: 0.11416
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02002, current rewards: 275.21152, mean: 0.11420
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02002, current rewards: 281.00607, mean: 0.11423
[32m[0906 13-45-34 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-45-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-45-34 @MBExp.py:227][0m Rewards obtained: [285.9255269160229], Lows: [0], Highs: [0], Total time: 290.612964
[32m[0906 13-45-50 @MBExp.py:144][0m ####################################################################
[32m[0906 13-45-50 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01971, current rewards: -1.05478, mean: -0.10548
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01994, current rewards: 4.64396, mean: 0.07740
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01995, current rewards: 10.26271, mean: 0.09330
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02000, current rewards: 15.88885, mean: 0.09931
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01998, current rewards: 21.45434, mean: 0.10216
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02000, current rewards: 26.95357, mean: 0.10367
[32m[0906 13-45-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01999, current rewards: 32.49945, mean: 0.10484
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01993, current rewards: 38.04719, mean: 0.10569
[32m[0906 13-45-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01992, current rewards: 43.58651, mean: 0.10631
[32m[0906 13-45-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01989, current rewards: 49.13541, mean: 0.10682
[32m[0906 13-46-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01988, current rewards: 54.67276, mean: 0.10720
[32m[0906 13-46-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01988, current rewards: 60.22353, mean: 0.10754
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01987, current rewards: 65.80941, mean: 0.10788
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01986, current rewards: 71.44808, mean: 0.10825
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01987, current rewards: 77.03970, mean: 0.10851
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01987, current rewards: 82.62327, mean: 0.10871
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01988, current rewards: 88.21184, mean: 0.10890
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01989, current rewards: 93.79971, mean: 0.10907
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01990, current rewards: 99.39208, mean: 0.10922
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01991, current rewards: 104.97785, mean: 0.10935
[32m[0906 13-46-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01991, current rewards: 110.57032, mean: 0.10948
[32m[0906 13-46-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01991, current rewards: 116.12199, mean: 0.10955
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01993, current rewards: 121.70421, mean: 0.10964
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01996, current rewards: 127.28780, mean: 0.10973
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01998, current rewards: 132.85969, mean: 0.10980
[32m[0906 13-46-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01999, current rewards: 138.38744, mean: 0.10983
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02001, current rewards: 143.91295, mean: 0.10986
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02002, current rewards: 149.43561, mean: 0.10988
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02002, current rewards: 154.95183, mean: 0.10989
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02002, current rewards: 160.49291, mean: 0.10993
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02003, current rewards: 166.08011, mean: 0.10999
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02003, current rewards: 171.54434, mean: 0.10996
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02004, current rewards: 177.00755, mean: 0.10994
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02003, current rewards: 182.47090, mean: 0.10992
[32m[0906 13-46-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02003, current rewards: 187.93572, mean: 0.10990
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02003, current rewards: 193.44249, mean: 0.10991
[32m[0906 13-46-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02002, current rewards: 198.93168, mean: 0.10991
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02001, current rewards: 204.36346, mean: 0.10987
[32m[0906 13-46-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02000, current rewards: 209.84032, mean: 0.10986
[32m[0906 13-46-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02000, current rewards: 215.67589, mean: 0.11004
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01999, current rewards: 221.25322, mean: 0.11008
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01999, current rewards: 226.83386, mean: 0.11011
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02000, current rewards: 232.40732, mean: 0.11015
[32m[0906 13-46-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01999, current rewards: 237.98123, mean: 0.11018
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01999, current rewards: 243.55174, mean: 0.11020
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02000, current rewards: 249.18699, mean: 0.11026
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02000, current rewards: 254.77848, mean: 0.11029
[32m[0906 13-46-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02000, current rewards: 260.32481, mean: 0.11031
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02000, current rewards: 265.87269, mean: 0.11032
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02000, current rewards: 271.42066, mean: 0.11033
[32m[0906 13-46-40 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-46-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-46-40 @MBExp.py:227][0m Rewards obtained: [274.6912998868499], Lows: [0], Highs: [3], Total time: 341.282829
[32m[0906 13-46-59 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-59 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01972, current rewards: 1.03813, mean: 0.10381
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01991, current rewards: 6.58318, mean: 0.10972
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01998, current rewards: 12.11954, mean: 0.11018
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01996, current rewards: 17.66285, mean: 0.11039
[32m[0906 13-47-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01989, current rewards: 23.04794, mean: 0.10975
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01987, current rewards: 28.58953, mean: 0.10996
[32m[0906 13-47-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01980, current rewards: 34.12298, mean: 0.11007
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01981, current rewards: 39.65519, mean: 0.11015
[32m[0906 13-47-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01980, current rewards: 45.19415, mean: 0.11023
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01980, current rewards: 50.73491, mean: 0.11029
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01979, current rewards: 56.26163, mean: 0.11032
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01978, current rewards: 61.78705, mean: 0.11033
[32m[0906 13-47-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01978, current rewards: 67.34353, mean: 0.11040
[32m[0906 13-47-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01977, current rewards: 72.88631, mean: 0.11043
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01977, current rewards: 78.42735, mean: 0.11046
[32m[0906 13-47-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01975, current rewards: 83.96332, mean: 0.11048
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01976, current rewards: 89.50941, mean: 0.11051
[32m[0906 13-47-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01977, current rewards: 95.04521, mean: 0.11052
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01978, current rewards: 100.58499, mean: 0.11053
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01978, current rewards: 104.00763, mean: 0.10834
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01980, current rewards: 109.55237, mean: 0.10847
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01982, current rewards: 115.57939, mean: 0.10904
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01985, current rewards: 121.75707, mean: 0.10969
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01985, current rewards: 116.69921, mean: 0.10060
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01986, current rewards: 121.14528, mean: 0.10012
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01987, current rewards: 126.70346, mean: 0.10056
[32m[0906 13-47-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01987, current rewards: 132.25969, mean: 0.10096
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01988, current rewards: 137.81825, mean: 0.10134
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01988, current rewards: 143.37192, mean: 0.10168
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01988, current rewards: 148.93673, mean: 0.10201
[32m[0906 13-47-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01988, current rewards: 154.57350, mean: 0.10237
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01989, current rewards: 160.17963, mean: 0.10268
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01990, current rewards: 165.77987, mean: 0.10297
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01990, current rewards: 171.37918, mean: 0.10324
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01990, current rewards: 176.98520, mean: 0.10350
[32m[0906 13-47-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01989, current rewards: 182.58854, mean: 0.10374
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01988, current rewards: 188.33321, mean: 0.10405
[32m[0906 13-47-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01988, current rewards: 193.85829, mean: 0.10422
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01987, current rewards: 199.40136, mean: 0.10440
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01988, current rewards: 204.94200, mean: 0.10456
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01988, current rewards: 210.48361, mean: 0.10472
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01988, current rewards: 216.02640, mean: 0.10487
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01989, current rewards: 221.56781, mean: 0.10501
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01989, current rewards: 227.11192, mean: 0.10514
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01990, current rewards: 232.65644, mean: 0.10527
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01990, current rewards: 238.17545, mean: 0.10539
[32m[0906 13-47-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01992, current rewards: 243.70847, mean: 0.10550
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01992, current rewards: 249.24586, mean: 0.10561
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01992, current rewards: 254.78510, mean: 0.10572
[32m[0906 13-47-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01992, current rewards: 260.32233, mean: 0.10582
[32m[0906 13-47-49 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-47-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-47-49 @MBExp.py:227][0m Rewards obtained: [264.7526042673686], Lows: [1], Highs: [11], Total time: 391.761215
[32m[0906 13-48-09 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-09 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-48-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02079, current rewards: 0.01232, mean: 0.00123
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02021, current rewards: 5.63629, mean: 0.09394
[32m[0906 13-48-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01995, current rewards: 11.19613, mean: 0.10178
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01984, current rewards: 16.75609, mean: 0.10473
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01978, current rewards: 22.27589, mean: 0.10608
[32m[0906 13-48-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01976, current rewards: 27.91132, mean: 0.10735
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01975, current rewards: 32.38236, mean: 0.10446
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01974, current rewards: 37.94708, mean: 0.10541
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01972, current rewards: 43.51129, mean: 0.10613
[32m[0906 13-48-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01974, current rewards: 49.07661, mean: 0.10669
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01974, current rewards: 54.65016, mean: 0.10716
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01972, current rewards: 60.22324, mean: 0.10754
[32m[0906 13-48-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01971, current rewards: 65.80766, mean: 0.10788
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01970, current rewards: 71.37903, mean: 0.10815
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01971, current rewards: 76.94165, mean: 0.10837
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01972, current rewards: 82.51385, mean: 0.10857
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01971, current rewards: 88.08374, mean: 0.10875
[32m[0906 13-48-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01971, current rewards: 93.61625, mean: 0.10886
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01973, current rewards: 99.23496, mean: 0.10905
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01972, current rewards: 104.85654, mean: 0.10923
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01971, current rewards: 110.48866, mean: 0.10939
[32m[0906 13-48-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01972, current rewards: 116.10621, mean: 0.10953
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01974, current rewards: 121.72568, mean: 0.10966
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01975, current rewards: 127.33957, mean: 0.10978
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01977, current rewards: 132.95117, mean: 0.10988
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01979, current rewards: 138.57013, mean: 0.10998
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01979, current rewards: 144.18519, mean: 0.11007
[32m[0906 13-48-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01980, current rewards: 149.79859, mean: 0.11015
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01981, current rewards: 155.51506, mean: 0.11029
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01982, current rewards: 161.09489, mean: 0.11034
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01983, current rewards: 166.67778, mean: 0.11038
[32m[0906 13-48-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01984, current rewards: 172.25408, mean: 0.11042
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01984, current rewards: 177.83246, mean: 0.11045
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01983, current rewards: 183.40950, mean: 0.11049
[32m[0906 13-48-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01983, current rewards: 188.98853, mean: 0.11052
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01983, current rewards: 194.60636, mean: 0.11057
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01984, current rewards: 200.30447, mean: 0.11067
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01984, current rewards: 205.95314, mean: 0.11073
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01985, current rewards: 211.60899, mean: 0.11079
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01986, current rewards: 217.25941, mean: 0.11085
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01986, current rewards: 222.91441, mean: 0.11090
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01987, current rewards: 228.49975, mean: 0.11092
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01988, current rewards: 234.08955, mean: 0.11094
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01989, current rewards: 239.67362, mean: 0.11096
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01989, current rewards: 245.25668, mean: 0.11098
[32m[0906 13-48-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01989, current rewards: 250.84206, mean: 0.11099
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01989, current rewards: 256.43076, mean: 0.11101
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01991, current rewards: 262.01312, mean: 0.11102
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01991, current rewards: 267.60383, mean: 0.11104
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01991, current rewards: 273.19246, mean: 0.11105
[32m[0906 13-49-00 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-49-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-49-00 @MBExp.py:227][0m Rewards obtained: [277.66412171253677], Lows: [0], Highs: [2], Total time: 442.220634
[32m[0906 13-49-22 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-22 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01981, current rewards: 0.02058, mean: 0.00206
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01977, current rewards: 5.58725, mean: 0.09312
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01972, current rewards: 11.06454, mean: 0.10059
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01971, current rewards: 16.47280, mean: 0.10296
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01970, current rewards: 21.86463, mean: 0.10412
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01968, current rewards: 27.29919, mean: 0.10500
[32m[0906 13-49-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01968, current rewards: 32.74043, mean: 0.10561
[32m[0906 13-49-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01969, current rewards: 38.18239, mean: 0.10606
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01968, current rewards: 43.61955, mean: 0.10639
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01967, current rewards: 49.05372, mean: 0.10664
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01966, current rewards: 54.49274, mean: 0.10685
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01966, current rewards: 59.93574, mean: 0.10703
[32m[0906 13-49-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01965, current rewards: 65.44920, mean: 0.10729
[32m[0906 13-49-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01965, current rewards: 70.85886, mean: 0.10736
[32m[0906 13-49-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01964, current rewards: 76.27179, mean: 0.10743
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01961, current rewards: 81.68304, mean: 0.10748
[32m[0906 13-49-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01958, current rewards: 87.10042, mean: 0.10753
[32m[0906 13-49-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: 92.53547, mean: 0.10760
[32m[0906 13-49-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01954, current rewards: 97.96519, mean: 0.10765
[32m[0906 13-49-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01951, current rewards: 103.39524, mean: 0.10770
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01949, current rewards: 106.61102, mean: 0.10556
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01949, current rewards: 111.81514, mean: 0.10549
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01951, current rewards: 117.27678, mean: 0.10565
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01953, current rewards: 122.73571, mean: 0.10581
[32m[0906 13-49-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01955, current rewards: 128.19516, mean: 0.10595
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01956, current rewards: 133.65905, mean: 0.10608
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01958, current rewards: 139.11889, mean: 0.10620
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01961, current rewards: 144.57983, mean: 0.10631
[32m[0906 13-49-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01962, current rewards: 150.03987, mean: 0.10641
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01962, current rewards: 155.61119, mean: 0.10658
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01962, current rewards: 161.07129, mean: 0.10667
[32m[0906 13-49-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01962, current rewards: 164.30644, mean: 0.10532
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01962, current rewards: 169.70845, mean: 0.10541
[32m[0906 13-49-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01962, current rewards: 175.10683, mean: 0.10549
[32m[0906 13-49-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01963, current rewards: 180.50248, mean: 0.10556
[32m[0906 13-49-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01964, current rewards: 185.90092, mean: 0.10563
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01965, current rewards: 191.33388, mean: 0.10571
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01966, current rewards: 196.72050, mean: 0.10576
[32m[0906 13-50-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01967, current rewards: 202.14842, mean: 0.10584
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01968, current rewards: 207.58587, mean: 0.10591
[32m[0906 13-50-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01969, current rewards: 213.02425, mean: 0.10598
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01970, current rewards: 218.47259, mean: 0.10605
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01971, current rewards: 223.91931, mean: 0.10612
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01972, current rewards: 229.36417, mean: 0.10619
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01973, current rewards: 234.80759, mean: 0.10625
[32m[0906 13-50-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01974, current rewards: 240.24948, mean: 0.10631
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01974, current rewards: 245.68697, mean: 0.10636
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01974, current rewards: 251.13169, mean: 0.10641
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01975, current rewards: 256.57620, mean: 0.10646
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01975, current rewards: 262.02092, mean: 0.10651
[32m[0906 13-50-12 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-50-12 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-50-12 @MBExp.py:227][0m Rewards obtained: [266.3743650430056], Lows: [1], Highs: [3], Total time: 492.279588
[32m[0906 13-50-37 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-37 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02017, current rewards: -0.07902, mean: -0.00790
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01967, current rewards: 5.42488, mean: 0.09041
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01968, current rewards: 10.92807, mean: 0.09935
[32m[0906 13-50-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01964, current rewards: 16.43085, mean: 0.10269
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01966, current rewards: 23.06180, mean: 0.10982
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01967, current rewards: 31.36192, mean: 0.12062
[32m[0906 13-50-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01966, current rewards: 39.66204, mean: 0.12794
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01966, current rewards: 31.63813, mean: 0.08788
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01964, current rewards: -18.36187, mean: -0.04479
[32m[0906 13-50-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01963, current rewards: -68.36187, mean: -0.14861
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01961, current rewards: -118.36187, mean: -0.23208
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01955, current rewards: -168.36187, mean: -0.30065
[32m[0906 13-50-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01953, current rewards: -218.36187, mean: -0.35797
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01951, current rewards: -268.36187, mean: -0.40661
[32m[0906 13-50-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01950, current rewards: -318.36187, mean: -0.44840
[32m[0906 13-50-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01948, current rewards: -368.36187, mean: -0.48469
[32m[0906 13-50-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01946, current rewards: -418.36187, mean: -0.51650
[32m[0906 13-50-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01945, current rewards: -468.36187, mean: -0.54461
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01943, current rewards: -518.36187, mean: -0.56963
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01941, current rewards: -568.36187, mean: -0.59204
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01940, current rewards: -618.36187, mean: -0.61224
[32m[0906 13-50-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01938, current rewards: -668.36187, mean: -0.63053
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01937, current rewards: -718.36187, mean: -0.64717
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01938, current rewards: -768.36187, mean: -0.66238
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01941, current rewards: -818.36187, mean: -0.67633
[32m[0906 13-51-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01943, current rewards: -868.36187, mean: -0.68918
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01945, current rewards: -918.36187, mean: -0.70104
[32m[0906 13-51-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01946, current rewards: -968.36187, mean: -0.71203
[32m[0906 13-51-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01947, current rewards: -1018.36187, mean: -0.72224
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01948, current rewards: -1068.36187, mean: -0.73175
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01948, current rewards: -1118.36187, mean: -0.74064
[32m[0906 13-51-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01948, current rewards: -1168.36187, mean: -0.74895
[32m[0906 13-51-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01948, current rewards: -1218.36187, mean: -0.75675
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01950, current rewards: -1268.36187, mean: -0.76407
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01952, current rewards: -1318.36187, mean: -0.77097
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01953, current rewards: -1368.36187, mean: -0.77748
[32m[0906 13-51-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01954, current rewards: -1418.36187, mean: -0.78363
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01956, current rewards: -1468.36187, mean: -0.78944
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01958, current rewards: -1518.36187, mean: -0.79495
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01959, current rewards: -1568.36187, mean: -0.80018
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01959, current rewards: -1618.36187, mean: -0.80516
[32m[0906 13-51-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01961, current rewards: -1668.36187, mean: -0.80988
[32m[0906 13-51-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01961, current rewards: -1718.36187, mean: -0.81439
[32m[0906 13-51-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01962, current rewards: -1768.36187, mean: -0.81869
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01963, current rewards: -1818.36187, mean: -0.82279
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01963, current rewards: -1868.36187, mean: -0.82671
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01964, current rewards: -1918.36187, mean: -0.83046
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01966, current rewards: -1956.00278, mean: -0.82881
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01966, current rewards: -1949.82510, mean: -0.80906
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01966, current rewards: -1943.64742, mean: -0.79010
[32m[0906 13-51-27 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 13-51-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-51-27 @MBExp.py:227][0m Rewards obtained: [-1938.7052739587482], Lows: [0], Highs: [2004], Total time: 542.121065
[32m[0906 13-51-54 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-54 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-51-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01983, current rewards: 0.99602, mean: 0.09960
[32m[0906 13-51-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01967, current rewards: 6.52827, mean: 0.10880
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01967, current rewards: 12.06284, mean: 0.10966
[32m[0906 13-51-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01966, current rewards: 17.59504, mean: 0.10997
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01965, current rewards: 23.12769, mean: 0.11013
[32m[0906 13-51-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01966, current rewards: 28.70710, mean: 0.11041
[32m[0906 13-52-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01964, current rewards: 34.23415, mean: 0.11043
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01954, current rewards: 39.76089, mean: 0.11045
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01948, current rewards: 45.28747, mean: 0.11046
[32m[0906 13-52-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01944, current rewards: 50.81445, mean: 0.11047
[32m[0906 13-52-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01941, current rewards: 56.29990, mean: 0.11039
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01939, current rewards: 61.85399, mean: 0.11045
[32m[0906 13-52-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01938, current rewards: 67.40720, mean: 0.11050
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01936, current rewards: 72.93487, mean: 0.11051
[32m[0906 13-52-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01935, current rewards: 78.47399, mean: 0.11053
[32m[0906 13-52-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01934, current rewards: 84.01701, mean: 0.11055
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01933, current rewards: 89.56092, mean: 0.11057
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01932, current rewards: 95.10133, mean: 0.11058
[32m[0906 13-52-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01931, current rewards: 100.63915, mean: 0.11059
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01931, current rewards: 106.18617, mean: 0.11061
[32m[0906 13-52-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01931, current rewards: 111.75382, mean: 0.11065
[32m[0906 13-52-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01930, current rewards: 117.29616, mean: 0.11066
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01929, current rewards: 122.85913, mean: 0.11068
[32m[0906 13-52-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01930, current rewards: 128.41617, mean: 0.11070
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01931, current rewards: 133.97364, mean: 0.11072
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01931, current rewards: 139.53582, mean: 0.11074
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01931, current rewards: 145.09528, mean: 0.11076
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01932, current rewards: 150.65744, mean: 0.11078
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01933, current rewards: 156.21853, mean: 0.11079
[32m[0906 13-52-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01934, current rewards: 161.79834, mean: 0.11082
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01935, current rewards: 167.39767, mean: 0.11086
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01936, current rewards: 173.09891, mean: 0.11096
[32m[0906 13-52-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01938, current rewards: 178.62178, mean: 0.11095
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01940, current rewards: 184.14552, mean: 0.11093
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01942, current rewards: 189.67286, mean: 0.11092
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01944, current rewards: 195.19677, mean: 0.11091
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01946, current rewards: 200.80651, mean: 0.11094
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01947, current rewards: 206.34129, mean: 0.11094
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01949, current rewards: 211.87636, mean: 0.11093
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01951, current rewards: 217.41109, mean: 0.11092
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01952, current rewards: 222.94375, mean: 0.11092
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01953, current rewards: 228.47889, mean: 0.11091
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01954, current rewards: 234.00792, mean: 0.11090
[32m[0906 13-52-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01956, current rewards: 239.53976, mean: 0.11090
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01957, current rewards: 245.07076, mean: 0.11089
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01959, current rewards: 250.59919, mean: 0.11088
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01960, current rewards: 256.11849, mean: 0.11087
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01961, current rewards: 261.72162, mean: 0.11090
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01962, current rewards: 267.32094, mean: 0.11092
[32m[0906 13-52-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01963, current rewards: 272.92583, mean: 0.11095
[32m[0906 13-52-44 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 13-52-44 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-52-44 @MBExp.py:227][0m Rewards obtained: [277.41224086335416], Lows: [0], Highs: [0], Total time: 591.881529
[32m[0906 13-53-13 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-13 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01969, current rewards: 1.17700, mean: 0.11770
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01954, current rewards: 6.85407, mean: 0.11423
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01948, current rewards: 12.53113, mean: 0.11392
[32m[0906 13-53-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01937, current rewards: 18.20820, mean: 0.11380
[32m[0906 13-53-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01928, current rewards: 22.44756, mean: 0.10689
[32m[0906 13-53-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 24.88967, mean: 0.09573
[32m[0906 13-53-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 27.33178, mean: 0.08817
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 29.77388, mean: 0.08271
[32m[0906 13-53-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 23.82525, mean: 0.05811
[32m[0906 13-53-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: -26.17475, mean: -0.05690
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: -76.17475, mean: -0.14936
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: -126.17475, mean: -0.22531
[32m[0906 13-53-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: -176.17475, mean: -0.28881
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: -226.17475, mean: -0.34269
[32m[0906 13-53-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: -276.17475, mean: -0.38898
[32m[0906 13-53-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: -326.17475, mean: -0.42918
[32m[0906 13-53-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: -376.17475, mean: -0.46441
[32m[0906 13-53-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: -426.17475, mean: -0.49555
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: -476.17475, mean: -0.52327
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: -526.17475, mean: -0.54810
[32m[0906 13-53-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: -576.17475, mean: -0.57047
[32m[0906 13-53-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: -626.17475, mean: -0.59073
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: -676.17475, mean: -0.60917
[32m[0906 13-53-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: -726.17475, mean: -0.62601
[32m[0906 13-53-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: -776.17475, mean: -0.64147
[32m[0906 13-53-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: -826.17475, mean: -0.65569
[32m[0906 13-53-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: -876.17475, mean: -0.66884
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: -926.17475, mean: -0.68101
[32m[0906 13-53-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: -976.17475, mean: -0.69232
[32m[0906 13-53-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: -1026.17475, mean: -0.70286
[32m[0906 13-53-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: -1076.17475, mean: -0.71270
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: -1126.17475, mean: -0.72191
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01920, current rewards: -1176.17475, mean: -0.73054
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01922, current rewards: -1226.17475, mean: -0.73866
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01924, current rewards: -1276.17475, mean: -0.74630
[32m[0906 13-53-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01927, current rewards: -1326.17475, mean: -0.75351
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01928, current rewards: -1376.17475, mean: -0.76032
[32m[0906 13-53-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01929, current rewards: -1426.17475, mean: -0.76676
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01931, current rewards: -1476.17475, mean: -0.77287
[32m[0906 13-53-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01933, current rewards: -1526.17475, mean: -0.77866
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01935, current rewards: -1576.17475, mean: -0.78417
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01936, current rewards: -1626.17475, mean: -0.78941
[32m[0906 13-53-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01938, current rewards: -1676.17475, mean: -0.79440
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01939, current rewards: -1726.17475, mean: -0.79915
[32m[0906 13-53-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01940, current rewards: -1776.17475, mean: -0.80370
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01941, current rewards: -1826.17475, mean: -0.80804
[32m[0906 13-53-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01942, current rewards: -1876.17475, mean: -0.81220
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01943, current rewards: -1926.17475, mean: -0.81618
[32m[0906 13-54-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01945, current rewards: -1976.17475, mean: -0.81999
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01946, current rewards: -2026.17475, mean: -0.82365
[32m[0906 13-54-02 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 13-54-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-54-02 @MBExp.py:227][0m Rewards obtained: [-2066.174745652664], Lows: [0], Highs: [2098], Total time: 641.226812
[32m[0906 13-54-34 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-34 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 13-54-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 1.41380, mean: 0.14138
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01907, current rewards: 6.91199, mean: 0.11520
[32m[0906 13-54-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.44573, mean: 0.11314
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01903, current rewards: 17.98023, mean: 0.11238
[32m[0906 13-54-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 23.51262, mean: 0.11196
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01905, current rewards: 29.04428, mean: 0.11171
[32m[0906 13-54-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.68611, mean: 0.11189
[32m[0906 13-54-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 40.20818, mean: 0.11169
[32m[0906 13-54-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 45.73080, mean: 0.11154
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 51.24583, mean: 0.11140
[32m[0906 13-54-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 56.75803, mean: 0.11129
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 62.27550, mean: 0.11121
[32m[0906 13-54-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 67.72873, mean: 0.11103
[32m[0906 13-54-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.15175, mean: 0.11084
[32m[0906 13-54-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 78.58469, mean: 0.11068
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 84.01960, mean: 0.11055
[32m[0906 13-54-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 89.45285, mean: 0.11044
[32m[0906 13-54-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 94.88104, mean: 0.11033
[32m[0906 13-54-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 100.31648, mean: 0.11024
[32m[0906 13-54-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 105.74982, mean: 0.11016
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 111.30067, mean: 0.11020
[32m[0906 13-54-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 116.82604, mean: 0.11021
[32m[0906 13-54-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01909, current rewards: 122.35171, mean: 0.11023
[32m[0906 13-54-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01906, current rewards: 127.88019, mean: 0.11024
[32m[0906 13-54-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01905, current rewards: 133.41292, mean: 0.11026
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 138.93715, mean: 0.11027
[32m[0906 13-54-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01905, current rewards: 144.91025, mean: 0.11062
[32m[0906 13-55-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 150.43164, mean: 0.11061
[32m[0906 13-55-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 155.94512, mean: 0.11060
[32m[0906 13-55-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01906, current rewards: 161.46426, mean: 0.11059
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 166.98335, mean: 0.11059
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 172.50232, mean: 0.11058
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: 178.02232, mean: 0.11057
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01914, current rewards: 183.54115, mean: 0.11057
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 187.97680, mean: 0.10993
[32m[0906 13-55-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01919, current rewards: 193.49915, mean: 0.10994
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: 199.02059, mean: 0.10996
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01924, current rewards: 204.54597, mean: 0.10997
[32m[0906 13-55-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01926, current rewards: 210.06834, mean: 0.10998
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01927, current rewards: 215.58697, mean: 0.10999
[32m[0906 13-55-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01929, current rewards: 221.17156, mean: 0.11004
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01931, current rewards: 226.75899, mean: 0.11008
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01932, current rewards: 232.33964, mean: 0.11011
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01934, current rewards: 237.92674, mean: 0.11015
[32m[0906 13-55-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01936, current rewards: 241.46793, mean: 0.10926
[32m[0906 13-55-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01938, current rewards: 246.99873, mean: 0.10929
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01939, current rewards: 252.52293, mean: 0.10932
[32m[0906 13-55-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01940, current rewards: 258.04635, mean: 0.10934
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01942, current rewards: 263.57291, mean: 0.10937
[32m[0906 13-55-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01943, current rewards: 269.10029, mean: 0.10939
[32m[0906 13-55-23 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 13-55-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-55-23 @MBExp.py:227][0m Rewards obtained: [273.5223838449877], Lows: [1], Highs: [1], Total time: 690.498241
[32m[0906 13-55-56 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-56 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 13-55-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01932, current rewards: 0.10585, mean: 0.01058
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 5.75408, mean: 0.09590
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 11.33474, mean: 0.10304
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 16.86778, mean: 0.10542
[32m[0906 13-56-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 22.43896, mean: 0.10685
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 28.01616, mean: 0.10775
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 33.59105, mean: 0.10836
[32m[0906 13-56-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.16423, mean: 0.10879
[32m[0906 13-56-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 44.73813, mean: 0.10912
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 50.31247, mean: 0.10937
[32m[0906 13-56-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 55.88546, mean: 0.10958
[32m[0906 13-56-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 61.45935, mean: 0.10975
[32m[0906 13-56-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 65.08276, mean: 0.10669
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 70.67135, mean: 0.10708
[32m[0906 13-56-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 76.25839, mean: 0.10741
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 81.84528, mean: 0.10769
[32m[0906 13-56-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: 86.32688, mean: 0.10658
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 91.97570, mean: 0.10695
[32m[0906 13-56-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 97.63036, mean: 0.10729
[32m[0906 13-56-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 103.28002, mean: 0.10758
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 108.92847, mean: 0.10785
[32m[0906 13-56-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01908, current rewards: 114.57617, mean: 0.10809
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01907, current rewards: 120.22501, mean: 0.10831
[32m[0906 13-56-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01904, current rewards: 125.87180, mean: 0.10851
[32m[0906 13-56-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01903, current rewards: 131.52233, mean: 0.10870
[32m[0906 13-56-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01904, current rewards: 137.17260, mean: 0.10887
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01904, current rewards: 142.82243, mean: 0.10902
[32m[0906 13-56-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 148.51972, mean: 0.10921
[32m[0906 13-56-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01906, current rewards: 154.05424, mean: 0.10926
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01908, current rewards: 159.64900, mean: 0.10935
[32m[0906 13-56-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 165.24377, mean: 0.10943
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 170.84170, mean: 0.10951
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: 176.43449, mean: 0.10959
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 182.13886, mean: 0.10972
[32m[0906 13-56-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 187.68401, mean: 0.10976
[32m[0906 13-56-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 193.22844, mean: 0.10979
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 198.76765, mean: 0.10982
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01922, current rewards: 204.30882, mean: 0.10984
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01924, current rewards: 209.85082, mean: 0.10987
[32m[0906 13-56-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01926, current rewards: 215.39592, mean: 0.10990
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 220.99614, mean: 0.10995
[32m[0906 13-56-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01930, current rewards: 226.59327, mean: 0.11000
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01931, current rewards: 232.19743, mean: 0.11005
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01933, current rewards: 237.79656, mean: 0.11009
[32m[0906 13-56-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01935, current rewards: 243.42430, mean: 0.11015
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01936, current rewards: 249.02106, mean: 0.11019
[32m[0906 13-56-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01938, current rewards: 254.61795, mean: 0.11022
[32m[0906 13-56-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01940, current rewards: 260.21657, mean: 0.11026
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01941, current rewards: 265.81501, mean: 0.11030
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01943, current rewards: 271.40040, mean: 0.11033
[32m[0906 13-56-46 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 13-56-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-56-46 @MBExp.py:227][0m Rewards obtained: [275.8550658511981], Lows: [1], Highs: [2], Total time: 739.751542
[32m[0906 13-57-22 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-22 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 0.01867, mean: 0.00187
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 5.57422, mean: 0.09290
[32m[0906 13-57-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01929, current rewards: 11.16277, mean: 0.10148
[32m[0906 13-57-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 16.72630, mean: 0.10454
[32m[0906 13-57-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01919, current rewards: 22.28686, mean: 0.10613
[32m[0906 13-57-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 27.85084, mean: 0.10712
[32m[0906 13-57-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 33.41157, mean: 0.10778
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 38.92852, mean: 0.10813
[32m[0906 13-57-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 44.48974, mean: 0.10851
[32m[0906 13-57-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 50.05521, mean: 0.10882
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 55.61850, mean: 0.10906
[32m[0906 13-57-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 61.30429, mean: 0.10947
[32m[0906 13-57-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 65.06212, mean: 0.10666
[32m[0906 13-57-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 72.15868, mean: 0.10933
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 79.25523, mean: 0.11163
[32m[0906 13-57-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 86.35178, mean: 0.11362
[32m[0906 13-57-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 93.44833, mean: 0.11537
[32m[0906 13-57-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 100.54488, mean: 0.11691
[32m[0906 13-57-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 107.64143, mean: 0.11829
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 114.21365, mean: 0.11897
[32m[0906 13-57-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01907, current rewards: 120.39133, mean: 0.11920
[32m[0906 13-57-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01905, current rewards: 126.56901, mean: 0.11940
[32m[0906 13-57-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01903, current rewards: 90.05166, mean: 0.08113
[32m[0906 13-57-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01901, current rewards: 40.05166, mean: 0.03453
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01899, current rewards: -9.94834, mean: -0.00822
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01898, current rewards: -59.94834, mean: -0.04758
[32m[0906 13-57-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01899, current rewards: -109.94834, mean: -0.08393
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01901, current rewards: -159.94834, mean: -0.11761
[32m[0906 13-57-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: -209.94834, mean: -0.14890
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: -259.94834, mean: -0.17805
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01907, current rewards: -309.94834, mean: -0.20526
[32m[0906 13-57-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: -359.94834, mean: -0.23074
[32m[0906 13-57-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: -409.94834, mean: -0.25463
[32m[0906 13-57-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: -459.94834, mean: -0.27708
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: -509.94834, mean: -0.29822
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01916, current rewards: -559.94834, mean: -0.31815
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01917, current rewards: -609.94834, mean: -0.33699
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: -659.94834, mean: -0.35481
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01920, current rewards: -709.94834, mean: -0.37170
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: -759.94834, mean: -0.38773
[32m[0906 13-58-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01924, current rewards: -809.94834, mean: -0.40296
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01926, current rewards: -859.94834, mean: -0.41745
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01929, current rewards: -909.94834, mean: -0.43126
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01930, current rewards: -959.94834, mean: -0.44442
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01932, current rewards: -1009.94834, mean: -0.45699
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01933, current rewards: -1059.94834, mean: -0.46900
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01935, current rewards: -1109.94834, mean: -0.48050
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01936, current rewards: -1159.94834, mean: -0.49150
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01938, current rewards: -1209.94834, mean: -0.50205
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01939, current rewards: -1259.94834, mean: -0.51217
[32m[0906 13-58-11 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 13-58-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-58-11 @MBExp.py:227][0m Rewards obtained: [-1299.9483434188076], Lows: [1], Highs: [1429], Total time: 788.944668
[32m[0906 13-58-49 @MBExp.py:144][0m ####################################################################
[32m[0906 13-58-49 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 13-58-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01968, current rewards: -0.78549, mean: -0.07855
[32m[0906 13-58-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01921, current rewards: 4.69722, mean: 0.07829
[32m[0906 13-58-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 10.28800, mean: 0.09353
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 16.02819, mean: 0.10018
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01930, current rewards: 21.64818, mean: 0.10309
[32m[0906 13-58-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01928, current rewards: 27.26148, mean: 0.10485
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01925, current rewards: 32.87853, mean: 0.10606
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01922, current rewards: 38.49542, mean: 0.10693
[32m[0906 13-58-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01921, current rewards: 44.11014, mean: 0.10759
[32m[0906 13-58-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01921, current rewards: 51.39992, mean: 0.11174
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 59.47421, mean: 0.11662
[32m[0906 13-59-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 65.69077, mean: 0.11730
[32m[0906 13-59-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 15.69077, mean: 0.02572
[32m[0906 13-59-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: -34.30923, mean: -0.05198
[32m[0906 13-59-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: -83.20760, mean: -0.11719
[32m[0906 13-59-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: -77.63690, mean: -0.10215
[32m[0906 13-59-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: -72.05578, mean: -0.08896
[32m[0906 13-59-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: -66.47278, mean: -0.07729
[32m[0906 13-59-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01907, current rewards: -60.88793, mean: -0.06691
[32m[0906 13-59-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01904, current rewards: -55.30319, mean: -0.05761
[32m[0906 13-59-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01902, current rewards: -49.63474, mean: -0.04914
[32m[0906 13-59-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01899, current rewards: -44.03195, mean: -0.04154
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01897, current rewards: -38.43089, mean: -0.03462
[32m[0906 13-59-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01895, current rewards: -32.83144, mean: -0.02830
[32m[0906 13-59-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01893, current rewards: -27.23143, mean: -0.02251
[32m[0906 13-59-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01892, current rewards: -21.63188, mean: -0.01717
[32m[0906 13-59-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01894, current rewards: -16.02828, mean: -0.01224
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01897, current rewards: -10.40141, mean: -0.00765
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01900, current rewards: -4.79364, mean: -0.00340
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 0.80057, mean: 0.00055
[32m[0906 13-59-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 6.39932, mean: 0.00424
[32m[0906 13-59-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 11.99256, mean: 0.00769
[32m[0906 13-59-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01907, current rewards: 17.58691, mean: 0.01092
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 23.18092, mean: 0.01396
[32m[0906 13-59-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 28.77836, mean: 0.01683
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 34.37771, mean: 0.01953
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01914, current rewards: 39.92011, mean: 0.02206
[32m[0906 13-59-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01915, current rewards: 45.52128, mean: 0.02447
[32m[0906 13-59-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 51.16308, mean: 0.02679
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01919, current rewards: 56.73460, mean: 0.02895
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 62.30226, mean: 0.03100
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 67.87224, mean: 0.03295
[32m[0906 13-59-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01922, current rewards: 73.44202, mean: 0.03481
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01924, current rewards: 79.01155, mean: 0.03658
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01926, current rewards: 84.55819, mean: 0.03826
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 90.13009, mean: 0.03988
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01930, current rewards: 95.69328, mean: 0.04143
[32m[0906 13-59-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01931, current rewards: 101.25009, mean: 0.04290
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01933, current rewards: 106.81248, mean: 0.04432
[32m[0906 13-59-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01934, current rewards: 112.36954, mean: 0.04568
[32m[0906 13-59-38 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 13-59-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-59-38 @MBExp.py:227][0m Rewards obtained: [116.81515236464503], Lows: [1], Highs: [149], Total time: 837.9962889999999
[32m[0906 14-00-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-00-18 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01933, current rewards: 0.00794, mean: 0.00079
[32m[0906 14-00-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01943, current rewards: 5.62486, mean: 0.09375
[32m[0906 14-00-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01938, current rewards: 11.23905, mean: 0.10217
[32m[0906 14-00-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01928, current rewards: 16.84686, mean: 0.10529
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01926, current rewards: 22.46351, mean: 0.10697
[32m[0906 14-00-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01920, current rewards: 28.07523, mean: 0.10798
[32m[0906 14-00-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 33.68606, mean: 0.10866
[32m[0906 14-00-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01922, current rewards: 39.30114, mean: 0.10917
[32m[0906 14-00-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 44.91872, mean: 0.10956
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.53893, mean: 0.10987
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 53.97076, mean: 0.10583
[32m[0906 14-00-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 59.43445, mean: 0.10613
[32m[0906 14-00-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 64.94773, mean: 0.10647
[32m[0906 14-00-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 70.46481, mean: 0.10676
[32m[0906 14-00-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 75.98115, mean: 0.10702
[32m[0906 14-00-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 81.49939, mean: 0.10724
[32m[0906 14-00-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01907, current rewards: 87.01442, mean: 0.10743
[32m[0906 14-00-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01904, current rewards: 92.52952, mean: 0.10759
[32m[0906 14-00-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01901, current rewards: 98.04459, mean: 0.10774
[32m[0906 14-00-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01899, current rewards: 103.50996, mean: 0.10782
[32m[0906 14-00-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01896, current rewards: 109.00264, mean: 0.10792
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01894, current rewards: 114.63307, mean: 0.10814
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01892, current rewards: 120.26183, mean: 0.10834
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01890, current rewards: 125.88905, mean: 0.10853
[32m[0906 14-00-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01888, current rewards: 131.51617, mean: 0.10869
[32m[0906 14-00-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01888, current rewards: 137.15160, mean: 0.10885
[32m[0906 14-00-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01890, current rewards: 142.78559, mean: 0.10900
[32m[0906 14-00-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01893, current rewards: 148.50311, mean: 0.10919
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01896, current rewards: 154.15418, mean: 0.10933
[32m[0906 14-00-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01898, current rewards: 159.80404, mean: 0.10945
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01901, current rewards: 165.45362, mean: 0.10957
[32m[0906 14-00-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 171.10320, mean: 0.10968
[32m[0906 14-00-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 176.75583, mean: 0.10979
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 182.44799, mean: 0.10991
[32m[0906 14-00-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 188.04756, mean: 0.10997
[32m[0906 14-00-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: 193.56550, mean: 0.10998
[32m[0906 14-00-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01912, current rewards: 199.09518, mean: 0.11000
[32m[0906 14-00-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 204.65866, mean: 0.11003
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 210.22109, mean: 0.11006
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 215.78527, mean: 0.11009
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01916, current rewards: 221.34902, mean: 0.11012
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 226.90983, mean: 0.11015
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 232.47748, mean: 0.11018
[32m[0906 14-01-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: 238.03928, mean: 0.11020
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 243.68219, mean: 0.11026
[32m[0906 14-01-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01922, current rewards: 249.28610, mean: 0.11030
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01924, current rewards: 254.88455, mean: 0.11034
[32m[0906 14-01-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01926, current rewards: 260.48843, mean: 0.11038
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01927, current rewards: 266.08948, mean: 0.11041
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01929, current rewards: 271.69139, mean: 0.11044
[32m[0906 14-01-07 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-01-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-01-07 @MBExp.py:227][0m Rewards obtained: [276.1736263793943], Lows: [1], Highs: [1], Total time: 886.936936
[32m[0906 14-01-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-50 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-01-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01961, current rewards: 1.07746, mean: 0.10775
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01968, current rewards: 6.60825, mean: 0.11014
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01952, current rewards: 12.23740, mean: 0.11125
[32m[0906 14-01-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01944, current rewards: 17.91597, mean: 0.11197
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01936, current rewards: 23.49879, mean: 0.11190
[32m[0906 14-01-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01932, current rewards: 30.04215, mean: 0.11555
[32m[0906 14-01-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01928, current rewards: 38.58007, mean: 0.12445
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 47.11799, mean: 0.13088
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01924, current rewards: 55.65591, mean: 0.13575
[32m[0906 14-01-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 64.19383, mean: 0.13955
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01925, current rewards: 72.73174, mean: 0.14261
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01924, current rewards: 79.28314, mean: 0.14158
[32m[0906 14-02-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 49.37985, mean: 0.08095
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: -0.62015, mean: -0.00094
[32m[0906 14-02-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: -50.62015, mean: -0.07130
[32m[0906 14-02-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01905, current rewards: -100.62015, mean: -0.13239
[32m[0906 14-02-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01903, current rewards: -150.62015, mean: -0.18595
[32m[0906 14-02-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01899, current rewards: -200.62015, mean: -0.23328
[32m[0906 14-02-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01896, current rewards: -250.62015, mean: -0.27541
[32m[0906 14-02-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01896, current rewards: -300.62015, mean: -0.31315
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01895, current rewards: -350.62015, mean: -0.34715
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01893, current rewards: -400.62015, mean: -0.37794
[32m[0906 14-02-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01891, current rewards: -450.62015, mean: -0.40596
[32m[0906 14-02-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01889, current rewards: -500.62015, mean: -0.43157
[32m[0906 14-02-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01889, current rewards: -550.62015, mean: -0.45506
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01890, current rewards: -600.62015, mean: -0.47668
[32m[0906 14-02-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01892, current rewards: -650.62015, mean: -0.49666
[32m[0906 14-02-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01893, current rewards: -700.62015, mean: -0.51516
[32m[0906 14-02-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01896, current rewards: -750.62015, mean: -0.53235
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01898, current rewards: -800.62015, mean: -0.54837
[32m[0906 14-02-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01899, current rewards: -850.62015, mean: -0.56332
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01901, current rewards: -900.62015, mean: -0.57732
[32m[0906 14-02-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: -950.62015, mean: -0.59045
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: -1000.62015, mean: -0.60278
[32m[0906 14-02-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: -1050.62015, mean: -0.61440
[32m[0906 14-02-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01910, current rewards: -1100.62015, mean: -0.62535
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: -1150.62015, mean: -0.63570
[32m[0906 14-02-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: -1200.62015, mean: -0.64549
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: -1250.62015, mean: -0.65477
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: -1300.62015, mean: -0.66358
[32m[0906 14-02-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01916, current rewards: -1350.62015, mean: -0.67195
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: -1400.62015, mean: -0.67991
[32m[0906 14-02-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: -1450.62015, mean: -0.68750
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01920, current rewards: -1500.62015, mean: -0.69473
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: -1550.62015, mean: -0.70164
[32m[0906 14-02-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01922, current rewards: -1600.62015, mean: -0.70824
[32m[0906 14-02-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01922, current rewards: -1650.62015, mean: -0.71455
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01923, current rewards: -1700.62015, mean: -0.72060
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01925, current rewards: -1750.62015, mean: -0.72640
[32m[0906 14-02-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: -1800.62015, mean: -0.73196
[32m[0906 14-02-38 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-02-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-02-38 @MBExp.py:227][0m Rewards obtained: [-1840.6201520981194], Lows: [0], Highs: [1921], Total time: 935.8172139999999
[32m[0906 14-03-23 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-23 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01912, current rewards: 1.07727, mean: 0.10773
[32m[0906 14-03-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01955, current rewards: 6.68845, mean: 0.11147
[32m[0906 14-03-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01954, current rewards: 12.23383, mean: 0.11122
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01942, current rewards: 17.70449, mean: 0.11065
[32m[0906 14-03-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01939, current rewards: 23.18542, mean: 0.11041
[32m[0906 14-03-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01935, current rewards: 28.73062, mean: 0.11050
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01931, current rewards: 34.27259, mean: 0.11056
[32m[0906 14-03-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01928, current rewards: 39.81339, mean: 0.11059
[32m[0906 14-03-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.35310, mean: 0.11062
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 51.05893, mean: 0.11100
[32m[0906 14-03-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.59159, mean: 0.11096
[32m[0906 14-03-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.12951, mean: 0.11095
[32m[0906 14-03-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 67.66067, mean: 0.11092
[32m[0906 14-03-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01906, current rewards: 73.19236, mean: 0.11090
[32m[0906 14-03-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01903, current rewards: 78.72617, mean: 0.11088
[32m[0906 14-03-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01900, current rewards: 84.26216, mean: 0.11087
[32m[0906 14-03-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01896, current rewards: 89.79342, mean: 0.11086
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01894, current rewards: 95.32572, mean: 0.11084
[32m[0906 14-03-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01891, current rewards: 100.85696, mean: 0.11083
[32m[0906 14-03-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01890, current rewards: 106.38858, mean: 0.11082
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01889, current rewards: 112.06312, mean: 0.11095
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01889, current rewards: 117.59353, mean: 0.11094
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01887, current rewards: 123.13107, mean: 0.11093
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01889, current rewards: 128.67007, mean: 0.11092
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01890, current rewards: 134.20703, mean: 0.11091
[32m[0906 14-03-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01892, current rewards: 139.74937, mean: 0.11091
[32m[0906 14-03-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01894, current rewards: 145.28383, mean: 0.11090
[32m[0906 14-03-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01895, current rewards: 150.82133, mean: 0.11090
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01896, current rewards: 156.31800, mean: 0.11086
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01899, current rewards: 161.78081, mean: 0.11081
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01901, current rewards: 167.30827, mean: 0.11080
[32m[0906 14-03-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 172.82722, mean: 0.11079
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 178.33627, mean: 0.11077
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 183.82941, mean: 0.11074
[32m[0906 14-03-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: 189.32370, mean: 0.11072
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 194.81678, mean: 0.11069
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 200.31122, mean: 0.11067
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: 205.94240, mean: 0.11072
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 211.48619, mean: 0.11073
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 217.03165, mean: 0.11073
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01916, current rewards: 222.57854, mean: 0.11074
[32m[0906 14-04-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 228.12690, mean: 0.11074
[32m[0906 14-04-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 233.67663, mean: 0.11075
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: 239.36025, mean: 0.11081
[32m[0906 14-04-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 245.12593, mean: 0.11092
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 250.86207, mean: 0.11100
[32m[0906 14-04-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01922, current rewards: 256.49239, mean: 0.11104
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01923, current rewards: 262.15924, mean: 0.11108
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01924, current rewards: 267.82830, mean: 0.11113
[32m[0906 14-04-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01925, current rewards: 273.49649, mean: 0.11118
[32m[0906 14-04-12 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-04-12 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-04-12 @MBExp.py:227][0m Rewards obtained: [278.0308541992795], Lows: [0], Highs: [0], Total time: 984.6519689999999
[32m[0906 14-04-59 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-59 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-04-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01925, current rewards: 1.07252, mean: 0.10725
[32m[0906 14-05-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01963, current rewards: 6.63993, mean: 0.11067
[32m[0906 14-05-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01962, current rewards: 12.20373, mean: 0.11094
[32m[0906 14-05-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01945, current rewards: 17.76912, mean: 0.11106
[32m[0906 14-05-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01937, current rewards: 23.33998, mean: 0.11114
[32m[0906 14-05-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01932, current rewards: 29.13208, mean: 0.11205
[32m[0906 14-05-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01932, current rewards: 34.89563, mean: 0.11257
[32m[0906 14-05-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01930, current rewards: 40.65948, mean: 0.11294
[32m[0906 14-05-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 46.42386, mean: 0.11323
[32m[0906 14-05-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 52.18887, mean: 0.11345
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 57.95356, mean: 0.11363
[32m[0906 14-05-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 63.71802, mean: 0.11378
[32m[0906 14-05-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01901, current rewards: 69.37196, mean: 0.11372
[32m[0906 14-05-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01898, current rewards: 74.97633, mean: 0.11360
[32m[0906 14-05-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01896, current rewards: 80.57774, mean: 0.11349
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01893, current rewards: 86.18081, mean: 0.11340
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01891, current rewards: 91.78189, mean: 0.11331
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01890, current rewards: 97.38487, mean: 0.11324
[32m[0906 14-05-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01889, current rewards: 102.98735, mean: 0.11317
[32m[0906 14-05-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01887, current rewards: 108.59129, mean: 0.11312
[32m[0906 14-05-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01886, current rewards: 114.17177, mean: 0.11304
[32m[0906 14-05-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01886, current rewards: 119.76427, mean: 0.11299
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01888, current rewards: 125.35690, mean: 0.11293
[32m[0906 14-05-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01889, current rewards: 130.95124, mean: 0.11289
[32m[0906 14-05-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01891, current rewards: 136.54175, mean: 0.11284
[32m[0906 14-05-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01892, current rewards: 142.09366, mean: 0.11277
[32m[0906 14-05-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01892, current rewards: 147.58146, mean: 0.11266
[32m[0906 14-05-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01894, current rewards: 153.07059, mean: 0.11255
[32m[0906 14-05-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01895, current rewards: 158.56713, mean: 0.11246
[32m[0906 14-05-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01897, current rewards: 164.12713, mean: 0.11242
[32m[0906 14-05-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01899, current rewards: 169.70114, mean: 0.11238
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01901, current rewards: 175.28060, mean: 0.11236
[32m[0906 14-05-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 180.85358, mean: 0.11233
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 186.44078, mean: 0.11231
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: 192.00942, mean: 0.11229
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: 197.57931, mean: 0.11226
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01910, current rewards: 203.11818, mean: 0.11222
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 208.67757, mean: 0.11219
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 214.23881, mean: 0.11217
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 219.80048, mean: 0.11214
[32m[0906 14-05-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 225.36232, mean: 0.11212
[32m[0906 14-05-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01916, current rewards: 230.92171, mean: 0.11210
[32m[0906 14-05-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 236.48258, mean: 0.11208
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: 242.06043, mean: 0.11207
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 247.68858, mean: 0.11208
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 253.29163, mean: 0.11208
[32m[0906 14-05-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01921, current rewards: 258.89002, mean: 0.11207
[32m[0906 14-05-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01923, current rewards: 264.49321, mean: 0.11207
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01924, current rewards: 270.07098, mean: 0.11206
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01925, current rewards: 275.64910, mean: 0.11205
[32m[0906 14-05-48 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-05-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-05-48 @MBExp.py:227][0m Rewards obtained: [280.1131177405993], Lows: [0], Highs: [0], Total time: 1033.4660179999998
[32m[0906 14-06-37 @MBExp.py:144][0m ####################################################################
[32m[0906 14-06-37 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02026, current rewards: 1.07865, mean: 0.10786
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01981, current rewards: 6.62106, mean: 0.11035
[32m[0906 14-06-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01964, current rewards: 12.16366, mean: 0.11058
[32m[0906 14-06-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01950, current rewards: 17.70403, mean: 0.11065
[32m[0906 14-06-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01944, current rewards: 23.24540, mean: 0.11069
[32m[0906 14-06-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01935, current rewards: 28.78608, mean: 0.11072
[32m[0906 14-06-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01922, current rewards: 34.32773, mean: 0.11073
[32m[0906 14-06-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.86893, mean: 0.11075
[32m[0906 14-06-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01905, current rewards: 45.41375, mean: 0.11077
[32m[0906 14-06-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01899, current rewards: 50.95435, mean: 0.11077
[32m[0906 14-06-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01895, current rewards: 56.49467, mean: 0.11077
[32m[0906 14-06-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01890, current rewards: 61.99183, mean: 0.11070
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01885, current rewards: 67.47279, mean: 0.11061
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01882, current rewards: 72.99585, mean: 0.11060
[32m[0906 14-06-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01881, current rewards: 78.51906, mean: 0.11059
[32m[0906 14-06-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01879, current rewards: 84.04263, mean: 0.11058
[32m[0906 14-06-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01877, current rewards: 89.56486, mean: 0.11057
[32m[0906 14-06-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01877, current rewards: 95.08828, mean: 0.11057
[32m[0906 14-06-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01877, current rewards: 100.61501, mean: 0.11057
[32m[0906 14-06-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01877, current rewards: 106.17813, mean: 0.11060
[32m[0906 14-06-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01878, current rewards: 111.71327, mean: 0.11061
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01881, current rewards: 117.24893, mean: 0.11061
[32m[0906 14-06-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01881, current rewards: 122.77703, mean: 0.11061
[32m[0906 14-06-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01883, current rewards: 128.31169, mean: 0.11061
[32m[0906 14-07-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01885, current rewards: 133.84878, mean: 0.11062
[32m[0906 14-07-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01886, current rewards: 139.39009, mean: 0.11063
[32m[0906 14-07-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01887, current rewards: 144.92799, mean: 0.11063
[32m[0906 14-07-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01888, current rewards: 150.49489, mean: 0.11066
[32m[0906 14-07-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01889, current rewards: 155.95969, mean: 0.11061
[32m[0906 14-07-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01890, current rewards: 161.43454, mean: 0.11057
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01892, current rewards: 166.90474, mean: 0.11053
[32m[0906 14-07-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01894, current rewards: 172.37558, mean: 0.11050
[32m[0906 14-07-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01897, current rewards: 177.85345, mean: 0.11047
[32m[0906 14-07-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 183.32031, mean: 0.11043
[32m[0906 14-07-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: 188.79772, mean: 0.11041
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01903, current rewards: 194.23042, mean: 0.11036
[32m[0906 14-07-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: 199.68582, mean: 0.11032
[32m[0906 14-07-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 205.14379, mean: 0.11029
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 210.59854, mean: 0.11026
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 216.11026, mean: 0.11026
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 221.65715, mean: 0.11028
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: 227.20733, mean: 0.11029
[32m[0906 14-07-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01913, current rewards: 232.75041, mean: 0.11031
[32m[0906 14-07-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 238.41165, mean: 0.11038
[32m[0906 14-07-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01916, current rewards: 244.06853, mean: 0.11044
[32m[0906 14-07-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01917, current rewards: 249.70604, mean: 0.11049
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: 255.34054, mean: 0.11054
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01919, current rewards: 260.97375, mean: 0.11058
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01920, current rewards: 266.60639, mean: 0.11063
[32m[0906 14-07-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: 272.15313, mean: 0.11063
[32m[0906 14-07-26 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-07-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-07-26 @MBExp.py:227][0m Rewards obtained: [276.5951568578483], Lows: [0], Highs: [0], Total time: 1082.2015069999998
[32m[0906 14-08-17 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-17 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01927, current rewards: 0.05017, mean: 0.00502
[32m[0906 14-08-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01956, current rewards: 5.66393, mean: 0.09440
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01964, current rewards: 11.24353, mean: 0.10221
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01949, current rewards: 16.83298, mean: 0.10521
[32m[0906 14-08-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01932, current rewards: 22.42278, mean: 0.10678
[32m[0906 14-08-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 28.01491, mean: 0.10775
[32m[0906 14-08-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01905, current rewards: 33.60062, mean: 0.10839
[32m[0906 14-08-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01897, current rewards: 39.19366, mean: 0.10887
[32m[0906 14-08-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01891, current rewards: 44.78150, mean: 0.10922
[32m[0906 14-08-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01888, current rewards: 50.35110, mean: 0.10946
[32m[0906 14-08-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01885, current rewards: 55.90101, mean: 0.10961
[32m[0906 14-08-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01882, current rewards: 61.46830, mean: 0.10976
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01880, current rewards: 67.03550, mean: 0.10989
[32m[0906 14-08-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01878, current rewards: 72.60775, mean: 0.11001
[32m[0906 14-08-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01876, current rewards: 78.18494, mean: 0.11012
[32m[0906 14-08-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01875, current rewards: 83.74932, mean: 0.11020
[32m[0906 14-08-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01872, current rewards: 89.31503, mean: 0.11027
[32m[0906 14-08-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01872, current rewards: 94.88302, mean: 0.11033
[32m[0906 14-08-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01871, current rewards: 100.51958, mean: 0.11046
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01873, current rewards: 106.09668, mean: 0.11052
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01876, current rewards: 111.67315, mean: 0.11057
[32m[0906 14-08-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01878, current rewards: 117.24697, mean: 0.11061
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01879, current rewards: 122.82022, mean: 0.11065
[32m[0906 14-08-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01880, current rewards: 128.39690, mean: 0.11069
[32m[0906 14-08-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01881, current rewards: 133.97147, mean: 0.11072
[32m[0906 14-08-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01883, current rewards: 139.54292, mean: 0.11075
[32m[0906 14-08-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01884, current rewards: 145.12948, mean: 0.11079
[32m[0906 14-08-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01885, current rewards: 150.71112, mean: 0.11082
[32m[0906 14-08-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01886, current rewards: 156.28823, mean: 0.11084
[32m[0906 14-08-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01888, current rewards: 161.85940, mean: 0.11086
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01890, current rewards: 167.42584, mean: 0.11088
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01893, current rewards: 172.99265, mean: 0.11089
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01895, current rewards: 178.55808, mean: 0.11091
[32m[0906 14-08-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01897, current rewards: 184.11965, mean: 0.11092
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01899, current rewards: 189.69188, mean: 0.11093
[32m[0906 14-08-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01901, current rewards: 195.08734, mean: 0.11085
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01902, current rewards: 200.61086, mean: 0.11083
[32m[0906 14-08-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01904, current rewards: 206.18338, mean: 0.11085
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 211.75716, mean: 0.11087
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 217.33289, mean: 0.11088
[32m[0906 14-08-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 222.90882, mean: 0.11090
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 228.47986, mean: 0.11091
[32m[0906 14-08-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 234.05417, mean: 0.11093
[32m[0906 14-08-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: 239.69096, mean: 0.11097
[32m[0906 14-09-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01913, current rewards: 245.22628, mean: 0.11096
[32m[0906 14-09-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 250.75762, mean: 0.11095
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 256.29474, mean: 0.11095
[32m[0906 14-09-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: 261.82709, mean: 0.11094
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01917, current rewards: 267.36067, mean: 0.11094
[32m[0906 14-09-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01917, current rewards: 272.89593, mean: 0.11093
[32m[0906 14-09-06 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-09-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-09-06 @MBExp.py:227][0m Rewards obtained: [277.32265874352385], Lows: [0], Highs: [1], Total time: 1130.8364229999997
[32m[0906 14-09-59 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-59 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01955, current rewards: 1.05772, mean: 0.10577
[32m[0906 14-10-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01947, current rewards: 6.61875, mean: 0.11031
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01939, current rewards: 12.16582, mean: 0.11060
[32m[0906 14-10-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01934, current rewards: 17.71349, mean: 0.11071
[32m[0906 14-10-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.25584, mean: 0.11074
[32m[0906 14-10-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01900, current rewards: 28.79940, mean: 0.11077
[32m[0906 14-10-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01890, current rewards: 34.42802, mean: 0.11106
[32m[0906 14-10-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01884, current rewards: 39.95163, mean: 0.11098
[32m[0906 14-10-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01880, current rewards: 45.47436, mean: 0.11091
[32m[0906 14-10-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01876, current rewards: 51.01112, mean: 0.11089
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01875, current rewards: 56.60897, mean: 0.11100
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01873, current rewards: 62.16717, mean: 0.11101
[32m[0906 14-10-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01872, current rewards: 67.73551, mean: 0.11104
[32m[0906 14-10-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01872, current rewards: 73.30531, mean: 0.11107
[32m[0906 14-10-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01870, current rewards: 78.87960, mean: 0.11110
[32m[0906 14-10-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01868, current rewards: 84.44822, mean: 0.11112
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01867, current rewards: 90.01502, mean: 0.11113
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01868, current rewards: 95.58092, mean: 0.11114
[32m[0906 14-10-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01870, current rewards: 101.07959, mean: 0.11108
[32m[0906 14-10-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01872, current rewards: 106.61869, mean: 0.11106
[32m[0906 14-10-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01875, current rewards: 112.15984, mean: 0.11105
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01877, current rewards: 117.71265, mean: 0.11105
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01878, current rewards: 123.26116, mean: 0.11105
[32m[0906 14-10-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01880, current rewards: 128.80539, mean: 0.11104
[32m[0906 14-10-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01882, current rewards: 134.35462, mean: 0.11104
[32m[0906 14-10-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01884, current rewards: 139.89872, mean: 0.11103
[32m[0906 14-10-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01885, current rewards: 145.40883, mean: 0.11100
[32m[0906 14-10-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01886, current rewards: 151.02943, mean: 0.11105
[32m[0906 14-10-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01887, current rewards: 156.56691, mean: 0.11104
[32m[0906 14-10-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01888, current rewards: 162.11157, mean: 0.11104
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01889, current rewards: 167.64813, mean: 0.11103
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01891, current rewards: 173.18715, mean: 0.11102
[32m[0906 14-10-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 178.72116, mean: 0.11101
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 182.13917, mean: 0.10972
[32m[0906 14-10-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01897, current rewards: 187.89940, mean: 0.10988
[32m[0906 14-10-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01899, current rewards: 193.69823, mean: 0.11006
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01901, current rewards: 199.49424, mean: 0.11022
[32m[0906 14-10-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: 205.29363, mean: 0.11037
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01904, current rewards: 211.08839, mean: 0.11052
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01905, current rewards: 216.88771, mean: 0.11066
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01906, current rewards: 222.68789, mean: 0.11079
[32m[0906 14-10-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01907, current rewards: 228.48378, mean: 0.11091
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01908, current rewards: 234.28478, mean: 0.11104
[32m[0906 14-10-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01910, current rewards: 240.08243, mean: 0.11115
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01911, current rewards: 245.88058, mean: 0.11126
[32m[0906 14-10-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01912, current rewards: 251.67908, mean: 0.11136
[32m[0906 14-10-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 257.47734, mean: 0.11146
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01914, current rewards: 263.27511, mean: 0.11156
[32m[0906 14-10-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 269.07016, mean: 0.11165
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01916, current rewards: 274.86632, mean: 0.11173
[32m[0906 14-10-48 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-10-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-10-48 @MBExp.py:227][0m Rewards obtained: [279.5030363281628], Lows: [1], Highs: [0], Total time: 1179.4281539999997
[32m[0906 14-11-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-44 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-11-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01886, current rewards: 1.10126, mean: 0.11013
[32m[0906 14-11-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01900, current rewards: 7.91166, mean: 0.13186
[32m[0906 14-11-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 15.00821, mean: 0.13644
[32m[0906 14-11-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 22.10476, mean: 0.13815
[32m[0906 14-11-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01898, current rewards: 18.92394, mean: 0.09011
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01888, current rewards: -31.07606, mean: -0.11952
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01884, current rewards: -81.07606, mean: -0.26154
[32m[0906 14-11-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01879, current rewards: -131.07606, mean: -0.36410
[32m[0906 14-11-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01875, current rewards: -181.07606, mean: -0.44165
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01871, current rewards: -231.07606, mean: -0.50234
[32m[0906 14-11-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01870, current rewards: -281.07606, mean: -0.55113
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01869, current rewards: -331.07606, mean: -0.59121
[32m[0906 14-11-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01868, current rewards: -381.07606, mean: -0.62471
[32m[0906 14-11-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01865, current rewards: -414.40231, mean: -0.62788
[32m[0906 14-11-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01864, current rewards: -408.78901, mean: -0.57576
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01865, current rewards: -403.17621, mean: -0.53050
[32m[0906 14-11-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01868, current rewards: -397.56719, mean: -0.49082
[32m[0906 14-12-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01871, current rewards: -392.07549, mean: -0.45590
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01874, current rewards: -386.50156, mean: -0.42473
[32m[0906 14-12-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01877, current rewards: -380.94011, mean: -0.39681
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01879, current rewards: -375.37468, mean: -0.37166
[32m[0906 14-12-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01880, current rewards: -369.81316, mean: -0.34888
[32m[0906 14-12-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01882, current rewards: -364.24886, mean: -0.32815
[32m[0906 14-12-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01883, current rewards: -358.68255, mean: -0.30921
[32m[0906 14-12-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01884, current rewards: -353.11764, mean: -0.29183
[32m[0906 14-12-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01886, current rewards: -347.53035, mean: -0.27582
[32m[0906 14-12-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01887, current rewards: -341.82883, mean: -0.26094
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01888, current rewards: -336.23108, mean: -0.24723
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01890, current rewards: -330.56001, mean: -0.23444
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01892, current rewards: -324.94141, mean: -0.22256
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01893, current rewards: -319.32188, mean: -0.21147
[32m[0906 14-12-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01895, current rewards: -313.70270, mean: -0.20109
[32m[0906 14-12-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01898, current rewards: -308.08248, mean: -0.19136
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01900, current rewards: -302.46232, mean: -0.18221
[32m[0906 14-12-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01902, current rewards: -296.84878, mean: -0.17360
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01904, current rewards: -291.23226, mean: -0.16547
[32m[0906 14-12-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: -285.61121, mean: -0.15780
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: -280.01205, mean: -0.15054
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: -274.41526, mean: -0.14367
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01910, current rewards: -268.81283, mean: -0.13715
[32m[0906 14-12-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: -263.21466, mean: -0.13095
[32m[0906 14-12-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01913, current rewards: -257.61771, mean: -0.12506
[32m[0906 14-12-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: -252.04835, mean: -0.11945
[32m[0906 14-12-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01916, current rewards: -246.46474, mean: -0.11410
[32m[0906 14-12-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01917, current rewards: -240.85562, mean: -0.10898
[32m[0906 14-12-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01918, current rewards: -235.24494, mean: -0.10409
[32m[0906 14-12-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: -229.63169, mean: -0.09941
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: -224.02166, mean: -0.09492
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: -218.40989, mean: -0.09063
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01922, current rewards: -212.79928, mean: -0.08650
[32m[0906 14-12-32 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-12-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-12-32 @MBExp.py:227][0m Rewards obtained: [-208.3217001598888], Lows: [0], Highs: [444], Total time: 1228.1671269999997
[32m[0906 14-13-30 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-30 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01898, current rewards: 1.02819, mean: 0.10282
[32m[0906 14-13-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: 6.62433, mean: 0.11041
[32m[0906 14-13-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.21982, mean: 0.11109
[32m[0906 14-13-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.81635, mean: 0.11135
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 23.41115, mean: 0.11148
[32m[0906 14-13-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01893, current rewards: 29.00472, mean: 0.11156
[32m[0906 14-13-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01887, current rewards: 34.60246, mean: 0.11162
[32m[0906 14-13-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01885, current rewards: 40.20197, mean: 0.11167
[32m[0906 14-13-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01881, current rewards: 45.80291, mean: 0.11171
[32m[0906 14-13-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01878, current rewards: 51.52047, mean: 0.11200
[32m[0906 14-13-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01876, current rewards: 57.13264, mean: 0.11202
[32m[0906 14-13-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01873, current rewards: 62.74756, mean: 0.11205
[32m[0906 14-13-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01873, current rewards: 68.38626, mean: 0.11211
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01871, current rewards: 73.99055, mean: 0.11211
[32m[0906 14-13-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01875, current rewards: 79.59954, mean: 0.11211
[32m[0906 14-13-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01878, current rewards: 85.20351, mean: 0.11211
[32m[0906 14-13-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01881, current rewards: 90.80572, mean: 0.11211
[32m[0906 14-13-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01883, current rewards: 96.33634, mean: 0.11202
[32m[0906 14-13-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01886, current rewards: 101.86910, mean: 0.11194
[32m[0906 14-13-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01888, current rewards: 107.39766, mean: 0.11187
[32m[0906 14-13-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01890, current rewards: 112.93213, mean: 0.11181
[32m[0906 14-13-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01891, current rewards: 118.46880, mean: 0.11176
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01892, current rewards: 124.00022, mean: 0.11171
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01894, current rewards: 129.52885, mean: 0.11166
[32m[0906 14-13-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01895, current rewards: 135.03243, mean: 0.11160
[32m[0906 14-13-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01896, current rewards: 140.58737, mean: 0.11158
[32m[0906 14-13-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01896, current rewards: 146.13424, mean: 0.11155
[32m[0906 14-13-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01898, current rewards: 151.68215, mean: 0.11153
[32m[0906 14-13-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01899, current rewards: 157.22706, mean: 0.11151
[32m[0906 14-13-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01900, current rewards: 162.77064, mean: 0.11149
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01900, current rewards: 168.38627, mean: 0.11151
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01902, current rewards: 173.97912, mean: 0.11153
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: 179.57369, mean: 0.11154
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 185.17803, mean: 0.11155
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 190.80329, mean: 0.11158
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 196.40420, mean: 0.11159
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: 202.00205, mean: 0.11160
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: 207.60179, mean: 0.11161
[32m[0906 14-14-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 213.20516, mean: 0.11163
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 218.80763, mean: 0.11164
[32m[0906 14-14-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01916, current rewards: 224.59668, mean: 0.11174
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 230.17341, mean: 0.11173
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 235.73647, mean: 0.11172
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: 241.30937, mean: 0.11172
[32m[0906 14-14-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01920, current rewards: 246.88191, mean: 0.11171
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: 251.31398, mean: 0.11120
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01922, current rewards: 256.86667, mean: 0.11120
[32m[0906 14-14-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01924, current rewards: 262.42046, mean: 0.11120
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01925, current rewards: 267.97719, mean: 0.11119
[32m[0906 14-14-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01926, current rewards: 273.53164, mean: 0.11119
[32m[0906 14-14-19 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-14-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-14-19 @MBExp.py:227][0m Rewards obtained: [278.09524090235453], Lows: [0], Highs: [1], Total time: 1277.0045399999997
[32m[0906 14-15-19 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-19 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-15-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01913, current rewards: 1.11366, mean: 0.11137
[32m[0906 14-15-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01935, current rewards: 6.70636, mean: 0.11177
[32m[0906 14-15-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01922, current rewards: 12.29787, mean: 0.11180
[32m[0906 14-15-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 17.88946, mean: 0.11181
[32m[0906 14-15-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 23.48214, mean: 0.11182
[32m[0906 14-15-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01896, current rewards: 29.07941, mean: 0.11184
[32m[0906 14-15-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01889, current rewards: 34.67428, mean: 0.11185
[32m[0906 14-15-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01882, current rewards: 40.23543, mean: 0.11177
[32m[0906 14-15-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01877, current rewards: 45.69532, mean: 0.11145
[32m[0906 14-15-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01875, current rewards: 51.21814, mean: 0.11134
[32m[0906 14-15-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01872, current rewards: 56.73169, mean: 0.11124
[32m[0906 14-15-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01870, current rewards: 62.25073, mean: 0.11116
[32m[0906 14-15-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01873, current rewards: 67.76789, mean: 0.11109
[32m[0906 14-15-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01877, current rewards: 73.28756, mean: 0.11104
[32m[0906 14-15-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01880, current rewards: 78.80813, mean: 0.11100
[32m[0906 14-15-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01883, current rewards: 84.32852, mean: 0.11096
[32m[0906 14-15-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01885, current rewards: 89.87745, mean: 0.11096
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01886, current rewards: 95.46025, mean: 0.11100
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01889, current rewards: 101.02490, mean: 0.11102
[32m[0906 14-15-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01890, current rewards: 106.58921, mean: 0.11103
[32m[0906 14-15-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01892, current rewards: 112.15423, mean: 0.11104
[32m[0906 14-15-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01893, current rewards: 117.71679, mean: 0.11105
[32m[0906 14-15-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01894, current rewards: 123.23457, mean: 0.11102
[32m[0906 14-15-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01897, current rewards: 128.78337, mean: 0.11102
[32m[0906 14-15-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01898, current rewards: 134.36655, mean: 0.11105
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01899, current rewards: 139.91870, mean: 0.11105
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01900, current rewards: 145.47335, mean: 0.11105
[32m[0906 14-15-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01901, current rewards: 151.02834, mean: 0.11105
[32m[0906 14-15-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01901, current rewards: 156.51933, mean: 0.11101
[32m[0906 14-15-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 162.03320, mean: 0.11098
[32m[0906 14-15-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 167.55195, mean: 0.11096
[32m[0906 14-15-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01904, current rewards: 173.07149, mean: 0.11094
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 178.55907, mean: 0.11091
[32m[0906 14-15-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01907, current rewards: 184.06911, mean: 0.11089
[32m[0906 14-15-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 189.57883, mean: 0.11086
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: 195.12572, mean: 0.11087
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 200.66759, mean: 0.11087
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: 206.21320, mean: 0.11087
[32m[0906 14-15-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01915, current rewards: 211.75470, mean: 0.11087
[32m[0906 14-15-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01916, current rewards: 217.30439, mean: 0.11087
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: 222.86557, mean: 0.11088
[32m[0906 14-15-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01918, current rewards: 228.41746, mean: 0.11088
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01919, current rewards: 233.96122, mean: 0.11088
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01920, current rewards: 239.50467, mean: 0.11088
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: 245.04527, mean: 0.11088
[32m[0906 14-16-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01923, current rewards: 250.59848, mean: 0.11088
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01923, current rewards: 256.14944, mean: 0.11089
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01924, current rewards: 261.69535, mean: 0.11089
[32m[0906 14-16-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01925, current rewards: 267.23610, mean: 0.11089
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: 272.77181, mean: 0.11088
[32m[0906 14-16-08 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-16-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-16-08 @MBExp.py:227][0m Rewards obtained: [277.2389574023567], Lows: [0], Highs: [0], Total time: 1325.8796949999996
[32m[0906 14-17-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-10 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-17-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01892, current rewards: 1.09171, mean: 0.10917
[32m[0906 14-17-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01928, current rewards: 6.65570, mean: 0.11093
[32m[0906 14-17-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 12.22184, mean: 0.11111
[32m[0906 14-17-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.78841, mean: 0.11118
[32m[0906 14-17-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01905, current rewards: 23.35095, mean: 0.11119
[32m[0906 14-17-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01894, current rewards: 28.91557, mean: 0.11121
[32m[0906 14-17-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01888, current rewards: 34.47265, mean: 0.11120
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01883, current rewards: 40.04979, mean: 0.11125
[32m[0906 14-17-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01878, current rewards: 45.62187, mean: 0.11127
[32m[0906 14-17-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01877, current rewards: 51.19200, mean: 0.11129
[32m[0906 14-17-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01879, current rewards: 56.75810, mean: 0.11129
[32m[0906 14-17-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01884, current rewards: 62.33085, mean: 0.11131
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01887, current rewards: 67.90488, mean: 0.11132
[32m[0906 14-17-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01889, current rewards: 73.47903, mean: 0.11133
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01892, current rewards: 79.05049, mean: 0.11134
[32m[0906 14-17-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01893, current rewards: 82.50531, mean: 0.10856
[32m[0906 14-17-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01895, current rewards: 88.01848, mean: 0.10866
[32m[0906 14-17-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01897, current rewards: 93.52938, mean: 0.10876
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01898, current rewards: 99.04663, mean: 0.10884
[32m[0906 14-17-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01900, current rewards: 104.56539, mean: 0.10892
[32m[0906 14-17-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01901, current rewards: 110.08204, mean: 0.10899
[32m[0906 14-17-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01902, current rewards: 115.59439, mean: 0.10905
[32m[0906 14-17-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01903, current rewards: 121.09541, mean: 0.10909
[32m[0906 14-17-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01904, current rewards: 126.72780, mean: 0.10925
[32m[0906 14-17-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01905, current rewards: 132.29696, mean: 0.10934
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 137.86244, mean: 0.10941
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01907, current rewards: 143.42898, mean: 0.10949
[32m[0906 14-17-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 148.99565, mean: 0.10956
[32m[0906 14-17-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 154.55509, mean: 0.10961
[32m[0906 14-17-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 160.12892, mean: 0.10968
[32m[0906 14-17-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 165.70702, mean: 0.10974
[32m[0906 14-17-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 171.16222, mean: 0.10972
[32m[0906 14-17-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: 176.68831, mean: 0.10974
[32m[0906 14-17-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: 182.25277, mean: 0.10979
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 187.81209, mean: 0.10983
[32m[0906 14-17-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01917, current rewards: 193.36324, mean: 0.10987
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 198.91735, mean: 0.10990
[32m[0906 14-17-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01920, current rewards: 204.47983, mean: 0.10994
[32m[0906 14-17-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 210.03920, mean: 0.10997
[32m[0906 14-17-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01922, current rewards: 215.59698, mean: 0.11000
[32m[0906 14-17-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01923, current rewards: 221.31562, mean: 0.11011
[32m[0906 14-17-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01924, current rewards: 226.88928, mean: 0.11014
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: 232.44976, mean: 0.11017
[32m[0906 14-17-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01927, current rewards: 238.03538, mean: 0.11020
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01927, current rewards: 243.61676, mean: 0.11023
[32m[0906 14-17-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 249.19763, mean: 0.11026
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01929, current rewards: 254.77336, mean: 0.11029
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01930, current rewards: 260.34845, mean: 0.11032
[32m[0906 14-17-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01931, current rewards: 265.84992, mean: 0.11031
[32m[0906 14-17-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01932, current rewards: 271.37873, mean: 0.11032
[32m[0906 14-17-59 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-17-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-17-59 @MBExp.py:227][0m Rewards obtained: [275.8164261883472], Lows: [1], Highs: [0], Total time: 1374.8741239999997
[32m[0906 14-19-03 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-03 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-19-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01912, current rewards: 1.13961, mean: 0.11396
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01933, current rewards: 7.20732, mean: 0.12012
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 13.26968, mean: 0.12063
[32m[0906 14-19-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 19.33116, mean: 0.12082
[32m[0906 14-19-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 25.39581, mean: 0.12093
[32m[0906 14-19-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01899, current rewards: 31.46145, mean: 0.12101
[32m[0906 14-19-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01894, current rewards: 37.52194, mean: 0.12104
[32m[0906 14-19-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01887, current rewards: 43.92204, mean: 0.12201
[32m[0906 14-19-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01885, current rewards: 50.38937, mean: 0.12290
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01889, current rewards: 56.85159, mean: 0.12359
[32m[0906 14-19-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01892, current rewards: 63.31729, mean: 0.12415
[32m[0906 14-19-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01896, current rewards: 67.97517, mean: 0.12138
[32m[0906 14-19-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01898, current rewards: 73.44912, mean: 0.12041
[32m[0906 14-19-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01900, current rewards: 78.92839, mean: 0.11959
[32m[0906 14-19-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01902, current rewards: 84.41033, mean: 0.11889
[32m[0906 14-19-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01903, current rewards: 89.88529, mean: 0.11827
[32m[0906 14-19-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01904, current rewards: 95.36040, mean: 0.11773
[32m[0906 14-19-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01905, current rewards: 100.84116, mean: 0.11726
[32m[0906 14-19-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01907, current rewards: 106.30884, mean: 0.11682
[32m[0906 14-19-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 111.98129, mean: 0.11665
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01906, current rewards: 117.65085, mean: 0.11649
[32m[0906 14-19-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 123.32096, mean: 0.11634
[32m[0906 14-19-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01906, current rewards: 128.99425, mean: 0.11621
[32m[0906 14-19-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 134.84041, mean: 0.11624
[32m[0906 14-19-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 140.66128, mean: 0.11625
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01908, current rewards: 146.48485, mean: 0.11626
[32m[0906 14-19-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01908, current rewards: 152.30770, mean: 0.11627
[32m[0906 14-19-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: 158.13042, mean: 0.11627
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01910, current rewards: 163.95207, mean: 0.11628
[32m[0906 14-19-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 169.77303, mean: 0.11628
[32m[0906 14-19-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 175.48892, mean: 0.11622
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 181.13975, mean: 0.11612
[32m[0906 14-19-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 186.77134, mean: 0.11601
[32m[0906 14-19-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 192.39734, mean: 0.11590
[32m[0906 14-19-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01916, current rewards: 198.02017, mean: 0.11580
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 203.97488, mean: 0.11589
[32m[0906 14-19-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01919, current rewards: 209.96275, mean: 0.11600
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01921, current rewards: 215.96136, mean: 0.11611
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: 221.95260, mean: 0.11621
[32m[0906 14-19-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01922, current rewards: 227.94578, mean: 0.11630
[32m[0906 14-19-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01923, current rewards: 233.93200, mean: 0.11638
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01924, current rewards: 239.92679, mean: 0.11647
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: 245.90582, mean: 0.11654
[32m[0906 14-19-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01926, current rewards: 251.94375, mean: 0.11664
[32m[0906 14-19-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01927, current rewards: 258.00054, mean: 0.11674
[32m[0906 14-19-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 264.05597, mean: 0.11684
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: 270.11161, mean: 0.11693
[32m[0906 14-19-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01929, current rewards: 276.04531, mean: 0.11697
[32m[0906 14-19-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01930, current rewards: 281.88602, mean: 0.11697
[32m[0906 14-19-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01931, current rewards: 287.73124, mean: 0.11696
[32m[0906 14-19-52 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-19-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-19-52 @MBExp.py:227][0m Rewards obtained: [292.405865775534], Lows: [0], Highs: [1], Total time: 1423.8445909999998
[32m[0906 14-20-59 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-59 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01927, current rewards: -0.90397, mean: -0.09040
[32m[0906 14-21-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 4.59771, mean: 0.07663
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 10.15393, mean: 0.09231
[32m[0906 14-21-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01903, current rewards: 15.70629, mean: 0.09816
[32m[0906 14-21-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01890, current rewards: 21.26393, mean: 0.10126
[32m[0906 14-21-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01883, current rewards: 26.81696, mean: 0.10314
[32m[0906 14-21-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01885, current rewards: 32.31569, mean: 0.10424
[32m[0906 14-21-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01888, current rewards: 37.86660, mean: 0.10519
[32m[0906 14-21-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01891, current rewards: 43.42065, mean: 0.10590
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01895, current rewards: 48.96363, mean: 0.10644
[32m[0906 14-21-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01898, current rewards: 54.51157, mean: 0.10689
[32m[0906 14-21-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01900, current rewards: 60.06940, mean: 0.10727
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01901, current rewards: 65.51612, mean: 0.10740
[32m[0906 14-21-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01903, current rewards: 70.97361, mean: 0.10754
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01904, current rewards: 76.45925, mean: 0.10769
[32m[0906 14-21-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01905, current rewards: 81.94781, mean: 0.10783
[32m[0906 14-21-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01905, current rewards: 87.42229, mean: 0.10793
[32m[0906 14-21-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: 92.90063, mean: 0.10802
[32m[0906 14-21-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01907, current rewards: 98.38849, mean: 0.10812
[32m[0906 14-21-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 103.87584, mean: 0.10820
[32m[0906 14-21-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: 109.35951, mean: 0.10828
[32m[0906 14-21-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 114.84438, mean: 0.10834
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 120.34060, mean: 0.10841
[32m[0906 14-21-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 125.93533, mean: 0.10856
[32m[0906 14-21-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: 130.29193, mean: 0.10768
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 137.05597, mean: 0.10877
[32m[0906 14-21-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 143.82001, mean: 0.10979
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 150.58405, mean: 0.11072
[32m[0906 14-21-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 157.34808, mean: 0.11159
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 164.11212, mean: 0.11241
[32m[0906 14-21-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 170.87616, mean: 0.11316
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01913, current rewards: 176.76984, mean: 0.11331
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01915, current rewards: 182.01452, mean: 0.11305
[32m[0906 14-21-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: 134.22431, mean: 0.08086
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01917, current rewards: 84.22431, mean: 0.04925
[32m[0906 14-21-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 34.22431, mean: 0.01945
[32m[0906 14-21-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01919, current rewards: -15.77569, mean: -0.00872
[32m[0906 14-21-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01921, current rewards: -65.77569, mean: -0.03536
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01922, current rewards: -115.77569, mean: -0.06062
[32m[0906 14-21-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01923, current rewards: -165.77569, mean: -0.08458
[32m[0906 14-21-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01923, current rewards: -215.77569, mean: -0.10735
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01924, current rewards: -265.77569, mean: -0.12902
[32m[0906 14-21-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: -315.77569, mean: -0.14966
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01927, current rewards: -365.77569, mean: -0.16934
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: -415.77569, mean: -0.18813
[32m[0906 14-21-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01929, current rewards: -465.77569, mean: -0.20610
[32m[0906 14-21-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01930, current rewards: -515.77569, mean: -0.22328
[32m[0906 14-21-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01930, current rewards: -565.77569, mean: -0.23974
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01931, current rewards: -615.77569, mean: -0.25551
[32m[0906 14-21-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01931, current rewards: -665.77569, mean: -0.27064
[32m[0906 14-21-48 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-21-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-21-48 @MBExp.py:227][0m Rewards obtained: [-705.775688868925], Lows: [2], Highs: [888], Total time: 1472.8269689999997
[32m[0906 14-22-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-22-56 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-22-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: 1.04620, mean: 0.10462
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 6.58901, mean: 0.10982
[32m[0906 14-22-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 12.13039, mean: 0.11028
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01898, current rewards: 17.67178, mean: 0.11045
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01888, current rewards: 23.20715, mean: 0.11051
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01891, current rewards: 28.75433, mean: 0.11059
[32m[0906 14-23-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01897, current rewards: 34.29625, mean: 0.11063
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01900, current rewards: 39.82977, mean: 0.11064
[32m[0906 14-23-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01900, current rewards: 45.36022, mean: 0.11063
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01903, current rewards: 50.88231, mean: 0.11061
[32m[0906 14-23-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01904, current rewards: 56.41910, mean: 0.11063
[32m[0906 14-23-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 61.95854, mean: 0.11064
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01906, current rewards: 67.48830, mean: 0.11064
[32m[0906 14-23-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01906, current rewards: 73.04419, mean: 0.11067
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 78.58429, mean: 0.11068
[32m[0906 14-23-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01907, current rewards: 82.04655, mean: 0.10796
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01908, current rewards: 87.62104, mean: 0.10817
[32m[0906 14-23-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01908, current rewards: 93.19218, mean: 0.10836
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01909, current rewards: 98.76272, mean: 0.10853
[32m[0906 14-23-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01910, current rewards: 104.33620, mean: 0.10868
[32m[0906 14-23-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 109.84069, mean: 0.10875
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 115.37411, mean: 0.10884
[32m[0906 14-23-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 120.90613, mean: 0.10892
[32m[0906 14-23-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 126.43637, mean: 0.10900
[32m[0906 14-23-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 131.96987, mean: 0.10907
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 137.50461, mean: 0.10913
[32m[0906 14-23-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 143.04156, mean: 0.10919
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 148.57326, mean: 0.10925
[32m[0906 14-23-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 154.07975, mean: 0.10928
[32m[0906 14-23-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01915, current rewards: 159.66218, mean: 0.10936
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: 165.21622, mean: 0.10941
[32m[0906 14-23-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01915, current rewards: 170.75420, mean: 0.10946
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01916, current rewards: 176.39688, mean: 0.10956
[32m[0906 14-23-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 181.95330, mean: 0.10961
[32m[0906 14-23-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01919, current rewards: 187.51573, mean: 0.10966
[32m[0906 14-23-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01921, current rewards: 193.07555, mean: 0.10970
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01922, current rewards: 198.63905, mean: 0.10975
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01923, current rewards: 204.19635, mean: 0.10978
[32m[0906 14-23-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01924, current rewards: 209.65093, mean: 0.10976
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01925, current rewards: 215.21677, mean: 0.10980
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01926, current rewards: 220.75364, mean: 0.10983
[32m[0906 14-23-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01927, current rewards: 226.29551, mean: 0.10985
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01928, current rewards: 231.84063, mean: 0.10988
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01928, current rewards: 237.38144, mean: 0.10990
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01929, current rewards: 242.91389, mean: 0.10992
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01930, current rewards: 248.45459, mean: 0.10994
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01931, current rewards: 253.91317, mean: 0.10992
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01932, current rewards: 259.45669, mean: 0.10994
[32m[0906 14-23-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01932, current rewards: 264.99984, mean: 0.10996
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01933, current rewards: 270.51470, mean: 0.10997
[32m[0906 14-23-45 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-23-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-23-46 @MBExp.py:227][0m Rewards obtained: [274.92568946586294], Lows: [1], Highs: [0], Total time: 1521.8591509999997
[32m[0906 14-24-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-56 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01909, current rewards: 1.09530, mean: 0.10953
[32m[0906 14-24-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01917, current rewards: 6.61885, mean: 0.11031
[32m[0906 14-24-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 12.15383, mean: 0.11049
[32m[0906 14-24-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01913, current rewards: 17.69498, mean: 0.11059
[32m[0906 14-25-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 23.22767, mean: 0.11061
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 28.78217, mean: 0.11070
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.32142, mean: 0.11071
[32m[0906 14-25-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 39.86015, mean: 0.11072
[32m[0906 14-25-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.39774, mean: 0.11073
[32m[0906 14-25-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.93505, mean: 0.11073
[32m[0906 14-25-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.46311, mean: 0.11071
[32m[0906 14-25-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 62.01889, mean: 0.11075
[32m[0906 14-25-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.55398, mean: 0.11074
[32m[0906 14-25-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.12518, mean: 0.11080
[32m[0906 14-25-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 78.66657, mean: 0.11080
[32m[0906 14-25-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01922, current rewards: 84.20438, mean: 0.11080
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 89.74516, mean: 0.11080
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 95.28854, mean: 0.11080
[32m[0906 14-25-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.83160, mean: 0.11080
[32m[0906 14-25-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 106.34112, mean: 0.11077
[32m[0906 14-25-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 111.92617, mean: 0.11082
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01922, current rewards: 117.49335, mean: 0.11084
[32m[0906 14-25-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01923, current rewards: 123.07097, mean: 0.11087
[32m[0906 14-25-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01923, current rewards: 128.65212, mean: 0.11091
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 134.23298, mean: 0.11094
[32m[0906 14-25-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01923, current rewards: 139.81290, mean: 0.11096
[32m[0906 14-25-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01923, current rewards: 145.39040, mean: 0.11099
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01923, current rewards: 150.96557, mean: 0.11100
[32m[0906 14-25-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01923, current rewards: 156.49026, mean: 0.11099
[32m[0906 14-25-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 162.15579, mean: 0.11107
[32m[0906 14-25-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01924, current rewards: 167.73692, mean: 0.11108
[32m[0906 14-25-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01925, current rewards: 173.31643, mean: 0.11110
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01926, current rewards: 178.89748, mean: 0.11112
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01928, current rewards: 184.47816, mean: 0.11113
[32m[0906 14-25-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01928, current rewards: 190.06123, mean: 0.11115
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01930, current rewards: 195.64239, mean: 0.11116
[32m[0906 14-25-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: 201.22550, mean: 0.11117
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01931, current rewards: 206.74516, mean: 0.11115
[32m[0906 14-25-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01932, current rewards: 212.22100, mean: 0.11111
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01933, current rewards: 217.74783, mean: 0.11110
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01934, current rewards: 223.27516, mean: 0.11108
[32m[0906 14-25-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01935, current rewards: 228.79744, mean: 0.11107
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01936, current rewards: 234.31922, mean: 0.11105
[32m[0906 14-25-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01937, current rewards: 239.84582, mean: 0.11104
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01937, current rewards: 245.36978, mean: 0.11103
[32m[0906 14-25-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01938, current rewards: 250.89193, mean: 0.11101
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01939, current rewards: 256.43824, mean: 0.11101
[32m[0906 14-25-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01939, current rewards: 261.97306, mean: 0.11101
[32m[0906 14-25-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01940, current rewards: 267.50157, mean: 0.11100
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01940, current rewards: 273.03502, mean: 0.11099
[32m[0906 14-25-45 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-25-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-25-45 @MBExp.py:227][0m Rewards obtained: [277.4630280697987], Lows: [0], Highs: [0], Total time: 1571.0729939999997
[32m[0906 14-26-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-58 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02062, current rewards: 0.05261, mean: 0.00526
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01976, current rewards: 5.61713, mean: 0.09362
[32m[0906 14-27-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01948, current rewards: 11.16616, mean: 0.10151
[32m[0906 14-27-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01940, current rewards: 16.71444, mean: 0.10447
[32m[0906 14-27-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01935, current rewards: 22.43519, mean: 0.10683
[32m[0906 14-27-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01929, current rewards: 29.04343, mean: 0.11171
[32m[0906 14-27-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01928, current rewards: 35.65166, mean: 0.11501
[32m[0906 14-27-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01926, current rewards: 42.25989, mean: 0.11739
[32m[0906 14-27-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01925, current rewards: 48.86812, mean: 0.11919
[32m[0906 14-27-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 48.68337, mean: 0.10583
[32m[0906 14-27-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: -1.31663, mean: -0.00258
[32m[0906 14-27-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: -51.31663, mean: -0.09164
[32m[0906 14-27-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: -101.31663, mean: -0.16609
[32m[0906 14-27-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: -151.31663, mean: -0.22927
[32m[0906 14-27-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: -201.31663, mean: -0.28354
[32m[0906 14-27-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: -251.31663, mean: -0.33068
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: -301.31663, mean: -0.37200
[32m[0906 14-27-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: -351.31663, mean: -0.40851
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: -401.31663, mean: -0.44101
[32m[0906 14-27-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: -451.31663, mean: -0.47012
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: -501.31663, mean: -0.49635
[32m[0906 14-27-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: -551.31663, mean: -0.52011
[32m[0906 14-27-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: -601.31663, mean: -0.54173
[32m[0906 14-27-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: -651.31663, mean: -0.56148
[32m[0906 14-27-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: -701.31663, mean: -0.57960
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01921, current rewards: -751.31663, mean: -0.59628
[32m[0906 14-27-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: -801.31663, mean: -0.61169
[32m[0906 14-27-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: -851.31663, mean: -0.62597
[32m[0906 14-27-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: -901.31663, mean: -0.63923
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: -951.31663, mean: -0.65159
[32m[0906 14-27-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: -1001.31663, mean: -0.66312
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01920, current rewards: -1051.31663, mean: -0.67392
[32m[0906 14-27-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01922, current rewards: -1101.31663, mean: -0.68405
[32m[0906 14-27-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01923, current rewards: -1151.31663, mean: -0.69356
[32m[0906 14-27-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01924, current rewards: -1201.31663, mean: -0.70252
[32m[0906 14-27-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01925, current rewards: -1251.31663, mean: -0.71098
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01926, current rewards: -1301.31663, mean: -0.71896
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01927, current rewards: -1351.31663, mean: -0.72651
[32m[0906 14-27-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01928, current rewards: -1401.31663, mean: -0.73367
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01929, current rewards: -1451.31663, mean: -0.74047
[32m[0906 14-27-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01930, current rewards: -1501.31663, mean: -0.74692
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01930, current rewards: -1551.31663, mean: -0.75307
[32m[0906 14-27-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01931, current rewards: -1601.31663, mean: -0.75892
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01932, current rewards: -1651.31663, mean: -0.76450
[32m[0906 14-27-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01932, current rewards: -1701.31663, mean: -0.76983
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01933, current rewards: -1751.31663, mean: -0.77492
[32m[0906 14-27-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01934, current rewards: -1801.31663, mean: -0.77979
[32m[0906 14-27-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01934, current rewards: -1851.31663, mean: -0.78446
[32m[0906 14-27-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01935, current rewards: -1901.31663, mean: -0.78893
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01936, current rewards: -1951.31663, mean: -0.79322
[32m[0906 14-27-47 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-27-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-27-47 @MBExp.py:227][0m Rewards obtained: [-1991.3166307488232], Lows: [0], Highs: [2047], Total time: 1620.1792179999998
[32m[0906 14-29-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-02 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01993, current rewards: 1.16582, mean: 0.11658
[32m[0906 14-29-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01943, current rewards: 6.70979, mean: 0.11183
[32m[0906 14-29-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01933, current rewards: 12.24627, mean: 0.11133
[32m[0906 14-29-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01939, current rewards: 17.78249, mean: 0.11114
[32m[0906 14-29-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01936, current rewards: 23.30544, mean: 0.11098
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01934, current rewards: 28.83091, mean: 0.11089
[32m[0906 14-29-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01932, current rewards: 34.36883, mean: 0.11087
[32m[0906 14-29-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01929, current rewards: 39.90255, mean: 0.11084
[32m[0906 14-29-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01929, current rewards: 45.43682, mean: 0.11082
[32m[0906 14-29-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 50.97054, mean: 0.11081
[32m[0906 14-29-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01927, current rewards: 56.50932, mean: 0.11080
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01925, current rewards: 62.14834, mean: 0.11098
[32m[0906 14-29-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 67.69728, mean: 0.11098
[32m[0906 14-29-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01926, current rewards: 73.24616, mean: 0.11098
[32m[0906 14-29-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01925, current rewards: 78.79569, mean: 0.11098
[32m[0906 14-29-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01924, current rewards: 84.34525, mean: 0.11098
[32m[0906 14-29-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01924, current rewards: 89.89409, mean: 0.11098
[32m[0906 14-29-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01924, current rewards: 95.44421, mean: 0.11098
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01925, current rewards: 100.99255, mean: 0.11098
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01924, current rewards: 105.36340, mean: 0.10975
[32m[0906 14-29-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01925, current rewards: 110.82879, mean: 0.10973
[32m[0906 14-29-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01925, current rewards: 116.35174, mean: 0.10977
[32m[0906 14-29-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01924, current rewards: 121.87280, mean: 0.10980
[32m[0906 14-29-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01924, current rewards: 127.38890, mean: 0.10982
[32m[0906 14-29-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01924, current rewards: 132.90298, mean: 0.10984
[32m[0906 14-29-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01924, current rewards: 138.42070, mean: 0.10986
[32m[0906 14-29-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01924, current rewards: 143.94404, mean: 0.10988
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01924, current rewards: 149.46884, mean: 0.10990
[32m[0906 14-29-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01924, current rewards: 155.05030, mean: 0.10996
[32m[0906 14-29-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 160.62972, mean: 0.11002
[32m[0906 14-29-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01924, current rewards: 166.20638, mean: 0.11007
[32m[0906 14-29-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01925, current rewards: 171.75305, mean: 0.11010
[32m[0906 14-29-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01926, current rewards: 177.29717, mean: 0.11012
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01927, current rewards: 182.84149, mean: 0.11015
[32m[0906 14-29-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01928, current rewards: 188.38433, mean: 0.11017
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01929, current rewards: 193.93065, mean: 0.11019
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01930, current rewards: 199.46494, mean: 0.11020
[32m[0906 14-29-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01931, current rewards: 204.92972, mean: 0.11018
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01932, current rewards: 210.43068, mean: 0.11017
[32m[0906 14-29-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01933, current rewards: 215.93655, mean: 0.11017
[32m[0906 14-29-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01934, current rewards: 221.43829, mean: 0.11017
[32m[0906 14-29-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01935, current rewards: 226.94027, mean: 0.11017
[32m[0906 14-29-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01935, current rewards: 232.44751, mean: 0.11016
[32m[0906 14-29-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01936, current rewards: 237.95322, mean: 0.11016
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01937, current rewards: 243.45522, mean: 0.11016
[32m[0906 14-29-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01938, current rewards: 248.93238, mean: 0.11015
[32m[0906 14-29-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01938, current rewards: 254.45036, mean: 0.11015
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01939, current rewards: 259.98605, mean: 0.11016
[32m[0906 14-29-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01939, current rewards: 265.51970, mean: 0.11017
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01939, current rewards: 271.06133, mean: 0.11019
[32m[0906 14-29-51 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-29-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-29-51 @MBExp.py:227][0m Rewards obtained: [275.4875576519067], Lows: [0], Highs: [1], Total time: 1669.3580839999997
[32m[0906 14-31-09 @MBExp.py:144][0m ####################################################################
[32m[0906 14-31-09 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01954, current rewards: 1.09417, mean: 0.10942
[32m[0906 14-31-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.62605, mean: 0.11043
[32m[0906 14-31-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.15053, mean: 0.11046
[32m[0906 14-31-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01913, current rewards: 17.67433, mean: 0.11046
[32m[0906 14-31-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.19807, mean: 0.11047
[32m[0906 14-31-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 28.71253, mean: 0.11043
[32m[0906 14-31-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 34.23292, mean: 0.11043
[32m[0906 14-31-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 39.75647, mean: 0.11043
[32m[0906 14-31-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 45.27353, mean: 0.11042
[32m[0906 14-31-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.79114, mean: 0.11042
[32m[0906 14-31-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.31026, mean: 0.11041
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 61.88301, mean: 0.11051
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 67.31313, mean: 0.11035
[32m[0906 14-31-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 72.82434, mean: 0.11034
[32m[0906 14-31-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 78.33486, mean: 0.11033
[32m[0906 14-31-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 83.84264, mean: 0.11032
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 89.35668, mean: 0.11032
[32m[0906 14-31-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 94.86010, mean: 0.11030
[32m[0906 14-31-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 100.37023, mean: 0.11030
[32m[0906 14-31-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 105.88219, mean: 0.11029
[32m[0906 14-31-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 111.54575, mean: 0.11044
[32m[0906 14-31-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 117.04649, mean: 0.11042
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 122.54601, mean: 0.11040
[32m[0906 14-31-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 128.04008, mean: 0.11038
[32m[0906 14-31-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 133.52882, mean: 0.11035
[32m[0906 14-31-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: 139.03513, mean: 0.11035
[32m[0906 14-31-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: 144.53623, mean: 0.11033
[32m[0906 14-31-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01917, current rewards: 150.03742, mean: 0.11032
[32m[0906 14-31-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 155.53178, mean: 0.11031
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01917, current rewards: 161.04736, mean: 0.11031
[32m[0906 14-31-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 166.56033, mean: 0.11030
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 172.07415, mean: 0.11030
[32m[0906 14-31-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01920, current rewards: 177.58761, mean: 0.11030
[32m[0906 14-31-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01921, current rewards: 183.10211, mean: 0.11030
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01922, current rewards: 188.61204, mean: 0.11030
[32m[0906 14-31-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01923, current rewards: 194.12451, mean: 0.11030
[32m[0906 14-31-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01924, current rewards: 199.74078, mean: 0.11035
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01925, current rewards: 205.28312, mean: 0.11037
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01927, current rewards: 210.81857, mean: 0.11038
[32m[0906 14-31-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01928, current rewards: 216.34842, mean: 0.11038
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 221.88364, mean: 0.11039
[32m[0906 14-31-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01929, current rewards: 227.41370, mean: 0.11040
[32m[0906 14-31-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01930, current rewards: 232.94843, mean: 0.11040
[32m[0906 14-31-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01931, current rewards: 240.40621, mean: 0.11130
[32m[0906 14-31-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01931, current rewards: 249.45964, mean: 0.11288
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01932, current rewards: 253.96625, mean: 0.11237
[32m[0906 14-31-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01932, current rewards: 257.76549, mean: 0.11159
[32m[0906 14-31-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01931, current rewards: 261.56474, mean: 0.11083
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01931, current rewards: 226.62853, mean: 0.09404
[32m[0906 14-31-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01931, current rewards: 176.62853, mean: 0.07180
[32m[0906 14-31-58 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-31-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-31-58 @MBExp.py:227][0m Rewards obtained: [136.62853445584608], Lows: [0], Highs: [126], Total time: 1718.3152089999996
[32m[0906 14-33-17 @MBExp.py:144][0m ####################################################################
[32m[0906 14-33-17 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-33-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01902, current rewards: 1.07124, mean: 0.10712
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 6.62733, mean: 0.11046
[32m[0906 14-33-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.19483, mean: 0.11086
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01913, current rewards: 17.74430, mean: 0.11090
[32m[0906 14-33-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 23.31220, mean: 0.11101
[32m[0906 14-33-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 28.88054, mean: 0.11108
[32m[0906 14-33-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.44525, mean: 0.11111
[32m[0906 14-33-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 40.00845, mean: 0.11113
[32m[0906 14-33-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.57426, mean: 0.11116
[32m[0906 14-33-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.13678, mean: 0.11117
[32m[0906 14-33-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.70326, mean: 0.11118
[32m[0906 14-33-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 62.36661, mean: 0.11137
[32m[0906 14-33-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 67.94468, mean: 0.11138
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 73.51198, mean: 0.11138
[32m[0906 14-33-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 79.08044, mean: 0.11138
[32m[0906 14-33-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 84.74004, mean: 0.11150
[32m[0906 14-33-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 90.28300, mean: 0.11146
[32m[0906 14-33-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 95.82725, mean: 0.11143
[32m[0906 14-33-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 101.36875, mean: 0.11139
[32m[0906 14-33-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 106.88905, mean: 0.11134
[32m[0906 14-33-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 112.36342, mean: 0.11125
[32m[0906 14-33-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 117.89112, mean: 0.11122
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 123.34072, mean: 0.11112
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 128.79851, mean: 0.11103
[32m[0906 14-33-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 134.25691, mean: 0.11096
[32m[0906 14-33-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: 139.71774, mean: 0.11089
[32m[0906 14-33-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 145.17351, mean: 0.11082
[32m[0906 14-33-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 150.62585, mean: 0.11075
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 156.08139, mean: 0.11070
[32m[0906 14-33-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01920, current rewards: 161.53264, mean: 0.11064
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01920, current rewards: 166.98054, mean: 0.11058
[32m[0906 14-33-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01922, current rewards: 172.44109, mean: 0.11054
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01924, current rewards: 177.90175, mean: 0.11050
[32m[0906 14-33-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01925, current rewards: 183.35024, mean: 0.11045
[32m[0906 14-33-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01926, current rewards: 188.80715, mean: 0.11041
[32m[0906 14-33-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01927, current rewards: 194.25987, mean: 0.11037
[32m[0906 14-33-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01927, current rewards: 199.70433, mean: 0.11033
[32m[0906 14-33-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01928, current rewards: 205.14754, mean: 0.11029
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01928, current rewards: 210.70392, mean: 0.11032
[32m[0906 14-33-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01929, current rewards: 216.26049, mean: 0.11034
[32m[0906 14-33-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01930, current rewards: 221.82588, mean: 0.11036
[32m[0906 14-33-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01931, current rewards: 227.38395, mean: 0.11038
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01932, current rewards: 232.94094, mean: 0.11040
[32m[0906 14-33-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01933, current rewards: 238.49978, mean: 0.11042
[32m[0906 14-34-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01933, current rewards: 244.17091, mean: 0.11048
[32m[0906 14-34-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01933, current rewards: 249.76378, mean: 0.11051
[32m[0906 14-34-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01933, current rewards: 255.36120, mean: 0.11055
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01932, current rewards: 260.95323, mean: 0.11057
[32m[0906 14-34-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01932, current rewards: 266.70589, mean: 0.11067
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01932, current rewards: 272.44082, mean: 0.11075
[32m[0906 14-34-06 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-34-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-34-06 @MBExp.py:227][0m Rewards obtained: [277.0259939875646], Lows: [0], Highs: [0], Total time: 1767.3002099999997
[32m[0906 14-35-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-27 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01895, current rewards: 1.01273, mean: 0.10127
[32m[0906 14-35-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.52582, mean: 0.10876
[32m[0906 14-35-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.04021, mean: 0.10946
[32m[0906 14-35-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 17.55839, mean: 0.10974
[32m[0906 14-35-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.07224, mean: 0.10987
[32m[0906 14-35-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 28.58737, mean: 0.10995
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.10053, mean: 0.11000
[32m[0906 14-35-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 39.61608, mean: 0.11004
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: 45.12576, mean: 0.11006
[32m[0906 14-35-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.64558, mean: 0.11010
[32m[0906 14-35-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 56.19098, mean: 0.11018
[32m[0906 14-35-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 61.84648, mean: 0.11044
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 67.40784, mean: 0.11050
[32m[0906 14-35-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 73.46267, mean: 0.11131
[32m[0906 14-35-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 79.77810, mean: 0.11236
[32m[0906 14-35-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 86.09352, mean: 0.11328
[32m[0906 14-35-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 92.40895, mean: 0.11409
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 84.72272, mean: 0.09851
[32m[0906 14-35-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 90.29037, mean: 0.09922
[32m[0906 14-35-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 95.73514, mean: 0.09972
[32m[0906 14-35-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 101.25567, mean: 0.10025
[32m[0906 14-35-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 106.79165, mean: 0.10075
[32m[0906 14-35-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 112.29875, mean: 0.10117
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 117.80875, mean: 0.10156
[32m[0906 14-35-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 123.31778, mean: 0.10192
[32m[0906 14-35-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 128.83269, mean: 0.10225
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 134.33540, mean: 0.10255
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 139.84658, mean: 0.10283
[32m[0906 14-35-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01914, current rewards: 145.46270, mean: 0.10317
[32m[0906 14-35-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01914, current rewards: 151.03551, mean: 0.10345
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 156.61263, mean: 0.10372
[32m[0906 14-35-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 162.18361, mean: 0.10396
[32m[0906 14-35-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 167.76229, mean: 0.10420
[32m[0906 14-35-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01919, current rewards: 173.31704, mean: 0.10441
[32m[0906 14-36-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01920, current rewards: 178.87307, mean: 0.10460
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01922, current rewards: 184.43314, mean: 0.10479
[32m[0906 14-36-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01923, current rewards: 189.99069, mean: 0.10497
[32m[0906 14-36-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01924, current rewards: 195.54561, mean: 0.10513
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01925, current rewards: 201.10276, mean: 0.10529
[32m[0906 14-36-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01926, current rewards: 206.65801, mean: 0.10544
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01927, current rewards: 212.21361, mean: 0.10558
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01928, current rewards: 217.77535, mean: 0.10572
[32m[0906 14-36-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01929, current rewards: 223.33515, mean: 0.10585
[32m[0906 14-36-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01928, current rewards: 228.89854, mean: 0.10597
[32m[0906 14-36-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: 234.48283, mean: 0.10610
[32m[0906 14-36-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 240.04594, mean: 0.10622
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: 245.61040, mean: 0.10632
[32m[0906 14-36-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01928, current rewards: 252.08844, mean: 0.10682
[32m[0906 14-36-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01928, current rewards: 258.40387, mean: 0.10722
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: 264.71929, mean: 0.10761
[32m[0906 14-36-16 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-36-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-36-16 @MBExp.py:227][0m Rewards obtained: [269.7716328540052], Lows: [0], Highs: [12], Total time: 1816.1795039999997
[32m[0906 14-37-40 @MBExp.py:144][0m ####################################################################
[32m[0906 14-37-40 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-37-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01954, current rewards: -0.99159, mean: -0.09916
[32m[0906 14-37-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 4.50498, mean: 0.07508
[32m[0906 14-37-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 9.92400, mean: 0.09022
[32m[0906 14-37-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 15.31064, mean: 0.09569
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01925, current rewards: 20.78060, mean: 0.09896
[32m[0906 14-37-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 26.31390, mean: 0.10121
[32m[0906 14-37-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01926, current rewards: 31.96573, mean: 0.10312
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01925, current rewards: 37.61484, mean: 0.10449
[32m[0906 14-37-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 43.26577, mean: 0.10553
[32m[0906 14-37-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 48.91655, mean: 0.10634
[32m[0906 14-37-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 54.56748, mean: 0.10700
[32m[0906 14-37-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 60.34715, mean: 0.10776
[32m[0906 14-37-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 66.66257, mean: 0.10928
[32m[0906 14-37-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 36.93613, mean: 0.05596
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: -13.06387, mean: -0.01840
[32m[0906 14-37-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: -63.06387, mean: -0.08298
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: -113.06387, mean: -0.13959
[32m[0906 14-37-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: -163.06387, mean: -0.18961
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: -213.06387, mean: -0.23414
[32m[0906 14-37-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: -263.06387, mean: -0.27402
[32m[0906 14-37-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: -313.06387, mean: -0.30996
[32m[0906 14-38-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: -363.06387, mean: -0.34251
[32m[0906 14-38-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: -413.06387, mean: -0.37213
[32m[0906 14-38-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: -463.06387, mean: -0.39919
[32m[0906 14-38-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01917, current rewards: -513.06387, mean: -0.42402
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: -563.06387, mean: -0.44688
[32m[0906 14-38-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: -613.06387, mean: -0.46799
[32m[0906 14-38-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: -663.06387, mean: -0.48755
[32m[0906 14-38-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: -713.06387, mean: -0.50572
[32m[0906 14-38-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: -763.06387, mean: -0.52265
[32m[0906 14-38-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01920, current rewards: -813.06387, mean: -0.53845
[32m[0906 14-38-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01921, current rewards: -863.06387, mean: -0.55325
[32m[0906 14-38-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01922, current rewards: -913.06387, mean: -0.56712
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01924, current rewards: -963.06387, mean: -0.58016
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01925, current rewards: -1013.06387, mean: -0.59244
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01926, current rewards: -1063.06387, mean: -0.60401
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01927, current rewards: -1113.06387, mean: -0.61495
[32m[0906 14-38-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01927, current rewards: -1163.06387, mean: -0.62530
[32m[0906 14-38-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01928, current rewards: -1213.06387, mean: -0.63511
[32m[0906 14-38-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01929, current rewards: -1263.06387, mean: -0.64442
[32m[0906 14-38-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01929, current rewards: -1313.06387, mean: -0.65327
[32m[0906 14-38-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01929, current rewards: -1363.06387, mean: -0.66168
[32m[0906 14-38-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01928, current rewards: -1413.06387, mean: -0.66970
[32m[0906 14-38-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01928, current rewards: -1463.06387, mean: -0.67734
[32m[0906 14-38-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: -1513.06387, mean: -0.68464
[32m[0906 14-38-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: -1563.06387, mean: -0.69162
[32m[0906 14-38-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01928, current rewards: -1610.79331, mean: -0.69731
[32m[0906 14-38-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01927, current rewards: -1604.02927, mean: -0.67967
[32m[0906 14-38-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01928, current rewards: -1597.26524, mean: -0.66277
[32m[0906 14-38-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01927, current rewards: -1590.50120, mean: -0.64655
[32m[0906 14-38-28 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-38-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-38-29 @MBExp.py:227][0m Rewards obtained: [-1585.0899675628207], Lows: [1], Highs: [1680], Total time: 1865.0607499999996
[32m[0906 14-39-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-54 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 14-39-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01895, current rewards: 1.22028, mean: 0.12203
[32m[0906 14-39-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.83854, mean: 0.11398
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 12.53504, mean: 0.11395
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 18.29324, mean: 0.11433
[32m[0906 14-39-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 24.04804, mean: 0.11451
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 29.76779, mean: 0.11449
[32m[0906 14-40-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 35.48845, mean: 0.11448
[32m[0906 14-40-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 40.10799, mean: 0.11141
[32m[0906 14-40-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.66765, mean: 0.11138
[32m[0906 14-40-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.22858, mean: 0.11137
[32m[0906 14-40-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 56.78391, mean: 0.11134
[32m[0906 14-40-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.34476, mean: 0.11133
[32m[0906 14-40-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 67.86849, mean: 0.11126
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 73.41907, mean: 0.11124
[32m[0906 14-40-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.97053, mean: 0.11123
[32m[0906 14-40-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 84.52349, mean: 0.11122
[32m[0906 14-40-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 90.07478, mean: 0.11120
[32m[0906 14-40-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 95.63024, mean: 0.11120
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01919, current rewards: 101.18186, mean: 0.11119
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01920, current rewards: 106.72857, mean: 0.11118
[32m[0906 14-40-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: 112.30817, mean: 0.11120
[32m[0906 14-40-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 117.84967, mean: 0.11118
[32m[0906 14-40-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 123.38920, mean: 0.11116
[32m[0906 14-40-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01921, current rewards: 128.93228, mean: 0.11115
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01921, current rewards: 134.47480, mean: 0.11114
[32m[0906 14-40-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01921, current rewards: 140.01709, mean: 0.11112
[32m[0906 14-40-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 145.55868, mean: 0.11111
[32m[0906 14-40-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01921, current rewards: 151.10407, mean: 0.11111
[32m[0906 14-40-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01921, current rewards: 156.66364, mean: 0.11111
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01921, current rewards: 162.21029, mean: 0.11110
[32m[0906 14-40-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01922, current rewards: 167.76787, mean: 0.11110
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01924, current rewards: 173.31691, mean: 0.11110
[32m[0906 14-40-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01926, current rewards: 178.86940, mean: 0.11110
[32m[0906 14-40-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01928, current rewards: 184.41512, mean: 0.11109
[32m[0906 14-40-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01929, current rewards: 189.96483, mean: 0.11109
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01930, current rewards: 195.51603, mean: 0.11109
[32m[0906 14-40-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01931, current rewards: 200.99801, mean: 0.11105
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01933, current rewards: 206.52822, mean: 0.11104
[32m[0906 14-40-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01933, current rewards: 212.05674, mean: 0.11102
[32m[0906 14-40-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01932, current rewards: 217.60372, mean: 0.11102
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01932, current rewards: 223.14645, mean: 0.11102
[32m[0906 14-40-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01931, current rewards: 228.69477, mean: 0.11102
[32m[0906 14-40-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01931, current rewards: 234.23558, mean: 0.11101
[32m[0906 14-40-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01930, current rewards: 239.78177, mean: 0.11101
[32m[0906 14-40-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01930, current rewards: 245.33232, mean: 0.11101
[32m[0906 14-40-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01929, current rewards: 250.96248, mean: 0.11105
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01929, current rewards: 256.51968, mean: 0.11105
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01929, current rewards: 262.11754, mean: 0.11107
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01930, current rewards: 267.67587, mean: 0.11107
[32m[0906 14-40-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01930, current rewards: 273.24180, mean: 0.11107
[32m[0906 14-40-43 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-40-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-40-43 @MBExp.py:227][0m Rewards obtained: [277.6925384335876], Lows: [0], Highs: [1], Total time: 1913.9827409999996
[32m[0906 14-42-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-11 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 14-42-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01966, current rewards: 1.72994, mean: 0.17299
[32m[0906 14-42-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01906, current rewards: 7.04791, mean: 0.11747
[32m[0906 14-42-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.61045, mean: 0.11464
[32m[0906 14-42-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 18.11357, mean: 0.11321
[32m[0906 14-42-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.67106, mean: 0.11272
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 29.22593, mean: 0.11241
[32m[0906 14-42-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.78123, mean: 0.11220
[32m[0906 14-42-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 40.33750, mean: 0.11205
[32m[0906 14-42-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.85121, mean: 0.11183
[32m[0906 14-42-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 51.39141, mean: 0.11172
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.93572, mean: 0.11164
[32m[0906 14-42-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.49195, mean: 0.11159
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 68.07920, mean: 0.11161
[32m[0906 14-42-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 73.63169, mean: 0.11156
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01918, current rewards: 79.17970, mean: 0.11152
[32m[0906 14-42-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 84.72744, mean: 0.11148
[32m[0906 14-42-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 90.27898, mean: 0.11146
[32m[0906 14-42-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 95.83287, mean: 0.11143
[32m[0906 14-42-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 101.38520, mean: 0.11141
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01917, current rewards: 106.92496, mean: 0.11138
[32m[0906 14-42-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 112.49680, mean: 0.11138
[32m[0906 14-42-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01918, current rewards: 118.03307, mean: 0.11135
[32m[0906 14-42-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01918, current rewards: 123.56655, mean: 0.11132
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 129.10258, mean: 0.11130
[32m[0906 14-42-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 134.63204, mean: 0.11127
[32m[0906 14-42-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 140.17019, mean: 0.11125
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 145.70675, mean: 0.11123
[32m[0906 14-42-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 151.24600, mean: 0.11121
[32m[0906 14-42-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: 156.79971, mean: 0.11121
[32m[0906 14-42-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01920, current rewards: 162.35891, mean: 0.11120
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01922, current rewards: 167.91792, mean: 0.11120
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01924, current rewards: 173.47923, mean: 0.11120
[32m[0906 14-42-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01925, current rewards: 179.03393, mean: 0.11120
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01926, current rewards: 184.58662, mean: 0.11120
[32m[0906 14-42-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01927, current rewards: 190.14318, mean: 0.11119
[32m[0906 14-42-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01928, current rewards: 195.70204, mean: 0.11119
[32m[0906 14-42-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01928, current rewards: 201.26911, mean: 0.11120
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01928, current rewards: 206.90946, mean: 0.11124
[32m[0906 14-42-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01928, current rewards: 212.46913, mean: 0.11124
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01928, current rewards: 218.03176, mean: 0.11124
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 223.57478, mean: 0.11123
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01928, current rewards: 229.12526, mean: 0.11123
[32m[0906 14-42-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01928, current rewards: 234.68293, mean: 0.11122
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01928, current rewards: 240.23490, mean: 0.11122
[32m[0906 14-42-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: 245.67856, mean: 0.11117
[32m[0906 14-42-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01928, current rewards: 251.20552, mean: 0.11115
[32m[0906 14-42-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01929, current rewards: 256.74255, mean: 0.11114
[32m[0906 14-42-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01929, current rewards: 262.28032, mean: 0.11114
[32m[0906 14-42-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01929, current rewards: 267.82296, mean: 0.11113
[32m[0906 14-42-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01929, current rewards: 273.38174, mean: 0.11113
[32m[0906 14-43-00 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-43-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-43-00 @MBExp.py:227][0m Rewards obtained: [277.816560032356], Lows: [0], Highs: [0], Total time: 1962.9063629999996
[32m[0906 14-44-30 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-30 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 14-44-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.32696, mean: 0.13270
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.86870, mean: 0.11448
[32m[0906 14-44-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.40795, mean: 0.11280
[32m[0906 14-44-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 17.87349, mean: 0.11171
[32m[0906 14-44-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.40043, mean: 0.11143
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 28.92380, mean: 0.11125
[32m[0906 14-44-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.42106, mean: 0.11104
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 39.92360, mean: 0.11090
[32m[0906 14-44-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.41573, mean: 0.11077
[32m[0906 14-44-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 50.91850, mean: 0.11069
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 56.41518, mean: 0.11062
[32m[0906 14-44-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01919, current rewards: 61.94462, mean: 0.11062
[32m[0906 14-44-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01920, current rewards: 67.45215, mean: 0.11058
[32m[0906 14-44-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01920, current rewards: 72.96301, mean: 0.11055
[32m[0906 14-44-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01920, current rewards: 78.47450, mean: 0.11053
[32m[0906 14-44-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 83.98172, mean: 0.11050
[32m[0906 14-44-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 89.48689, mean: 0.11048
[32m[0906 14-44-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01919, current rewards: 94.99401, mean: 0.11046
[32m[0906 14-44-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 98.44258, mean: 0.10818
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 104.01951, mean: 0.10835
[32m[0906 14-44-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 109.59649, mean: 0.10851
[32m[0906 14-44-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 115.17437, mean: 0.10866
[32m[0906 14-44-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01918, current rewards: 120.74995, mean: 0.10878
[32m[0906 14-44-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 125.20636, mean: 0.10794
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 130.73207, mean: 0.10804
[32m[0906 14-44-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 136.25972, mean: 0.10814
[32m[0906 14-44-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 141.78767, mean: 0.10823
[32m[0906 14-44-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 147.38014, mean: 0.10837
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: 152.91062, mean: 0.10845
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 158.44480, mean: 0.10852
[32m[0906 14-45-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01921, current rewards: 163.98034, mean: 0.10860
[32m[0906 14-45-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01922, current rewards: 169.51525, mean: 0.10866
[32m[0906 14-45-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01923, current rewards: 175.04455, mean: 0.10872
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01925, current rewards: 180.62101, mean: 0.10881
[32m[0906 14-45-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01926, current rewards: 186.16646, mean: 0.10887
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01926, current rewards: 191.71412, mean: 0.10893
[32m[0906 14-45-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01926, current rewards: 197.26147, mean: 0.10898
[32m[0906 14-45-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01926, current rewards: 202.80750, mean: 0.10904
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01926, current rewards: 208.35389, mean: 0.10909
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01926, current rewards: 213.89513, mean: 0.10913
[32m[0906 14-45-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01925, current rewards: 219.43583, mean: 0.10917
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01926, current rewards: 224.95576, mean: 0.10920
[32m[0906 14-45-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01926, current rewards: 230.47807, mean: 0.10923
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01925, current rewards: 235.99880, mean: 0.10926
[32m[0906 14-45-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01926, current rewards: 241.51243, mean: 0.10928
[32m[0906 14-45-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01926, current rewards: 247.03057, mean: 0.10931
[32m[0906 14-45-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01926, current rewards: 252.54583, mean: 0.10933
[32m[0906 14-45-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01925, current rewards: 258.05741, mean: 0.10935
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01926, current rewards: 263.57135, mean: 0.10937
[32m[0906 14-45-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01925, current rewards: 269.09893, mean: 0.10939
[32m[0906 14-45-19 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-45-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-45-19 @MBExp.py:227][0m Rewards obtained: [273.51355348102425], Lows: [1], Highs: [1], Total time: 2011.7404579999995
[32m[0906 14-46-51 @MBExp.py:144][0m ####################################################################
[32m[0906 14-46-51 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 14-46-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01835, current rewards: 1.13564, mean: 0.11356
[32m[0906 14-46-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01901, current rewards: 6.67285, mean: 0.11121
[32m[0906 14-46-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01904, current rewards: 12.16958, mean: 0.11063
[32m[0906 14-46-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01905, current rewards: 17.69821, mean: 0.11061
[32m[0906 14-46-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01902, current rewards: 23.22367, mean: 0.11059
[32m[0906 14-46-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: 28.74705, mean: 0.11057
[32m[0906 14-46-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01907, current rewards: 34.27436, mean: 0.11056
[32m[0906 14-46-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 39.80435, mean: 0.11057
[32m[0906 14-46-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 45.32905, mean: 0.11056
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 50.85695, mean: 0.11056
[32m[0906 14-47-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 56.46530, mean: 0.11072
[32m[0906 14-47-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 62.01289, mean: 0.11074
[32m[0906 14-47-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 67.54964, mean: 0.11074
[32m[0906 14-47-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 73.10169, mean: 0.11076
[32m[0906 14-47-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 78.65294, mean: 0.11078
[32m[0906 14-47-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01913, current rewards: 84.19971, mean: 0.11079
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 89.75742, mean: 0.11081
[32m[0906 14-47-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 95.29231, mean: 0.11081
[32m[0906 14-47-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 100.82879, mean: 0.11080
[32m[0906 14-47-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 106.36368, mean: 0.11080
[32m[0906 14-47-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 111.89279, mean: 0.11078
[32m[0906 14-47-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 117.42846, mean: 0.11078
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 122.98425, mean: 0.11080
[32m[0906 14-47-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 128.53891, mean: 0.11081
[32m[0906 14-47-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 134.09255, mean: 0.11082
[32m[0906 14-47-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 139.65040, mean: 0.11083
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 145.19644, mean: 0.11084
[32m[0906 14-47-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 150.75384, mean: 0.11085
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 156.31259, mean: 0.11086
[32m[0906 14-47-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01917, current rewards: 161.86762, mean: 0.11087
[32m[0906 14-47-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 167.42747, mean: 0.11088
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01920, current rewards: 172.98474, mean: 0.11089
[32m[0906 14-47-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01920, current rewards: 178.54743, mean: 0.11090
[32m[0906 14-47-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01920, current rewards: 184.92422, mean: 0.11140
[32m[0906 14-47-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01920, current rewards: 190.46729, mean: 0.11138
[32m[0906 14-47-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01919, current rewards: 194.92603, mean: 0.11075
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01919, current rewards: 199.38478, mean: 0.11016
[32m[0906 14-47-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: 203.84352, mean: 0.10959
[32m[0906 14-47-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01919, current rewards: 171.27032, mean: 0.08967
[32m[0906 14-47-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01919, current rewards: 121.27032, mean: 0.06187
[32m[0906 14-47-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01919, current rewards: 71.27032, mean: 0.03546
[32m[0906 14-47-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01919, current rewards: 21.27032, mean: 0.01033
[32m[0906 14-47-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01919, current rewards: -28.72968, mean: -0.01362
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01919, current rewards: -78.72968, mean: -0.03645
[32m[0906 14-47-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01919, current rewards: -128.72968, mean: -0.05825
[32m[0906 14-47-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: -178.72968, mean: -0.07908
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01920, current rewards: -228.72968, mean: -0.09902
[32m[0906 14-47-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01920, current rewards: -278.72968, mean: -0.11811
[32m[0906 14-47-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: -328.72968, mean: -0.13640
[32m[0906 14-47-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: -378.72968, mean: -0.15396
[32m[0906 14-47-40 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-47-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-47-40 @MBExp.py:227][0m Rewards obtained: [-418.72967959720984], Lows: [0], Highs: [624], Total time: 2060.4584859999995
[32m[0906 14-49-14 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-14 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 14-49-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01856, current rewards: 1.18153, mean: 0.11815
[32m[0906 14-49-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01899, current rewards: 6.81267, mean: 0.11354
[32m[0906 14-49-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.38892, mean: 0.11263
[32m[0906 14-49-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.96138, mean: 0.11226
[32m[0906 14-49-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.53650, mean: 0.11208
[32m[0906 14-49-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 29.10681, mean: 0.11195
[32m[0906 14-49-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.67985, mean: 0.11187
[32m[0906 14-49-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01916, current rewards: 40.24801, mean: 0.11180
[32m[0906 14-49-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.86878, mean: 0.11188
[32m[0906 14-49-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.34534, mean: 0.11162
[32m[0906 14-49-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 56.94970, mean: 0.11167
[32m[0906 14-49-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.54495, mean: 0.11169
[32m[0906 14-49-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 68.13945, mean: 0.11170
[32m[0906 14-49-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 73.73766, mean: 0.11172
[32m[0906 14-49-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 79.33459, mean: 0.11174
[32m[0906 14-49-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 84.93307, mean: 0.11175
[32m[0906 14-49-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: 90.53224, mean: 0.11177
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 96.14274, mean: 0.11179
[32m[0906 14-49-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 103.09897, mean: 0.11330
[32m[0906 14-49-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01917, current rewards: 111.88763, mean: 0.11655
[32m[0906 14-49-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 120.67630, mean: 0.11948
[32m[0906 14-49-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01918, current rewards: 129.46496, mean: 0.12214
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01918, current rewards: 138.25362, mean: 0.12455
[32m[0906 14-49-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 147.04229, mean: 0.12676
[32m[0906 14-49-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01919, current rewards: 155.83095, mean: 0.12879
[32m[0906 14-49-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 164.61961, mean: 0.13065
[32m[0906 14-49-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01919, current rewards: 140.48662, mean: 0.10724
[32m[0906 14-49-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01919, current rewards: 90.48662, mean: 0.06653
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01919, current rewards: 40.48662, mean: 0.02871
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01920, current rewards: -9.51338, mean: -0.00652
[32m[0906 14-49-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01921, current rewards: -59.51338, mean: -0.03941
[32m[0906 14-49-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01921, current rewards: -109.51338, mean: -0.07020
[32m[0906 14-49-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01921, current rewards: -159.51338, mean: -0.09908
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01921, current rewards: -209.51338, mean: -0.12621
[32m[0906 14-49-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01921, current rewards: -259.51338, mean: -0.15176
[32m[0906 14-49-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01921, current rewards: -309.51338, mean: -0.17586
[32m[0906 14-49-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: -359.51338, mean: -0.19863
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01921, current rewards: -409.51338, mean: -0.22017
[32m[0906 14-49-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01921, current rewards: -459.51338, mean: -0.24058
[32m[0906 14-49-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: -509.51338, mean: -0.25996
[32m[0906 14-49-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01921, current rewards: -559.51338, mean: -0.27836
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: -609.51338, mean: -0.29588
[32m[0906 14-49-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01921, current rewards: -659.51338, mean: -0.31257
[32m[0906 14-49-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01922, current rewards: -709.51338, mean: -0.32848
[32m[0906 14-49-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: -759.51338, mean: -0.34367
[32m[0906 14-49-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01921, current rewards: -809.51338, mean: -0.35819
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01921, current rewards: -859.51338, mean: -0.37208
[32m[0906 14-50-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01921, current rewards: -909.51338, mean: -0.38539
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: -959.51338, mean: -0.39814
[32m[0906 14-50-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: -1009.51338, mean: -0.41037
[32m[0906 14-50-03 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-50-03 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-50-03 @MBExp.py:227][0m Rewards obtained: [-1049.513378475213], Lows: [0], Highs: [1218], Total time: 2109.1806439999996
[32m[0906 14-51-40 @MBExp.py:144][0m ####################################################################
[32m[0906 14-51-40 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 14-51-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 1.09949, mean: 0.10995
[32m[0906 14-51-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01927, current rewards: 6.70018, mean: 0.11167
[32m[0906 14-51-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 12.26404, mean: 0.11149
[32m[0906 14-51-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01926, current rewards: 17.83246, mean: 0.11145
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01926, current rewards: 23.40223, mean: 0.11144
[32m[0906 14-51-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01923, current rewards: 28.96530, mean: 0.11141
[32m[0906 14-51-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.50254, mean: 0.11130
[32m[0906 14-51-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01924, current rewards: 40.06668, mean: 0.11130
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 45.62981, mean: 0.11129
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01923, current rewards: 51.19310, mean: 0.11129
[32m[0906 14-51-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01923, current rewards: 56.75282, mean: 0.11128
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01922, current rewards: 62.31194, mean: 0.11127
[32m[0906 14-51-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01923, current rewards: 67.86642, mean: 0.11126
[32m[0906 14-51-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01922, current rewards: 73.42671, mean: 0.11125
[32m[0906 14-51-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01921, current rewards: 78.98674, mean: 0.11125
[32m[0906 14-51-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 84.53698, mean: 0.11123
[32m[0906 14-51-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 90.09103, mean: 0.11122
[32m[0906 14-51-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 95.63809, mean: 0.11121
[32m[0906 14-51-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: 101.18619, mean: 0.11119
[32m[0906 14-51-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 106.74291, mean: 0.11119
[32m[0906 14-51-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01922, current rewards: 112.29643, mean: 0.11118
[32m[0906 14-52-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 117.84609, mean: 0.11118
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 123.39985, mean: 0.11117
[32m[0906 14-52-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01922, current rewards: 128.95483, mean: 0.11117
[32m[0906 14-52-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 134.50749, mean: 0.11116
[32m[0906 14-52-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01921, current rewards: 140.03963, mean: 0.11114
[32m[0906 14-52-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01921, current rewards: 145.62094, mean: 0.11116
[32m[0906 14-52-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01921, current rewards: 151.07800, mean: 0.11109
[32m[0906 14-52-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01921, current rewards: 156.53297, mean: 0.11102
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01921, current rewards: 161.98503, mean: 0.11095
[32m[0906 14-52-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01921, current rewards: 167.44146, mean: 0.11089
[32m[0906 14-52-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01921, current rewards: 172.89820, mean: 0.11083
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01921, current rewards: 177.31028, mean: 0.11013
[32m[0906 14-52-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01921, current rewards: 182.82379, mean: 0.11013
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01921, current rewards: 188.37358, mean: 0.11016
[32m[0906 14-52-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01922, current rewards: 193.91815, mean: 0.11018
[32m[0906 14-52-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01921, current rewards: 199.47605, mean: 0.11021
[32m[0906 14-52-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01922, current rewards: 205.01598, mean: 0.11022
[32m[0906 14-52-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01922, current rewards: 210.56011, mean: 0.11024
[32m[0906 14-52-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01921, current rewards: 216.09984, mean: 0.11026
[32m[0906 14-52-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01922, current rewards: 221.64259, mean: 0.11027
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01922, current rewards: 227.18352, mean: 0.11028
[32m[0906 14-52-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01922, current rewards: 232.75584, mean: 0.11031
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01922, current rewards: 238.32694, mean: 0.11034
[32m[0906 14-52-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: 243.89797, mean: 0.11036
[32m[0906 14-52-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01922, current rewards: 249.46554, mean: 0.11038
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01921, current rewards: 255.04213, mean: 0.11041
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01921, current rewards: 260.61228, mean: 0.11043
[32m[0906 14-52-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01921, current rewards: 266.18410, mean: 0.11045
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01921, current rewards: 271.76506, mean: 0.11047
[32m[0906 14-52-28 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-52-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-52-28 @MBExp.py:227][0m Rewards obtained: [276.31829542547024], Lows: [0], Highs: [1], Total time: 2157.9145389999994
[32m[0906 14-54-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-07 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 14-54-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 1.03964, mean: 0.10396
[32m[0906 14-54-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01925, current rewards: 6.53764, mean: 0.10896
[32m[0906 14-54-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.03983, mean: 0.10945
[32m[0906 14-54-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.54015, mean: 0.10963
[32m[0906 14-54-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.03833, mean: 0.10971
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 28.54074, mean: 0.10977
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.03834, mean: 0.10980
[32m[0906 14-54-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.53569, mean: 0.10982
[32m[0906 14-54-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.12265, mean: 0.11006
[32m[0906 14-54-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 50.64584, mean: 0.11010
[32m[0906 14-54-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 56.16322, mean: 0.11012
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 61.70315, mean: 0.11018
[32m[0906 14-54-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 67.22409, mean: 0.11020
[32m[0906 14-54-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 72.74840, mean: 0.11022
[32m[0906 14-54-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 78.27259, mean: 0.11024
[32m[0906 14-54-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 83.79342, mean: 0.11025
[32m[0906 14-54-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 89.34189, mean: 0.11030
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01915, current rewards: 94.91933, mean: 0.11037
[32m[0906 14-54-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 100.44507, mean: 0.11038
[32m[0906 14-54-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 105.97201, mean: 0.11039
[32m[0906 14-54-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 111.49882, mean: 0.11039
[32m[0906 14-54-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 117.02939, mean: 0.11041
[32m[0906 14-54-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 122.54975, mean: 0.11041
[32m[0906 14-54-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 128.07363, mean: 0.11041
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 133.60238, mean: 0.11042
[32m[0906 14-54-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 139.12846, mean: 0.11042
[32m[0906 14-54-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01914, current rewards: 144.65706, mean: 0.11043
[32m[0906 14-54-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 150.18529, mean: 0.11043
[32m[0906 14-54-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 158.52614, mean: 0.11243
[32m[0906 14-54-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 167.57957, mean: 0.11478
[32m[0906 14-54-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 176.63300, mean: 0.11698
[32m[0906 14-54-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 185.68644, mean: 0.11903
[32m[0906 14-54-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 185.29132, mean: 0.11509
[32m[0906 14-54-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 135.29132, mean: 0.08150
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: 85.29132, mean: 0.04988
[32m[0906 14-54-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: 35.29132, mean: 0.02005
[32m[0906 14-54-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: -14.70868, mean: -0.00813
[32m[0906 14-54-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: -64.70868, mean: -0.03479
[32m[0906 14-54-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01912, current rewards: -114.70868, mean: -0.06006
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01912, current rewards: -164.70868, mean: -0.08404
[32m[0906 14-54-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: -214.70868, mean: -0.10682
[32m[0906 14-54-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: -264.70868, mean: -0.12850
[32m[0906 14-54-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: -314.70868, mean: -0.14915
[32m[0906 14-54-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01912, current rewards: -364.70868, mean: -0.16885
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01912, current rewards: -414.70868, mean: -0.18765
[32m[0906 14-54-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: -464.70868, mean: -0.20562
[32m[0906 14-54-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: -514.70868, mean: -0.22282
[32m[0906 14-54-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: -564.70868, mean: -0.23928
[32m[0906 14-54-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01913, current rewards: -614.70868, mean: -0.25507
[32m[0906 14-54-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01913, current rewards: -664.70868, mean: -0.27021
[32m[0906 14-54-55 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-54-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-54-55 @MBExp.py:227][0m Rewards obtained: [-704.708679822051], Lows: [0], Highs: [898], Total time: 2206.4544459999993
[32m[0906 14-56-36 @MBExp.py:144][0m ####################################################################
[32m[0906 14-56-36 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 14-56-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01881, current rewards: -0.02161, mean: -0.00216
[32m[0906 14-56-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01937, current rewards: 5.41053, mean: 0.09018
[32m[0906 14-56-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01925, current rewards: 10.85559, mean: 0.09869
[32m[0906 14-56-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 16.28810, mean: 0.10180
[32m[0906 14-56-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 21.72703, mean: 0.10346
[32m[0906 14-56-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 27.16629, mean: 0.10449
[32m[0906 14-56-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 32.60941, mean: 0.10519
[32m[0906 14-56-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 38.07702, mean: 0.10577
[32m[0906 14-56-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01914, current rewards: 43.59920, mean: 0.10634
[32m[0906 14-56-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 49.06670, mean: 0.10667
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 54.53227, mean: 0.10693
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 59.99897, mean: 0.10714
[32m[0906 14-56-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 65.46744, mean: 0.10732
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 70.95588, mean: 0.10751
[32m[0906 14-56-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 76.48578, mean: 0.10773
[32m[0906 14-56-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 82.01505, mean: 0.10791
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 87.42825, mean: 0.10794
[32m[0906 14-56-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 92.93985, mean: 0.10807
[32m[0906 14-56-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 98.46811, mean: 0.10821
[32m[0906 14-56-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 103.98992, mean: 0.10832
[32m[0906 14-56-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 109.51164, mean: 0.10843
[32m[0906 14-56-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 115.03271, mean: 0.10852
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 120.56033, mean: 0.10861
[32m[0906 14-56-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 126.08095, mean: 0.10869
[32m[0906 14-57-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01914, current rewards: 131.59182, mean: 0.10875
[32m[0906 14-57-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: 137.11250, mean: 0.10882
[32m[0906 14-57-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 142.63309, mean: 0.10888
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 148.15181, mean: 0.10894
[32m[0906 14-57-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01909, current rewards: 153.67345, mean: 0.10899
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 159.19644, mean: 0.10904
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 164.71777, mean: 0.10908
[32m[0906 14-57-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01909, current rewards: 170.23468, mean: 0.10912
[32m[0906 14-57-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01909, current rewards: 175.80448, mean: 0.10920
[32m[0906 14-57-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: 181.34256, mean: 0.10924
[32m[0906 14-57-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: 186.91282, mean: 0.10931
[32m[0906 14-57-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 192.44003, mean: 0.10934
[32m[0906 14-57-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 197.96533, mean: 0.10937
[32m[0906 14-57-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 203.49084, mean: 0.10940
[32m[0906 14-57-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 209.01576, mean: 0.10943
[32m[0906 14-57-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 214.54553, mean: 0.10946
[32m[0906 14-57-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 220.07612, mean: 0.10949
[32m[0906 14-57-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01909, current rewards: 225.70012, mean: 0.10956
[32m[0906 14-57-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 231.24931, mean: 0.10960
[32m[0906 14-57-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 236.79521, mean: 0.10963
[32m[0906 14-57-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 242.34458, mean: 0.10966
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 247.92172, mean: 0.10970
[32m[0906 14-57-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 253.42448, mean: 0.10971
[32m[0906 14-57-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01911, current rewards: 258.92657, mean: 0.10971
[32m[0906 14-57-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: 264.42873, mean: 0.10972
[32m[0906 14-57-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 269.85988, mean: 0.10970
[32m[0906 14-57-25 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-57-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-57-25 @MBExp.py:227][0m Rewards obtained: [274.24971485669295], Lows: [0], Highs: [1], Total time: 2254.9494679999993
[32m[0906 14-59-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-08 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 14-59-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02013, current rewards: 1.09143, mean: 0.10914
[32m[0906 14-59-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01931, current rewards: 6.63707, mean: 0.11062
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01923, current rewards: 12.18376, mean: 0.11076
[32m[0906 14-59-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 17.73126, mean: 0.11082
[32m[0906 14-59-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 23.28211, mean: 0.11087
[32m[0906 14-59-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 28.83433, mean: 0.11090
[32m[0906 14-59-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01924, current rewards: 34.38042, mean: 0.11090
[32m[0906 14-59-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01926, current rewards: 39.99244, mean: 0.11109
[32m[0906 14-59-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01926, current rewards: 45.55829, mean: 0.11112
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01926, current rewards: 51.12569, mean: 0.11114
[32m[0906 14-59-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01924, current rewards: 56.69168, mean: 0.11116
[32m[0906 14-59-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 62.25297, mean: 0.11117
[32m[0906 14-59-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 67.82709, mean: 0.11119
[32m[0906 14-59-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 73.39227, mean: 0.11120
[32m[0906 14-59-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 78.95796, mean: 0.11121
[32m[0906 14-59-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01924, current rewards: 84.55013, mean: 0.11125
[32m[0906 14-59-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01924, current rewards: 90.11790, mean: 0.11126
[32m[0906 14-59-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01924, current rewards: 95.69079, mean: 0.11127
[32m[0906 14-59-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01923, current rewards: 101.25880, mean: 0.11127
[32m[0906 14-59-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01923, current rewards: 106.82424, mean: 0.11128
[32m[0906 14-59-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01923, current rewards: 112.40237, mean: 0.11129
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01923, current rewards: 117.96254, mean: 0.11129
[32m[0906 14-59-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01922, current rewards: 123.52366, mean: 0.11128
[32m[0906 14-59-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 129.08799, mean: 0.11128
[32m[0906 14-59-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 134.64999, mean: 0.11128
[32m[0906 14-59-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 140.21120, mean: 0.11128
[32m[0906 14-59-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: 145.77232, mean: 0.11128
[32m[0906 14-59-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 151.33404, mean: 0.11128
[32m[0906 14-59-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 156.89391, mean: 0.11127
[32m[0906 14-59-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 162.45274, mean: 0.11127
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 168.01591, mean: 0.11127
[32m[0906 14-59-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 173.69524, mean: 0.11134
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01913, current rewards: 179.28131, mean: 0.11135
[32m[0906 14-59-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: 184.85918, mean: 0.11136
[32m[0906 14-59-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01913, current rewards: 190.43526, mean: 0.11137
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01914, current rewards: 196.00947, mean: 0.11137
[32m[0906 14-59-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 201.58640, mean: 0.11137
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01915, current rewards: 207.15953, mean: 0.11138
[32m[0906 14-59-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01915, current rewards: 212.73356, mean: 0.11138
[32m[0906 14-59-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 218.30572, mean: 0.11138
[32m[0906 14-59-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 223.81035, mean: 0.11135
[32m[0906 14-59-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 227.23782, mean: 0.11031
[32m[0906 14-59-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 232.75904, mean: 0.11031
[32m[0906 14-59-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01916, current rewards: 238.27702, mean: 0.11031
[32m[0906 14-59-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01916, current rewards: 243.79571, mean: 0.11031
[32m[0906 14-59-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01916, current rewards: 249.31550, mean: 0.11032
[32m[0906 14-59-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01916, current rewards: 254.83462, mean: 0.11032
[32m[0906 14-59-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: 260.35465, mean: 0.11032
[32m[0906 14-59-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 265.85946, mean: 0.11032
[32m[0906 14-59-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01917, current rewards: 271.38118, mean: 0.11032
[32m[0906 14-59-56 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-59-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-59-56 @MBExp.py:227][0m Rewards obtained: [275.7955427849245], Lows: [1], Highs: [0], Total time: 2303.596699999999
[32m[0906 15-01-41 @MBExp.py:144][0m ####################################################################
[32m[0906 15-01-41 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-01-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01918, current rewards: 1.10316, mean: 0.11032
[32m[0906 15-01-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.66937, mean: 0.11116
[32m[0906 15-01-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 12.20611, mean: 0.11096
[32m[0906 15-01-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.74491, mean: 0.11091
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 23.27908, mean: 0.11085
[32m[0906 15-01-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 28.81349, mean: 0.11082
[32m[0906 15-01-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 34.36400, mean: 0.11085
[32m[0906 15-01-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01921, current rewards: 40.01603, mean: 0.11116
[32m[0906 15-01-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01923, current rewards: 45.60961, mean: 0.11124
[32m[0906 15-01-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01922, current rewards: 51.20432, mean: 0.11131
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01922, current rewards: 56.79858, mean: 0.11137
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 62.39377, mean: 0.11142
[32m[0906 15-01-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01921, current rewards: 67.98655, mean: 0.11145
[32m[0906 15-01-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01921, current rewards: 73.57977, mean: 0.11148
[32m[0906 15-01-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01922, current rewards: 79.15748, mean: 0.11149
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01921, current rewards: 84.69218, mean: 0.11144
[32m[0906 15-01-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01921, current rewards: 89.12323, mean: 0.11003
[32m[0906 15-01-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 94.65347, mean: 0.11006
[32m[0906 15-01-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 100.18575, mean: 0.11009
[32m[0906 15-02-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01922, current rewards: 105.72548, mean: 0.11013
[32m[0906 15-02-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 111.25138, mean: 0.11015
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 116.78343, mean: 0.11017
[32m[0906 15-02-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 122.32158, mean: 0.11020
[32m[0906 15-02-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 127.80913, mean: 0.11018
[32m[0906 15-02-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 133.33948, mean: 0.11020
[32m[0906 15-02-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01907, current rewards: 138.86668, mean: 0.11021
[32m[0906 15-02-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01905, current rewards: 144.39627, mean: 0.11023
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01904, current rewards: 149.87973, mean: 0.11021
[32m[0906 15-02-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: 155.40820, mean: 0.11022
[32m[0906 15-02-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 160.93933, mean: 0.11023
[32m[0906 15-02-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 166.46372, mean: 0.11024
[32m[0906 15-02-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01904, current rewards: 171.98786, mean: 0.11025
[32m[0906 15-02-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 177.51613, mean: 0.11026
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 183.04641, mean: 0.11027
[32m[0906 15-02-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 188.58479, mean: 0.11028
[32m[0906 15-02-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 194.10876, mean: 0.11029
[32m[0906 15-02-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 199.63582, mean: 0.11030
[32m[0906 15-02-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 205.16070, mean: 0.11030
[32m[0906 15-02-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01908, current rewards: 210.71441, mean: 0.11032
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01909, current rewards: 216.40130, mean: 0.11041
[32m[0906 15-02-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01909, current rewards: 221.94002, mean: 0.11042
[32m[0906 15-02-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 227.47771, mean: 0.11043
[32m[0906 15-02-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01910, current rewards: 233.01991, mean: 0.11044
[32m[0906 15-02-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01910, current rewards: 238.55870, mean: 0.11044
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 244.09930, mean: 0.11045
[32m[0906 15-02-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01911, current rewards: 249.68315, mean: 0.11048
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01911, current rewards: 255.23720, mean: 0.11049
[32m[0906 15-02-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 260.78621, mean: 0.11050
[32m[0906 15-02-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 266.25711, mean: 0.11048
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 271.80823, mean: 0.11049
[32m[0906 15-02-30 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-02-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-02-30 @MBExp.py:227][0m Rewards obtained: [276.2458824607972], Lows: [0], Highs: [1], Total time: 2352.105628999999
[32m[0906 15-04-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-04-16 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01920, current rewards: 1.19567, mean: 0.11957
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 6.75270, mean: 0.11254
[32m[0906 15-04-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 12.31028, mean: 0.11191
[32m[0906 15-04-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.86802, mean: 0.11168
[32m[0906 15-04-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.42814, mean: 0.11156
[32m[0906 15-04-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01911, current rewards: 28.98523, mean: 0.11148
[32m[0906 15-04-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.54421, mean: 0.11143
[32m[0906 15-04-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 40.10386, mean: 0.11140
[32m[0906 15-04-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.69224, mean: 0.11144
[32m[0906 15-04-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 51.20329, mean: 0.11131
[32m[0906 15-04-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 56.71349, mean: 0.11120
[32m[0906 15-04-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.22614, mean: 0.11112
[32m[0906 15-04-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 67.73750, mean: 0.11105
[32m[0906 15-04-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 73.24666, mean: 0.11098
[32m[0906 15-04-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 78.73444, mean: 0.11089
[32m[0906 15-04-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 84.24164, mean: 0.11084
[32m[0906 15-04-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 89.74800, mean: 0.11080
[32m[0906 15-04-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 95.30000, mean: 0.11081
[32m[0906 15-04-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 100.85670, mean: 0.11083
[32m[0906 15-04-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 106.41587, mean: 0.11085
[32m[0906 15-04-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 111.97468, mean: 0.11087
[32m[0906 15-04-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 117.54907, mean: 0.11090
[32m[0906 15-04-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01909, current rewards: 122.96531, mean: 0.11078
[32m[0906 15-04-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 128.44051, mean: 0.11072
[32m[0906 15-04-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01906, current rewards: 133.91803, mean: 0.11068
[32m[0906 15-04-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01904, current rewards: 139.39719, mean: 0.11063
[32m[0906 15-04-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 144.87434, mean: 0.11059
[32m[0906 15-04-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 150.35265, mean: 0.11055
[32m[0906 15-04-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: 155.83200, mean: 0.11052
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 161.30739, mean: 0.11048
[32m[0906 15-04-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01904, current rewards: 166.81877, mean: 0.11048
[32m[0906 15-04-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01905, current rewards: 172.28023, mean: 0.11044
[32m[0906 15-04-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 177.74386, mean: 0.11040
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 182.09920, mean: 0.10970
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 187.64729, mean: 0.10974
[32m[0906 15-04-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01906, current rewards: 193.21121, mean: 0.10978
[32m[0906 15-04-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01907, current rewards: 198.76066, mean: 0.10981
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 204.31592, mean: 0.10985
[32m[0906 15-04-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01907, current rewards: 209.86499, mean: 0.10988
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 215.40843, mean: 0.10990
[32m[0906 15-04-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 220.96400, mean: 0.10993
[32m[0906 15-04-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 226.51624, mean: 0.10996
[32m[0906 15-04-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01908, current rewards: 232.06913, mean: 0.10999
[32m[0906 15-04-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 237.62488, mean: 0.11001
[32m[0906 15-04-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: 243.17893, mean: 0.11004
[32m[0906 15-05-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 248.72912, mean: 0.11006
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 254.27713, mean: 0.11008
[32m[0906 15-05-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 259.75837, mean: 0.11007
[32m[0906 15-05-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 265.29937, mean: 0.11008
[32m[0906 15-05-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 270.83896, mean: 0.11010
[32m[0906 15-05-05 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-05-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-05-05 @MBExp.py:227][0m Rewards obtained: [275.27350692439126], Lows: [0], Highs: [1], Total time: 2400.593799999999
[32m[0906 15-06-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-54 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-06-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01957, current rewards: 1.08549, mean: 0.10855
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01932, current rewards: 6.62451, mean: 0.11041
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01926, current rewards: 12.16279, mean: 0.11057
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01923, current rewards: 17.69940, mean: 0.11062
[32m[0906 15-06-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 23.23958, mean: 0.11066
[32m[0906 15-06-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 28.76085, mean: 0.11062
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.29963, mean: 0.11064
[32m[0906 15-07-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 39.84068, mean: 0.11067
[32m[0906 15-07-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 45.37560, mean: 0.11067
[32m[0906 15-07-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 50.90959, mean: 0.11067
[32m[0906 15-07-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01921, current rewards: 56.44892, mean: 0.11068
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01921, current rewards: 61.98647, mean: 0.11069
[32m[0906 15-07-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01922, current rewards: 67.52351, mean: 0.11069
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01923, current rewards: 73.17207, mean: 0.11087
[32m[0906 15-07-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01923, current rewards: 78.73181, mean: 0.11089
[32m[0906 15-07-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 84.28174, mean: 0.11090
[32m[0906 15-07-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 89.84749, mean: 0.11092
[32m[0906 15-07-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01920, current rewards: 95.41183, mean: 0.11094
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 100.98059, mean: 0.11097
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 106.53430, mean: 0.11097
[32m[0906 15-07-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 112.10832, mean: 0.11100
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01908, current rewards: 117.67405, mean: 0.11101
[32m[0906 15-07-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01905, current rewards: 123.16361, mean: 0.11096
[32m[0906 15-07-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01904, current rewards: 128.71948, mean: 0.11097
[32m[0906 15-07-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01901, current rewards: 134.27576, mean: 0.11097
[32m[0906 15-07-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01900, current rewards: 139.83905, mean: 0.11098
[32m[0906 15-07-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01898, current rewards: 145.40054, mean: 0.11099
[32m[0906 15-07-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01899, current rewards: 150.96307, mean: 0.11100
[32m[0906 15-07-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01901, current rewards: 156.52718, mean: 0.11101
[32m[0906 15-07-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 162.09342, mean: 0.11102
[32m[0906 15-07-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: 167.69139, mean: 0.11105
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 173.23730, mean: 0.11105
[32m[0906 15-07-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 178.79923, mean: 0.11106
[32m[0906 15-07-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: 184.36075, mean: 0.11106
[32m[0906 15-07-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 189.92110, mean: 0.11106
[32m[0906 15-07-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 195.48034, mean: 0.11107
[32m[0906 15-07-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01906, current rewards: 201.04122, mean: 0.11107
[32m[0906 15-07-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01906, current rewards: 206.60448, mean: 0.11108
[32m[0906 15-07-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 212.11525, mean: 0.11106
[32m[0906 15-07-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 217.65823, mean: 0.11105
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 223.22239, mean: 0.11106
[32m[0906 15-07-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 228.76022, mean: 0.11105
[32m[0906 15-07-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01908, current rewards: 234.29628, mean: 0.11104
[32m[0906 15-07-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01908, current rewards: 239.83447, mean: 0.11103
[32m[0906 15-07-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01909, current rewards: 245.37097, mean: 0.11103
[32m[0906 15-07-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 250.90753, mean: 0.11102
[32m[0906 15-07-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 254.43872, mean: 0.11015
[32m[0906 15-07-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 259.99175, mean: 0.11017
[32m[0906 15-07-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 265.54391, mean: 0.11018
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 271.09698, mean: 0.11020
[32m[0906 15-07-42 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-07-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-07-42 @MBExp.py:227][0m Rewards obtained: [275.5379220769384], Lows: [1], Highs: [0], Total time: 2449.0781469999993
[32m[0906 15-09-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-09-33 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-09-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01926, current rewards: 1.07818, mean: 0.10782
[32m[0906 15-09-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 6.63733, mean: 0.11062
[32m[0906 15-09-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 12.20007, mean: 0.11091
[32m[0906 15-09-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.76065, mean: 0.11100
[32m[0906 15-09-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.31797, mean: 0.11104
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 28.97589, mean: 0.11145
[32m[0906 15-09-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.91015, mean: 0.11261
[32m[0906 15-09-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 41.67418, mean: 0.11576
[32m[0906 15-09-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 48.43822, mean: 0.11814
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 55.20226, mean: 0.12000
[32m[0906 15-09-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 61.96630, mean: 0.12150
[32m[0906 15-09-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 68.73034, mean: 0.12273
[32m[0906 15-09-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 75.49437, mean: 0.12376
[32m[0906 15-09-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 80.72590, mean: 0.12231
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01911, current rewards: 83.72429, mean: 0.11792
[32m[0906 15-09-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01909, current rewards: 59.16351, mean: 0.07785
[32m[0906 15-09-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 9.16351, mean: 0.01131
[32m[0906 15-09-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01901, current rewards: -40.83649, mean: -0.04748
[32m[0906 15-09-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01899, current rewards: -90.83649, mean: -0.09982
[32m[0906 15-09-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01896, current rewards: -140.83649, mean: -0.14670
[32m[0906 15-09-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01894, current rewards: -190.83649, mean: -0.18895
[32m[0906 15-09-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01892, current rewards: -240.83649, mean: -0.22720
[32m[0906 15-09-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01890, current rewards: -290.83649, mean: -0.26201
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01888, current rewards: -340.83649, mean: -0.29382
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01886, current rewards: -390.83649, mean: -0.32301
[32m[0906 15-09-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01885, current rewards: -440.83649, mean: -0.34987
[32m[0906 15-09-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01885, current rewards: -490.83649, mean: -0.37468
[32m[0906 15-09-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01886, current rewards: -540.83649, mean: -0.39767
[32m[0906 15-10-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01888, current rewards: -590.83649, mean: -0.41903
[32m[0906 15-10-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01889, current rewards: -640.83649, mean: -0.43893
[32m[0906 15-10-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01890, current rewards: -690.83649, mean: -0.45751
[32m[0906 15-10-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01891, current rewards: -740.83649, mean: -0.47490
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01892, current rewards: -790.83649, mean: -0.49120
[32m[0906 15-10-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01893, current rewards: -840.83649, mean: -0.50653
[32m[0906 15-10-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: -890.83649, mean: -0.52096
[32m[0906 15-10-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01894, current rewards: -940.83649, mean: -0.53457
[32m[0906 15-10-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01895, current rewards: -990.83649, mean: -0.54742
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: -1040.83649, mean: -0.55959
[32m[0906 15-10-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01897, current rewards: -1090.83649, mean: -0.57112
[32m[0906 15-10-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: -1140.83649, mean: -0.58206
[32m[0906 15-10-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01897, current rewards: -1190.83649, mean: -0.59246
[32m[0906 15-10-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: -1240.83649, mean: -0.60235
[32m[0906 15-10-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01898, current rewards: -1290.83649, mean: -0.61177
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01898, current rewards: -1340.83649, mean: -0.62076
[32m[0906 15-10-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01898, current rewards: -1390.83649, mean: -0.62934
[32m[0906 15-10-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01899, current rewards: -1440.83649, mean: -0.63754
[32m[0906 15-10-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01899, current rewards: -1490.83649, mean: -0.64538
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01899, current rewards: -1540.83649, mean: -0.65290
[32m[0906 15-10-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01900, current rewards: -1590.83649, mean: -0.66010
[32m[0906 15-10-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01900, current rewards: -1640.83649, mean: -0.66701
[32m[0906 15-10-21 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-10-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-10-22 @MBExp.py:227][0m Rewards obtained: [-1680.8364850143867], Lows: [0], Highs: [1766], Total time: 2497.313215999999
[32m[0906 15-12-15 @MBExp.py:144][0m ####################################################################
[32m[0906 15-12-15 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01929, current rewards: -0.89849, mean: -0.08985
[32m[0906 15-12-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01914, current rewards: 4.64774, mean: 0.07746
[32m[0906 15-12-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 10.21099, mean: 0.09283
[32m[0906 15-12-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01904, current rewards: 15.77211, mean: 0.09858
[32m[0906 15-12-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 21.25245, mean: 0.10120
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: 26.80000, mean: 0.10308
[32m[0906 15-12-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01907, current rewards: 32.41764, mean: 0.10457
[32m[0906 15-12-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01907, current rewards: 37.97176, mean: 0.10548
[32m[0906 15-12-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 43.54043, mean: 0.10620
[32m[0906 15-12-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 49.10212, mean: 0.10674
[32m[0906 15-12-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 54.65947, mean: 0.10718
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 60.22513, mean: 0.10754
[32m[0906 15-12-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 65.79778, mean: 0.10787
[32m[0906 15-12-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 71.49183, mean: 0.10832
[32m[0906 15-12-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01907, current rewards: 77.06370, mean: 0.10854
[32m[0906 15-12-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01904, current rewards: 82.63740, mean: 0.10873
[32m[0906 15-12-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01902, current rewards: 89.36530, mean: 0.11033
[32m[0906 15-12-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01899, current rewards: 96.46185, mean: 0.11216
[32m[0906 15-12-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01897, current rewards: 103.55840, mean: 0.11380
[32m[0906 15-12-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01895, current rewards: 91.24213, mean: 0.09504
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01894, current rewards: 41.24213, mean: 0.04083
[32m[0906 15-12-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01892, current rewards: -8.75787, mean: -0.00826
[32m[0906 15-12-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01890, current rewards: -34.29762, mean: -0.03090
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01889, current rewards: -28.73529, mean: -0.02477
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01888, current rewards: -23.17337, mean: -0.01915
[32m[0906 15-12-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01887, current rewards: -17.61586, mean: -0.01398
[32m[0906 15-12-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01887, current rewards: -12.04851, mean: -0.00920
[32m[0906 15-12-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01889, current rewards: -6.48946, mean: -0.00477
[32m[0906 15-12-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01891, current rewards: -0.92802, mean: -0.00066
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01891, current rewards: 4.63256, mean: 0.00317
[32m[0906 15-12-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01892, current rewards: 10.17376, mean: 0.00674
[32m[0906 15-12-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01892, current rewards: 15.71628, mean: 0.01007
[32m[0906 15-12-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 21.26452, mean: 0.01321
[32m[0906 15-12-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01894, current rewards: 26.81035, mean: 0.01615
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: 32.35584, mean: 0.01892
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01895, current rewards: 37.89843, mean: 0.02153
[32m[0906 15-12-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: 43.45181, mean: 0.02401
[32m[0906 15-12-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: 49.00991, mean: 0.02635
[32m[0906 15-12-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01897, current rewards: 54.64801, mean: 0.02861
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 60.21022, mean: 0.03072
[32m[0906 15-12-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01898, current rewards: 65.77946, mean: 0.03273
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: 71.34640, mean: 0.03463
[32m[0906 15-12-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01900, current rewards: 76.91465, mean: 0.03645
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01900, current rewards: 82.47581, mean: 0.03818
[32m[0906 15-12-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01901, current rewards: 88.04074, mean: 0.03984
[32m[0906 15-12-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01901, current rewards: 93.60384, mean: 0.04142
[32m[0906 15-12-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01901, current rewards: 99.10732, mean: 0.04290
[32m[0906 15-13-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01902, current rewards: 104.66558, mean: 0.04435
[32m[0906 15-13-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01902, current rewards: 110.22287, mean: 0.04574
[32m[0906 15-13-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01902, current rewards: 115.77770, mean: 0.04706
[32m[0906 15-13-03 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-13-03 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-13-03 @MBExp.py:227][0m Rewards obtained: [120.22682644591507], Lows: [1], Highs: [145], Total time: 2545.592497999999
[32m[0906 15-14-58 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-58 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01893, current rewards: 1.05667, mean: 0.10567
[32m[0906 15-14-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 6.59736, mean: 0.10996
[32m[0906 15-15-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 12.13626, mean: 0.11033
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01916, current rewards: 17.66872, mean: 0.11043
[32m[0906 15-15-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 23.22824, mean: 0.11061
[32m[0906 15-15-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 28.84176, mean: 0.11093
[32m[0906 15-15-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 34.39036, mean: 0.11094
[32m[0906 15-15-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 39.93940, mean: 0.11094
[32m[0906 15-15-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.48883, mean: 0.11095
[32m[0906 15-15-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.04244, mean: 0.11096
[32m[0906 15-15-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.59097, mean: 0.11096
[32m[0906 15-15-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 62.13284, mean: 0.11095
[32m[0906 15-15-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01906, current rewards: 67.67985, mean: 0.11095
[32m[0906 15-15-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01903, current rewards: 73.33391, mean: 0.11111
[32m[0906 15-15-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01900, current rewards: 78.92560, mean: 0.11116
[32m[0906 15-15-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01896, current rewards: 84.51727, mean: 0.11121
[32m[0906 15-15-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01894, current rewards: 90.11077, mean: 0.11125
[32m[0906 15-15-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01891, current rewards: 95.70749, mean: 0.11129
[32m[0906 15-15-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01889, current rewards: 101.38374, mean: 0.11141
[32m[0906 15-15-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01886, current rewards: 106.93951, mean: 0.11140
[32m[0906 15-15-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01885, current rewards: 112.49523, mean: 0.11138
[32m[0906 15-15-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01884, current rewards: 117.96923, mean: 0.11129
[32m[0906 15-15-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01883, current rewards: 123.47306, mean: 0.11124
[32m[0906 15-15-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01881, current rewards: 129.02567, mean: 0.11123
[32m[0906 15-15-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01880, current rewards: 134.56749, mean: 0.11121
[32m[0906 15-15-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01880, current rewards: 140.10085, mean: 0.11119
[32m[0906 15-15-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01881, current rewards: 145.62889, mean: 0.11117
[32m[0906 15-15-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01882, current rewards: 151.15894, mean: 0.11115
[32m[0906 15-15-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01883, current rewards: 156.68680, mean: 0.11113
[32m[0906 15-15-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01884, current rewards: 162.21405, mean: 0.11111
[32m[0906 15-15-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01885, current rewards: 167.86088, mean: 0.11117
[32m[0906 15-15-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01886, current rewards: 173.40236, mean: 0.11116
[32m[0906 15-15-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01888, current rewards: 178.94581, mean: 0.11115
[32m[0906 15-15-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01888, current rewards: 184.48819, mean: 0.11114
[32m[0906 15-15-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01889, current rewards: 190.16399, mean: 0.11121
[32m[0906 15-15-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01890, current rewards: 195.71575, mean: 0.11120
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01890, current rewards: 201.26978, mean: 0.11120
[32m[0906 15-15-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01892, current rewards: 206.82251, mean: 0.11119
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01893, current rewards: 212.37625, mean: 0.11119
[32m[0906 15-15-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01893, current rewards: 217.92489, mean: 0.11119
[32m[0906 15-15-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 223.47551, mean: 0.11118
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01895, current rewards: 229.02607, mean: 0.11118
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01895, current rewards: 234.58367, mean: 0.11118
[32m[0906 15-15-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: 240.13981, mean: 0.11118
[32m[0906 15-15-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01896, current rewards: 245.69878, mean: 0.11118
[32m[0906 15-15-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01896, current rewards: 249.14472, mean: 0.11024
[32m[0906 15-15-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01896, current rewards: 254.63438, mean: 0.11023
[32m[0906 15-15-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01897, current rewards: 260.17669, mean: 0.11024
[32m[0906 15-15-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01897, current rewards: 265.71890, mean: 0.11026
[32m[0906 15-15-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01898, current rewards: 271.25867, mean: 0.11027
[32m[0906 15-15-46 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-15-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-15-46 @MBExp.py:227][0m Rewards obtained: [275.6899014001122], Lows: [1], Highs: [0], Total time: 2593.773242999999
[32m[0906 15-17-43 @MBExp.py:144][0m ####################################################################
[32m[0906 15-17-43 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-17-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01852, current rewards: 1.09849, mean: 0.10985
[32m[0906 15-17-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01903, current rewards: 6.65096, mean: 0.11085
[32m[0906 15-17-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.20244, mean: 0.11093
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01905, current rewards: 17.75267, mean: 0.11095
[32m[0906 15-17-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 23.30680, mean: 0.11098
[32m[0906 15-17-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 28.84317, mean: 0.11094
[32m[0906 15-17-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.39865, mean: 0.11096
[32m[0906 15-17-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.98265, mean: 0.11106
[32m[0906 15-17-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.53277, mean: 0.11106
[32m[0906 15-17-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01910, current rewards: 51.08670, mean: 0.11106
[32m[0906 15-17-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01905, current rewards: 56.64916, mean: 0.11108
[32m[0906 15-17-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01902, current rewards: 62.20669, mean: 0.11108
[32m[0906 15-17-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01897, current rewards: 67.77154, mean: 0.11110
[32m[0906 15-17-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01895, current rewards: 73.28934, mean: 0.11104
[32m[0906 15-17-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01891, current rewards: 78.72658, mean: 0.11088
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01889, current rewards: 84.16361, mean: 0.11074
[32m[0906 15-17-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01887, current rewards: 89.60001, mean: 0.11062
[32m[0906 15-18-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01885, current rewards: 95.03797, mean: 0.11051
[32m[0906 15-18-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01884, current rewards: 100.47566, mean: 0.11041
[32m[0906 15-18-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01881, current rewards: 105.91414, mean: 0.11033
[32m[0906 15-18-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01880, current rewards: 111.35379, mean: 0.11025
[32m[0906 15-18-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01878, current rewards: 116.79109, mean: 0.11018
[32m[0906 15-18-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01877, current rewards: 121.15188, mean: 0.10915
[32m[0906 15-18-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01876, current rewards: 126.69613, mean: 0.10922
[32m[0906 15-18-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01875, current rewards: 132.24609, mean: 0.10929
[32m[0906 15-18-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01875, current rewards: 137.79236, mean: 0.10936
[32m[0906 15-18-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01877, current rewards: 143.33427, mean: 0.10942
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01878, current rewards: 148.88334, mean: 0.10947
[32m[0906 15-18-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01880, current rewards: 154.42855, mean: 0.10952
[32m[0906 15-18-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01882, current rewards: 159.88630, mean: 0.10951
[32m[0906 15-18-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01884, current rewards: 165.42321, mean: 0.10955
[32m[0906 15-18-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01885, current rewards: 170.96280, mean: 0.10959
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01886, current rewards: 176.50086, mean: 0.10963
[32m[0906 15-18-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01887, current rewards: 182.09280, mean: 0.10969
[32m[0906 15-18-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01888, current rewards: 187.62630, mean: 0.10972
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01888, current rewards: 193.16656, mean: 0.10975
[32m[0906 15-18-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01889, current rewards: 198.70232, mean: 0.10978
[32m[0906 15-18-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01890, current rewards: 204.27226, mean: 0.10982
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01891, current rewards: 209.82115, mean: 0.10985
[32m[0906 15-18-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01892, current rewards: 215.36885, mean: 0.10988
[32m[0906 15-18-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 220.91482, mean: 0.10991
[32m[0906 15-18-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01893, current rewards: 226.45686, mean: 0.10993
[32m[0906 15-18-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01894, current rewards: 231.99414, mean: 0.10995
[32m[0906 15-18-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: 237.52826, mean: 0.10997
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01895, current rewards: 243.07353, mean: 0.10999
[32m[0906 15-18-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01896, current rewards: 248.61089, mean: 0.11000
[32m[0906 15-18-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01897, current rewards: 254.20244, mean: 0.11004
[32m[0906 15-18-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01897, current rewards: 259.74928, mean: 0.11006
[32m[0906 15-18-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01898, current rewards: 265.27216, mean: 0.11007
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01899, current rewards: 270.81177, mean: 0.11009
[32m[0906 15-18-31 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-18-31 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-18-31 @MBExp.py:227][0m Rewards obtained: [275.24607105931653], Lows: [0], Highs: [1], Total time: 2641.9776739999993
[32m[0906 15-20-31 @MBExp.py:144][0m ####################################################################
[32m[0906 15-20-31 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-20-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01897, current rewards: 1.26355, mean: 0.12635
[32m[0906 15-20-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.71593, mean: 0.11193
[32m[0906 15-20-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01900, current rewards: 12.25703, mean: 0.11143
[32m[0906 15-20-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.79850, mean: 0.11124
[32m[0906 15-20-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 23.36078, mean: 0.11124
[32m[0906 15-20-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 28.94985, mean: 0.11135
[32m[0906 15-20-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.49744, mean: 0.11128
[32m[0906 15-20-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01903, current rewards: 40.04307, mean: 0.11123
[32m[0906 15-20-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01895, current rewards: 45.58588, mean: 0.11119
[32m[0906 15-20-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01892, current rewards: 51.12848, mean: 0.11115
[32m[0906 15-20-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01888, current rewards: 56.66594, mean: 0.11111
[32m[0906 15-20-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01883, current rewards: 62.21181, mean: 0.11109
[32m[0906 15-20-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01880, current rewards: 67.75773, mean: 0.11108
[32m[0906 15-20-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01878, current rewards: 73.32832, mean: 0.11110
[32m[0906 15-20-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01877, current rewards: 78.87394, mean: 0.11109
[32m[0906 15-20-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01876, current rewards: 84.42062, mean: 0.11108
[32m[0906 15-20-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01874, current rewards: 89.96793, mean: 0.11107
[32m[0906 15-20-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01873, current rewards: 95.51676, mean: 0.11107
[32m[0906 15-20-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01871, current rewards: 101.06369, mean: 0.11106
[32m[0906 15-20-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01870, current rewards: 106.60916, mean: 0.11105
[32m[0906 15-20-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01869, current rewards: 112.14087, mean: 0.11103
[32m[0906 15-20-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01868, current rewards: 117.70551, mean: 0.11104
[32m[0906 15-20-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01867, current rewards: 123.26465, mean: 0.11105
[32m[0906 15-20-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01867, current rewards: 128.81784, mean: 0.11105
[32m[0906 15-20-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01866, current rewards: 134.38283, mean: 0.11106
[32m[0906 15-20-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01867, current rewards: 139.93248, mean: 0.11106
[32m[0906 15-20-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01869, current rewards: 145.48948, mean: 0.11106
[32m[0906 15-20-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: 151.04562, mean: 0.11106
[32m[0906 15-20-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 156.60181, mean: 0.11107
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: 162.16261, mean: 0.11107
[32m[0906 15-20-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 167.68919, mean: 0.11105
[32m[0906 15-21-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01876, current rewards: 173.22889, mean: 0.11104
[32m[0906 15-21-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01877, current rewards: 178.77031, mean: 0.11104
[32m[0906 15-21-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01878, current rewards: 184.31184, mean: 0.11103
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: 189.85569, mean: 0.11103
[32m[0906 15-21-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: 195.39796, mean: 0.11102
[32m[0906 15-21-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01881, current rewards: 200.93629, mean: 0.11101
[32m[0906 15-21-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: 206.48256, mean: 0.11101
[32m[0906 15-21-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: 212.02473, mean: 0.11101
[32m[0906 15-21-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: 217.78926, mean: 0.11112
[32m[0906 15-21-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 223.34133, mean: 0.11112
[32m[0906 15-21-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 228.89317, mean: 0.11111
[32m[0906 15-21-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: 234.44548, mean: 0.11111
[32m[0906 15-21-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 239.99733, mean: 0.11111
[32m[0906 15-21-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 245.54917, mean: 0.11111
[32m[0906 15-21-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 251.10120, mean: 0.11111
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 256.65380, mean: 0.11111
[32m[0906 15-21-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 262.20583, mean: 0.11110
[32m[0906 15-21-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 267.75767, mean: 0.11110
[32m[0906 15-21-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 271.07251, mean: 0.11019
[32m[0906 15-21-19 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-21-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-21-19 @MBExp.py:227][0m Rewards obtained: [275.50855737990804], Lows: [0], Highs: [2], Total time: 2690.0254409999993
[32m[0906 15-23-20 @MBExp.py:144][0m ####################################################################
[32m[0906 15-23-20 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01837, current rewards: 1.20234, mean: 0.12023
[32m[0906 15-23-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01892, current rewards: 6.72870, mean: 0.11215
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01892, current rewards: 12.30566, mean: 0.11187
[32m[0906 15-23-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01900, current rewards: 17.88337, mean: 0.11177
[32m[0906 15-23-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01904, current rewards: 23.45198, mean: 0.11168
[32m[0906 15-23-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01890, current rewards: 29.02655, mean: 0.11164
[32m[0906 15-23-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01882, current rewards: 34.60515, mean: 0.11163
[32m[0906 15-23-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01876, current rewards: 40.17577, mean: 0.11160
[32m[0906 15-23-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01873, current rewards: 45.74855, mean: 0.11158
[32m[0906 15-23-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01874, current rewards: 51.31736, mean: 0.11156
[32m[0906 15-23-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01871, current rewards: 56.88670, mean: 0.11154
[32m[0906 15-23-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01872, current rewards: 62.47180, mean: 0.11156
[32m[0906 15-23-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01869, current rewards: 68.06110, mean: 0.11158
[32m[0906 15-23-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01867, current rewards: 73.69203, mean: 0.11165
[32m[0906 15-23-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01868, current rewards: 79.32385, mean: 0.11172
[32m[0906 15-23-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01866, current rewards: 84.95362, mean: 0.11178
[32m[0906 15-23-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01865, current rewards: 90.58610, mean: 0.11183
[32m[0906 15-23-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01864, current rewards: 96.21804, mean: 0.11188
[32m[0906 15-23-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01863, current rewards: 101.84914, mean: 0.11192
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01863, current rewards: 107.51921, mean: 0.11200
[32m[0906 15-23-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01862, current rewards: 113.09526, mean: 0.11198
[32m[0906 15-23-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01862, current rewards: 118.67215, mean: 0.11195
[32m[0906 15-23-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01862, current rewards: 124.25034, mean: 0.11194
[32m[0906 15-23-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 129.82860, mean: 0.11192
[32m[0906 15-23-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 134.31010, mean: 0.11100
[32m[0906 15-23-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01863, current rewards: 139.88586, mean: 0.11102
[32m[0906 15-23-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 145.46430, mean: 0.11104
[32m[0906 15-23-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01867, current rewards: 151.03589, mean: 0.11106
[32m[0906 15-23-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: 156.61492, mean: 0.11107
[32m[0906 15-23-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: 162.18994, mean: 0.11109
[32m[0906 15-23-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01873, current rewards: 167.76249, mean: 0.11110
[32m[0906 15-23-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 173.35128, mean: 0.11112
[32m[0906 15-23-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: 178.93870, mean: 0.11114
[32m[0906 15-23-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01878, current rewards: 184.52395, mean: 0.11116
[32m[0906 15-23-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: 190.10511, mean: 0.11117
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01881, current rewards: 195.70156, mean: 0.11119
[32m[0906 15-23-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: 201.37574, mean: 0.11126
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 206.96060, mean: 0.11127
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: 212.54118, mean: 0.11128
[32m[0906 15-23-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: 218.12988, mean: 0.11129
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 223.71863, mean: 0.11130
[32m[0906 15-23-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 229.30238, mean: 0.11131
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: 234.88724, mean: 0.11132
[32m[0906 15-24-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: 240.46419, mean: 0.11133
[32m[0906 15-24-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: 245.99268, mean: 0.11131
[32m[0906 15-24-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 251.56980, mean: 0.11131
[32m[0906 15-24-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 257.15669, mean: 0.11132
[32m[0906 15-24-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 262.73582, mean: 0.11133
[32m[0906 15-24-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 268.31358, mean: 0.11133
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 273.89525, mean: 0.11134
[32m[0906 15-24-08 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-24-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-24-08 @MBExp.py:227][0m Rewards obtained: [278.3598956342956], Lows: [0], Highs: [1], Total time: 2738.0437379999994
[32m[0906 15-26-11 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-11 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-26-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01915, current rewards: 1.12250, mean: 0.11225
[32m[0906 15-26-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 6.69089, mean: 0.11151
[32m[0906 15-26-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01913, current rewards: 12.21435, mean: 0.11104
[32m[0906 15-26-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01882, current rewards: 17.67985, mean: 0.11050
[32m[0906 15-26-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01881, current rewards: 23.21051, mean: 0.11053
[32m[0906 15-26-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01877, current rewards: 28.70923, mean: 0.11042
[32m[0906 15-26-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01876, current rewards: 34.23772, mean: 0.11044
[32m[0906 15-26-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01871, current rewards: 39.76550, mean: 0.11046
[32m[0906 15-26-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01870, current rewards: 45.28492, mean: 0.11045
[32m[0906 15-26-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01869, current rewards: 50.80776, mean: 0.11045
[32m[0906 15-26-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01869, current rewards: 56.32553, mean: 0.11044
[32m[0906 15-26-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01869, current rewards: 61.92118, mean: 0.11057
[32m[0906 15-26-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01869, current rewards: 67.50513, mean: 0.11066
[32m[0906 15-26-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01869, current rewards: 73.04520, mean: 0.11067
[32m[0906 15-26-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01870, current rewards: 78.58908, mean: 0.11069
[32m[0906 15-26-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01869, current rewards: 84.12935, mean: 0.11070
[32m[0906 15-26-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01868, current rewards: 89.66801, mean: 0.11070
[32m[0906 15-26-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01869, current rewards: 95.20814, mean: 0.11071
[32m[0906 15-26-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01869, current rewards: 100.74679, mean: 0.11071
[32m[0906 15-26-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01867, current rewards: 106.29002, mean: 0.11072
[32m[0906 15-26-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01867, current rewards: 111.83124, mean: 0.11072
[32m[0906 15-26-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01867, current rewards: 117.37183, mean: 0.11073
[32m[0906 15-26-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01866, current rewards: 122.89935, mean: 0.11072
[32m[0906 15-26-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01866, current rewards: 128.43976, mean: 0.11072
[32m[0906 15-26-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01865, current rewards: 133.98390, mean: 0.11073
[32m[0906 15-26-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01866, current rewards: 139.52478, mean: 0.11073
[32m[0906 15-26-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01869, current rewards: 145.19526, mean: 0.11084
[32m[0906 15-26-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: 150.68373, mean: 0.11080
[32m[0906 15-26-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01872, current rewards: 156.22979, mean: 0.11080
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: 161.78126, mean: 0.11081
[32m[0906 15-26-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01875, current rewards: 167.33112, mean: 0.11082
[32m[0906 15-26-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01877, current rewards: 172.88207, mean: 0.11082
[32m[0906 15-26-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: 178.43242, mean: 0.11083
[32m[0906 15-26-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01880, current rewards: 183.98167, mean: 0.11083
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01881, current rewards: 189.53159, mean: 0.11084
[32m[0906 15-26-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01882, current rewards: 195.06961, mean: 0.11084
[32m[0906 15-26-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01883, current rewards: 200.59055, mean: 0.11082
[32m[0906 15-26-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 205.02091, mean: 0.11023
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01885, current rewards: 210.53306, mean: 0.11023
[32m[0906 15-26-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01885, current rewards: 216.04957, mean: 0.11023
[32m[0906 15-26-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 221.56758, mean: 0.11023
[32m[0906 15-26-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 227.08017, mean: 0.11023
[32m[0906 15-26-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 232.60703, mean: 0.11024
[32m[0906 15-26-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 238.12914, mean: 0.11024
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 243.74602, mean: 0.11029
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 249.28107, mean: 0.11030
[32m[0906 15-26-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 254.81678, mean: 0.11031
[32m[0906 15-26-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 260.35284, mean: 0.11032
[32m[0906 15-26-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: 265.88838, mean: 0.11033
[32m[0906 15-26-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 271.42767, mean: 0.11034
[32m[0906 15-26-59 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-26-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-26-59 @MBExp.py:227][0m Rewards obtained: [275.85074448698714], Lows: [0], Highs: [1], Total time: 2786.1224049999996
[32m[0906 15-29-04 @MBExp.py:144][0m ####################################################################
[32m[0906 15-29-04 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 15-29-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01964, current rewards: 1.08490, mean: 0.10849
[32m[0906 15-29-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01868, current rewards: 6.61453, mean: 0.11024
[32m[0906 15-29-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01867, current rewards: 12.10964, mean: 0.11009
[32m[0906 15-29-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: 17.63704, mean: 0.11023
[32m[0906 15-29-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01860, current rewards: 23.16379, mean: 0.11030
[32m[0906 15-29-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01861, current rewards: 28.69494, mean: 0.11037
[32m[0906 15-29-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01860, current rewards: 34.22746, mean: 0.11041
[32m[0906 15-29-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01860, current rewards: 39.75692, mean: 0.11044
[32m[0906 15-29-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01861, current rewards: 45.23493, mean: 0.11033
[32m[0906 15-29-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01864, current rewards: 50.74636, mean: 0.11032
[32m[0906 15-29-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01864, current rewards: 56.29641, mean: 0.11039
[32m[0906 15-29-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01861, current rewards: 61.91144, mean: 0.11056
[32m[0906 15-29-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01861, current rewards: 67.45368, mean: 0.11058
[32m[0906 15-29-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01860, current rewards: 72.99722, mean: 0.11060
[32m[0906 15-29-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01862, current rewards: 78.54201, mean: 0.11062
[32m[0906 15-29-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01863, current rewards: 84.08796, mean: 0.11064
[32m[0906 15-29-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01862, current rewards: 89.63473, mean: 0.11066
[32m[0906 15-29-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01863, current rewards: 95.16259, mean: 0.11065
[32m[0906 15-29-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01863, current rewards: 100.71932, mean: 0.11068
[32m[0906 15-29-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01864, current rewards: 106.30478, mean: 0.11073
[32m[0906 15-29-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01864, current rewards: 111.86467, mean: 0.11076
[32m[0906 15-29-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01865, current rewards: 117.42776, mean: 0.11078
[32m[0906 15-29-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01864, current rewards: 122.98409, mean: 0.11080
[32m[0906 15-29-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 128.54356, mean: 0.11081
[32m[0906 15-29-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: 134.10067, mean: 0.11083
[32m[0906 15-29-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01866, current rewards: 139.62381, mean: 0.11081
[32m[0906 15-29-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01868, current rewards: 145.16713, mean: 0.11081
[32m[0906 15-29-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: 150.60447, mean: 0.11074
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01872, current rewards: 156.09899, mean: 0.11071
[32m[0906 15-29-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: 161.61364, mean: 0.11069
[32m[0906 15-29-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01875, current rewards: 167.12696, mean: 0.11068
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01877, current rewards: 172.63948, mean: 0.11067
[32m[0906 15-29-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: 178.15622, mean: 0.11066
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01879, current rewards: 183.66438, mean: 0.11064
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01881, current rewards: 189.17570, mean: 0.11063
[32m[0906 15-29-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01882, current rewards: 194.68948, mean: 0.11062
[32m[0906 15-29-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01883, current rewards: 200.30772, mean: 0.11067
[32m[0906 15-29-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01885, current rewards: 205.90414, mean: 0.11070
[32m[0906 15-29-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01885, current rewards: 211.46416, mean: 0.11071
[32m[0906 15-29-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01887, current rewards: 217.02074, mean: 0.11072
[32m[0906 15-29-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01888, current rewards: 222.58026, mean: 0.11074
[32m[0906 15-29-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 228.13990, mean: 0.11075
[32m[0906 15-29-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 233.70086, mean: 0.11076
[32m[0906 15-29-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01890, current rewards: 239.25708, mean: 0.11077
[32m[0906 15-29-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 244.77771, mean: 0.11076
[32m[0906 15-29-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 250.32334, mean: 0.11076
[32m[0906 15-29-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 255.86830, mean: 0.11077
[32m[0906 15-29-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 261.40052, mean: 0.11076
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: 266.94225, mean: 0.11076
[32m[0906 15-29-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 272.47825, mean: 0.11076
[32m[0906 15-29-52 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-29-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-29-52 @MBExp.py:227][0m Rewards obtained: [276.91645974662936], Lows: [0], Highs: [0], Total time: 2834.2068889999996
[32m[0906 15-31-59 @MBExp.py:144][0m ####################################################################
[32m[0906 15-31-59 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 15-31-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01827, current rewards: 1.05982, mean: 0.10598
[32m[0906 15-32-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01842, current rewards: 6.54185, mean: 0.10903
[32m[0906 15-32-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01839, current rewards: 12.04980, mean: 0.10954
[32m[0906 15-32-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 17.65581, mean: 0.11035
[32m[0906 15-32-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.16215, mean: 0.11030
[32m[0906 15-32-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 28.67619, mean: 0.11029
[32m[0906 15-32-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.18164, mean: 0.11026
[32m[0906 15-32-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.71450, mean: 0.11032
[32m[0906 15-32-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 45.24554, mean: 0.11035
[32m[0906 15-32-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.77672, mean: 0.11038
[32m[0906 15-32-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 56.30470, mean: 0.11040
[32m[0906 15-32-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 61.70179, mean: 0.11018
[32m[0906 15-32-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 67.23790, mean: 0.11023
[32m[0906 15-32-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 72.76659, mean: 0.11025
[32m[0906 15-32-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 78.30303, mean: 0.11029
[32m[0906 15-32-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 83.83881, mean: 0.11031
[32m[0906 15-32-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 89.37261, mean: 0.11034
[32m[0906 15-32-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 94.90465, mean: 0.11035
[32m[0906 15-32-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 100.43755, mean: 0.11037
[32m[0906 15-32-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 105.96243, mean: 0.11038
[32m[0906 15-32-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 111.49623, mean: 0.11039
[32m[0906 15-32-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 117.02752, mean: 0.11040
[32m[0906 15-32-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: 122.56128, mean: 0.11042
[32m[0906 15-32-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 128.09030, mean: 0.11042
[32m[0906 15-32-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 133.61712, mean: 0.11043
[32m[0906 15-32-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01854, current rewards: 139.15729, mean: 0.11044
[32m[0906 15-32-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 144.69419, mean: 0.11045
[32m[0906 15-32-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: 150.23939, mean: 0.11047
[32m[0906 15-32-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 155.87334, mean: 0.11055
[32m[0906 15-32-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01862, current rewards: 161.40916, mean: 0.11055
[32m[0906 15-32-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01865, current rewards: 166.94731, mean: 0.11056
[32m[0906 15-32-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01866, current rewards: 172.48082, mean: 0.11056
[32m[0906 15-32-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01868, current rewards: 178.01845, mean: 0.11057
[32m[0906 15-32-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01869, current rewards: 183.55376, mean: 0.11057
[32m[0906 15-32-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01870, current rewards: 189.11072, mean: 0.11059
[32m[0906 15-32-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01872, current rewards: 194.66386, mean: 0.11060
[32m[0906 15-32-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01873, current rewards: 200.09315, mean: 0.11055
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01874, current rewards: 205.62003, mean: 0.11055
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01875, current rewards: 211.14798, mean: 0.11055
[32m[0906 15-32-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 216.68443, mean: 0.11055
[32m[0906 15-32-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01878, current rewards: 222.21821, mean: 0.11056
[32m[0906 15-32-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01878, current rewards: 227.75134, mean: 0.11056
[32m[0906 15-32-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01879, current rewards: 233.28309, mean: 0.11056
[32m[0906 15-32-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 238.81695, mean: 0.11056
[32m[0906 15-32-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 244.36372, mean: 0.11057
[32m[0906 15-32-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 249.89941, mean: 0.11057
[32m[0906 15-32-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 255.43515, mean: 0.11058
[32m[0906 15-32-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: 261.01484, mean: 0.11060
[32m[0906 15-32-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 266.60949, mean: 0.11063
[32m[0906 15-32-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 272.20553, mean: 0.11065
[32m[0906 15-32-47 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-32-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-32-47 @MBExp.py:227][0m Rewards obtained: [276.6850568626674], Lows: [0], Highs: [0], Total time: 2882.0816749999994
[32m[0906 15-34-56 @MBExp.py:144][0m ####################################################################
[32m[0906 15-34-56 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 15-34-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01906, current rewards: -0.75438, mean: -0.07544
[32m[0906 15-34-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01863, current rewards: 4.78769, mean: 0.07979
[32m[0906 15-34-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01863, current rewards: 10.34298, mean: 0.09403
[32m[0906 15-34-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 15.95480, mean: 0.09972
[32m[0906 15-34-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 21.52487, mean: 0.10250
[32m[0906 15-35-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 27.09468, mean: 0.10421
[32m[0906 15-35-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 32.66494, mean: 0.10537
[32m[0906 15-35-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 38.23490, mean: 0.10621
[32m[0906 15-35-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 43.80493, mean: 0.10684
[32m[0906 15-35-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 47.15471, mean: 0.10251
[32m[0906 15-35-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 52.72016, mean: 0.10337
[32m[0906 15-35-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 58.31634, mean: 0.10414
[32m[0906 15-35-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 63.88528, mean: 0.10473
[32m[0906 15-35-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 69.45295, mean: 0.10523
[32m[0906 15-35-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 75.01696, mean: 0.10566
[32m[0906 15-35-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 80.58311, mean: 0.10603
[32m[0906 15-35-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 86.15267, mean: 0.10636
[32m[0906 15-35-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 91.72386, mean: 0.10666
[32m[0906 15-35-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 97.28853, mean: 0.10691
[32m[0906 15-35-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 102.76791, mean: 0.10705
[32m[0906 15-35-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 108.29415, mean: 0.10722
[32m[0906 15-35-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 113.82660, mean: 0.10738
[32m[0906 15-35-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 119.36446, mean: 0.10754
[32m[0906 15-35-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: 124.90826, mean: 0.10768
[32m[0906 15-35-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01850, current rewards: 130.66545, mean: 0.10799
[32m[0906 15-35-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 136.14186, mean: 0.10805
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01854, current rewards: 141.61835, mean: 0.10811
[32m[0906 15-35-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01856, current rewards: 147.10321, mean: 0.10816
[32m[0906 15-35-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01859, current rewards: 152.58279, mean: 0.10821
[32m[0906 15-35-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: 158.06310, mean: 0.10826
[32m[0906 15-35-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01863, current rewards: 163.53873, mean: 0.10830
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01864, current rewards: 169.01302, mean: 0.10834
[32m[0906 15-35-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01866, current rewards: 174.49030, mean: 0.10838
[32m[0906 15-35-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01868, current rewards: 179.97338, mean: 0.10842
[32m[0906 15-35-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01869, current rewards: 185.45574, mean: 0.10845
[32m[0906 15-35-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01871, current rewards: 190.92845, mean: 0.10848
[32m[0906 15-35-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01872, current rewards: 196.48364, mean: 0.10855
[32m[0906 15-35-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01873, current rewards: 202.01850, mean: 0.10861
[32m[0906 15-35-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01875, current rewards: 207.54327, mean: 0.10866
[32m[0906 15-35-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01876, current rewards: 213.07115, mean: 0.10871
[32m[0906 15-35-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01878, current rewards: 218.60517, mean: 0.10876
[32m[0906 15-35-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01879, current rewards: 224.14397, mean: 0.10881
[32m[0906 15-35-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: 229.67800, mean: 0.10885
[32m[0906 15-35-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 235.25278, mean: 0.10891
[32m[0906 15-35-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01882, current rewards: 240.78188, mean: 0.10895
[32m[0906 15-35-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 246.33112, mean: 0.10900
[32m[0906 15-35-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 251.87978, mean: 0.10904
[32m[0906 15-35-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: 257.42968, mean: 0.10908
[32m[0906 15-35-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 262.97650, mean: 0.10912
[32m[0906 15-35-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 268.52597, mean: 0.10916
[32m[0906 15-35-43 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-35-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-35-43 @MBExp.py:227][0m Rewards obtained: [272.9632295363051], Lows: [1], Highs: [2], Total time: 2929.9639719999996
[32m[0906 15-37-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-37-54 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 15-37-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01878, current rewards: 1.56025, mean: 0.15602
[32m[0906 15-37-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 7.00521, mean: 0.11675
[32m[0906 15-37-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 12.43827, mean: 0.11308
[32m[0906 15-37-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01850, current rewards: 17.88268, mean: 0.11177
[32m[0906 15-37-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01857, current rewards: 23.32735, mean: 0.11108
[32m[0906 15-37-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01853, current rewards: 28.77252, mean: 0.11066
[32m[0906 15-38-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01856, current rewards: 34.22058, mean: 0.11039
[32m[0906 15-38-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 39.67010, mean: 0.11019
[32m[0906 15-38-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: 45.22935, mean: 0.11032
[32m[0906 15-38-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 50.69660, mean: 0.11021
[32m[0906 15-38-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 56.19659, mean: 0.11019
[32m[0906 15-38-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 61.67698, mean: 0.11014
[32m[0906 15-38-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 67.16143, mean: 0.11010
[32m[0906 15-38-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 72.64859, mean: 0.11007
[32m[0906 15-38-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 78.13440, mean: 0.11005
[32m[0906 15-38-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 83.61834, mean: 0.11002
[32m[0906 15-38-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 89.10584, mean: 0.11001
[32m[0906 15-38-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 94.59490, mean: 0.10999
[32m[0906 15-38-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 100.17496, mean: 0.11008
[32m[0906 15-38-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 105.75463, mean: 0.11016
[32m[0906 15-38-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 111.33159, mean: 0.11023
[32m[0906 15-38-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 116.91042, mean: 0.11029
[32m[0906 15-38-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 122.49094, mean: 0.11035
[32m[0906 15-38-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 128.07005, mean: 0.11041
[32m[0906 15-38-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 133.66484, mean: 0.11047
[32m[0906 15-38-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 139.22265, mean: 0.11049
[32m[0906 15-38-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 144.78067, mean: 0.11052
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 150.17640, mean: 0.11042
[32m[0906 15-38-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01865, current rewards: 155.66904, mean: 0.11040
[32m[0906 15-38-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01867, current rewards: 161.15991, mean: 0.11038
[32m[0906 15-38-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: 166.65734, mean: 0.11037
[32m[0906 15-38-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: 172.14669, mean: 0.11035
[32m[0906 15-38-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01872, current rewards: 177.64368, mean: 0.11034
[32m[0906 15-38-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: 183.14508, mean: 0.11033
[32m[0906 15-38-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 188.78345, mean: 0.11040
[32m[0906 15-38-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01876, current rewards: 194.35745, mean: 0.11043
[32m[0906 15-38-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 201.53432, mean: 0.11134
[32m[0906 15-38-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01878, current rewards: 209.18940, mean: 0.11247
[32m[0906 15-38-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01879, current rewards: 207.61967, mean: 0.10870
[32m[0906 15-38-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: 157.61967, mean: 0.08042
[32m[0906 15-38-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 107.61967, mean: 0.05354
[32m[0906 15-38-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 57.61967, mean: 0.02797
[32m[0906 15-38-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 7.61967, mean: 0.00361
[32m[0906 15-38-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: -42.38033, mean: -0.01962
[32m[0906 15-38-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: -92.38033, mean: -0.04180
[32m[0906 15-38-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: -142.38033, mean: -0.06300
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: -192.38033, mean: -0.08328
[32m[0906 15-38-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: -242.38033, mean: -0.10270
[32m[0906 15-38-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: -292.38033, mean: -0.12132
[32m[0906 15-38-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: -342.38033, mean: -0.13918
[32m[0906 15-38-42 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-38-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-38-42 @MBExp.py:227][0m Rewards obtained: [-382.3803292750136], Lows: [0], Highs: [598], Total time: 2977.8887909999994
[32m[0906 15-40-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-54 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 15-40-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01846, current rewards: 1.12577, mean: 0.11258
[32m[0906 15-40-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01833, current rewards: 6.66389, mean: 0.11106
[32m[0906 15-40-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01840, current rewards: 12.23227, mean: 0.11120
[32m[0906 15-40-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.78040, mean: 0.11113
[32m[0906 15-40-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.33083, mean: 0.11110
[32m[0906 15-40-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 28.88211, mean: 0.11109
[32m[0906 15-41-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.43898, mean: 0.11109
[32m[0906 15-41-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 39.95303, mean: 0.11098
[32m[0906 15-41-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.47575, mean: 0.11092
[32m[0906 15-41-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.99769, mean: 0.11086
[32m[0906 15-41-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 56.50723, mean: 0.11080
[32m[0906 15-41-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 61.98078, mean: 0.11068
[32m[0906 15-41-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 67.55739, mean: 0.11075
[32m[0906 15-41-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.13239, mean: 0.11081
[32m[0906 15-41-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 78.70598, mean: 0.11085
[32m[0906 15-41-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.28020, mean: 0.11090
[32m[0906 15-41-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 89.85793, mean: 0.11094
[32m[0906 15-41-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 95.43137, mean: 0.11097
[32m[0906 15-41-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 101.00588, mean: 0.11100
[32m[0906 15-41-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 106.69991, mean: 0.11115
[32m[0906 15-41-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 112.22490, mean: 0.11111
[32m[0906 15-41-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 117.73496, mean: 0.11107
[32m[0906 15-41-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 123.24903, mean: 0.11104
[32m[0906 15-41-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01854, current rewards: 128.79386, mean: 0.11103
[32m[0906 15-41-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 134.33871, mean: 0.11102
[32m[0906 15-41-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 139.88195, mean: 0.11102
[32m[0906 15-41-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 145.42682, mean: 0.11101
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 150.97054, mean: 0.11101
[32m[0906 15-41-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: 156.47445, mean: 0.11097
[32m[0906 15-41-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01865, current rewards: 162.04941, mean: 0.11099
[32m[0906 15-41-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01867, current rewards: 167.55392, mean: 0.11096
[32m[0906 15-41-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01869, current rewards: 173.05581, mean: 0.11093
[32m[0906 15-41-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01870, current rewards: 178.55569, mean: 0.11090
[32m[0906 15-41-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: 184.06514, mean: 0.11088
[32m[0906 15-41-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01873, current rewards: 189.56698, mean: 0.11086
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: 195.06798, mean: 0.11083
[32m[0906 15-41-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01876, current rewards: 200.58297, mean: 0.11082
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 206.05207, mean: 0.11078
[32m[0906 15-41-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: 211.58395, mean: 0.11078
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01879, current rewards: 217.11779, mean: 0.11077
[32m[0906 15-41-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01880, current rewards: 222.65127, mean: 0.11077
[32m[0906 15-41-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: 228.18189, mean: 0.11077
[32m[0906 15-41-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01882, current rewards: 233.71479, mean: 0.11077
[32m[0906 15-41-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: 239.24704, mean: 0.11076
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: 244.73900, mean: 0.11074
[32m[0906 15-41-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 250.27362, mean: 0.11074
[32m[0906 15-41-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 255.80829, mean: 0.11074
[32m[0906 15-41-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 261.34176, mean: 0.11074
[32m[0906 15-41-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 266.91285, mean: 0.11075
[32m[0906 15-41-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 272.49700, mean: 0.11077
[32m[0906 15-41-42 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-41-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-41-42 @MBExp.py:227][0m Rewards obtained: [276.9664554516593], Lows: [0], Highs: [0], Total time: 3025.8442199999995
[32m[0906 15-43-57 @MBExp.py:144][0m ####################################################################
[32m[0906 15-43-57 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 15-43-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01836, current rewards: 0.02151, mean: 0.00215
[32m[0906 15-43-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01861, current rewards: 5.62829, mean: 0.09380
[32m[0906 15-43-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01855, current rewards: 11.17538, mean: 0.10159
[32m[0906 15-44-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 16.66604, mean: 0.10416
[32m[0906 15-44-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 22.20491, mean: 0.10574
[32m[0906 15-44-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 27.72241, mean: 0.10662
[32m[0906 15-44-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 33.25696, mean: 0.10728
[32m[0906 15-44-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 38.79109, mean: 0.10775
[32m[0906 15-44-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 44.32120, mean: 0.10810
[32m[0906 15-44-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 49.85239, mean: 0.10837
[32m[0906 15-44-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 55.38514, mean: 0.10860
[32m[0906 15-44-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 60.92800, mean: 0.10880
[32m[0906 15-44-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 66.44790, mean: 0.10893
[32m[0906 15-44-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 71.96572, mean: 0.10904
[32m[0906 15-44-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 77.48551, mean: 0.10913
[32m[0906 15-44-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 83.00377, mean: 0.10922
[32m[0906 15-44-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 87.47014, mean: 0.10799
[32m[0906 15-44-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 93.03298, mean: 0.10818
[32m[0906 15-44-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 98.59211, mean: 0.10834
[32m[0906 15-44-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 104.13637, mean: 0.10848
[32m[0906 15-44-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 109.68970, mean: 0.10860
[32m[0906 15-44-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 115.25564, mean: 0.10873
[32m[0906 15-44-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 120.79553, mean: 0.10882
[32m[0906 15-44-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 126.33201, mean: 0.10891
[32m[0906 15-44-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: 131.87339, mean: 0.10899
[32m[0906 15-44-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: 137.41627, mean: 0.10906
[32m[0906 15-44-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 142.95252, mean: 0.10912
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 148.52436, mean: 0.10921
[32m[0906 15-44-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01865, current rewards: 154.06359, mean: 0.10926
[32m[0906 15-44-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01867, current rewards: 159.59877, mean: 0.10931
[32m[0906 15-44-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: 165.12832, mean: 0.10936
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: 170.66116, mean: 0.10940
[32m[0906 15-44-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01872, current rewards: 176.18873, mean: 0.10943
[32m[0906 15-44-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: 181.67004, mean: 0.10944
[32m[0906 15-44-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 187.19046, mean: 0.10947
[32m[0906 15-44-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01876, current rewards: 192.70798, mean: 0.10949
[32m[0906 15-44-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 198.22053, mean: 0.10951
[32m[0906 15-44-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01878, current rewards: 203.73937, mean: 0.10954
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: 209.25732, mean: 0.10956
[32m[0906 15-44-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: 214.77637, mean: 0.10958
[32m[0906 15-44-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 220.29472, mean: 0.10960
[32m[0906 15-44-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 225.81139, mean: 0.10962
[32m[0906 15-44-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 231.32529, mean: 0.10963
[32m[0906 15-44-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 237.07900, mean: 0.10976
[32m[0906 15-44-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 242.56213, mean: 0.10976
[32m[0906 15-44-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 248.09002, mean: 0.10977
[32m[0906 15-44-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 253.62662, mean: 0.10980
[32m[0906 15-44-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 259.16504, mean: 0.10982
[32m[0906 15-44-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 264.69326, mean: 0.10983
[32m[0906 15-44-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 270.22775, mean: 0.10985
[32m[0906 15-44-45 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-44-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-44-45 @MBExp.py:227][0m Rewards obtained: [274.64990125929864], Lows: [0], Highs: [2], Total time: 3073.8083739999993
[32m[0906 15-47-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-47-02 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01898, current rewards: 1.12130, mean: 0.11213
[32m[0906 15-47-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01862, current rewards: 6.70958, mean: 0.11183
[32m[0906 15-47-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01862, current rewards: 12.24281, mean: 0.11130
[32m[0906 15-47-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01863, current rewards: 17.78279, mean: 0.11114
[32m[0906 15-47-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01860, current rewards: 23.32207, mean: 0.11106
[32m[0906 15-47-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01858, current rewards: 28.86200, mean: 0.11101
[32m[0906 15-47-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 35.15422, mean: 0.11340
[32m[0906 15-47-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 40.73240, mean: 0.11315
[32m[0906 15-47-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 46.30907, mean: 0.11295
[32m[0906 15-47-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 51.89048, mean: 0.11281
[32m[0906 15-47-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 57.35845, mean: 0.11247
[32m[0906 15-47-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: 62.78880, mean: 0.11212
[32m[0906 15-47-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 68.21452, mean: 0.11183
[32m[0906 15-47-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 73.64067, mean: 0.11158
[32m[0906 15-47-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 79.07127, mean: 0.11137
[32m[0906 15-47-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: 84.49298, mean: 0.11117
[32m[0906 15-47-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: 88.62719, mean: 0.10942
[32m[0906 15-47-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 94.75518, mean: 0.11018
[32m[0906 15-47-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01858, current rewards: 100.88536, mean: 0.11086
[32m[0906 15-47-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 107.38978, mean: 0.11186
[32m[0906 15-47-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 110.74798, mean: 0.10965
[32m[0906 15-47-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 60.74798, mean: 0.05731
[32m[0906 15-47-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 10.74798, mean: 0.00968
[32m[0906 15-47-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: -39.25202, mean: -0.03384
[32m[0906 15-47-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01859, current rewards: -89.25202, mean: -0.07376
[32m[0906 15-47-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01861, current rewards: -139.25202, mean: -0.11052
[32m[0906 15-47-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: -185.96725, mean: -0.14196
[32m[0906 15-47-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01864, current rewards: -180.42337, mean: -0.13266
[32m[0906 15-47-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01867, current rewards: -174.87761, mean: -0.12403
[32m[0906 15-47-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: -169.33415, mean: -0.11598
[32m[0906 15-47-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: -163.79173, mean: -0.10847
[32m[0906 15-47-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01873, current rewards: -158.24883, mean: -0.10144
[32m[0906 15-47-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: -152.70609, mean: -0.09485
[32m[0906 15-47-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: -148.78205, mean: -0.08963
[32m[0906 15-47-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: -143.28067, mean: -0.08379
[32m[0906 15-47-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: -137.85179, mean: -0.07832
[32m[0906 15-47-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: -132.02526, mean: -0.07294
[32m[0906 15-47-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: -126.19510, mean: -0.06785
[32m[0906 15-47-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: -120.36768, mean: -0.06302
[32m[0906 15-47-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: -114.53818, mean: -0.05844
[32m[0906 15-47-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: -108.71024, mean: -0.05408
[32m[0906 15-47-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: -102.88892, mean: -0.04995
[32m[0906 15-47-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: -97.06021, mean: -0.04600
[32m[0906 15-47-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: -91.23386, mean: -0.04224
[32m[0906 15-47-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: -85.40606, mean: -0.03865
[32m[0906 15-47-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: -79.57119, mean: -0.03521
[32m[0906 15-47-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: -74.08575, mean: -0.03207
[32m[0906 15-47-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: -68.59745, mean: -0.02907
[32m[0906 15-47-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: -63.10878, mean: -0.02619
[32m[0906 15-47-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: -57.61756, mean: -0.02342
[32m[0906 15-47-50 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-47-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-47-50 @MBExp.py:227][0m Rewards obtained: [-53.22538840940627], Lows: [2], Highs: [300], Total time: 3121.840884999999
[32m[0906 15-50-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-50-09 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 15-50-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01834, current rewards: 1.90943, mean: 0.19094
[32m[0906 15-50-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01852, current rewards: 7.53434, mean: 0.12557
[32m[0906 15-50-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 13.19079, mean: 0.11992
[32m[0906 15-50-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 18.83697, mean: 0.11773
[32m[0906 15-50-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01852, current rewards: 24.48393, mean: 0.11659
[32m[0906 15-50-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 30.13013, mean: 0.11589
[32m[0906 15-50-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 35.77564, mean: 0.11541
[32m[0906 15-50-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 41.42154, mean: 0.11506
[32m[0906 15-50-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 47.06815, mean: 0.11480
[32m[0906 15-50-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 52.71440, mean: 0.11460
[32m[0906 15-50-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 17.21971, mean: 0.03376
[32m[0906 15-50-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: -32.78029, mean: -0.05854
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: -82.78029, mean: -0.13571
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: -132.78029, mean: -0.20118
[32m[0906 15-50-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: -182.78029, mean: -0.25744
[32m[0906 15-50-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: -232.78029, mean: -0.30629
[32m[0906 15-50-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: -282.78029, mean: -0.34911
[32m[0906 15-50-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: -332.78029, mean: -0.38695
[32m[0906 15-50-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: -382.78029, mean: -0.42064
[32m[0906 15-50-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: -432.78029, mean: -0.45081
[32m[0906 15-50-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: -482.78029, mean: -0.47800
[32m[0906 15-50-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: -532.78029, mean: -0.50262
[32m[0906 15-50-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: -582.78029, mean: -0.52503
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: -632.78029, mean: -0.54550
[32m[0906 15-50-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: -682.78029, mean: -0.56428
[32m[0906 15-50-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: -732.78029, mean: -0.58157
[32m[0906 15-50-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01859, current rewards: -782.78029, mean: -0.59754
[32m[0906 15-50-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: -832.78029, mean: -0.61234
[32m[0906 15-50-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: -882.78029, mean: -0.62609
[32m[0906 15-50-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01865, current rewards: -932.78029, mean: -0.63889
[32m[0906 15-50-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01867, current rewards: -982.78029, mean: -0.65085
[32m[0906 15-50-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01869, current rewards: -1032.78029, mean: -0.66204
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01871, current rewards: -1082.78029, mean: -0.67253
[32m[0906 15-50-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: -1132.78029, mean: -0.68240
[32m[0906 15-50-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01873, current rewards: -1182.78029, mean: -0.69168
[32m[0906 15-50-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: -1232.78029, mean: -0.70044
[32m[0906 15-50-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: -1282.78029, mean: -0.70872
[32m[0906 15-50-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01878, current rewards: -1332.78029, mean: -0.71655
[32m[0906 15-50-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: -1382.78029, mean: -0.72397
[32m[0906 15-50-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01879, current rewards: -1432.78029, mean: -0.73101
[32m[0906 15-50-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01880, current rewards: -1482.78029, mean: -0.73770
[32m[0906 15-50-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: -1532.78029, mean: -0.74407
[32m[0906 15-50-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01882, current rewards: -1568.99731, mean: -0.74360
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: -1563.36108, mean: -0.72378
[32m[0906 15-50-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: -1557.56585, mean: -0.70478
[32m[0906 15-50-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: -1551.77063, mean: -0.68662
[32m[0906 15-50-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: -1545.97540, mean: -0.66925
[32m[0906 15-50-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: -1540.18017, mean: -0.65262
[32m[0906 15-50-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: -1534.38494, mean: -0.63667
[32m[0906 15-50-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: -1528.58972, mean: -0.62138
[32m[0906 15-50-57 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-50-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-50-57 @MBExp.py:227][0m Rewards obtained: [-1523.9535327223255], Lows: [0], Highs: [1624], Total time: 3169.7633219999993
[32m[0906 15-53-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-53-18 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 15-53-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01861, current rewards: 0.03132, mean: 0.00313
[32m[0906 15-53-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01862, current rewards: 5.64033, mean: 0.09401
[32m[0906 15-53-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01857, current rewards: 11.20672, mean: 0.10188
[32m[0906 15-53-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01859, current rewards: 16.76575, mean: 0.10479
[32m[0906 15-53-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01859, current rewards: 22.33266, mean: 0.10635
[32m[0906 15-53-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 27.89692, mean: 0.10730
[32m[0906 15-53-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 33.46180, mean: 0.10794
[32m[0906 15-53-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.02078, mean: 0.10839
[32m[0906 15-53-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 44.56812, mean: 0.10870
[32m[0906 15-53-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 50.07785, mean: 0.10886
[32m[0906 15-53-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 55.63287, mean: 0.10908
[32m[0906 15-53-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 61.18557, mean: 0.10926
[32m[0906 15-53-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 66.73593, mean: 0.10940
[32m[0906 15-53-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 72.28698, mean: 0.10953
[32m[0906 15-53-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 77.83952, mean: 0.10963
[32m[0906 15-53-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 83.39535, mean: 0.10973
[32m[0906 15-53-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 88.94205, mean: 0.10981
[32m[0906 15-53-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 94.49972, mean: 0.10988
[32m[0906 15-53-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 100.05462, mean: 0.10995
[32m[0906 15-53-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 105.60468, mean: 0.11000
[32m[0906 15-53-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 111.15509, mean: 0.11005
[32m[0906 15-53-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 116.70844, mean: 0.11010
[32m[0906 15-53-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 122.26783, mean: 0.11015
[32m[0906 15-53-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: 127.81793, mean: 0.11019
[32m[0906 15-53-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 133.38501, mean: 0.11024
[32m[0906 15-53-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 138.91886, mean: 0.11025
[32m[0906 15-53-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 144.48812, mean: 0.11030
[32m[0906 15-53-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: 150.05012, mean: 0.11033
[32m[0906 15-53-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 155.61624, mean: 0.11037
[32m[0906 15-53-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 161.17894, mean: 0.11040
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01865, current rewards: 166.74353, mean: 0.11043
[32m[0906 15-53-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01867, current rewards: 172.30854, mean: 0.11045
[32m[0906 15-53-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01868, current rewards: 177.87168, mean: 0.11048
[32m[0906 15-53-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01870, current rewards: 183.51593, mean: 0.11055
[32m[0906 15-53-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 189.22979, mean: 0.11066
[32m[0906 15-53-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01872, current rewards: 194.73349, mean: 0.11064
[32m[0906 15-53-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01874, current rewards: 200.29913, mean: 0.11066
[32m[0906 15-53-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01875, current rewards: 205.86479, mean: 0.11068
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: 211.42971, mean: 0.11070
[32m[0906 15-53-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 216.99362, mean: 0.11071
[32m[0906 15-53-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01878, current rewards: 222.55846, mean: 0.11073
[32m[0906 15-53-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01879, current rewards: 228.75353, mean: 0.11105
[32m[0906 15-53-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01879, current rewards: 234.15151, mean: 0.11097
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 184.15151, mean: 0.08526
[32m[0906 15-54-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01880, current rewards: 134.15151, mean: 0.06070
[32m[0906 15-54-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 84.15151, mean: 0.03724
[32m[0906 15-54-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 34.15151, mean: 0.01478
[32m[0906 15-54-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01882, current rewards: -15.84849, mean: -0.00672
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01883, current rewards: -65.84849, mean: -0.02732
[32m[0906 15-54-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: -115.84849, mean: -0.04709
[32m[0906 15-54-06 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 15-54-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-54-06 @MBExp.py:227][0m Rewards obtained: [-155.84849429814977], Lows: [1], Highs: [392], Total time: 3217.627366999999
[32m[0906 15-56-29 @MBExp.py:144][0m ####################################################################
[32m[0906 15-56-29 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 15-56-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 1.15956, mean: 0.11596
[32m[0906 15-56-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01866, current rewards: 6.78905, mean: 0.11315
[32m[0906 15-56-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01855, current rewards: 12.36655, mean: 0.11242
[32m[0906 15-56-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 17.94415, mean: 0.11215
[32m[0906 15-56-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 23.51837, mean: 0.11199
[32m[0906 15-56-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 29.09684, mean: 0.11191
[32m[0906 15-56-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.67657, mean: 0.11186
[32m[0906 15-56-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.25476, mean: 0.11182
[32m[0906 15-56-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.83130, mean: 0.11178
[32m[0906 15-56-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 51.34871, mean: 0.11163
[32m[0906 15-56-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.88053, mean: 0.11153
[32m[0906 15-56-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 62.38418, mean: 0.11140
[32m[0906 15-56-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.88715, mean: 0.11129
[32m[0906 15-56-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 73.38927, mean: 0.11120
[32m[0906 15-56-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 78.89106, mean: 0.11111
[32m[0906 15-56-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.39174, mean: 0.11104
[32m[0906 15-56-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.89678, mean: 0.11098
[32m[0906 15-56-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 95.40870, mean: 0.11094
[32m[0906 15-56-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 101.02705, mean: 0.11102
[32m[0906 15-56-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 106.64512, mean: 0.11109
[32m[0906 15-56-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 112.26271, mean: 0.11115
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 117.88057, mean: 0.11121
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01849, current rewards: 123.49688, mean: 0.11126
[32m[0906 15-56-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: 129.11819, mean: 0.11131
[32m[0906 15-56-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 136.22007, mean: 0.11258
[32m[0906 15-56-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 144.52019, mean: 0.11470
[32m[0906 15-56-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01856, current rewards: 150.79649, mean: 0.11511
[32m[0906 15-56-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01859, current rewards: 156.39994, mean: 0.11500
[32m[0906 15-56-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01862, current rewards: 161.87539, mean: 0.11481
[32m[0906 15-56-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 167.40028, mean: 0.11466
[32m[0906 15-56-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01866, current rewards: 172.92871, mean: 0.11452
[32m[0906 15-56-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01868, current rewards: 178.45740, mean: 0.11440
[32m[0906 15-56-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01869, current rewards: 183.98243, mean: 0.11427
[32m[0906 15-57-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01871, current rewards: 189.51213, mean: 0.11416
[32m[0906 15-57-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01873, current rewards: 194.99957, mean: 0.11403
[32m[0906 15-57-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01874, current rewards: 200.52474, mean: 0.11393
[32m[0906 15-57-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01875, current rewards: 206.05434, mean: 0.11384
[32m[0906 15-57-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01876, current rewards: 211.58197, mean: 0.11375
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: 217.08333, mean: 0.11366
[32m[0906 15-57-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01878, current rewards: 222.60350, mean: 0.11357
[32m[0906 15-57-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01879, current rewards: 228.12053, mean: 0.11349
[32m[0906 15-57-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01880, current rewards: 233.64374, mean: 0.11342
[32m[0906 15-57-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: 239.14083, mean: 0.11334
[32m[0906 15-57-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01881, current rewards: 244.66051, mean: 0.11327
[32m[0906 15-57-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 250.18280, mean: 0.11320
[32m[0906 15-57-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 255.70201, mean: 0.11314
[32m[0906 15-57-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 261.22372, mean: 0.11308
[32m[0906 15-57-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: 266.74463, mean: 0.11303
[32m[0906 15-57-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 272.26636, mean: 0.11297
[32m[0906 15-57-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 277.78661, mean: 0.11292
[32m[0906 15-57-16 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-57-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-57-17 @MBExp.py:227][0m Rewards obtained: [282.2069424366114], Lows: [0], Highs: [0], Total time: 3265.557685999999
[32m[0906 15-59-42 @MBExp.py:144][0m ####################################################################
[32m[0906 15-59-42 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 15-59-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01892, current rewards: 1.09267, mean: 0.10927
[32m[0906 15-59-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01860, current rewards: 6.67237, mean: 0.11121
[32m[0906 15-59-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: 12.22260, mean: 0.11111
[32m[0906 15-59-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 17.76899, mean: 0.11106
[32m[0906 15-59-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 23.31709, mean: 0.11103
[32m[0906 15-59-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 28.82515, mean: 0.11087
[32m[0906 15-59-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 34.39318, mean: 0.11095
[32m[0906 15-59-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.96303, mean: 0.11101
[32m[0906 15-59-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.52576, mean: 0.11104
[32m[0906 15-59-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 51.06500, mean: 0.11101
[32m[0906 15-59-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.62125, mean: 0.11102
[32m[0906 15-59-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.18052, mean: 0.11104
[32m[0906 15-59-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 67.73736, mean: 0.11104
[32m[0906 15-59-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.29879, mean: 0.11106
[32m[0906 15-59-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 78.85615, mean: 0.11106
[32m[0906 15-59-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.41829, mean: 0.11108
[32m[0906 15-59-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 89.97434, mean: 0.11108
[32m[0906 15-59-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 95.52319, mean: 0.11107
[32m[0906 15-59-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 101.06318, mean: 0.11106
[32m[0906 16-00-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 106.60412, mean: 0.11105
[32m[0906 16-00-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 112.14348, mean: 0.11103
[32m[0906 16-00-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 117.68137, mean: 0.11102
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 123.22431, mean: 0.11101
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 128.76411, mean: 0.11100
[32m[0906 16-00-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 134.30175, mean: 0.11099
[32m[0906 16-00-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 139.84322, mean: 0.11099
[32m[0906 16-00-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 145.38422, mean: 0.11098
[32m[0906 16-00-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 150.92603, mean: 0.11098
[32m[0906 16-00-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01864, current rewards: 156.46760, mean: 0.11097
[32m[0906 16-00-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01866, current rewards: 162.00872, mean: 0.11096
[32m[0906 16-00-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01867, current rewards: 167.57028, mean: 0.11097
[32m[0906 16-00-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01869, current rewards: 173.13395, mean: 0.11098
[32m[0906 16-00-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01871, current rewards: 178.69623, mean: 0.11099
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: 184.29001, mean: 0.11102
[32m[0906 16-00-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01873, current rewards: 189.89402, mean: 0.11105
[32m[0906 16-00-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01874, current rewards: 195.47209, mean: 0.11106
[32m[0906 16-00-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01875, current rewards: 201.05106, mean: 0.11108
[32m[0906 16-00-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01876, current rewards: 207.71066, mean: 0.11167
[32m[0906 16-00-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01877, current rewards: 214.98487, mean: 0.11256
[32m[0906 16-00-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01878, current rewards: 222.25909, mean: 0.11340
[32m[0906 16-00-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01879, current rewards: 229.53330, mean: 0.11420
[32m[0906 16-00-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01880, current rewards: 236.80752, mean: 0.11496
[32m[0906 16-00-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 242.04805, mean: 0.11471
[32m[0906 16-00-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 246.74446, mean: 0.11423
[32m[0906 16-00-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 251.44087, mean: 0.11377
[32m[0906 16-00-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01883, current rewards: 256.13728, mean: 0.11334
[32m[0906 16-00-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 252.08227, mean: 0.10913
[32m[0906 16-00-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 202.08227, mean: 0.08563
[32m[0906 16-00-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: 152.08227, mean: 0.06310
[32m[0906 16-00-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 102.08227, mean: 0.04150
[32m[0906 16-00-29 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-00-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-00-30 @MBExp.py:227][0m Rewards obtained: [62.08226664812048], Lows: [0], Highs: [198], Total time: 3313.506718999999
[32m[0906 16-02-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-02-57 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: 1.06709, mean: 0.10671
[32m[0906 16-02-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01881, current rewards: 6.53512, mean: 0.10892
[32m[0906 16-02-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01863, current rewards: 12.05573, mean: 0.10960
[32m[0906 16-03-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 17.57620, mean: 0.10985
[32m[0906 16-03-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01860, current rewards: 23.09753, mean: 0.10999
[32m[0906 16-03-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01858, current rewards: 28.62057, mean: 0.11008
[32m[0906 16-03-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01856, current rewards: 34.13782, mean: 0.11012
[32m[0906 16-03-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01859, current rewards: 39.65890, mean: 0.11016
[32m[0906 16-03-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01858, current rewards: 45.18049, mean: 0.11020
[32m[0906 16-03-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 52.00986, mean: 0.11306
[32m[0906 16-03-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 60.08415, mean: 0.11781
[32m[0906 16-03-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 68.15843, mean: 0.12171
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 73.90975, mean: 0.12116
[32m[0906 16-03-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 71.49041, mean: 0.10832
[32m[0906 16-03-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 77.01152, mean: 0.10847
[32m[0906 16-03-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01856, current rewards: 82.53298, mean: 0.10860
[32m[0906 16-03-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01856, current rewards: 88.05633, mean: 0.10871
[32m[0906 16-03-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 93.57007, mean: 0.10880
[32m[0906 16-03-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 99.11171, mean: 0.10891
[32m[0906 16-03-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 104.65596, mean: 0.10902
[32m[0906 16-03-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 110.20153, mean: 0.10911
[32m[0906 16-03-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 115.74327, mean: 0.10919
[32m[0906 16-03-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 121.28604, mean: 0.10927
[32m[0906 16-03-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 126.83161, mean: 0.10934
[32m[0906 16-03-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: 132.37887, mean: 0.10940
[32m[0906 16-03-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 137.81389, mean: 0.10938
[32m[0906 16-03-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 143.33336, mean: 0.10941
[32m[0906 16-03-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01867, current rewards: 148.87420, mean: 0.10947
[32m[0906 16-03-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01869, current rewards: 154.41333, mean: 0.10951
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01870, current rewards: 159.95299, mean: 0.10956
[32m[0906 16-03-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01872, current rewards: 165.49181, mean: 0.10960
[32m[0906 16-03-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 171.03540, mean: 0.10964
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: 176.57421, mean: 0.10967
[32m[0906 16-03-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 182.12092, mean: 0.10971
[32m[0906 16-03-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: 187.66236, mean: 0.10974
[32m[0906 16-03-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 193.20482, mean: 0.10978
[32m[0906 16-03-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 198.74783, mean: 0.10981
[32m[0906 16-03-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: 204.29124, mean: 0.10983
[32m[0906 16-03-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 209.83199, mean: 0.10986
[32m[0906 16-03-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 215.36891, mean: 0.10988
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 221.28511, mean: 0.11009
[32m[0906 16-03-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 226.82168, mean: 0.11011
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 232.35990, mean: 0.11012
[32m[0906 16-03-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 237.89677, mean: 0.11014
[32m[0906 16-03-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 243.42500, mean: 0.11015
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: 248.96246, mean: 0.11016
[32m[0906 16-03-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 254.49969, mean: 0.11017
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 260.03396, mean: 0.11018
[32m[0906 16-03-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 265.56812, mean: 0.11019
[32m[0906 16-03-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 271.10052, mean: 0.11020
[32m[0906 16-03-45 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-03-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-03-45 @MBExp.py:227][0m Rewards obtained: [275.52660791273917], Lows: [0], Highs: [9], Total time: 3361.558303999999
[32m[0906 16-06-14 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-14 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-06-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01927, current rewards: 0.01249, mean: 0.00125
[32m[0906 16-06-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01860, current rewards: 5.53079, mean: 0.09218
[32m[0906 16-06-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01861, current rewards: 11.02042, mean: 0.10019
[32m[0906 16-06-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01858, current rewards: 16.51000, mean: 0.10319
[32m[0906 16-06-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 22.00146, mean: 0.10477
[32m[0906 16-06-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 27.48934, mean: 0.10573
[32m[0906 16-06-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 32.97866, mean: 0.10638
[32m[0906 16-06-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 38.46938, mean: 0.10686
[32m[0906 16-06-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 44.25592, mean: 0.10794
[32m[0906 16-06-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.57135, mean: 0.10994
[32m[0906 16-06-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 2.82397, mean: 0.00554
[32m[0906 16-06-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: -47.17603, mean: -0.08424
[32m[0906 16-06-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: -97.17603, mean: -0.15930
[32m[0906 16-06-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: -101.51766, mean: -0.15381
[32m[0906 16-06-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: -95.86761, mean: -0.13502
[32m[0906 16-06-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: -90.27814, mean: -0.11879
[32m[0906 16-06-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: -84.75024, mean: -0.10463
[32m[0906 16-06-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: -79.16679, mean: -0.09205
[32m[0906 16-06-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: -73.58369, mean: -0.08086
[32m[0906 16-06-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: -67.99958, mean: -0.07083
[32m[0906 16-06-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: -62.41918, mean: -0.06180
[32m[0906 16-06-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: -56.83477, mean: -0.05362
[32m[0906 16-06-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: -51.25193, mean: -0.04617
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: -45.66594, mean: -0.03937
[32m[0906 16-06-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: -40.07938, mean: -0.03312
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: -34.43249, mean: -0.02733
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01862, current rewards: -28.81723, mean: -0.02200
[32m[0906 16-06-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: -23.19099, mean: -0.01705
[32m[0906 16-06-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01865, current rewards: -17.56107, mean: -0.01245
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01866, current rewards: -11.93469, mean: -0.00817
[32m[0906 16-06-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01868, current rewards: -6.30340, mean: -0.00417
[32m[0906 16-06-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: -0.67832, mean: -0.00043
[32m[0906 16-06-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01871, current rewards: 4.95349, mean: 0.00308
[32m[0906 16-06-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: 10.52118, mean: 0.00634
[32m[0906 16-06-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 16.16442, mean: 0.00945
[32m[0906 16-06-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01876, current rewards: 21.70868, mean: 0.01233
[32m[0906 16-06-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 27.25656, mean: 0.01506
[32m[0906 16-06-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 32.81136, mean: 0.01764
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 38.36812, mean: 0.02009
[32m[0906 16-06-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 43.92014, mean: 0.02241
[32m[0906 16-06-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 49.48117, mean: 0.02462
[32m[0906 16-06-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 55.03146, mean: 0.02671
[32m[0906 16-06-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 60.59294, mean: 0.02872
[32m[0906 16-06-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 66.17423, mean: 0.03064
[32m[0906 16-06-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 71.76049, mean: 0.03247
[32m[0906 16-06-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 77.34493, mean: 0.03422
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 82.92465, mean: 0.03590
[32m[0906 16-06-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 88.50646, mean: 0.03750
[32m[0906 16-07-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 94.08936, mean: 0.03904
[32m[0906 16-07-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 99.67715, mean: 0.04052
[32m[0906 16-07-02 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-07-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-07-02 @MBExp.py:227][0m Rewards obtained: [104.12640634734133], Lows: [0], Highs: [158], Total time: 3409.5573289999993
[32m[0906 16-09-33 @MBExp.py:144][0m ####################################################################
[32m[0906 16-09-33 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-09-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01809, current rewards: 1.32937, mean: 0.13294
[32m[0906 16-09-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01832, current rewards: 6.89162, mean: 0.11486
[32m[0906 16-09-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 12.45216, mean: 0.11320
[32m[0906 16-09-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 18.01706, mean: 0.11261
[32m[0906 16-09-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 23.54001, mean: 0.11210
[32m[0906 16-09-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 29.09828, mean: 0.11192
[32m[0906 16-09-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.65457, mean: 0.11179
[32m[0906 16-09-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 40.16216, mean: 0.11156
[32m[0906 16-09-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 45.65388, mean: 0.11135
[32m[0906 16-09-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.18764, mean: 0.11128
[32m[0906 16-09-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 56.70835, mean: 0.11119
[32m[0906 16-09-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.23003, mean: 0.11113
[32m[0906 16-09-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.75213, mean: 0.11107
[32m[0906 16-09-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 73.27412, mean: 0.11102
[32m[0906 16-09-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 78.79665, mean: 0.11098
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 84.31643, mean: 0.11094
[32m[0906 16-09-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 90.44569, mean: 0.11166
[32m[0906 16-09-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 97.20973, mean: 0.11303
[32m[0906 16-09-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 103.97377, mean: 0.11426
[32m[0906 16-09-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 110.73781, mean: 0.11535
[32m[0906 16-09-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 107.28432, mean: 0.10622
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 57.28432, mean: 0.05404
[32m[0906 16-09-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 7.28432, mean: 0.00656
[32m[0906 16-09-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: -42.71568, mean: -0.03682
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: -92.71568, mean: -0.07662
[32m[0906 16-09-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01863, current rewards: -110.52260, mean: -0.08772
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01866, current rewards: -104.97292, mean: -0.08013
[32m[0906 16-09-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01867, current rewards: -99.41797, mean: -0.07310
[32m[0906 16-09-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01869, current rewards: -93.86907, mean: -0.06657
[32m[0906 16-10-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01870, current rewards: -88.31795, mean: -0.06049
[32m[0906 16-10-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: -82.76539, mean: -0.05481
[32m[0906 16-10-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: -77.21347, mean: -0.04950
[32m[0906 16-10-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01873, current rewards: -71.66141, mean: -0.04451
[32m[0906 16-10-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: -66.13337, mean: -0.03984
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: -60.43404, mean: -0.03534
[32m[0906 16-10-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: -54.90535, mean: -0.03120
[32m[0906 16-10-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: -49.36651, mean: -0.02727
[32m[0906 16-10-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: -43.83066, mean: -0.02356
[32m[0906 16-10-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: -38.29618, mean: -0.02005
[32m[0906 16-10-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: -32.76051, mean: -0.01671
[32m[0906 16-10-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: -27.22707, mean: -0.01355
[32m[0906 16-10-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: -21.64801, mean: -0.01051
[32m[0906 16-10-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: -16.11239, mean: -0.00764
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: -10.57194, mean: -0.00489
[32m[0906 16-10-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: -5.06566, mean: -0.00229
[32m[0906 16-10-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 0.47610, mean: 0.00021
[32m[0906 16-10-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 6.02092, mean: 0.00261
[32m[0906 16-10-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 11.56526, mean: 0.00490
[32m[0906 16-10-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 17.10835, mean: 0.00710
[32m[0906 16-10-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 22.72686, mean: 0.00924
[32m[0906 16-10-21 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-10-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-10-21 @MBExp.py:227][0m Rewards obtained: [27.169685311994836], Lows: [0], Highs: [230], Total time: 3457.5596989999995
[32m[0906 16-12-54 @MBExp.py:144][0m ####################################################################
[32m[0906 16-12-54 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-12-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01873, current rewards: 1.15878, mean: 0.11588
[32m[0906 16-12-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01840, current rewards: 6.69887, mean: 0.11165
[32m[0906 16-12-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.27506, mean: 0.11159
[32m[0906 16-12-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01843, current rewards: 17.85922, mean: 0.11162
[32m[0906 16-12-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 23.43741, mean: 0.11161
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 29.02048, mean: 0.11162
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.60355, mean: 0.11162
[32m[0906 16-13-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 40.18040, mean: 0.11161
[32m[0906 16-13-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.85447, mean: 0.11184
[32m[0906 16-13-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.42357, mean: 0.11179
[32m[0906 16-13-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.98988, mean: 0.11174
[32m[0906 16-13-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.54976, mean: 0.11170
[32m[0906 16-13-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 68.08026, mean: 0.11161
[32m[0906 16-13-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: 73.61355, mean: 0.11154
[32m[0906 16-13-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01847, current rewards: 79.14494, mean: 0.11147
[32m[0906 16-13-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: 84.68059, mean: 0.11142
[32m[0906 16-13-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01849, current rewards: 90.19559, mean: 0.11135
[32m[0906 16-13-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: 95.77972, mean: 0.11137
[32m[0906 16-13-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 101.36389, mean: 0.11139
[32m[0906 16-13-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 106.95019, mean: 0.11141
[32m[0906 16-13-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 112.72377, mean: 0.11161
[32m[0906 16-13-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 118.33323, mean: 0.11164
[32m[0906 16-13-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 123.94045, mean: 0.11166
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 129.55125, mean: 0.11168
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 135.10885, mean: 0.11166
[32m[0906 16-13-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: 140.70638, mean: 0.11167
[32m[0906 16-13-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: 146.30414, mean: 0.11168
[32m[0906 16-13-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01865, current rewards: 151.90187, mean: 0.11169
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01867, current rewards: 157.50129, mean: 0.11170
[32m[0906 16-13-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01868, current rewards: 163.02049, mean: 0.11166
[32m[0906 16-13-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: 168.57417, mean: 0.11164
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: 174.13522, mean: 0.11163
[32m[0906 16-13-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01873, current rewards: 179.69330, mean: 0.11161
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: 185.37343, mean: 0.11167
[32m[0906 16-13-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01875, current rewards: 190.95900, mean: 0.11167
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: 196.54300, mean: 0.11167
[32m[0906 16-13-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 202.12763, mean: 0.11167
[32m[0906 16-13-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 207.71314, mean: 0.11167
[32m[0906 16-13-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 213.29012, mean: 0.11167
[32m[0906 16-13-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: 218.88526, mean: 0.11168
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 224.48103, mean: 0.11168
[32m[0906 16-13-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 229.97632, mean: 0.11164
[32m[0906 16-13-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 235.56576, mean: 0.11164
[32m[0906 16-13-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 241.15650, mean: 0.11165
[32m[0906 16-13-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: 246.74382, mean: 0.11165
[32m[0906 16-13-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 252.33062, mean: 0.11165
[32m[0906 16-13-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: 257.91436, mean: 0.11165
[32m[0906 16-13-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 263.50053, mean: 0.11165
[32m[0906 16-13-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 269.08904, mean: 0.11166
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: 274.67952, mean: 0.11166
[32m[0906 16-13-42 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-13-42 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-13-42 @MBExp.py:227][0m Rewards obtained: [279.2025946055964], Lows: [0], Highs: [0], Total time: 3505.5331529999994
[32m[0906 16-16-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-16-17 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-16-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01849, current rewards: -0.03042, mean: -0.00304
[32m[0906 16-16-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01839, current rewards: 5.50694, mean: 0.09178
[32m[0906 16-16-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 11.04642, mean: 0.10042
[32m[0906 16-16-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 16.58724, mean: 0.10367
[32m[0906 16-16-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 22.13041, mean: 0.10538
[32m[0906 16-16-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 27.67142, mean: 0.10643
[32m[0906 16-16-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 33.21166, mean: 0.10713
[32m[0906 16-16-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 38.78125, mean: 0.10773
[32m[0906 16-16-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01845, current rewards: 44.38334, mean: 0.10825
[32m[0906 16-16-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01844, current rewards: 49.91471, mean: 0.10851
[32m[0906 16-16-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01845, current rewards: 55.44897, mean: 0.10872
[32m[0906 16-16-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01844, current rewards: 60.98563, mean: 0.10890
[32m[0906 16-16-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01844, current rewards: 66.51762, mean: 0.10905
[32m[0906 16-16-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01845, current rewards: 72.06451, mean: 0.10919
[32m[0906 16-16-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01846, current rewards: 77.62095, mean: 0.10933
[32m[0906 16-16-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01846, current rewards: 83.17640, mean: 0.10944
[32m[0906 16-16-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 88.66450, mean: 0.10946
[32m[0906 16-16-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: 94.20785, mean: 0.10954
[32m[0906 16-16-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 99.75221, mean: 0.10962
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01848, current rewards: 105.30330, mean: 0.10969
[32m[0906 16-16-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 110.85370, mean: 0.10976
[32m[0906 16-16-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01848, current rewards: 116.39807, mean: 0.10981
[32m[0906 16-16-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01848, current rewards: 121.94388, mean: 0.10986
[32m[0906 16-16-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: 127.49298, mean: 0.10991
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 132.99756, mean: 0.10992
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: 138.51393, mean: 0.10993
[32m[0906 16-16-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: 144.03204, mean: 0.10995
[32m[0906 16-16-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: 149.55004, mean: 0.10996
[32m[0906 16-16-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 155.07387, mean: 0.10998
[32m[0906 16-16-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01863, current rewards: 160.59225, mean: 0.10999
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01865, current rewards: 166.11013, mean: 0.11001
[32m[0906 16-16-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01866, current rewards: 171.63228, mean: 0.11002
[32m[0906 16-16-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01868, current rewards: 177.14994, mean: 0.11003
[32m[0906 16-16-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01870, current rewards: 182.81288, mean: 0.11013
[32m[0906 16-16-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01872, current rewards: 188.35688, mean: 0.11015
[32m[0906 16-16-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01873, current rewards: 193.91610, mean: 0.11018
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01875, current rewards: 199.43001, mean: 0.11018
[32m[0906 16-16-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01876, current rewards: 204.94963, mean: 0.11019
[32m[0906 16-16-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01877, current rewards: 210.46885, mean: 0.11019
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01878, current rewards: 215.99013, mean: 0.11020
[32m[0906 16-16-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01879, current rewards: 220.27373, mean: 0.10959
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01880, current rewards: 227.58782, mean: 0.11048
[32m[0906 16-16-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 233.13702, mean: 0.11049
[32m[0906 16-16-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 238.68635, mean: 0.11050
[32m[0906 16-16-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 244.23790, mean: 0.11051
[32m[0906 16-17-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: 248.67834, mean: 0.11003
[32m[0906 16-17-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 254.17144, mean: 0.11003
[32m[0906 16-17-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 259.67252, mean: 0.11003
[32m[0906 16-17-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 265.17428, mean: 0.11003
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 270.65740, mean: 0.11002
[32m[0906 16-17-05 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-17-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-17-05 @MBExp.py:227][0m Rewards obtained: [275.0034298525205], Lows: [1], Highs: [2], Total time: 3553.467887999999
[32m[0906 16-19-42 @MBExp.py:144][0m ####################################################################
[32m[0906 16-19-42 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-19-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01828, current rewards: 1.22600, mean: 0.12260
[32m[0906 16-19-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01852, current rewards: 6.78786, mean: 0.11313
[32m[0906 16-19-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.34801, mean: 0.11225
[32m[0906 16-19-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01845, current rewards: 17.90733, mean: 0.11192
[32m[0906 16-19-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01842, current rewards: 23.40260, mean: 0.11144
[32m[0906 16-19-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.91938, mean: 0.11123
[32m[0906 16-19-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.43856, mean: 0.11109
[32m[0906 16-19-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 39.95755, mean: 0.11099
[32m[0906 16-19-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.47261, mean: 0.11091
[32m[0906 16-19-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 50.99363, mean: 0.11086
[32m[0906 16-19-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.51296, mean: 0.11081
[32m[0906 16-19-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.04092, mean: 0.11079
[32m[0906 16-19-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 67.60057, mean: 0.11082
[32m[0906 16-19-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 73.16202, mean: 0.11085
[32m[0906 16-19-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 78.72608, mean: 0.11088
[32m[0906 16-19-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 84.28976, mean: 0.11091
[32m[0906 16-19-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 89.83584, mean: 0.11091
[32m[0906 16-19-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 95.39968, mean: 0.11093
[32m[0906 16-19-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01848, current rewards: 100.93950, mean: 0.11092
[32m[0906 16-20-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 106.48260, mean: 0.11092
[32m[0906 16-20-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 112.02131, mean: 0.11091
[32m[0906 16-20-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01848, current rewards: 117.55755, mean: 0.11090
[32m[0906 16-20-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01849, current rewards: 123.09536, mean: 0.11090
[32m[0906 16-20-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01849, current rewards: 128.63223, mean: 0.11089
[32m[0906 16-20-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 134.11307, mean: 0.11084
[32m[0906 16-20-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: 137.54833, mean: 0.10917
[32m[0906 16-20-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01859, current rewards: 143.12952, mean: 0.10926
[32m[0906 16-20-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: 148.71313, mean: 0.10935
[32m[0906 16-20-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01862, current rewards: 154.29798, mean: 0.10943
[32m[0906 16-20-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 159.87614, mean: 0.10950
[32m[0906 16-20-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01866, current rewards: 165.45637, mean: 0.10957
[32m[0906 16-20-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01867, current rewards: 171.02848, mean: 0.10963
[32m[0906 16-20-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01868, current rewards: 176.57094, mean: 0.10967
[32m[0906 16-20-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01870, current rewards: 182.08505, mean: 0.10969
[32m[0906 16-20-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 187.59616, mean: 0.10971
[32m[0906 16-20-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01873, current rewards: 193.11156, mean: 0.10972
[32m[0906 16-20-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01874, current rewards: 198.62747, mean: 0.10974
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01875, current rewards: 204.25518, mean: 0.10981
[32m[0906 16-20-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: 209.83589, mean: 0.10986
[32m[0906 16-20-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 215.41674, mean: 0.10991
[32m[0906 16-20-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01878, current rewards: 221.06005, mean: 0.10998
[32m[0906 16-20-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01879, current rewards: 226.71382, mean: 0.11006
[32m[0906 16-20-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: 232.32210, mean: 0.11011
[32m[0906 16-20-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01881, current rewards: 237.92984, mean: 0.11015
[32m[0906 16-20-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 243.40252, mean: 0.11014
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 248.96425, mean: 0.11016
[32m[0906 16-20-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 254.52312, mean: 0.11018
[32m[0906 16-20-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01883, current rewards: 260.08054, mean: 0.11020
[32m[0906 16-20-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 265.64060, mean: 0.11022
[32m[0906 16-20-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01884, current rewards: 271.23848, mean: 0.11026
[32m[0906 16-20-30 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-20-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-20-30 @MBExp.py:227][0m Rewards obtained: [275.68270902799725], Lows: [1], Highs: [0], Total time: 3601.3827459999993
[32m[0906 16-23-10 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-10 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 16-23-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01815, current rewards: 1.19858, mean: 0.11986
[32m[0906 16-23-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 6.84422, mean: 0.11407
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01845, current rewards: 12.42446, mean: 0.11295
[32m[0906 16-23-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 18.00207, mean: 0.11251
[32m[0906 16-23-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.58146, mean: 0.11229
[32m[0906 16-23-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 30.02467, mean: 0.11548
[32m[0906 16-23-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 38.81334, mean: 0.12520
[32m[0906 16-23-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 46.86819, mean: 0.13019
[32m[0906 16-23-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 50.07118, mean: 0.12212
[32m[0906 16-23-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 53.23091, mean: 0.11572
[32m[0906 16-23-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 56.39065, mean: 0.11057
[32m[0906 16-23-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 59.55038, mean: 0.10634
[32m[0906 16-23-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 62.71011, mean: 0.10280
[32m[0906 16-23-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 54.17471, mean: 0.08208
[32m[0906 16-23-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 4.17471, mean: 0.00588
[32m[0906 16-23-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: -45.82529, mean: -0.06030
[32m[0906 16-23-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: -95.82529, mean: -0.11830
[32m[0906 16-23-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: -145.82529, mean: -0.16956
[32m[0906 16-23-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: -195.82529, mean: -0.21519
[32m[0906 16-23-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: -245.82529, mean: -0.25607
[32m[0906 16-23-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: -295.82529, mean: -0.29290
[32m[0906 16-23-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: -345.82529, mean: -0.32625
[32m[0906 16-23-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: -395.82529, mean: -0.35660
[32m[0906 16-23-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: -445.82529, mean: -0.38433
[32m[0906 16-23-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: -495.82529, mean: -0.40977
[32m[0906 16-23-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01861, current rewards: -545.82529, mean: -0.43319
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: -595.82529, mean: -0.45483
[32m[0906 16-23-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01865, current rewards: -645.82529, mean: -0.47487
[32m[0906 16-23-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01867, current rewards: -695.82529, mean: -0.49349
[32m[0906 16-23-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: -745.82529, mean: -0.51084
[32m[0906 16-23-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: -795.82529, mean: -0.52704
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: -845.82529, mean: -0.54220
[32m[0906 16-23-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: -895.82529, mean: -0.55641
[32m[0906 16-23-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01875, current rewards: -945.82529, mean: -0.56977
[32m[0906 16-23-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: -995.82529, mean: -0.58235
[32m[0906 16-23-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: -1045.82529, mean: -0.59422
[32m[0906 16-23-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: -1095.82529, mean: -0.60543
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: -1145.82529, mean: -0.61604
[32m[0906 16-23-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: -1195.82529, mean: -0.62609
[32m[0906 16-23-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: -1245.82529, mean: -0.63563
[32m[0906 16-23-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: -1295.82529, mean: -0.64469
[32m[0906 16-23-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: -1345.82529, mean: -0.65331
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: -1395.82529, mean: -0.66153
[32m[0906 16-23-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: -1445.82529, mean: -0.66936
[32m[0906 16-23-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: -1495.82529, mean: -0.67684
[32m[0906 16-23-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: -1545.82529, mean: -0.68399
[32m[0906 16-23-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: -1595.82529, mean: -0.69083
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: -1645.82529, mean: -0.69738
[32m[0906 16-23-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: -1695.82529, mean: -0.70366
[32m[0906 16-23-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: -1745.82529, mean: -0.70969
[32m[0906 16-23-57 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-23-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-23-58 @MBExp.py:227][0m Rewards obtained: [-1785.8252937880707], Lows: [1], Highs: [1851], Total time: 3649.4097459999994
[32m[0906 16-26-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-26-39 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 16-26-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01873, current rewards: 1.30039, mean: 0.13004
[32m[0906 16-26-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01849, current rewards: 9.15993, mean: 0.15267
[32m[0906 16-26-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01852, current rewards: 17.01947, mean: 0.15472
[32m[0906 16-26-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 24.87901, mean: 0.15549
[32m[0906 16-26-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01847, current rewards: 1.49440, mean: 0.00712
[32m[0906 16-26-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: -48.50560, mean: -0.18656
[32m[0906 16-26-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: -98.50560, mean: -0.31776
[32m[0906 16-26-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: -148.50560, mean: -0.41252
[32m[0906 16-26-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: -162.73333, mean: -0.39691
[32m[0906 16-26-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: -157.05305, mean: -0.34142
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: -151.36533, mean: -0.29679
[32m[0906 16-26-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: -145.68271, mean: -0.26015
[32m[0906 16-26-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: -139.99760, mean: -0.22950
[32m[0906 16-26-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: -138.56787, mean: -0.20995
[32m[0906 16-26-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: -132.95310, mean: -0.18726
[32m[0906 16-26-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01856, current rewards: -127.33699, mean: -0.16755
[32m[0906 16-26-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01856, current rewards: -121.74169, mean: -0.15030
[32m[0906 16-26-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01857, current rewards: -116.11339, mean: -0.13502
[32m[0906 16-26-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: -110.53070, mean: -0.12146
[32m[0906 16-26-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: -104.95302, mean: -0.10933
[32m[0906 16-26-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: -99.36814, mean: -0.09838
[32m[0906 16-26-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: -93.78277, mean: -0.08847
[32m[0906 16-27-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: -88.20454, mean: -0.07946
[32m[0906 16-27-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: -82.61923, mean: -0.07122
[32m[0906 16-27-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: -77.04861, mean: -0.06368
[32m[0906 16-27-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: -71.48059, mean: -0.05673
[32m[0906 16-27-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: -65.89942, mean: -0.05030
[32m[0906 16-27-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01867, current rewards: -60.32298, mean: -0.04436
[32m[0906 16-27-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: -54.75402, mean: -0.03883
[32m[0906 16-27-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: -49.18213, mean: -0.03369
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01872, current rewards: -43.61573, mean: -0.02888
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: -38.04949, mean: -0.02439
[32m[0906 16-27-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: -32.51107, mean: -0.02019
[32m[0906 16-27-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: -26.95715, mean: -0.01624
[32m[0906 16-27-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: -21.40449, mean: -0.01252
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: -15.85089, mean: -0.00901
[32m[0906 16-27-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: -10.29837, mean: -0.00569
[32m[0906 16-27-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: -4.74528, mean: -0.00255
[32m[0906 16-27-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: 0.85558, mean: 0.00045
[32m[0906 16-27-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: 6.41096, mean: 0.00327
[32m[0906 16-27-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01883, current rewards: 11.95999, mean: 0.00595
[32m[0906 16-27-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 17.50567, mean: 0.00850
[32m[0906 16-27-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 23.05176, mean: 0.01093
[32m[0906 16-27-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 28.60167, mean: 0.01324
[32m[0906 16-27-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 34.14578, mean: 0.01545
[32m[0906 16-27-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 39.69004, mean: 0.01756
[32m[0906 16-27-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: 45.23829, mean: 0.01958
[32m[0906 16-27-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 50.78355, mean: 0.02152
[32m[0906 16-27-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 56.36424, mean: 0.02339
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: 61.87674, mean: 0.02515
[32m[0906 16-27-27 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-27-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-27-27 @MBExp.py:227][0m Rewards obtained: [66.28359748544605], Lows: [3], Highs: [193], Total time: 3697.4722009999996
[32m[0906 16-30-11 @MBExp.py:144][0m ####################################################################
[32m[0906 16-30-11 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 16-30-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01853, current rewards: 1.15419, mean: 0.11542
[32m[0906 16-30-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01849, current rewards: 6.73348, mean: 0.11222
[32m[0906 16-30-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 12.24291, mean: 0.11130
[32m[0906 16-30-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.75558, mean: 0.11097
[32m[0906 16-30-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01857, current rewards: 23.27528, mean: 0.11083
[32m[0906 16-30-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 28.78838, mean: 0.11072
[32m[0906 16-30-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01858, current rewards: 34.30270, mean: 0.11065
[32m[0906 16-30-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01858, current rewards: 39.73023, mean: 0.11036
[32m[0906 16-30-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01857, current rewards: 45.24382, mean: 0.11035
[32m[0906 16-30-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01859, current rewards: 50.75896, mean: 0.11035
[32m[0906 16-30-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 56.26811, mean: 0.11033
[32m[0906 16-30-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 61.77477, mean: 0.11031
[32m[0906 16-30-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 67.31728, mean: 0.11036
[32m[0906 16-30-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 72.83433, mean: 0.11036
[32m[0906 16-30-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 78.35737, mean: 0.11036
[32m[0906 16-30-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 83.86037, mean: 0.11034
[32m[0906 16-30-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 89.37831, mean: 0.11034
[32m[0906 16-30-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01857, current rewards: 94.90120, mean: 0.11035
[32m[0906 16-30-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 100.42006, mean: 0.11035
[32m[0906 16-30-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 105.93501, mean: 0.11035
[32m[0906 16-30-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 111.45073, mean: 0.11035
[32m[0906 16-30-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 116.97639, mean: 0.11036
[32m[0906 16-30-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: 122.49531, mean: 0.11036
[32m[0906 16-30-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01862, current rewards: 128.08708, mean: 0.11042
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01865, current rewards: 133.65469, mean: 0.11046
[32m[0906 16-30-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01867, current rewards: 139.16744, mean: 0.11045
[32m[0906 16-30-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01868, current rewards: 144.68411, mean: 0.11045
[32m[0906 16-30-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: 150.19430, mean: 0.11044
[32m[0906 16-30-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 155.70486, mean: 0.11043
[32m[0906 16-30-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: 161.21885, mean: 0.11042
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 166.72757, mean: 0.11042
[32m[0906 16-30-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01876, current rewards: 172.24504, mean: 0.11041
[32m[0906 16-30-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: 177.61714, mean: 0.11032
[32m[0906 16-30-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01879, current rewards: 183.12866, mean: 0.11032
[32m[0906 16-30-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01880, current rewards: 188.74737, mean: 0.11038
[32m[0906 16-30-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01881, current rewards: 194.29429, mean: 0.11039
[32m[0906 16-30-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: 199.83878, mean: 0.11041
[32m[0906 16-30-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 205.38532, mean: 0.11042
[32m[0906 16-30-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 210.93011, mean: 0.11043
[32m[0906 16-30-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01885, current rewards: 216.47814, mean: 0.11045
[32m[0906 16-30-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01886, current rewards: 222.06981, mean: 0.11048
[32m[0906 16-30-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01887, current rewards: 227.67030, mean: 0.11052
[32m[0906 16-30-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 233.19614, mean: 0.11052
[32m[0906 16-30-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: 238.71837, mean: 0.11052
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: 244.25371, mean: 0.11052
[32m[0906 16-30-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 249.80491, mean: 0.11053
[32m[0906 16-30-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 255.35989, mean: 0.11055
[32m[0906 16-30-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 260.91327, mean: 0.11056
[32m[0906 16-30-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 267.18060, mean: 0.11086
[32m[0906 16-30-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 274.05872, mean: 0.11141
[32m[0906 16-30-58 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-30-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-30-59 @MBExp.py:227][0m Rewards obtained: [280.0268708684752], Lows: [0], Highs: [0], Total time: 3745.6066269999997
[32m[0906 16-33-44 @MBExp.py:144][0m ####################################################################
[32m[0906 16-33-44 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 16-33-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01949, current rewards: 1.09089, mean: 0.10909
[32m[0906 16-33-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01873, current rewards: 6.61335, mean: 0.11022
[32m[0906 16-33-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01867, current rewards: 12.18260, mean: 0.11075
[32m[0906 16-33-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01861, current rewards: 17.75381, mean: 0.11096
[32m[0906 16-33-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 23.31869, mean: 0.11104
[32m[0906 16-33-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 28.89035, mean: 0.11112
[32m[0906 16-33-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01858, current rewards: 34.46332, mean: 0.11117
[32m[0906 16-33-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 40.04355, mean: 0.11123
[32m[0906 16-33-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 45.61218, mean: 0.11125
[32m[0906 16-33-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 51.18182, mean: 0.11126
[32m[0906 16-33-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 56.75023, mean: 0.11127
[32m[0906 16-33-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 62.31901, mean: 0.11128
[32m[0906 16-33-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 67.88364, mean: 0.11128
[32m[0906 16-33-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 73.46506, mean: 0.11131
[32m[0906 16-33-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 79.04542, mean: 0.11133
[32m[0906 16-33-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 84.59088, mean: 0.11130
[32m[0906 16-33-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 90.14511, mean: 0.11129
[32m[0906 16-34-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 95.71924, mean: 0.11130
[32m[0906 16-34-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 101.29528, mean: 0.11131
[32m[0906 16-34-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 106.86950, mean: 0.11132
[32m[0906 16-34-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 112.44660, mean: 0.11133
[32m[0906 16-34-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 118.02255, mean: 0.11134
[32m[0906 16-34-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: 123.59956, mean: 0.11135
[32m[0906 16-34-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01862, current rewards: 129.17755, mean: 0.11136
[32m[0906 16-34-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: 134.87512, mean: 0.11147
[32m[0906 16-34-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01866, current rewards: 140.45692, mean: 0.11147
[32m[0906 16-34-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01868, current rewards: 146.04726, mean: 0.11149
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: 151.64069, mean: 0.11150
[32m[0906 16-34-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 157.23355, mean: 0.11151
[32m[0906 16-34-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01872, current rewards: 162.83239, mean: 0.11153
[32m[0906 16-34-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 168.38542, mean: 0.11151
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 173.94391, mean: 0.11150
[32m[0906 16-34-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: 179.49946, mean: 0.11149
[32m[0906 16-34-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01877, current rewards: 185.02443, mean: 0.11146
[32m[0906 16-34-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: 190.59079, mean: 0.11146
[32m[0906 16-34-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: 196.15711, mean: 0.11145
[32m[0906 16-34-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: 201.72319, mean: 0.11145
[32m[0906 16-34-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 207.29728, mean: 0.11145
[32m[0906 16-34-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 212.86509, mean: 0.11145
[32m[0906 16-34-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: 218.50947, mean: 0.11148
[32m[0906 16-34-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 223.89556, mean: 0.11139
[32m[0906 16-34-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 229.44179, mean: 0.11138
[32m[0906 16-34-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 235.01675, mean: 0.11138
[32m[0906 16-34-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: 240.58988, mean: 0.11138
[32m[0906 16-34-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: 246.16647, mean: 0.11139
[32m[0906 16-34-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 251.73889, mean: 0.11139
[32m[0906 16-34-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 257.31556, mean: 0.11139
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 262.89035, mean: 0.11139
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 268.46670, mean: 0.11140
[32m[0906 16-34-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 274.11049, mean: 0.11143
[32m[0906 16-34-32 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-34-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-34-32 @MBExp.py:227][0m Rewards obtained: [278.5604572364874], Lows: [0], Highs: [0], Total time: 3793.7631909999996
[32m[0906 16-37-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-37-19 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 16-37-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.04091, mean: 0.10409
[32m[0906 16-37-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.56062, mean: 0.10934
[32m[0906 16-37-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01845, current rewards: 12.08504, mean: 0.10986
[32m[0906 16-37-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 17.60604, mean: 0.11004
[32m[0906 16-37-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.13623, mean: 0.11017
[32m[0906 16-37-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01854, current rewards: 28.66089, mean: 0.11023
[32m[0906 16-37-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 34.18692, mean: 0.11028
[32m[0906 16-37-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 39.83879, mean: 0.11066
[32m[0906 16-37-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 45.37199, mean: 0.11066
[32m[0906 16-37-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 50.90390, mean: 0.11066
[32m[0906 16-37-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 56.43521, mean: 0.11066
[32m[0906 16-37-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 61.92888, mean: 0.11059
[32m[0906 16-37-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.47196, mean: 0.11061
[32m[0906 16-37-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 73.02130, mean: 0.11064
[32m[0906 16-37-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 78.56227, mean: 0.11065
[32m[0906 16-37-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 84.09061, mean: 0.11065
[32m[0906 16-37-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 87.48120, mean: 0.10800
[32m[0906 16-37-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 93.03620, mean: 0.10818
[32m[0906 16-37-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 98.58890, mean: 0.10834
[32m[0906 16-37-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 104.14414, mean: 0.10848
[32m[0906 16-37-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 109.69587, mean: 0.10861
[32m[0906 16-37-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 115.25518, mean: 0.10873
[32m[0906 16-37-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 120.76944, mean: 0.10880
[32m[0906 16-37-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: 126.28329, mean: 0.10886
[32m[0906 16-37-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 131.77138, mean: 0.10890
[32m[0906 16-37-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 137.28493, mean: 0.10896
[32m[0906 16-37-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 142.80516, mean: 0.10901
[32m[0906 16-37-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: 148.31730, mean: 0.10906
[32m[0906 16-37-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: 153.83460, mean: 0.10910
[32m[0906 16-37-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: 159.34672, mean: 0.10914
[32m[0906 16-37-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: 164.89917, mean: 0.10920
[32m[0906 16-37-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: 170.45836, mean: 0.10927
[32m[0906 16-37-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: 175.96584, mean: 0.10930
[32m[0906 16-37-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 181.51097, mean: 0.10934
[32m[0906 16-37-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: 187.05630, mean: 0.10939
[32m[0906 16-37-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: 192.59697, mean: 0.10943
[32m[0906 16-37-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 198.14500, mean: 0.10947
[32m[0906 16-37-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: 203.68938, mean: 0.10951
[32m[0906 16-37-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 209.23432, mean: 0.10955
[32m[0906 16-37-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 214.78033, mean: 0.10958
[32m[0906 16-37-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 220.35704, mean: 0.10963
[32m[0906 16-37-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 225.90440, mean: 0.10966
[32m[0906 16-38-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 231.45300, mean: 0.10969
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01886, current rewards: 237.07026, mean: 0.10975
[32m[0906 16-38-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 242.58436, mean: 0.10977
[32m[0906 16-38-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 248.09792, mean: 0.10978
[32m[0906 16-38-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: 253.61064, mean: 0.10979
[32m[0906 16-38-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 259.12995, mean: 0.10980
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 264.64446, mean: 0.10981
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 270.15998, mean: 0.10982
[32m[0906 16-38-07 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-38-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-38-08 @MBExp.py:227][0m Rewards obtained: [274.56924886084323], Lows: [1], Highs: [0], Total time: 3841.8580069999994
[32m[0906 16-40-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-40-57 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 16-40-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01837, current rewards: 1.12995, mean: 0.11299
[32m[0906 16-40-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01834, current rewards: 6.67152, mean: 0.11119
[32m[0906 16-40-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 12.21496, mean: 0.11105
[32m[0906 16-41-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.75545, mean: 0.11097
[32m[0906 16-41-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 23.42166, mean: 0.11153
[32m[0906 16-41-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 29.04195, mean: 0.11170
[32m[0906 16-41-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.56703, mean: 0.11151
[32m[0906 16-41-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01845, current rewards: 40.16730, mean: 0.11158
[32m[0906 16-41-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.76968, mean: 0.11163
[32m[0906 16-41-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 51.37167, mean: 0.11168
[32m[0906 16-41-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.91665, mean: 0.11160
[32m[0906 16-41-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 62.49487, mean: 0.11160
[32m[0906 16-41-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 68.07763, mean: 0.11160
[32m[0906 16-41-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 73.66592, mean: 0.11162
[32m[0906 16-41-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 79.28552, mean: 0.11167
[32m[0906 16-41-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.97189, mean: 0.11181
[32m[0906 16-41-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 90.57182, mean: 0.11182
[32m[0906 16-41-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 96.14280, mean: 0.11179
[32m[0906 16-41-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 101.71813, mean: 0.11178
[32m[0906 16-41-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 107.29785, mean: 0.11177
[32m[0906 16-41-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 112.87319, mean: 0.11176
[32m[0906 16-41-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 118.44535, mean: 0.11174
[32m[0906 16-41-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 124.02276, mean: 0.11173
[32m[0906 16-41-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: 129.56916, mean: 0.11170
[32m[0906 16-41-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 135.11731, mean: 0.11167
[32m[0906 16-41-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 140.66143, mean: 0.11164
[32m[0906 16-41-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01867, current rewards: 146.20453, mean: 0.11161
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01868, current rewards: 151.74553, mean: 0.11158
[32m[0906 16-41-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01870, current rewards: 157.28421, mean: 0.11155
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01870, current rewards: 162.83038, mean: 0.11153
[32m[0906 16-41-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01872, current rewards: 168.37826, mean: 0.11151
[32m[0906 16-41-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 173.91273, mean: 0.11148
[32m[0906 16-41-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: 179.46283, mean: 0.11147
[32m[0906 16-41-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 185.05839, mean: 0.11148
[32m[0906 16-41-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: 190.62726, mean: 0.11148
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 196.19257, mean: 0.11147
[32m[0906 16-41-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01881, current rewards: 201.76399, mean: 0.11147
[32m[0906 16-41-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: 207.32849, mean: 0.11147
[32m[0906 16-41-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 212.89592, mean: 0.11146
[32m[0906 16-41-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 218.47786, mean: 0.11147
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 224.01757, mean: 0.11145
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 229.55941, mean: 0.11144
[32m[0906 16-41-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 235.10228, mean: 0.11142
[32m[0906 16-41-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 240.64123, mean: 0.11141
[32m[0906 16-41-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: 246.18156, mean: 0.11139
[32m[0906 16-41-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: 251.75994, mean: 0.11140
[32m[0906 16-41-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 257.34182, mean: 0.11140
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 262.86173, mean: 0.11138
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 268.43523, mean: 0.11138
[32m[0906 16-41-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 274.00558, mean: 0.11138
[32m[0906 16-41-45 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-41-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-41-45 @MBExp.py:227][0m Rewards obtained: [278.4653098990355], Lows: [0], Highs: [0], Total time: 3889.9865599999994
[32m[0906 16-44-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-44-37 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 16-44-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01813, current rewards: -2.34699, mean: -0.23470
[32m[0906 16-44-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01844, current rewards: 3.30829, mean: 0.05514
[32m[0906 16-44-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01848, current rewards: 8.96577, mean: 0.08151
[32m[0906 16-44-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 14.61913, mean: 0.09137
[32m[0906 16-44-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01848, current rewards: 20.27781, mean: 0.09656
[32m[0906 16-44-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 25.95455, mean: 0.09983
[32m[0906 16-44-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 31.49299, mean: 0.10159
[32m[0906 16-44-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01853, current rewards: 36.90694, mean: 0.10252
[32m[0906 16-44-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 42.43935, mean: 0.10351
[32m[0906 16-44-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 47.97339, mean: 0.10429
[32m[0906 16-44-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 53.50749, mean: 0.10492
[32m[0906 16-44-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 59.04365, mean: 0.10544
[32m[0906 16-44-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 64.57547, mean: 0.10586
[32m[0906 16-44-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 58.70925, mean: 0.08895
[32m[0906 16-44-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 8.70925, mean: 0.01227
[32m[0906 16-44-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: -41.29075, mean: -0.05433
[32m[0906 16-44-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: -91.29075, mean: -0.11270
[32m[0906 16-44-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01857, current rewards: -141.29075, mean: -0.16429
[32m[0906 16-44-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: -191.29075, mean: -0.21021
[32m[0906 16-44-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: -241.29075, mean: -0.25134
[32m[0906 16-44-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: -291.29075, mean: -0.28841
[32m[0906 16-44-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: -341.29075, mean: -0.32197
[32m[0906 16-44-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: -391.29075, mean: -0.35251
[32m[0906 16-44-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01862, current rewards: -441.29075, mean: -0.38042
[32m[0906 16-45-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: -491.29075, mean: -0.40603
[32m[0906 16-45-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01867, current rewards: -541.29075, mean: -0.42960
[32m[0906 16-45-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01868, current rewards: -560.72065, mean: -0.42803
[32m[0906 16-45-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: -551.93198, mean: -0.40583
[32m[0906 16-45-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: -543.14332, mean: -0.38521
[32m[0906 16-45-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01872, current rewards: -534.35466, mean: -0.36600
[32m[0906 16-45-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: -526.01428, mean: -0.34835
[32m[0906 16-45-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01876, current rewards: -520.66712, mean: -0.33376
[32m[0906 16-45-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01877, current rewards: -556.27686, mean: -0.34551
[32m[0906 16-45-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01878, current rewards: -606.27686, mean: -0.36523
[32m[0906 16-45-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: -656.27686, mean: -0.38379
[32m[0906 16-45-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: -706.27686, mean: -0.40129
[32m[0906 16-45-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: -756.27686, mean: -0.41783
[32m[0906 16-45-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: -806.27686, mean: -0.43348
[32m[0906 16-45-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: -856.27686, mean: -0.44831
[32m[0906 16-45-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: -906.27686, mean: -0.46239
[32m[0906 16-45-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: -956.27686, mean: -0.47576
[32m[0906 16-45-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: -1006.27686, mean: -0.48848
[32m[0906 16-45-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: -1056.27686, mean: -0.50061
[32m[0906 16-45-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: -1106.27686, mean: -0.51217
[32m[0906 16-45-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: -1156.27686, mean: -0.52320
[32m[0906 16-45-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: -1206.27686, mean: -0.53375
[32m[0906 16-45-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: -1256.27686, mean: -0.54384
[32m[0906 16-45-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: -1306.27686, mean: -0.55351
[32m[0906 16-45-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: -1356.27686, mean: -0.56277
[32m[0906 16-45-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: -1406.27686, mean: -0.57166
[32m[0906 16-45-25 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-45-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-45-25 @MBExp.py:227][0m Rewards obtained: [-1446.2768603998024], Lows: [1], Highs: [1563], Total time: 3938.1095959999993
[32m[0906 16-48-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-18 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 16-48-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01831, current rewards: 1.12774, mean: 0.11277
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01836, current rewards: 6.65784, mean: 0.11096
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01837, current rewards: 12.18618, mean: 0.11078
[32m[0906 16-48-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 17.71468, mean: 0.11072
[32m[0906 16-48-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.23796, mean: 0.11066
[32m[0906 16-48-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 28.78312, mean: 0.11070
[32m[0906 16-48-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 34.30841, mean: 0.11067
[32m[0906 16-48-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 39.83836, mean: 0.11066
[32m[0906 16-48-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.36392, mean: 0.11064
[32m[0906 16-48-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 50.89131, mean: 0.11063
[32m[0906 16-48-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 56.42973, mean: 0.11065
[32m[0906 16-48-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 61.96004, mean: 0.11064
[32m[0906 16-48-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 67.49834, mean: 0.11065
[32m[0906 16-48-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 73.00646, mean: 0.11062
[32m[0906 16-48-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 78.53525, mean: 0.11061
[32m[0906 16-48-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.07137, mean: 0.11062
[32m[0906 16-48-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.60639, mean: 0.11063
[32m[0906 16-48-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 95.13955, mean: 0.11063
[32m[0906 16-48-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 100.67307, mean: 0.11063
[32m[0906 16-48-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 106.21000, mean: 0.11064
[32m[0906 16-48-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 111.74157, mean: 0.11064
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 117.24932, mean: 0.11061
[32m[0906 16-48-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 122.82588, mean: 0.11065
[32m[0906 16-48-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: 128.34672, mean: 0.11064
[32m[0906 16-48-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 133.87480, mean: 0.11064
[32m[0906 16-48-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01863, current rewards: 139.40170, mean: 0.11064
[32m[0906 16-48-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01864, current rewards: 144.92632, mean: 0.11063
[32m[0906 16-48-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: 150.45496, mean: 0.11063
[32m[0906 16-48-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: 155.97958, mean: 0.11062
[32m[0906 16-48-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01870, current rewards: 161.55441, mean: 0.11065
[32m[0906 16-48-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01872, current rewards: 167.07550, mean: 0.11065
[32m[0906 16-48-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01873, current rewards: 172.61418, mean: 0.11065
[32m[0906 16-48-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: 178.15634, mean: 0.11066
[32m[0906 16-48-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 183.69751, mean: 0.11066
[32m[0906 16-48-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: 189.23826, mean: 0.11067
[32m[0906 16-48-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: 194.78043, mean: 0.11067
[32m[0906 16-48-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: 200.32046, mean: 0.11067
[32m[0906 16-48-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: 205.88673, mean: 0.11069
[32m[0906 16-48-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: 211.45561, mean: 0.11071
[32m[0906 16-48-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 217.11016, mean: 0.11077
[32m[0906 16-48-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: 222.68681, mean: 0.11079
[32m[0906 16-48-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 228.26359, mean: 0.11081
[32m[0906 16-48-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 233.84010, mean: 0.11082
[32m[0906 16-49-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 239.41920, mean: 0.11084
[32m[0906 16-49-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 244.99352, mean: 0.11086
[32m[0906 16-49-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: 250.57354, mean: 0.11087
[32m[0906 16-49-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 256.07166, mean: 0.11085
[32m[0906 16-49-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: 261.63055, mean: 0.11086
[32m[0906 16-49-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: 267.76712, mean: 0.11111
[32m[0906 16-49-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 273.31006, mean: 0.11110
[32m[0906 16-49-06 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-49-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-49-07 @MBExp.py:227][0m Rewards obtained: [277.74475307877907], Lows: [0], Highs: [0], Total time: 3986.222693999999
[32m[0906 16-52-02 @MBExp.py:144][0m ####################################################################
[32m[0906 16-52-02 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 16-52-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01841, current rewards: 1.11097, mean: 0.11110
[32m[0906 16-52-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01842, current rewards: 6.69340, mean: 0.11156
[32m[0906 16-52-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: 12.26867, mean: 0.11153
[32m[0906 16-52-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.82967, mean: 0.11144
[32m[0906 16-52-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.34969, mean: 0.11119
[32m[0906 16-52-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 28.92475, mean: 0.11125
[32m[0906 16-52-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.49666, mean: 0.11128
[32m[0906 16-52-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 40.06956, mean: 0.11130
[32m[0906 16-52-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.63354, mean: 0.11130
[32m[0906 16-52-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 51.21086, mean: 0.11133
[32m[0906 16-52-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 54.66449, mean: 0.10719
[32m[0906 16-52-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 60.21331, mean: 0.10752
[32m[0906 16-52-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 65.99276, mean: 0.10818
[32m[0906 16-52-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 74.78142, mean: 0.11331
[32m[0906 16-52-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 83.57008, mean: 0.11770
[32m[0906 16-52-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 92.35874, mean: 0.12152
[32m[0906 16-52-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 56.46802, mean: 0.06971
[32m[0906 16-52-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 6.46802, mean: 0.00752
[32m[0906 16-52-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01848, current rewards: -43.53198, mean: -0.04784
[32m[0906 16-52-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: -56.70951, mean: -0.05907
[32m[0906 16-52-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: -50.89551, mean: -0.05039
[32m[0906 16-52-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: -45.09775, mean: -0.04255
[32m[0906 16-52-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: -39.29598, mean: -0.03540
[32m[0906 16-52-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: -33.49149, mean: -0.02887
[32m[0906 16-52-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: -27.60530, mean: -0.02281
[32m[0906 16-52-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: -21.80055, mean: -0.01730
[32m[0906 16-52-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: -16.00041, mean: -0.01221
[32m[0906 16-52-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01867, current rewards: -10.19674, mean: -0.00750
[32m[0906 16-52-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01869, current rewards: -4.40364, mean: -0.00312
[32m[0906 16-52-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: 1.32620, mean: 0.00091
[32m[0906 16-52-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01872, current rewards: 6.90797, mean: 0.00457
[32m[0906 16-52-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 12.49028, mean: 0.00801
[32m[0906 16-52-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01875, current rewards: 18.07225, mean: 0.01123
[32m[0906 16-52-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 23.65731, mean: 0.01425
[32m[0906 16-52-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: 29.24122, mean: 0.01710
[32m[0906 16-52-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 34.81802, mean: 0.01978
[32m[0906 16-52-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: 40.62227, mean: 0.02244
[32m[0906 16-52-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01881, current rewards: 46.46109, mean: 0.02498
[32m[0906 16-52-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: 52.26434, mean: 0.02736
[32m[0906 16-52-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 58.06334, mean: 0.02962
[32m[0906 16-52-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 64.00671, mean: 0.03184
[32m[0906 16-52-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: 69.59733, mean: 0.03379
[32m[0906 16-52-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 75.19149, mean: 0.03564
[32m[0906 16-52-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 80.78762, mean: 0.03740
[32m[0906 16-52-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 86.38138, mean: 0.03909
[32m[0906 16-52-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 91.95386, mean: 0.04069
[32m[0906 16-52-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 97.54062, mean: 0.04223
[32m[0906 16-52-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 101.08333, mean: 0.04283
[32m[0906 16-52-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 107.54218, mean: 0.04462
[32m[0906 16-52-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 114.00101, mean: 0.04634
[32m[0906 16-52-50 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-52-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-52-50 @MBExp.py:227][0m Rewards obtained: [119.16806423256801], Lows: [2], Highs: [155], Total time: 4034.3952009999994
[32m[0906 16-55-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-55-49 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 16-55-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01800, current rewards: 1.12422, mean: 0.11242
[32m[0906 16-55-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.69153, mean: 0.11153
[32m[0906 16-55-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01850, current rewards: 12.25362, mean: 0.11140
[32m[0906 16-55-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.84275, mean: 0.11152
[32m[0906 16-55-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 23.41445, mean: 0.11150
[32m[0906 16-55-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01854, current rewards: 28.98040, mean: 0.11146
[32m[0906 16-55-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 34.54859, mean: 0.11145
[32m[0906 16-55-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 40.18833, mean: 0.11163
[32m[0906 16-55-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 45.77465, mean: 0.11165
[32m[0906 16-55-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.35934, mean: 0.11165
[32m[0906 16-55-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.94490, mean: 0.11166
[32m[0906 16-55-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.51364, mean: 0.11163
[32m[0906 16-56-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 68.09680, mean: 0.11163
[32m[0906 16-56-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 73.68225, mean: 0.11164
[32m[0906 16-56-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 79.27084, mean: 0.11165
[32m[0906 16-56-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.85845, mean: 0.11166
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 90.44682, mean: 0.11166
[32m[0906 16-56-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 94.93728, mean: 0.11039
[32m[0906 16-56-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 100.51166, mean: 0.11045
[32m[0906 16-56-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 105.99416, mean: 0.11041
[32m[0906 16-56-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 111.55780, mean: 0.11045
[32m[0906 16-56-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 117.11719, mean: 0.11049
[32m[0906 16-56-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01861, current rewards: 122.67325, mean: 0.11052
[32m[0906 16-56-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01863, current rewards: 128.23957, mean: 0.11055
[32m[0906 16-56-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01865, current rewards: 133.80350, mean: 0.11058
[32m[0906 16-56-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01868, current rewards: 139.36400, mean: 0.11061
[32m[0906 16-56-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01869, current rewards: 144.92435, mean: 0.11063
[32m[0906 16-56-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01872, current rewards: 150.49742, mean: 0.11066
[32m[0906 16-56-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01873, current rewards: 156.07169, mean: 0.11069
[32m[0906 16-56-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01874, current rewards: 161.63215, mean: 0.11071
[32m[0906 16-56-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01876, current rewards: 167.18457, mean: 0.11072
[32m[0906 16-56-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01877, current rewards: 172.74728, mean: 0.11074
[32m[0906 16-56-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01879, current rewards: 178.30791, mean: 0.11075
[32m[0906 16-56-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01880, current rewards: 183.86198, mean: 0.11076
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01881, current rewards: 189.43218, mean: 0.11078
[32m[0906 16-56-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 194.98661, mean: 0.11079
[32m[0906 16-56-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 200.65663, mean: 0.11086
[32m[0906 16-56-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01885, current rewards: 204.17941, mean: 0.10977
[32m[0906 16-56-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01886, current rewards: 209.76123, mean: 0.10982
[32m[0906 16-56-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01887, current rewards: 215.34437, mean: 0.10987
[32m[0906 16-56-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01888, current rewards: 220.92769, mean: 0.10991
[32m[0906 16-56-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 226.50952, mean: 0.10996
[32m[0906 16-56-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01890, current rewards: 232.09528, mean: 0.11000
[32m[0906 16-56-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 237.67909, mean: 0.11004
[32m[0906 16-56-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: 243.21595, mean: 0.11005
[32m[0906 16-56-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01892, current rewards: 248.77808, mean: 0.11008
[32m[0906 16-56-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 254.35926, mean: 0.11011
[32m[0906 16-56-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01894, current rewards: 259.93601, mean: 0.11014
[32m[0906 16-56-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01896, current rewards: 265.52441, mean: 0.11018
[32m[0906 16-56-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01897, current rewards: 271.10106, mean: 0.11020
[32m[0906 16-56-37 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 16-56-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-56-37 @MBExp.py:227][0m Rewards obtained: [275.56586968684235], Lows: [1], Highs: [1], Total time: 4082.6579139999994
[32m[0906 16-59-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-59-37 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 16-59-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01860, current rewards: 1.01672, mean: 0.10167
[32m[0906 16-59-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01852, current rewards: 6.57881, mean: 0.10965
[32m[0906 16-59-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 12.10769, mean: 0.11007
[32m[0906 16-59-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 17.67143, mean: 0.11045
[32m[0906 16-59-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 23.23307, mean: 0.11063
[32m[0906 16-59-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 28.79342, mean: 0.11074
[32m[0906 16-59-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 34.35496, mean: 0.11082
[32m[0906 16-59-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 39.83641, mean: 0.11066
[32m[0906 16-59-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01854, current rewards: 45.38624, mean: 0.11070
[32m[0906 16-59-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 50.93716, mean: 0.11073
[32m[0906 16-59-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 56.53090, mean: 0.11084
[32m[0906 16-59-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 62.18473, mean: 0.11104
[32m[0906 16-59-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 67.74848, mean: 0.11106
[32m[0906 16-59-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 73.31156, mean: 0.11108
[32m[0906 16-59-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 78.87614, mean: 0.11109
[32m[0906 16-59-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: 84.44038, mean: 0.11111
[32m[0906 16-59-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 90.00411, mean: 0.11112
[32m[0906 16-59-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 95.54410, mean: 0.11110
[32m[0906 16-59-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 101.10709, mean: 0.11111
[32m[0906 16-59-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 106.58040, mean: 0.11102
[32m[0906 16-59-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 112.12446, mean: 0.11101
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 117.67640, mean: 0.11102
[32m[0906 16-59-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 123.23046, mean: 0.11102
[32m[0906 16-59-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01865, current rewards: 128.78390, mean: 0.11102
[32m[0906 17-00-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01867, current rewards: 134.31572, mean: 0.11100
[32m[0906 17-00-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01869, current rewards: 139.85094, mean: 0.11099
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01872, current rewards: 145.39218, mean: 0.11099
[32m[0906 17-00-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01873, current rewards: 150.95802, mean: 0.11100
[32m[0906 17-00-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01875, current rewards: 156.50418, mean: 0.11100
[32m[0906 17-00-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01877, current rewards: 162.04335, mean: 0.11099
[32m[0906 17-00-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01878, current rewards: 167.58778, mean: 0.11099
[32m[0906 17-00-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01880, current rewards: 173.09220, mean: 0.11096
[32m[0906 17-00-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01881, current rewards: 178.64591, mean: 0.11096
[32m[0906 17-00-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01882, current rewards: 184.20524, mean: 0.11097
[32m[0906 17-00-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01883, current rewards: 189.76214, mean: 0.11097
[32m[0906 17-00-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 195.31173, mean: 0.11097
[32m[0906 17-00-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 200.78644, mean: 0.11093
[32m[0906 17-00-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01885, current rewards: 206.33177, mean: 0.11093
[32m[0906 17-00-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01886, current rewards: 211.87778, mean: 0.11093
[32m[0906 17-00-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01887, current rewards: 217.42251, mean: 0.11093
[32m[0906 17-00-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01888, current rewards: 222.97006, mean: 0.11093
[32m[0906 17-00-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 228.51719, mean: 0.11093
[32m[0906 17-00-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01890, current rewards: 234.03272, mean: 0.11092
[32m[0906 17-00-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01890, current rewards: 239.56726, mean: 0.11091
[32m[0906 17-00-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 245.21721, mean: 0.11096
[32m[0906 17-00-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 250.76998, mean: 0.11096
[32m[0906 17-00-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 256.32654, mean: 0.11096
[32m[0906 17-00-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01892, current rewards: 261.88049, mean: 0.11097
[32m[0906 17-00-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01893, current rewards: 267.39978, mean: 0.11095
[32m[0906 17-00-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 272.96593, mean: 0.11096
[32m[0906 17-00-25 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-00-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-00-25 @MBExp.py:227][0m Rewards obtained: [277.4165152685468], Lows: [0], Highs: [0], Total time: 4130.790830999999
[32m[0906 17-03-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-03-27 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-03-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01858, current rewards: -0.84308, mean: -0.08431
[32m[0906 17-03-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01846, current rewards: 4.74659, mean: 0.07911
[32m[0906 17-03-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 10.35495, mean: 0.09414
[32m[0906 17-03-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 15.96613, mean: 0.09979
[32m[0906 17-03-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 21.57228, mean: 0.10273
[32m[0906 17-03-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 27.18202, mean: 0.10455
[32m[0906 17-03-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 32.78571, mean: 0.10576
[32m[0906 17-03-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 38.34470, mean: 0.10651
[32m[0906 17-03-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 43.90020, mean: 0.10707
[32m[0906 17-03-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 49.45094, mean: 0.10750
[32m[0906 17-03-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 55.00107, mean: 0.10785
[32m[0906 17-03-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: 60.55013, mean: 0.10813
[32m[0906 17-03-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 66.10102, mean: 0.10836
[32m[0906 17-03-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 71.65257, mean: 0.10856
[32m[0906 17-03-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 77.20266, mean: 0.10874
[32m[0906 17-03-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 82.75347, mean: 0.10889
[32m[0906 17-03-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 88.30846, mean: 0.10902
[32m[0906 17-03-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 93.85559, mean: 0.10913
[32m[0906 17-03-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 99.33233, mean: 0.10916
[32m[0906 17-03-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 104.81898, mean: 0.10919
[32m[0906 17-03-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 110.30817, mean: 0.10922
[32m[0906 17-03-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01861, current rewards: 115.79923, mean: 0.10924
[32m[0906 17-03-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 121.29151, mean: 0.10927
[32m[0906 17-03-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01865, current rewards: 126.77944, mean: 0.10929
[32m[0906 17-03-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01867, current rewards: 132.27465, mean: 0.10932
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01869, current rewards: 137.76342, mean: 0.10934
[32m[0906 17-03-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01871, current rewards: 143.25604, mean: 0.10936
[32m[0906 17-03-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01873, current rewards: 148.66707, mean: 0.10931
[32m[0906 17-03-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01873, current rewards: 154.16234, mean: 0.10933
[32m[0906 17-03-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01875, current rewards: 159.65839, mean: 0.10936
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01876, current rewards: 165.15312, mean: 0.10937
[32m[0906 17-03-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01877, current rewards: 170.64954, mean: 0.10939
[32m[0906 17-03-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: 176.15096, mean: 0.10941
[32m[0906 17-03-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01880, current rewards: 181.64604, mean: 0.10943
[32m[0906 17-04-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01881, current rewards: 187.32877, mean: 0.10955
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01882, current rewards: 192.98461, mean: 0.10965
[32m[0906 17-04-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 198.53024, mean: 0.10969
[32m[0906 17-04-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 204.07336, mean: 0.10972
[32m[0906 17-04-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01886, current rewards: 209.61190, mean: 0.10974
[32m[0906 17-04-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01887, current rewards: 215.15264, mean: 0.10977
[32m[0906 17-04-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01888, current rewards: 220.69399, mean: 0.10980
[32m[0906 17-04-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 225.24608, mean: 0.10934
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 230.85788, mean: 0.10941
[32m[0906 17-04-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01890, current rewards: 236.50003, mean: 0.10949
[32m[0906 17-04-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 242.12700, mean: 0.10956
[32m[0906 17-04-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 247.73652, mean: 0.10962
[32m[0906 17-04-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 253.34922, mean: 0.10967
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 258.96130, mean: 0.10973
[32m[0906 17-04-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01894, current rewards: 264.57544, mean: 0.10978
[32m[0906 17-04-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 270.19017, mean: 0.10983
[32m[0906 17-04-15 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-04-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-04-15 @MBExp.py:227][0m Rewards obtained: [274.6773612148938], Lows: [1], Highs: [1], Total time: 4178.95735
[32m[0906 17-07-20 @MBExp.py:144][0m ####################################################################
[32m[0906 17-07-20 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-07-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 1.14950, mean: 0.11495
[32m[0906 17-07-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01844, current rewards: 6.72078, mean: 0.11201
[32m[0906 17-07-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01844, current rewards: 12.25638, mean: 0.11142
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 17.78814, mean: 0.11118
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01848, current rewards: 23.32323, mean: 0.11106
[32m[0906 17-07-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 30.80255, mean: 0.11847
[32m[0906 17-07-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 40.13600, mean: 0.12947
[32m[0906 17-07-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 49.46945, mean: 0.13742
[32m[0906 17-07-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 58.80289, mean: 0.14342
[32m[0906 17-07-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 68.13634, mean: 0.14812
[32m[0906 17-07-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 57.57383, mean: 0.11289
[32m[0906 17-07-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 7.57383, mean: 0.01352
[32m[0906 17-07-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: -42.42617, mean: -0.06955
[32m[0906 17-07-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: -92.42617, mean: -0.14004
[32m[0906 17-07-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: -142.42617, mean: -0.20060
[32m[0906 17-07-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: -192.42617, mean: -0.25319
[32m[0906 17-07-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01849, current rewards: -242.42617, mean: -0.29929
[32m[0906 17-07-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: -292.42617, mean: -0.34003
[32m[0906 17-07-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: -342.42617, mean: -0.37629
[32m[0906 17-07-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01848, current rewards: -392.42617, mean: -0.40878
[32m[0906 17-07-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: -442.42617, mean: -0.43805
[32m[0906 17-07-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: -492.42617, mean: -0.46455
[32m[0906 17-07-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: -542.42617, mean: -0.48867
[32m[0906 17-07-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: -592.42617, mean: -0.51071
[32m[0906 17-07-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01862, current rewards: -642.42617, mean: -0.53093
[32m[0906 17-07-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01865, current rewards: -692.42617, mean: -0.54954
[32m[0906 17-07-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01868, current rewards: -742.42617, mean: -0.56674
[32m[0906 17-07-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: -792.42617, mean: -0.58267
[32m[0906 17-07-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01872, current rewards: -842.42617, mean: -0.59747
[32m[0906 17-07-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01872, current rewards: -892.42617, mean: -0.61125
[32m[0906 17-07-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: -942.42617, mean: -0.62412
[32m[0906 17-07-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01875, current rewards: -992.42617, mean: -0.63617
[32m[0906 17-07-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: -1042.42617, mean: -0.64747
[32m[0906 17-07-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01877, current rewards: -1092.42617, mean: -0.65809
[32m[0906 17-07-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: -1142.42617, mean: -0.66809
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: -1192.42617, mean: -0.67751
[32m[0906 17-07-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01880, current rewards: -1242.42617, mean: -0.68642
[32m[0906 17-07-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: -1292.42617, mean: -0.69485
[32m[0906 17-07-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01882, current rewards: -1342.42617, mean: -0.70284
[32m[0906 17-07-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: -1392.42617, mean: -0.71042
[32m[0906 17-07-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01884, current rewards: -1442.42617, mean: -0.71762
[32m[0906 17-07-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: -1492.42617, mean: -0.72448
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: -1542.42617, mean: -0.73101
[32m[0906 17-08-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01886, current rewards: -1592.42617, mean: -0.73723
[32m[0906 17-08-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: -1642.42617, mean: -0.74318
[32m[0906 17-08-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: -1692.42617, mean: -0.74886
[32m[0906 17-08-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: -1742.42617, mean: -0.75430
[32m[0906 17-08-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: -1792.42617, mean: -0.75950
[32m[0906 17-08-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: -1842.42617, mean: -0.76449
[32m[0906 17-08-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: -1892.42617, mean: -0.76928
[32m[0906 17-08-07 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-08-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-08-08 @MBExp.py:227][0m Rewards obtained: [-1932.426174056358], Lows: [0], Highs: [2006], Total time: 4227.011697999999
[32m[0906 17-11-14 @MBExp.py:144][0m ####################################################################
[32m[0906 17-11-14 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-11-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01822, current rewards: 1.14504, mean: 0.11450
[32m[0906 17-11-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 6.69307, mean: 0.11155
[32m[0906 17-11-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01847, current rewards: 12.17964, mean: 0.11072
[32m[0906 17-11-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.66216, mean: 0.11039
[32m[0906 17-11-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.15685, mean: 0.11027
[32m[0906 17-11-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01854, current rewards: 28.65434, mean: 0.11021
[32m[0906 17-11-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 34.14767, mean: 0.11015
[32m[0906 17-11-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.64193, mean: 0.11012
[32m[0906 17-11-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 45.13806, mean: 0.11009
[32m[0906 17-11-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 50.63281, mean: 0.11007
[32m[0906 17-11-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 56.13006, mean: 0.11006
[32m[0906 17-11-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 59.77637, mean: 0.10674
[32m[0906 17-11-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 65.51204, mean: 0.10740
[32m[0906 17-11-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 71.24837, mean: 0.10795
[32m[0906 17-11-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 76.98507, mean: 0.10843
[32m[0906 17-11-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 82.72139, mean: 0.10884
[32m[0906 17-11-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 88.45743, mean: 0.10921
[32m[0906 17-11-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 94.05186, mean: 0.10936
[32m[0906 17-11-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 99.58814, mean: 0.10944
[32m[0906 17-11-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 105.01988, mean: 0.10940
[32m[0906 17-11-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 110.60101, mean: 0.10951
[32m[0906 17-11-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01859, current rewards: 116.18679, mean: 0.10961
[32m[0906 17-11-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01861, current rewards: 121.76649, mean: 0.10970
[32m[0906 17-11-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 127.35289, mean: 0.10979
[32m[0906 17-11-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01867, current rewards: 132.93597, mean: 0.10986
[32m[0906 17-11-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01868, current rewards: 138.51872, mean: 0.10994
[32m[0906 17-11-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01870, current rewards: 144.10529, mean: 0.11000
[32m[0906 17-11-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01872, current rewards: 149.69429, mean: 0.11007
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01873, current rewards: 155.26830, mean: 0.11012
[32m[0906 17-11-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01875, current rewards: 160.84667, mean: 0.11017
[32m[0906 17-11-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01877, current rewards: 166.42344, mean: 0.11021
[32m[0906 17-11-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01878, current rewards: 171.99886, mean: 0.11026
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01879, current rewards: 177.57966, mean: 0.11030
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01880, current rewards: 183.09052, mean: 0.11030
[32m[0906 17-11-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01882, current rewards: 188.60923, mean: 0.11030
[32m[0906 17-11-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 194.12347, mean: 0.11030
[32m[0906 17-11-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 199.63930, mean: 0.11030
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01885, current rewards: 205.15601, mean: 0.11030
[32m[0906 17-11-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01886, current rewards: 210.67189, mean: 0.11030
[32m[0906 17-11-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01887, current rewards: 216.18615, mean: 0.11030
[32m[0906 17-11-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01888, current rewards: 221.69884, mean: 0.11030
[32m[0906 17-11-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01889, current rewards: 227.21439, mean: 0.11030
[32m[0906 17-11-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: 232.72313, mean: 0.11030
[32m[0906 17-11-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01890, current rewards: 238.25574, mean: 0.11030
[32m[0906 17-11-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01891, current rewards: 243.77970, mean: 0.11031
[32m[0906 17-11-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: 247.27236, mean: 0.10941
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 252.90263, mean: 0.10948
[32m[0906 17-11-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01893, current rewards: 258.53245, mean: 0.10955
[32m[0906 17-12-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01894, current rewards: 264.15648, mean: 0.10961
[32m[0906 17-12-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01894, current rewards: 269.77761, mean: 0.10967
[32m[0906 17-12-02 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-12-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-12-02 @MBExp.py:227][0m Rewards obtained: [274.28288528203717], Lows: [2], Highs: [0], Total time: 4275.182972
[32m[0906 17-15-10 @MBExp.py:144][0m ####################################################################
[32m[0906 17-15-10 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 17-15-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01838, current rewards: 1.18931, mean: 0.11893
[32m[0906 17-15-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 6.69146, mean: 0.11152
[32m[0906 17-15-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 12.16495, mean: 0.11059
[32m[0906 17-15-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01841, current rewards: 17.66686, mean: 0.11042
[32m[0906 17-15-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01839, current rewards: 23.16929, mean: 0.11033
[32m[0906 17-15-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01841, current rewards: 28.67368, mean: 0.11028
[32m[0906 17-15-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01841, current rewards: 34.17448, mean: 0.11024
[32m[0906 17-15-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01842, current rewards: 39.67800, mean: 0.11022
[32m[0906 17-15-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01843, current rewards: 45.17855, mean: 0.11019
[32m[0906 17-15-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01844, current rewards: 50.67530, mean: 0.11016
[32m[0906 17-15-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.85688, mean: 0.11148
[32m[0906 17-15-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 64.71642, mean: 0.11557
[32m[0906 17-15-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01845, current rewards: 47.11776, mean: 0.07724
[32m[0906 17-15-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01844, current rewards: -2.88224, mean: -0.00437
[32m[0906 17-15-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01846, current rewards: -52.88224, mean: -0.07448
[32m[0906 17-15-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: -102.88224, mean: -0.13537
[32m[0906 17-15-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: -152.88224, mean: -0.18874
[32m[0906 17-15-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01846, current rewards: -202.88224, mean: -0.23591
[32m[0906 17-15-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01846, current rewards: -252.88224, mean: -0.27789
[32m[0906 17-15-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01848, current rewards: -302.88224, mean: -0.31550
[32m[0906 17-15-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: -352.88224, mean: -0.34939
[32m[0906 17-15-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: -402.88224, mean: -0.38008
[32m[0906 17-15-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: -452.88224, mean: -0.40800
[32m[0906 17-15-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: -502.88224, mean: -0.43352
[32m[0906 17-15-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: -552.88224, mean: -0.45693
[32m[0906 17-15-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: -602.88224, mean: -0.47848
[32m[0906 17-15-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: -652.88224, mean: -0.49838
[32m[0906 17-15-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: -702.88224, mean: -0.51683
[32m[0906 17-15-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: -752.88224, mean: -0.53396
[32m[0906 17-15-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: -802.88224, mean: -0.54992
[32m[0906 17-15-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01870, current rewards: -852.88224, mean: -0.56482
[32m[0906 17-15-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01871, current rewards: -902.88224, mean: -0.57877
[32m[0906 17-15-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: -952.88224, mean: -0.59185
[32m[0906 17-15-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: -1002.88224, mean: -0.60415
[32m[0906 17-15-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: -1052.88224, mean: -0.61572
[32m[0906 17-15-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: -1102.88224, mean: -0.62664
[32m[0906 17-15-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: -1152.88224, mean: -0.63695
[32m[0906 17-15-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: -1202.88224, mean: -0.64671
[32m[0906 17-15-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: -1252.88224, mean: -0.65596
[32m[0906 17-15-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01882, current rewards: -1302.88224, mean: -0.66474
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: -1352.88224, mean: -0.67308
[32m[0906 17-15-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: -1402.88224, mean: -0.68101
[32m[0906 17-15-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: -1452.88224, mean: -0.68857
[32m[0906 17-15-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: -1502.88224, mean: -0.69578
[32m[0906 17-15-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: -1552.88224, mean: -0.70266
[32m[0906 17-15-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: -1602.88224, mean: -0.70924
[32m[0906 17-15-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: -1652.88224, mean: -0.71553
[32m[0906 17-15-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: -1702.88224, mean: -0.72156
[32m[0906 17-15-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: -1752.88224, mean: -0.72734
[32m[0906 17-15-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: -1802.88224, mean: -0.73288
[32m[0906 17-15-58 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-15-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-15-58 @MBExp.py:227][0m Rewards obtained: [-1842.8822425902365], Lows: [0], Highs: [1912], Total time: 4323.218577
[32m[0906 17-19-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-19-09 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 17-19-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01843, current rewards: 0.10340, mean: 0.01034
[32m[0906 17-19-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01841, current rewards: 5.68165, mean: 0.09469
[32m[0906 17-19-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 11.40030, mean: 0.10364
[32m[0906 17-19-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01841, current rewards: 16.98618, mean: 0.10616
[32m[0906 17-19-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 20.85110, mean: 0.09929
[32m[0906 17-19-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 29.63976, mean: 0.11400
[32m[0906 17-19-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01844, current rewards: 38.42843, mean: 0.12396
[32m[0906 17-19-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01845, current rewards: 47.21709, mean: 0.13116
[32m[0906 17-19-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 53.71448, mean: 0.13101
[32m[0906 17-19-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 56.13849, mean: 0.12204
[32m[0906 17-19-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 50.17465, mean: 0.09838
[32m[0906 17-19-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 0.17465, mean: 0.00031
[32m[0906 17-19-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01847, current rewards: -49.82535, mean: -0.08168
[32m[0906 17-19-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: -99.82535, mean: -0.15125
[32m[0906 17-19-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01847, current rewards: -149.82535, mean: -0.21102
[32m[0906 17-19-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01846, current rewards: -199.82535, mean: -0.26293
[32m[0906 17-19-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01845, current rewards: -249.82535, mean: -0.30843
[32m[0906 17-19-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01844, current rewards: -299.82535, mean: -0.34863
[32m[0906 17-19-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01843, current rewards: -349.82535, mean: -0.38442
[32m[0906 17-19-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01847, current rewards: -358.71023, mean: -0.37366
[32m[0906 17-19-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: -353.13281, mean: -0.34964
[32m[0906 17-19-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: -347.55539, mean: -0.32788
[32m[0906 17-19-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: -341.97754, mean: -0.30809
[32m[0906 17-19-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: -336.39471, mean: -0.29000
[32m[0906 17-19-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01863, current rewards: -330.81797, mean: -0.27340
[32m[0906 17-19-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01865, current rewards: -325.10093, mean: -0.25802
[32m[0906 17-19-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01867, current rewards: -319.53893, mean: -0.24392
[32m[0906 17-19-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: -313.91274, mean: -0.23082
[32m[0906 17-19-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: -308.35152, mean: -0.21869
[32m[0906 17-19-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: -302.78343, mean: -0.20739
[32m[0906 17-19-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: -297.21542, mean: -0.19683
[32m[0906 17-19-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01875, current rewards: -291.65065, mean: -0.18696
[32m[0906 17-19-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: -286.08842, mean: -0.17769
[32m[0906 17-19-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01878, current rewards: -280.51612, mean: -0.16899
[32m[0906 17-19-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01878, current rewards: -274.95483, mean: -0.16079
[32m[0906 17-19-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: -269.38747, mean: -0.15306
[32m[0906 17-19-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01881, current rewards: -263.82305, mean: -0.14576
[32m[0906 17-19-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: -258.25281, mean: -0.13885
[32m[0906 17-19-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: -252.68256, mean: -0.13229
[32m[0906 17-19-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01884, current rewards: -247.10384, mean: -0.12607
[32m[0906 17-19-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: -241.53511, mean: -0.12017
[32m[0906 17-19-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01886, current rewards: -235.96179, mean: -0.11454
[32m[0906 17-19-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: -230.38941, mean: -0.10919
[32m[0906 17-19-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: -224.84956, mean: -0.10410
[32m[0906 17-19-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: -219.30383, mean: -0.09923
[32m[0906 17-19-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: -213.73132, mean: -0.09457
[32m[0906 17-19-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: -208.16379, mean: -0.09011
[32m[0906 17-19-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: -202.58583, mean: -0.08584
[32m[0906 17-19-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: -197.01026, mean: -0.08175
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: -191.43263, mean: -0.07782
[32m[0906 17-19-57 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-19-57 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-19-57 @MBExp.py:227][0m Rewards obtained: [-186.9745831547423], Lows: [1], Highs: [422], Total time: 4371.305641
[32m[0906 17-23-08 @MBExp.py:144][0m ####################################################################
[32m[0906 17-23-08 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 17-23-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01876, current rewards: 1.14187, mean: 0.11419
[32m[0906 17-23-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01857, current rewards: 6.74703, mean: 0.11245
[32m[0906 17-23-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 12.30763, mean: 0.11189
[32m[0906 17-23-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01850, current rewards: 17.86338, mean: 0.11165
[32m[0906 17-23-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 23.41868, mean: 0.11152
[32m[0906 17-23-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.97214, mean: 0.11143
[32m[0906 17-23-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.58718, mean: 0.11157
[32m[0906 17-23-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.14205, mean: 0.11151
[32m[0906 17-23-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 45.69944, mean: 0.11146
[32m[0906 17-23-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.25577, mean: 0.11143
[32m[0906 17-23-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.74096, mean: 0.11126
[32m[0906 17-23-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 62.24423, mean: 0.11115
[32m[0906 17-23-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 67.80348, mean: 0.11115
[32m[0906 17-23-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 73.36004, mean: 0.11115
[32m[0906 17-23-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 78.92764, mean: 0.11117
[32m[0906 17-23-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: 84.48803, mean: 0.11117
[32m[0906 17-23-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 90.04795, mean: 0.11117
[32m[0906 17-23-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 95.55145, mean: 0.11111
[32m[0906 17-23-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 101.04628, mean: 0.11104
[32m[0906 17-23-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 106.55784, mean: 0.11100
[32m[0906 17-23-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 112.05929, mean: 0.11095
[32m[0906 17-23-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 117.56675, mean: 0.11091
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01862, current rewards: 123.07096, mean: 0.11087
[32m[0906 17-23-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01865, current rewards: 128.57318, mean: 0.11084
[32m[0906 17-23-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01867, current rewards: 134.07507, mean: 0.11081
[32m[0906 17-23-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01870, current rewards: 139.58033, mean: 0.11078
[32m[0906 17-23-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01871, current rewards: 145.08752, mean: 0.11075
[32m[0906 17-23-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01873, current rewards: 150.73631, mean: 0.11084
[32m[0906 17-23-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01874, current rewards: 156.24630, mean: 0.11081
[32m[0906 17-23-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01876, current rewards: 161.75901, mean: 0.11079
[32m[0906 17-23-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01878, current rewards: 167.27058, mean: 0.11078
[32m[0906 17-23-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01879, current rewards: 174.24058, mean: 0.11169
[32m[0906 17-23-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01880, current rewards: 181.00462, mean: 0.11243
[32m[0906 17-23-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01881, current rewards: 187.76866, mean: 0.11311
[32m[0906 17-23-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01882, current rewards: 194.53270, mean: 0.11376
[32m[0906 17-23-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 201.27084, mean: 0.11436
[32m[0906 17-23-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01883, current rewards: 205.58639, mean: 0.11358
[32m[0906 17-23-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 209.82767, mean: 0.11281
[32m[0906 17-23-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01885, current rewards: 214.06894, mean: 0.11208
[32m[0906 17-23-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01886, current rewards: 189.01993, mean: 0.09644
[32m[0906 17-23-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 139.01993, mean: 0.06916
[32m[0906 17-23-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01887, current rewards: 89.01993, mean: 0.04321
[32m[0906 17-23-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 39.01993, mean: 0.01849
[32m[0906 17-23-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: -10.98007, mean: -0.00508
[32m[0906 17-23-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: -60.98007, mean: -0.02759
[32m[0906 17-23-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: -110.98007, mean: -0.04911
[32m[0906 17-23-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: -160.98007, mean: -0.06969
[32m[0906 17-23-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: -210.98007, mean: -0.08940
[32m[0906 17-23-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: -260.98007, mean: -0.10829
[32m[0906 17-23-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: -310.98007, mean: -0.12641
[32m[0906 17-23-56 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-23-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-23-57 @MBExp.py:227][0m Rewards obtained: [-350.98007223883167], Lows: [0], Highs: [567], Total time: 4419.43494
[32m[0906 17-27-10 @MBExp.py:144][0m ####################################################################
[32m[0906 17-27-10 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 17-27-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01858, current rewards: 1.15676, mean: 0.11568
[32m[0906 17-27-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01858, current rewards: 6.70592, mean: 0.11177
[32m[0906 17-27-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01858, current rewards: 12.22968, mean: 0.11118
[32m[0906 17-27-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.78003, mean: 0.11113
[32m[0906 17-27-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01847, current rewards: 23.32898, mean: 0.11109
[32m[0906 17-27-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 28.84001, mean: 0.11092
[32m[0906 17-27-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 34.33028, mean: 0.11074
[32m[0906 17-27-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.82340, mean: 0.11062
[32m[0906 17-27-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: 45.31320, mean: 0.11052
[32m[0906 17-27-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 50.80439, mean: 0.11044
[32m[0906 17-27-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 56.29689, mean: 0.11039
[32m[0906 17-27-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 61.79523, mean: 0.11035
[32m[0906 17-27-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.29274, mean: 0.11032
[32m[0906 17-27-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 72.78610, mean: 0.11028
[32m[0906 17-27-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 78.27963, mean: 0.11025
[32m[0906 17-27-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 83.77190, mean: 0.11023
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 89.26765, mean: 0.11021
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 94.77450, mean: 0.11020
[32m[0906 17-27-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 100.36388, mean: 0.11029
[32m[0906 17-27-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 105.89961, mean: 0.11031
[32m[0906 17-27-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 111.43745, mean: 0.11033
[32m[0906 17-27-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 116.96864, mean: 0.11035
[32m[0906 17-27-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 122.50528, mean: 0.11037
[32m[0906 17-27-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 128.01214, mean: 0.11036
[32m[0906 17-27-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: 133.47461, mean: 0.11031
[32m[0906 17-27-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: 138.94005, mean: 0.11027
[32m[0906 17-27-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: 144.41482, mean: 0.11024
[32m[0906 17-27-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01864, current rewards: 149.88346, mean: 0.11021
[32m[0906 17-27-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01866, current rewards: 155.36167, mean: 0.11019
[32m[0906 17-27-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01868, current rewards: 160.90146, mean: 0.11021
[32m[0906 17-27-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01870, current rewards: 166.44256, mean: 0.11023
[32m[0906 17-27-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: 171.97981, mean: 0.11024
[32m[0906 17-27-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: 177.52475, mean: 0.11026
[32m[0906 17-27-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: 183.06484, mean: 0.11028
[32m[0906 17-27-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: 188.58769, mean: 0.11029
[32m[0906 17-27-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: 194.05696, mean: 0.11026
[32m[0906 17-27-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 199.58757, mean: 0.11027
[32m[0906 17-27-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 205.11452, mean: 0.11028
[32m[0906 17-27-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 210.64387, mean: 0.11028
[32m[0906 17-27-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 216.16659, mean: 0.11029
[32m[0906 17-27-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 221.69085, mean: 0.11029
[32m[0906 17-27-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 227.21334, mean: 0.11030
[32m[0906 17-27-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 232.73591, mean: 0.11030
[32m[0906 17-27-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 238.20772, mean: 0.11028
[32m[0906 17-27-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 243.73112, mean: 0.11029
[32m[0906 17-27-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 249.26195, mean: 0.11029
[32m[0906 17-27-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 254.78793, mean: 0.11030
[32m[0906 17-27-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 260.31138, mean: 0.11030
[32m[0906 17-27-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 265.83785, mean: 0.11031
[32m[0906 17-27-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 271.36758, mean: 0.11031
[32m[0906 17-27-58 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-27-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-27-58 @MBExp.py:227][0m Rewards obtained: [275.7915601876801], Lows: [0], Highs: [0], Total time: 4467.490257
[32m[0906 17-31-14 @MBExp.py:144][0m ####################################################################
[32m[0906 17-31-14 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 17-31-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01847, current rewards: 1.02532, mean: 0.10253
[32m[0906 17-31-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01849, current rewards: 6.52831, mean: 0.10881
[32m[0906 17-31-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 12.06868, mean: 0.10972
[32m[0906 17-31-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.61907, mean: 0.11012
[32m[0906 17-31-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01851, current rewards: 23.16496, mean: 0.11031
[32m[0906 17-31-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 28.71001, mean: 0.11042
[32m[0906 17-31-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.25776, mean: 0.11051
[32m[0906 17-31-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01845, current rewards: 39.80152, mean: 0.11056
[32m[0906 17-31-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.38592, mean: 0.11070
[32m[0906 17-31-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01845, current rewards: 50.97265, mean: 0.11081
[32m[0906 17-31-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.56394, mean: 0.11091
[32m[0906 17-31-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 62.15540, mean: 0.11099
[32m[0906 17-31-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01846, current rewards: 67.74327, mean: 0.11105
[32m[0906 17-31-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: 73.33678, mean: 0.11112
[32m[0906 17-31-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 78.92482, mean: 0.11116
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 84.51764, mean: 0.11121
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 90.10821, mean: 0.11124
[32m[0906 17-31-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01848, current rewards: 95.70300, mean: 0.11128
[32m[0906 17-31-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 101.37043, mean: 0.11140
[32m[0906 17-31-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 107.08651, mean: 0.11155
[32m[0906 17-31-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 112.67701, mean: 0.11156
[32m[0906 17-31-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 118.26755, mean: 0.11157
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 123.85891, mean: 0.11158
[32m[0906 17-31-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 129.44883, mean: 0.11159
[32m[0906 17-31-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01859, current rewards: 135.03659, mean: 0.11160
[32m[0906 17-31-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01862, current rewards: 141.37086, mean: 0.11220
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01864, current rewards: 147.03690, mean: 0.11224
[32m[0906 17-31-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: 152.58300, mean: 0.11219
[32m[0906 17-31-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: 158.14676, mean: 0.11216
[32m[0906 17-31-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01871, current rewards: 163.70469, mean: 0.11213
[32m[0906 17-31-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01873, current rewards: 169.26462, mean: 0.11210
[32m[0906 17-31-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01875, current rewards: 174.82311, mean: 0.11207
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: 180.38490, mean: 0.11204
[32m[0906 17-31-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01877, current rewards: 185.94695, mean: 0.11202
[32m[0906 17-31-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: 191.50604, mean: 0.11199
[32m[0906 17-31-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01880, current rewards: 197.85676, mean: 0.11242
[32m[0906 17-31-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01881, current rewards: 157.05039, mean: 0.08677
[32m[0906 17-31-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 107.05039, mean: 0.05755
[32m[0906 17-31-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 57.05039, mean: 0.02987
[32m[0906 17-31-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01885, current rewards: 7.05039, mean: 0.00360
[32m[0906 17-31-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01886, current rewards: -42.94961, mean: -0.02137
[32m[0906 17-31-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01887, current rewards: -92.94961, mean: -0.04512
[32m[0906 17-31-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: -142.94961, mean: -0.06775
[32m[0906 17-31-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: -192.94961, mean: -0.08933
[32m[0906 17-31-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: -242.94961, mean: -0.10993
[32m[0906 17-31-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: -292.94961, mean: -0.12962
[32m[0906 17-31-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: -342.94961, mean: -0.14846
[32m[0906 17-31-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: -392.94961, mean: -0.16650
[32m[0906 17-32-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: -442.94961, mean: -0.18380
[32m[0906 17-32-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: -492.94961, mean: -0.20039
[32m[0906 17-32-02 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-32-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-32-02 @MBExp.py:227][0m Rewards obtained: [-532.9496052657543], Lows: [0], Highs: [732], Total time: 4515.629173
[32m[0906 17-35-20 @MBExp.py:144][0m ####################################################################
[32m[0906 17-35-20 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 17-35-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01831, current rewards: 1.04534, mean: 0.10453
[32m[0906 17-35-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01840, current rewards: 6.53513, mean: 0.10892
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01847, current rewards: 12.03854, mean: 0.10944
[32m[0906 17-35-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 17.53283, mean: 0.10958
[32m[0906 17-35-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 23.02811, mean: 0.10966
[32m[0906 17-35-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 28.52269, mean: 0.10970
[32m[0906 17-35-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01856, current rewards: 34.01553, mean: 0.10973
[32m[0906 17-35-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 39.51100, mean: 0.10975
[32m[0906 17-35-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 45.00488, mean: 0.10977
[32m[0906 17-35-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.49946, mean: 0.10978
[32m[0906 17-35-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 55.84159, mean: 0.10949
[32m[0906 17-35-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 61.31863, mean: 0.10950
[32m[0906 17-35-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 66.79080, mean: 0.10949
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 72.26402, mean: 0.10949
[32m[0906 17-35-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 77.74238, mean: 0.10950
[32m[0906 17-35-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 83.22156, mean: 0.10950
[32m[0906 17-35-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 88.69391, mean: 0.10950
[32m[0906 17-35-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: 94.22512, mean: 0.10956
[32m[0906 17-35-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 99.77849, mean: 0.10965
[32m[0906 17-35-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 105.28589, mean: 0.10967
[32m[0906 17-35-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 110.79244, mean: 0.10970
[32m[0906 17-35-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01848, current rewards: 116.29796, mean: 0.10972
[32m[0906 17-35-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01850, current rewards: 121.80471, mean: 0.10973
[32m[0906 17-35-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 127.31270, mean: 0.10975
[32m[0906 17-35-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 132.81800, mean: 0.10977
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: 138.32906, mean: 0.10978
[32m[0906 17-35-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 143.76714, mean: 0.10975
[32m[0906 17-35-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 149.33284, mean: 0.10980
[32m[0906 17-35-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01865, current rewards: 154.80422, mean: 0.10979
[32m[0906 17-35-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01867, current rewards: 160.27761, mean: 0.10978
[32m[0906 17-35-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: 165.75111, mean: 0.10977
[32m[0906 17-35-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: 171.21466, mean: 0.10975
[32m[0906 17-35-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01872, current rewards: 176.64693, mean: 0.10972
[32m[0906 17-35-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: 182.16563, mean: 0.10974
[32m[0906 17-35-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01873, current rewards: 187.68804, mean: 0.10976
[32m[0906 17-35-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: 193.16002, mean: 0.10975
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 198.67675, mean: 0.10977
[32m[0906 17-35-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01878, current rewards: 204.19680, mean: 0.10978
[32m[0906 17-35-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01879, current rewards: 209.71330, mean: 0.10980
[32m[0906 17-35-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: 215.23248, mean: 0.10981
[32m[0906 17-35-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: 220.75400, mean: 0.10983
[32m[0906 17-36-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 226.33421, mean: 0.10987
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 231.84782, mean: 0.10988
[32m[0906 17-36-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 237.40076, mean: 0.10991
[32m[0906 17-36-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 242.90562, mean: 0.10991
[32m[0906 17-36-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 248.41251, mean: 0.10992
[32m[0906 17-36-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 253.92093, mean: 0.10992
[32m[0906 17-36-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 259.43903, mean: 0.10993
[32m[0906 17-36-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 264.93402, mean: 0.10993
[32m[0906 17-36-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 270.42886, mean: 0.10993
[32m[0906 17-36-08 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-36-08 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-36-08 @MBExp.py:227][0m Rewards obtained: [274.8282124886606], Lows: [0], Highs: [0], Total time: 4563.670588
[32m[0906 17-39-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-39-28 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 17-39-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01802, current rewards: 1.11220, mean: 0.11122
[32m[0906 17-39-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 6.69672, mean: 0.11161
[32m[0906 17-39-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 12.17697, mean: 0.11070
[32m[0906 17-39-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01841, current rewards: 17.72036, mean: 0.11075
[32m[0906 17-39-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.26234, mean: 0.11077
[32m[0906 17-39-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 29.03534, mean: 0.11167
[32m[0906 17-39-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.58209, mean: 0.11156
[32m[0906 17-39-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.12924, mean: 0.11147
[32m[0906 17-39-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.68272, mean: 0.11142
[32m[0906 17-39-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 51.23244, mean: 0.11137
[32m[0906 17-39-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01843, current rewards: 56.73352, mean: 0.11124
[32m[0906 17-39-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01842, current rewards: 62.29112, mean: 0.11123
[32m[0906 17-39-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01844, current rewards: 67.84773, mean: 0.11123
[32m[0906 17-39-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01844, current rewards: 73.40490, mean: 0.11122
[32m[0906 17-39-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01844, current rewards: 78.96289, mean: 0.11122
[32m[0906 17-39-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01845, current rewards: 84.51380, mean: 0.11120
[32m[0906 17-39-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01845, current rewards: 90.07098, mean: 0.11120
[32m[0906 17-39-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 95.62265, mean: 0.11119
[32m[0906 17-39-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01846, current rewards: 99.08789, mean: 0.10889
[32m[0906 17-39-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01846, current rewards: 104.65539, mean: 0.10902
[32m[0906 17-39-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01846, current rewards: 110.17900, mean: 0.10909
[32m[0906 17-39-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01845, current rewards: 115.70618, mean: 0.10916
[32m[0906 17-39-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01849, current rewards: 121.32502, mean: 0.10930
[32m[0906 17-39-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: 126.86030, mean: 0.10936
[32m[0906 17-39-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01854, current rewards: 132.38996, mean: 0.10941
[32m[0906 17-39-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 137.92534, mean: 0.10946
[32m[0906 17-39-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01859, current rewards: 143.45641, mean: 0.10951
[32m[0906 17-39-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: 146.95633, mean: 0.10806
[32m[0906 17-39-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: 152.75162, mean: 0.10833
[32m[0906 17-39-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01865, current rewards: 158.54685, mean: 0.10859
[32m[0906 17-39-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01866, current rewards: 164.34208, mean: 0.10884
[32m[0906 17-39-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01867, current rewards: 170.13730, mean: 0.10906
[32m[0906 17-39-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01869, current rewards: 175.93253, mean: 0.10927
[32m[0906 17-39-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01871, current rewards: 172.80052, mean: 0.10410
[32m[0906 17-40-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 172.76456, mean: 0.10103
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01872, current rewards: 178.18455, mean: 0.10124
[32m[0906 17-40-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01873, current rewards: 183.71451, mean: 0.10150
[32m[0906 17-40-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01874, current rewards: 189.24140, mean: 0.10174
[32m[0906 17-40-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01875, current rewards: 194.77221, mean: 0.10197
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01876, current rewards: 200.30505, mean: 0.10220
[32m[0906 17-40-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01877, current rewards: 205.83996, mean: 0.10241
[32m[0906 17-40-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01878, current rewards: 211.40216, mean: 0.10262
[32m[0906 17-40-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01879, current rewards: 216.95486, mean: 0.10282
[32m[0906 17-40-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01880, current rewards: 222.51291, mean: 0.10302
[32m[0906 17-40-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 228.06756, mean: 0.10320
[32m[0906 17-40-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 233.62690, mean: 0.10337
[32m[0906 17-40-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01883, current rewards: 239.18361, mean: 0.10354
[32m[0906 17-40-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01883, current rewards: 244.73773, mean: 0.10370
[32m[0906 17-40-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01884, current rewards: 250.29206, mean: 0.10386
[32m[0906 17-40-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 255.84455, mean: 0.10400
[32m[0906 17-40-16 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-40-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-40-16 @MBExp.py:227][0m Rewards obtained: [260.28368105105267], Lows: [2], Highs: [13], Total time: 4611.622528
[32m[0906 17-43-38 @MBExp.py:144][0m ####################################################################
[32m[0906 17-43-38 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 17-43-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01912, current rewards: 1.15890, mean: 0.11589
[32m[0906 17-43-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01860, current rewards: 6.65313, mean: 0.11089
[32m[0906 17-43-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01869, current rewards: 12.06366, mean: 0.10967
[32m[0906 17-43-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01866, current rewards: 17.53029, mean: 0.10956
[32m[0906 17-43-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01861, current rewards: 22.99294, mean: 0.10949
[32m[0906 17-43-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01860, current rewards: 28.46139, mean: 0.10947
[32m[0906 17-43-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01859, current rewards: 33.92886, mean: 0.10945
[32m[0906 17-43-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.43837, mean: 0.10955
[32m[0906 17-43-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 44.96956, mean: 0.10968
[32m[0906 17-43-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.49939, mean: 0.10978
[32m[0906 17-43-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.04789, mean: 0.10990
[32m[0906 17-43-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 61.58180, mean: 0.10997
[32m[0906 17-43-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 67.11710, mean: 0.11003
[32m[0906 17-43-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 72.65320, mean: 0.11008
[32m[0906 17-43-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 78.17539, mean: 0.11011
[32m[0906 17-43-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 83.62585, mean: 0.11003
[32m[0906 17-43-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 89.07825, mean: 0.10997
[32m[0906 17-43-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 94.53591, mean: 0.10993
[32m[0906 17-43-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 99.96527, mean: 0.10985
[32m[0906 17-43-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 105.42025, mean: 0.10981
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 110.87865, mean: 0.10978
[32m[0906 17-43-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 116.34114, mean: 0.10976
[32m[0906 17-43-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 121.80390, mean: 0.10973
[32m[0906 17-44-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 127.26210, mean: 0.10971
[32m[0906 17-44-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01859, current rewards: 132.72263, mean: 0.10969
[32m[0906 17-44-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01861, current rewards: 138.18993, mean: 0.10967
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: 143.72649, mean: 0.10971
[32m[0906 17-44-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: 149.13644, mean: 0.10966
[32m[0906 17-44-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01867, current rewards: 154.54507, mean: 0.10961
[32m[0906 17-44-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01870, current rewards: 159.94987, mean: 0.10955
[32m[0906 17-44-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: 165.35716, mean: 0.10951
[32m[0906 17-44-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: 170.76378, mean: 0.10946
[32m[0906 17-44-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: 176.16780, mean: 0.10942
[32m[0906 17-44-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01875, current rewards: 181.57627, mean: 0.10938
[32m[0906 17-44-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: 186.94083, mean: 0.10932
[32m[0906 17-44-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: 192.59577, mean: 0.10943
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 198.12649, mean: 0.10946
[32m[0906 17-44-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 203.66783, mean: 0.10950
[32m[0906 17-44-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01879, current rewards: 209.19265, mean: 0.10952
[32m[0906 17-44-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 214.72039, mean: 0.10955
[32m[0906 17-44-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 220.25098, mean: 0.10958
[32m[0906 17-44-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 225.78562, mean: 0.10960
[32m[0906 17-44-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 231.32833, mean: 0.10963
[32m[0906 17-44-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 236.86204, mean: 0.10966
[32m[0906 17-44-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 242.39414, mean: 0.10968
[32m[0906 17-44-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 247.92692, mean: 0.10970
[32m[0906 17-44-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 253.44287, mean: 0.10972
[32m[0906 17-44-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 258.86951, mean: 0.10969
[32m[0906 17-44-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 264.29401, mean: 0.10967
[32m[0906 17-44-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 269.71207, mean: 0.10964
[32m[0906 17-44-26 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-44-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-44-27 @MBExp.py:227][0m Rewards obtained: [274.1026424701108], Lows: [0], Highs: [0], Total time: 4659.660577
[32m[0906 17-47-51 @MBExp.py:144][0m ####################################################################
[32m[0906 17-47-51 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 17-47-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01835, current rewards: 1.10385, mean: 0.11038
[32m[0906 17-47-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01859, current rewards: 6.63529, mean: 0.11059
[32m[0906 17-47-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01856, current rewards: 12.18339, mean: 0.11076
[32m[0906 17-47-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 17.73450, mean: 0.11084
[32m[0906 17-47-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 23.27886, mean: 0.11085
[32m[0906 17-47-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 28.83102, mean: 0.11089
[32m[0906 17-47-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01852, current rewards: 34.38628, mean: 0.11092
[32m[0906 17-47-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01852, current rewards: 39.93629, mean: 0.11093
[32m[0906 17-47-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 45.48801, mean: 0.11095
[32m[0906 17-47-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 51.11511, mean: 0.11112
[32m[0906 17-48-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 56.66411, mean: 0.11111
[32m[0906 17-48-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 62.21993, mean: 0.11111
[32m[0906 17-48-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.87434, mean: 0.11127
[32m[0906 17-48-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 73.44584, mean: 0.11128
[32m[0906 17-48-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 79.01667, mean: 0.11129
[32m[0906 17-48-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.58702, mean: 0.11130
[32m[0906 17-48-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 90.15802, mean: 0.11131
[32m[0906 17-48-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 95.60334, mean: 0.11117
[32m[0906 17-48-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 101.14500, mean: 0.11115
[32m[0906 17-48-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 106.68645, mean: 0.11113
[32m[0906 17-48-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 111.17887, mean: 0.11008
[32m[0906 17-48-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 116.71736, mean: 0.11011
[32m[0906 17-48-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 122.25518, mean: 0.11014
[32m[0906 17-48-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 127.78610, mean: 0.11016
[32m[0906 17-48-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 133.32068, mean: 0.11018
[32m[0906 17-48-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: 138.85729, mean: 0.11020
[32m[0906 17-48-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01862, current rewards: 144.39501, mean: 0.11023
[32m[0906 17-48-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01865, current rewards: 149.92628, mean: 0.11024
[32m[0906 17-48-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01866, current rewards: 155.44620, mean: 0.11025
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01868, current rewards: 160.99890, mean: 0.11027
[32m[0906 17-48-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01870, current rewards: 166.55051, mean: 0.11030
[32m[0906 17-48-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01871, current rewards: 172.10193, mean: 0.11032
[32m[0906 17-48-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01873, current rewards: 177.65310, mean: 0.11034
[32m[0906 17-48-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: 183.22069, mean: 0.11037
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01875, current rewards: 188.77013, mean: 0.11039
[32m[0906 17-48-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01876, current rewards: 194.32118, mean: 0.11041
[32m[0906 17-48-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 199.86985, mean: 0.11043
[32m[0906 17-48-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01878, current rewards: 205.42207, mean: 0.11044
[32m[0906 17-48-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 210.97720, mean: 0.11046
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 216.49132, mean: 0.11045
[32m[0906 17-48-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 222.02109, mean: 0.11046
[32m[0906 17-48-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 227.57245, mean: 0.11047
[32m[0906 17-48-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 233.20069, mean: 0.11052
[32m[0906 17-48-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 238.73988, mean: 0.11053
[32m[0906 17-48-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 244.27589, mean: 0.11053
[32m[0906 17-48-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 249.81919, mean: 0.11054
[32m[0906 17-48-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 255.38240, mean: 0.11056
[32m[0906 17-48-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 260.94464, mean: 0.11057
[32m[0906 17-48-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 266.50809, mean: 0.11058
[32m[0906 17-48-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 272.06949, mean: 0.11060
[32m[0906 17-48-38 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-48-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-48-39 @MBExp.py:227][0m Rewards obtained: [276.4533237242944], Lows: [0], Highs: [1], Total time: 4707.7171929999995
[32m[0906 17-52-06 @MBExp.py:144][0m ####################################################################
[32m[0906 17-52-06 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 17-52-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01882, current rewards: 1.11198, mean: 0.11120
[32m[0906 17-52-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01861, current rewards: 6.65996, mean: 0.11100
[32m[0906 17-52-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01858, current rewards: 12.20765, mean: 0.11098
[32m[0906 17-52-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01857, current rewards: 17.75319, mean: 0.11096
[32m[0906 17-52-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 23.29968, mean: 0.11095
[32m[0906 17-52-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 28.84781, mean: 0.11095
[32m[0906 17-52-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 34.39661, mean: 0.11096
[32m[0906 17-52-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 39.94487, mean: 0.11096
[32m[0906 17-52-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 45.50395, mean: 0.11099
[32m[0906 17-52-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 51.04429, mean: 0.11097
[32m[0906 17-52-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 56.58425, mean: 0.11095
[32m[0906 17-52-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 62.12575, mean: 0.11094
[32m[0906 17-52-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.66441, mean: 0.11093
[32m[0906 17-52-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.20468, mean: 0.11092
[32m[0906 17-52-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 78.73949, mean: 0.11090
[32m[0906 17-52-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.27746, mean: 0.11089
[32m[0906 17-52-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.80891, mean: 0.11088
[32m[0906 17-52-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 95.31233, mean: 0.11083
[32m[0906 17-52-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 100.84114, mean: 0.11081
[32m[0906 17-52-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 106.36658, mean: 0.11080
[32m[0906 17-52-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 111.84846, mean: 0.11074
[32m[0906 17-52-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 117.35383, mean: 0.11071
[32m[0906 17-52-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 122.85645, mean: 0.11068
[32m[0906 17-52-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 128.35556, mean: 0.11065
[32m[0906 17-52-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 133.85819, mean: 0.11063
[32m[0906 17-52-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 139.38785, mean: 0.11063
[32m[0906 17-52-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01861, current rewards: 144.95688, mean: 0.11065
[32m[0906 17-52-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01864, current rewards: 150.42921, mean: 0.11061
[32m[0906 17-52-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01866, current rewards: 155.90569, mean: 0.11057
[32m[0906 17-52-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01868, current rewards: 161.38342, mean: 0.11054
[32m[0906 17-52-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01870, current rewards: 166.85710, mean: 0.11050
[32m[0906 17-52-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01871, current rewards: 172.33311, mean: 0.11047
[32m[0906 17-52-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01872, current rewards: 177.80844, mean: 0.11044
[32m[0906 17-52-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01874, current rewards: 183.37097, mean: 0.11046
[32m[0906 17-52-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01876, current rewards: 188.85625, mean: 0.11044
[32m[0906 17-52-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: 194.34243, mean: 0.11042
[32m[0906 17-52-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 199.82584, mean: 0.11040
[32m[0906 17-52-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 205.31183, mean: 0.11038
[32m[0906 17-52-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 210.96021, mean: 0.11045
[32m[0906 17-52-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 216.50005, mean: 0.11046
[32m[0906 17-52-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 222.03961, mean: 0.11047
[32m[0906 17-52-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 227.55941, mean: 0.11047
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 233.09536, mean: 0.11047
[32m[0906 17-52-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 238.63500, mean: 0.11048
[32m[0906 17-52-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 244.17336, mean: 0.11049
[32m[0906 17-52-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 249.71137, mean: 0.11049
[32m[0906 17-52-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 255.25083, mean: 0.11050
[32m[0906 17-52-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: 259.75150, mean: 0.11006
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 265.29059, mean: 0.11008
[32m[0906 17-52-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 270.81503, mean: 0.11009
[32m[0906 17-52-54 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-52-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-52-54 @MBExp.py:227][0m Rewards obtained: [275.24173985804623], Lows: [0], Highs: [1], Total time: 4755.783326999999
[32m[0906 17-56-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-23 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 17-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01810, current rewards: 1.06068, mean: 0.10607
[32m[0906 17-56-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.53768, mean: 0.10896
[32m[0906 17-56-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 12.02180, mean: 0.10929
[32m[0906 17-56-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 17.49888, mean: 0.10937
[32m[0906 17-56-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 22.97345, mean: 0.10940
[32m[0906 17-56-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 28.45502, mean: 0.10944
[32m[0906 17-56-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 33.92950, mean: 0.10945
[32m[0906 17-56-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 39.42089, mean: 0.10950
[32m[0906 17-56-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 44.99065, mean: 0.10973
[32m[0906 17-56-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 50.52605, mean: 0.10984
[32m[0906 17-56-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.06512, mean: 0.10993
[32m[0906 17-56-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 61.60578, mean: 0.11001
[32m[0906 17-56-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 65.08584, mean: 0.10670
[32m[0906 17-56-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 70.64908, mean: 0.10704
[32m[0906 17-56-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 76.21261, mean: 0.10734
[32m[0906 17-56-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: 81.77535, mean: 0.10760
[32m[0906 17-56-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 87.33842, mean: 0.10783
[32m[0906 17-56-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 92.90236, mean: 0.10803
[32m[0906 17-56-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 98.46500, mean: 0.10820
[32m[0906 17-56-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 104.02843, mean: 0.10836
[32m[0906 17-56-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 109.59133, mean: 0.10851
[32m[0906 17-56-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 115.08192, mean: 0.10857
[32m[0906 17-56-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 120.59889, mean: 0.10865
[32m[0906 17-56-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 126.11428, mean: 0.10872
[32m[0906 17-56-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 131.60058, mean: 0.10876
[32m[0906 17-56-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 137.10961, mean: 0.10882
[32m[0906 17-56-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 142.61773, mean: 0.10887
[32m[0906 17-56-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01862, current rewards: 148.12967, mean: 0.10892
[32m[0906 17-56-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01864, current rewards: 153.63805, mean: 0.10896
[32m[0906 17-56-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01866, current rewards: 159.14810, mean: 0.10901
[32m[0906 17-56-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01868, current rewards: 164.66292, mean: 0.10905
[32m[0906 17-56-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01870, current rewards: 170.19366, mean: 0.10910
[32m[0906 17-56-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01871, current rewards: 175.71517, mean: 0.10914
[32m[0906 17-56-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01873, current rewards: 181.26968, mean: 0.10920
[32m[0906 17-56-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 186.81837, mean: 0.10925
[32m[0906 17-56-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: 192.36738, mean: 0.10930
[32m[0906 17-56-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01876, current rewards: 197.91726, mean: 0.10935
[32m[0906 17-56-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 203.47092, mean: 0.10939
[32m[0906 17-57-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: 209.02311, mean: 0.10944
[32m[0906 17-57-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01879, current rewards: 214.57222, mean: 0.10948
[32m[0906 17-57-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01880, current rewards: 220.12772, mean: 0.10952
[32m[0906 17-57-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 225.67436, mean: 0.10955
[32m[0906 17-57-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01882, current rewards: 231.21108, mean: 0.10958
[32m[0906 17-57-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: 236.74181, mean: 0.10960
[32m[0906 17-57-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01884, current rewards: 242.27670, mean: 0.10963
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 247.80883, mean: 0.10965
[32m[0906 17-57-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 253.34046, mean: 0.10967
[32m[0906 17-57-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 258.87268, mean: 0.10969
[32m[0906 17-57-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 264.38307, mean: 0.10970
[32m[0906 17-57-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: 269.91906, mean: 0.10972
[32m[0906 17-57-11 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-57-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-57-11 @MBExp.py:227][0m Rewards obtained: [274.3482900736562], Lows: [1], Highs: [0], Total time: 4803.8350789999995
[32m[0906 18-00-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-00-42 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-00-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01828, current rewards: 1.11954, mean: 0.11195
[32m[0906 18-00-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01842, current rewards: 6.63260, mean: 0.11054
[32m[0906 18-00-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01850, current rewards: 12.09121, mean: 0.10992
[32m[0906 18-00-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01851, current rewards: 17.55492, mean: 0.10972
[32m[0906 18-00-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 23.02319, mean: 0.10963
[32m[0906 18-00-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 28.49038, mean: 0.10958
[32m[0906 18-00-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 33.90533, mean: 0.10937
[32m[0906 18-00-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.32750, mean: 0.10924
[32m[0906 18-00-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 44.81317, mean: 0.10930
[32m[0906 18-00-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 50.29944, mean: 0.10935
[32m[0906 18-00-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 55.79001, mean: 0.10939
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 61.25789, mean: 0.10939
[32m[0906 18-00-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 66.77629, mean: 0.10947
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 72.30337, mean: 0.10955
[32m[0906 18-00-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 77.82425, mean: 0.10961
[32m[0906 18-00-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 83.44924, mean: 0.10980
[32m[0906 18-00-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 88.97640, mean: 0.10985
[32m[0906 18-00-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 94.52481, mean: 0.10991
[32m[0906 18-00-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 100.06194, mean: 0.10996
[32m[0906 18-01-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 105.59701, mean: 0.11000
[32m[0906 18-01-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 111.13144, mean: 0.11003
[32m[0906 18-01-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 116.65617, mean: 0.11005
[32m[0906 18-01-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 122.12377, mean: 0.11002
[32m[0906 18-01-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 127.51499, mean: 0.10993
[32m[0906 18-01-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 132.97187, mean: 0.10989
[32m[0906 18-01-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: 138.48328, mean: 0.10991
[32m[0906 18-01-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01856, current rewards: 143.98679, mean: 0.10991
[32m[0906 18-01-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01856, current rewards: 147.35898, mean: 0.10835
[32m[0906 18-01-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01856, current rewards: 152.73972, mean: 0.10833
[32m[0906 18-01-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 158.12142, mean: 0.10830
[32m[0906 18-01-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01857, current rewards: 163.49935, mean: 0.10828
[32m[0906 18-01-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01856, current rewards: 168.87958, mean: 0.10826
[32m[0906 18-01-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01856, current rewards: 174.31963, mean: 0.10827
[32m[0906 18-01-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 179.66878, mean: 0.10823
[32m[0906 18-01-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01860, current rewards: 185.01805, mean: 0.10820
[32m[0906 18-01-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: 190.37155, mean: 0.10817
[32m[0906 18-01-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01863, current rewards: 195.71944, mean: 0.10813
[32m[0906 18-01-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01865, current rewards: 201.07291, mean: 0.10810
[32m[0906 18-01-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01867, current rewards: 206.42153, mean: 0.10807
[32m[0906 18-01-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01868, current rewards: 211.76841, mean: 0.10805
[32m[0906 18-01-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01869, current rewards: 217.16985, mean: 0.10804
[32m[0906 18-01-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01870, current rewards: 219.27033, mean: 0.10644
[32m[0906 18-01-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01871, current rewards: 224.72847, mean: 0.10651
[32m[0906 18-01-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01872, current rewards: 230.17944, mean: 0.10656
[32m[0906 18-01-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01873, current rewards: 235.62529, mean: 0.10662
[32m[0906 18-01-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01874, current rewards: 241.07992, mean: 0.10667
[32m[0906 18-01-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01875, current rewards: 246.53708, mean: 0.10673
[32m[0906 18-01-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01876, current rewards: 251.98903, mean: 0.10678
[32m[0906 18-01-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01877, current rewards: 257.46758, mean: 0.10683
[32m[0906 18-01-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01878, current rewards: 262.92121, mean: 0.10688
[32m[0906 18-01-30 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-01-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-01-30 @MBExp.py:227][0m Rewards obtained: [267.28564837057655], Lows: [1], Highs: [3], Total time: 4851.610213
[32m[0906 18-05-03 @MBExp.py:144][0m ####################################################################
[32m[0906 18-05-03 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01868, current rewards: 1.15373, mean: 0.11537
[32m[0906 18-05-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01860, current rewards: 6.69960, mean: 0.11166
[32m[0906 18-05-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 12.23058, mean: 0.11119
[32m[0906 18-05-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 17.76099, mean: 0.11101
[32m[0906 18-05-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01857, current rewards: 23.29195, mean: 0.11091
[32m[0906 18-05-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 28.82285, mean: 0.11086
[32m[0906 18-05-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 33.29621, mean: 0.10741
[32m[0906 18-05-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01852, current rewards: 39.00050, mean: 0.10833
[32m[0906 18-05-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 44.72575, mean: 0.10909
[32m[0906 18-05-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01855, current rewards: 50.44876, mean: 0.10967
[32m[0906 18-05-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 56.17549, mean: 0.11015
[32m[0906 18-05-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01856, current rewards: 61.89757, mean: 0.11053
[32m[0906 18-05-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 67.63201, mean: 0.11087
[32m[0906 18-05-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01856, current rewards: 73.35042, mean: 0.11114
[32m[0906 18-05-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 79.07760, mean: 0.11138
[32m[0906 18-05-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01856, current rewards: 84.78608, mean: 0.11156
[32m[0906 18-05-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 90.57127, mean: 0.11182
[32m[0906 18-05-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01857, current rewards: 96.35423, mean: 0.11204
[32m[0906 18-05-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01859, current rewards: 102.13483, mean: 0.11224
[32m[0906 18-05-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 107.67288, mean: 0.11216
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01859, current rewards: 113.19046, mean: 0.11207
[32m[0906 18-05-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 118.70312, mean: 0.11198
[32m[0906 18-05-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 124.21990, mean: 0.11191
[32m[0906 18-05-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 129.78229, mean: 0.11188
[32m[0906 18-05-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 135.29380, mean: 0.11181
[32m[0906 18-05-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 140.81593, mean: 0.11176
[32m[0906 18-05-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: 146.33363, mean: 0.11171
[32m[0906 18-05-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: 151.95485, mean: 0.11173
[32m[0906 18-05-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 157.54774, mean: 0.11174
[32m[0906 18-05-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 163.13815, mean: 0.11174
[32m[0906 18-05-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 168.72983, mean: 0.11174
[32m[0906 18-05-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01857, current rewards: 174.30801, mean: 0.11174
[32m[0906 18-05-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01859, current rewards: 179.89792, mean: 0.11174
[32m[0906 18-05-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01862, current rewards: 185.49050, mean: 0.11174
[32m[0906 18-05-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01864, current rewards: 191.08174, mean: 0.11174
[32m[0906 18-05-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01865, current rewards: 196.67186, mean: 0.11175
[32m[0906 18-05-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01867, current rewards: 202.25704, mean: 0.11174
[32m[0906 18-05-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01869, current rewards: 207.84349, mean: 0.11174
[32m[0906 18-05-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01870, current rewards: 213.47332, mean: 0.11177
[32m[0906 18-05-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01871, current rewards: 219.06721, mean: 0.11177
[32m[0906 18-05-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01872, current rewards: 224.63490, mean: 0.11176
[32m[0906 18-05-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01874, current rewards: 230.20540, mean: 0.11175
[32m[0906 18-05-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01875, current rewards: 235.77236, mean: 0.11174
[32m[0906 18-05-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01876, current rewards: 241.34042, mean: 0.11173
[32m[0906 18-05-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01877, current rewards: 246.91051, mean: 0.11172
[32m[0906 18-05-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01878, current rewards: 252.57100, mean: 0.11176
[32m[0906 18-05-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: 258.12157, mean: 0.11174
[32m[0906 18-05-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 263.68039, mean: 0.11173
[32m[0906 18-05-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: 269.23783, mean: 0.11172
[32m[0906 18-05-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: 274.79987, mean: 0.11171
[32m[0906 18-05-50 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-05-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-05-51 @MBExp.py:227][0m Rewards obtained: [279.24768084128726], Lows: [0], Highs: [1], Total time: 4899.4874119999995
[32m[0906 18-09-26 @MBExp.py:144][0m ####################################################################
[32m[0906 18-09-26 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 18-09-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01906, current rewards: 1.18403, mean: 0.11840
[32m[0906 18-09-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01863, current rewards: 6.68927, mean: 0.11149
[32m[0906 18-09-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01861, current rewards: 12.25375, mean: 0.11140
[32m[0906 18-09-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01859, current rewards: 17.81660, mean: 0.11135
[32m[0906 18-09-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01855, current rewards: 23.38265, mean: 0.11135
[32m[0906 18-09-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01854, current rewards: 28.93693, mean: 0.11130
[32m[0906 18-09-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 34.48224, mean: 0.11123
[32m[0906 18-09-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01858, current rewards: 40.03402, mean: 0.11121
[32m[0906 18-09-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 45.58861, mean: 0.11119
[32m[0906 18-09-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01859, current rewards: 51.14560, mean: 0.11119
[32m[0906 18-09-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01859, current rewards: 56.69344, mean: 0.11116
[32m[0906 18-09-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 62.24810, mean: 0.11116
[32m[0906 18-09-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01856, current rewards: 67.80633, mean: 0.11116
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 73.35800, mean: 0.11115
[32m[0906 18-09-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 78.99131, mean: 0.11126
[32m[0906 18-09-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 84.61611, mean: 0.11134
[32m[0906 18-09-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 90.18753, mean: 0.11134
[32m[0906 18-09-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 95.76341, mean: 0.11135
[32m[0906 18-09-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01858, current rewards: 101.34432, mean: 0.11137
[32m[0906 18-09-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 106.92399, mean: 0.11138
[32m[0906 18-09-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 112.50488, mean: 0.11139
[32m[0906 18-09-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 118.07831, mean: 0.11139
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 123.61909, mean: 0.11137
[32m[0906 18-09-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 129.16897, mean: 0.11135
[32m[0906 18-09-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 134.71948, mean: 0.11134
[32m[0906 18-09-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 140.27481, mean: 0.11133
[32m[0906 18-09-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: 145.82901, mean: 0.11132
[32m[0906 18-09-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: 151.38098, mean: 0.11131
[32m[0906 18-09-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 156.87892, mean: 0.11126
[32m[0906 18-09-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 162.38341, mean: 0.11122
[32m[0906 18-09-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 167.88924, mean: 0.11118
[32m[0906 18-09-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01859, current rewards: 173.55197, mean: 0.11125
[32m[0906 18-09-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 179.12797, mean: 0.11126
[32m[0906 18-09-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01862, current rewards: 184.70416, mean: 0.11127
[32m[0906 18-09-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01864, current rewards: 190.28270, mean: 0.11128
[32m[0906 18-09-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01866, current rewards: 195.85742, mean: 0.11128
[32m[0906 18-10-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01868, current rewards: 201.43604, mean: 0.11129
[32m[0906 18-10-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01869, current rewards: 208.17397, mean: 0.11192
[32m[0906 18-10-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01871, current rewards: 215.63416, mean: 0.11290
[32m[0906 18-10-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01872, current rewards: 219.23298, mean: 0.11185
[32m[0906 18-10-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01872, current rewards: 169.23298, mean: 0.08420
[32m[0906 18-10-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01874, current rewards: 119.23298, mean: 0.05788
[32m[0906 18-10-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01875, current rewards: 69.23298, mean: 0.03281
[32m[0906 18-10-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01875, current rewards: 19.23298, mean: 0.00890
[32m[0906 18-10-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01876, current rewards: -30.76702, mean: -0.01392
[32m[0906 18-10-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01877, current rewards: -80.76702, mean: -0.03574
[32m[0906 18-10-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01878, current rewards: -130.76702, mean: -0.05661
[32m[0906 18-10-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01879, current rewards: -180.76702, mean: -0.07660
[32m[0906 18-10-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: -230.76702, mean: -0.09575
[32m[0906 18-10-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: -280.76702, mean: -0.11413
[32m[0906 18-10-14 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-10-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-10-14 @MBExp.py:227][0m Rewards obtained: [-320.7670205017762], Lows: [0], Highs: [542], Total time: 4947.348935999999
[32m[0906 18-13-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-13-51 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 18-13-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01825, current rewards: 1.12930, mean: 0.11293
[32m[0906 18-13-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.67424, mean: 0.11124
[32m[0906 18-13-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 12.23836, mean: 0.11126
[32m[0906 18-13-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01840, current rewards: 17.80079, mean: 0.11125
[32m[0906 18-13-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01839, current rewards: 23.36878, mean: 0.11128
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.97295, mean: 0.11143
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 34.55417, mean: 0.11147
[32m[0906 18-13-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.13149, mean: 0.11148
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 45.70711, mean: 0.11148
[32m[0906 18-13-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 51.29135, mean: 0.11150
[32m[0906 18-14-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 56.86376, mean: 0.11150
[32m[0906 18-14-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 62.42566, mean: 0.11147
[32m[0906 18-14-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 67.99638, mean: 0.11147
[32m[0906 18-14-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 73.56106, mean: 0.11146
[32m[0906 18-14-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 79.16636, mean: 0.11150
[32m[0906 18-14-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.73430, mean: 0.11149
[32m[0906 18-14-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 90.30754, mean: 0.11149
[32m[0906 18-14-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 95.85037, mean: 0.11145
[32m[0906 18-14-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 101.38999, mean: 0.11142
[32m[0906 18-14-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 106.93758, mean: 0.11139
[32m[0906 18-14-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 112.48660, mean: 0.11137
[32m[0906 18-14-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 118.02986, mean: 0.11135
[32m[0906 18-14-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 123.54910, mean: 0.11131
[32m[0906 18-14-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 129.09114, mean: 0.11129
[32m[0906 18-14-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 134.62988, mean: 0.11126
[32m[0906 18-14-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01850, current rewards: 140.17545, mean: 0.11125
[32m[0906 18-14-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01851, current rewards: 145.72208, mean: 0.11124
[32m[0906 18-14-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01850, current rewards: 151.32139, mean: 0.11127
[32m[0906 18-14-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01850, current rewards: 156.90311, mean: 0.11128
[32m[0906 18-14-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01850, current rewards: 162.48742, mean: 0.11129
[32m[0906 18-14-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 168.03648, mean: 0.11128
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01853, current rewards: 173.56512, mean: 0.11126
[32m[0906 18-14-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 179.13435, mean: 0.11126
[32m[0906 18-14-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 184.70954, mean: 0.11127
[32m[0906 18-14-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01859, current rewards: 190.27437, mean: 0.11127
[32m[0906 18-14-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 195.85032, mean: 0.11128
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01862, current rewards: 201.42446, mean: 0.11128
[32m[0906 18-14-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01864, current rewards: 206.99581, mean: 0.11129
[32m[0906 18-14-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01866, current rewards: 212.56154, mean: 0.11129
[32m[0906 18-14-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01867, current rewards: 218.18446, mean: 0.11132
[32m[0906 18-14-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01868, current rewards: 223.90009, mean: 0.11139
[32m[0906 18-14-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01870, current rewards: 229.37800, mean: 0.11135
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01871, current rewards: 234.85754, mean: 0.11131
[32m[0906 18-14-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01871, current rewards: 240.33820, mean: 0.11127
[32m[0906 18-14-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01873, current rewards: 245.81863, mean: 0.11123
[32m[0906 18-14-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01874, current rewards: 250.22054, mean: 0.11072
[32m[0906 18-14-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01875, current rewards: 255.75948, mean: 0.11072
[32m[0906 18-14-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01876, current rewards: 261.34896, mean: 0.11074
[32m[0906 18-14-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01877, current rewards: 266.89348, mean: 0.11074
[32m[0906 18-14-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01878, current rewards: 272.44125, mean: 0.11075
[32m[0906 18-14-38 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-14-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-14-38 @MBExp.py:227][0m Rewards obtained: [276.87788564311586], Lows: [0], Highs: [1], Total time: 4995.124986
[32m[0906 18-18-18 @MBExp.py:144][0m ####################################################################
[32m[0906 18-18-18 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 18-18-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01858, current rewards: 1.07601, mean: 0.10760
[32m[0906 18-18-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01850, current rewards: 6.61363, mean: 0.11023
[32m[0906 18-18-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01832, current rewards: 12.14096, mean: 0.11037
[32m[0906 18-18-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01832, current rewards: 17.66615, mean: 0.11041
[32m[0906 18-18-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01837, current rewards: 23.19289, mean: 0.11044
[32m[0906 18-18-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01841, current rewards: 28.72630, mean: 0.11049
[32m[0906 18-18-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01844, current rewards: 34.30275, mean: 0.11065
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 36.43752, mean: 0.10122
[32m[0906 18-18-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 41.92592, mean: 0.10226
[32m[0906 18-18-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 47.41617, mean: 0.10308
[32m[0906 18-18-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 52.90824, mean: 0.10374
[32m[0906 18-18-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 58.39252, mean: 0.10427
[32m[0906 18-18-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 63.87984, mean: 0.10472
[32m[0906 18-18-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 69.37058, mean: 0.10511
[32m[0906 18-18-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 74.82491, mean: 0.10539
[32m[0906 18-18-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 80.30985, mean: 0.10567
[32m[0906 18-18-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 86.02104, mean: 0.10620
[32m[0906 18-18-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 91.56429, mean: 0.10647
[32m[0906 18-18-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 97.10297, mean: 0.10671
[32m[0906 18-18-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 102.64531, mean: 0.10692
[32m[0906 18-18-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 108.18639, mean: 0.10712
[32m[0906 18-18-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 113.72666, mean: 0.10729
[32m[0906 18-18-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 119.29854, mean: 0.10748
[32m[0906 18-18-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 124.77913, mean: 0.10757
[32m[0906 18-18-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 130.27173, mean: 0.10766
[32m[0906 18-18-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01854, current rewards: 135.77096, mean: 0.10775
[32m[0906 18-18-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01854, current rewards: 141.26602, mean: 0.10784
[32m[0906 18-18-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 146.76054, mean: 0.10791
[32m[0906 18-18-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 152.25519, mean: 0.10798
[32m[0906 18-18-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 157.74944, mean: 0.10805
[32m[0906 18-18-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 163.20318, mean: 0.10808
[32m[0906 18-18-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 168.68476, mean: 0.10813
[32m[0906 18-18-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 174.17613, mean: 0.10818
[32m[0906 18-18-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01856, current rewards: 179.66318, mean: 0.10823
[32m[0906 18-18-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01856, current rewards: 185.15677, mean: 0.10828
[32m[0906 18-18-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: 190.65018, mean: 0.10832
[32m[0906 18-18-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 196.14425, mean: 0.10837
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: 201.63100, mean: 0.10840
[32m[0906 18-18-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01857, current rewards: 207.05061, mean: 0.10840
[32m[0906 18-18-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: 212.52760, mean: 0.10843
[32m[0906 18-18-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: 218.01400, mean: 0.10846
[32m[0906 18-18-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01862, current rewards: 223.46395, mean: 0.10848
[32m[0906 18-18-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01864, current rewards: 228.94457, mean: 0.10850
[32m[0906 18-18-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01865, current rewards: 234.42491, mean: 0.10853
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: 239.90791, mean: 0.10856
[32m[0906 18-19-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01868, current rewards: 245.39080, mean: 0.10858
[32m[0906 18-19-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01869, current rewards: 250.87834, mean: 0.10861
[32m[0906 18-19-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01870, current rewards: 256.44163, mean: 0.10866
[32m[0906 18-19-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01871, current rewards: 261.94786, mean: 0.10869
[32m[0906 18-19-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01872, current rewards: 267.45475, mean: 0.10872
[32m[0906 18-19-06 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-19-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-19-06 @MBExp.py:227][0m Rewards obtained: [271.8623078222722], Lows: [0], Highs: [3], Total time: 5042.768543
[32m[0906 18-22-48 @MBExp.py:144][0m ####################################################################
[32m[0906 18-22-48 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 18-22-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01826, current rewards: -2.10241, mean: -0.21024
[32m[0906 18-22-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01827, current rewards: 3.47888, mean: 0.05798
[32m[0906 18-22-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01834, current rewards: 8.99639, mean: 0.08179
[32m[0906 18-22-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01837, current rewards: 14.51129, mean: 0.09070
[32m[0906 18-22-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01839, current rewards: 20.02680, mean: 0.09537
[32m[0906 18-22-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 25.49562, mean: 0.09806
[32m[0906 18-22-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 30.95009, mean: 0.09984
[32m[0906 18-22-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 36.44628, mean: 0.10124
[32m[0906 18-22-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 41.93928, mean: 0.10229
[32m[0906 18-22-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 47.49096, mean: 0.10324
[32m[0906 18-22-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 53.09878, mean: 0.10412
[32m[0906 18-22-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 58.70749, mean: 0.10483
[32m[0906 18-22-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 64.31251, mean: 0.10543
[32m[0906 18-23-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 69.91481, mean: 0.10593
[32m[0906 18-23-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 75.45998, mean: 0.10628
[32m[0906 18-23-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 80.97871, mean: 0.10655
[32m[0906 18-23-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 86.49698, mean: 0.10679
[32m[0906 18-23-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 92.01560, mean: 0.10699
[32m[0906 18-23-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 97.53674, mean: 0.10718
[32m[0906 18-23-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 103.05408, mean: 0.10735
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 108.57237, mean: 0.10750
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 114.08996, mean: 0.10763
[32m[0906 18-23-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 119.69615, mean: 0.10783
[32m[0906 18-23-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01849, current rewards: 125.22772, mean: 0.10795
[32m[0906 18-23-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01849, current rewards: 124.19869, mean: 0.10264
[32m[0906 18-23-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01849, current rewards: 129.68698, mean: 0.10293
[32m[0906 18-23-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01849, current rewards: 135.17452, mean: 0.10319
[32m[0906 18-23-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01849, current rewards: 140.66131, mean: 0.10343
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01849, current rewards: 146.14372, mean: 0.10365
[32m[0906 18-23-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01849, current rewards: 151.66575, mean: 0.10388
[32m[0906 18-23-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01849, current rewards: 157.20076, mean: 0.10411
[32m[0906 18-23-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01848, current rewards: 162.74093, mean: 0.10432
[32m[0906 18-23-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01849, current rewards: 168.27685, mean: 0.10452
[32m[0906 18-23-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01850, current rewards: 173.81936, mean: 0.10471
[32m[0906 18-23-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01849, current rewards: 179.35555, mean: 0.10489
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01850, current rewards: 184.89604, mean: 0.10505
[32m[0906 18-23-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01850, current rewards: 190.43288, mean: 0.10521
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01853, current rewards: 195.92789, mean: 0.10534
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01854, current rewards: 201.38201, mean: 0.10544
[32m[0906 18-23-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01856, current rewards: 206.81229, mean: 0.10552
[32m[0906 18-23-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01858, current rewards: 212.27754, mean: 0.10561
[32m[0906 18-23-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01859, current rewards: 217.73988, mean: 0.10570
[32m[0906 18-23-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: 223.21397, mean: 0.10579
[32m[0906 18-23-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 228.68097, mean: 0.10587
[32m[0906 18-23-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01862, current rewards: 234.12661, mean: 0.10594
[32m[0906 18-23-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01863, current rewards: 239.58375, mean: 0.10601
[32m[0906 18-23-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01864, current rewards: 245.03476, mean: 0.10608
[32m[0906 18-23-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01865, current rewards: 250.57130, mean: 0.10617
[32m[0906 18-23-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01867, current rewards: 256.10674, mean: 0.10627
[32m[0906 18-23-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01867, current rewards: 261.64480, mean: 0.10636
[32m[0906 18-23-35 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-23-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-23-35 @MBExp.py:227][0m Rewards obtained: [266.0674467494946], Lows: [2], Highs: [5], Total time: 5090.306447
[32m[0906 18-27-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-27-19 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 18-27-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01846, current rewards: 1.61600, mean: 0.16160
[32m[0906 18-27-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01831, current rewards: 7.15152, mean: 0.11919
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01843, current rewards: 12.72571, mean: 0.11569
[32m[0906 18-27-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01842, current rewards: 18.30517, mean: 0.11441
[32m[0906 18-27-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01843, current rewards: 23.87992, mean: 0.11371
[32m[0906 18-27-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 29.42218, mean: 0.11316
[32m[0906 18-27-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.98755, mean: 0.11286
[32m[0906 18-27-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 40.55449, mean: 0.11265
[32m[0906 18-27-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 46.12162, mean: 0.11249
[32m[0906 18-27-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 51.68401, mean: 0.11236
[32m[0906 18-27-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 57.24756, mean: 0.11225
[32m[0906 18-27-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.81191, mean: 0.11216
[32m[0906 18-27-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 68.39309, mean: 0.11212
[32m[0906 18-27-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 73.91761, mean: 0.11200
[32m[0906 18-27-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 79.44098, mean: 0.11189
[32m[0906 18-27-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 84.99458, mean: 0.11183
[32m[0906 18-27-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 90.54538, mean: 0.11178
[32m[0906 18-27-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 96.09666, mean: 0.11174
[32m[0906 18-27-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 101.64718, mean: 0.11170
[32m[0906 18-27-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 107.19760, mean: 0.11166
[32m[0906 18-27-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 112.73952, mean: 0.11162
[32m[0906 18-27-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 118.28237, mean: 0.11159
[32m[0906 18-27-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 123.90657, mean: 0.11163
[32m[0906 18-27-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 129.46298, mean: 0.11161
[32m[0906 18-27-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 135.01839, mean: 0.11159
[32m[0906 18-27-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 140.57372, mean: 0.11157
[32m[0906 18-27-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 146.12601, mean: 0.11155
[32m[0906 18-27-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 151.68409, mean: 0.11153
[32m[0906 18-27-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: 157.23986, mean: 0.11152
[32m[0906 18-27-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 162.79639, mean: 0.11150
[32m[0906 18-27-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01856, current rewards: 168.49089, mean: 0.11158
[32m[0906 18-27-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01857, current rewards: 174.07053, mean: 0.11158
[32m[0906 18-27-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01856, current rewards: 179.64535, mean: 0.11158
[32m[0906 18-27-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01856, current rewards: 185.24766, mean: 0.11159
[32m[0906 18-27-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01856, current rewards: 190.86842, mean: 0.11162
[32m[0906 18-27-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01856, current rewards: 196.48937, mean: 0.11164
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01856, current rewards: 202.10776, mean: 0.11166
[32m[0906 18-27-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01858, current rewards: 205.73388, mean: 0.11061
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 211.48880, mean: 0.11073
[32m[0906 18-27-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 217.24624, mean: 0.11084
[32m[0906 18-27-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 222.99952, mean: 0.11095
[32m[0906 18-27-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01863, current rewards: 228.75502, mean: 0.11105
[32m[0906 18-27-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01864, current rewards: 234.51192, mean: 0.11114
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01865, current rewards: 240.26684, mean: 0.11123
[32m[0906 18-28-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: 246.02507, mean: 0.11132
[32m[0906 18-28-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01867, current rewards: 253.20032, mean: 0.11204
[32m[0906 18-28-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01869, current rewards: 260.59661, mean: 0.11281
[32m[0906 18-28-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01870, current rewards: 225.47079, mean: 0.09554
[32m[0906 18-28-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01871, current rewards: 175.47079, mean: 0.07281
[32m[0906 18-28-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01871, current rewards: 125.47079, mean: 0.05100
[32m[0906 18-28-07 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-28-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-28-07 @MBExp.py:227][0m Rewards obtained: [85.47078508371845], Lows: [1], Highs: [176], Total time: 5137.938902
[32m[0906 18-31-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-31-53 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 18-31-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01818, current rewards: 1.03547, mean: 0.10355
[32m[0906 18-31-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01825, current rewards: 6.51657, mean: 0.10861
[32m[0906 18-31-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01836, current rewards: 12.02632, mean: 0.10933
[32m[0906 18-31-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01840, current rewards: 17.53964, mean: 0.10962
[32m[0906 18-31-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01841, current rewards: 23.05206, mean: 0.10977
[32m[0906 18-31-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01842, current rewards: 28.60129, mean: 0.11000
[32m[0906 18-31-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.13285, mean: 0.11011
[32m[0906 18-32-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 39.61719, mean: 0.11005
[32m[0906 18-32-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.09763, mean: 0.10999
[32m[0906 18-32-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.57395, mean: 0.10994
[32m[0906 18-32-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 56.05518, mean: 0.10991
[32m[0906 18-32-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 61.53272, mean: 0.10988
[32m[0906 18-32-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 67.09013, mean: 0.10998
[32m[0906 18-32-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 72.62218, mean: 0.11003
[32m[0906 18-32-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 78.04188, mean: 0.10992
[32m[0906 18-32-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 83.58692, mean: 0.10998
[32m[0906 18-32-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01857, current rewards: 89.13187, mean: 0.11004
[32m[0906 18-32-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01857, current rewards: 94.67476, mean: 0.11009
[32m[0906 18-32-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 100.21906, mean: 0.11013
[32m[0906 18-32-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 105.94488, mean: 0.11036
[32m[0906 18-32-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 111.49913, mean: 0.11040
[32m[0906 18-32-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 117.06112, mean: 0.11044
[32m[0906 18-32-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 122.65739, mean: 0.11050
[32m[0906 18-32-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 128.23433, mean: 0.11055
[32m[0906 18-32-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 133.75779, mean: 0.11054
[32m[0906 18-32-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: 139.28032, mean: 0.11054
[32m[0906 18-32-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01856, current rewards: 144.80616, mean: 0.11054
[32m[0906 18-32-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 150.32650, mean: 0.11053
[32m[0906 18-32-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01856, current rewards: 155.84966, mean: 0.11053
[32m[0906 18-32-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01857, current rewards: 161.37182, mean: 0.11053
[32m[0906 18-32-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01857, current rewards: 166.89280, mean: 0.11053
[32m[0906 18-32-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01857, current rewards: 172.37278, mean: 0.11050
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01857, current rewards: 177.89412, mean: 0.11049
[32m[0906 18-32-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01857, current rewards: 183.41303, mean: 0.11049
[32m[0906 18-32-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01857, current rewards: 188.93286, mean: 0.11049
[32m[0906 18-32-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 194.45271, mean: 0.11048
[32m[0906 18-32-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01860, current rewards: 199.97483, mean: 0.11048
[32m[0906 18-32-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 205.55958, mean: 0.11052
[32m[0906 18-32-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01863, current rewards: 211.10734, mean: 0.11053
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01864, current rewards: 216.64477, mean: 0.11053
[32m[0906 18-32-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01866, current rewards: 222.19242, mean: 0.11054
[32m[0906 18-32-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01867, current rewards: 227.74014, mean: 0.11055
[32m[0906 18-32-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01868, current rewards: 233.28844, mean: 0.11056
[32m[0906 18-32-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01869, current rewards: 238.83420, mean: 0.11057
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01870, current rewards: 244.38022, mean: 0.11058
[32m[0906 18-32-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01871, current rewards: 249.92876, mean: 0.11059
[32m[0906 18-32-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01872, current rewards: 253.26969, mean: 0.10964
[32m[0906 18-32-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01873, current rewards: 258.81317, mean: 0.10967
[32m[0906 18-32-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01875, current rewards: 264.28793, mean: 0.10966
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01875, current rewards: 269.76225, mean: 0.10966
[32m[0906 18-32-41 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-32-41 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-32-41 @MBExp.py:227][0m Rewards obtained: [274.1384429967708], Lows: [0], Highs: [2], Total time: 5185.679306999999
[32m[0906 18-36-30 @MBExp.py:144][0m ####################################################################
[32m[0906 18-36-30 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 18-36-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01829, current rewards: 1.04274, mean: 0.10427
[32m[0906 18-36-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01857, current rewards: 6.59856, mean: 0.10998
[32m[0906 18-36-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 12.16592, mean: 0.11060
[32m[0906 18-36-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.73205, mean: 0.11083
[32m[0906 18-36-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01853, current rewards: 23.30159, mean: 0.11096
[32m[0906 18-36-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 28.86861, mean: 0.11103
[32m[0906 18-36-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 34.31768, mean: 0.11070
[32m[0906 18-36-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.85498, mean: 0.11071
[32m[0906 18-36-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.39609, mean: 0.11072
[32m[0906 18-36-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 50.93725, mean: 0.11073
[32m[0906 18-36-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.47529, mean: 0.11074
[32m[0906 18-36-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.01025, mean: 0.11073
[32m[0906 18-36-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 67.55086, mean: 0.11074
[32m[0906 18-36-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.08740, mean: 0.11074
[32m[0906 18-36-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 78.66130, mean: 0.11079
[32m[0906 18-36-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.20330, mean: 0.11079
[32m[0906 18-36-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.74632, mean: 0.11080
[32m[0906 18-36-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 95.24891, mean: 0.11075
[32m[0906 18-36-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 100.78330, mean: 0.11075
[32m[0906 18-36-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 106.31622, mean: 0.11075
[32m[0906 18-36-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 111.84977, mean: 0.11074
[32m[0906 18-36-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 117.37581, mean: 0.11073
[32m[0906 18-36-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 122.95879, mean: 0.11077
[32m[0906 18-36-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01854, current rewards: 128.50523, mean: 0.11078
[32m[0906 18-36-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 134.09439, mean: 0.11082
[32m[0906 18-36-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 139.68308, mean: 0.11086
[32m[0906 18-36-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01856, current rewards: 145.27172, mean: 0.11089
[32m[0906 18-36-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01855, current rewards: 150.85825, mean: 0.11093
[32m[0906 18-36-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 156.44879, mean: 0.11096
[32m[0906 18-36-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 162.03917, mean: 0.11099
[32m[0906 18-36-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 167.81985, mean: 0.11114
[32m[0906 18-36-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 173.42269, mean: 0.11117
[32m[0906 18-37-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 179.02565, mean: 0.11120
[32m[0906 18-37-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: 184.62868, mean: 0.11122
[32m[0906 18-37-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: 186.88284, mean: 0.10929
[32m[0906 18-37-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: 192.48970, mean: 0.10937
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01854, current rewards: 198.09798, mean: 0.10945
[32m[0906 18-37-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01857, current rewards: 203.70470, mean: 0.10952
[32m[0906 18-37-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01858, current rewards: 209.33298, mean: 0.10960
[32m[0906 18-37-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01860, current rewards: 214.86807, mean: 0.10963
[32m[0906 18-37-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 220.40309, mean: 0.10965
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01863, current rewards: 225.93323, mean: 0.10968
[32m[0906 18-37-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01865, current rewards: 231.46084, mean: 0.10970
[32m[0906 18-37-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01866, current rewards: 236.99113, mean: 0.10972
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01867, current rewards: 242.51748, mean: 0.10974
[32m[0906 18-37-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01868, current rewards: 248.05005, mean: 0.10976
[32m[0906 18-37-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01869, current rewards: 253.56718, mean: 0.10977
[32m[0906 18-37-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01870, current rewards: 259.10219, mean: 0.10979
[32m[0906 18-37-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01871, current rewards: 264.74774, mean: 0.10985
[32m[0906 18-37-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01872, current rewards: 270.32469, mean: 0.10989
[32m[0906 18-37-17 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-37-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-37-17 @MBExp.py:227][0m Rewards obtained: [274.78782269788667], Lows: [0], Highs: [3], Total time: 5233.354914
[32m[0906 18-41-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-41-07 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 18-41-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01822, current rewards: 1.34183, mean: 0.13418
[32m[0906 18-41-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01823, current rewards: 6.82570, mean: 0.11376
[32m[0906 18-41-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01829, current rewards: 12.35286, mean: 0.11230
[32m[0906 18-41-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01834, current rewards: 17.88233, mean: 0.11176
[32m[0906 18-41-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01836, current rewards: 23.41301, mean: 0.11149
[32m[0906 18-41-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01838, current rewards: 29.01792, mean: 0.11161
[32m[0906 18-41-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01838, current rewards: 34.56398, mean: 0.11150
[32m[0906 18-41-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01838, current rewards: 40.11402, mean: 0.11143
[32m[0906 18-41-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01841, current rewards: 45.66143, mean: 0.11137
[32m[0906 18-41-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 51.21404, mean: 0.11133
[32m[0906 18-41-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.76206, mean: 0.11130
[32m[0906 18-41-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01846, current rewards: 62.30936, mean: 0.11127
[32m[0906 18-41-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01845, current rewards: 67.85945, mean: 0.11124
[32m[0906 18-41-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01846, current rewards: 73.47655, mean: 0.11133
[32m[0906 18-41-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01846, current rewards: 79.03406, mean: 0.11132
[32m[0906 18-41-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 84.59538, mean: 0.11131
[32m[0906 18-41-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 88.56297, mean: 0.10934
[32m[0906 18-41-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01848, current rewards: 94.48085, mean: 0.10986
[32m[0906 18-41-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 100.39872, mean: 0.11033
[32m[0906 18-41-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 106.31660, mean: 0.11075
[32m[0906 18-41-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 112.23447, mean: 0.11112
[32m[0906 18-41-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 118.02543, mean: 0.11134
[32m[0906 18-41-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01850, current rewards: 95.75867, mean: 0.08627
[32m[0906 18-41-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 45.75867, mean: 0.03945
[32m[0906 18-41-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: -4.24133, mean: -0.00351
[32m[0906 18-41-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: -54.24133, mean: -0.04305
[32m[0906 18-41-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: -104.24133, mean: -0.07957
[32m[0906 18-41-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: -154.24133, mean: -0.11341
[32m[0906 18-41-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: -204.24133, mean: -0.14485
[32m[0906 18-41-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: -254.24133, mean: -0.17414
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01853, current rewards: -304.24133, mean: -0.20148
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01853, current rewards: -354.24133, mean: -0.22708
[32m[0906 18-41-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01853, current rewards: -404.24133, mean: -0.25108
[32m[0906 18-41-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01853, current rewards: -454.24133, mean: -0.27364
[32m[0906 18-41-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01853, current rewards: -504.24133, mean: -0.29488
[32m[0906 18-41-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01853, current rewards: -554.24133, mean: -0.31491
[32m[0906 18-41-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01853, current rewards: -604.24133, mean: -0.33383
[32m[0906 18-41-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: -654.24133, mean: -0.35174
[32m[0906 18-41-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01857, current rewards: -704.24133, mean: -0.36871
[32m[0906 18-41-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: -754.24133, mean: -0.38482
[32m[0906 18-41-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: -804.24133, mean: -0.40012
[32m[0906 18-41-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01861, current rewards: -854.24133, mean: -0.41468
[32m[0906 18-41-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01863, current rewards: -904.24133, mean: -0.42855
[32m[0906 18-41-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01865, current rewards: -954.24133, mean: -0.44178
[32m[0906 18-41-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: -1004.24133, mean: -0.45441
[32m[0906 18-41-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01867, current rewards: -1054.24133, mean: -0.46648
[32m[0906 18-41-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01868, current rewards: -1104.24133, mean: -0.47803
[32m[0906 18-41-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01869, current rewards: -1154.24133, mean: -0.48909
[32m[0906 18-41-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01870, current rewards: -1204.24133, mean: -0.49969
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01871, current rewards: -1254.24133, mean: -0.50985
[32m[0906 18-41-55 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-41-55 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-41-55 @MBExp.py:227][0m Rewards obtained: [-1294.241329096721], Lows: [1], Highs: [1414], Total time: 5280.988829999999
[32m[0906 18-45-47 @MBExp.py:144][0m ####################################################################
[32m[0906 18-45-47 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 18-45-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01987, current rewards: -0.02420, mean: -0.00242
[32m[0906 18-45-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01813, current rewards: 5.57996, mean: 0.09300
[32m[0906 18-45-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01830, current rewards: 11.18556, mean: 0.10169
[32m[0906 18-45-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01840, current rewards: 16.79316, mean: 0.10496
[32m[0906 18-45-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 22.40190, mean: 0.10668
[32m[0906 18-45-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 28.00715, mean: 0.10772
[32m[0906 18-45-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 33.61247, mean: 0.10843
[32m[0906 18-45-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 39.21855, mean: 0.10894
[32m[0906 18-45-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 44.81965, mean: 0.10932
[32m[0906 18-45-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 50.42719, mean: 0.10962
[32m[0906 18-45-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 56.03478, mean: 0.10987
[32m[0906 18-45-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 61.63969, mean: 0.11007
[32m[0906 18-45-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 67.24938, mean: 0.11024
[32m[0906 18-45-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 70.89420, mean: 0.10742
[32m[0906 18-46-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01856, current rewards: 79.05336, mean: 0.11134
[32m[0906 18-46-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 86.91291, mean: 0.11436
[32m[0906 18-46-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: 94.77245, mean: 0.11700
[32m[0906 18-46-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01859, current rewards: 102.63199, mean: 0.11934
[32m[0906 18-46-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01859, current rewards: 61.88952, mean: 0.06801
[32m[0906 18-46-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 11.88952, mean: 0.01238
[32m[0906 18-46-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01859, current rewards: -38.11048, mean: -0.03773
[32m[0906 18-46-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01859, current rewards: -88.11048, mean: -0.08312
[32m[0906 18-46-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: -87.00921, mean: -0.07839
[32m[0906 18-46-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: -81.41798, mean: -0.07019
[32m[0906 18-46-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: -75.83245, mean: -0.06267
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01859, current rewards: -70.02974, mean: -0.05558
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: -64.43661, mean: -0.04919
[32m[0906 18-46-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: -58.84097, mean: -0.04327
[32m[0906 18-46-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: -53.24991, mean: -0.03777
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01860, current rewards: -47.67263, mean: -0.03265
[32m[0906 18-46-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01860, current rewards: -42.24152, mean: -0.02797
[32m[0906 18-46-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01860, current rewards: -36.68524, mean: -0.02352
[32m[0906 18-46-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01860, current rewards: -31.12684, mean: -0.01933
[32m[0906 18-46-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01860, current rewards: -25.57111, mean: -0.01540
[32m[0906 18-46-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01860, current rewards: -20.01840, mean: -0.01171
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: -14.46168, mean: -0.00822
[32m[0906 18-46-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01861, current rewards: -8.90765, mean: -0.00492
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01862, current rewards: -3.34820, mean: -0.00180
[32m[0906 18-46-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01864, current rewards: 2.32570, mean: 0.00122
[32m[0906 18-46-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01865, current rewards: 7.89561, mean: 0.00403
[32m[0906 18-46-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01866, current rewards: 13.47452, mean: 0.00670
[32m[0906 18-46-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01868, current rewards: 19.05516, mean: 0.00925
[32m[0906 18-46-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01869, current rewards: 24.63944, mean: 0.01168
[32m[0906 18-46-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01870, current rewards: 30.22738, mean: 0.01399
[32m[0906 18-46-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01871, current rewards: 35.81508, mean: 0.01621
[32m[0906 18-46-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01872, current rewards: 41.40239, mean: 0.01832
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01873, current rewards: 46.99164, mean: 0.02034
[32m[0906 18-46-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01874, current rewards: 52.47408, mean: 0.02223
[32m[0906 18-46-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01875, current rewards: 58.06372, mean: 0.02409
[32m[0906 18-46-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01876, current rewards: 63.65410, mean: 0.02588
[32m[0906 18-46-34 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-46-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-46-35 @MBExp.py:227][0m Rewards obtained: [68.11291760341433], Lows: [1], Highs: [197], Total time: 5328.751638
[32m[0906 18-50-28 @MBExp.py:144][0m ####################################################################
[32m[0906 18-50-28 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 18-50-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01665, current rewards: 1.01919, mean: 0.10192
[32m[0906 18-50-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01829, current rewards: 6.58040, mean: 0.10967
[32m[0906 18-50-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.14861, mean: 0.11044
[32m[0906 18-50-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.71849, mean: 0.11074
[32m[0906 18-50-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01848, current rewards: 23.28597, mean: 0.11089
[32m[0906 18-50-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.91650, mean: 0.11122
[32m[0906 18-50-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 35.58958, mean: 0.11481
[32m[0906 18-50-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 42.51625, mean: 0.11810
[32m[0906 18-50-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 49.44291, mean: 0.12059
[32m[0906 18-50-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 56.36958, mean: 0.12254
[32m[0906 18-50-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 63.29624, mean: 0.12411
[32m[0906 18-50-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 54.28344, mean: 0.09693
[32m[0906 18-50-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 49.80465, mean: 0.08165
[32m[0906 18-50-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 55.36075, mean: 0.08388
[32m[0906 18-50-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: 60.82108, mean: 0.08566
[32m[0906 18-50-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 66.93945, mean: 0.08808
[32m[0906 18-50-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01856, current rewards: 72.49262, mean: 0.08950
[32m[0906 18-50-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 78.04818, mean: 0.09075
[32m[0906 18-50-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 83.60115, mean: 0.09187
[32m[0906 18-50-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 89.16025, mean: 0.09288
[32m[0906 18-50-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 94.71200, mean: 0.09377
[32m[0906 18-50-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 100.25825, mean: 0.09458
[32m[0906 18-50-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 105.87466, mean: 0.09538
[32m[0906 18-50-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 111.43028, mean: 0.09606
[32m[0906 18-50-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 116.98549, mean: 0.09668
[32m[0906 18-50-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 122.54089, mean: 0.09725
[32m[0906 18-50-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 128.09339, mean: 0.09778
[32m[0906 18-50-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: 131.56682, mean: 0.09674
[32m[0906 18-50-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 137.14039, mean: 0.09726
[32m[0906 18-50-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01857, current rewards: 142.71646, mean: 0.09775
[32m[0906 18-50-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 148.28733, mean: 0.09820
[32m[0906 18-50-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 153.86610, mean: 0.09863
[32m[0906 18-50-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 159.42403, mean: 0.09902
[32m[0906 18-50-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01858, current rewards: 164.99228, mean: 0.09939
[32m[0906 18-51-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 170.55639, mean: 0.09974
[32m[0906 18-51-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 176.12622, mean: 0.10007
[32m[0906 18-51-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01860, current rewards: 181.69556, mean: 0.10038
[32m[0906 18-51-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 187.26481, mean: 0.10068
[32m[0906 18-51-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01863, current rewards: 192.82791, mean: 0.10096
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01865, current rewards: 198.36258, mean: 0.10121
[32m[0906 18-51-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01866, current rewards: 203.92424, mean: 0.10145
[32m[0906 18-51-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01868, current rewards: 209.48684, mean: 0.10169
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01869, current rewards: 215.31795, mean: 0.10205
[32m[0906 18-51-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01870, current rewards: 220.87462, mean: 0.10226
[32m[0906 18-51-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01871, current rewards: 226.42953, mean: 0.10246
[32m[0906 18-51-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01872, current rewards: 231.98334, mean: 0.10265
[32m[0906 18-51-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01873, current rewards: 237.53785, mean: 0.10283
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01874, current rewards: 243.11425, mean: 0.10301
[32m[0906 18-51-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01875, current rewards: 248.67110, mean: 0.10318
[32m[0906 18-51-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01876, current rewards: 254.19739, mean: 0.10333
[32m[0906 18-51-16 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-51-16 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-51-16 @MBExp.py:227][0m Rewards obtained: [258.64314009352483], Lows: [1], Highs: [23], Total time: 5376.501405
[32m[0906 18-55-12 @MBExp.py:144][0m ####################################################################
[32m[0906 18-55-12 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 18-55-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01863, current rewards: 1.10170, mean: 0.11017
[32m[0906 18-55-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01886, current rewards: 6.65387, mean: 0.11090
[32m[0906 18-55-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 12.21260, mean: 0.11102
[32m[0906 18-55-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01850, current rewards: 17.76248, mean: 0.11102
[32m[0906 18-55-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01848, current rewards: 23.31382, mean: 0.11102
[32m[0906 18-55-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 28.96917, mean: 0.11142
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 34.51956, mean: 0.11135
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 40.08126, mean: 0.11134
[32m[0906 18-55-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 45.63922, mean: 0.11132
[32m[0906 18-55-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 51.19421, mean: 0.11129
[32m[0906 18-55-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01857, current rewards: 56.79514, mean: 0.11136
[32m[0906 18-55-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 62.33713, mean: 0.11132
[32m[0906 18-55-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 67.88001, mean: 0.11128
[32m[0906 18-55-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01857, current rewards: 73.40157, mean: 0.11121
[32m[0906 18-55-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01857, current rewards: 78.94315, mean: 0.11119
[32m[0906 18-55-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 84.48808, mean: 0.11117
[32m[0906 18-55-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01856, current rewards: 90.02673, mean: 0.11114
[32m[0906 18-55-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 95.56824, mean: 0.11113
[32m[0906 18-55-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 101.10924, mean: 0.11111
[32m[0906 18-55-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 106.73458, mean: 0.11118
[32m[0906 18-55-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 112.26642, mean: 0.11115
[32m[0906 18-55-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 117.78371, mean: 0.11112
[32m[0906 18-55-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 123.24491, mean: 0.11103
[32m[0906 18-55-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 128.78578, mean: 0.11102
[32m[0906 18-55-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01854, current rewards: 134.44279, mean: 0.11111
[32m[0906 18-55-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: 139.97326, mean: 0.11109
[32m[0906 18-55-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: 145.50454, mean: 0.11107
[32m[0906 18-55-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 151.03739, mean: 0.11106
[32m[0906 18-55-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 156.57225, mean: 0.11104
[32m[0906 18-55-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01852, current rewards: 162.10343, mean: 0.11103
[32m[0906 18-55-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01852, current rewards: 167.73057, mean: 0.11108
[32m[0906 18-55-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01852, current rewards: 173.28415, mean: 0.11108
[32m[0906 18-55-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01852, current rewards: 178.83789, mean: 0.11108
[32m[0906 18-55-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01852, current rewards: 184.39217, mean: 0.11108
[32m[0906 18-55-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: 189.94687, mean: 0.11108
[32m[0906 18-55-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01851, current rewards: 193.27222, mean: 0.10981
[32m[0906 18-55-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01854, current rewards: 198.84128, mean: 0.10986
[32m[0906 18-55-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01856, current rewards: 204.41121, mean: 0.10990
[32m[0906 18-55-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01858, current rewards: 209.90597, mean: 0.10990
[32m[0906 18-55-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01859, current rewards: 215.41810, mean: 0.10991
[32m[0906 18-55-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01861, current rewards: 220.98578, mean: 0.10994
[32m[0906 18-55-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01862, current rewards: 226.56092, mean: 0.10998
[32m[0906 18-55-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01863, current rewards: 232.12438, mean: 0.11001
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01864, current rewards: 237.68830, mean: 0.11004
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01865, current rewards: 243.24907, mean: 0.11007
[32m[0906 18-55-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01866, current rewards: 248.80023, mean: 0.11009
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01867, current rewards: 254.35576, mean: 0.11011
[32m[0906 18-55-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01868, current rewards: 259.98179, mean: 0.11016
[32m[0906 18-55-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01869, current rewards: 265.53181, mean: 0.11018
[32m[0906 18-55-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01870, current rewards: 271.08711, mean: 0.11020
[32m[0906 18-55-59 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 18-55-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-55-59 @MBExp.py:227][0m Rewards obtained: [275.5277401044954], Lows: [0], Highs: [2], Total time: 5424.117291
[32m[0906 18-59-58 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-58 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 18-59-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01900, current rewards: 1.08978, mean: 0.10898
[32m[0906 18-59-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01892, current rewards: 6.63701, mean: 0.11062
[32m[0906 19-00-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01857, current rewards: 12.18444, mean: 0.11077
[32m[0906 19-00-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01853, current rewards: 17.73389, mean: 0.11084
[32m[0906 19-00-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01860, current rewards: 23.28840, mean: 0.11090
[32m[0906 19-00-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01859, current rewards: 28.89568, mean: 0.11114
[32m[0906 19-00-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 34.43280, mean: 0.11107
[32m[0906 19-00-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01858, current rewards: 39.96706, mean: 0.11102
[32m[0906 19-00-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01857, current rewards: 45.50861, mean: 0.11100
[32m[0906 19-00-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01859, current rewards: 51.05556, mean: 0.11099
[32m[0906 19-00-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01859, current rewards: 56.59428, mean: 0.11097
[32m[0906 19-00-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 62.13258, mean: 0.11095
[32m[0906 19-00-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01859, current rewards: 67.67966, mean: 0.11095
[32m[0906 19-00-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 73.21947, mean: 0.11094
[32m[0906 19-00-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 78.69120, mean: 0.11083
[32m[0906 19-00-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01861, current rewards: 84.23766, mean: 0.11084
[32m[0906 19-00-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01862, current rewards: 89.79287, mean: 0.11086
[32m[0906 19-00-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01862, current rewards: 95.34144, mean: 0.11086
[32m[0906 19-00-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01862, current rewards: 100.89650, mean: 0.11088
[32m[0906 19-00-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01862, current rewards: 106.44735, mean: 0.11088
[32m[0906 19-00-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01863, current rewards: 111.99674, mean: 0.11089
[32m[0906 19-00-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01864, current rewards: 117.54484, mean: 0.11089
[32m[0906 19-00-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01865, current rewards: 123.10092, mean: 0.11090
[32m[0906 19-00-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01864, current rewards: 128.64874, mean: 0.11090
[32m[0906 19-00-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01864, current rewards: 134.20328, mean: 0.11091
[32m[0906 19-00-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 139.75123, mean: 0.11091
[32m[0906 19-00-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01863, current rewards: 145.36029, mean: 0.11096
[32m[0906 19-00-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 150.86102, mean: 0.11093
[32m[0906 19-00-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01863, current rewards: 156.35975, mean: 0.11089
[32m[0906 19-00-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01863, current rewards: 161.86047, mean: 0.11086
[32m[0906 19-00-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01862, current rewards: 167.51844, mean: 0.11094
[32m[0906 19-00-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01862, current rewards: 173.43632, mean: 0.11118
[32m[0906 19-00-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01862, current rewards: 179.35419, mean: 0.11140
[32m[0906 19-00-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01862, current rewards: 185.27207, mean: 0.11161
[32m[0906 19-00-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01862, current rewards: 191.18994, mean: 0.11181
[32m[0906 19-00-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: 162.43873, mean: 0.09229
[32m[0906 19-00-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01864, current rewards: 112.43873, mean: 0.06212
[32m[0906 19-00-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01865, current rewards: 62.43873, mean: 0.03357
[32m[0906 19-00-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01866, current rewards: 12.43873, mean: 0.00651
[32m[0906 19-00-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01867, current rewards: -37.56127, mean: -0.01916
[32m[0906 19-00-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01869, current rewards: -87.56127, mean: -0.04356
[32m[0906 19-00-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01870, current rewards: -137.56127, mean: -0.06678
[32m[0906 19-00-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01871, current rewards: -187.56127, mean: -0.08889
[32m[0906 19-00-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01873, current rewards: -237.56127, mean: -0.10998
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01874, current rewards: -287.56127, mean: -0.13012
[32m[0906 19-00-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01875, current rewards: -337.56127, mean: -0.14936
[32m[0906 19-00-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01876, current rewards: -387.56127, mean: -0.16778
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01877, current rewards: -437.56127, mean: -0.18541
[32m[0906 19-00-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01878, current rewards: -487.56127, mean: -0.20231
[32m[0906 19-00-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01879, current rewards: -537.56127, mean: -0.21852
[32m[0906 19-00-46 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 19-00-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-00-46 @MBExp.py:227][0m Rewards obtained: [-577.5612652186284], Lows: [0], Highs: [771], Total time: 5471.957848
[32m[0906 19-04-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-04-46 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 19-04-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02043, current rewards: 1.97309, mean: 0.19731
[32m[0906 19-04-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02236, current rewards: 10.44933, mean: 0.17416
[32m[0906 19-04-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02259, current rewards: 18.66217, mean: 0.16966
[32m[0906 19-04-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02274, current rewards: 27.09874, mean: 0.16937
[32m[0906 19-04-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02291, current rewards: 35.50104, mean: 0.16905
[32m[0906 19-04-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02294, current rewards: 43.95983, mean: 0.16908
[32m[0906 19-04-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02223, current rewards: 49.55187, mean: 0.15984
[32m[0906 19-04-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02175, current rewards: 55.10582, mean: 0.15307
[32m[0906 19-04-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02135, current rewards: 60.66081, mean: 0.14795
[32m[0906 19-04-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02104, current rewards: 66.22484, mean: 0.14397
[32m[0906 19-04-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02078, current rewards: 71.77933, mean: 0.14074
[32m[0906 19-04-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02058, current rewards: 77.33481, mean: 0.13810
[32m[0906 19-04-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02041, current rewards: 82.89081, mean: 0.13589
[32m[0906 19-05-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02028, current rewards: 88.47802, mean: 0.13406
[32m[0906 19-05-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02017, current rewards: 92.12273, mean: 0.12975
[32m[0906 19-05-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02006, current rewards: 98.80287, mean: 0.13000
[32m[0906 19-05-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01997, current rewards: 105.65650, mean: 0.13044
[32m[0906 19-05-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01990, current rewards: 112.49825, mean: 0.13081
[32m[0906 19-05-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01983, current rewards: 119.35158, mean: 0.13116
[32m[0906 19-05-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01976, current rewards: 126.21123, mean: 0.13147
[32m[0906 19-05-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01970, current rewards: 133.05940, mean: 0.13174
[32m[0906 19-05-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01965, current rewards: 137.91218, mean: 0.13011
[32m[0906 19-05-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01960, current rewards: 144.40562, mean: 0.13010
[32m[0906 19-05-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01956, current rewards: 150.91081, mean: 0.13010
[32m[0906 19-05-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01951, current rewards: 157.40960, mean: 0.13009
[32m[0906 19-05-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01947, current rewards: 163.81719, mean: 0.13001
[32m[0906 19-05-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01943, current rewards: 170.29463, mean: 0.13000
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01941, current rewards: 176.80215, mean: 0.13000
[32m[0906 19-05-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01938, current rewards: 183.30253, mean: 0.13000
[32m[0906 19-05-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01935, current rewards: 189.74424, mean: 0.12996
[32m[0906 19-05-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01933, current rewards: 196.54228, mean: 0.13016
[32m[0906 19-05-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01930, current rewards: 203.46894, mean: 0.13043
[32m[0906 19-05-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01928, current rewards: 210.39560, mean: 0.13068
[32m[0906 19-05-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01926, current rewards: 166.08826, mean: 0.10005
[32m[0906 19-05-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01926, current rewards: 116.08826, mean: 0.06789
[32m[0906 19-05-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01926, current rewards: 66.08826, mean: 0.03755
[32m[0906 19-05-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01926, current rewards: 16.08826, mean: 0.00889
[32m[0906 19-05-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01926, current rewards: -33.91174, mean: -0.01823
[32m[0906 19-05-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01926, current rewards: -83.91174, mean: -0.04393
[32m[0906 19-05-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01925, current rewards: -133.91174, mean: -0.06832
[32m[0906 19-05-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01925, current rewards: -183.91174, mean: -0.09150
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01925, current rewards: -233.91174, mean: -0.11355
[32m[0906 19-05-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: -283.91174, mean: -0.13456
[32m[0906 19-05-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01925, current rewards: -333.91174, mean: -0.15459
[32m[0906 19-05-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01925, current rewards: -383.91174, mean: -0.17372
[32m[0906 19-05-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01925, current rewards: -433.91174, mean: -0.19200
[32m[0906 19-05-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01924, current rewards: -483.91174, mean: -0.20949
[32m[0906 19-05-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01924, current rewards: -533.91174, mean: -0.22623
[32m[0906 19-05-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01924, current rewards: -583.91174, mean: -0.24229
[32m[0906 19-05-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01924, current rewards: -633.91174, mean: -0.25769
[32m[0906 19-05-35 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 19-05-35 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-05-35 @MBExp.py:227][0m Rewards obtained: [-673.9117359557844], Lows: [2], Highs: [885], Total time: 5520.913555
[32m[0906 19-09-40 @MBExp.py:144][0m ####################################################################
[32m[0906 19-09-40 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 19-09-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01977, current rewards: -20.00000, mean: -2.00000
[32m[0906 19-09-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01863, current rewards: -16.01078, mean: -0.26685
[32m[0906 19-09-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01854, current rewards: -10.14634, mean: -0.09224
[32m[0906 19-09-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: -4.28948, mean: -0.02681
[32m[0906 19-09-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 1.56635, mean: 0.00746
[32m[0906 19-09-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 7.43499, mean: 0.02860
[32m[0906 19-09-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 13.58105, mean: 0.04381
[32m[0906 19-09-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 19.72279, mean: 0.05479
[32m[0906 19-09-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 25.86575, mean: 0.06309
[32m[0906 19-09-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 31.99952, mean: 0.06956
[32m[0906 19-09-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 38.13477, mean: 0.07477
[32m[0906 19-09-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 44.27055, mean: 0.07905
[32m[0906 19-09-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 50.39928, mean: 0.08262
[32m[0906 19-09-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 56.61561, mean: 0.08578
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 62.49969, mean: 0.08803
[32m[0906 19-09-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 68.36580, mean: 0.08995
[32m[0906 19-09-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 74.18153, mean: 0.09158
[32m[0906 19-09-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 80.00406, mean: 0.09303
[32m[0906 19-09-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 85.81757, mean: 0.09431
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 91.63933, mean: 0.09546
[32m[0906 19-09-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 97.46427, mean: 0.09650
[32m[0906 19-10-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 103.28312, mean: 0.09744
[32m[0906 19-10-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 32.91874, mean: 0.02966
[32m[0906 19-10-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: -67.08126, mean: -0.05783
[32m[0906 19-10-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: -167.08126, mean: -0.13808
[32m[0906 19-10-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01851, current rewards: -267.08126, mean: -0.21197
[32m[0906 19-10-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01851, current rewards: -367.08126, mean: -0.28021
[32m[0906 19-10-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: -467.08126, mean: -0.34344
[32m[0906 19-10-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: -567.08126, mean: -0.40219
[32m[0906 19-10-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: -667.08126, mean: -0.45690
[32m[0906 19-10-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: -767.08126, mean: -0.50800
[32m[0906 19-10-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: -867.08126, mean: -0.55582
[32m[0906 19-10-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: -967.08126, mean: -0.60067
[32m[0906 19-10-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: -1067.08126, mean: -0.64282
[32m[0906 19-10-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01853, current rewards: -1167.08126, mean: -0.68250
[32m[0906 19-10-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: -1267.08126, mean: -0.71993
[32m[0906 19-10-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01854, current rewards: -1367.08126, mean: -0.75529
[32m[0906 19-10-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01854, current rewards: -1467.08126, mean: -0.78875
[32m[0906 19-10-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01854, current rewards: -1567.08126, mean: -0.82046
[32m[0906 19-10-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01856, current rewards: -1667.08126, mean: -0.85055
[32m[0906 19-10-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01857, current rewards: -1767.08126, mean: -0.87914
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01858, current rewards: -1867.08126, mean: -0.90635
[32m[0906 19-10-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: -1967.08126, mean: -0.93227
[32m[0906 19-10-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: -2067.08126, mean: -0.95698
[32m[0906 19-10-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01863, current rewards: -2167.08126, mean: -0.98058
[32m[0906 19-10-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01864, current rewards: -2267.08126, mean: -1.00313
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01865, current rewards: -2367.08126, mean: -1.02471
[32m[0906 19-10-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: -2467.08126, mean: -1.04537
[32m[0906 19-10-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01867, current rewards: -2567.08126, mean: -1.06518
[32m[0906 19-10-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01868, current rewards: -2667.08126, mean: -1.08418
[32m[0906 19-10-27 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-10-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-10-28 @MBExp.py:227][0m Rewards obtained: [-2747.0812648939673], Lows: [1437], Highs: [0], Total time: 5568.482138
[32m[0906 19-14-32 @MBExp.py:144][0m ####################################################################
[32m[0906 19-14-32 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 19-14-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01701, current rewards: 1.02094, mean: 0.10209
[32m[0906 19-14-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01847, current rewards: 6.57149, mean: 0.10952
[32m[0906 19-14-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01862, current rewards: 12.11692, mean: 0.11015
[32m[0906 19-14-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01870, current rewards: 17.65986, mean: 0.11037
[32m[0906 19-14-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01872, current rewards: 23.24802, mean: 0.11070
[32m[0906 19-14-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01867, current rewards: 28.82487, mean: 0.11086
[32m[0906 19-14-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01866, current rewards: 34.37652, mean: 0.11089
[32m[0906 19-14-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01864, current rewards: 39.96206, mean: 0.11101
[32m[0906 19-14-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01863, current rewards: 45.49230, mean: 0.11096
[32m[0906 19-14-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01863, current rewards: 51.02297, mean: 0.11092
[32m[0906 19-14-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01862, current rewards: 56.55795, mean: 0.11090
[32m[0906 19-14-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01863, current rewards: 62.08668, mean: 0.11087
[32m[0906 19-14-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01862, current rewards: 67.61746, mean: 0.11085
[32m[0906 19-14-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01859, current rewards: 73.02546, mean: 0.11064
[32m[0906 19-14-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 78.53809, mean: 0.11062
[32m[0906 19-14-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 84.05596, mean: 0.11060
[32m[0906 19-14-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01859, current rewards: 89.57040, mean: 0.11058
[32m[0906 19-14-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01860, current rewards: 95.08617, mean: 0.11057
[32m[0906 19-14-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01859, current rewards: 100.59854, mean: 0.11055
[32m[0906 19-14-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01859, current rewards: 106.13801, mean: 0.11056
[32m[0906 19-14-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 111.67926, mean: 0.11057
[32m[0906 19-14-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01861, current rewards: 117.25958, mean: 0.11062
[32m[0906 19-14-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: 122.79141, mean: 0.11062
[32m[0906 19-14-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 128.32311, mean: 0.11062
[32m[0906 19-14-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: 133.85929, mean: 0.11063
[32m[0906 19-14-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: 139.38557, mean: 0.11062
[32m[0906 19-14-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 144.91846, mean: 0.11062
[32m[0906 19-14-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01861, current rewards: 150.45236, mean: 0.11063
[32m[0906 19-14-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 155.99154, mean: 0.11063
[32m[0906 19-14-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 161.59086, mean: 0.11068
[32m[0906 19-15-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01861, current rewards: 167.12859, mean: 0.11068
[32m[0906 19-15-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 172.78893, mean: 0.11076
[32m[0906 19-15-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 178.33698, mean: 0.11077
[32m[0906 19-15-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 183.88085, mean: 0.11077
[32m[0906 19-15-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01861, current rewards: 189.42985, mean: 0.11078
[32m[0906 19-15-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01861, current rewards: 194.97875, mean: 0.11078
[32m[0906 19-15-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01861, current rewards: 200.52672, mean: 0.11079
[32m[0906 19-15-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 206.08113, mean: 0.11080
[32m[0906 19-15-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: 211.63980, mean: 0.11081
[32m[0906 19-15-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01862, current rewards: 217.18795, mean: 0.11081
[32m[0906 19-15-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 222.73679, mean: 0.11081
[32m[0906 19-15-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01862, current rewards: 228.52374, mean: 0.11093
[32m[0906 19-15-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01863, current rewards: 234.83917, mean: 0.11130
[32m[0906 19-15-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01864, current rewards: 241.15459, mean: 0.11165
[32m[0906 19-15-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01866, current rewards: 247.47002, mean: 0.11198
[32m[0906 19-15-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01867, current rewards: 223.37511, mean: 0.09884
[32m[0906 19-15-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01868, current rewards: 173.37511, mean: 0.07505
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01870, current rewards: 123.37511, mean: 0.05228
[32m[0906 19-15-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01871, current rewards: 73.37511, mean: 0.03045
[32m[0906 19-15-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01872, current rewards: 23.37511, mean: 0.00950
[32m[0906 19-15-19 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-15-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-15-20 @MBExp.py:227][0m Rewards obtained: [-16.624885804944597], Lows: [0], Highs: [267], Total time: 5616.137445
[32m[0906 19-19-26 @MBExp.py:144][0m ####################################################################
[32m[0906 19-19-26 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 19-19-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01751, current rewards: 0.04792, mean: 0.00479
[32m[0906 19-19-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01858, current rewards: 5.54671, mean: 0.09245
[32m[0906 19-19-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01855, current rewards: 11.05092, mean: 0.10046
[32m[0906 19-19-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01863, current rewards: 16.55491, mean: 0.10347
[32m[0906 19-19-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 22.08300, mean: 0.10516
[32m[0906 19-19-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01857, current rewards: 27.61308, mean: 0.10620
[32m[0906 19-19-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01858, current rewards: 33.02978, mean: 0.10655
[32m[0906 19-19-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01861, current rewards: 38.44548, mean: 0.10679
[32m[0906 19-19-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 43.85550, mean: 0.10696
[32m[0906 19-19-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01862, current rewards: 47.60802, mean: 0.10350
[32m[0906 19-19-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01861, current rewards: 53.30624, mean: 0.10452
[32m[0906 19-19-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01863, current rewards: 58.99763, mean: 0.10535
[32m[0906 19-19-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01860, current rewards: 64.69594, mean: 0.10606
[32m[0906 19-19-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01860, current rewards: 70.22738, mean: 0.10641
[32m[0906 19-19-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01860, current rewards: 75.80890, mean: 0.10677
[32m[0906 19-19-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01860, current rewards: 81.38243, mean: 0.10708
[32m[0906 19-19-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01861, current rewards: 86.96350, mean: 0.10736
[32m[0906 19-19-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01861, current rewards: 92.54083, mean: 0.10761
[32m[0906 19-19-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01861, current rewards: 98.12555, mean: 0.10783
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01861, current rewards: 103.71173, mean: 0.10803
[32m[0906 19-19-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01861, current rewards: 109.28911, mean: 0.10821
[32m[0906 19-19-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01860, current rewards: 114.88553, mean: 0.10838
[32m[0906 19-19-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: 120.44131, mean: 0.10851
[32m[0906 19-19-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01860, current rewards: 125.99429, mean: 0.10862
[32m[0906 19-19-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 131.54943, mean: 0.10872
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01861, current rewards: 137.10104, mean: 0.10881
[32m[0906 19-19-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01860, current rewards: 140.88333, mean: 0.10754
[32m[0906 19-19-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01860, current rewards: 146.72654, mean: 0.10789
[32m[0906 19-19-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01861, current rewards: 152.56584, mean: 0.10820
[32m[0906 19-19-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 158.45158, mean: 0.10853
[32m[0906 19-19-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01861, current rewards: 166.72206, mean: 0.11041
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 155.88213, mean: 0.09992
[32m[0906 19-19-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 105.88213, mean: 0.06577
[32m[0906 19-19-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01859, current rewards: 55.88213, mean: 0.03366
[32m[0906 19-19-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01859, current rewards: 5.88213, mean: 0.00344
[32m[0906 19-19-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01859, current rewards: -44.11787, mean: -0.02507
[32m[0906 19-20-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01859, current rewards: -94.11787, mean: -0.05200
[32m[0906 19-20-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01859, current rewards: -144.11787, mean: -0.07748
[32m[0906 19-20-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: -194.11787, mean: -0.10163
[32m[0906 19-20-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01859, current rewards: -244.11787, mean: -0.12455
[32m[0906 19-20-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01860, current rewards: -294.11787, mean: -0.14633
[32m[0906 19-20-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01858, current rewards: -344.11787, mean: -0.16705
[32m[0906 19-20-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: -394.11787, mean: -0.18679
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01862, current rewards: -444.11787, mean: -0.20561
[32m[0906 19-20-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01864, current rewards: -494.11787, mean: -0.22358
[32m[0906 19-20-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01865, current rewards: -544.11787, mean: -0.24076
[32m[0906 19-20-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01867, current rewards: -594.11787, mean: -0.25719
[32m[0906 19-20-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01868, current rewards: -644.11787, mean: -0.27293
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01869, current rewards: -694.11787, mean: -0.28802
[32m[0906 19-20-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01871, current rewards: -744.11787, mean: -0.30249
[32m[0906 19-20-13 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-20-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-20-13 @MBExp.py:227][0m Rewards obtained: [-784.1178657518623], Lows: [2], Highs: [958], Total time: 5663.785551
[32m[0906 19-24-23 @MBExp.py:144][0m ####################################################################
[32m[0906 19-24-23 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 19-24-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01932, current rewards: 1.06401, mean: 0.10640
[32m[0906 19-24-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01856, current rewards: 6.54672, mean: 0.10911
[32m[0906 19-24-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01852, current rewards: 12.11275, mean: 0.11012
[32m[0906 19-24-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01855, current rewards: 17.67110, mean: 0.11044
[32m[0906 19-24-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 23.23687, mean: 0.11065
[32m[0906 19-24-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 28.82232, mean: 0.11086
[32m[0906 19-24-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01852, current rewards: 34.38607, mean: 0.11092
[32m[0906 19-24-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01852, current rewards: 39.95438, mean: 0.11098
[32m[0906 19-24-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 45.51173, mean: 0.11100
[32m[0906 19-24-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.13729, mean: 0.11117
[32m[0906 19-24-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.71039, mean: 0.11120
[32m[0906 19-24-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 62.28742, mean: 0.11123
[32m[0906 19-24-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 67.86367, mean: 0.11125
[32m[0906 19-24-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 73.51323, mean: 0.11138
[32m[0906 19-24-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 79.10185, mean: 0.11141
[32m[0906 19-24-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 84.68328, mean: 0.11143
[32m[0906 19-24-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 90.26711, mean: 0.11144
[32m[0906 19-24-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 95.84711, mean: 0.11145
[32m[0906 19-24-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01856, current rewards: 101.43046, mean: 0.11146
[32m[0906 19-24-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01856, current rewards: 107.01270, mean: 0.11147
[32m[0906 19-24-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 112.59542, mean: 0.11148
[32m[0906 19-24-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 116.10234, mean: 0.10953
[32m[0906 19-24-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 121.66619, mean: 0.10961
[32m[0906 19-24-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 127.25039, mean: 0.10970
[32m[0906 19-24-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01857, current rewards: 132.83830, mean: 0.10978
[32m[0906 19-24-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01858, current rewards: 138.42222, mean: 0.10986
[32m[0906 19-24-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: 144.00743, mean: 0.10993
[32m[0906 19-24-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01858, current rewards: 149.59160, mean: 0.10999
[32m[0906 19-24-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 155.12594, mean: 0.11002
[32m[0906 19-24-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 160.70135, mean: 0.11007
[32m[0906 19-24-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 166.19463, mean: 0.11006
[32m[0906 19-24-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 171.76001, mean: 0.11010
[32m[0906 19-24-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 177.32002, mean: 0.11014
[32m[0906 19-24-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01859, current rewards: 182.88370, mean: 0.11017
[32m[0906 19-24-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01859, current rewards: 188.45098, mean: 0.11021
[32m[0906 19-24-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01859, current rewards: 194.01743, mean: 0.11024
[32m[0906 19-24-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01859, current rewards: 199.58495, mean: 0.11027
[32m[0906 19-24-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01859, current rewards: 205.14427, mean: 0.11029
[32m[0906 19-24-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01859, current rewards: 210.88015, mean: 0.11041
[32m[0906 19-24-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01859, current rewards: 216.49897, mean: 0.11046
[32m[0906 19-25-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01858, current rewards: 222.11540, mean: 0.11051
[32m[0906 19-25-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01858, current rewards: 227.73126, mean: 0.11055
[32m[0906 19-25-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01860, current rewards: 233.37420, mean: 0.11060
[32m[0906 19-25-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01861, current rewards: 238.93618, mean: 0.11062
[32m[0906 19-25-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01862, current rewards: 244.49866, mean: 0.11063
[32m[0906 19-25-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01863, current rewards: 250.05494, mean: 0.11064
[32m[0906 19-25-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01864, current rewards: 255.62121, mean: 0.11066
[32m[0906 19-25-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: 261.20430, mean: 0.11068
[32m[0906 19-25-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01867, current rewards: 266.76496, mean: 0.11069
[32m[0906 19-25-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01868, current rewards: 272.32406, mean: 0.11070
[32m[0906 19-25-10 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 19-25-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-25-10 @MBExp.py:227][0m Rewards obtained: [276.77309014909525], Lows: [1], Highs: [0], Total time: 5711.372697
[32m[0906 19-29-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-29-22 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 19-29-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01764, current rewards: 0.07830, mean: 0.00783
[32m[0906 19-29-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01824, current rewards: 5.62103, mean: 0.09368
[32m[0906 19-29-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01840, current rewards: 11.16650, mean: 0.10151
[32m[0906 19-29-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 16.71556, mean: 0.10447
[32m[0906 19-29-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 22.26175, mean: 0.10601
[32m[0906 19-29-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01853, current rewards: 27.77789, mean: 0.10684
[32m[0906 19-29-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 33.34605, mean: 0.10757
[32m[0906 19-29-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01854, current rewards: 38.91376, mean: 0.10809
[32m[0906 19-29-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01856, current rewards: 44.48100, mean: 0.10849
[32m[0906 19-29-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 50.04539, mean: 0.10879
[32m[0906 19-29-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01856, current rewards: 55.61055, mean: 0.10904
[32m[0906 19-29-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 61.17058, mean: 0.10923
[32m[0906 19-29-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 66.73722, mean: 0.10941
[32m[0906 19-29-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01858, current rewards: 72.31470, mean: 0.10957
[32m[0906 19-29-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 77.99114, mean: 0.10985
[32m[0906 19-29-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01860, current rewards: 83.50308, mean: 0.10987
[32m[0906 19-29-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01861, current rewards: 89.02260, mean: 0.10990
[32m[0906 19-29-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01861, current rewards: 94.53729, mean: 0.10993
[32m[0906 19-29-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01862, current rewards: 100.05118, mean: 0.10995
[32m[0906 19-29-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01861, current rewards: 105.56402, mean: 0.10996
[32m[0906 19-29-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01862, current rewards: 111.07425, mean: 0.10997
[32m[0906 19-29-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01863, current rewards: 116.59798, mean: 0.11000
[32m[0906 19-29-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 122.11323, mean: 0.11001
[32m[0906 19-29-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01863, current rewards: 127.63307, mean: 0.11003
[32m[0906 19-29-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01863, current rewards: 133.15388, mean: 0.11004
[32m[0906 19-29-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 138.66687, mean: 0.11005
[32m[0906 19-29-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01864, current rewards: 144.18625, mean: 0.11007
[32m[0906 19-29-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01864, current rewards: 149.70406, mean: 0.11008
[32m[0906 19-29-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01864, current rewards: 155.20778, mean: 0.11008
[32m[0906 19-29-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 160.85158, mean: 0.11017
[32m[0906 19-29-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01864, current rewards: 166.42152, mean: 0.11021
[32m[0906 19-29-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01865, current rewards: 172.00291, mean: 0.11026
[32m[0906 19-29-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01866, current rewards: 177.57719, mean: 0.11030
[32m[0906 19-29-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01865, current rewards: 183.13265, mean: 0.11032
[32m[0906 19-29-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01866, current rewards: 188.69133, mean: 0.11035
[32m[0906 19-29-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01866, current rewards: 194.24418, mean: 0.11037
[32m[0906 19-29-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01865, current rewards: 199.80046, mean: 0.11039
[32m[0906 19-29-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01865, current rewards: 205.37284, mean: 0.11042
[32m[0906 19-29-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01865, current rewards: 210.93336, mean: 0.11044
[32m[0906 19-30-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01865, current rewards: 216.48214, mean: 0.11045
[32m[0906 19-30-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01865, current rewards: 222.02665, mean: 0.11046
[32m[0906 19-30-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01865, current rewards: 227.57601, mean: 0.11047
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01867, current rewards: 233.10953, mean: 0.11048
[32m[0906 19-30-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01868, current rewards: 238.66092, mean: 0.11049
[32m[0906 19-30-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01869, current rewards: 244.20639, mean: 0.11050
[32m[0906 19-30-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01871, current rewards: 249.75231, mean: 0.11051
[32m[0906 19-30-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01872, current rewards: 255.25920, mean: 0.11050
[32m[0906 19-30-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01873, current rewards: 260.80762, mean: 0.11051
[32m[0906 19-30-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01874, current rewards: 266.36070, mean: 0.11052
[32m[0906 19-30-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01876, current rewards: 271.91744, mean: 0.11054
[32m[0906 19-30-10 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 19-30-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-30-10 @MBExp.py:227][0m Rewards obtained: [276.36294477326186], Lows: [0], Highs: [1], Total time: 5759.158856
[32m[0906 19-34-24 @MBExp.py:144][0m ####################################################################
[32m[0906 19-34-24 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 19-34-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01887, current rewards: 1.04650, mean: 0.10465
[32m[0906 19-34-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01922, current rewards: 6.58107, mean: 0.10968
[32m[0906 19-34-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01898, current rewards: 12.11615, mean: 0.11015
[32m[0906 19-34-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01832, current rewards: 17.65413, mean: 0.11034
[32m[0906 19-34-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01799, current rewards: 23.14006, mean: 0.11019
[32m[0906 19-34-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01771, current rewards: 28.67806, mean: 0.11030
[32m[0906 19-34-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01757, current rewards: 34.22004, mean: 0.11039
[32m[0906 19-34-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01743, current rewards: 39.75089, mean: 0.11042
[32m[0906 19-34-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01729, current rewards: 45.30819, mean: 0.11051
[32m[0906 19-34-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01722, current rewards: 50.86044, mean: 0.11057
[32m[0906 19-34-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01716, current rewards: 56.41823, mean: 0.11062
[32m[0906 19-34-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01711, current rewards: 61.97807, mean: 0.11068
[32m[0906 19-34-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01706, current rewards: 67.42667, mean: 0.11054
[32m[0906 19-34-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01704, current rewards: 72.96985, mean: 0.11056
[32m[0906 19-34-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01700, current rewards: 78.51806, mean: 0.11059
[32m[0906 19-34-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01698, current rewards: 84.07221, mean: 0.11062
[32m[0906 19-34-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01695, current rewards: 89.62147, mean: 0.11064
[32m[0906 19-34-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01693, current rewards: 95.16644, mean: 0.11066
[32m[0906 19-34-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01691, current rewards: 100.71635, mean: 0.11068
[32m[0906 19-34-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01689, current rewards: 106.26221, mean: 0.11069
[32m[0906 19-34-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01688, current rewards: 111.81468, mean: 0.11071
[32m[0906 19-34-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01687, current rewards: 117.40452, mean: 0.11076
[32m[0906 19-34-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01686, current rewards: 123.00796, mean: 0.11082
[32m[0906 19-34-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01684, current rewards: 128.62029, mean: 0.11088
[32m[0906 19-34-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01683, current rewards: 134.22409, mean: 0.11093
[32m[0906 19-34-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01681, current rewards: 139.82749, mean: 0.11097
[32m[0906 19-34-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01681, current rewards: 145.43352, mean: 0.11102
[32m[0906 19-34-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01680, current rewards: 151.03867, mean: 0.11106
[32m[0906 19-34-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01679, current rewards: 156.66108, mean: 0.11111
[32m[0906 19-34-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01678, current rewards: 162.61490, mean: 0.11138
[32m[0906 19-34-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01678, current rewards: 168.53278, mean: 0.11161
[32m[0906 19-34-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01677, current rewards: 174.45065, mean: 0.11183
[32m[0906 19-34-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01676, current rewards: 135.63423, mean: 0.08424
[32m[0906 19-34-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01676, current rewards: 85.63423, mean: 0.05159
[32m[0906 19-34-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01675, current rewards: 35.63423, mean: 0.02084
[32m[0906 19-34-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01675, current rewards: -14.36577, mean: -0.00816
[32m[0906 19-34-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01675, current rewards: -64.36577, mean: -0.03556
[32m[0906 19-34-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01674, current rewards: -114.36577, mean: -0.06149
[32m[0906 19-34-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01674, current rewards: -164.36577, mean: -0.08606
[32m[0906 19-34-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01673, current rewards: -214.36577, mean: -0.10937
[32m[0906 19-34-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01673, current rewards: -264.36577, mean: -0.13153
[32m[0906 19-34-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01673, current rewards: -314.36577, mean: -0.15260
[32m[0906 19-34-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01673, current rewards: -364.36577, mean: -0.17269
[32m[0906 19-35-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01675, current rewards: -414.36577, mean: -0.19184
[32m[0906 19-35-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01676, current rewards: -464.36577, mean: -0.21012
[32m[0906 19-35-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01677, current rewards: -514.36577, mean: -0.22760
[32m[0906 19-35-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01678, current rewards: -564.36577, mean: -0.24431
[32m[0906 19-35-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01679, current rewards: -614.36577, mean: -0.26032
[32m[0906 19-35-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01680, current rewards: -664.36577, mean: -0.27567
[32m[0906 19-35-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01681, current rewards: -714.36577, mean: -0.29039
[32m[0906 19-35-06 @Agent.py:117][0m Average action selection time: 0.0168
[32m[0906 19-35-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-35-06 @MBExp.py:227][0m Rewards obtained: [-754.3657694855407], Lows: [0], Highs: [930], Total time: 5802.00184
