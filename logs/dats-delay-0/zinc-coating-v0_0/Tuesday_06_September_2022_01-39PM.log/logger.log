[32m[0906 13-39-24 @logger.py:99][0m Log file set to /app/logs/dats-delay-0/zinc-coating-v0_0/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-24 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: -13.90097, mean: -1.39010
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -67.21182, mean: -1.12020
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -116.45429, mean: -1.05868
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -172.55958, mean: -1.07850
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -229.01358, mean: -1.09054
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -283.62970, mean: -1.09088
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -353.75935, mean: -1.14116
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -417.01816, mean: -1.15838
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -482.11011, mean: -1.17588
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -553.11996, mean: -1.20243
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -630.03554, mean: -1.23536
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -700.48847, mean: -1.25087
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -770.32290, mean: -1.26282
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -823.12776, mean: -1.24716
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -874.15137, mean: -1.23120
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -931.55527, mean: -1.22573
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -984.61141, mean: -1.21557
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -1038.38588, mean: -1.20743
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1089.55372, mean: -1.19731
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1150.11527, mean: -1.19804
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1198.78954, mean: -1.18692
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1256.24902, mean: -1.18514
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1309.48828, mean: -1.17972
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1359.10152, mean: -1.17164
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1414.11293, mean: -1.16869
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1459.81866, mean: -1.15859
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1510.72617, mean: -1.15323
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1564.90148, mean: -1.15066
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1620.13385, mean: -1.14903
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1673.40343, mean: -1.14617
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1716.15947, mean: -1.13653
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1763.20839, mean: -1.13026
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -1818.22683, mean: -1.12933
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -1877.35231, mean: -1.13094
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -1939.41401, mean: -1.13416
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2003.24722, mean: -1.13821
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2077.10276, mean: -1.14757
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2144.70364, mean: -1.15307
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2200.67032, mean: -1.15218
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2269.00399, mean: -1.15766
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2337.07209, mean: -1.16272
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2408.62576, mean: -1.16924
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2479.93921, mean: -1.17533
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2554.25504, mean: -1.18253
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2612.00471, mean: -1.18190
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2663.23874, mean: -1.17842
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2711.29676, mean: -1.17372
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2750.76259, mean: -1.16558
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2792.44140, mean: -1.15869
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -2836.74733, mean: -1.15315
[32m[0906 13-39-24 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-39-26 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-26 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02144, current rewards: -1.09756, mean: -0.10976
[32m[0906 13-39-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01343, current rewards: 3.42304, mean: 0.05705
[32m[0906 13-39-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01262, current rewards: 7.87006, mean: 0.07155
[32m[0906 13-39-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01231, current rewards: 12.31792, mean: 0.07699
[32m[0906 13-39-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01218, current rewards: 16.76312, mean: 0.07982
[32m[0906 13-39-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01210, current rewards: 21.21229, mean: 0.08159
[32m[0906 13-39-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01204, current rewards: 25.65761, mean: 0.08277
[32m[0906 13-39-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01200, current rewards: 30.10797, mean: 0.08363
[32m[0906 13-39-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01197, current rewards: 34.60953, mean: 0.08441
[32m[0906 13-39-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01195, current rewards: 43.94744, mean: 0.09554
[32m[0906 13-39-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01193, current rewards: 56.13236, mean: 0.11006
[32m[0906 13-39-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01192, current rewards: 68.31572, mean: 0.12199
[32m[0906 13-39-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01190, current rewards: 80.49907, mean: 0.13197
[32m[0906 13-39-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01189, current rewards: 92.69366, mean: 0.14044
[32m[0906 13-39-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01187, current rewards: 105.24288, mean: 0.14823
[32m[0906 13-39-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01185, current rewards: 119.69191, mean: 0.15749
[32m[0906 13-39-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01184, current rewards: 134.14074, mean: 0.16561
[32m[0906 13-39-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01184, current rewards: 145.19211, mean: 0.16883
[32m[0906 13-39-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01183, current rewards: 151.26140, mean: 0.16622
[32m[0906 13-39-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01182, current rewards: 157.34330, mean: 0.16390
[32m[0906 13-39-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01182, current rewards: 163.42175, mean: 0.16180
[32m[0906 13-39-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01181, current rewards: 169.50211, mean: 0.15991
[32m[0906 13-39-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01181, current rewards: 175.58966, mean: 0.15819
[32m[0906 13-39-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01180, current rewards: 181.67109, mean: 0.15661
[32m[0906 13-39-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01180, current rewards: 187.74672, mean: 0.15516
[32m[0906 13-39-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01180, current rewards: 193.82942, mean: 0.15383
[32m[0906 13-39-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01180, current rewards: 201.81048, mean: 0.15405
[32m[0906 13-39-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01180, current rewards: 209.37889, mean: 0.15396
[32m[0906 13-39-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01180, current rewards: 214.17585, mean: 0.15190
[32m[0906 13-39-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01179, current rewards: 218.97448, mean: 0.14998
[32m[0906 13-39-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01178, current rewards: 223.77176, mean: 0.14819
[32m[0906 13-39-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01178, current rewards: 228.56866, mean: 0.14652
[32m[0906 13-39-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01178, current rewards: 233.36391, mean: 0.14495
[32m[0906 13-39-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01177, current rewards: 238.15992, mean: 0.14347
[32m[0906 13-39-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01177, current rewards: 243.10265, mean: 0.14217
[32m[0906 13-39-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01177, current rewards: 248.08193, mean: 0.14096
[32m[0906 13-39-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01177, current rewards: 253.06143, mean: 0.13981
[32m[0906 13-39-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01176, current rewards: 258.04252, mean: 0.13873
[32m[0906 13-39-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01176, current rewards: 262.13345, mean: 0.13724
[32m[0906 13-39-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01176, current rewards: 269.92104, mean: 0.13771
[32m[0906 13-39-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01176, current rewards: 277.69505, mean: 0.13816
[32m[0906 13-39-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01176, current rewards: 285.47804, mean: 0.13858
[32m[0906 13-39-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01176, current rewards: 291.55985, mean: 0.13818
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01177, current rewards: 294.52459, mean: 0.13635
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01180, current rewards: 299.65837, mean: 0.13559
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01180, current rewards: 304.79078, mean: 0.13486
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01180, current rewards: 309.92650, mean: 0.13417
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01180, current rewards: 315.06361, mean: 0.13350
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01180, current rewards: 320.20134, mean: 0.13286
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01180, current rewards: 325.33569, mean: 0.13225
[32m[0906 13-39-56 @Agent.py:117][0m Average action selection time: 0.0118
[32m[0906 13-39-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-39-56 @MBExp.py:227][0m Rewards obtained: [329.633209537218], Lows: [2], Highs: [3], Total time: 30.011189
[32m[0906 13-39-59 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-59 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-39-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01444, current rewards: 0.05883, mean: 0.00588
[32m[0906 13-40-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01423, current rewards: 6.26941, mean: 0.10449
[32m[0906 13-40-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01421, current rewards: 12.60636, mean: 0.11460
[32m[0906 13-40-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01416, current rewards: 18.93644, mean: 0.11835
[32m[0906 13-40-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01414, current rewards: 25.27628, mean: 0.12036
[32m[0906 13-40-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01411, current rewards: 29.82281, mean: 0.11470
[32m[0906 13-40-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01413, current rewards: 36.52570, mean: 0.11782
[32m[0906 13-40-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01413, current rewards: 43.22236, mean: 0.12006
[32m[0906 13-40-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01412, current rewards: 49.92632, mean: 0.12177
[32m[0906 13-40-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01412, current rewards: 55.89763, mean: 0.12152
[32m[0906 13-40-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01412, current rewards: 61.04865, mean: 0.11970
[32m[0906 13-40-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01413, current rewards: 66.20073, mean: 0.11822
[32m[0906 13-40-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01424, current rewards: 71.34802, mean: 0.11696
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01424, current rewards: 76.50173, mean: 0.11591
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01423, current rewards: 81.65375, mean: 0.11501
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01422, current rewards: 86.80818, mean: 0.11422
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01423, current rewards: 91.95671, mean: 0.11353
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01422, current rewards: 95.89619, mean: 0.11151
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01423, current rewards: 101.36468, mean: 0.11139
[32m[0906 13-40-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01426, current rewards: 106.85488, mean: 0.11131
[32m[0906 13-40-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01432, current rewards: 112.34510, mean: 0.11123
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01438, current rewards: 117.83559, mean: 0.11117
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01445, current rewards: 123.32723, mean: 0.11111
[32m[0906 13-40-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01453, current rewards: 126.60496, mean: 0.10914
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01459, current rewards: 131.88667, mean: 0.10900
[32m[0906 13-40-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01465, current rewards: 137.17317, mean: 0.10887
[32m[0906 13-40-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01471, current rewards: 141.99048, mean: 0.10839
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01475, current rewards: 146.58115, mean: 0.10778
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01481, current rewards: 151.77724, mean: 0.10764
[32m[0906 13-40-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01485, current rewards: 157.30992, mean: 0.10775
[32m[0906 13-40-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01490, current rewards: 162.84246, mean: 0.10784
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01494, current rewards: 168.37926, mean: 0.10794
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01498, current rewards: 173.91647, mean: 0.10802
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01501, current rewards: 179.45007, mean: 0.10810
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01505, current rewards: 185.17467, mean: 0.10829
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01508, current rewards: 191.10785, mean: 0.10858
[32m[0906 13-40-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01511, current rewards: 197.04098, mean: 0.10886
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01514, current rewards: 200.80144, mean: 0.10796
[32m[0906 13-40-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01516, current rewards: 206.64557, mean: 0.10819
[32m[0906 13-40-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01521, current rewards: 212.49404, mean: 0.10842
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01524, current rewards: 218.33859, mean: 0.10863
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01527, current rewards: 224.18612, mean: 0.10883
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01530, current rewards: 228.92479, mean: 0.10850
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01532, current rewards: 234.63491, mean: 0.10863
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01535, current rewards: 240.34684, mean: 0.10875
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01537, current rewards: 246.06514, mean: 0.10888
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01540, current rewards: 251.78244, mean: 0.10900
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01545, current rewards: 257.50172, mean: 0.10911
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01550, current rewards: 263.21299, mean: 0.10922
[32m[0906 13-40-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01555, current rewards: 268.92469, mean: 0.10932
[32m[0906 13-40-39 @Agent.py:117][0m Average action selection time: 0.0156
[32m[0906 13-40-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-40-39 @MBExp.py:227][0m Rewards obtained: [273.4956714553955], Lows: [3], Highs: [3], Total time: 69.558244
[32m[0906 13-40-45 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-45 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-40-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01841, current rewards: 1.08028, mean: 0.10803
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01834, current rewards: 6.87033, mean: 0.11451
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01828, current rewards: 12.68302, mean: 0.11530
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01825, current rewards: 18.49762, mean: 0.11561
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01822, current rewards: 24.30559, mean: 0.11574
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01827, current rewards: 30.12197, mean: 0.11585
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01826, current rewards: 35.93201, mean: 0.11591
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01826, current rewards: 41.74654, mean: 0.11596
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01825, current rewards: 47.56038, mean: 0.11600
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01826, current rewards: 52.58988, mean: 0.11433
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01826, current rewards: 59.20726, mean: 0.11609
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01825, current rewards: 65.82248, mean: 0.11754
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01825, current rewards: 72.42137, mean: 0.11872
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01825, current rewards: 79.01662, mean: 0.11972
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01825, current rewards: 83.14179, mean: 0.11710
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01824, current rewards: 89.34352, mean: 0.11756
[32m[0906 13-41-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01822, current rewards: 95.54803, mean: 0.11796
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01820, current rewards: 101.74969, mean: 0.11831
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01817, current rewards: 106.86905, mean: 0.11744
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01815, current rewards: 113.25390, mean: 0.11797
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01815, current rewards: 119.64785, mean: 0.11846
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01815, current rewards: 126.03916, mean: 0.11890
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01816, current rewards: 132.42770, mean: 0.11930
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01817, current rewards: 138.81423, mean: 0.11967
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01818, current rewards: 146.11977, mean: 0.12076
[32m[0906 13-41-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01818, current rewards: 153.03205, mean: 0.12145
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01818, current rewards: 159.81112, mean: 0.12199
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01818, current rewards: 166.61098, mean: 0.12251
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01819, current rewards: 173.40927, mean: 0.12299
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01820, current rewards: 180.21243, mean: 0.12343
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01820, current rewards: 187.02238, mean: 0.12386
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01821, current rewards: 193.82748, mean: 0.12425
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01822, current rewards: 201.22484, mean: 0.12498
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01822, current rewards: 207.84536, mean: 0.12521
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01822, current rewards: 213.70162, mean: 0.12497
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01822, current rewards: 219.43389, mean: 0.12468
[32m[0906 13-41-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01822, current rewards: 225.17067, mean: 0.12440
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01822, current rewards: 230.89919, mean: 0.12414
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01823, current rewards: 236.62544, mean: 0.12389
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01825, current rewards: 242.35792, mean: 0.12365
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01825, current rewards: 248.08947, mean: 0.12343
[32m[0906 13-41-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01826, current rewards: 253.82598, mean: 0.12322
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01826, current rewards: 259.78629, mean: 0.12312
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01825, current rewards: 264.88100, mean: 0.12263
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01825, current rewards: 271.11584, mean: 0.12268
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01826, current rewards: 277.35060, mean: 0.12272
[32m[0906 13-41-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01829, current rewards: 283.57411, mean: 0.12276
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01833, current rewards: 289.81932, mean: 0.12280
[32m[0906 13-41-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01836, current rewards: 295.90431, mean: 0.12278
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01839, current rewards: 301.88829, mean: 0.12272
[32m[0906 13-41-32 @Agent.py:117][0m Average action selection time: 0.0184
[32m[0906 13-41-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-41-32 @MBExp.py:227][0m Rewards obtained: [306.6562887363171], Lows: [1], Highs: [3], Total time: 116.241697
[32m[0906 13-41-41 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-41 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02035, current rewards: -2.24393, mean: -0.22439
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02024, current rewards: 2.93003, mean: 0.04883
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02023, current rewards: 8.06861, mean: 0.07335
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02029, current rewards: 13.20670, mean: 0.08254
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02036, current rewards: 18.34152, mean: 0.08734
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02036, current rewards: 23.48294, mean: 0.09032
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02035, current rewards: 28.61976, mean: 0.09232
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02035, current rewards: 33.76062, mean: 0.09378
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02033, current rewards: 39.04402, mean: 0.09523
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02034, current rewards: 44.21246, mean: 0.09611
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02032, current rewards: 49.39505, mean: 0.09685
[32m[0906 13-41-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02029, current rewards: 54.56825, mean: 0.09744
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02026, current rewards: 59.74669, mean: 0.09795
[32m[0906 13-41-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02023, current rewards: 64.92759, mean: 0.09838
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02023, current rewards: 70.10730, mean: 0.09874
[32m[0906 13-41-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02020, current rewards: 74.20092, mean: 0.09763
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02018, current rewards: 79.43870, mean: 0.09807
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02017, current rewards: 84.48393, mean: 0.09824
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02018, current rewards: 89.54204, mean: 0.09840
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02017, current rewards: 94.59903, mean: 0.09854
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02018, current rewards: 99.65892, mean: 0.09867
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02019, current rewards: 104.72029, mean: 0.09879
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02020, current rewards: 109.78293, mean: 0.09890
[32m[0906 13-42-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02021, current rewards: 114.84547, mean: 0.09900
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02021, current rewards: 119.90589, mean: 0.09910
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02021, current rewards: 125.01090, mean: 0.09922
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02021, current rewards: 130.13351, mean: 0.09934
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02021, current rewards: 135.25029, mean: 0.09945
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02022, current rewards: 140.36288, mean: 0.09955
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02021, current rewards: 145.48137, mean: 0.09964
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02022, current rewards: 150.59870, mean: 0.09973
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02023, current rewards: 153.65649, mean: 0.09850
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02024, current rewards: 158.89305, mean: 0.09869
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02024, current rewards: 164.24512, mean: 0.09894
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02024, current rewards: 169.71041, mean: 0.09925
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02025, current rewards: 175.12612, mean: 0.09950
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02026, current rewards: 180.54098, mean: 0.09975
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02026, current rewards: 184.76096, mean: 0.09933
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02025, current rewards: 189.96531, mean: 0.09946
[32m[0906 13-42-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02024, current rewards: 195.16859, mean: 0.09958
[32m[0906 13-42-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02023, current rewards: 200.37154, mean: 0.09969
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02022, current rewards: 205.56958, mean: 0.09979
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02021, current rewards: 208.50924, mean: 0.09882
[32m[0906 13-42-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02020, current rewards: 213.64531, mean: 0.09891
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02020, current rewards: 218.77576, mean: 0.09899
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02020, current rewards: 223.91473, mean: 0.09908
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02020, current rewards: 229.05009, mean: 0.09916
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02020, current rewards: 234.18429, mean: 0.09923
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02020, current rewards: 239.32049, mean: 0.09930
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02019, current rewards: 244.45331, mean: 0.09937
[32m[0906 13-42-32 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-42-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-42-32 @MBExp.py:227][0m Rewards obtained: [248.56261505448722], Lows: [2], Highs: [5], Total time: 167.402261
[32m[0906 13-42-43 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-43 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02084, current rewards: -2.24393, mean: -0.22439
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02058, current rewards: 3.06949, mean: 0.05116
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02049, current rewards: 8.35649, mean: 0.07597
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02044, current rewards: 13.63683, mean: 0.08523
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02039, current rewards: 18.91676, mean: 0.09008
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02034, current rewards: 24.20401, mean: 0.09309
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02033, current rewards: 29.64330, mean: 0.09562
[32m[0906 13-42-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02028, current rewards: 34.79959, mean: 0.09667
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02026, current rewards: 39.95917, mean: 0.09746
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02023, current rewards: 45.13249, mean: 0.09811
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02022, current rewards: 50.41426, mean: 0.09885
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02022, current rewards: 55.69662, mean: 0.09946
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02022, current rewards: 60.98633, mean: 0.09998
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02021, current rewards: 66.27090, mean: 0.10041
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02019, current rewards: 71.55302, mean: 0.10078
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02018, current rewards: 76.83604, mean: 0.10110
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02020, current rewards: 82.12167, mean: 0.10138
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02020, current rewards: 87.38497, mean: 0.10161
[32m[0906 13-43-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02023, current rewards: 92.69132, mean: 0.10186
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02024, current rewards: 97.99042, mean: 0.10207
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02024, current rewards: 103.31452, mean: 0.10229
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02025, current rewards: 108.92213, mean: 0.10276
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02026, current rewards: 114.52706, mean: 0.10318
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02026, current rewards: 120.13338, mean: 0.10356
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02027, current rewards: 125.74325, mean: 0.10392
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02027, current rewards: 131.47559, mean: 0.10435
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02028, current rewards: 137.14338, mean: 0.10469
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02028, current rewards: 142.76760, mean: 0.10498
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02028, current rewards: 148.39234, mean: 0.10524
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02029, current rewards: 153.87628, mean: 0.10539
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02029, current rewards: 159.26328, mean: 0.10547
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02029, current rewards: 164.64989, mean: 0.10554
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02029, current rewards: 170.03442, mean: 0.10561
[32m[0906 13-43-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02028, current rewards: 175.42064, mean: 0.10568
[32m[0906 13-43-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02026, current rewards: 178.42929, mean: 0.10434
[32m[0906 13-43-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02024, current rewards: 183.71588, mean: 0.10438
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02023, current rewards: 189.00540, mean: 0.10442
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02022, current rewards: 194.29847, mean: 0.10446
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02020, current rewards: 199.58946, mean: 0.10450
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02019, current rewards: 204.87818, mean: 0.10453
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02018, current rewards: 210.17019, mean: 0.10456
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02019, current rewards: 215.45485, mean: 0.10459
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02018, current rewards: 220.76129, mean: 0.10463
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02018, current rewards: 226.02763, mean: 0.10464
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02018, current rewards: 231.29669, mean: 0.10466
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02018, current rewards: 235.46965, mean: 0.10419
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02018, current rewards: 240.98195, mean: 0.10432
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02018, current rewards: 246.48660, mean: 0.10444
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02018, current rewards: 251.99424, mean: 0.10456
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02018, current rewards: 257.49648, mean: 0.10467
[32m[0906 13-43-34 @Agent.py:117][0m Average action selection time: 0.0202
[32m[0906 13-43-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-43-34 @MBExp.py:227][0m Rewards obtained: [261.90336405178607], Lows: [1], Highs: [4], Total time: 218.507887
[32m[0906 13-43-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-48 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02075, current rewards: -2.21975, mean: -0.22198
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02037, current rewards: 3.48565, mean: 0.05809
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02020, current rewards: 9.10236, mean: 0.08275
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02020, current rewards: 14.70635, mean: 0.09191
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02013, current rewards: 20.32648, mean: 0.09679
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02006, current rewards: 25.94126, mean: 0.09977
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02006, current rewards: 31.55795, mean: 0.10180
[32m[0906 13-43-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02007, current rewards: 37.17000, mean: 0.10325
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02003, current rewards: 42.78162, mean: 0.10435
[32m[0906 13-43-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02005, current rewards: 48.56727, mean: 0.10558
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02003, current rewards: 54.27644, mean: 0.10642
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02003, current rewards: 59.99122, mean: 0.10713
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02004, current rewards: 65.69579, mean: 0.10770
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02006, current rewards: 71.40697, mean: 0.10819
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02008, current rewards: 77.11608, mean: 0.10861
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02012, current rewards: 82.82512, mean: 0.10898
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02012, current rewards: 88.53826, mean: 0.10931
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02013, current rewards: 94.25316, mean: 0.10960
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02013, current rewards: 100.16882, mean: 0.11008
[32m[0906 13-44-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02014, current rewards: 105.85421, mean: 0.11026
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02015, current rewards: 111.53769, mean: 0.11043
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02017, current rewards: 117.21983, mean: 0.11058
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02018, current rewards: 122.90343, mean: 0.11072
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02020, current rewards: 128.59175, mean: 0.11085
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02021, current rewards: 134.27959, mean: 0.11097
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02021, current rewards: 139.83286, mean: 0.11098
[32m[0906 13-44-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02021, current rewards: 145.35426, mean: 0.11096
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02020, current rewards: 150.51546, mean: 0.11067
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02020, current rewards: 155.67045, mean: 0.11040
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02019, current rewards: 160.82787, mean: 0.11016
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02018, current rewards: 165.98601, mean: 0.10992
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02016, current rewards: 171.14090, mean: 0.10971
[32m[0906 13-44-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02014, current rewards: 176.29818, mean: 0.10950
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02012, current rewards: 181.45118, mean: 0.10931
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02011, current rewards: 186.60873, mean: 0.10913
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02009, current rewards: 191.95413, mean: 0.10906
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02009, current rewards: 197.57287, mean: 0.10916
[32m[0906 13-44-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02009, current rewards: 203.19452, mean: 0.10924
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02009, current rewards: 208.80884, mean: 0.10932
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02009, current rewards: 214.42462, mean: 0.10940
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02009, current rewards: 220.05189, mean: 0.10948
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02008, current rewards: 225.67521, mean: 0.10955
[32m[0906 13-44-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02009, current rewards: 231.38748, mean: 0.10966
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02009, current rewards: 237.01872, mean: 0.10973
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02009, current rewards: 242.65345, mean: 0.10980
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02009, current rewards: 248.29241, mean: 0.10986
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02008, current rewards: 253.92648, mean: 0.10992
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02008, current rewards: 259.56690, mean: 0.10999
[32m[0906 13-44-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02008, current rewards: 265.20460, mean: 0.11004
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02007, current rewards: 268.71031, mean: 0.10923
[32m[0906 13-44-39 @Agent.py:117][0m Average action selection time: 0.0201
[32m[0906 13-44-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-44-39 @MBExp.py:227][0m Rewards obtained: [273.14359072358417], Lows: [1], Highs: [3], Total time: 269.36127500000003
[32m[0906 13-44-55 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-55 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02015, current rewards: 0.01713, mean: 0.00171
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01989, current rewards: 5.54448, mean: 0.09241
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01981, current rewards: 11.04406, mean: 0.10040
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01986, current rewards: 16.53733, mean: 0.10336
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01993, current rewards: 22.03387, mean: 0.10492
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01991, current rewards: 27.53447, mean: 0.10590
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01988, current rewards: 33.02878, mean: 0.10654
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01989, current rewards: 38.52530, mean: 0.10701
[32m[0906 13-45-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01990, current rewards: 44.01635, mean: 0.10736
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01987, current rewards: 49.65484, mean: 0.10795
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01987, current rewards: 55.22680, mean: 0.10829
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01989, current rewards: 60.79207, mean: 0.10856
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01992, current rewards: 66.36391, mean: 0.10879
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01995, current rewards: 71.93046, mean: 0.10899
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01998, current rewards: 77.50018, mean: 0.10916
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01998, current rewards: 83.10497, mean: 0.10935
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02002, current rewards: 88.64604, mean: 0.10944
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02003, current rewards: 94.00851, mean: 0.10931
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02004, current rewards: 99.46152, mean: 0.10930
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02006, current rewards: 104.91540, mean: 0.10929
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02006, current rewards: 110.37213, mean: 0.10928
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02006, current rewards: 115.82268, mean: 0.10927
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02007, current rewards: 121.27831, mean: 0.10926
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02006, current rewards: 126.73227, mean: 0.10925
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02006, current rewards: 132.19019, mean: 0.10925
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02006, current rewards: 137.64975, mean: 0.10925
[32m[0906 13-45-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02004, current rewards: 143.29456, mean: 0.10939
[32m[0906 13-45-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02002, current rewards: 146.98329, mean: 0.10808
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02001, current rewards: 153.74733, mean: 0.10904
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02001, current rewards: 160.51136, mean: 0.10994
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01999, current rewards: 167.27540, mean: 0.11078
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01998, current rewards: 174.03944, mean: 0.11156
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01998, current rewards: 180.80348, mean: 0.11230
[32m[0906 13-45-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01999, current rewards: 187.56752, mean: 0.11299
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01998, current rewards: 193.67390, mean: 0.11326
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01999, current rewards: 172.40114, mean: 0.09796
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01999, current rewards: 122.40114, mean: 0.06762
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01999, current rewards: 72.40114, mean: 0.03893
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01999, current rewards: 22.40114, mean: 0.01173
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01999, current rewards: -27.59886, mean: -0.01408
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01999, current rewards: -77.59886, mean: -0.03861
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01998, current rewards: -127.59886, mean: -0.06194
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01999, current rewards: -177.59886, mean: -0.08417
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01999, current rewards: -227.59886, mean: -0.10537
[32m[0906 13-45-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01999, current rewards: -277.59886, mean: -0.12561
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01999, current rewards: -327.59886, mean: -0.14496
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01998, current rewards: -377.59886, mean: -0.16346
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01998, current rewards: -427.59886, mean: -0.18119
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01998, current rewards: -477.59886, mean: -0.19817
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01998, current rewards: -527.59886, mean: -0.21447
[32m[0906 13-45-45 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-45-45 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-45-45 @MBExp.py:227][0m Rewards obtained: [-567.5988604840678], Lows: [1], Highs: [765], Total time: 319.97935600000005
[32m[0906 13-46-03 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-03 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02003, current rewards: -0.11703, mean: -0.01170
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01996, current rewards: 5.12885, mean: 0.08548
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01996, current rewards: 10.37849, mean: 0.09435
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01992, current rewards: 15.62254, mean: 0.09764
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01996, current rewards: 20.86652, mean: 0.09936
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01998, current rewards: 26.11159, mean: 0.10043
[32m[0906 13-46-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02001, current rewards: 31.35877, mean: 0.10116
[32m[0906 13-46-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02002, current rewards: 36.60103, mean: 0.10167
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02003, current rewards: 41.86805, mean: 0.10212
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02005, current rewards: 47.69150, mean: 0.10368
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02007, current rewards: 53.37223, mean: 0.10465
[32m[0906 13-46-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02008, current rewards: 58.98186, mean: 0.10532
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02010, current rewards: 64.58832, mean: 0.10588
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02010, current rewards: 70.20056, mean: 0.10636
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02011, current rewards: 75.80934, mean: 0.10677
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02009, current rewards: 81.41858, mean: 0.10713
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02009, current rewards: 87.02950, mean: 0.10744
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02008, current rewards: 92.62122, mean: 0.10770
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02007, current rewards: 98.22878, mean: 0.10794
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02008, current rewards: 103.83406, mean: 0.10816
[32m[0906 13-46-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02006, current rewards: 109.44054, mean: 0.10836
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02005, current rewards: 112.95197, mean: 0.10656
[32m[0906 13-46-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02004, current rewards: 118.57402, mean: 0.10682
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02002, current rewards: 124.19666, mean: 0.10707
[32m[0906 13-46-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02001, current rewards: 129.82063, mean: 0.10729
[32m[0906 13-46-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02000, current rewards: 135.38178, mean: 0.10745
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01998, current rewards: 140.94022, mean: 0.10759
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01996, current rewards: 146.49792, mean: 0.10772
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01997, current rewards: 152.05195, mean: 0.10784
[32m[0906 13-46-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01998, current rewards: 157.60592, mean: 0.10795
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01998, current rewards: 163.15714, mean: 0.10805
[32m[0906 13-46-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01999, current rewards: 168.70883, mean: 0.10815
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01999, current rewards: 174.26416, mean: 0.10824
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01997, current rewards: 179.72571, mean: 0.10827
[32m[0906 13-46-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01998, current rewards: 185.32296, mean: 0.10838
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01998, current rewards: 190.91472, mean: 0.10847
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01997, current rewards: 196.50762, mean: 0.10857
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 202.09989, mean: 0.10866
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01998, current rewards: 207.72532, mean: 0.10876
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 213.32527, mean: 0.10884
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: 218.92248, mean: 0.10892
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01998, current rewards: 224.57060, mean: 0.10901
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01998, current rewards: 230.15637, mean: 0.10908
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01998, current rewards: 235.70701, mean: 0.10912
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01999, current rewards: 241.25198, mean: 0.10916
[32m[0906 13-46-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01999, current rewards: 246.79683, mean: 0.10920
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02000, current rewards: 252.34289, mean: 0.10924
[32m[0906 13-46-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02000, current rewards: 257.88867, mean: 0.10927
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02000, current rewards: 263.43399, mean: 0.10931
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01999, current rewards: 268.95903, mean: 0.10933
[32m[0906 13-46-54 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-46-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-46-54 @MBExp.py:227][0m Rewards obtained: [273.4106159200244], Lows: [1], Highs: [1], Total time: 370.6380280000001
[32m[0906 13-47-14 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-14 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02018, current rewards: 0.01386, mean: 0.00139
[32m[0906 13-47-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01989, current rewards: 5.68088, mean: 0.09468
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01990, current rewards: 11.34042, mean: 0.10309
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01985, current rewards: 17.00128, mean: 0.10626
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01992, current rewards: 22.66291, mean: 0.10792
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01994, current rewards: 28.32456, mean: 0.10894
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01998, current rewards: 34.01055, mean: 0.10971
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02000, current rewards: 39.70719, mean: 0.11030
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02001, current rewards: 45.25130, mean: 0.11037
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02003, current rewards: 50.85464, mean: 0.11055
[32m[0906 13-47-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02004, current rewards: 56.46377, mean: 0.11071
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02003, current rewards: 62.07175, mean: 0.11084
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02002, current rewards: 67.67407, mean: 0.11094
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02002, current rewards: 73.26576, mean: 0.11101
[32m[0906 13-47-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02001, current rewards: 78.85862, mean: 0.11107
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02000, current rewards: 84.45505, mean: 0.11113
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02000, current rewards: 90.06426, mean: 0.11119
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01999, current rewards: 95.65577, mean: 0.11123
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01997, current rewards: 101.22015, mean: 0.11123
[32m[0906 13-47-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01995, current rewards: 106.86908, mean: 0.11132
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01994, current rewards: 112.51593, mean: 0.11140
[32m[0906 13-47-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01993, current rewards: 118.16538, mean: 0.11148
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01992, current rewards: 123.81441, mean: 0.11154
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01992, current rewards: 129.46135, mean: 0.11160
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01992, current rewards: 135.12609, mean: 0.11167
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: 140.94458, mean: 0.11186
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 146.67068, mean: 0.11196
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01994, current rewards: 152.52472, mean: 0.11215
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01995, current rewards: 158.15231, mean: 0.11216
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01995, current rewards: 163.78275, mean: 0.11218
[32m[0906 13-47-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01995, current rewards: 169.40820, mean: 0.11219
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01994, current rewards: 175.03431, mean: 0.11220
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01995, current rewards: 180.66163, mean: 0.11221
[32m[0906 13-47-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01996, current rewards: 186.27685, mean: 0.11221
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01997, current rewards: 192.92324, mean: 0.11282
[32m[0906 13-47-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01996, current rewards: 199.53147, mean: 0.11337
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01996, current rewards: 206.13971, mean: 0.11389
[32m[0906 13-47-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 212.74794, mean: 0.11438
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01996, current rewards: 219.35617, mean: 0.11485
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01996, current rewards: 225.96440, mean: 0.11529
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01996, current rewards: 188.41822, mean: 0.09374
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01996, current rewards: 138.41822, mean: 0.06719
[32m[0906 13-47-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01996, current rewards: 88.41822, mean: 0.04190
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01997, current rewards: 38.41822, mean: 0.01779
[32m[0906 13-47-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01996, current rewards: -11.58178, mean: -0.00524
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01996, current rewards: -61.58178, mean: -0.02725
[32m[0906 13-48-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01997, current rewards: -111.58178, mean: -0.04830
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01997, current rewards: -161.58178, mean: -0.06847
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01997, current rewards: -211.58178, mean: -0.08779
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01997, current rewards: -261.58178, mean: -0.10633
[32m[0906 13-48-05 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-48-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-48-05 @MBExp.py:227][0m Rewards obtained: [-301.58178388325206], Lows: [0], Highs: [530], Total time: 421.23419100000007
[32m[0906 13-48-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-27 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01956, current rewards: 1.11254, mean: 0.11125
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01967, current rewards: 6.69836, mean: 0.11164
[32m[0906 13-48-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01959, current rewards: 12.28121, mean: 0.11165
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01963, current rewards: 17.86455, mean: 0.11165
[32m[0906 13-48-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01978, current rewards: 23.41660, mean: 0.11151
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01982, current rewards: 28.99703, mean: 0.11153
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01987, current rewards: 34.58185, mean: 0.11155
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01988, current rewards: 40.13689, mean: 0.11149
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01990, current rewards: 45.66979, mean: 0.11139
[32m[0906 13-48-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01989, current rewards: 51.26228, mean: 0.11144
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01990, current rewards: 56.85285, mean: 0.11148
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01993, current rewards: 62.44036, mean: 0.11150
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01994, current rewards: 68.03214, mean: 0.11153
[32m[0906 13-48-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01994, current rewards: 73.62650, mean: 0.11156
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01992, current rewards: 79.18613, mean: 0.11153
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01989, current rewards: 84.74592, mean: 0.11151
[32m[0906 13-48-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01988, current rewards: 90.34821, mean: 0.11154
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01987, current rewards: 95.91235, mean: 0.11153
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01986, current rewards: 101.47537, mean: 0.11151
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01987, current rewards: 107.03829, mean: 0.11150
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01989, current rewards: 112.60269, mean: 0.11149
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01990, current rewards: 118.11013, mean: 0.11142
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01991, current rewards: 123.68043, mean: 0.11142
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01992, current rewards: 129.25328, mean: 0.11143
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01993, current rewards: 134.75840, mean: 0.11137
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01994, current rewards: 140.33030, mean: 0.11137
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01994, current rewards: 145.89697, mean: 0.11137
[32m[0906 13-48-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01995, current rewards: 151.46756, mean: 0.11137
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01995, current rewards: 157.04576, mean: 0.11138
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01995, current rewards: 162.61621, mean: 0.11138
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01996, current rewards: 168.18616, mean: 0.11138
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01996, current rewards: 173.75620, mean: 0.11138
[32m[0906 13-49-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01996, current rewards: 179.36186, mean: 0.11140
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01995, current rewards: 185.04041, mean: 0.11147
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01995, current rewards: 189.21714, mean: 0.11065
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01995, current rewards: 197.29143, mean: 0.11210
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01995, current rewards: 205.36572, mean: 0.11346
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 213.44000, mean: 0.11475
[32m[0906 13-49-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01996, current rewards: 221.51429, mean: 0.11598
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01995, current rewards: 229.58858, mean: 0.11714
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01996, current rewards: 237.66287, mean: 0.11824
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01995, current rewards: 243.62093, mean: 0.11826
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01996, current rewards: 246.65836, mean: 0.11690
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01996, current rewards: 249.69579, mean: 0.11560
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01997, current rewards: 226.21450, mean: 0.10236
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01997, current rewards: 176.21450, mean: 0.07797
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01997, current rewards: 126.21450, mean: 0.05464
[32m[0906 13-49-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01997, current rewards: 76.21450, mean: 0.03229
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01997, current rewards: 26.21450, mean: 0.01088
[32m[0906 13-49-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01997, current rewards: -23.78550, mean: -0.00967
[32m[0906 13-49-18 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 13-49-18 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-49-18 @MBExp.py:227][0m Rewards obtained: [-63.785498510027], Lows: [1], Highs: [315], Total time: 471.84958700000004
[32m[0906 13-49-43 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-43 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02018, current rewards: 1.08491, mean: 0.10849
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01993, current rewards: 6.62704, mean: 0.11045
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01992, current rewards: 12.24147, mean: 0.11129
[32m[0906 13-49-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01995, current rewards: 17.85152, mean: 0.11157
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01998, current rewards: 23.45919, mean: 0.11171
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01997, current rewards: 29.07129, mean: 0.11181
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02001, current rewards: 34.68137, mean: 0.11188
[32m[0906 13-49-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02003, current rewards: 40.28944, mean: 0.11192
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01998, current rewards: 45.95704, mean: 0.11209
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01993, current rewards: 51.59257, mean: 0.11216
[32m[0906 13-49-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01988, current rewards: 57.22750, mean: 0.11221
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01983, current rewards: 62.86058, mean: 0.11225
[32m[0906 13-49-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01981, current rewards: 68.49589, mean: 0.11229
[32m[0906 13-49-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01981, current rewards: 74.13055, mean: 0.11232
[32m[0906 13-49-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01981, current rewards: 79.76508, mean: 0.11235
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01982, current rewards: 85.40120, mean: 0.11237
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01984, current rewards: 89.89253, mean: 0.11098
[32m[0906 13-50-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01986, current rewards: 95.43495, mean: 0.11097
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01986, current rewards: 100.98054, mean: 0.11097
[32m[0906 13-50-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01987, current rewards: 106.52264, mean: 0.11096
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01988, current rewards: 112.06475, mean: 0.11096
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01988, current rewards: 117.56855, mean: 0.11091
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01989, current rewards: 123.09328, mean: 0.11089
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01989, current rewards: 128.60700, mean: 0.11087
[32m[0906 13-50-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01989, current rewards: 134.08934, mean: 0.11082
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01989, current rewards: 139.60098, mean: 0.11079
[32m[0906 13-50-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01990, current rewards: 145.11651, mean: 0.11078
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01990, current rewards: 150.63956, mean: 0.11076
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01991, current rewards: 156.16187, mean: 0.11075
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01991, current rewards: 161.68298, mean: 0.11074
[32m[0906 13-50-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01990, current rewards: 167.20238, mean: 0.11073
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01990, current rewards: 172.71990, mean: 0.11072
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01990, current rewards: 178.24512, mean: 0.11071
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01990, current rewards: 183.75292, mean: 0.11069
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01990, current rewards: 189.25845, mean: 0.11068
[32m[0906 13-50-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01991, current rewards: 194.76647, mean: 0.11066
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01991, current rewards: 200.27406, mean: 0.11065
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01992, current rewards: 205.77964, mean: 0.11063
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01991, current rewards: 211.28326, mean: 0.11062
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01991, current rewards: 216.78930, mean: 0.11061
[32m[0906 13-50-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01991, current rewards: 222.30135, mean: 0.11060
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01992, current rewards: 227.82785, mean: 0.11060
[32m[0906 13-50-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01992, current rewards: 233.32875, mean: 0.11058
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01991, current rewards: 238.82371, mean: 0.11057
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01992, current rewards: 244.32060, mean: 0.11055
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01992, current rewards: 249.82327, mean: 0.11054
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01992, current rewards: 255.39222, mean: 0.11056
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01993, current rewards: 260.86417, mean: 0.11054
[32m[0906 13-50-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01993, current rewards: 266.33745, mean: 0.11051
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01993, current rewards: 271.79721, mean: 0.11049
[32m[0906 13-50-33 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-50-33 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-50-33 @MBExp.py:227][0m Rewards obtained: [276.18509672124026], Lows: [0], Highs: [1], Total time: 522.3595270000001
[32m[0906 13-51-00 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-00 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02047, current rewards: -0.00743, mean: -0.00074
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02008, current rewards: 5.36841, mean: 0.08947
[32m[0906 13-51-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02007, current rewards: 10.73679, mean: 0.09761
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02000, current rewards: 16.10661, mean: 0.10067
[32m[0906 13-51-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01986, current rewards: 21.47313, mean: 0.10225
[32m[0906 13-51-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01981, current rewards: 26.84544, mean: 0.10325
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01977, current rewards: 32.22165, mean: 0.10394
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01976, current rewards: 37.65192, mean: 0.10459
[32m[0906 13-51-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01973, current rewards: 43.03833, mean: 0.10497
[32m[0906 13-51-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01971, current rewards: 48.43117, mean: 0.10529
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01973, current rewards: 53.90802, mean: 0.10570
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01976, current rewards: 59.38847, mean: 0.10605
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01978, current rewards: 64.86538, mean: 0.10634
[32m[0906 13-51-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01982, current rewards: 70.34100, mean: 0.10658
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01985, current rewards: 75.81867, mean: 0.10679
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01986, current rewards: 81.26058, mean: 0.10692
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01986, current rewards: 86.74855, mean: 0.10710
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01986, current rewards: 92.29841, mean: 0.10732
[32m[0906 13-51-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01988, current rewards: 97.66893, mean: 0.10733
[32m[0906 13-51-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01987, current rewards: 103.04059, mean: 0.10733
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01987, current rewards: 108.41627, mean: 0.10734
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01987, current rewards: 113.78681, mean: 0.10735
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01987, current rewards: 119.15834, mean: 0.10735
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01988, current rewards: 124.53100, mean: 0.10735
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01990, current rewards: 129.90226, mean: 0.10736
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01989, current rewards: 135.27648, mean: 0.10736
[32m[0906 13-51-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01989, current rewards: 140.64948, mean: 0.10737
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01988, current rewards: 146.02320, mean: 0.10737
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01988, current rewards: 151.39332, mean: 0.10737
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01989, current rewards: 156.76406, mean: 0.10737
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01989, current rewards: 162.16326, mean: 0.10739
[32m[0906 13-51-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01989, current rewards: 167.70050, mean: 0.10750
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01989, current rewards: 173.23065, mean: 0.10760
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01990, current rewards: 178.71053, mean: 0.10766
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01991, current rewards: 184.19162, mean: 0.10771
[32m[0906 13-51-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01991, current rewards: 189.67216, mean: 0.10777
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01992, current rewards: 195.15312, mean: 0.10782
[32m[0906 13-51-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01992, current rewards: 200.63540, mean: 0.10787
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01992, current rewards: 206.11338, mean: 0.10791
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01992, current rewards: 211.59570, mean: 0.10796
[32m[0906 13-51-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01992, current rewards: 216.94888, mean: 0.10793
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01992, current rewards: 222.42664, mean: 0.10797
[32m[0906 13-51-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01992, current rewards: 227.90095, mean: 0.10801
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01992, current rewards: 233.38101, mean: 0.10805
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01992, current rewards: 238.85385, mean: 0.10808
[32m[0906 13-51-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01993, current rewards: 244.33003, mean: 0.10811
[32m[0906 13-51-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01993, current rewards: 249.81043, mean: 0.10814
[32m[0906 13-51-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01993, current rewards: 255.28877, mean: 0.10817
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01993, current rewards: 260.79879, mean: 0.10822
[32m[0906 13-51-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01993, current rewards: 266.27428, mean: 0.10824
[32m[0906 13-51-51 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-51-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-51-51 @MBExp.py:227][0m Rewards obtained: [270.6460483456314], Lows: [0], Highs: [1], Total time: 572.8464050000001
[32m[0906 13-52-20 @MBExp.py:144][0m ####################################################################
[32m[0906 13-52-20 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02030, current rewards: -0.05938, mean: -0.00594
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01970, current rewards: 5.41527, mean: 0.09025
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01970, current rewards: 10.89046, mean: 0.09900
[32m[0906 13-52-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01965, current rewards: 16.36694, mean: 0.10229
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01966, current rewards: 21.84079, mean: 0.10400
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01967, current rewards: 27.31517, mean: 0.10506
[32m[0906 13-52-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01975, current rewards: 32.78940, mean: 0.10577
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01978, current rewards: 38.20982, mean: 0.10614
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01981, current rewards: 43.66738, mean: 0.10651
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01985, current rewards: 49.16903, mean: 0.10689
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01988, current rewards: 54.72129, mean: 0.10730
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01991, current rewards: 60.27380, mean: 0.10763
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01989, current rewards: 65.83511, mean: 0.10793
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01990, current rewards: 71.39428, mean: 0.10817
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01991, current rewards: 76.95294, mean: 0.10838
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01993, current rewards: 82.57160, mean: 0.10865
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01992, current rewards: 88.05997, mean: 0.10872
[32m[0906 13-52-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01993, current rewards: 93.51910, mean: 0.10874
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01995, current rewards: 98.97909, mean: 0.10877
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01996, current rewards: 104.44109, mean: 0.10879
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01997, current rewards: 109.90233, mean: 0.10881
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01998, current rewards: 115.36198, mean: 0.10883
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01998, current rewards: 120.82235, mean: 0.10885
[32m[0906 13-52-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01998, current rewards: 126.34354, mean: 0.10892
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01996, current rewards: 131.82746, mean: 0.10895
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01995, current rewards: 137.30876, mean: 0.10898
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01996, current rewards: 142.79076, mean: 0.10900
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01996, current rewards: 148.27231, mean: 0.10902
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01997, current rewards: 153.76039, mean: 0.10905
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01996, current rewards: 159.24488, mean: 0.10907
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01997, current rewards: 164.73398, mean: 0.10910
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01997, current rewards: 170.21326, mean: 0.10911
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01997, current rewards: 175.60851, mean: 0.10907
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01997, current rewards: 181.06618, mean: 0.10908
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01997, current rewards: 186.52316, mean: 0.10908
[32m[0906 13-52-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01998, current rewards: 191.98121, mean: 0.10908
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01998, current rewards: 197.45099, mean: 0.10909
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01998, current rewards: 202.91710, mean: 0.10910
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01998, current rewards: 208.38249, mean: 0.10910
[32m[0906 13-52-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 213.84857, mean: 0.10911
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01998, current rewards: 219.32250, mean: 0.10912
[32m[0906 13-53-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01997, current rewards: 224.78540, mean: 0.10912
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01997, current rewards: 230.25488, mean: 0.10913
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01997, current rewards: 233.60779, mean: 0.10815
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01997, current rewards: 239.09627, mean: 0.10819
[32m[0906 13-53-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01997, current rewards: 244.58354, mean: 0.10822
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01996, current rewards: 250.07415, mean: 0.10826
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01996, current rewards: 255.56554, mean: 0.10829
[32m[0906 13-53-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01995, current rewards: 261.03428, mean: 0.10831
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01995, current rewards: 266.52512, mean: 0.10834
[32m[0906 13-53-10 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-53-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-53-10 @MBExp.py:227][0m Rewards obtained: [270.91701284084377], Lows: [1], Highs: [1], Total time: 623.3832770000001
[32m[0906 13-53-42 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-42 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 13-53-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01947, current rewards: 1.21524, mean: 0.12152
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01979, current rewards: 7.25615, mean: 0.12094
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01990, current rewards: 13.29938, mean: 0.12090
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01991, current rewards: 19.34335, mean: 0.12090
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01994, current rewards: 25.38384, mean: 0.12088
[32m[0906 13-53-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01995, current rewards: 31.42572, mean: 0.12087
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01991, current rewards: 37.40850, mean: 0.12067
[32m[0906 13-53-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01994, current rewards: 43.42774, mean: 0.12063
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01992, current rewards: 49.45351, mean: 0.12062
[32m[0906 13-53-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01992, current rewards: 55.47910, mean: 0.12061
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01992, current rewards: 61.50330, mean: 0.12059
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01994, current rewards: 65.97747, mean: 0.11782
[32m[0906 13-53-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01994, current rewards: 71.56220, mean: 0.11732
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01992, current rewards: 77.14635, mean: 0.11689
[32m[0906 13-53-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01991, current rewards: 82.76212, mean: 0.11657
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01991, current rewards: 88.41546, mean: 0.11634
[32m[0906 13-53-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01993, current rewards: 94.06960, mean: 0.11614
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01993, current rewards: 99.73537, mean: 0.11597
[32m[0906 13-54-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01993, current rewards: 105.38415, mean: 0.11581
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01993, current rewards: 111.03241, mean: 0.11566
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01993, current rewards: 116.68825, mean: 0.11553
[32m[0906 13-54-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01992, current rewards: 122.33613, mean: 0.11541
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01991, current rewards: 127.98919, mean: 0.11531
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01992, current rewards: 133.64879, mean: 0.11521
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01993, current rewards: 139.30194, mean: 0.11513
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: 144.96576, mean: 0.11505
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 150.74061, mean: 0.11507
[32m[0906 13-54-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01994, current rewards: 156.52280, mean: 0.11509
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01994, current rewards: 162.30327, mean: 0.11511
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01994, current rewards: 168.08416, mean: 0.11513
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01995, current rewards: 173.86612, mean: 0.11514
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01995, current rewards: 179.42918, mean: 0.11502
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01995, current rewards: 185.03300, mean: 0.11493
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01996, current rewards: 190.62730, mean: 0.11484
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01996, current rewards: 196.22168, mean: 0.11475
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01996, current rewards: 201.81672, mean: 0.11467
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01996, current rewards: 207.41050, mean: 0.11459
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 213.00998, mean: 0.11452
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01996, current rewards: 218.60515, mean: 0.11445
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01996, current rewards: 224.25288, mean: 0.11441
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01996, current rewards: 229.89361, mean: 0.11437
[32m[0906 13-54-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01995, current rewards: 235.43676, mean: 0.11429
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01995, current rewards: 240.97379, mean: 0.11421
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01995, current rewards: 246.51655, mean: 0.11413
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01995, current rewards: 252.05929, mean: 0.11405
[32m[0906 13-54-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01994, current rewards: 257.59905, mean: 0.11398
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01993, current rewards: 263.13609, mean: 0.11391
[32m[0906 13-54-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01992, current rewards: 268.67217, mean: 0.11384
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01991, current rewards: 274.18384, mean: 0.11377
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01990, current rewards: 279.70701, mean: 0.11370
[32m[0906 13-54-32 @Agent.py:117][0m Average action selection time: 0.0199
[32m[0906 13-54-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-54-32 @MBExp.py:227][0m Rewards obtained: [284.12184867766354], Lows: [0], Highs: [1], Total time: 673.8291040000001
[32m[0906 13-55-05 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-05 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02037, current rewards: -0.03951, mean: -0.00395
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01994, current rewards: 5.46648, mean: 0.09111
[32m[0906 13-55-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01985, current rewards: 10.97741, mean: 0.09979
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01988, current rewards: 16.48257, mean: 0.10302
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01992, current rewards: 21.98874, mean: 0.10471
[32m[0906 13-55-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01995, current rewards: 27.49175, mean: 0.10574
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01994, current rewards: 33.02945, mean: 0.10655
[32m[0906 13-55-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01993, current rewards: 38.54203, mean: 0.10706
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01992, current rewards: 44.04486, mean: 0.10743
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01994, current rewards: 49.54946, mean: 0.10772
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01993, current rewards: 55.04485, mean: 0.10793
[32m[0906 13-55-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01997, current rewards: 60.56542, mean: 0.10815
[32m[0906 13-55-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01998, current rewards: 66.09369, mean: 0.10835
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01997, current rewards: 71.62084, mean: 0.10852
[32m[0906 13-55-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01997, current rewards: 77.21934, mean: 0.10876
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01996, current rewards: 82.76515, mean: 0.10890
[32m[0906 13-55-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01996, current rewards: 86.19653, mean: 0.10642
[32m[0906 13-55-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01994, current rewards: 91.58016, mean: 0.10649
[32m[0906 13-55-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01991, current rewards: 96.96347, mean: 0.10655
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01990, current rewards: 102.34738, mean: 0.10661
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01991, current rewards: 107.73066, mean: 0.10666
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01991, current rewards: 110.89973, mean: 0.10462
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01992, current rewards: 116.27404, mean: 0.10475
[32m[0906 13-55-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01991, current rewards: 121.71653, mean: 0.10493
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01992, current rewards: 127.15965, mean: 0.10509
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01992, current rewards: 132.60666, mean: 0.10524
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01995, current rewards: 138.04909, mean: 0.10538
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01995, current rewards: 143.50151, mean: 0.10552
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01995, current rewards: 148.99069, mean: 0.10567
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01994, current rewards: 154.47735, mean: 0.10581
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01995, current rewards: 159.95532, mean: 0.10593
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01995, current rewards: 165.45118, mean: 0.10606
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01996, current rewards: 170.94526, mean: 0.10618
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01997, current rewards: 176.43817, mean: 0.10629
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01996, current rewards: 181.93545, mean: 0.10639
[32m[0906 13-55-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01996, current rewards: 187.43267, mean: 0.10650
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01996, current rewards: 192.90261, mean: 0.10658
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01996, current rewards: 198.44013, mean: 0.10669
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01996, current rewards: 203.98511, mean: 0.10680
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01996, current rewards: 209.55190, mean: 0.10691
[32m[0906 13-55-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01995, current rewards: 215.07167, mean: 0.10700
[32m[0906 13-55-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01995, current rewards: 220.59860, mean: 0.10709
[32m[0906 13-55-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01994, current rewards: 226.12256, mean: 0.10717
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01993, current rewards: 231.64353, mean: 0.10724
[32m[0906 13-55-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01992, current rewards: 237.11760, mean: 0.10729
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01991, current rewards: 242.62314, mean: 0.10736
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01991, current rewards: 248.12183, mean: 0.10741
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01989, current rewards: 253.65187, mean: 0.10748
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01987, current rewards: 259.15332, mean: 0.10753
[32m[0906 13-55-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01986, current rewards: 264.65873, mean: 0.10758
[32m[0906 13-55-56 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-55-56 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-55-56 @MBExp.py:227][0m Rewards obtained: [269.06093816205544], Lows: [1], Highs: [3], Total time: 724.1250020000001
[32m[0906 13-56-31 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-31 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 13-56-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01958, current rewards: 1.02912, mean: 0.10291
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01978, current rewards: 6.51332, mean: 0.10856
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01987, current rewards: 12.01099, mean: 0.10919
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01989, current rewards: 17.50806, mean: 0.10943
[32m[0906 13-56-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01991, current rewards: 23.00267, mean: 0.10954
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01992, current rewards: 28.46127, mean: 0.10947
[32m[0906 13-56-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01992, current rewards: 33.95773, mean: 0.10954
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01992, current rewards: 39.45413, mean: 0.10959
[32m[0906 13-56-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01992, current rewards: 44.94767, mean: 0.10963
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01994, current rewards: 50.43859, mean: 0.10965
[32m[0906 13-56-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01995, current rewards: 55.93999, mean: 0.10969
[32m[0906 13-56-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01997, current rewards: 61.43432, mean: 0.10970
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01996, current rewards: 66.92890, mean: 0.10972
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01996, current rewards: 72.50590, mean: 0.10986
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01997, current rewards: 78.02125, mean: 0.10989
[32m[0906 13-56-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01995, current rewards: 83.52834, mean: 0.10991
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01992, current rewards: 89.02581, mean: 0.10991
[32m[0906 13-56-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01992, current rewards: 94.52855, mean: 0.10992
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01992, current rewards: 100.02938, mean: 0.10992
[32m[0906 13-56-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01992, current rewards: 105.54559, mean: 0.10994
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01994, current rewards: 111.06455, mean: 0.10996
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01994, current rewards: 116.57508, mean: 0.10998
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01995, current rewards: 121.96569, mean: 0.10988
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01995, current rewards: 127.44608, mean: 0.10987
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01995, current rewards: 132.92918, mean: 0.10986
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01995, current rewards: 138.41807, mean: 0.10986
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01997, current rewards: 143.90071, mean: 0.10985
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01997, current rewards: 149.38695, mean: 0.10984
[32m[0906 13-57-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01997, current rewards: 154.82363, mean: 0.10980
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01998, current rewards: 160.30173, mean: 0.10980
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01998, current rewards: 165.88758, mean: 0.10986
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01998, current rewards: 171.41489, mean: 0.10988
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01997, current rewards: 176.89287, mean: 0.10987
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01997, current rewards: 182.37557, mean: 0.10986
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01997, current rewards: 187.85919, mean: 0.10986
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01998, current rewards: 193.34271, mean: 0.10985
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01999, current rewards: 197.00003, mean: 0.10884
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01998, current rewards: 203.04530, mean: 0.10916
[32m[0906 13-57-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01998, current rewards: 209.09056, mean: 0.10947
[32m[0906 13-57-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01998, current rewards: 217.31559, mean: 0.11088
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01996, current rewards: 226.10425, mean: 0.11249
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01995, current rewards: 234.89291, mean: 0.11403
[32m[0906 13-57-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01994, current rewards: 243.68157, mean: 0.11549
[32m[0906 13-57-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01992, current rewards: 212.49395, mean: 0.09838
[32m[0906 13-57-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01990, current rewards: 162.49395, mean: 0.07353
[32m[0906 13-57-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01989, current rewards: 112.49395, mean: 0.04978
[32m[0906 13-57-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01987, current rewards: 62.49395, mean: 0.02705
[32m[0906 13-57-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01986, current rewards: 12.49395, mean: 0.00529
[32m[0906 13-57-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01984, current rewards: -37.50605, mean: -0.01556
[32m[0906 13-57-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01983, current rewards: -87.50605, mean: -0.03557
[32m[0906 13-57-21 @Agent.py:117][0m Average action selection time: 0.0198
[32m[0906 13-57-21 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-57-21 @MBExp.py:227][0m Rewards obtained: [-127.50605452192102], Lows: [1], Highs: [374], Total time: 774.3557670000001
[32m[0906 13-57-59 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-59 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02048, current rewards: -0.03403, mean: -0.00340
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01990, current rewards: 5.38206, mean: 0.08970
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01996, current rewards: 10.80338, mean: 0.09821
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01990, current rewards: 16.21536, mean: 0.10135
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01989, current rewards: 21.63732, mean: 0.10303
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01990, current rewards: 27.16942, mean: 0.10450
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01993, current rewards: 32.60053, mean: 0.10516
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01997, current rewards: 38.00861, mean: 0.10558
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01996, current rewards: 43.42191, mean: 0.10591
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01996, current rewards: 48.83628, mean: 0.10617
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01996, current rewards: 54.24401, mean: 0.10636
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01998, current rewards: 59.65654, mean: 0.10653
[32m[0906 13-58-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01995, current rewards: 65.92020, mean: 0.10807
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01993, current rewards: 71.48339, mean: 0.10831
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01991, current rewards: 79.61216, mean: 0.11213
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01991, current rewards: 88.15008, mean: 0.11599
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01993, current rewards: 96.68800, mean: 0.11937
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01993, current rewards: 80.63999, mean: 0.09377
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01994, current rewards: 30.63999, mean: 0.03367
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01994, current rewards: -19.36001, mean: -0.02017
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01995, current rewards: -69.36001, mean: -0.06867
[32m[0906 13-58-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01995, current rewards: -119.36001, mean: -0.11260
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01994, current rewards: -169.36001, mean: -0.15258
[32m[0906 13-58-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01994, current rewards: -219.36001, mean: -0.18910
[32m[0906 13-58-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01993, current rewards: -269.36001, mean: -0.22261
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: -319.36001, mean: -0.25346
[32m[0906 13-58-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: -369.36001, mean: -0.28195
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01993, current rewards: -419.36001, mean: -0.30835
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01994, current rewards: -469.36001, mean: -0.33288
[32m[0906 13-58-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01994, current rewards: -519.36001, mean: -0.35573
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01993, current rewards: -569.36001, mean: -0.37706
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01993, current rewards: -619.36001, mean: -0.39703
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01993, current rewards: -669.36001, mean: -0.41575
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01993, current rewards: -719.36001, mean: -0.43335
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01993, current rewards: -769.36001, mean: -0.44992
[32m[0906 13-58-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01993, current rewards: -819.36001, mean: -0.46555
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01993, current rewards: -869.36001, mean: -0.48031
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01992, current rewards: -919.36001, mean: -0.49428
[32m[0906 13-58-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01991, current rewards: -969.36001, mean: -0.50752
[32m[0906 13-58-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01989, current rewards: -1019.36001, mean: -0.52008
[32m[0906 13-58-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01987, current rewards: -1069.36001, mean: -0.53202
[32m[0906 13-58-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01985, current rewards: -1119.36001, mean: -0.54338
[32m[0906 13-58-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01983, current rewards: -1169.36001, mean: -0.55420
[32m[0906 13-58-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01982, current rewards: -1219.36001, mean: -0.56452
[32m[0906 13-58-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01981, current rewards: -1269.36001, mean: -0.57437
[32m[0906 13-58-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01979, current rewards: -1319.36001, mean: -0.58379
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01978, current rewards: -1369.36001, mean: -0.59280
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01976, current rewards: -1419.36001, mean: -0.60142
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01975, current rewards: -1469.36001, mean: -0.60969
[32m[0906 13-58-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01974, current rewards: -1519.36001, mean: -0.61763
[32m[0906 13-58-49 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 13-58-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 13-58-49 @MBExp.py:227][0m Rewards obtained: [-1559.3600078584268], Lows: [0], Highs: [1662], Total time: 824.3533150000002
[32m[0906 13-59-29 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-29 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01998, current rewards: 1.01742, mean: 0.10174
[32m[0906 13-59-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01995, current rewards: 6.54731, mean: 0.10912
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01998, current rewards: 12.07731, mean: 0.10979
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01997, current rewards: 17.61175, mean: 0.11007
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01994, current rewards: 23.14574, mean: 0.11022
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01994, current rewards: 28.70140, mean: 0.11039
[32m[0906 13-59-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01993, current rewards: 34.20600, mean: 0.11034
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01990, current rewards: 39.73355, mean: 0.11037
[32m[0906 13-59-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01990, current rewards: 45.26272, mean: 0.11040
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01985, current rewards: 50.79130, mean: 0.11042
[32m[0906 13-59-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01982, current rewards: 56.32078, mean: 0.11043
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01980, current rewards: 61.84274, mean: 0.11043
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01978, current rewards: 67.37483, mean: 0.11045
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01980, current rewards: 72.86587, mean: 0.11040
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01981, current rewards: 78.38779, mean: 0.11041
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01982, current rewards: 83.91426, mean: 0.11041
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01983, current rewards: 89.43152, mean: 0.11041
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01985, current rewards: 94.95314, mean: 0.11041
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01986, current rewards: 100.48010, mean: 0.11042
[32m[0906 13-59-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01986, current rewards: 106.04742, mean: 0.11047
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01987, current rewards: 111.57035, mean: 0.11047
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01988, current rewards: 117.13488, mean: 0.11050
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01988, current rewards: 122.67700, mean: 0.11052
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01987, current rewards: 128.21902, mean: 0.11053
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01987, current rewards: 133.76212, mean: 0.11055
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01987, current rewards: 139.30882, mean: 0.11056
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01988, current rewards: 144.84950, mean: 0.11057
[32m[0906 13-59-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01988, current rewards: 150.36856, mean: 0.11057
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01989, current rewards: 155.92497, mean: 0.11059
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01989, current rewards: 161.53883, mean: 0.11064
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01990, current rewards: 167.09262, mean: 0.11066
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01991, current rewards: 172.65073, mean: 0.11067
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01993, current rewards: 178.20820, mean: 0.11069
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01993, current rewards: 183.76463, mean: 0.11070
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01993, current rewards: 189.26813, mean: 0.11068
[32m[0906 14-00-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01992, current rewards: 194.74634, mean: 0.11065
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01989, current rewards: 200.22539, mean: 0.11062
[32m[0906 14-00-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01988, current rewards: 205.70649, mean: 0.11059
[32m[0906 14-00-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01986, current rewards: 211.18424, mean: 0.11057
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01984, current rewards: 216.79106, mean: 0.11061
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01982, current rewards: 222.30481, mean: 0.11060
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01981, current rewards: 227.82223, mean: 0.11059
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01979, current rewards: 233.33930, mean: 0.11059
[32m[0906 14-00-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01978, current rewards: 238.85766, mean: 0.11058
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01977, current rewards: 244.37444, mean: 0.11058
[32m[0906 14-00-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01975, current rewards: 248.74063, mean: 0.11006
[32m[0906 14-00-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01974, current rewards: 254.24016, mean: 0.11006
[32m[0906 14-00-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01972, current rewards: 259.76654, mean: 0.11007
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01972, current rewards: 265.29218, mean: 0.11008
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01971, current rewards: 270.82316, mean: 0.11009
[32m[0906 14-00-19 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-00-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-00-19 @MBExp.py:227][0m Rewards obtained: [275.2428301551854], Lows: [0], Highs: [1], Total time: 874.3224260000002
[32m[0906 14-01-01 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-01 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01943, current rewards: 0.05940, mean: 0.00594
[32m[0906 14-01-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01987, current rewards: 5.76674, mean: 0.09611
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01992, current rewards: 11.37381, mean: 0.10340
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01993, current rewards: 16.98799, mean: 0.10617
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01993, current rewards: 22.62407, mean: 0.10773
[32m[0906 14-01-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01992, current rewards: 28.23981, mean: 0.10861
[32m[0906 14-01-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01991, current rewards: 31.93651, mean: 0.10302
[32m[0906 14-01-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01985, current rewards: 38.70055, mean: 0.10750
[32m[0906 14-01-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01983, current rewards: 45.46459, mean: 0.11089
[32m[0906 14-01-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01981, current rewards: 52.22863, mean: 0.11354
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01982, current rewards: 58.99267, mean: 0.11567
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01982, current rewards: 14.66907, mean: 0.02619
[32m[0906 14-01-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01984, current rewards: -35.33093, mean: -0.05792
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01984, current rewards: -85.33093, mean: -0.12929
[32m[0906 14-01-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01984, current rewards: -135.33093, mean: -0.19061
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01986, current rewards: -185.33093, mean: -0.24386
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01986, current rewards: -235.33093, mean: -0.29053
[32m[0906 14-01-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01985, current rewards: -285.33093, mean: -0.33178
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01985, current rewards: -335.33093, mean: -0.36850
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01987, current rewards: -385.33093, mean: -0.40139
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01988, current rewards: -435.33093, mean: -0.43102
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01989, current rewards: -485.33093, mean: -0.45786
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01990, current rewards: -535.33093, mean: -0.48228
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01990, current rewards: -585.33093, mean: -0.50460
[32m[0906 14-01-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01991, current rewards: -635.33093, mean: -0.52507
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01991, current rewards: -685.33093, mean: -0.54391
[32m[0906 14-01-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01991, current rewards: -735.33093, mean: -0.56132
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01991, current rewards: -785.33093, mean: -0.57745
[32m[0906 14-01-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01992, current rewards: -835.33093, mean: -0.59243
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01992, current rewards: -885.33093, mean: -0.60639
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01991, current rewards: -935.33093, mean: -0.61942
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01991, current rewards: -985.33093, mean: -0.63162
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01990, current rewards: -1035.33093, mean: -0.64306
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01988, current rewards: -1085.33093, mean: -0.65381
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01985, current rewards: -1135.33093, mean: -0.66394
[32m[0906 14-01-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01984, current rewards: -1185.33093, mean: -0.67348
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01981, current rewards: -1235.33093, mean: -0.68250
[32m[0906 14-01-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01980, current rewards: -1285.33093, mean: -0.69104
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01978, current rewards: -1335.33093, mean: -0.69913
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01977, current rewards: -1385.33093, mean: -0.70680
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01976, current rewards: -1435.33093, mean: -0.71409
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01974, current rewards: -1485.33093, mean: -0.72103
[32m[0906 14-01-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01972, current rewards: -1535.33093, mean: -0.72764
[32m[0906 14-01-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01971, current rewards: -1585.33093, mean: -0.73395
[32m[0906 14-01-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01970, current rewards: -1635.33093, mean: -0.73997
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01969, current rewards: -1685.33093, mean: -0.74572
[32m[0906 14-01-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01968, current rewards: -1735.33093, mean: -0.75123
[32m[0906 14-01-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01967, current rewards: -1785.33093, mean: -0.75650
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01965, current rewards: -1835.33093, mean: -0.76155
[32m[0906 14-01-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01965, current rewards: -1885.33093, mean: -0.76639
[32m[0906 14-01-51 @Agent.py:117][0m Average action selection time: 0.0197
[32m[0906 14-01-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-01-51 @MBExp.py:227][0m Rewards obtained: [-1925.33092940959], Lows: [1], Highs: [1986], Total time: 924.1411300000002
[32m[0906 14-02-35 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-35 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01960, current rewards: 1.08672, mean: 0.10867
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01993, current rewards: 6.75160, mean: 0.11253
[32m[0906 14-02-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01991, current rewards: 12.38325, mean: 0.11257
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01992, current rewards: 17.99748, mean: 0.11248
[32m[0906 14-02-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01984, current rewards: 23.16751, mean: 0.11032
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01977, current rewards: 28.33584, mean: 0.10898
[32m[0906 14-02-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01978, current rewards: 33.50110, mean: 0.10807
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01976, current rewards: 38.70971, mean: 0.10753
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01979, current rewards: 44.16904, mean: 0.10773
[32m[0906 14-02-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01979, current rewards: 49.63214, mean: 0.10790
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01982, current rewards: 55.09160, mean: 0.10802
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01985, current rewards: 60.55297, mean: 0.10813
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01987, current rewards: 66.11001, mean: 0.10838
[32m[0906 14-02-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01989, current rewards: 71.61421, mean: 0.10851
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01989, current rewards: 77.09210, mean: 0.10858
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01990, current rewards: 82.57000, mean: 0.10864
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01990, current rewards: 88.04188, mean: 0.10869
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01991, current rewards: 93.47344, mean: 0.10869
[32m[0906 14-02-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01990, current rewards: 98.90925, mean: 0.10869
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01989, current rewards: 104.34538, mean: 0.10869
[32m[0906 14-02-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01991, current rewards: 109.77877, mean: 0.10869
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01992, current rewards: 115.21428, mean: 0.10869
[32m[0906 14-02-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01992, current rewards: 120.64529, mean: 0.10869
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01993, current rewards: 126.30124, mean: 0.10888
[32m[0906 14-03-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01993, current rewards: 131.61087, mean: 0.10877
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01993, current rewards: 136.91988, mean: 0.10867
[32m[0906 14-03-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01993, current rewards: 142.22984, mean: 0.10857
[32m[0906 14-03-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01992, current rewards: 147.54012, mean: 0.10849
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01992, current rewards: 152.84992, mean: 0.10840
[32m[0906 14-03-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01990, current rewards: 158.14063, mean: 0.10832
[32m[0906 14-03-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01989, current rewards: 163.46219, mean: 0.10825
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01986, current rewards: 168.78474, mean: 0.10820
[32m[0906 14-03-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01984, current rewards: 174.10700, mean: 0.10814
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01983, current rewards: 179.42831, mean: 0.10809
[32m[0906 14-03-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01981, current rewards: 183.79640, mean: 0.10748
[32m[0906 14-03-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01979, current rewards: 189.27834, mean: 0.10754
[32m[0906 14-03-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01978, current rewards: 194.75745, mean: 0.10760
[32m[0906 14-03-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01976, current rewards: 200.27040, mean: 0.10767
[32m[0906 14-03-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01975, current rewards: 205.75414, mean: 0.10772
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01974, current rewards: 211.31473, mean: 0.10781
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01972, current rewards: 216.83227, mean: 0.10788
[32m[0906 14-03-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01971, current rewards: 222.35104, mean: 0.10794
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01969, current rewards: 227.87440, mean: 0.10800
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01968, current rewards: 233.39917, mean: 0.10806
[32m[0906 14-03-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01967, current rewards: 238.92073, mean: 0.10811
[32m[0906 14-03-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01967, current rewards: 244.45986, mean: 0.10817
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01966, current rewards: 249.97938, mean: 0.10822
[32m[0906 14-03-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01965, current rewards: 255.49982, mean: 0.10826
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01964, current rewards: 261.00710, mean: 0.10830
[32m[0906 14-03-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01964, current rewards: 266.46491, mean: 0.10832
[32m[0906 14-03-25 @Agent.py:117][0m Average action selection time: 0.0196
[32m[0906 14-03-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-03-25 @MBExp.py:227][0m Rewards obtained: [270.8327355336907], Lows: [0], Highs: [1], Total time: 973.9441420000002
[32m[0906 14-04-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-12 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-04-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02028, current rewards: -0.00749, mean: -0.00075
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01964, current rewards: 5.55459, mean: 0.09258
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01963, current rewards: 11.11939, mean: 0.10109
[32m[0906 14-04-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01972, current rewards: 16.81181, mean: 0.10507
[32m[0906 14-04-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01965, current rewards: 22.34838, mean: 0.10642
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01965, current rewards: 27.88710, mean: 0.10726
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01967, current rewards: 33.42481, mean: 0.10782
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01968, current rewards: 38.96754, mean: 0.10824
[32m[0906 14-04-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01973, current rewards: 44.50499, mean: 0.10855
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01975, current rewards: 50.04391, mean: 0.10879
[32m[0906 14-04-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01975, current rewards: 55.58445, mean: 0.10899
[32m[0906 14-04-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01976, current rewards: 61.13120, mean: 0.10916
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01977, current rewards: 66.70847, mean: 0.10936
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01977, current rewards: 72.23433, mean: 0.10945
[32m[0906 14-04-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01979, current rewards: 77.75654, mean: 0.10952
[32m[0906 14-04-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01978, current rewards: 83.28141, mean: 0.10958
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01979, current rewards: 88.81238, mean: 0.10964
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01980, current rewards: 94.34063, mean: 0.10970
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01981, current rewards: 99.86447, mean: 0.10974
[32m[0906 14-04-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01982, current rewards: 105.39343, mean: 0.10978
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01983, current rewards: 110.91804, mean: 0.10982
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01984, current rewards: 116.70237, mean: 0.11010
[32m[0906 14-04-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01983, current rewards: 122.37544, mean: 0.11025
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01982, current rewards: 128.05421, mean: 0.11039
[32m[0906 14-04-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01981, current rewards: 133.73118, mean: 0.11052
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01980, current rewards: 139.40271, mean: 0.11064
[32m[0906 14-04-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01979, current rewards: 145.07780, mean: 0.11075
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01979, current rewards: 150.75401, mean: 0.11085
[32m[0906 14-04-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01977, current rewards: 156.38061, mean: 0.11091
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01975, current rewards: 162.02558, mean: 0.11098
[32m[0906 14-04-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01973, current rewards: 168.57578, mean: 0.11164
[32m[0906 14-04-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01970, current rewards: 175.03461, mean: 0.11220
[32m[0906 14-04-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01969, current rewards: 181.49343, mean: 0.11273
[32m[0906 14-04-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01967, current rewards: 187.95226, mean: 0.11322
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01965, current rewards: 194.41108, mean: 0.11369
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01964, current rewards: 200.86990, mean: 0.11413
[32m[0906 14-04-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01964, current rewards: 187.02104, mean: 0.10333
[32m[0906 14-04-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01962, current rewards: 137.02104, mean: 0.07367
[32m[0906 14-04-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01961, current rewards: 87.02104, mean: 0.04556
[32m[0906 14-04-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01960, current rewards: 37.02104, mean: 0.01889
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01959, current rewards: -12.97896, mean: -0.00646
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01957, current rewards: -62.97896, mean: -0.03057
[32m[0906 14-04-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01956, current rewards: -112.97896, mean: -0.05354
[32m[0906 14-04-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01956, current rewards: -162.97896, mean: -0.07545
[32m[0906 14-04-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01954, current rewards: -212.97896, mean: -0.09637
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01953, current rewards: -262.97896, mean: -0.11636
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01953, current rewards: -312.97896, mean: -0.13549
[32m[0906 14-04-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01952, current rewards: -362.97896, mean: -0.15380
[32m[0906 14-04-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01952, current rewards: -412.97896, mean: -0.17136
[32m[0906 14-05-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01952, current rewards: -462.97896, mean: -0.18820
[32m[0906 14-05-01 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-05-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-05-01 @MBExp.py:227][0m Rewards obtained: [-502.9789630671718], Lows: [0], Highs: [708], Total time: 1023.4437620000002
[32m[0906 14-05-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-50 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01979, current rewards: 1.14291, mean: 0.11429
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01963, current rewards: 6.73657, mean: 0.11228
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01957, current rewards: 12.32817, mean: 0.11207
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01961, current rewards: 17.78657, mean: 0.11117
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01972, current rewards: 23.43793, mean: 0.11161
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01974, current rewards: 29.08958, mean: 0.11188
[32m[0906 14-05-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01978, current rewards: 34.74533, mean: 0.11208
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01980, current rewards: 40.40223, mean: 0.11223
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01984, current rewards: 46.05293, mean: 0.11232
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01983, current rewards: 51.70862, mean: 0.11241
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01987, current rewards: 57.36039, mean: 0.11247
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01988, current rewards: 63.06105, mean: 0.11261
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01988, current rewards: 68.81485, mean: 0.11281
[32m[0906 14-06-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01988, current rewards: 74.39792, mean: 0.11272
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01988, current rewards: 78.82175, mean: 0.11102
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01988, current rewards: 84.32975, mean: 0.11096
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01989, current rewards: 89.83559, mean: 0.11091
[32m[0906 14-06-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01989, current rewards: 95.34451, mean: 0.11087
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01990, current rewards: 100.85212, mean: 0.11083
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01990, current rewards: 106.36226, mean: 0.11079
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01987, current rewards: 111.92298, mean: 0.11081
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01986, current rewards: 117.45672, mean: 0.11081
[32m[0906 14-06-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01985, current rewards: 122.99057, mean: 0.11080
[32m[0906 14-06-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01983, current rewards: 128.51218, mean: 0.11079
[32m[0906 14-06-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01982, current rewards: 134.04834, mean: 0.11078
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01981, current rewards: 139.56942, mean: 0.11077
[32m[0906 14-06-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01979, current rewards: 145.13546, mean: 0.11079
[32m[0906 14-06-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01977, current rewards: 150.65283, mean: 0.11077
[32m[0906 14-06-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01975, current rewards: 156.16954, mean: 0.11076
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01972, current rewards: 161.68488, mean: 0.11074
[32m[0906 14-06-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01970, current rewards: 167.20116, mean: 0.11073
[32m[0906 14-06-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01969, current rewards: 172.71875, mean: 0.11072
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01968, current rewards: 178.26083, mean: 0.11072
[32m[0906 14-06-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01966, current rewards: 183.79882, mean: 0.11072
[32m[0906 14-06-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01965, current rewards: 189.34040, mean: 0.11073
[32m[0906 14-06-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01963, current rewards: 194.87276, mean: 0.11072
[32m[0906 14-06-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01962, current rewards: 200.37492, mean: 0.11070
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01961, current rewards: 205.91212, mean: 0.11071
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01960, current rewards: 211.45654, mean: 0.11071
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01959, current rewards: 216.99213, mean: 0.11071
[32m[0906 14-06-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01958, current rewards: 222.53315, mean: 0.11071
[32m[0906 14-06-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01956, current rewards: 228.07613, mean: 0.11072
[32m[0906 14-06-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01955, current rewards: 233.62677, mean: 0.11072
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01954, current rewards: 239.17053, mean: 0.11073
[32m[0906 14-06-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01954, current rewards: 244.63515, mean: 0.11069
[32m[0906 14-06-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01952, current rewards: 250.15532, mean: 0.11069
[32m[0906 14-06-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01952, current rewards: 255.67459, mean: 0.11068
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01951, current rewards: 261.20759, mean: 0.11068
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01952, current rewards: 266.73835, mean: 0.11068
[32m[0906 14-06-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01952, current rewards: 272.27262, mean: 0.11068
[32m[0906 14-06-40 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-06-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-06-40 @MBExp.py:227][0m Rewards obtained: [276.699149786812], Lows: [0], Highs: [1], Total time: 1072.9319490000003
[32m[0906 14-07-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-31 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01906, current rewards: 1.09129, mean: 0.10913
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01959, current rewards: 6.71035, mean: 0.11184
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01986, current rewards: 12.32974, mean: 0.11209
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01986, current rewards: 17.97653, mean: 0.11235
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01989, current rewards: 23.61301, mean: 0.11244
[32m[0906 14-07-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01991, current rewards: 29.25266, mean: 0.11251
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01992, current rewards: 34.88953, mean: 0.11255
[32m[0906 14-07-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01994, current rewards: 40.52516, mean: 0.11257
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01993, current rewards: 46.16146, mean: 0.11259
[32m[0906 14-07-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01996, current rewards: 51.80001, mean: 0.11261
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01998, current rewards: 57.43815, mean: 0.11262
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02000, current rewards: 62.99703, mean: 0.11249
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02001, current rewards: 68.54758, mean: 0.11237
[32m[0906 14-07-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02002, current rewards: 74.09045, mean: 0.11226
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02003, current rewards: 79.63269, mean: 0.11216
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02001, current rewards: 85.18247, mean: 0.11208
[32m[0906 14-07-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02000, current rewards: 90.72015, mean: 0.11200
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01998, current rewards: 96.26845, mean: 0.11194
[32m[0906 14-07-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01996, current rewards: 101.81634, mean: 0.11189
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01994, current rewards: 107.36785, mean: 0.11184
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01993, current rewards: 112.91678, mean: 0.11180
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01990, current rewards: 118.46202, mean: 0.11176
[32m[0906 14-07-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01989, current rewards: 124.01057, mean: 0.11172
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01987, current rewards: 129.55200, mean: 0.11168
[32m[0906 14-07-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01985, current rewards: 135.09805, mean: 0.11165
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01982, current rewards: 140.64597, mean: 0.11162
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01981, current rewards: 146.13521, mean: 0.11155
[32m[0906 14-07-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01977, current rewards: 151.69235, mean: 0.11154
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01975, current rewards: 157.18795, mean: 0.11148
[32m[0906 14-08-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01973, current rewards: 162.68610, mean: 0.11143
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01971, current rewards: 168.18861, mean: 0.11138
[32m[0906 14-08-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01969, current rewards: 173.84262, mean: 0.11144
[32m[0906 14-08-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01967, current rewards: 179.32704, mean: 0.11138
[32m[0906 14-08-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01966, current rewards: 184.81124, mean: 0.11133
[32m[0906 14-08-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01964, current rewards: 190.29230, mean: 0.11128
[32m[0906 14-08-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01963, current rewards: 195.66926, mean: 0.11118
[32m[0906 14-08-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01961, current rewards: 201.19038, mean: 0.11115
[32m[0906 14-08-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01960, current rewards: 206.71648, mean: 0.11114
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01958, current rewards: 212.66569, mean: 0.11134
[32m[0906 14-08-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01957, current rewards: 218.19082, mean: 0.11132
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01956, current rewards: 223.71049, mean: 0.11130
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01955, current rewards: 229.23068, mean: 0.11128
[32m[0906 14-08-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01954, current rewards: 234.75159, mean: 0.11126
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01953, current rewards: 240.26924, mean: 0.11124
[32m[0906 14-08-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01952, current rewards: 245.92751, mean: 0.11128
[32m[0906 14-08-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01951, current rewards: 251.51496, mean: 0.11129
[32m[0906 14-08-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01950, current rewards: 257.11002, mean: 0.11130
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01949, current rewards: 262.41678, mean: 0.11119
[32m[0906 14-08-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01950, current rewards: 267.70236, mean: 0.11108
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01950, current rewards: 272.98729, mean: 0.11097
[32m[0906 14-08-20 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-08-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-08-20 @MBExp.py:227][0m Rewards obtained: [277.21283813915215], Lows: [0], Highs: [0], Total time: 1122.3721740000003
[32m[0906 14-09-13 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-13 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01958, current rewards: 1.10987, mean: 0.11099
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01992, current rewards: 6.41104, mean: 0.10685
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01996, current rewards: 11.78036, mean: 0.10709
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01997, current rewards: 17.27195, mean: 0.10795
[32m[0906 14-09-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01994, current rewards: 22.72776, mean: 0.10823
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02001, current rewards: 28.17768, mean: 0.10838
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01997, current rewards: 33.63001, mean: 0.10848
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01999, current rewards: 39.10939, mean: 0.10864
[32m[0906 14-09-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01997, current rewards: 44.66361, mean: 0.10894
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01996, current rewards: 50.21228, mean: 0.10916
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01997, current rewards: 55.75929, mean: 0.10933
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01997, current rewards: 61.16202, mean: 0.10922
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01994, current rewards: 66.70205, mean: 0.10935
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01991, current rewards: 72.24171, mean: 0.10946
[32m[0906 14-09-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01989, current rewards: 77.77842, mean: 0.10955
[32m[0906 14-09-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01987, current rewards: 83.31787, mean: 0.10963
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01984, current rewards: 88.86205, mean: 0.10971
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01982, current rewards: 94.39115, mean: 0.10976
[32m[0906 14-09-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01983, current rewards: 99.87486, mean: 0.10975
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01982, current rewards: 105.38554, mean: 0.10978
[32m[0906 14-09-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01980, current rewards: 110.88252, mean: 0.10978
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01979, current rewards: 116.37881, mean: 0.10979
[32m[0906 14-09-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01977, current rewards: 121.87933, mean: 0.10980
[32m[0906 14-09-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01975, current rewards: 127.37944, mean: 0.10981
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01972, current rewards: 132.88180, mean: 0.10982
[32m[0906 14-09-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01970, current rewards: 138.38231, mean: 0.10983
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01968, current rewards: 143.88102, mean: 0.10983
[32m[0906 14-09-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01966, current rewards: 149.37873, mean: 0.10984
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01964, current rewards: 154.83950, mean: 0.10982
[32m[0906 14-09-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01962, current rewards: 160.41902, mean: 0.10988
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01961, current rewards: 165.99391, mean: 0.10993
[32m[0906 14-09-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01960, current rewards: 171.56740, mean: 0.10998
[32m[0906 14-09-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01958, current rewards: 177.13982, mean: 0.11002
[32m[0906 14-09-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01958, current rewards: 182.71712, mean: 0.11007
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01957, current rewards: 188.29581, mean: 0.11011
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01956, current rewards: 193.94330, mean: 0.11020
[32m[0906 14-09-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01955, current rewards: 199.57837, mean: 0.11026
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01954, current rewards: 205.13868, mean: 0.11029
[32m[0906 14-09-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01953, current rewards: 210.65136, mean: 0.11029
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01954, current rewards: 216.20241, mean: 0.11031
[32m[0906 14-09-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01953, current rewards: 221.74871, mean: 0.11032
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01951, current rewards: 227.29853, mean: 0.11034
[32m[0906 14-09-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01951, current rewards: 232.85033, mean: 0.11036
[32m[0906 14-09-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01950, current rewards: 238.40402, mean: 0.11037
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01950, current rewards: 243.92966, mean: 0.11038
[32m[0906 14-09-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01949, current rewards: 249.47378, mean: 0.11039
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01949, current rewards: 255.01992, mean: 0.11040
[32m[0906 14-10-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01948, current rewards: 260.56729, mean: 0.11041
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01949, current rewards: 266.11229, mean: 0.11042
[32m[0906 14-10-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01949, current rewards: 271.65952, mean: 0.11043
[32m[0906 14-10-03 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 14-10-03 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-10-03 @MBExp.py:227][0m Rewards obtained: [276.09415820979484], Lows: [0], Highs: [0], Total time: 1171.7609180000004
[32m[0906 14-10-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-58 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02046, current rewards: 1.05549, mean: 0.10555
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02014, current rewards: 6.56752, mean: 0.10946
[32m[0906 14-11-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02012, current rewards: 12.20027, mean: 0.11091
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02014, current rewards: 17.81276, mean: 0.11133
[32m[0906 14-11-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02009, current rewards: 23.38133, mean: 0.11134
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02007, current rewards: 28.94921, mean: 0.11134
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02001, current rewards: 34.51645, mean: 0.11134
[32m[0906 14-11-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01991, current rewards: 39.96012, mean: 0.11100
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01989, current rewards: 45.39652, mean: 0.11072
[32m[0906 14-11-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01987, current rewards: 50.83058, mean: 0.11050
[32m[0906 14-11-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01986, current rewards: 56.26770, mean: 0.11033
[32m[0906 14-11-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01984, current rewards: 61.62834, mean: 0.11005
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01982, current rewards: 67.15029, mean: 0.11008
[32m[0906 14-11-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01981, current rewards: 72.67166, mean: 0.11011
[32m[0906 14-11-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01979, current rewards: 78.18702, mean: 0.11012
[32m[0906 14-11-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01979, current rewards: 83.70948, mean: 0.11014
[32m[0906 14-11-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01978, current rewards: 89.22698, mean: 0.11016
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01977, current rewards: 94.74531, mean: 0.11017
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01976, current rewards: 100.26936, mean: 0.11019
[32m[0906 14-11-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01975, current rewards: 105.83657, mean: 0.11025
[32m[0906 14-11-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01972, current rewards: 111.32859, mean: 0.11023
[32m[0906 14-11-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01969, current rewards: 116.82793, mean: 0.11022
[32m[0906 14-11-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01967, current rewards: 122.28966, mean: 0.11017
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01964, current rewards: 127.75717, mean: 0.11014
[32m[0906 14-11-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01962, current rewards: 133.22030, mean: 0.11010
[32m[0906 14-11-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01961, current rewards: 138.68153, mean: 0.11006
[32m[0906 14-11-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01960, current rewards: 144.14755, mean: 0.11004
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01958, current rewards: 149.61037, mean: 0.11001
[32m[0906 14-11-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01957, current rewards: 155.15982, mean: 0.11004
[32m[0906 14-11-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01956, current rewards: 160.63894, mean: 0.11003
[32m[0906 14-11-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01955, current rewards: 166.06738, mean: 0.10998
[32m[0906 14-11-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01954, current rewards: 171.49791, mean: 0.10993
[32m[0906 14-11-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01953, current rewards: 176.92545, mean: 0.10989
[32m[0906 14-11-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01952, current rewards: 182.35283, mean: 0.10985
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01951, current rewards: 187.78065, mean: 0.10981
[32m[0906 14-11-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01950, current rewards: 193.21026, mean: 0.10978
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01949, current rewards: 198.64374, mean: 0.10975
[32m[0906 14-11-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01948, current rewards: 205.71433, mean: 0.11060
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01947, current rewards: 214.50299, mean: 0.11231
[32m[0906 14-11-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01947, current rewards: 223.29166, mean: 0.11392
[32m[0906 14-11-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01946, current rewards: 232.08032, mean: 0.11546
[32m[0906 14-11-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01946, current rewards: 240.86898, mean: 0.11693
[32m[0906 14-11-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01945, current rewards: 249.65764, mean: 0.11832
[32m[0906 14-11-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01944, current rewards: 258.44630, mean: 0.11965
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01944, current rewards: 265.09644, mean: 0.11995
[32m[0906 14-11-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01943, current rewards: 265.95634, mean: 0.11768
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01942, current rewards: 215.95634, mean: 0.09349
[32m[0906 14-11-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01942, current rewards: 165.95634, mean: 0.07032
[32m[0906 14-11-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01941, current rewards: 115.95634, mean: 0.04811
[32m[0906 14-11-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01940, current rewards: 65.95634, mean: 0.02681
[32m[0906 14-11-47 @Agent.py:117][0m Average action selection time: 0.0194
[32m[0906 14-11-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-11-47 @MBExp.py:227][0m Rewards obtained: [25.956344802137437], Lows: [0], Highs: [243], Total time: 1220.9375520000003
[32m[0906 14-12-45 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-45 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01971, current rewards: 0.98900, mean: 0.09890
[32m[0906 14-12-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02000, current rewards: 6.49650, mean: 0.10828
[32m[0906 14-12-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01996, current rewards: 11.99735, mean: 0.10907
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01980, current rewards: 17.50175, mean: 0.10939
[32m[0906 14-12-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01976, current rewards: 23.00458, mean: 0.10955
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01972, current rewards: 28.50735, mean: 0.10964
[32m[0906 14-12-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01969, current rewards: 34.01539, mean: 0.10973
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01966, current rewards: 39.51580, mean: 0.10977
[32m[0906 14-12-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01966, current rewards: 45.02194, mean: 0.10981
[32m[0906 14-12-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01966, current rewards: 50.52535, mean: 0.10984
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01964, current rewards: 56.05606, mean: 0.10991
[32m[0906 14-12-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01964, current rewards: 61.72686, mean: 0.11023
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01963, current rewards: 67.30729, mean: 0.11034
[32m[0906 14-12-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01963, current rewards: 73.27210, mean: 0.11102
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01964, current rewards: 79.44269, mean: 0.11189
[32m[0906 14-13-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01963, current rewards: 85.61277, mean: 0.11265
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01963, current rewards: 91.78391, mean: 0.11331
[32m[0906 14-13-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01963, current rewards: 97.95654, mean: 0.11390
[32m[0906 14-13-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01960, current rewards: 104.12812, mean: 0.11443
[32m[0906 14-13-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01959, current rewards: 111.22086, mean: 0.11586
[32m[0906 14-13-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01957, current rewards: 119.29515, mean: 0.11811
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01955, current rewards: 113.88680, mean: 0.10744
[32m[0906 14-13-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01954, current rewards: 119.48499, mean: 0.10764
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01952, current rewards: 125.08068, mean: 0.10783
[32m[0906 14-13-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01951, current rewards: 130.68292, mean: 0.10800
[32m[0906 14-13-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01950, current rewards: 136.28556, mean: 0.10816
[32m[0906 14-13-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01948, current rewards: 141.85546, mean: 0.10829
[32m[0906 14-13-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01947, current rewards: 147.26034, mean: 0.10828
[32m[0906 14-13-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01946, current rewards: 152.60835, mean: 0.10823
[32m[0906 14-13-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01946, current rewards: 157.99643, mean: 0.10822
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01946, current rewards: 163.38361, mean: 0.10820
[32m[0906 14-13-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01945, current rewards: 168.76935, mean: 0.10819
[32m[0906 14-13-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01944, current rewards: 174.16063, mean: 0.10817
[32m[0906 14-13-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01943, current rewards: 179.54734, mean: 0.10816
[32m[0906 14-13-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01942, current rewards: 184.92950, mean: 0.10815
[32m[0906 14-13-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01941, current rewards: 190.35454, mean: 0.10816
[32m[0906 14-13-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01940, current rewards: 195.84543, mean: 0.10820
[32m[0906 14-13-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01940, current rewards: 201.35174, mean: 0.10825
[32m[0906 14-13-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01939, current rewards: 206.85644, mean: 0.10830
[32m[0906 14-13-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01938, current rewards: 212.35990, mean: 0.10835
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01937, current rewards: 217.86858, mean: 0.10839
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01937, current rewards: 223.37560, mean: 0.10843
[32m[0906 14-13-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01936, current rewards: 228.87953, mean: 0.10847
[32m[0906 14-13-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01936, current rewards: 234.39541, mean: 0.10852
[32m[0906 14-13-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01936, current rewards: 240.00203, mean: 0.10860
[32m[0906 14-13-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01934, current rewards: 245.56882, mean: 0.10866
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01933, current rewards: 251.13142, mean: 0.10871
[32m[0906 14-13-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01932, current rewards: 256.69555, mean: 0.10877
[32m[0906 14-13-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01932, current rewards: 262.26005, mean: 0.10882
[32m[0906 14-13-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01932, current rewards: 267.82172, mean: 0.10887
[32m[0906 14-13-34 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-13-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-13-34 @MBExp.py:227][0m Rewards obtained: [272.2459755633018], Lows: [0], Highs: [11], Total time: 1269.9181220000003
[32m[0906 14-14-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-14-34 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-14-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01967, current rewards: 1.50777, mean: 0.15078
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01963, current rewards: 7.02899, mean: 0.11715
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01965, current rewards: 12.47362, mean: 0.11340
[32m[0906 14-14-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01962, current rewards: 18.02279, mean: 0.11264
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01963, current rewards: 23.56751, mean: 0.11223
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01963, current rewards: 29.10793, mean: 0.11195
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01962, current rewards: 34.65220, mean: 0.11178
[32m[0906 14-14-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01960, current rewards: 40.23795, mean: 0.11177
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01961, current rewards: 45.74810, mean: 0.11158
[32m[0906 14-14-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01961, current rewards: 51.26351, mean: 0.11144
[32m[0906 14-14-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01961, current rewards: 56.78698, mean: 0.11135
[32m[0906 14-14-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01961, current rewards: 62.33145, mean: 0.11131
[32m[0906 14-14-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01959, current rewards: 67.83975, mean: 0.11121
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01959, current rewards: 73.34372, mean: 0.11113
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01960, current rewards: 78.84946, mean: 0.11106
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01961, current rewards: 84.35543, mean: 0.11099
[32m[0906 14-14-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01959, current rewards: 89.86061, mean: 0.11094
[32m[0906 14-14-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01956, current rewards: 95.47573, mean: 0.11102
[32m[0906 14-14-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01954, current rewards: 100.98584, mean: 0.11097
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01953, current rewards: 106.51245, mean: 0.11095
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01951, current rewards: 111.98111, mean: 0.11087
[32m[0906 14-14-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01949, current rewards: 117.45094, mean: 0.11080
[32m[0906 14-14-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01947, current rewards: 122.91795, mean: 0.11074
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01946, current rewards: 128.38476, mean: 0.11068
[32m[0906 14-14-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01945, current rewards: 133.86013, mean: 0.11063
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01944, current rewards: 139.39475, mean: 0.11063
[32m[0906 14-15-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01942, current rewards: 144.93011, mean: 0.11063
[32m[0906 14-15-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01940, current rewards: 150.42187, mean: 0.11060
[32m[0906 14-15-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01941, current rewards: 155.93911, mean: 0.11060
[32m[0906 14-15-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01939, current rewards: 161.46057, mean: 0.11059
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01938, current rewards: 166.97683, mean: 0.11058
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01938, current rewards: 172.49272, mean: 0.11057
[32m[0906 14-15-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01937, current rewards: 178.00885, mean: 0.11056
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01936, current rewards: 183.52786, mean: 0.11056
[32m[0906 14-15-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01936, current rewards: 189.04447, mean: 0.11055
[32m[0906 14-15-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01935, current rewards: 194.65370, mean: 0.11060
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01934, current rewards: 200.18203, mean: 0.11060
[32m[0906 14-15-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01934, current rewards: 205.70886, mean: 0.11060
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01933, current rewards: 211.23374, mean: 0.11059
[32m[0906 14-15-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01933, current rewards: 216.76238, mean: 0.11059
[32m[0906 14-15-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01933, current rewards: 222.28806, mean: 0.11059
[32m[0906 14-15-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01932, current rewards: 227.81545, mean: 0.11059
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01932, current rewards: 233.34242, mean: 0.11059
[32m[0906 14-15-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01930, current rewards: 238.93423, mean: 0.11062
[32m[0906 14-15-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01928, current rewards: 244.49540, mean: 0.11063
[32m[0906 14-15-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01927, current rewards: 248.88591, mean: 0.11013
[32m[0906 14-15-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01925, current rewards: 254.38299, mean: 0.11012
[32m[0906 14-15-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01925, current rewards: 259.88373, mean: 0.11012
[32m[0906 14-15-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01925, current rewards: 265.38396, mean: 0.11012
[32m[0906 14-15-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01925, current rewards: 270.88551, mean: 0.11012
[32m[0906 14-15-23 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 14-15-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-15-23 @MBExp.py:227][0m Rewards obtained: [275.2835913513005], Lows: [0], Highs: [1], Total time: 1318.7441210000002
[32m[0906 14-16-25 @MBExp.py:144][0m ####################################################################
[32m[0906 14-16-25 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-16-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01984, current rewards: 1.05109, mean: 0.10511
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01950, current rewards: 6.55302, mean: 0.10922
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01959, current rewards: 12.07869, mean: 0.10981
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01961, current rewards: 17.60696, mean: 0.11004
[32m[0906 14-16-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01959, current rewards: 23.13782, mean: 0.11018
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01956, current rewards: 28.66454, mean: 0.11025
[32m[0906 14-16-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01956, current rewards: 34.18977, mean: 0.11029
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01957, current rewards: 39.72478, mean: 0.11035
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01958, current rewards: 45.25515, mean: 0.11038
[32m[0906 14-16-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01959, current rewards: 50.79417, mean: 0.11042
[32m[0906 14-16-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01958, current rewards: 56.31974, mean: 0.11043
[32m[0906 14-16-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01957, current rewards: 61.86987, mean: 0.11048
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01957, current rewards: 67.42436, mean: 0.11053
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01957, current rewards: 72.97405, mean: 0.11057
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01954, current rewards: 78.52879, mean: 0.11060
[32m[0906 14-16-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01952, current rewards: 84.07946, mean: 0.11063
[32m[0906 14-16-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01949, current rewards: 89.63493, mean: 0.11066
[32m[0906 14-16-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01946, current rewards: 95.18350, mean: 0.11068
[32m[0906 14-16-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01944, current rewards: 100.73911, mean: 0.11070
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01943, current rewards: 106.26173, mean: 0.11069
[32m[0906 14-16-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01942, current rewards: 111.78447, mean: 0.11068
[32m[0906 14-16-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01941, current rewards: 117.30394, mean: 0.11066
[32m[0906 14-16-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01939, current rewards: 122.82159, mean: 0.11065
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01938, current rewards: 128.34104, mean: 0.11064
[32m[0906 14-16-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01936, current rewards: 133.85884, mean: 0.11063
[32m[0906 14-16-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01935, current rewards: 139.38252, mean: 0.11062
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01935, current rewards: 144.90692, mean: 0.11062
[32m[0906 14-16-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01934, current rewards: 150.42591, mean: 0.11061
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01933, current rewards: 155.94544, mean: 0.11060
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01933, current rewards: 161.46261, mean: 0.11059
[32m[0906 14-16-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01932, current rewards: 166.98369, mean: 0.11059
[32m[0906 14-16-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01932, current rewards: 172.50258, mean: 0.11058
[32m[0906 14-16-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01932, current rewards: 178.01536, mean: 0.11057
[32m[0906 14-16-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01931, current rewards: 183.52865, mean: 0.11056
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01931, current rewards: 189.04080, mean: 0.11055
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01930, current rewards: 194.55853, mean: 0.11054
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01930, current rewards: 200.07498, mean: 0.11054
[32m[0906 14-17-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01929, current rewards: 205.89251, mean: 0.11069
[32m[0906 14-17-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01929, current rewards: 211.45066, mean: 0.11071
[32m[0906 14-17-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01929, current rewards: 216.99892, mean: 0.11071
[32m[0906 14-17-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 222.55094, mean: 0.11072
[32m[0906 14-17-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01926, current rewards: 228.10494, mean: 0.11073
[32m[0906 14-17-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01924, current rewards: 233.69552, mean: 0.11076
[32m[0906 14-17-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01923, current rewards: 239.24148, mean: 0.11076
[32m[0906 14-17-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01921, current rewards: 244.78831, mean: 0.11076
[32m[0906 14-17-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01919, current rewards: 250.33554, mean: 0.11077
[32m[0906 14-17-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01918, current rewards: 255.88954, mean: 0.11077
[32m[0906 14-17-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01918, current rewards: 259.35829, mean: 0.10990
[32m[0906 14-17-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 264.93895, mean: 0.10993
[32m[0906 14-17-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01918, current rewards: 270.52137, mean: 0.10997
[32m[0906 14-17-13 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-17-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-17-14 @MBExp.py:227][0m Rewards obtained: [275.31831949086245], Lows: [1], Highs: [0], Total time: 1367.3842640000003
[32m[0906 14-18-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-18 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-18-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01984, current rewards: 1.10515, mean: 0.11051
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01999, current rewards: 8.21001, mean: 0.13683
[32m[0906 14-18-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01983, current rewards: 15.86509, mean: 0.14423
[32m[0906 14-18-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01979, current rewards: 23.52017, mean: 0.14700
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01975, current rewards: 31.17525, mean: 0.14845
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01978, current rewards: 38.83033, mean: 0.14935
[32m[0906 14-18-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01977, current rewards: 46.48542, mean: 0.14995
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01972, current rewards: 54.14050, mean: 0.15039
[32m[0906 14-18-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01969, current rewards: 40.30821, mean: 0.09831
[32m[0906 14-18-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01968, current rewards: 45.83765, mean: 0.09965
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01966, current rewards: 51.38042, mean: 0.10075
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01965, current rewards: 56.92107, mean: 0.10164
[32m[0906 14-18-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01959, current rewards: 62.46205, mean: 0.10240
[32m[0906 14-18-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01956, current rewards: 68.00304, mean: 0.10303
[32m[0906 14-18-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01955, current rewards: 73.54734, mean: 0.10359
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01953, current rewards: 79.08830, mean: 0.10406
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01950, current rewards: 84.63073, mean: 0.10448
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01948, current rewards: 90.07065, mean: 0.10473
[32m[0906 14-18-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01945, current rewards: 95.59695, mean: 0.10505
[32m[0906 14-18-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01943, current rewards: 101.12399, mean: 0.10534
[32m[0906 14-18-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01942, current rewards: 106.65287, mean: 0.10560
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01941, current rewards: 112.18257, mean: 0.10583
[32m[0906 14-18-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01940, current rewards: 117.71507, mean: 0.10605
[32m[0906 14-18-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01938, current rewards: 123.24205, mean: 0.10624
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01937, current rewards: 128.78839, mean: 0.10644
[32m[0906 14-18-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01937, current rewards: 134.33660, mean: 0.10662
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01936, current rewards: 139.88214, mean: 0.10678
[32m[0906 14-18-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01935, current rewards: 145.42409, mean: 0.10693
[32m[0906 14-18-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01936, current rewards: 150.97076, mean: 0.10707
[32m[0906 14-18-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01936, current rewards: 156.52093, mean: 0.10721
[32m[0906 14-18-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01935, current rewards: 162.07643, mean: 0.10734
[32m[0906 14-18-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01935, current rewards: 167.61774, mean: 0.10745
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01934, current rewards: 173.16613, mean: 0.10756
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01934, current rewards: 178.61271, mean: 0.10760
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01933, current rewards: 184.14776, mean: 0.10769
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01933, current rewards: 189.68689, mean: 0.10778
[32m[0906 14-18-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01933, current rewards: 195.22052, mean: 0.10786
[32m[0906 14-18-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01933, current rewards: 200.76140, mean: 0.10794
[32m[0906 14-18-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01932, current rewards: 206.29399, mean: 0.10801
[32m[0906 14-18-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01930, current rewards: 211.83458, mean: 0.10808
[32m[0906 14-18-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01928, current rewards: 217.38203, mean: 0.10815
[32m[0906 14-18-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01926, current rewards: 222.92324, mean: 0.10822
[32m[0906 14-18-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01925, current rewards: 228.46638, mean: 0.10828
[32m[0906 14-19-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01924, current rewards: 234.00711, mean: 0.10834
[32m[0906 14-19-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01922, current rewards: 239.55300, mean: 0.10840
[32m[0906 14-19-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01920, current rewards: 245.09705, mean: 0.10845
[32m[0906 14-19-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01919, current rewards: 250.61759, mean: 0.10849
[32m[0906 14-19-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01919, current rewards: 256.15500, mean: 0.10854
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01918, current rewards: 261.69127, mean: 0.10859
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01918, current rewards: 267.28057, mean: 0.10865
[32m[0906 14-19-07 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 14-19-07 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-19-07 @MBExp.py:227][0m Rewards obtained: [271.71690852119156], Lows: [0], Highs: [18], Total time: 1416.0062230000003
[32m[0906 14-20-13 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-13 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-20-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01938, current rewards: -0.49995, mean: -0.04999
[32m[0906 14-20-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01936, current rewards: 7.80017, mean: 0.13000
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01944, current rewards: 16.10030, mean: 0.14637
[32m[0906 14-20-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01945, current rewards: 24.40042, mean: 0.15250
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01947, current rewards: 32.70054, mean: 0.15572
[32m[0906 14-20-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01946, current rewards: 41.00066, mean: 0.15769
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01947, current rewards: 3.82669, mean: 0.01234
[32m[0906 14-20-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01948, current rewards: -46.17331, mean: -0.12826
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01952, current rewards: -57.36449, mean: -0.13991
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01952, current rewards: -51.81239, mean: -0.11264
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01946, current rewards: -46.25800, mean: -0.09070
[32m[0906 14-20-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01942, current rewards: -40.69438, mean: -0.07267
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01940, current rewards: -35.13677, mean: -0.05760
[32m[0906 14-20-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01939, current rewards: -29.58461, mean: -0.04483
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01938, current rewards: -24.02394, mean: -0.03384
[32m[0906 14-20-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01937, current rewards: -18.47296, mean: -0.02431
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01936, current rewards: -12.81811, mean: -0.01582
[32m[0906 14-20-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01934, current rewards: -7.26141, mean: -0.00844
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01932, current rewards: -1.70241, mean: -0.00187
[32m[0906 14-20-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01930, current rewards: 3.85424, mean: 0.00401
[32m[0906 14-20-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01929, current rewards: 9.41486, mean: 0.00932
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01929, current rewards: 14.97503, mean: 0.01413
[32m[0906 14-20-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01927, current rewards: 20.54121, mean: 0.01851
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01927, current rewards: 26.12273, mean: 0.02252
[32m[0906 14-20-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01927, current rewards: 31.70246, mean: 0.02620
[32m[0906 14-20-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01926, current rewards: 37.23196, mean: 0.02955
[32m[0906 14-20-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01926, current rewards: 42.81555, mean: 0.03268
[32m[0906 14-20-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01925, current rewards: 48.39575, mean: 0.03559
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01924, current rewards: 54.12332, mean: 0.03839
[32m[0906 14-20-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01924, current rewards: 59.78144, mean: 0.04095
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01923, current rewards: 65.43435, mean: 0.04333
[32m[0906 14-20-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01923, current rewards: 71.08912, mean: 0.04557
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01923, current rewards: 76.74559, mean: 0.04767
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01922, current rewards: 82.33661, mean: 0.04960
[32m[0906 14-20-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01922, current rewards: 87.98861, mean: 0.05146
[32m[0906 14-20-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01922, current rewards: 93.63398, mean: 0.05320
[32m[0906 14-20-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 99.28140, mean: 0.05485
[32m[0906 14-20-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01919, current rewards: 104.92318, mean: 0.05641
[32m[0906 14-20-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01917, current rewards: 110.57041, mean: 0.05789
[32m[0906 14-20-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 116.22313, mean: 0.05930
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 121.76171, mean: 0.06058
[32m[0906 14-20-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01913, current rewards: 127.33214, mean: 0.06181
[32m[0906 14-20-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 132.89772, mean: 0.06298
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01910, current rewards: 138.46825, mean: 0.06411
[32m[0906 14-20-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: 144.03588, mean: 0.06517
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: 149.60240, mean: 0.06620
[32m[0906 14-20-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01907, current rewards: 155.16855, mean: 0.06717
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01906, current rewards: 160.72948, mean: 0.06811
[32m[0906 14-21-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01906, current rewards: 166.29690, mean: 0.06900
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01906, current rewards: 171.90500, mean: 0.06988
[32m[0906 14-21-02 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 14-21-02 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-21-02 @MBExp.py:227][0m Rewards obtained: [176.34880079366627], Lows: [1], Highs: [104], Total time: 1464.3576930000004
[32m[0906 14-22-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-22-11 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-22-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01922, current rewards: 1.05208, mean: 0.10521
[32m[0906 14-22-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01957, current rewards: 6.61476, mean: 0.11025
[32m[0906 14-22-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01965, current rewards: 12.18278, mean: 0.11075
[32m[0906 14-22-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01959, current rewards: 17.75381, mean: 0.11096
[32m[0906 14-22-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01958, current rewards: 23.32146, mean: 0.11105
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01955, current rewards: 28.88636, mean: 0.11110
[32m[0906 14-22-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01955, current rewards: 34.44409, mean: 0.11111
[32m[0906 14-22-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01957, current rewards: 40.06743, mean: 0.11130
[32m[0906 14-22-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01949, current rewards: 45.62849, mean: 0.11129
[32m[0906 14-22-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01944, current rewards: 51.19152, mean: 0.11129
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01941, current rewards: 56.76426, mean: 0.11130
[32m[0906 14-22-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01940, current rewards: 62.32803, mean: 0.11130
[32m[0906 14-22-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01938, current rewards: 67.93411, mean: 0.11137
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01936, current rewards: 73.51900, mean: 0.11139
[32m[0906 14-22-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01935, current rewards: 79.10314, mean: 0.11141
[32m[0906 14-22-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01934, current rewards: 84.71619, mean: 0.11147
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01933, current rewards: 90.29324, mean: 0.11147
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01932, current rewards: 95.87066, mean: 0.11148
[32m[0906 14-22-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01932, current rewards: 102.04342, mean: 0.11214
[32m[0906 14-22-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01931, current rewards: 108.22110, mean: 0.11273
[32m[0906 14-22-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01932, current rewards: 114.39878, mean: 0.11327
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01931, current rewards: 120.57646, mean: 0.11375
[32m[0906 14-22-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01930, current rewards: 126.75414, mean: 0.11419
[32m[0906 14-22-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01929, current rewards: 132.93182, mean: 0.11460
[32m[0906 14-22-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01929, current rewards: 105.48303, mean: 0.08718
[32m[0906 14-22-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01928, current rewards: 55.48303, mean: 0.04403
[32m[0906 14-22-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01928, current rewards: 5.48303, mean: 0.00419
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01928, current rewards: -44.51697, mean: -0.03273
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01928, current rewards: -94.51697, mean: -0.06703
[32m[0906 14-22-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01927, current rewards: -144.51697, mean: -0.09898
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01927, current rewards: -194.51697, mean: -0.12882
[32m[0906 14-22-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01926, current rewards: -244.51697, mean: -0.15674
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01926, current rewards: -294.51697, mean: -0.18293
[32m[0906 14-22-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01926, current rewards: -344.51697, mean: -0.20754
[32m[0906 14-22-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01924, current rewards: -394.51697, mean: -0.23071
[32m[0906 14-22-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01922, current rewards: -444.51697, mean: -0.25257
[32m[0906 14-22-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: -494.51697, mean: -0.27321
[32m[0906 14-22-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: -544.51697, mean: -0.29275
[32m[0906 14-22-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: -594.51697, mean: -0.31127
[32m[0906 14-22-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: -644.51697, mean: -0.32884
[32m[0906 14-22-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01913, current rewards: -694.51697, mean: -0.34553
[32m[0906 14-22-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01911, current rewards: -744.51697, mean: -0.36142
[32m[0906 14-22-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01910, current rewards: -794.51697, mean: -0.37655
[32m[0906 14-22-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: -844.51697, mean: -0.39098
[32m[0906 14-22-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01908, current rewards: -894.51697, mean: -0.40476
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01907, current rewards: -944.51697, mean: -0.41793
[32m[0906 14-22-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01906, current rewards: -994.51697, mean: -0.43053
[32m[0906 14-22-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01905, current rewards: -1044.51697, mean: -0.44259
[32m[0906 14-22-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01904, current rewards: -1094.51697, mean: -0.45416
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01904, current rewards: -1144.51697, mean: -0.46525
[32m[0906 14-22-59 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-22-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-22-59 @MBExp.py:227][0m Rewards obtained: [-1184.5169653555108], Lows: [0], Highs: [1319], Total time: 1512.6509730000005
[32m[0906 14-24-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-10 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-24-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: 1.13440, mean: 0.11344
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01948, current rewards: 6.58635, mean: 0.10977
[32m[0906 14-24-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01955, current rewards: 12.16886, mean: 0.11063
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01947, current rewards: 17.74843, mean: 0.11093
[32m[0906 14-24-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01950, current rewards: 23.32903, mean: 0.11109
[32m[0906 14-24-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01953, current rewards: 28.91434, mean: 0.11121
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01945, current rewards: 34.49508, mean: 0.11127
[32m[0906 14-24-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01940, current rewards: 40.07979, mean: 0.11133
[32m[0906 14-24-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01936, current rewards: 45.65670, mean: 0.11136
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01934, current rewards: 51.24094, mean: 0.11139
[32m[0906 14-24-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01930, current rewards: 56.82700, mean: 0.11143
[32m[0906 14-24-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01928, current rewards: 62.41502, mean: 0.11146
[32m[0906 14-24-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01926, current rewards: 67.99717, mean: 0.11147
[32m[0906 14-24-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01925, current rewards: 73.57960, mean: 0.11148
[32m[0906 14-24-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: 79.16804, mean: 0.11150
[32m[0906 14-24-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01923, current rewards: 84.75069, mean: 0.11151
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: 90.37433, mean: 0.11157
[32m[0906 14-24-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01922, current rewards: 95.94534, mean: 0.11156
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: 101.52887, mean: 0.11157
[32m[0906 14-24-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01919, current rewards: 107.11002, mean: 0.11157
[32m[0906 14-24-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01919, current rewards: 112.69696, mean: 0.11158
[32m[0906 14-24-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 118.27701, mean: 0.11158
[32m[0906 14-24-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 123.85985, mean: 0.11159
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: 129.44840, mean: 0.11159
[32m[0906 14-24-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 135.12548, mean: 0.11167
[32m[0906 14-24-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01918, current rewards: 140.68788, mean: 0.11166
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: 146.25216, mean: 0.11164
[32m[0906 14-24-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01917, current rewards: 151.81793, mean: 0.11163
[32m[0906 14-24-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 157.38004, mean: 0.11162
[32m[0906 14-24-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01917, current rewards: 162.94782, mean: 0.11161
[32m[0906 14-24-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01917, current rewards: 168.52646, mean: 0.11161
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 174.14310, mean: 0.11163
[32m[0906 14-24-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01915, current rewards: 179.72720, mean: 0.11163
[32m[0906 14-24-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01912, current rewards: 185.24551, mean: 0.11159
[32m[0906 14-24-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 190.81734, mean: 0.11159
[32m[0906 14-24-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01909, current rewards: 196.38470, mean: 0.11158
[32m[0906 14-24-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01908, current rewards: 201.96135, mean: 0.11158
[32m[0906 14-24-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 207.53095, mean: 0.11158
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01905, current rewards: 213.10553, mean: 0.11157
[32m[0906 14-24-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01904, current rewards: 218.67390, mean: 0.11157
[32m[0906 14-24-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01903, current rewards: 224.24211, mean: 0.11156
[32m[0906 14-24-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01902, current rewards: 229.86595, mean: 0.11159
[32m[0906 14-24-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01901, current rewards: 235.45966, mean: 0.11159
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01900, current rewards: 241.05276, mean: 0.11160
[32m[0906 14-24-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01899, current rewards: 246.64364, mean: 0.11160
[32m[0906 14-24-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01898, current rewards: 252.21312, mean: 0.11160
[32m[0906 14-24-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01897, current rewards: 257.77374, mean: 0.11159
[32m[0906 14-24-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01897, current rewards: 263.32968, mean: 0.11158
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01896, current rewards: 268.89035, mean: 0.11157
[32m[0906 14-24-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01897, current rewards: 274.48799, mean: 0.11158
[32m[0906 14-24-58 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 14-24-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-24-58 @MBExp.py:227][0m Rewards obtained: [278.9351737504], Lows: [0], Highs: [0], Total time: 1560.7607060000005
[32m[0906 14-26-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-12 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01985, current rewards: 1.09807, mean: 0.10981
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01966, current rewards: 6.72007, mean: 0.11200
[32m[0906 14-26-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01962, current rewards: 12.26145, mean: 0.11147
[32m[0906 14-26-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01962, current rewards: 17.79704, mean: 0.11123
[32m[0906 14-26-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01947, current rewards: 23.33867, mean: 0.11114
[32m[0906 14-26-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01943, current rewards: 30.58901, mean: 0.11765
[32m[0906 14-26-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01939, current rewards: 38.88913, mean: 0.12545
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01936, current rewards: 47.18925, mean: 0.13108
[32m[0906 14-26-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01935, current rewards: 53.18713, mean: 0.12972
[32m[0906 14-26-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01931, current rewards: 58.33278, mean: 0.12681
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01928, current rewards: 63.47843, mean: 0.12447
[32m[0906 14-26-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01926, current rewards: 68.62407, mean: 0.12254
[32m[0906 14-26-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01925, current rewards: 66.04933, mean: 0.10828
[32m[0906 14-26-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01924, current rewards: 16.04933, mean: 0.02432
[32m[0906 14-26-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01924, current rewards: -33.95067, mean: -0.04782
[32m[0906 14-26-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01924, current rewards: -83.95067, mean: -0.11046
[32m[0906 14-26-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01922, current rewards: -133.95067, mean: -0.16537
[32m[0906 14-26-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: -183.95067, mean: -0.21390
[32m[0906 14-26-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01921, current rewards: -233.95067, mean: -0.25709
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: -283.95067, mean: -0.29578
[32m[0906 14-26-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01920, current rewards: -333.95067, mean: -0.33064
[32m[0906 14-26-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: -383.95067, mean: -0.36222
[32m[0906 14-26-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: -433.95067, mean: -0.39095
[32m[0906 14-26-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01918, current rewards: -483.95067, mean: -0.41720
[32m[0906 14-26-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: -533.95067, mean: -0.44128
[32m[0906 14-26-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01917, current rewards: -583.95067, mean: -0.46345
[32m[0906 14-26-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: -633.95067, mean: -0.48393
[32m[0906 14-26-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01917, current rewards: -683.95067, mean: -0.50290
[32m[0906 14-26-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: -733.95067, mean: -0.52053
[32m[0906 14-26-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01916, current rewards: -783.95067, mean: -0.53695
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01914, current rewards: -833.95067, mean: -0.55229
[32m[0906 14-26-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: -883.95067, mean: -0.56664
[32m[0906 14-26-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: -933.95067, mean: -0.58009
[32m[0906 14-26-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01909, current rewards: -983.95067, mean: -0.59274
[32m[0906 14-26-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01907, current rewards: -1033.95067, mean: -0.60465
[32m[0906 14-26-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: -1083.95067, mean: -0.61588
[32m[0906 14-26-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01904, current rewards: -1133.95067, mean: -0.62649
[32m[0906 14-26-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: -1183.95067, mean: -0.63653
[32m[0906 14-26-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01901, current rewards: -1233.95067, mean: -0.64605
[32m[0906 14-26-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01900, current rewards: -1283.95067, mean: -0.65508
[32m[0906 14-26-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01899, current rewards: -1333.95067, mean: -0.66366
[32m[0906 14-26-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: -1383.95067, mean: -0.67182
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01896, current rewards: -1433.95067, mean: -0.67960
[32m[0906 14-26-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: -1483.95067, mean: -0.68701
[32m[0906 14-26-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: -1533.95067, mean: -0.69410
[32m[0906 14-26-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: -1583.95067, mean: -0.70086
[32m[0906 14-26-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: -1633.95067, mean: -0.70734
[32m[0906 14-26-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: -1683.95067, mean: -0.71354
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: -1733.95067, mean: -0.71948
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: -1783.95067, mean: -0.72518
[32m[0906 14-27-00 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-27-00 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-27-00 @MBExp.py:227][0m Rewards obtained: [-1823.9506667412275], Lows: [0], Highs: [1897], Total time: 1608.7623170000004
[32m[0906 14-28-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-28-15 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-28-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01951, current rewards: 1.10459, mean: 0.11046
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01970, current rewards: 6.75559, mean: 0.11259
[32m[0906 14-28-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01935, current rewards: 12.40599, mean: 0.11278
[32m[0906 14-28-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01929, current rewards: 18.05656, mean: 0.11285
[32m[0906 14-28-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01927, current rewards: 23.70979, mean: 0.11290
[32m[0906 14-28-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01926, current rewards: 29.36011, mean: 0.11292
[32m[0906 14-28-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01923, current rewards: 35.01185, mean: 0.11294
[32m[0906 14-28-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01919, current rewards: 40.63250, mean: 0.11287
[32m[0906 14-28-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01918, current rewards: 46.24494, mean: 0.11279
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 51.85606, mean: 0.11273
[32m[0906 14-28-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.34766, mean: 0.11049
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01918, current rewards: 61.96217, mean: 0.11065
[32m[0906 14-28-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 67.58152, mean: 0.11079
[32m[0906 14-28-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 73.20141, mean: 0.11091
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 78.82034, mean: 0.11101
[32m[0906 14-28-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 84.43541, mean: 0.11110
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 90.01441, mean: 0.11113
[32m[0906 14-28-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 95.55598, mean: 0.11111
[32m[0906 14-28-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 101.09779, mean: 0.11110
[32m[0906 14-28-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 106.64405, mean: 0.11109
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 112.18589, mean: 0.11108
[32m[0906 14-28-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 117.73502, mean: 0.11107
[32m[0906 14-28-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 123.33116, mean: 0.11111
[32m[0906 14-28-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: 128.87577, mean: 0.11110
[32m[0906 14-28-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 134.40502, mean: 0.11108
[32m[0906 14-28-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 139.94235, mean: 0.11107
[32m[0906 14-28-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 145.47361, mean: 0.11105
[32m[0906 14-28-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 151.00937, mean: 0.11104
[32m[0906 14-28-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 156.61699, mean: 0.11108
[32m[0906 14-28-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 162.18556, mean: 0.11109
[32m[0906 14-28-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01909, current rewards: 167.76210, mean: 0.11110
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01907, current rewards: 173.33122, mean: 0.11111
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01905, current rewards: 178.91136, mean: 0.11113
[32m[0906 14-28-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: 184.41808, mean: 0.11110
[32m[0906 14-28-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01902, current rewards: 190.05994, mean: 0.11115
[32m[0906 14-28-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: 195.71608, mean: 0.11120
[32m[0906 14-28-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01899, current rewards: 201.37238, mean: 0.11126
[32m[0906 14-28-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01898, current rewards: 207.03042, mean: 0.11131
[32m[0906 14-28-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01896, current rewards: 212.68516, mean: 0.11135
[32m[0906 14-28-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01895, current rewards: 218.34167, mean: 0.11140
[32m[0906 14-28-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01894, current rewards: 224.00082, mean: 0.11144
[32m[0906 14-28-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01893, current rewards: 229.58811, mean: 0.11145
[32m[0906 14-28-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 235.08770, mean: 0.11142
[32m[0906 14-28-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: 240.59180, mean: 0.11139
[32m[0906 14-28-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01890, current rewards: 246.09523, mean: 0.11136
[32m[0906 14-28-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 251.59388, mean: 0.11132
[32m[0906 14-29-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: 257.10266, mean: 0.11130
[32m[0906 14-29-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 262.60788, mean: 0.11127
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: 268.11360, mean: 0.11125
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 273.62393, mean: 0.11123
[32m[0906 14-29-03 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-29-03 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-29-03 @MBExp.py:227][0m Rewards obtained: [278.0275989723062], Lows: [0], Highs: [1], Total time: 1656.7126000000003
[32m[0906 14-30-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-30-21 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-30-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01949, current rewards: 0.99093, mean: 0.09909
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 6.40247, mean: 0.10671
[32m[0906 14-30-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 11.84747, mean: 0.10770
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.29556, mean: 0.10810
[32m[0906 14-30-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 22.74091, mean: 0.10829
[32m[0906 14-30-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 28.18642, mean: 0.10841
[32m[0906 14-30-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 33.63194, mean: 0.10849
[32m[0906 14-30-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 39.07625, mean: 0.10855
[32m[0906 14-30-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 44.52274, mean: 0.10859
[32m[0906 14-30-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 49.96610, mean: 0.10862
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 55.41364, mean: 0.10865
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01916, current rewards: 60.86034, mean: 0.10868
[32m[0906 14-30-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 66.30560, mean: 0.10870
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 71.75034, mean: 0.10871
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 77.33742, mean: 0.10893
[32m[0906 14-30-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 83.05060, mean: 0.10928
[32m[0906 14-30-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 88.72767, mean: 0.10954
[32m[0906 14-30-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 45.40891, mean: 0.05280
[32m[0906 14-30-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: -4.59109, mean: -0.00505
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: -54.59109, mean: -0.05687
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: -104.59109, mean: -0.10356
[32m[0906 14-30-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: -154.59109, mean: -0.14584
[32m[0906 14-30-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: -204.59109, mean: -0.18432
[32m[0906 14-30-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01916, current rewards: -254.59109, mean: -0.21948
[32m[0906 14-30-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: -304.59109, mean: -0.25173
[32m[0906 14-30-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: -354.59109, mean: -0.28142
[32m[0906 14-30-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: -404.59109, mean: -0.30885
[32m[0906 14-30-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01909, current rewards: -454.59109, mean: -0.33426
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01907, current rewards: -504.59109, mean: -0.35787
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01905, current rewards: -554.59109, mean: -0.37986
[32m[0906 14-30-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: -604.59109, mean: -0.40039
[32m[0906 14-30-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01901, current rewards: -654.59109, mean: -0.41961
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: -704.59109, mean: -0.43763
[32m[0906 14-30-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01898, current rewards: -754.59109, mean: -0.45457
[32m[0906 14-30-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01897, current rewards: -804.59109, mean: -0.47052
[32m[0906 14-30-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01896, current rewards: -854.59109, mean: -0.48556
[32m[0906 14-30-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01895, current rewards: -904.59109, mean: -0.49977
[32m[0906 14-30-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01893, current rewards: -954.59109, mean: -0.51322
[32m[0906 14-30-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01892, current rewards: -1004.59109, mean: -0.52596
[32m[0906 14-30-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01892, current rewards: -1054.59109, mean: -0.53806
[32m[0906 14-31-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01891, current rewards: -1104.59109, mean: -0.54955
[32m[0906 14-31-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01890, current rewards: -1154.59109, mean: -0.56048
[32m[0906 14-31-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: -1204.59109, mean: -0.57090
[32m[0906 14-31-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: -1254.59109, mean: -0.58083
[32m[0906 14-31-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01887, current rewards: -1304.59109, mean: -0.59031
[32m[0906 14-31-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: -1354.59109, mean: -0.59938
[32m[0906 14-31-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: -1404.59109, mean: -0.60805
[32m[0906 14-31-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01887, current rewards: -1454.59109, mean: -0.61635
[32m[0906 14-31-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: -1504.59109, mean: -0.62431
[32m[0906 14-31-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01888, current rewards: -1554.59109, mean: -0.63195
[32m[0906 14-31-09 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-31-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-31-09 @MBExp.py:227][0m Rewards obtained: [-1594.5910863638608], Lows: [0], Highs: [1684], Total time: 1704.6274560000004
[32m[0906 14-32-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-32-29 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-32-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01870, current rewards: 0.06604, mean: 0.00660
[32m[0906 14-32-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01927, current rewards: 5.68731, mean: 0.09479
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01916, current rewards: 11.25497, mean: 0.10232
[32m[0906 14-32-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 16.82069, mean: 0.10513
[32m[0906 14-32-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 22.38724, mean: 0.10661
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 27.95203, mean: 0.10751
[32m[0906 14-32-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01916, current rewards: 33.52886, mean: 0.10816
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 39.11805, mean: 0.10866
[32m[0906 14-32-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 44.66235, mean: 0.10893
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 50.21498, mean: 0.10916
[32m[0906 14-32-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 55.76143, mean: 0.10934
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 61.31991, mean: 0.10950
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 66.87493, mean: 0.10963
[32m[0906 14-32-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 72.42876, mean: 0.10974
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 77.96573, mean: 0.10981
[32m[0906 14-32-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 83.52576, mean: 0.10990
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: 89.08661, mean: 0.10998
[32m[0906 14-32-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 94.64984, mean: 0.11006
[32m[0906 14-32-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 100.21260, mean: 0.11012
[32m[0906 14-32-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01917, current rewards: 105.77593, mean: 0.11018
[32m[0906 14-32-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01917, current rewards: 111.33828, mean: 0.11024
[32m[0906 14-32-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01917, current rewards: 116.90417, mean: 0.11029
[32m[0906 14-32-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01917, current rewards: 122.46538, mean: 0.11033
[32m[0906 14-32-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 127.37734, mean: 0.10981
[32m[0906 14-32-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 135.67746, mean: 0.11213
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 143.97758, mean: 0.11427
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01906, current rewards: 152.27770, mean: 0.11624
[32m[0906 14-32-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 160.57782, mean: 0.11807
[32m[0906 14-32-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01903, current rewards: 168.87794, mean: 0.11977
[32m[0906 14-32-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01901, current rewards: 177.17806, mean: 0.12135
[32m[0906 14-32-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01900, current rewards: 185.47818, mean: 0.12283
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01898, current rewards: 186.29185, mean: 0.11942
[32m[0906 14-33-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01898, current rewards: 136.29185, mean: 0.08465
[32m[0906 14-33-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01896, current rewards: 86.29185, mean: 0.05198
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01895, current rewards: 36.29185, mean: 0.02122
[32m[0906 14-33-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01894, current rewards: -13.70815, mean: -0.00779
[32m[0906 14-33-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01893, current rewards: -63.70815, mean: -0.03520
[32m[0906 14-33-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01892, current rewards: -113.70815, mean: -0.06113
[32m[0906 14-33-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01891, current rewards: -163.70815, mean: -0.08571
[32m[0906 14-33-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01890, current rewards: -213.70815, mean: -0.10903
[32m[0906 14-33-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: -263.70815, mean: -0.13120
[32m[0906 14-33-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: -313.70815, mean: -0.15229
[32m[0906 14-33-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: -331.45762, mean: -0.15709
[32m[0906 14-33-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01886, current rewards: -325.88382, mean: -0.15087
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: -320.31074, mean: -0.14494
[32m[0906 14-33-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: -314.74378, mean: -0.13927
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: -309.18990, mean: -0.13385
[32m[0906 14-33-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: -303.70566, mean: -0.12869
[32m[0906 14-33-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01888, current rewards: -298.12777, mean: -0.12370
[32m[0906 14-33-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: -292.54584, mean: -0.11892
[32m[0906 14-33-17 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-33-17 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-33-17 @MBExp.py:227][0m Rewards obtained: [-288.08138229528805], Lows: [1], Highs: [527], Total time: 1752.5580430000005
[32m[0906 14-34-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-39 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-34-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01953, current rewards: 1.08986, mean: 0.10899
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01924, current rewards: 6.61844, mean: 0.11031
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01928, current rewards: 12.14831, mean: 0.11044
[32m[0906 14-34-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01920, current rewards: 17.67684, mean: 0.11048
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01921, current rewards: 23.20627, mean: 0.11051
[32m[0906 14-34-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01922, current rewards: 28.73093, mean: 0.11050
[32m[0906 14-34-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01921, current rewards: 34.23882, mean: 0.11045
[32m[0906 14-34-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01922, current rewards: 39.76582, mean: 0.11046
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01922, current rewards: 45.29478, mean: 0.11048
[32m[0906 14-34-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 50.81816, mean: 0.11047
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01920, current rewards: 56.34759, mean: 0.11049
[32m[0906 14-34-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 61.87376, mean: 0.11049
[32m[0906 14-34-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 66.28251, mean: 0.10866
[32m[0906 14-34-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01918, current rewards: 71.76751, mean: 0.10874
[32m[0906 14-34-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 77.27012, mean: 0.10883
[32m[0906 14-34-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01919, current rewards: 82.75169, mean: 0.10888
[32m[0906 14-34-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01919, current rewards: 88.24097, mean: 0.10894
[32m[0906 14-34-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01918, current rewards: 93.74260, mean: 0.10900
[32m[0906 14-34-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 99.27377, mean: 0.10909
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 104.80802, mean: 0.10918
[32m[0906 14-34-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01917, current rewards: 110.33800, mean: 0.10925
[32m[0906 14-35-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 115.87570, mean: 0.10932
[32m[0906 14-35-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 121.45442, mean: 0.10942
[32m[0906 14-35-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 127.00497, mean: 0.10949
[32m[0906 14-35-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 132.54859, mean: 0.10954
[32m[0906 14-35-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 138.08938, mean: 0.10959
[32m[0906 14-35-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01904, current rewards: 143.63230, mean: 0.10964
[32m[0906 14-35-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 149.18000, mean: 0.10969
[32m[0906 14-35-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01901, current rewards: 154.71815, mean: 0.10973
[32m[0906 14-35-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01899, current rewards: 160.26816, mean: 0.10977
[32m[0906 14-35-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01898, current rewards: 165.76621, mean: 0.10978
[32m[0906 14-35-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01897, current rewards: 171.29727, mean: 0.10981
[32m[0906 14-35-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01896, current rewards: 176.83498, mean: 0.10984
[32m[0906 14-35-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01895, current rewards: 182.36576, mean: 0.10986
[32m[0906 14-35-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01895, current rewards: 187.90112, mean: 0.10988
[32m[0906 14-35-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01894, current rewards: 193.43904, mean: 0.10991
[32m[0906 14-35-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01893, current rewards: 198.97648, mean: 0.10993
[32m[0906 14-35-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01892, current rewards: 204.51182, mean: 0.10995
[32m[0906 14-35-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01891, current rewards: 210.07133, mean: 0.10998
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01890, current rewards: 215.61306, mean: 0.11001
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 221.14979, mean: 0.11002
[32m[0906 14-35-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 226.65813, mean: 0.11003
[32m[0906 14-35-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: 232.17067, mean: 0.11003
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 237.69282, mean: 0.11004
[32m[0906 14-35-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 243.20814, mean: 0.11005
[32m[0906 14-35-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 248.72684, mean: 0.11006
[32m[0906 14-35-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01889, current rewards: 254.24444, mean: 0.11006
[32m[0906 14-35-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01890, current rewards: 259.75878, mean: 0.11007
[32m[0906 14-35-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 265.27524, mean: 0.11007
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 270.83226, mean: 0.11009
[32m[0906 14-35-27 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-35-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-35-27 @MBExp.py:227][0m Rewards obtained: [275.2604096369581], Lows: [0], Highs: [1], Total time: 1800.5609480000005
[32m[0906 14-36-51 @MBExp.py:144][0m ####################################################################
[32m[0906 14-36-51 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-36-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01892, current rewards: 1.31720, mean: 0.13172
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 7.11243, mean: 0.11854
[32m[0906 14-36-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 12.90766, mean: 0.11734
[32m[0906 14-36-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01903, current rewards: 18.70290, mean: 0.11689
[32m[0906 14-36-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01905, current rewards: 24.19901, mean: 0.11523
[32m[0906 14-36-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 29.73368, mean: 0.11436
[32m[0906 14-36-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 35.23646, mean: 0.11367
[32m[0906 14-36-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01911, current rewards: 40.74329, mean: 0.11318
[32m[0906 14-36-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 46.25345, mean: 0.11281
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 51.76235, mean: 0.11253
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 57.27262, mean: 0.11230
[32m[0906 14-37-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01913, current rewards: 62.78509, mean: 0.11212
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 68.29050, mean: 0.11195
[32m[0906 14-37-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.82052, mean: 0.11185
[32m[0906 14-37-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 79.33181, mean: 0.11173
[32m[0906 14-37-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01913, current rewards: 84.84136, mean: 0.11163
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 90.37114, mean: 0.11157
[32m[0906 14-37-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 95.94050, mean: 0.11156
[32m[0906 14-37-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 101.50557, mean: 0.11154
[32m[0906 14-37-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 107.06484, mean: 0.11153
[32m[0906 14-37-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: 112.62740, mean: 0.11151
[32m[0906 14-37-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 118.19186, mean: 0.11150
[32m[0906 14-37-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01904, current rewards: 123.76100, mean: 0.11150
[32m[0906 14-37-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01902, current rewards: 129.32250, mean: 0.11148
[32m[0906 14-37-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01901, current rewards: 134.88876, mean: 0.11148
[32m[0906 14-37-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01900, current rewards: 140.62853, mean: 0.11161
[32m[0906 14-37-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01899, current rewards: 146.32948, mean: 0.11170
[32m[0906 14-37-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01898, current rewards: 152.02903, mean: 0.11179
[32m[0906 14-37-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01897, current rewards: 157.73185, mean: 0.11187
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01894, current rewards: 163.41763, mean: 0.11193
[32m[0906 14-37-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01893, current rewards: 169.14533, mean: 0.11202
[32m[0906 14-37-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01892, current rewards: 174.84462, mean: 0.11208
[32m[0906 14-37-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01891, current rewards: 180.48666, mean: 0.11210
[32m[0906 14-37-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01889, current rewards: 186.12376, mean: 0.11212
[32m[0906 14-37-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01889, current rewards: 191.76735, mean: 0.11214
[32m[0906 14-37-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01888, current rewards: 197.41207, mean: 0.11217
[32m[0906 14-37-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01887, current rewards: 203.04741, mean: 0.11218
[32m[0906 14-37-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01886, current rewards: 208.67482, mean: 0.11219
[32m[0906 14-37-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01886, current rewards: 214.31575, mean: 0.11221
[32m[0906 14-37-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01885, current rewards: 219.95449, mean: 0.11222
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 225.59550, mean: 0.11224
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 231.23741, mean: 0.11225
[32m[0906 14-37-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01886, current rewards: 236.87516, mean: 0.11226
[32m[0906 14-37-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01887, current rewards: 242.51804, mean: 0.11228
[32m[0906 14-37-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: 248.15227, mean: 0.11229
[32m[0906 14-37-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01889, current rewards: 253.79156, mean: 0.11230
[32m[0906 14-37-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: 259.43120, mean: 0.11231
[32m[0906 14-37-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 265.06559, mean: 0.11232
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 270.72695, mean: 0.11233
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01892, current rewards: 276.40797, mean: 0.11236
[32m[0906 14-37-39 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-37-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-37-39 @MBExp.py:227][0m Rewards obtained: [280.94971525103176], Lows: [0], Highs: [0], Total time: 1848.5731570000005
[32m[0906 14-39-05 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-05 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01919, current rewards: 1.14713, mean: 0.11471
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01930, current rewards: 6.72118, mean: 0.11202
[32m[0906 14-39-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01927, current rewards: 12.24943, mean: 0.11136
[32m[0906 14-39-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01922, current rewards: 17.75374, mean: 0.11096
[32m[0906 14-39-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.27066, mean: 0.11081
[32m[0906 14-39-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: 28.83207, mean: 0.11089
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 34.38767, mean: 0.11093
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 39.95445, mean: 0.11098
[32m[0906 14-39-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 45.51800, mean: 0.11102
[32m[0906 14-39-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.07832, mean: 0.11104
[32m[0906 14-39-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 56.64203, mean: 0.11106
[32m[0906 14-39-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 62.20222, mean: 0.11108
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01918, current rewards: 65.67626, mean: 0.10767
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 71.30248, mean: 0.10803
[32m[0906 14-39-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 76.92758, mean: 0.10835
[32m[0906 14-39-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 82.55311, mean: 0.10862
[32m[0906 14-39-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01917, current rewards: 88.17411, mean: 0.10886
[32m[0906 14-39-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01914, current rewards: 93.80058, mean: 0.10907
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: 99.42319, mean: 0.10926
[32m[0906 14-39-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 105.04664, mean: 0.10942
[32m[0906 14-39-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01905, current rewards: 111.55002, mean: 0.11045
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01902, current rewards: 120.33869, mean: 0.11353
[32m[0906 14-39-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01900, current rewards: 129.12735, mean: 0.11633
[32m[0906 14-39-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01898, current rewards: 134.60639, mean: 0.11604
[32m[0906 14-39-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01895, current rewards: 137.03040, mean: 0.11325
[32m[0906 14-39-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01893, current rewards: 139.45441, mean: 0.11068
[32m[0906 14-39-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01892, current rewards: 136.63602, mean: 0.10430
[32m[0906 14-39-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01890, current rewards: 86.63602, mean: 0.06370
[32m[0906 14-39-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01889, current rewards: 36.63602, mean: 0.02598
[32m[0906 14-39-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01888, current rewards: -13.36398, mean: -0.00915
[32m[0906 14-39-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01887, current rewards: -63.36398, mean: -0.04196
[32m[0906 14-39-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01886, current rewards: -113.36398, mean: -0.07267
[32m[0906 14-39-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01885, current rewards: -163.36398, mean: -0.10147
[32m[0906 14-39-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01884, current rewards: -213.36398, mean: -0.12853
[32m[0906 14-39-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01884, current rewards: -263.36398, mean: -0.15401
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: -313.36398, mean: -0.17805
[32m[0906 14-39-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: -363.36398, mean: -0.20075
[32m[0906 14-39-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01882, current rewards: -413.36398, mean: -0.22224
[32m[0906 14-39-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: -463.36398, mean: -0.24260
[32m[0906 14-39-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01880, current rewards: -513.36398, mean: -0.26192
[32m[0906 14-39-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01881, current rewards: -563.36398, mean: -0.28028
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: -613.36398, mean: -0.29775
[32m[0906 14-39-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: -663.36398, mean: -0.31439
[32m[0906 14-39-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: -713.36398, mean: -0.33026
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: -763.36398, mean: -0.34541
[32m[0906 14-39-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: -813.36398, mean: -0.35990
[32m[0906 14-39-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: -863.36398, mean: -0.37375
[32m[0906 14-39-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: -913.36398, mean: -0.38702
[32m[0906 14-39-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: -963.36398, mean: -0.39974
[32m[0906 14-39-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: -1013.36398, mean: -0.41194
[32m[0906 14-39-53 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-39-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-39-53 @MBExp.py:227][0m Rewards obtained: [-1053.363979296409], Lows: [1], Highs: [1195], Total time: 1896.4794800000004
[32m[0906 14-41-22 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-22 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 14-41-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01950, current rewards: 1.21026, mean: 0.12103
[32m[0906 14-41-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01912, current rewards: 6.56992, mean: 0.10950
[32m[0906 14-41-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01911, current rewards: 11.93526, mean: 0.10850
[32m[0906 14-41-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.10505, mean: 0.10691
[32m[0906 14-41-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01917, current rewards: 22.33634, mean: 0.10636
[32m[0906 14-41-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 27.56491, mean: 0.10602
[32m[0906 14-41-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 32.79326, mean: 0.10578
[32m[0906 14-41-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 38.02105, mean: 0.10561
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01914, current rewards: 43.25210, mean: 0.10549
[32m[0906 14-41-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 48.47987, mean: 0.10539
[32m[0906 14-41-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 53.70687, mean: 0.10531
[32m[0906 14-41-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 58.99324, mean: 0.10535
[32m[0906 14-41-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 64.30378, mean: 0.10542
[32m[0906 14-41-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 69.40201, mean: 0.10515
[32m[0906 14-41-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 74.47429, mean: 0.10489
[32m[0906 14-41-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 79.54469, mean: 0.10466
[32m[0906 14-41-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 84.61920, mean: 0.10447
[32m[0906 14-41-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01903, current rewards: 89.69027, mean: 0.10429
[32m[0906 14-41-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01900, current rewards: 94.77092, mean: 0.10414
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01898, current rewards: 99.84179, mean: 0.10400
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01895, current rewards: 104.94146, mean: 0.10390
[32m[0906 14-41-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01893, current rewards: 109.85216, mean: 0.10363
[32m[0906 14-41-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01892, current rewards: 114.22823, mean: 0.10291
[32m[0906 14-41-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01891, current rewards: 118.60962, mean: 0.10225
[32m[0906 14-41-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01889, current rewards: 122.99301, mean: 0.10165
[32m[0906 14-41-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01887, current rewards: 127.37565, mean: 0.10109
[32m[0906 14-41-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01886, current rewards: 131.75434, mean: 0.10058
[32m[0906 14-41-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01885, current rewards: 136.13266, mean: 0.10010
[32m[0906 14-41-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01884, current rewards: 140.42907, mean: 0.09960
[32m[0906 14-41-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01883, current rewards: 144.75312, mean: 0.09915
[32m[0906 14-41-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01882, current rewards: 149.08412, mean: 0.09873
[32m[0906 14-41-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01881, current rewards: 153.40773, mean: 0.09834
[32m[0906 14-41-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01881, current rewards: 157.73612, mean: 0.09797
[32m[0906 14-41-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01880, current rewards: 162.99144, mean: 0.09819
[32m[0906 14-41-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01879, current rewards: 168.55558, mean: 0.09857
[32m[0906 14-41-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 174.11643, mean: 0.09893
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: 179.66541, mean: 0.09926
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 185.22162, mean: 0.09958
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 190.77570, mean: 0.09988
[32m[0906 14-41-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 196.32669, mean: 0.10017
[32m[0906 14-42-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01883, current rewards: 201.88136, mean: 0.10044
[32m[0906 14-42-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 207.43248, mean: 0.10070
[32m[0906 14-42-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 212.98918, mean: 0.10094
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 218.54114, mean: 0.10118
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 224.17056, mean: 0.10143
[32m[0906 14-42-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: 229.77098, mean: 0.10167
[32m[0906 14-42-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 235.37091, mean: 0.10189
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 240.96988, mean: 0.10211
[32m[0906 14-42-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 245.89784, mean: 0.10203
[32m[0906 14-42-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01889, current rewards: 250.84174, mean: 0.10197
[32m[0906 14-42-10 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-42-10 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-42-10 @MBExp.py:227][0m Rewards obtained: [254.80120588795535], Lows: [0], Highs: [0], Total time: 1944.4201780000003
[32m[0906 14-43-41 @MBExp.py:144][0m ####################################################################
[32m[0906 14-43-41 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 14-43-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.10065, mean: 0.11007
[32m[0906 14-43-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01915, current rewards: 6.54742, mean: 0.10912
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01921, current rewards: 12.05514, mean: 0.10959
[32m[0906 14-43-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01921, current rewards: 17.61937, mean: 0.11012
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.08856, mean: 0.10995
[32m[0906 14-43-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 28.56176, mean: 0.10985
[32m[0906 14-43-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.03644, mean: 0.10979
[32m[0906 14-43-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01915, current rewards: 37.33113, mean: 0.10370
[32m[0906 14-43-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 42.70175, mean: 0.10415
[32m[0906 14-43-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 48.07621, mean: 0.10451
[32m[0906 14-43-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01916, current rewards: 53.44995, mean: 0.10480
[32m[0906 14-43-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 58.87133, mean: 0.10513
[32m[0906 14-43-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 64.33402, mean: 0.10547
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 69.84113, mean: 0.10582
[32m[0906 14-43-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 75.34630, mean: 0.10612
[32m[0906 14-43-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01903, current rewards: 80.85148, mean: 0.10638
[32m[0906 14-43-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01899, current rewards: 86.35531, mean: 0.10661
[32m[0906 14-43-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01897, current rewards: 91.84393, mean: 0.10680
[32m[0906 14-43-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01895, current rewards: 97.31506, mean: 0.10694
[32m[0906 14-43-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01892, current rewards: 102.78108, mean: 0.10706
[32m[0906 14-44-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01890, current rewards: 108.25572, mean: 0.10718
[32m[0906 14-44-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01888, current rewards: 113.72338, mean: 0.10729
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01888, current rewards: 119.19343, mean: 0.10738
[32m[0906 14-44-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01887, current rewards: 124.66594, mean: 0.10747
[32m[0906 14-44-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01885, current rewards: 130.13995, mean: 0.10755
[32m[0906 14-44-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01884, current rewards: 135.60864, mean: 0.10763
[32m[0906 14-44-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01882, current rewards: 141.07672, mean: 0.10769
[32m[0906 14-44-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01882, current rewards: 146.43882, mean: 0.10768
[32m[0906 14-44-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01881, current rewards: 151.92205, mean: 0.10775
[32m[0906 14-44-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01881, current rewards: 157.69938, mean: 0.10801
[32m[0906 14-44-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01880, current rewards: 163.17540, mean: 0.10806
[32m[0906 14-44-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01879, current rewards: 168.66312, mean: 0.10812
[32m[0906 14-44-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01878, current rewards: 174.15044, mean: 0.10817
[32m[0906 14-44-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01878, current rewards: 179.63087, mean: 0.10821
[32m[0906 14-44-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: 185.11318, mean: 0.10825
[32m[0906 14-44-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01877, current rewards: 190.59293, mean: 0.10829
[32m[0906 14-44-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01878, current rewards: 196.21048, mean: 0.10840
[32m[0906 14-44-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01879, current rewards: 201.73307, mean: 0.10846
[32m[0906 14-44-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01880, current rewards: 207.24690, mean: 0.10851
[32m[0906 14-44-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 212.76479, mean: 0.10855
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 218.33619, mean: 0.10862
[32m[0906 14-44-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 223.84688, mean: 0.10866
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 229.35940, mean: 0.10870
[32m[0906 14-44-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 234.87439, mean: 0.10874
[32m[0906 14-44-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 240.40281, mean: 0.10878
[32m[0906 14-44-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 245.91767, mean: 0.10881
[32m[0906 14-44-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01888, current rewards: 251.42740, mean: 0.10884
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 256.94275, mean: 0.10887
[32m[0906 14-44-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 262.45697, mean: 0.10890
[32m[0906 14-44-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: 267.96622, mean: 0.10893
[32m[0906 14-44-29 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-44-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-44-29 @MBExp.py:227][0m Rewards obtained: [272.37207093566775], Lows: [1], Highs: [0], Total time: 1992.3927370000004
[32m[0906 14-46-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-46-02 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 14-46-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01976, current rewards: 1.10253, mean: 0.11025
[32m[0906 14-46-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01913, current rewards: 6.75542, mean: 0.11259
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01910, current rewards: 12.29532, mean: 0.11178
[32m[0906 14-46-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01902, current rewards: 17.83748, mean: 0.11148
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01901, current rewards: 23.38020, mean: 0.11133
[32m[0906 14-46-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: 28.91880, mean: 0.11123
[32m[0906 14-46-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.46125, mean: 0.11117
[32m[0906 14-46-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 40.02189, mean: 0.11117
[32m[0906 14-46-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 45.56087, mean: 0.11112
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 51.10724, mean: 0.11110
[32m[0906 14-46-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01906, current rewards: 56.65490, mean: 0.11109
[32m[0906 14-46-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01900, current rewards: 62.20580, mean: 0.11108
[32m[0906 14-46-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01900, current rewards: 67.66958, mean: 0.11093
[32m[0906 14-46-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01897, current rewards: 73.13051, mean: 0.11080
[32m[0906 14-46-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01894, current rewards: 78.60199, mean: 0.11071
[32m[0906 14-46-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01891, current rewards: 84.08247, mean: 0.11063
[32m[0906 14-46-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01889, current rewards: 89.55185, mean: 0.11056
[32m[0906 14-46-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01887, current rewards: 95.02482, mean: 0.11049
[32m[0906 14-46-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01885, current rewards: 99.59228, mean: 0.10944
[32m[0906 14-46-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01884, current rewards: 105.71255, mean: 0.11012
[32m[0906 14-46-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01883, current rewards: 111.20785, mean: 0.11011
[32m[0906 14-46-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01881, current rewards: 116.70414, mean: 0.11010
[32m[0906 14-46-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01880, current rewards: 122.17759, mean: 0.11007
[32m[0906 14-46-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01880, current rewards: 127.74181, mean: 0.11012
[32m[0906 14-46-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01879, current rewards: 133.31010, mean: 0.11017
[32m[0906 14-46-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01878, current rewards: 138.87792, mean: 0.11022
[32m[0906 14-46-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01878, current rewards: 144.44769, mean: 0.11027
[32m[0906 14-46-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01877, current rewards: 149.91206, mean: 0.11023
[32m[0906 14-46-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01876, current rewards: 155.49230, mean: 0.11028
[32m[0906 14-46-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01875, current rewards: 161.06580, mean: 0.11032
[32m[0906 14-46-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 166.64404, mean: 0.11036
[32m[0906 14-46-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 172.22137, mean: 0.11040
[32m[0906 14-46-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: 177.80145, mean: 0.11044
[32m[0906 14-46-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01873, current rewards: 183.37818, mean: 0.11047
[32m[0906 14-46-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 188.95553, mean: 0.11050
[32m[0906 14-46-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: 194.56727, mean: 0.11055
[32m[0906 14-46-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01876, current rewards: 200.21661, mean: 0.11062
[32m[0906 14-46-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 205.75894, mean: 0.11062
[32m[0906 14-46-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01878, current rewards: 211.30031, mean: 0.11063
[32m[0906 14-46-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01879, current rewards: 216.83860, mean: 0.11063
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01880, current rewards: 222.36690, mean: 0.11063
[32m[0906 14-46-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: 227.90987, mean: 0.11064
[32m[0906 14-46-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 233.45913, mean: 0.11064
[32m[0906 14-46-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: 239.00620, mean: 0.11065
[32m[0906 14-46-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 244.44414, mean: 0.11061
[32m[0906 14-46-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: 249.98302, mean: 0.11061
[32m[0906 14-46-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01886, current rewards: 255.51900, mean: 0.11061
[32m[0906 14-46-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 261.05807, mean: 0.11062
[32m[0906 14-46-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01887, current rewards: 266.62938, mean: 0.11063
[32m[0906 14-46-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: 272.20537, mean: 0.11065
[32m[0906 14-46-50 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-46-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-46-50 @MBExp.py:227][0m Rewards obtained: [276.66643068145476], Lows: [1], Highs: [0], Total time: 2040.2808630000004
[32m[0906 14-48-25 @MBExp.py:144][0m ####################################################################
[32m[0906 14-48-25 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 14-48-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01922, current rewards: -0.09667, mean: -0.00967
[32m[0906 14-48-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: 4.87523, mean: 0.08125
[32m[0906 14-48-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 9.84141, mean: 0.08947
[32m[0906 14-48-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01915, current rewards: 16.05771, mean: 0.10036
[32m[0906 14-48-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 22.66594, mean: 0.10793
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01918, current rewards: -3.55860, mean: -0.01369
[32m[0906 14-48-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01919, current rewards: -53.55860, mean: -0.17277
[32m[0906 14-48-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: -103.55860, mean: -0.28766
[32m[0906 14-48-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01903, current rewards: -153.55860, mean: -0.37453
[32m[0906 14-48-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01897, current rewards: -203.55860, mean: -0.44252
[32m[0906 14-48-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01893, current rewards: -253.55860, mean: -0.49717
[32m[0906 14-48-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01888, current rewards: -254.87861, mean: -0.45514
[32m[0906 14-48-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01885, current rewards: -249.90956, mean: -0.40969
[32m[0906 14-48-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01884, current rewards: -244.94511, mean: -0.37113
[32m[0906 14-48-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01882, current rewards: -239.98423, mean: -0.33801
[32m[0906 14-48-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01880, current rewards: -235.02152, mean: -0.30924
[32m[0906 14-48-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01879, current rewards: -230.06094, mean: -0.28403
[32m[0906 14-48-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01877, current rewards: -224.38519, mean: -0.26091
[32m[0906 14-48-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01877, current rewards: -218.71798, mean: -0.24035
[32m[0906 14-48-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01875, current rewards: -212.98641, mean: -0.22186
[32m[0906 14-48-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01874, current rewards: -207.35392, mean: -0.20530
[32m[0906 14-48-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01872, current rewards: -201.71474, mean: -0.19030
[32m[0906 14-48-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01871, current rewards: -196.07928, mean: -0.17665
[32m[0906 14-48-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01871, current rewards: -190.39344, mean: -0.16413
[32m[0906 14-48-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01871, current rewards: -184.66698, mean: -0.15262
[32m[0906 14-48-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01870, current rewards: -178.94020, mean: -0.14202
[32m[0906 14-48-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01870, current rewards: -173.21274, mean: -0.13222
[32m[0906 14-48-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01870, current rewards: -167.48319, mean: -0.12315
[32m[0906 14-48-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01870, current rewards: -161.75686, mean: -0.11472
[32m[0906 14-48-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01870, current rewards: -156.03124, mean: -0.10687
[32m[0906 14-48-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01869, current rewards: -150.31177, mean: -0.09954
[32m[0906 14-48-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01869, current rewards: -144.59134, mean: -0.09269
[32m[0906 14-48-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01870, current rewards: -138.87331, mean: -0.08626
[32m[0906 14-48-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: -133.37896, mean: -0.08035
[32m[0906 14-48-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01873, current rewards: -127.87559, mean: -0.07478
[32m[0906 14-48-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01874, current rewards: -122.40230, mean: -0.06955
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01875, current rewards: -116.83136, mean: -0.06455
[32m[0906 14-49-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01876, current rewards: -111.26122, mean: -0.05982
[32m[0906 14-49-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01877, current rewards: -105.69279, mean: -0.05534
[32m[0906 14-49-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01879, current rewards: -100.12253, mean: -0.05108
[32m[0906 14-49-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01879, current rewards: -94.55820, mean: -0.04704
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01881, current rewards: -88.93047, mean: -0.04317
[32m[0906 14-49-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01882, current rewards: -83.19314, mean: -0.03943
[32m[0906 14-49-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: -77.46197, mean: -0.03586
[32m[0906 14-49-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: -71.74695, mean: -0.03246
[32m[0906 14-49-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: -65.97533, mean: -0.02919
[32m[0906 14-49-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: -60.21077, mean: -0.02607
[32m[0906 14-49-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: -54.44035, mean: -0.02307
[32m[0906 14-49-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: -48.67155, mean: -0.02020
[32m[0906 14-49-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: -42.96320, mean: -0.01746
[32m[0906 14-49-13 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-49-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-49-13 @MBExp.py:227][0m Rewards obtained: [-38.45371674882577], Lows: [0], Highs: [286], Total time: 2088.1780120000003
[32m[0906 14-50-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-50-50 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 14-50-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01866, current rewards: 1.02996, mean: 0.10300
[32m[0906 14-50-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01892, current rewards: 6.47539, mean: 0.10792
[32m[0906 14-50-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01896, current rewards: 11.95871, mean: 0.10872
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 17.39239, mean: 0.10870
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 22.82934, mean: 0.10871
[32m[0906 14-50-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01902, current rewards: 28.26350, mean: 0.10871
[32m[0906 14-50-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01893, current rewards: 33.72267, mean: 0.10878
[32m[0906 14-50-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01888, current rewards: 39.25071, mean: 0.10903
[32m[0906 14-50-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01884, current rewards: 44.77206, mean: 0.10920
[32m[0906 14-50-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01880, current rewards: 50.29434, mean: 0.10934
[32m[0906 14-51-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01880, current rewards: 55.75068, mean: 0.10932
[32m[0906 14-51-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01881, current rewards: 61.26981, mean: 0.10941
[32m[0906 14-51-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01879, current rewards: 66.79207, mean: 0.10950
[32m[0906 14-51-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01878, current rewards: 72.31035, mean: 0.10956
[32m[0906 14-51-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01877, current rewards: 77.83374, mean: 0.10962
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01875, current rewards: 83.35278, mean: 0.10967
[32m[0906 14-51-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01874, current rewards: 88.86878, mean: 0.10971
[32m[0906 14-51-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01872, current rewards: 94.38947, mean: 0.10976
[32m[0906 14-51-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01871, current rewards: 99.95189, mean: 0.10984
[32m[0906 14-51-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01871, current rewards: 105.63099, mean: 0.11003
[32m[0906 14-51-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01870, current rewards: 111.25589, mean: 0.11015
[32m[0906 14-51-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01869, current rewards: 116.88355, mean: 0.11027
[32m[0906 14-51-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01868, current rewards: 122.51129, mean: 0.11037
[32m[0906 14-51-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01867, current rewards: 128.13754, mean: 0.11046
[32m[0906 14-51-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01867, current rewards: 133.77051, mean: 0.11055
[32m[0906 14-51-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01866, current rewards: 139.40214, mean: 0.11064
[32m[0906 14-51-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 145.02342, mean: 0.11070
[32m[0906 14-51-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01866, current rewards: 150.59904, mean: 0.11073
[32m[0906 14-51-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01865, current rewards: 156.14877, mean: 0.11074
[32m[0906 14-51-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 161.69589, mean: 0.11075
[32m[0906 14-51-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01864, current rewards: 167.25028, mean: 0.11076
[32m[0906 14-51-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01866, current rewards: 172.80876, mean: 0.11077
[32m[0906 14-51-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01868, current rewards: 178.35885, mean: 0.11078
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01870, current rewards: 183.91019, mean: 0.11079
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 189.43569, mean: 0.11078
[32m[0906 14-51-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01872, current rewards: 194.86943, mean: 0.11072
[32m[0906 14-51-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01874, current rewards: 200.37746, mean: 0.11071
[32m[0906 14-51-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01875, current rewards: 205.88683, mean: 0.11069
[32m[0906 14-51-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01877, current rewards: 211.39470, mean: 0.11068
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01878, current rewards: 216.90222, mean: 0.11066
[32m[0906 14-51-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01879, current rewards: 222.45621, mean: 0.11067
[32m[0906 14-51-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01880, current rewards: 228.00709, mean: 0.11068
[32m[0906 14-51-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 233.56108, mean: 0.11069
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 239.21386, mean: 0.11075
[32m[0906 14-51-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 247.76217, mean: 0.11211
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01883, current rewards: 256.55083, mean: 0.11352
[32m[0906 14-51-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 265.33949, mean: 0.11487
[32m[0906 14-51-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 274.12815, mean: 0.11616
[32m[0906 14-51-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01885, current rewards: 282.91682, mean: 0.11739
[32m[0906 14-51-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 291.70548, mean: 0.11858
[32m[0906 14-51-38 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-51-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-51-38 @MBExp.py:227][0m Rewards obtained: [298.7364083588881], Lows: [0], Highs: [0], Total time: 2136.04822
[32m[0906 14-53-17 @MBExp.py:144][0m ####################################################################
[32m[0906 14-53-17 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01906, current rewards: 1.05658, mean: 0.10566
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01894, current rewards: 6.56288, mean: 0.10938
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.08389, mean: 0.10985
[32m[0906 14-53-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01893, current rewards: 17.59473, mean: 0.10997
[32m[0906 14-53-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01888, current rewards: 23.10067, mean: 0.11000
[32m[0906 14-53-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01886, current rewards: 28.60965, mean: 0.11004
[32m[0906 14-53-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01883, current rewards: 34.11739, mean: 0.11006
[32m[0906 14-53-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01878, current rewards: 39.69024, mean: 0.11025
[32m[0906 14-53-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01873, current rewards: 45.25763, mean: 0.11038
[32m[0906 14-53-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01870, current rewards: 50.82939, mean: 0.11050
[32m[0906 14-53-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01869, current rewards: 56.47172, mean: 0.11073
[32m[0906 14-53-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01868, current rewards: 62.03028, mean: 0.11077
[32m[0906 14-53-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01867, current rewards: 67.58682, mean: 0.11080
[32m[0906 14-53-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01865, current rewards: 73.19833, mean: 0.11091
[32m[0906 14-53-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01863, current rewards: 78.77287, mean: 0.11095
[32m[0906 14-53-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01861, current rewards: 84.35096, mean: 0.11099
[32m[0906 14-53-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01860, current rewards: 89.93064, mean: 0.11103
[32m[0906 14-53-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01859, current rewards: 95.51173, mean: 0.11106
[32m[0906 14-53-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01859, current rewards: 101.08960, mean: 0.11109
[32m[0906 14-53-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 106.66998, mean: 0.11111
[32m[0906 14-53-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 112.24506, mean: 0.11113
[32m[0906 14-53-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01858, current rewards: 117.84518, mean: 0.11117
[32m[0906 14-53-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 123.40328, mean: 0.11117
[32m[0906 14-53-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01857, current rewards: 128.96395, mean: 0.11118
[32m[0906 14-53-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01858, current rewards: 134.52006, mean: 0.11117
[32m[0906 14-53-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01857, current rewards: 140.08220, mean: 0.11118
[32m[0906 14-53-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01858, current rewards: 145.55234, mean: 0.11111
[32m[0906 14-53-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 151.08010, mean: 0.11109
[32m[0906 14-53-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: 156.64817, mean: 0.11110
[32m[0906 14-53-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01859, current rewards: 162.21823, mean: 0.11111
[32m[0906 14-53-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01860, current rewards: 167.79422, mean: 0.11112
[32m[0906 14-53-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01862, current rewards: 173.36569, mean: 0.11113
[32m[0906 14-53-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01864, current rewards: 178.93957, mean: 0.11114
[32m[0906 14-53-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01866, current rewards: 184.50696, mean: 0.11115
[32m[0906 14-53-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01868, current rewards: 190.08371, mean: 0.11116
[32m[0906 14-53-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01870, current rewards: 195.89399, mean: 0.11130
[32m[0906 14-53-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01871, current rewards: 201.47373, mean: 0.11131
[32m[0906 14-53-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01872, current rewards: 207.05745, mean: 0.11132
[32m[0906 14-53-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01873, current rewards: 212.63466, mean: 0.11133
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01875, current rewards: 218.20911, mean: 0.11133
[32m[0906 14-53-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01876, current rewards: 223.78366, mean: 0.11134
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01876, current rewards: 229.36127, mean: 0.11134
[32m[0906 14-53-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01877, current rewards: 234.93569, mean: 0.11134
[32m[0906 14-53-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01878, current rewards: 241.28193, mean: 0.11170
[32m[0906 14-53-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01879, current rewards: 246.82914, mean: 0.11169
[32m[0906 14-54-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01880, current rewards: 252.37537, mean: 0.11167
[32m[0906 14-54-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01880, current rewards: 257.92087, mean: 0.11165
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 263.46623, mean: 0.11164
[32m[0906 14-54-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01882, current rewards: 267.87092, mean: 0.11115
[32m[0906 14-54-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01883, current rewards: 273.43356, mean: 0.11115
[32m[0906 14-54-05 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 14-54-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-54-05 @MBExp.py:227][0m Rewards obtained: [277.8780527737302], Lows: [0], Highs: [1], Total time: 2183.830445
[32m[0906 14-55-46 @MBExp.py:144][0m ####################################################################
[32m[0906 14-55-46 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 14-55-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01883, current rewards: 1.29269, mean: 0.12927
[32m[0906 14-55-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01851, current rewards: 6.88493, mean: 0.11475
[32m[0906 14-55-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01855, current rewards: 12.37765, mean: 0.11252
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01857, current rewards: 17.91813, mean: 0.11199
[32m[0906 14-55-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01855, current rewards: 23.46541, mean: 0.11174
[32m[0906 14-55-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 29.01311, mean: 0.11159
[32m[0906 14-55-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 34.54594, mean: 0.11144
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 40.08951, mean: 0.11136
[32m[0906 14-55-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.60786, mean: 0.11124
[32m[0906 14-55-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 51.15955, mean: 0.11122
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 56.76848, mean: 0.11131
[32m[0906 14-55-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 62.31438, mean: 0.11128
[32m[0906 14-55-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 67.84539, mean: 0.11122
[32m[0906 14-55-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 73.38532, mean: 0.11119
[32m[0906 14-55-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 78.91725, mean: 0.11115
[32m[0906 14-56-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 84.91614, mean: 0.11173
[32m[0906 14-56-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 93.21626, mean: 0.11508
[32m[0906 14-56-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 101.51638, mean: 0.11804
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 108.76441, mean: 0.11952
[32m[0906 14-56-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 67.29818, mean: 0.07010
[32m[0906 14-56-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 17.29818, mean: 0.01713
[32m[0906 14-56-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01849, current rewards: -32.70182, mean: -0.03085
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01849, current rewards: -82.70182, mean: -0.07451
[32m[0906 14-56-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01849, current rewards: -132.70182, mean: -0.11440
[32m[0906 14-56-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01849, current rewards: -182.70182, mean: -0.15099
[32m[0906 14-56-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01849, current rewards: -232.70182, mean: -0.18468
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01850, current rewards: -282.70182, mean: -0.21580
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: -332.70182, mean: -0.24463
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: -382.70182, mean: -0.27142
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: -432.70182, mean: -0.29637
[32m[0906 14-56-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: -482.70182, mean: -0.31967
[32m[0906 14-56-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01860, current rewards: -532.70182, mean: -0.34148
[32m[0906 14-56-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01862, current rewards: -582.70182, mean: -0.36193
[32m[0906 14-56-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01863, current rewards: -632.70182, mean: -0.38115
[32m[0906 14-56-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01864, current rewards: -682.70182, mean: -0.39924
[32m[0906 14-56-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01865, current rewards: -732.70182, mean: -0.41631
[32m[0906 14-56-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01866, current rewards: -782.70182, mean: -0.43243
[32m[0906 14-56-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01868, current rewards: -832.70182, mean: -0.44769
[32m[0906 14-56-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01869, current rewards: -882.70182, mean: -0.46215
[32m[0906 14-56-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01870, current rewards: -932.70182, mean: -0.47587
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01871, current rewards: -982.70182, mean: -0.48891
[32m[0906 14-56-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01872, current rewards: -1032.70182, mean: -0.50131
[32m[0906 14-56-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01873, current rewards: -1082.70182, mean: -0.51313
[32m[0906 14-56-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01874, current rewards: -1132.70182, mean: -0.52440
[32m[0906 14-56-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01875, current rewards: -1182.70182, mean: -0.53516
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01877, current rewards: -1232.70182, mean: -0.54544
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01877, current rewards: -1282.70182, mean: -0.55528
[32m[0906 14-56-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01877, current rewards: -1332.70182, mean: -0.56470
[32m[0906 14-56-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01878, current rewards: -1382.70182, mean: -0.57374
[32m[0906 14-56-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01879, current rewards: -1432.70182, mean: -0.58240
[32m[0906 14-56-34 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 14-56-34 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-56-34 @MBExp.py:227][0m Rewards obtained: [-1472.701823796524], Lows: [0], Highs: [1582], Total time: 2231.533434
[32m[0906 14-58-17 @MBExp.py:144][0m ####################################################################
[32m[0906 14-58-17 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 14-58-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01823, current rewards: 1.13276, mean: 0.11328
[32m[0906 14-58-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01861, current rewards: 6.66329, mean: 0.11105
[32m[0906 14-58-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 12.23421, mean: 0.11122
[32m[0906 14-58-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 17.80261, mean: 0.11127
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01848, current rewards: 23.37280, mean: 0.11130
[32m[0906 14-58-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.97166, mean: 0.11143
[32m[0906 14-58-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.52742, mean: 0.11138
[32m[0906 14-58-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.08398, mean: 0.11134
[32m[0906 14-58-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.64218, mean: 0.11132
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 51.13674, mean: 0.11117
[32m[0906 14-58-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.68474, mean: 0.11115
[32m[0906 14-58-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.23396, mean: 0.11113
[32m[0906 14-58-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 67.77859, mean: 0.11111
[32m[0906 14-58-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.32488, mean: 0.11110
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 78.87108, mean: 0.11109
[32m[0906 14-58-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.47388, mean: 0.11115
[32m[0906 14-58-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 90.00091, mean: 0.11111
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 95.49117, mean: 0.11104
[32m[0906 14-58-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 101.00299, mean: 0.11099
[32m[0906 14-58-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 106.50957, mean: 0.11095
[32m[0906 14-58-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 112.02195, mean: 0.11091
[32m[0906 14-58-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 117.53193, mean: 0.11088
[32m[0906 14-58-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 123.03945, mean: 0.11085
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 128.60775, mean: 0.11087
[32m[0906 14-58-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 134.15235, mean: 0.11087
[32m[0906 14-58-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 139.70847, mean: 0.11088
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 145.33789, mean: 0.11094
[32m[0906 14-58-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 150.89043, mean: 0.11095
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01859, current rewards: 156.43686, mean: 0.11095
[32m[0906 14-58-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01861, current rewards: 161.99341, mean: 0.11095
[32m[0906 14-58-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01863, current rewards: 167.54741, mean: 0.11096
[32m[0906 14-58-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01865, current rewards: 173.10100, mean: 0.11096
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01866, current rewards: 176.59201, mean: 0.10968
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01868, current rewards: 182.21398, mean: 0.10977
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01869, current rewards: 187.72748, mean: 0.10978
[32m[0906 14-58-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01871, current rewards: 193.32393, mean: 0.10984
[32m[0906 14-58-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01872, current rewards: 198.92146, mean: 0.10990
[32m[0906 14-58-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01874, current rewards: 204.51568, mean: 0.10995
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01875, current rewards: 210.11369, mean: 0.11001
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01877, current rewards: 215.71020, mean: 0.11006
[32m[0906 14-58-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01878, current rewards: 221.24907, mean: 0.11007
[32m[0906 14-58-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01879, current rewards: 226.79496, mean: 0.11009
[32m[0906 14-58-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01880, current rewards: 232.38515, mean: 0.11014
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01881, current rewards: 237.96271, mean: 0.11017
[32m[0906 14-58-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01882, current rewards: 243.51714, mean: 0.11019
[32m[0906 14-59-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01884, current rewards: 249.07286, mean: 0.11021
[32m[0906 14-59-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 254.61674, mean: 0.11022
[32m[0906 14-59-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01885, current rewards: 260.16932, mean: 0.11024
[32m[0906 14-59-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: 265.72141, mean: 0.11026
[32m[0906 14-59-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01886, current rewards: 271.27625, mean: 0.11027
[32m[0906 14-59-05 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 14-59-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 14-59-05 @MBExp.py:227][0m Rewards obtained: [275.7190742484132], Lows: [1], Highs: [0], Total time: 2279.418231
[32m[0906 15-00-50 @MBExp.py:144][0m ####################################################################
[32m[0906 15-00-50 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-00-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01852, current rewards: 1.07811, mean: 0.10781
[32m[0906 15-00-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01848, current rewards: 6.52259, mean: 0.10871
[32m[0906 15-00-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01852, current rewards: 11.83177, mean: 0.10756
[32m[0906 15-00-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 17.17290, mean: 0.10733
[32m[0906 15-00-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01852, current rewards: 22.51619, mean: 0.10722
[32m[0906 15-00-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 27.85614, mean: 0.10714
[32m[0906 15-00-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 33.19489, mean: 0.10708
[32m[0906 15-00-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 38.53880, mean: 0.10705
[32m[0906 15-00-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01859, current rewards: 43.88349, mean: 0.10703
[32m[0906 15-00-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01858, current rewards: 49.22510, mean: 0.10701
[32m[0906 15-01-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 54.56465, mean: 0.10699
[32m[0906 15-01-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01858, current rewards: 60.14262, mean: 0.10740
[32m[0906 15-01-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 65.71918, mean: 0.10774
[32m[0906 15-01-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01859, current rewards: 71.29612, mean: 0.10802
[32m[0906 15-01-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 76.87410, mean: 0.10827
[32m[0906 15-01-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01857, current rewards: 82.44940, mean: 0.10849
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: 88.02245, mean: 0.10867
[32m[0906 15-01-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 93.59793, mean: 0.10883
[32m[0906 15-01-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01858, current rewards: 99.16854, mean: 0.10898
[32m[0906 15-01-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01858, current rewards: 104.74303, mean: 0.10911
[32m[0906 15-01-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 110.31725, mean: 0.10922
[32m[0906 15-01-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01859, current rewards: 115.89295, mean: 0.10933
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01859, current rewards: 121.46821, mean: 0.10943
[32m[0906 15-01-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01859, current rewards: 127.02378, mean: 0.10950
[32m[0906 15-01-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01862, current rewards: 132.62348, mean: 0.10961
[32m[0906 15-01-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01864, current rewards: 138.22424, mean: 0.10970
[32m[0906 15-01-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01866, current rewards: 143.84985, mean: 0.10981
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: 149.42985, mean: 0.10987
[32m[0906 15-01-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 155.00636, mean: 0.10993
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01874, current rewards: 160.58984, mean: 0.10999
[32m[0906 15-01-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01875, current rewards: 166.14574, mean: 0.11003
[32m[0906 15-01-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01878, current rewards: 171.59462, mean: 0.11000
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01879, current rewards: 177.03965, mean: 0.10996
[32m[0906 15-01-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01881, current rewards: 182.49007, mean: 0.10993
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01882, current rewards: 187.88447, mean: 0.10987
[32m[0906 15-01-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 193.35167, mean: 0.10986
[32m[0906 15-01-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01884, current rewards: 198.81775, mean: 0.10984
[32m[0906 15-01-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01886, current rewards: 204.28129, mean: 0.10983
[32m[0906 15-01-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01887, current rewards: 209.74159, mean: 0.10981
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01888, current rewards: 215.32275, mean: 0.10986
[32m[0906 15-01-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 220.90298, mean: 0.10990
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01891, current rewards: 226.48376, mean: 0.10994
[32m[0906 15-01-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01892, current rewards: 232.15114, mean: 0.11002
[32m[0906 15-01-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01892, current rewards: 237.73435, mean: 0.11006
[32m[0906 15-01-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01893, current rewards: 243.27504, mean: 0.11008
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: 248.81910, mean: 0.11010
[32m[0906 15-01-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01894, current rewards: 254.36020, mean: 0.11011
[32m[0906 15-01-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01894, current rewards: 259.90004, mean: 0.11013
[32m[0906 15-01-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01895, current rewards: 265.66657, mean: 0.11024
[32m[0906 15-01-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01896, current rewards: 271.45684, mean: 0.11035
[32m[0906 15-01-38 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-01-38 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-01-38 @MBExp.py:227][0m Rewards obtained: [276.0977394583836], Lows: [0], Highs: [0], Total time: 2327.544283
[32m[0906 15-03-26 @MBExp.py:144][0m ####################################################################
[32m[0906 15-03-26 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-03-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01870, current rewards: 1.06457, mean: 0.10646
[32m[0906 15-03-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01848, current rewards: 6.67971, mean: 0.11133
[32m[0906 15-03-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01860, current rewards: 12.23851, mean: 0.11126
[32m[0906 15-03-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01850, current rewards: 17.80621, mean: 0.11129
[32m[0906 15-03-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.37271, mean: 0.11130
[32m[0906 15-03-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 28.94969, mean: 0.11134
[32m[0906 15-03-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.63761, mean: 0.11173
[32m[0906 15-03-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 40.25199, mean: 0.11181
[32m[0906 15-03-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 45.86640, mean: 0.11187
[32m[0906 15-03-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.40173, mean: 0.11174
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 57.02004, mean: 0.11180
[32m[0906 15-03-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.63629, mean: 0.11185
[32m[0906 15-03-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 68.25175, mean: 0.11189
[32m[0906 15-03-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 73.86910, mean: 0.11192
[32m[0906 15-03-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 79.48618, mean: 0.11195
[32m[0906 15-03-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 85.10360, mean: 0.11198
[32m[0906 15-03-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 90.72371, mean: 0.11200
[32m[0906 15-03-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 96.39008, mean: 0.11208
[32m[0906 15-03-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 102.01684, mean: 0.11211
[32m[0906 15-03-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 107.54927, mean: 0.11203
[32m[0906 15-03-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 113.09677, mean: 0.11198
[32m[0906 15-03-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 118.64769, mean: 0.11193
[32m[0906 15-03-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 124.19531, mean: 0.11189
[32m[0906 15-03-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01858, current rewards: 129.74758, mean: 0.11185
[32m[0906 15-03-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01861, current rewards: 135.29365, mean: 0.11181
[32m[0906 15-03-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01863, current rewards: 140.84260, mean: 0.11178
[32m[0906 15-03-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 146.39326, mean: 0.11175
[32m[0906 15-03-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01867, current rewards: 151.94344, mean: 0.11172
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01868, current rewards: 157.49251, mean: 0.11170
[32m[0906 15-03-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: 163.04472, mean: 0.11167
[32m[0906 15-03-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01871, current rewards: 168.59578, mean: 0.11165
[32m[0906 15-03-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01872, current rewards: 174.15674, mean: 0.11164
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01874, current rewards: 179.74636, mean: 0.11164
[32m[0906 15-03-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 185.35788, mean: 0.11166
[32m[0906 15-03-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01877, current rewards: 190.97779, mean: 0.11168
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01878, current rewards: 196.56567, mean: 0.11169
[32m[0906 15-04-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01879, current rewards: 202.15679, mean: 0.11169
[32m[0906 15-04-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01880, current rewards: 207.75155, mean: 0.11169
[32m[0906 15-04-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01881, current rewards: 213.33989, mean: 0.11170
[32m[0906 15-04-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01881, current rewards: 218.93149, mean: 0.11170
[32m[0906 15-04-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 224.52497, mean: 0.11170
[32m[0906 15-04-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01883, current rewards: 230.09993, mean: 0.11170
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 235.66592, mean: 0.11169
[32m[0906 15-04-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01885, current rewards: 241.21595, mean: 0.11167
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01886, current rewards: 246.76550, mean: 0.11166
[32m[0906 15-04-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01887, current rewards: 252.31529, mean: 0.11164
[32m[0906 15-04-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 257.86940, mean: 0.11163
[32m[0906 15-04-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01888, current rewards: 263.41899, mean: 0.11162
[32m[0906 15-04-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: 268.97169, mean: 0.11161
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: 274.52375, mean: 0.11160
[32m[0906 15-04-13 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-04-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-04-14 @MBExp.py:227][0m Rewards obtained: [279.0391961213101], Lows: [0], Highs: [0], Total time: 2375.512125
[32m[0906 15-06-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-03 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-06-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01893, current rewards: 1.25793, mean: 0.12579
[32m[0906 15-06-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01839, current rewards: 6.83202, mean: 0.11387
[32m[0906 15-06-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.39346, mean: 0.11267
[32m[0906 15-06-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01845, current rewards: 17.96029, mean: 0.11225
[32m[0906 15-06-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01842, current rewards: 23.52878, mean: 0.11204
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01843, current rewards: 29.09599, mean: 0.11191
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.66725, mean: 0.11183
[32m[0906 15-06-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 40.25151, mean: 0.11181
[32m[0906 15-06-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 45.79517, mean: 0.11170
[32m[0906 15-06-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 51.36336, mean: 0.11166
[32m[0906 15-06-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 56.93266, mean: 0.11163
[32m[0906 15-06-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 62.50603, mean: 0.11162
[32m[0906 15-06-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01852, current rewards: 68.07742, mean: 0.11160
[32m[0906 15-06-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 71.56330, mean: 0.10843
[32m[0906 15-06-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 77.13314, mean: 0.10864
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 82.70313, mean: 0.10882
[32m[0906 15-06-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 88.27318, mean: 0.10898
[32m[0906 15-06-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 93.84355, mean: 0.10912
[32m[0906 15-06-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 99.41375, mean: 0.10925
[32m[0906 15-06-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 104.98401, mean: 0.10936
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 108.30852, mean: 0.10724
[32m[0906 15-06-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 113.88412, mean: 0.10744
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01858, current rewards: 119.45865, mean: 0.10762
[32m[0906 15-06-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 125.03180, mean: 0.10779
[32m[0906 15-06-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01863, current rewards: 130.61606, mean: 0.10795
[32m[0906 15-06-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01865, current rewards: 136.20222, mean: 0.10810
[32m[0906 15-06-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01867, current rewards: 141.77245, mean: 0.10822
[32m[0906 15-06-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: 147.34291, mean: 0.10834
[32m[0906 15-06-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01871, current rewards: 152.91685, mean: 0.10845
[32m[0906 15-06-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: 158.48772, mean: 0.10855
[32m[0906 15-06-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01874, current rewards: 164.10845, mean: 0.10868
[32m[0906 15-06-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01876, current rewards: 169.65439, mean: 0.10875
[32m[0906 15-06-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01877, current rewards: 175.07173, mean: 0.10874
[32m[0906 15-06-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01879, current rewards: 180.59977, mean: 0.10880
[32m[0906 15-06-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01880, current rewards: 186.14841, mean: 0.10886
[32m[0906 15-06-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01881, current rewards: 191.70405, mean: 0.10892
[32m[0906 15-06-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01882, current rewards: 197.25667, mean: 0.10898
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01883, current rewards: 202.80930, mean: 0.10904
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01884, current rewards: 208.36691, mean: 0.10909
[32m[0906 15-06-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01885, current rewards: 213.92366, mean: 0.10914
[32m[0906 15-06-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01887, current rewards: 219.47622, mean: 0.10919
[32m[0906 15-06-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01887, current rewards: 225.06914, mean: 0.10926
[32m[0906 15-06-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01888, current rewards: 230.62185, mean: 0.10930
[32m[0906 15-06-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 236.17586, mean: 0.10934
[32m[0906 15-06-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: 241.72783, mean: 0.10938
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01890, current rewards: 247.28152, mean: 0.10942
[32m[0906 15-06-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01891, current rewards: 252.83563, mean: 0.10945
[32m[0906 15-06-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 258.42026, mean: 0.10950
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01892, current rewards: 263.99936, mean: 0.10954
[32m[0906 15-06-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01893, current rewards: 269.56210, mean: 0.10958
[32m[0906 15-06-51 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-06-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-06-51 @MBExp.py:227][0m Rewards obtained: [274.01923941486723], Lows: [1], Highs: [2], Total time: 2423.578441
[32m[0906 15-08-42 @MBExp.py:144][0m ####################################################################
[32m[0906 15-08-42 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-08-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01787, current rewards: 1.15682, mean: 0.11568
[32m[0906 15-08-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 6.73033, mean: 0.11217
[32m[0906 15-08-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01840, current rewards: 12.27564, mean: 0.11160
[32m[0906 15-08-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 17.81986, mean: 0.11137
[32m[0906 15-08-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.37036, mean: 0.11129
[32m[0906 15-08-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01851, current rewards: 28.91672, mean: 0.11122
[32m[0906 15-08-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 34.46100, mean: 0.11116
[32m[0906 15-08-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.00587, mean: 0.11113
[32m[0906 15-08-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.55625, mean: 0.11111
[32m[0906 15-08-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 51.10250, mean: 0.11109
[32m[0906 15-08-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 56.65204, mean: 0.11108
[32m[0906 15-08-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 62.19630, mean: 0.11106
[32m[0906 15-08-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 67.74729, mean: 0.11106
[32m[0906 15-08-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 73.29493, mean: 0.11105
[32m[0906 15-08-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 78.84321, mean: 0.11105
[32m[0906 15-08-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: 84.32457, mean: 0.11095
[32m[0906 15-08-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01850, current rewards: 89.87278, mean: 0.11095
[32m[0906 15-08-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 95.51519, mean: 0.11106
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 101.19344, mean: 0.11120
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 106.87451, mean: 0.11133
[32m[0906 15-09-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01858, current rewards: 112.55450, mean: 0.11144
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01862, current rewards: 118.23465, mean: 0.11154
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01865, current rewards: 123.91449, mean: 0.11163
[32m[0906 15-09-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01868, current rewards: 129.60847, mean: 0.11173
[32m[0906 15-09-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01869, current rewards: 137.26649, mean: 0.11344
[32m[0906 15-09-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01870, current rewards: 146.05515, mean: 0.11592
[32m[0906 15-09-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01872, current rewards: 154.84381, mean: 0.11820
[32m[0906 15-09-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01873, current rewards: 160.95932, mean: 0.11835
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01875, current rewards: 163.38333, mean: 0.11587
[32m[0906 15-09-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01877, current rewards: 165.80734, mean: 0.11357
[32m[0906 15-09-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01879, current rewards: 168.23135, mean: 0.11141
[32m[0906 15-09-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01880, current rewards: 170.65536, mean: 0.10939
[32m[0906 15-09-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01882, current rewards: 144.77040, mean: 0.08992
[32m[0906 15-09-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01883, current rewards: 94.77040, mean: 0.05709
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01884, current rewards: 44.77040, mean: 0.02618
[32m[0906 15-09-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01885, current rewards: -5.22960, mean: -0.00297
[32m[0906 15-09-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01886, current rewards: -55.22960, mean: -0.03051
[32m[0906 15-09-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01887, current rewards: -105.22960, mean: -0.05658
[32m[0906 15-09-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01888, current rewards: -155.22960, mean: -0.08127
[32m[0906 15-09-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01889, current rewards: -205.22960, mean: -0.10471
[32m[0906 15-09-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: -255.22960, mean: -0.12698
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01890, current rewards: -305.22960, mean: -0.14817
[32m[0906 15-09-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01891, current rewards: -355.22960, mean: -0.16836
[32m[0906 15-09-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01891, current rewards: -405.22960, mean: -0.18761
[32m[0906 15-09-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: -455.22960, mean: -0.20599
[32m[0906 15-09-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: -505.22960, mean: -0.22355
[32m[0906 15-09-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: -555.22960, mean: -0.24036
[32m[0906 15-09-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01894, current rewards: -605.22960, mean: -0.25645
[32m[0906 15-09-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01894, current rewards: -655.22960, mean: -0.27188
[32m[0906 15-09-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01895, current rewards: -705.22960, mean: -0.28668
[32m[0906 15-09-30 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-09-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-09-30 @MBExp.py:227][0m Rewards obtained: [-745.229596994197], Lows: [0], Highs: [917], Total time: 2471.672568
[32m[0906 15-11-23 @MBExp.py:144][0m ####################################################################
[32m[0906 15-11-23 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-11-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01821, current rewards: 1.20213, mean: 0.12021
[32m[0906 15-11-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01854, current rewards: 6.61855, mean: 0.11031
[32m[0906 15-11-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01855, current rewards: 12.15371, mean: 0.11049
[32m[0906 15-11-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 17.68737, mean: 0.11055
[32m[0906 15-11-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 23.21891, mean: 0.11057
[32m[0906 15-11-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 28.75336, mean: 0.11059
[32m[0906 15-11-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 34.29140, mean: 0.11062
[32m[0906 15-11-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 39.82829, mean: 0.11063
[32m[0906 15-11-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 45.47579, mean: 0.11092
[32m[0906 15-11-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 51.00775, mean: 0.11089
[32m[0906 15-11-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.54557, mean: 0.11087
[32m[0906 15-11-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 62.12355, mean: 0.11093
[32m[0906 15-11-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 67.66746, mean: 0.11093
[32m[0906 15-11-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 73.21718, mean: 0.11094
[32m[0906 15-11-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01854, current rewards: 78.76656, mean: 0.11094
[32m[0906 15-11-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 84.31236, mean: 0.11094
[32m[0906 15-11-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 89.87975, mean: 0.11096
[32m[0906 15-11-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 95.43599, mean: 0.11097
[32m[0906 15-11-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 101.00108, mean: 0.11099
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01860, current rewards: 106.52673, mean: 0.11097
[32m[0906 15-11-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01863, current rewards: 112.06022, mean: 0.11095
[32m[0906 15-11-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01865, current rewards: 117.59193, mean: 0.11094
[32m[0906 15-11-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01868, current rewards: 123.13221, mean: 0.11093
[32m[0906 15-11-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01870, current rewards: 128.66606, mean: 0.11092
[32m[0906 15-11-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01872, current rewards: 134.19904, mean: 0.11091
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01874, current rewards: 139.73621, mean: 0.11090
[32m[0906 15-11-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01877, current rewards: 145.27371, mean: 0.11090
[32m[0906 15-11-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01878, current rewards: 150.93585, mean: 0.11098
[32m[0906 15-11-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01880, current rewards: 156.49800, mean: 0.11099
[32m[0906 15-11-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01881, current rewards: 162.06019, mean: 0.11100
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01882, current rewards: 167.62241, mean: 0.11101
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01884, current rewards: 173.18452, mean: 0.11102
[32m[0906 15-11-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01885, current rewards: 178.74662, mean: 0.11102
[32m[0906 15-11-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01886, current rewards: 182.00725, mean: 0.10964
[32m[0906 15-11-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01887, current rewards: 187.55382, mean: 0.10968
[32m[0906 15-11-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01888, current rewards: 193.09736, mean: 0.10971
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01888, current rewards: 198.64402, mean: 0.10975
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01889, current rewards: 204.18469, mean: 0.10978
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01890, current rewards: 209.73039, mean: 0.10981
[32m[0906 15-12-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01891, current rewards: 215.26381, mean: 0.10983
[32m[0906 15-12-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01891, current rewards: 220.74835, mean: 0.10983
[32m[0906 15-12-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 226.24479, mean: 0.10983
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: 231.79110, mean: 0.10985
[32m[0906 15-12-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01893, current rewards: 237.33625, mean: 0.10988
[32m[0906 15-12-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: 242.88209, mean: 0.10990
[32m[0906 15-12-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: 248.42371, mean: 0.10992
[32m[0906 15-12-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01895, current rewards: 253.96882, mean: 0.10994
[32m[0906 15-12-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01896, current rewards: 259.50813, mean: 0.10996
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01897, current rewards: 265.05444, mean: 0.10998
[32m[0906 15-12-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01897, current rewards: 270.60846, mean: 0.11000
[32m[0906 15-12-11 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-12-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-12-11 @MBExp.py:227][0m Rewards obtained: [275.036194024596], Lows: [0], Highs: [2], Total time: 2519.83878
[32m[0906 15-14-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-06 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-14-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01848, current rewards: 1.08706, mean: 0.10871
[32m[0906 15-14-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01863, current rewards: 6.63316, mean: 0.11055
[32m[0906 15-14-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 12.17942, mean: 0.11072
[32m[0906 15-14-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 17.72862, mean: 0.11080
[32m[0906 15-14-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01843, current rewards: 23.28257, mean: 0.11087
[32m[0906 15-14-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 28.83029, mean: 0.11089
[32m[0906 15-14-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.38331, mean: 0.11091
[32m[0906 15-14-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 39.88426, mean: 0.11079
[32m[0906 15-14-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.43540, mean: 0.11082
[32m[0906 15-14-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 50.98275, mean: 0.11083
[32m[0906 15-14-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 56.53306, mean: 0.11085
[32m[0906 15-14-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 62.08028, mean: 0.11086
[32m[0906 15-14-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 67.62806, mean: 0.11087
[32m[0906 15-14-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 73.17602, mean: 0.11087
[32m[0906 15-14-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 78.72748, mean: 0.11088
[32m[0906 15-14-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.25989, mean: 0.11087
[32m[0906 15-14-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 89.74102, mean: 0.11079
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01857, current rewards: 95.27018, mean: 0.11078
[32m[0906 15-14-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01861, current rewards: 100.80334, mean: 0.11077
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01864, current rewards: 106.33498, mean: 0.11077
[32m[0906 15-14-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01866, current rewards: 111.86636, mean: 0.11076
[32m[0906 15-14-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01869, current rewards: 117.39942, mean: 0.11075
[32m[0906 15-14-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01872, current rewards: 122.93087, mean: 0.11075
[32m[0906 15-14-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01874, current rewards: 128.53284, mean: 0.11080
[32m[0906 15-14-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01875, current rewards: 134.12435, mean: 0.11085
[32m[0906 15-14-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01878, current rewards: 139.65691, mean: 0.11084
[32m[0906 15-14-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01879, current rewards: 145.19710, mean: 0.11084
[32m[0906 15-14-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01881, current rewards: 150.73000, mean: 0.11083
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01881, current rewards: 156.30614, mean: 0.11086
[32m[0906 15-14-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01882, current rewards: 161.86159, mean: 0.11086
[32m[0906 15-14-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01884, current rewards: 167.41485, mean: 0.11087
[32m[0906 15-14-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01884, current rewards: 172.96878, mean: 0.11088
[32m[0906 15-14-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01885, current rewards: 178.34962, mean: 0.11078
[32m[0906 15-14-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01886, current rewards: 183.88645, mean: 0.11077
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01886, current rewards: 189.42169, mean: 0.11077
[32m[0906 15-14-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01887, current rewards: 194.95711, mean: 0.11077
[32m[0906 15-14-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01888, current rewards: 200.49498, mean: 0.11077
[32m[0906 15-14-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01889, current rewards: 206.03334, mean: 0.11077
[32m[0906 15-14-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01890, current rewards: 211.56749, mean: 0.11077
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01891, current rewards: 217.10357, mean: 0.11077
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01891, current rewards: 222.67882, mean: 0.11079
[32m[0906 15-14-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 228.21406, mean: 0.11078
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: 233.73394, mean: 0.11077
[32m[0906 15-14-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01894, current rewards: 239.24836, mean: 0.11076
[32m[0906 15-14-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: 244.76780, mean: 0.11075
[32m[0906 15-14-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01895, current rewards: 250.28483, mean: 0.11075
[32m[0906 15-14-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01895, current rewards: 255.80193, mean: 0.11074
[32m[0906 15-14-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01896, current rewards: 261.31927, mean: 0.11073
[32m[0906 15-14-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01896, current rewards: 266.84107, mean: 0.11072
[32m[0906 15-14-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01896, current rewards: 272.41892, mean: 0.11074
[32m[0906 15-14-54 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-14-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-14-54 @MBExp.py:227][0m Rewards obtained: [276.8309093746245], Lows: [0], Highs: [0], Total time: 2567.970735
[32m[0906 15-16-51 @MBExp.py:144][0m ####################################################################
[32m[0906 15-16-51 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-16-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01822, current rewards: 1.06202, mean: 0.10620
[32m[0906 15-16-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01859, current rewards: 6.57142, mean: 0.10952
[32m[0906 15-16-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01848, current rewards: 12.07867, mean: 0.10981
[32m[0906 15-16-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01850, current rewards: 17.58071, mean: 0.10988
[32m[0906 15-16-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01852, current rewards: 23.08673, mean: 0.10994
[32m[0906 15-16-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 28.59035, mean: 0.10996
[32m[0906 15-16-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 34.09749, mean: 0.10999
[32m[0906 15-16-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01851, current rewards: 39.57312, mean: 0.10993
[32m[0906 15-16-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.07483, mean: 0.10994
[32m[0906 15-16-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 50.58132, mean: 0.10996
[32m[0906 15-17-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01850, current rewards: 56.08975, mean: 0.10998
[32m[0906 15-17-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 61.59385, mean: 0.10999
[32m[0906 15-17-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 67.09059, mean: 0.10998
[32m[0906 15-17-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 72.58850, mean: 0.10998
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01859, current rewards: 78.09246, mean: 0.10999
[32m[0906 15-17-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01862, current rewards: 83.71711, mean: 0.11015
[32m[0906 15-17-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01866, current rewards: 89.48494, mean: 0.11048
[32m[0906 15-17-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01869, current rewards: 95.05196, mean: 0.11053
[32m[0906 15-17-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01872, current rewards: 100.61671, mean: 0.11057
[32m[0906 15-17-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01875, current rewards: 106.18316, mean: 0.11061
[32m[0906 15-17-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01877, current rewards: 111.74886, mean: 0.11064
[32m[0906 15-17-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01879, current rewards: 117.31142, mean: 0.11067
[32m[0906 15-17-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01883, current rewards: 122.87815, mean: 0.11070
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01884, current rewards: 128.39589, mean: 0.11069
[32m[0906 15-17-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01887, current rewards: 133.92459, mean: 0.11068
[32m[0906 15-17-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01888, current rewards: 139.45763, mean: 0.11068
[32m[0906 15-17-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01889, current rewards: 145.71494, mean: 0.11123
[32m[0906 15-17-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01890, current rewards: 152.81149, mean: 0.11236
[32m[0906 15-17-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01891, current rewards: 159.90804, mean: 0.11341
[32m[0906 15-17-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01892, current rewards: 167.00460, mean: 0.11439
[32m[0906 15-17-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01892, current rewards: 174.10115, mean: 0.11530
[32m[0906 15-17-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01893, current rewards: 172.06225, mean: 0.11030
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01894, current rewards: 122.06225, mean: 0.07582
[32m[0906 15-17-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01894, current rewards: 72.06225, mean: 0.04341
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01895, current rewards: 22.06225, mean: 0.01290
[32m[0906 15-17-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01896, current rewards: -27.93775, mean: -0.01587
[32m[0906 15-17-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01896, current rewards: -77.93775, mean: -0.04306
[32m[0906 15-17-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: -127.93775, mean: -0.06878
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01897, current rewards: -177.93775, mean: -0.09316
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01898, current rewards: -227.93775, mean: -0.11629
[32m[0906 15-17-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01898, current rewards: -277.93775, mean: -0.13828
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01899, current rewards: -327.93775, mean: -0.15919
[32m[0906 15-17-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01899, current rewards: -377.93775, mean: -0.17912
[32m[0906 15-17-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01900, current rewards: -427.93775, mean: -0.19812
[32m[0906 15-17-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01900, current rewards: -477.93775, mean: -0.21626
[32m[0906 15-17-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01901, current rewards: -527.93775, mean: -0.23360
[32m[0906 15-17-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01901, current rewards: -577.93775, mean: -0.25019
[32m[0906 15-17-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01902, current rewards: -627.93775, mean: -0.26608
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01902, current rewards: -677.93775, mean: -0.28130
[32m[0906 15-17-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01903, current rewards: -727.93775, mean: -0.29591
[32m[0906 15-17-39 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-17-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-17-39 @MBExp.py:227][0m Rewards obtained: [-767.9377510024773], Lows: [0], Highs: [948], Total time: 2616.26822
[32m[0906 15-19-38 @MBExp.py:144][0m ####################################################################
[32m[0906 15-19-38 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-19-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01854, current rewards: 1.35073, mean: 0.13507
[32m[0906 15-19-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01844, current rewards: 6.96654, mean: 0.11611
[32m[0906 15-19-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 12.57414, mean: 0.11431
[32m[0906 15-19-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01842, current rewards: 18.19273, mean: 0.11370
[32m[0906 15-19-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01841, current rewards: 23.80840, mean: 0.11337
[32m[0906 15-19-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 29.42530, mean: 0.11317
[32m[0906 15-19-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 35.03739, mean: 0.11302
[32m[0906 15-19-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.65908, mean: 0.11294
[32m[0906 15-19-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 46.28308, mean: 0.11289
[32m[0906 15-19-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 51.90356, mean: 0.11283
[32m[0906 15-19-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01855, current rewards: 57.52213, mean: 0.11279
[32m[0906 15-19-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 63.05986, mean: 0.11261
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01859, current rewards: 68.60953, mean: 0.11247
[32m[0906 15-19-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01863, current rewards: 74.16286, mean: 0.11237
[32m[0906 15-19-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01870, current rewards: 79.71507, mean: 0.11227
[32m[0906 15-19-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01874, current rewards: 85.28578, mean: 0.11222
[32m[0906 15-19-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01876, current rewards: 90.83959, mean: 0.11215
[32m[0906 15-19-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01878, current rewards: 96.39074, mean: 0.11208
[32m[0906 15-19-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01881, current rewards: 101.93796, mean: 0.11202
[32m[0906 15-19-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01883, current rewards: 107.49295, mean: 0.11197
[32m[0906 15-19-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01885, current rewards: 113.04031, mean: 0.11192
[32m[0906 15-19-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01887, current rewards: 118.59964, mean: 0.11189
[32m[0906 15-19-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01888, current rewards: 124.16018, mean: 0.11186
[32m[0906 15-20-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01888, current rewards: 129.60883, mean: 0.11173
[32m[0906 15-20-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01890, current rewards: 135.16189, mean: 0.11170
[32m[0906 15-20-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01891, current rewards: 140.71294, mean: 0.11168
[32m[0906 15-20-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01892, current rewards: 146.26327, mean: 0.11165
[32m[0906 15-20-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01893, current rewards: 151.81521, mean: 0.11163
[32m[0906 15-20-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01895, current rewards: 157.36549, mean: 0.11161
[32m[0906 15-20-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01895, current rewards: 162.92589, mean: 0.11159
[32m[0906 15-20-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01895, current rewards: 168.48579, mean: 0.11158
[32m[0906 15-20-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01896, current rewards: 174.05928, mean: 0.11158
[32m[0906 15-20-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01897, current rewards: 179.61490, mean: 0.11156
[32m[0906 15-20-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01898, current rewards: 185.16941, mean: 0.11155
[32m[0906 15-20-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 190.72625, mean: 0.11154
[32m[0906 15-20-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01898, current rewards: 196.28436, mean: 0.11153
[32m[0906 15-20-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01899, current rewards: 201.83976, mean: 0.11151
[32m[0906 15-20-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01899, current rewards: 207.39557, mean: 0.11150
[32m[0906 15-20-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01900, current rewards: 212.95312, mean: 0.11149
[32m[0906 15-20-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01900, current rewards: 218.60499, mean: 0.11153
[32m[0906 15-20-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01901, current rewards: 198.94182, mean: 0.09898
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01901, current rewards: 148.94182, mean: 0.07230
[32m[0906 15-20-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01901, current rewards: 98.94182, mean: 0.04689
[32m[0906 15-20-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01902, current rewards: 48.94182, mean: 0.02266
[32m[0906 15-20-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01903, current rewards: -1.05818, mean: -0.00048
[32m[0906 15-20-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01903, current rewards: -51.05818, mean: -0.02259
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01903, current rewards: -101.05818, mean: -0.04375
[32m[0906 15-20-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01903, current rewards: -151.05818, mean: -0.06401
[32m[0906 15-20-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01904, current rewards: -201.05818, mean: -0.08343
[32m[0906 15-20-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01904, current rewards: -251.05818, mean: -0.10206
[32m[0906 15-20-26 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-20-26 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-20-26 @MBExp.py:227][0m Rewards obtained: [-291.05818478110916], Lows: [0], Highs: [513], Total time: 2664.599624
[32m[0906 15-22-27 @MBExp.py:144][0m ####################################################################
[32m[0906 15-22-27 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-22-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01854, current rewards: 1.08248, mean: 0.10825
[32m[0906 15-22-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01833, current rewards: 6.60198, mean: 0.11003
[32m[0906 15-22-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01833, current rewards: 12.14895, mean: 0.11044
[32m[0906 15-22-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01838, current rewards: 17.69333, mean: 0.11058
[32m[0906 15-22-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01839, current rewards: 23.23893, mean: 0.11066
[32m[0906 15-22-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01840, current rewards: 28.77800, mean: 0.11068
[32m[0906 15-22-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01839, current rewards: 34.35715, mean: 0.11083
[32m[0906 15-22-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01840, current rewards: 39.84287, mean: 0.11067
[32m[0906 15-22-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01839, current rewards: 45.37842, mean: 0.11068
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01842, current rewards: 50.91663, mean: 0.11069
[32m[0906 15-22-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 56.45293, mean: 0.11069
[32m[0906 15-22-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01855, current rewards: 61.98439, mean: 0.11069
[32m[0906 15-22-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01859, current rewards: 67.49964, mean: 0.11066
[32m[0906 15-22-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01862, current rewards: 73.04529, mean: 0.11067
[32m[0906 15-22-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01866, current rewards: 78.59392, mean: 0.11070
[32m[0906 15-22-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01870, current rewards: 84.20681, mean: 0.11080
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01873, current rewards: 89.75239, mean: 0.11081
[32m[0906 15-22-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01875, current rewards: 95.29900, mean: 0.11081
[32m[0906 15-22-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01877, current rewards: 100.84427, mean: 0.11082
[32m[0906 15-22-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01878, current rewards: 106.39223, mean: 0.11083
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01880, current rewards: 111.94016, mean: 0.11083
[32m[0906 15-22-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01882, current rewards: 117.48855, mean: 0.11084
[32m[0906 15-22-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01884, current rewards: 123.03235, mean: 0.11084
[32m[0906 15-22-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01884, current rewards: 128.65979, mean: 0.11091
[32m[0906 15-22-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01886, current rewards: 134.25818, mean: 0.11096
[32m[0906 15-22-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01887, current rewards: 139.78922, mean: 0.11094
[32m[0906 15-22-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01888, current rewards: 145.32347, mean: 0.11093
[32m[0906 15-22-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01890, current rewards: 150.85404, mean: 0.11092
[32m[0906 15-22-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01891, current rewards: 156.38328, mean: 0.11091
[32m[0906 15-22-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01891, current rewards: 161.91161, mean: 0.11090
[32m[0906 15-22-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01892, current rewards: 167.44409, mean: 0.11089
[32m[0906 15-22-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01893, current rewards: 172.95339, mean: 0.11087
[32m[0906 15-22-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 178.47887, mean: 0.11086
[32m[0906 15-22-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01894, current rewards: 184.15316, mean: 0.11094
[32m[0906 15-22-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01894, current rewards: 189.69470, mean: 0.11093
[32m[0906 15-23-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01895, current rewards: 195.23642, mean: 0.11093
[32m[0906 15-23-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01895, current rewards: 200.77443, mean: 0.11093
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: 206.31920, mean: 0.11092
[32m[0906 15-23-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01896, current rewards: 211.86010, mean: 0.11092
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01897, current rewards: 217.40177, mean: 0.11092
[32m[0906 15-23-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01898, current rewards: 222.88791, mean: 0.11089
[32m[0906 15-23-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: 228.40913, mean: 0.11088
[32m[0906 15-23-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01898, current rewards: 233.92997, mean: 0.11087
[32m[0906 15-23-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01899, current rewards: 239.44847, mean: 0.11086
[32m[0906 15-23-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01900, current rewards: 244.96732, mean: 0.11084
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 250.48804, mean: 0.11084
[32m[0906 15-23-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01901, current rewards: 256.01963, mean: 0.11083
[32m[0906 15-23-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01901, current rewards: 261.54090, mean: 0.11082
[32m[0906 15-23-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01901, current rewards: 267.06705, mean: 0.11082
[32m[0906 15-23-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01902, current rewards: 272.60519, mean: 0.11082
[32m[0906 15-23-15 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-23-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-23-15 @MBExp.py:227][0m Rewards obtained: [277.0399156955641], Lows: [0], Highs: [0], Total time: 2712.8841549999997
[32m[0906 15-25-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-25-18 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-25-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01848, current rewards: 1.30849, mean: 0.13085
[32m[0906 15-25-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01835, current rewards: 6.73588, mean: 0.11226
[32m[0906 15-25-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01847, current rewards: 12.22169, mean: 0.11111
[32m[0906 15-25-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01842, current rewards: 17.70694, mean: 0.11067
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 23.19126, mean: 0.11043
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.67295, mean: 0.11028
[32m[0906 15-25-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.15321, mean: 0.11017
[32m[0906 15-25-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 39.63606, mean: 0.11010
[32m[0906 15-25-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01853, current rewards: 45.12603, mean: 0.11006
[32m[0906 15-25-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01860, current rewards: 50.61644, mean: 0.11004
[32m[0906 15-25-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01865, current rewards: 56.11388, mean: 0.11003
[32m[0906 15-25-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01869, current rewards: 61.60231, mean: 0.11000
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01875, current rewards: 67.09915, mean: 0.11000
[32m[0906 15-25-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01879, current rewards: 72.58971, mean: 0.10998
[32m[0906 15-25-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01883, current rewards: 78.03442, mean: 0.10991
[32m[0906 15-25-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01885, current rewards: 83.48969, mean: 0.10985
[32m[0906 15-25-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01888, current rewards: 88.94853, mean: 0.10981
[32m[0906 15-25-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01889, current rewards: 94.40910, mean: 0.10978
[32m[0906 15-25-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01892, current rewards: 99.86998, mean: 0.10975
[32m[0906 15-25-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01894, current rewards: 105.32904, mean: 0.10972
[32m[0906 15-25-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01896, current rewards: 110.78738, mean: 0.10969
[32m[0906 15-25-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01897, current rewards: 116.25048, mean: 0.10967
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01898, current rewards: 121.71145, mean: 0.10965
[32m[0906 15-25-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01899, current rewards: 127.23203, mean: 0.10968
[32m[0906 15-25-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01899, current rewards: 132.70516, mean: 0.10967
[32m[0906 15-25-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01900, current rewards: 138.18172, mean: 0.10967
[32m[0906 15-25-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01901, current rewards: 143.66046, mean: 0.10966
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01901, current rewards: 149.13749, mean: 0.10966
[32m[0906 15-25-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01902, current rewards: 154.61278, mean: 0.10965
[32m[0906 15-25-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01902, current rewards: 160.08727, mean: 0.10965
[32m[0906 15-25-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01903, current rewards: 165.56379, mean: 0.10964
[32m[0906 15-25-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01903, current rewards: 171.01878, mean: 0.10963
[32m[0906 15-25-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01903, current rewards: 176.49771, mean: 0.10963
[32m[0906 15-25-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01904, current rewards: 182.00011, mean: 0.10964
[32m[0906 15-25-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01905, current rewards: 187.51212, mean: 0.10966
[32m[0906 15-25-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01906, current rewards: 193.02287, mean: 0.10967
[32m[0906 15-25-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01906, current rewards: 198.53078, mean: 0.10969
[32m[0906 15-25-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01907, current rewards: 204.03944, mean: 0.10970
[32m[0906 15-25-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01907, current rewards: 209.54778, mean: 0.10971
[32m[0906 15-25-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01907, current rewards: 215.10217, mean: 0.10975
[32m[0906 15-25-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01908, current rewards: 220.65291, mean: 0.10978
[32m[0906 15-25-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01908, current rewards: 226.20487, mean: 0.10981
[32m[0906 15-25-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01909, current rewards: 231.75571, mean: 0.10984
[32m[0906 15-25-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01909, current rewards: 237.30768, mean: 0.10986
[32m[0906 15-26-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 242.85545, mean: 0.10989
[32m[0906 15-26-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01910, current rewards: 248.38554, mean: 0.10991
[32m[0906 15-26-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01910, current rewards: 253.94778, mean: 0.10993
[32m[0906 15-26-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01910, current rewards: 259.60367, mean: 0.11000
[32m[0906 15-26-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: 265.21507, mean: 0.11005
[32m[0906 15-26-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01911, current rewards: 270.82683, mean: 0.11009
[32m[0906 15-26-06 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-26-06 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-26-06 @MBExp.py:227][0m Rewards obtained: [275.3165557164724], Lows: [0], Highs: [0], Total time: 2761.393314
[32m[0906 15-28-11 @MBExp.py:144][0m ####################################################################
[32m[0906 15-28-11 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 15-28-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01872, current rewards: -1.01136, mean: -0.10114
[32m[0906 15-28-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01838, current rewards: 4.50946, mean: 0.07516
[32m[0906 15-28-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01840, current rewards: 10.07194, mean: 0.09156
[32m[0906 15-28-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 15.63057, mean: 0.09769
[32m[0906 15-28-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 21.19356, mean: 0.10092
[32m[0906 15-28-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01852, current rewards: 26.75401, mean: 0.10290
[32m[0906 15-28-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01860, current rewards: 32.32583, mean: 0.10428
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01865, current rewards: 37.88605, mean: 0.10524
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01872, current rewards: 43.44710, mean: 0.10597
[32m[0906 15-28-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01878, current rewards: 49.03383, mean: 0.10660
[32m[0906 15-28-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01882, current rewards: 54.56608, mean: 0.10699
[32m[0906 15-28-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01885, current rewards: 60.09804, mean: 0.10732
[32m[0906 15-28-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01887, current rewards: 65.62089, mean: 0.10758
[32m[0906 15-28-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01890, current rewards: 71.15198, mean: 0.10781
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01891, current rewards: 76.63798, mean: 0.10794
[32m[0906 15-28-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01894, current rewards: 82.15911, mean: 0.10810
[32m[0906 15-28-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01894, current rewards: 87.68475, mean: 0.10825
[32m[0906 15-28-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01895, current rewards: 93.20385, mean: 0.10838
[32m[0906 15-28-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01897, current rewards: 98.72579, mean: 0.10849
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01899, current rewards: 104.25187, mean: 0.10860
[32m[0906 15-28-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01901, current rewards: 109.77718, mean: 0.10869
[32m[0906 15-28-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01901, current rewards: 115.29101, mean: 0.10877
[32m[0906 15-28-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01901, current rewards: 120.86669, mean: 0.10889
[32m[0906 15-28-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01902, current rewards: 126.39080, mean: 0.10896
[32m[0906 15-28-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01904, current rewards: 131.94179, mean: 0.10904
[32m[0906 15-28-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01905, current rewards: 137.48612, mean: 0.10912
[32m[0906 15-28-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01905, current rewards: 143.03075, mean: 0.10918
[32m[0906 15-28-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: 148.57506, mean: 0.10925
[32m[0906 15-28-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: 154.11871, mean: 0.10930
[32m[0906 15-28-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01906, current rewards: 159.66036, mean: 0.10936
[32m[0906 15-28-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: 165.18555, mean: 0.10939
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 170.72395, mean: 0.10944
[32m[0906 15-28-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 176.27321, mean: 0.10949
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01906, current rewards: 181.81743, mean: 0.10953
[32m[0906 15-28-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01908, current rewards: 187.37662, mean: 0.10958
[32m[0906 15-28-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01908, current rewards: 192.92315, mean: 0.10962
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01909, current rewards: 198.46874, mean: 0.10965
[32m[0906 15-28-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01909, current rewards: 204.01530, mean: 0.10969
[32m[0906 15-28-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 209.55712, mean: 0.10972
[32m[0906 15-28-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01910, current rewards: 215.10727, mean: 0.10975
[32m[0906 15-28-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01910, current rewards: 220.65445, mean: 0.10978
[32m[0906 15-28-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01910, current rewards: 226.20002, mean: 0.10981
[32m[0906 15-28-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01911, current rewards: 231.74686, mean: 0.10983
[32m[0906 15-28-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01911, current rewards: 237.29179, mean: 0.10986
[32m[0906 15-28-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01911, current rewards: 242.84183, mean: 0.10988
[32m[0906 15-28-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01911, current rewards: 248.38882, mean: 0.10991
[32m[0906 15-28-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01912, current rewards: 253.97841, mean: 0.10995
[32m[0906 15-28-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 259.54754, mean: 0.10998
[32m[0906 15-28-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 265.08386, mean: 0.10999
[32m[0906 15-28-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 270.62944, mean: 0.11001
[32m[0906 15-28-59 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-28-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-28-59 @MBExp.py:227][0m Rewards obtained: [275.0659870234362], Lows: [1], Highs: [0], Total time: 2809.94573
[32m[0906 15-31-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-31-06 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 15-31-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01847, current rewards: 0.09576, mean: 0.00958
[32m[0906 15-31-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.03671, mean: 0.10061
[32m[0906 15-31-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01845, current rewards: 11.95472, mean: 0.10868
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 17.86339, mean: 0.11165
[32m[0906 15-31-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 23.78168, mean: 0.11325
[32m[0906 15-31-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01870, current rewards: 29.76995, mean: 0.11450
[32m[0906 15-31-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01875, current rewards: 35.96670, mean: 0.11602
[32m[0906 15-31-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01883, current rewards: 42.18785, mean: 0.11719
[32m[0906 15-31-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01887, current rewards: 48.40031, mean: 0.11805
[32m[0906 15-31-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01890, current rewards: 54.59647, mean: 0.11869
[32m[0906 15-31-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01894, current rewards: 60.80175, mean: 0.11922
[32m[0906 15-31-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01897, current rewards: 67.01446, mean: 0.11967
[32m[0906 15-31-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01898, current rewards: 73.23198, mean: 0.12005
[32m[0906 15-31-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01899, current rewards: 79.42688, mean: 0.12034
[32m[0906 15-31-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01901, current rewards: 85.62770, mean: 0.12060
[32m[0906 15-31-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01903, current rewards: 91.85117, mean: 0.12086
[32m[0906 15-31-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01904, current rewards: 97.86132, mean: 0.12082
[32m[0906 15-31-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01905, current rewards: 103.75269, mean: 0.12064
[32m[0906 15-31-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01906, current rewards: 109.64073, mean: 0.12048
[32m[0906 15-31-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 115.53233, mean: 0.12035
[32m[0906 15-31-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01908, current rewards: 121.42683, mean: 0.12022
[32m[0906 15-31-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 127.35092, mean: 0.12014
[32m[0906 15-31-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 132.99117, mean: 0.11981
[32m[0906 15-31-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 138.63125, mean: 0.11951
[32m[0906 15-31-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01910, current rewards: 144.26724, mean: 0.11923
[32m[0906 15-31-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 149.90947, mean: 0.11898
[32m[0906 15-31-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 155.54796, mean: 0.11874
[32m[0906 15-31-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 161.19178, mean: 0.11852
[32m[0906 15-31-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: 166.82814, mean: 0.11832
[32m[0906 15-31-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: 172.44353, mean: 0.11811
[32m[0906 15-31-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01911, current rewards: 177.99941, mean: 0.11788
[32m[0906 15-31-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01911, current rewards: 183.55491, mean: 0.11766
[32m[0906 15-31-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: 189.11111, mean: 0.11746
[32m[0906 15-31-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 194.66583, mean: 0.11727
[32m[0906 15-31-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: 200.22294, mean: 0.11709
[32m[0906 15-31-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 205.78019, mean: 0.11692
[32m[0906 15-31-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01914, current rewards: 211.33673, mean: 0.11676
[32m[0906 15-31-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01914, current rewards: 216.87931, mean: 0.11660
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01914, current rewards: 222.34874, mean: 0.11641
[32m[0906 15-31-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 227.83132, mean: 0.11624
[32m[0906 15-31-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 233.31345, mean: 0.11608
[32m[0906 15-31-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 238.79225, mean: 0.11592
[32m[0906 15-31-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 244.27812, mean: 0.11577
[32m[0906 15-31-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 249.76310, mean: 0.11563
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 255.24474, mean: 0.11550
[32m[0906 15-31-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 260.73208, mean: 0.11537
[32m[0906 15-31-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01916, current rewards: 266.17704, mean: 0.11523
[32m[0906 15-31-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01916, current rewards: 271.62608, mean: 0.11510
[32m[0906 15-31-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01916, current rewards: 277.08291, mean: 0.11497
[32m[0906 15-31-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 282.54262, mean: 0.11485
[32m[0906 15-31-54 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-31-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-31-54 @MBExp.py:227][0m Rewards obtained: [286.9000193297924], Lows: [0], Highs: [1], Total time: 2858.567303
[32m[0906 15-34-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-34-03 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 15-34-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01912, current rewards: 0.01479, mean: 0.00148
[32m[0906 15-34-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01860, current rewards: 5.58859, mean: 0.09314
[32m[0906 15-34-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01875, current rewards: 11.14947, mean: 0.10136
[32m[0906 15-34-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01887, current rewards: 16.70719, mean: 0.10442
[32m[0906 15-34-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01892, current rewards: 22.31411, mean: 0.10626
[32m[0906 15-34-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01900, current rewards: 27.87429, mean: 0.10721
[32m[0906 15-34-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01899, current rewards: 31.31963, mean: 0.10103
[32m[0906 15-34-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01902, current rewards: 36.84274, mean: 0.10234
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01903, current rewards: 42.36511, mean: 0.10333
[32m[0906 15-34-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01905, current rewards: 47.88822, mean: 0.10410
[32m[0906 15-34-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01906, current rewards: 53.41041, mean: 0.10473
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01907, current rewards: 58.93325, mean: 0.10524
[32m[0906 15-34-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 64.41630, mean: 0.10560
[32m[0906 15-34-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01910, current rewards: 69.91629, mean: 0.10593
[32m[0906 15-34-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 75.42104, mean: 0.10623
[32m[0906 15-34-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01911, current rewards: 81.01118, mean: 0.10659
[32m[0906 15-34-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 86.60353, mean: 0.10692
[32m[0906 15-34-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 92.19412, mean: 0.10720
[32m[0906 15-34-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 97.78686, mean: 0.10746
[32m[0906 15-34-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 103.38097, mean: 0.10769
[32m[0906 15-34-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: 109.03842, mean: 0.10796
[32m[0906 15-34-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 114.64481, mean: 0.10816
[32m[0906 15-34-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 120.18349, mean: 0.10827
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01912, current rewards: 125.73936, mean: 0.10840
[32m[0906 15-34-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 131.29049, mean: 0.10850
[32m[0906 15-34-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 136.84205, mean: 0.10860
[32m[0906 15-34-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01913, current rewards: 142.39385, mean: 0.10870
[32m[0906 15-34-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 147.94810, mean: 0.10879
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01913, current rewards: 153.49957, mean: 0.10886
[32m[0906 15-34-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 159.09441, mean: 0.10897
[32m[0906 15-34-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01913, current rewards: 164.64968, mean: 0.10904
[32m[0906 15-34-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01914, current rewards: 170.20389, mean: 0.10911
[32m[0906 15-34-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: 175.75913, mean: 0.10917
[32m[0906 15-34-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 181.31157, mean: 0.10922
[32m[0906 15-34-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 186.86336, mean: 0.10928
[32m[0906 15-34-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 192.41933, mean: 0.10933
[32m[0906 15-34-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01915, current rewards: 197.96411, mean: 0.10937
[32m[0906 15-34-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01915, current rewards: 203.44238, mean: 0.10938
[32m[0906 15-34-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01915, current rewards: 208.99300, mean: 0.10942
[32m[0906 15-34-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01915, current rewards: 214.54203, mean: 0.10946
[32m[0906 15-34-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 220.08710, mean: 0.10950
[32m[0906 15-34-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01915, current rewards: 225.63761, mean: 0.10953
[32m[0906 15-34-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01915, current rewards: 231.18511, mean: 0.10957
[32m[0906 15-34-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01915, current rewards: 236.73453, mean: 0.10960
[32m[0906 15-34-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 242.29090, mean: 0.10963
[32m[0906 15-34-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01916, current rewards: 247.78654, mean: 0.10964
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 253.34798, mean: 0.10967
[32m[0906 15-34-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 258.91185, mean: 0.10971
[32m[0906 15-34-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 264.47525, mean: 0.10974
[32m[0906 15-34-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 270.02937, mean: 0.10977
[32m[0906 15-34-51 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 15-34-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-34-51 @MBExp.py:227][0m Rewards obtained: [274.48430211139424], Lows: [1], Highs: [1], Total time: 2907.193739
[32m[0906 15-37-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-37-01 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01881, current rewards: 1.08699, mean: 0.10870
[32m[0906 15-37-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01899, current rewards: 6.61676, mean: 0.11028
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01906, current rewards: 12.14644, mean: 0.11042
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.68566, mean: 0.11054
[32m[0906 15-37-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.21250, mean: 0.11054
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 28.74300, mean: 0.11055
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01912, current rewards: 34.27334, mean: 0.11056
[32m[0906 15-37-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 39.81913, mean: 0.11061
[32m[0906 15-37-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.38056, mean: 0.11068
[32m[0906 15-37-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 50.93895, mean: 0.11074
[32m[0906 15-37-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01914, current rewards: 56.50456, mean: 0.11079
[32m[0906 15-37-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.09499, mean: 0.11088
[32m[0906 15-37-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 67.78691, mean: 0.11113
[32m[0906 15-37-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 73.42555, mean: 0.11125
[32m[0906 15-37-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 79.05726, mean: 0.11135
[32m[0906 15-37-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 84.69133, mean: 0.11144
[32m[0906 15-37-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 90.32488, mean: 0.11151
[32m[0906 15-37-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 95.96430, mean: 0.11159
[32m[0906 15-37-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01911, current rewards: 101.47852, mean: 0.11151
[32m[0906 15-37-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: 106.99787, mean: 0.11146
[32m[0906 15-37-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01911, current rewards: 112.46467, mean: 0.11135
[32m[0906 15-37-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: 117.99181, mean: 0.11131
[32m[0906 15-37-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01912, current rewards: 123.52903, mean: 0.11129
[32m[0906 15-37-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: 129.09039, mean: 0.11128
[32m[0906 15-37-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 134.65267, mean: 0.11128
[32m[0906 15-37-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 140.21676, mean: 0.11128
[32m[0906 15-37-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 145.77697, mean: 0.11128
[32m[0906 15-37-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: 151.34358, mean: 0.11128
[32m[0906 15-37-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 157.00022, mean: 0.11135
[32m[0906 15-37-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 162.55034, mean: 0.11134
[32m[0906 15-37-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: 168.10757, mean: 0.11133
[32m[0906 15-37-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: 173.66316, mean: 0.11132
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: 179.19540, mean: 0.11130
[32m[0906 15-37-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01913, current rewards: 184.72147, mean: 0.11128
[32m[0906 15-37-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01913, current rewards: 190.25457, mean: 0.11126
[32m[0906 15-37-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01913, current rewards: 195.79302, mean: 0.11125
[32m[0906 15-37-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 201.29364, mean: 0.11121
[32m[0906 15-37-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: 206.82351, mean: 0.11120
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: 212.35659, mean: 0.11118
[32m[0906 15-37-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 217.89997, mean: 0.11117
[32m[0906 15-37-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01914, current rewards: 223.43949, mean: 0.11116
[32m[0906 15-37-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 229.06836, mean: 0.11120
[32m[0906 15-37-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01914, current rewards: 234.74544, mean: 0.11125
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01914, current rewards: 240.42252, mean: 0.11131
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 246.03972, mean: 0.11133
[32m[0906 15-37-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 251.42323, mean: 0.11125
[32m[0906 15-37-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01915, current rewards: 257.01394, mean: 0.11126
[32m[0906 15-37-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 262.60466, mean: 0.11127
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01915, current rewards: 268.19450, mean: 0.11128
[32m[0906 15-37-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01915, current rewards: 273.78487, mean: 0.11129
[32m[0906 15-37-50 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-37-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-37-50 @MBExp.py:227][0m Rewards obtained: [278.25934385271233], Lows: [0], Highs: [0], Total time: 2955.7599849999997
[32m[0906 15-40-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-02 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 15-40-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01873, current rewards: 1.05731, mean: 0.10573
[32m[0906 15-40-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01908, current rewards: 6.57007, mean: 0.10950
[32m[0906 15-40-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01904, current rewards: 12.08081, mean: 0.10983
[32m[0906 15-40-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.60740, mean: 0.11005
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01912, current rewards: 23.12540, mean: 0.11012
[32m[0906 15-40-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 28.63923, mean: 0.11015
[32m[0906 15-40-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01913, current rewards: 34.15059, mean: 0.11016
[32m[0906 15-40-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.65949, mean: 0.11017
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.25612, mean: 0.11038
[32m[0906 15-40-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 50.76965, mean: 0.11037
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 56.28536, mean: 0.11036
[32m[0906 15-40-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 61.83612, mean: 0.11042
[32m[0906 15-40-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 67.36444, mean: 0.11043
[32m[0906 15-40-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 72.88744, mean: 0.11044
[32m[0906 15-40-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 78.41091, mean: 0.11044
[32m[0906 15-40-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 83.93989, mean: 0.11045
[32m[0906 15-40-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01911, current rewards: 89.46764, mean: 0.11045
[32m[0906 15-40-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 94.99285, mean: 0.11046
[32m[0906 15-40-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 98.45853, mean: 0.10820
[32m[0906 15-40-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 104.37374, mean: 0.10872
[32m[0906 15-40-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 112.67386, mean: 0.11156
[32m[0906 15-40-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 120.97398, mean: 0.11413
[32m[0906 15-40-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 129.27410, mean: 0.11646
[32m[0906 15-40-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01914, current rewards: 137.57422, mean: 0.11860
[32m[0906 15-40-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01913, current rewards: 145.87434, mean: 0.12056
[32m[0906 15-40-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01913, current rewards: 134.35242, mean: 0.10663
[32m[0906 15-40-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 84.35242, mean: 0.06439
[32m[0906 15-40-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01913, current rewards: 34.35242, mean: 0.02526
[32m[0906 15-40-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: -15.64758, mean: -0.01110
[32m[0906 15-40-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: -65.64758, mean: -0.04496
[32m[0906 15-40-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01912, current rewards: -115.64758, mean: -0.07659
[32m[0906 15-40-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01912, current rewards: -165.64758, mean: -0.10618
[32m[0906 15-40-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01912, current rewards: -215.64758, mean: -0.13394
[32m[0906 15-40-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01912, current rewards: -265.64758, mean: -0.16003
[32m[0906 15-40-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01912, current rewards: -315.64758, mean: -0.18459
[32m[0906 15-40-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01912, current rewards: -365.64758, mean: -0.20775
[32m[0906 15-40-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: -415.64758, mean: -0.22964
[32m[0906 15-40-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01913, current rewards: -465.64758, mean: -0.25035
[32m[0906 15-40-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01913, current rewards: -515.64758, mean: -0.26997
[32m[0906 15-40-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01913, current rewards: -565.64758, mean: -0.28860
[32m[0906 15-40-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01912, current rewards: -615.64758, mean: -0.30629
[32m[0906 15-40-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01912, current rewards: -665.64758, mean: -0.32313
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01912, current rewards: -715.64758, mean: -0.33917
[32m[0906 15-40-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01913, current rewards: -765.64758, mean: -0.35447
[32m[0906 15-40-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01913, current rewards: -815.64758, mean: -0.36907
[32m[0906 15-40-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01913, current rewards: -865.64758, mean: -0.38303
[32m[0906 15-40-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: -915.64758, mean: -0.39638
[32m[0906 15-40-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: -965.64758, mean: -0.40917
[32m[0906 15-40-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01911, current rewards: -1015.64758, mean: -0.42143
[32m[0906 15-40-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: -1065.64758, mean: -0.43319
[32m[0906 15-40-51 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-40-51 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-40-51 @MBExp.py:227][0m Rewards obtained: [-1105.6475842328364], Lows: [1], Highs: [1257], Total time: 3004.2176109999996
[32m[0906 15-43-05 @MBExp.py:144][0m ####################################################################
[32m[0906 15-43-05 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 15-43-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01872, current rewards: 1.10145, mean: 0.11015
[32m[0906 15-43-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01902, current rewards: 6.62337, mean: 0.11039
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.17611, mean: 0.11069
[32m[0906 15-43-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01906, current rewards: 17.81967, mean: 0.11137
[32m[0906 15-43-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.35105, mean: 0.11120
[32m[0906 15-43-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 28.88409, mean: 0.11109
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.41888, mean: 0.11103
[32m[0906 15-43-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.93494, mean: 0.11093
[32m[0906 15-43-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01914, current rewards: 45.47661, mean: 0.11092
[32m[0906 15-43-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01915, current rewards: 51.01829, mean: 0.11091
[32m[0906 15-43-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 56.55846, mean: 0.11090
[32m[0906 15-43-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 62.09801, mean: 0.11089
[32m[0906 15-43-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.61451, mean: 0.11084
[32m[0906 15-43-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01915, current rewards: 73.15491, mean: 0.11084
[32m[0906 15-43-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 78.70055, mean: 0.11085
[32m[0906 15-43-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01916, current rewards: 84.24520, mean: 0.11085
[32m[0906 15-43-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01916, current rewards: 89.78868, mean: 0.11085
[32m[0906 15-43-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 95.33395, mean: 0.11085
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01916, current rewards: 100.87747, mean: 0.11085
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 105.63787, mean: 0.11004
[32m[0906 15-43-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 110.65485, mean: 0.10956
[32m[0906 15-43-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 116.16298, mean: 0.10959
[32m[0906 15-43-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 121.66971, mean: 0.10961
[32m[0906 15-43-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 127.17609, mean: 0.10963
[32m[0906 15-43-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01916, current rewards: 131.57051, mean: 0.10874
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 137.07564, mean: 0.10879
[32m[0906 15-43-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: 142.58549, mean: 0.10884
[32m[0906 15-43-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01917, current rewards: 148.15137, mean: 0.10893
[32m[0906 15-43-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01917, current rewards: 153.65389, mean: 0.10897
[32m[0906 15-43-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 159.14930, mean: 0.10901
[32m[0906 15-43-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 164.64551, mean: 0.10904
[32m[0906 15-43-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01918, current rewards: 170.18781, mean: 0.10909
[32m[0906 15-43-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01918, current rewards: 175.72616, mean: 0.10915
[32m[0906 15-43-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01918, current rewards: 181.26584, mean: 0.10920
[32m[0906 15-43-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01918, current rewards: 186.81186, mean: 0.10925
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 192.34680, mean: 0.10929
[32m[0906 15-43-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 197.81700, mean: 0.10929
[32m[0906 15-43-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 203.35512, mean: 0.10933
[32m[0906 15-43-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01918, current rewards: 208.89420, mean: 0.10937
[32m[0906 15-43-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01918, current rewards: 214.42676, mean: 0.10940
[32m[0906 15-43-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01918, current rewards: 219.96085, mean: 0.10943
[32m[0906 15-43-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 225.46081, mean: 0.10945
[32m[0906 15-43-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 230.96764, mean: 0.10946
[32m[0906 15-43-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 236.46641, mean: 0.10948
[32m[0906 15-43-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01917, current rewards: 241.92582, mean: 0.10947
[32m[0906 15-43-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01917, current rewards: 247.43349, mean: 0.10948
[32m[0906 15-43-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01916, current rewards: 252.93432, mean: 0.10950
[32m[0906 15-43-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01915, current rewards: 258.44432, mean: 0.10951
[32m[0906 15-43-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 263.95727, mean: 0.10953
[32m[0906 15-43-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01912, current rewards: 269.45867, mean: 0.10954
[32m[0906 15-43-53 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-43-53 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-43-53 @MBExp.py:227][0m Rewards obtained: [273.86300150481026], Lows: [0], Highs: [1], Total time: 3052.7434269999994
[32m[0906 15-46-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-46-09 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 15-46-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01860, current rewards: 1.13075, mean: 0.11307
[32m[0906 15-46-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01896, current rewards: 6.70469, mean: 0.11174
[32m[0906 15-46-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 12.22124, mean: 0.11110
[32m[0906 15-46-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.69787, mean: 0.11061
[32m[0906 15-46-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.23456, mean: 0.11064
[32m[0906 15-46-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01914, current rewards: 28.77340, mean: 0.11067
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 34.30832, mean: 0.11067
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01918, current rewards: 39.84080, mean: 0.11067
[32m[0906 15-46-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01917, current rewards: 45.37647, mean: 0.11067
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01918, current rewards: 50.81270, mean: 0.11046
[32m[0906 15-46-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01917, current rewards: 56.24615, mean: 0.11029
[32m[0906 15-46-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 61.67961, mean: 0.11014
[32m[0906 15-46-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.11344, mean: 0.11002
[32m[0906 15-46-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 72.54889, mean: 0.10992
[32m[0906 15-46-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01916, current rewards: 76.91643, mean: 0.10833
[32m[0906 15-46-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01918, current rewards: 82.48411, mean: 0.10853
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01918, current rewards: 88.05521, mean: 0.10871
[32m[0906 15-46-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01917, current rewards: 93.61189, mean: 0.10885
[32m[0906 15-46-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01918, current rewards: 99.16834, mean: 0.10898
[32m[0906 15-46-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01918, current rewards: 104.82149, mean: 0.10919
[32m[0906 15-46-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01918, current rewards: 110.38821, mean: 0.10930
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01919, current rewards: 115.96218, mean: 0.10940
[32m[0906 15-46-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01919, current rewards: 121.49786, mean: 0.10946
[32m[0906 15-46-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01919, current rewards: 127.04404, mean: 0.10952
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01918, current rewards: 132.58862, mean: 0.10958
[32m[0906 15-46-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 138.14238, mean: 0.10964
[32m[0906 15-46-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01918, current rewards: 143.68918, mean: 0.10969
[32m[0906 15-46-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01918, current rewards: 149.17381, mean: 0.10969
[32m[0906 15-46-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01918, current rewards: 154.71641, mean: 0.10973
[32m[0906 15-46-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01918, current rewards: 160.26507, mean: 0.10977
[32m[0906 15-46-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01918, current rewards: 165.81408, mean: 0.10981
[32m[0906 15-46-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01917, current rewards: 171.35063, mean: 0.10984
[32m[0906 15-46-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01917, current rewards: 176.87268, mean: 0.10986
[32m[0906 15-46-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01917, current rewards: 182.39958, mean: 0.10988
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01918, current rewards: 187.93386, mean: 0.10990
[32m[0906 15-46-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01918, current rewards: 193.50045, mean: 0.10994
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01918, current rewards: 199.08817, mean: 0.10999
[32m[0906 15-46-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01918, current rewards: 204.62450, mean: 0.11001
[32m[0906 15-46-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01918, current rewards: 210.16222, mean: 0.11003
[32m[0906 15-46-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01917, current rewards: 215.70150, mean: 0.11005
[32m[0906 15-46-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01917, current rewards: 221.23518, mean: 0.11007
[32m[0906 15-46-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01917, current rewards: 226.77589, mean: 0.11009
[32m[0906 15-46-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01917, current rewards: 232.33620, mean: 0.11011
[32m[0906 15-46-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 237.87790, mean: 0.11013
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01916, current rewards: 243.30471, mean: 0.11009
[32m[0906 15-46-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 248.83907, mean: 0.11011
[32m[0906 15-46-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 254.37631, mean: 0.11012
[32m[0906 15-46-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01912, current rewards: 259.91296, mean: 0.11013
[32m[0906 15-46-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 265.44851, mean: 0.11014
[32m[0906 15-46-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 270.97696, mean: 0.11015
[32m[0906 15-46-58 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-46-58 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-46-58 @MBExp.py:227][0m Rewards obtained: [275.4054394610294], Lows: [0], Highs: [1], Total time: 3101.1919429999994
[32m[0906 15-49-17 @MBExp.py:144][0m ####################################################################
[32m[0906 15-49-17 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01882, current rewards: 0.04010, mean: 0.00401
[32m[0906 15-49-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01891, current rewards: 5.77044, mean: 0.09617
[32m[0906 15-49-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 11.40775, mean: 0.10371
[32m[0906 15-49-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 16.89503, mean: 0.10559
[32m[0906 15-49-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 22.48144, mean: 0.10705
[32m[0906 15-49-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01919, current rewards: 28.05512, mean: 0.10790
[32m[0906 15-49-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01920, current rewards: 33.64150, mean: 0.10852
[32m[0906 15-49-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01920, current rewards: 39.22155, mean: 0.10895
[32m[0906 15-49-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01920, current rewards: 44.80074, mean: 0.10927
[32m[0906 15-49-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01920, current rewards: 50.38314, mean: 0.10953
[32m[0906 15-49-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01919, current rewards: 55.96665, mean: 0.10974
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01920, current rewards: 61.55084, mean: 0.10991
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01919, current rewards: 67.17349, mean: 0.11012
[32m[0906 15-49-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 72.85788, mean: 0.11039
[32m[0906 15-49-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01919, current rewards: 78.54196, mean: 0.11062
[32m[0906 15-49-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01920, current rewards: 84.22250, mean: 0.11082
[32m[0906 15-49-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01920, current rewards: 89.90851, mean: 0.11100
[32m[0906 15-49-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01921, current rewards: 95.59094, mean: 0.11115
[32m[0906 15-49-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01920, current rewards: 101.27270, mean: 0.11129
[32m[0906 15-49-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01921, current rewards: 106.96685, mean: 0.11142
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01921, current rewards: 112.64905, mean: 0.11153
[32m[0906 15-49-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01921, current rewards: 118.33188, mean: 0.11163
[32m[0906 15-49-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01921, current rewards: 122.81829, mean: 0.11065
[32m[0906 15-49-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01920, current rewards: 128.29361, mean: 0.11060
[32m[0906 15-49-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 133.76808, mean: 0.11055
[32m[0906 15-49-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01920, current rewards: 139.24311, mean: 0.11051
[32m[0906 15-49-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01920, current rewards: 144.70440, mean: 0.11046
[32m[0906 15-49-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01920, current rewards: 150.20488, mean: 0.11044
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01920, current rewards: 155.67777, mean: 0.11041
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01919, current rewards: 161.14968, mean: 0.11038
[32m[0906 15-49-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01919, current rewards: 166.72119, mean: 0.11041
[32m[0906 15-49-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01919, current rewards: 172.29620, mean: 0.11045
[32m[0906 15-49-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01920, current rewards: 177.86896, mean: 0.11048
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01920, current rewards: 183.44146, mean: 0.11051
[32m[0906 15-49-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01920, current rewards: 189.01613, mean: 0.11054
[32m[0906 15-49-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01920, current rewards: 194.59012, mean: 0.11056
[32m[0906 15-49-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01920, current rewards: 200.20825, mean: 0.11061
[32m[0906 15-49-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01920, current rewards: 205.78068, mean: 0.11063
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01920, current rewards: 211.35646, mean: 0.11066
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01920, current rewards: 216.93037, mean: 0.11068
[32m[0906 15-49-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01920, current rewards: 222.51234, mean: 0.11070
[32m[0906 15-49-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01920, current rewards: 228.09134, mean: 0.11072
[32m[0906 15-49-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01918, current rewards: 233.66373, mean: 0.11074
[32m[0906 15-49-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01916, current rewards: 239.24477, mean: 0.11076
[32m[0906 15-49-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01915, current rewards: 244.83038, mean: 0.11078
[32m[0906 15-50-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01914, current rewards: 250.41225, mean: 0.11080
[32m[0906 15-50-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01913, current rewards: 255.98802, mean: 0.11082
[32m[0906 15-50-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01911, current rewards: 261.56709, mean: 0.11083
[32m[0906 15-50-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01910, current rewards: 267.14516, mean: 0.11085
[32m[0906 15-50-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01909, current rewards: 272.72571, mean: 0.11086
[32m[0906 15-50-05 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 15-50-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-50-05 @MBExp.py:227][0m Rewards obtained: [277.1904740278738], Lows: [0], Highs: [2], Total time: 3149.6419159999996
[32m[0906 15-52-26 @MBExp.py:144][0m ####################################################################
[32m[0906 15-52-26 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 15-52-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01909, current rewards: 1.03082, mean: 0.10308
[32m[0906 15-52-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: 6.51084, mean: 0.10851
[32m[0906 15-52-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01915, current rewards: 12.03789, mean: 0.10944
[32m[0906 15-52-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01917, current rewards: 17.52412, mean: 0.10953
[32m[0906 15-52-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 23.01132, mean: 0.10958
[32m[0906 15-52-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01913, current rewards: 28.49674, mean: 0.10960
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 33.98327, mean: 0.10962
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 39.47195, mean: 0.10964
[32m[0906 15-52-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01915, current rewards: 44.96299, mean: 0.10967
[32m[0906 15-52-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01917, current rewards: 50.72769, mean: 0.11028
[32m[0906 15-52-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 56.26680, mean: 0.11033
[32m[0906 15-52-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 61.72993, mean: 0.11023
[32m[0906 15-52-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01916, current rewards: 67.19286, mean: 0.11015
[32m[0906 15-52-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01916, current rewards: 72.65603, mean: 0.11008
[32m[0906 15-52-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01917, current rewards: 78.12002, mean: 0.11003
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01917, current rewards: 83.58338, mean: 0.10998
[32m[0906 15-52-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 89.04602, mean: 0.10993
[32m[0906 15-52-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 93.40369, mean: 0.10861
[32m[0906 15-52-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01917, current rewards: 98.98066, mean: 0.10877
[32m[0906 15-52-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 104.51593, mean: 0.10887
[32m[0906 15-52-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 110.05015, mean: 0.10896
[32m[0906 15-52-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01916, current rewards: 115.58493, mean: 0.10904
[32m[0906 15-52-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 121.12312, mean: 0.10912
[32m[0906 15-52-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 126.65888, mean: 0.10919
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 132.32230, mean: 0.10936
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01915, current rewards: 137.84796, mean: 0.10940
[32m[0906 15-52-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 143.34496, mean: 0.10942
[32m[0906 15-52-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 148.87350, mean: 0.10947
[32m[0906 15-52-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 154.39777, mean: 0.10950
[32m[0906 15-52-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01915, current rewards: 159.91997, mean: 0.10953
[32m[0906 15-52-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01916, current rewards: 165.45939, mean: 0.10958
[32m[0906 15-52-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01916, current rewards: 171.02077, mean: 0.10963
[32m[0906 15-52-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01916, current rewards: 176.57910, mean: 0.10968
[32m[0906 15-52-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01916, current rewards: 182.14719, mean: 0.10973
[32m[0906 15-52-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01916, current rewards: 187.65924, mean: 0.10974
[32m[0906 15-53-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01916, current rewards: 193.17857, mean: 0.10976
[32m[0906 15-53-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01916, current rewards: 198.73622, mean: 0.10980
[32m[0906 15-53-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01916, current rewards: 204.29447, mean: 0.10984
[32m[0906 15-53-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01916, current rewards: 209.85914, mean: 0.10987
[32m[0906 15-53-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01917, current rewards: 215.41521, mean: 0.10991
[32m[0906 15-53-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01915, current rewards: 220.97801, mean: 0.10994
[32m[0906 15-53-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01914, current rewards: 226.60498, mean: 0.11000
[32m[0906 15-53-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01913, current rewards: 232.39603, mean: 0.11014
[32m[0906 15-53-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01911, current rewards: 238.18933, mean: 0.11027
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01910, current rewards: 243.97927, mean: 0.11040
[32m[0906 15-53-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01909, current rewards: 249.76503, mean: 0.11052
[32m[0906 15-53-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01908, current rewards: 255.55505, mean: 0.11063
[32m[0906 15-53-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01906, current rewards: 261.34526, mean: 0.11074
[32m[0906 15-53-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01905, current rewards: 264.81096, mean: 0.10988
[32m[0906 15-53-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01903, current rewards: 270.29295, mean: 0.10988
[32m[0906 15-53-14 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-53-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-53-14 @MBExp.py:227][0m Rewards obtained: [274.67516535565863], Lows: [1], Highs: [1], Total time: 3197.9611089999994
[32m[0906 15-55-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-36 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 15-55-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01891, current rewards: 1.64209, mean: 0.16421
[32m[0906 15-55-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01919, current rewards: 7.24117, mean: 0.12069
[32m[0906 15-55-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01912, current rewards: 12.91183, mean: 0.11738
[32m[0906 15-55-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 18.54460, mean: 0.11590
[32m[0906 15-55-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 24.17046, mean: 0.11510
[32m[0906 15-55-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 29.79483, mean: 0.11460
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 35.32766, mean: 0.11396
[32m[0906 15-55-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 40.88706, mean: 0.11358
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01911, current rewards: 46.44516, mean: 0.11328
[32m[0906 15-55-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 52.00134, mean: 0.11305
[32m[0906 15-55-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01906, current rewards: 57.52753, mean: 0.11280
[32m[0906 15-55-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: 63.08225, mean: 0.11265
[32m[0906 15-55-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: 68.64195, mean: 0.11253
[32m[0906 15-55-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: 74.19810, mean: 0.11242
[32m[0906 15-55-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01908, current rewards: 79.75680, mean: 0.11233
[32m[0906 15-55-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01907, current rewards: 85.31325, mean: 0.11225
[32m[0906 15-55-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01907, current rewards: 90.86854, mean: 0.11218
[32m[0906 15-55-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01907, current rewards: 96.51678, mean: 0.11223
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01906, current rewards: 102.13085, mean: 0.11223
[32m[0906 15-55-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 107.79596, mean: 0.11229
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01907, current rewards: 113.45798, mean: 0.11233
[32m[0906 15-55-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 119.12661, mean: 0.11238
[32m[0906 15-55-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01908, current rewards: 124.78874, mean: 0.11242
[32m[0906 15-55-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 130.38652, mean: 0.11240
[32m[0906 15-56-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 135.93270, mean: 0.11234
[32m[0906 15-56-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01908, current rewards: 141.48348, mean: 0.11229
[32m[0906 15-56-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01909, current rewards: 147.11798, mean: 0.11230
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01908, current rewards: 152.67970, mean: 0.11226
[32m[0906 15-56-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01908, current rewards: 158.23348, mean: 0.11222
[32m[0906 15-56-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01909, current rewards: 163.78715, mean: 0.11218
[32m[0906 15-56-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 169.32005, mean: 0.11213
[32m[0906 15-56-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 174.86306, mean: 0.11209
[32m[0906 15-56-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 180.41010, mean: 0.11206
[32m[0906 15-56-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01911, current rewards: 185.94783, mean: 0.11202
[32m[0906 15-56-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01911, current rewards: 191.48717, mean: 0.11198
[32m[0906 15-56-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01911, current rewards: 196.96020, mean: 0.11191
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01911, current rewards: 202.50245, mean: 0.11188
[32m[0906 15-56-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01911, current rewards: 208.03487, mean: 0.11185
[32m[0906 15-56-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01909, current rewards: 213.57353, mean: 0.11182
[32m[0906 15-56-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 219.10939, mean: 0.11179
[32m[0906 15-56-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 224.63674, mean: 0.11176
[32m[0906 15-56-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01905, current rewards: 230.12720, mean: 0.11171
[32m[0906 15-56-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01904, current rewards: 235.67191, mean: 0.11169
[32m[0906 15-56-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01902, current rewards: 241.30115, mean: 0.11171
[32m[0906 15-56-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01901, current rewards: 246.84445, mean: 0.11169
[32m[0906 15-56-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 252.38986, mean: 0.11168
[32m[0906 15-56-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01898, current rewards: 257.90633, mean: 0.11165
[32m[0906 15-56-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01897, current rewards: 263.46233, mean: 0.11164
[32m[0906 15-56-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01897, current rewards: 269.01821, mean: 0.11163
[32m[0906 15-56-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01896, current rewards: 274.57855, mean: 0.11162
[32m[0906 15-56-24 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 15-56-24 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-56-24 @MBExp.py:227][0m Rewards obtained: [279.02463434942376], Lows: [0], Highs: [0], Total time: 3246.1160819999996
[32m[0906 15-58-49 @MBExp.py:144][0m ####################################################################
[32m[0906 15-58-49 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 15-58-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01850, current rewards: -1.02305, mean: -0.10231
[32m[0906 15-58-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01918, current rewards: 4.52357, mean: 0.07539
[32m[0906 15-58-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01909, current rewards: 10.19367, mean: 0.09267
[32m[0906 15-58-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01911, current rewards: 15.83288, mean: 0.09896
[32m[0906 15-58-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01913, current rewards: 21.47441, mean: 0.10226
[32m[0906 15-58-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01915, current rewards: 27.11809, mean: 0.10430
[32m[0906 15-58-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 32.75386, mean: 0.10566
[32m[0906 15-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01914, current rewards: 38.40550, mean: 0.10668
[32m[0906 15-58-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 44.05139, mean: 0.10744
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01919, current rewards: 49.69212, mean: 0.10803
[32m[0906 15-58-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01918, current rewards: 55.41010, mean: 0.10865
[32m[0906 15-59-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01917, current rewards: 61.06115, mean: 0.10904
[32m[0906 15-59-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01917, current rewards: 66.70658, mean: 0.10936
[32m[0906 15-59-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01917, current rewards: 72.34110, mean: 0.10961
[32m[0906 15-59-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01915, current rewards: 77.94733, mean: 0.10978
[32m[0906 15-59-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01915, current rewards: 83.56366, mean: 0.10995
[32m[0906 15-59-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01915, current rewards: 89.17571, mean: 0.11009
[32m[0906 15-59-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01916, current rewards: 94.79059, mean: 0.11022
[32m[0906 15-59-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 100.40892, mean: 0.11034
[32m[0906 15-59-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 106.04255, mean: 0.11046
[32m[0906 15-59-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 111.64737, mean: 0.11054
[32m[0906 15-59-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 117.25022, mean: 0.11061
[32m[0906 15-59-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01916, current rewards: 122.85731, mean: 0.11068
[32m[0906 15-59-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01917, current rewards: 128.46547, mean: 0.11075
[32m[0906 15-59-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 134.06758, mean: 0.11080
[32m[0906 15-59-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01914, current rewards: 139.63963, mean: 0.11083
[32m[0906 15-59-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01915, current rewards: 145.17944, mean: 0.11082
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01914, current rewards: 150.65959, mean: 0.11078
[32m[0906 15-59-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01915, current rewards: 156.23367, mean: 0.11080
[32m[0906 15-59-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01915, current rewards: 161.80922, mean: 0.11083
[32m[0906 15-59-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01915, current rewards: 167.38631, mean: 0.11085
[32m[0906 15-59-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01915, current rewards: 172.96083, mean: 0.11087
[32m[0906 15-59-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01914, current rewards: 178.53334, mean: 0.11089
[32m[0906 15-59-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01915, current rewards: 184.11036, mean: 0.11091
[32m[0906 15-59-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01915, current rewards: 189.68404, mean: 0.11093
[32m[0906 15-59-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01915, current rewards: 195.54404, mean: 0.11110
[32m[0906 15-59-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01913, current rewards: 201.23443, mean: 0.11118
[32m[0906 15-59-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01912, current rewards: 206.92816, mean: 0.11125
[32m[0906 15-59-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01910, current rewards: 212.61853, mean: 0.11132
[32m[0906 15-59-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01908, current rewards: 218.31309, mean: 0.11138
[32m[0906 15-59-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01907, current rewards: 224.00508, mean: 0.11145
[32m[0906 15-59-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01905, current rewards: 229.69734, mean: 0.11150
[32m[0906 15-59-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01904, current rewards: 234.27037, mean: 0.11103
[32m[0906 15-59-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01902, current rewards: 239.84233, mean: 0.11104
[32m[0906 15-59-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01901, current rewards: 245.45418, mean: 0.11107
[32m[0906 15-59-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01900, current rewards: 251.05850, mean: 0.11109
[32m[0906 15-59-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01899, current rewards: 256.66170, mean: 0.11111
[32m[0906 15-59-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01898, current rewards: 262.26927, mean: 0.11113
[32m[0906 15-59-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01897, current rewards: 267.87335, mean: 0.11115
[32m[0906 15-59-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01897, current rewards: 273.47752, mean: 0.11117
[32m[0906 15-59-37 @Agent.py:117][0m Average action selection time: 0.0190
[32m[0906 15-59-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 15-59-37 @MBExp.py:227][0m Rewards obtained: [277.9741107316876], Lows: [1], Highs: [1], Total time: 3294.2770669999995
[32m[0906 16-02-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-02-04 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-02-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.64735, mean: 0.16473
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01883, current rewards: 7.32098, mean: 0.12202
[32m[0906 16-02-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01896, current rewards: 13.62559, mean: 0.12387
[32m[0906 16-02-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01897, current rewards: 20.08441, mean: 0.12553
[32m[0906 16-02-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 26.54323, mean: 0.12640
[32m[0906 16-02-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 33.00206, mean: 0.12693
[32m[0906 16-02-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.94418, mean: 0.11272
[32m[0906 16-02-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: -15.05582, mean: -0.04182
[32m[0906 16-02-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01910, current rewards: -65.05582, mean: -0.15867
[32m[0906 16-02-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: -115.05582, mean: -0.25012
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: -165.05582, mean: -0.32364
[32m[0906 16-02-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01908, current rewards: -215.05582, mean: -0.38403
[32m[0906 16-02-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: -265.05582, mean: -0.43452
[32m[0906 16-02-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01908, current rewards: -315.05582, mean: -0.47736
[32m[0906 16-02-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: -365.05582, mean: -0.51416
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: -415.05582, mean: -0.54613
[32m[0906 16-02-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: -465.05582, mean: -0.57414
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: -515.05582, mean: -0.59890
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01910, current rewards: -565.05582, mean: -0.62094
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01911, current rewards: -615.05582, mean: -0.64068
[32m[0906 16-02-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01912, current rewards: -665.05582, mean: -0.65847
[32m[0906 16-02-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01911, current rewards: -715.05582, mean: -0.67458
[32m[0906 16-02-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: -765.05582, mean: -0.68924
[32m[0906 16-02-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01911, current rewards: -815.05582, mean: -0.70263
[32m[0906 16-02-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01911, current rewards: -865.05582, mean: -0.71492
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01911, current rewards: -915.05582, mean: -0.72623
[32m[0906 16-02-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01911, current rewards: -965.05582, mean: -0.73668
[32m[0906 16-02-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01911, current rewards: -1015.05582, mean: -0.74636
[32m[0906 16-02-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01911, current rewards: -1065.05582, mean: -0.75536
[32m[0906 16-02-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01911, current rewards: -1115.05582, mean: -0.76374
[32m[0906 16-02-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: -1165.05582, mean: -0.77156
[32m[0906 16-02-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: -1215.05582, mean: -0.77888
[32m[0906 16-02-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01911, current rewards: -1265.05582, mean: -0.78575
[32m[0906 16-02-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01910, current rewards: -1315.05582, mean: -0.79220
[32m[0906 16-02-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01909, current rewards: -1365.05582, mean: -0.79828
[32m[0906 16-02-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01907, current rewards: -1415.05582, mean: -0.80401
[32m[0906 16-02-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01905, current rewards: -1465.05582, mean: -0.80942
[32m[0906 16-02-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01903, current rewards: -1515.05582, mean: -0.81455
[32m[0906 16-02-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01902, current rewards: -1565.05582, mean: -0.81940
[32m[0906 16-02-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01901, current rewards: -1615.05582, mean: -0.82401
[32m[0906 16-02-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01900, current rewards: -1665.05582, mean: -0.82839
[32m[0906 16-02-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01898, current rewards: -1715.05582, mean: -0.83255
[32m[0906 16-02-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01897, current rewards: -1765.05582, mean: -0.83652
[32m[0906 16-02-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01896, current rewards: -1815.05582, mean: -0.84030
[32m[0906 16-02-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: -1865.05582, mean: -0.84392
[32m[0906 16-02-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01893, current rewards: -1915.05582, mean: -0.84737
[32m[0906 16-02-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: -1965.05582, mean: -0.85067
[32m[0906 16-02-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: -2015.05582, mean: -0.85384
[32m[0906 16-02-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01890, current rewards: -2065.05582, mean: -0.85687
[32m[0906 16-02-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: -2115.05582, mean: -0.85978
[32m[0906 16-02-52 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-02-52 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-02-52 @MBExp.py:227][0m Rewards obtained: [-2155.055824984699], Lows: [0], Highs: [2194], Total time: 3342.2789909999997
[32m[0906 16-05-21 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-21 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-05-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01851, current rewards: 1.17329, mean: 0.11733
[32m[0906 16-05-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01905, current rewards: 6.66956, mean: 0.11116
[32m[0906 16-05-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01898, current rewards: 12.24650, mean: 0.11133
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01898, current rewards: 17.77316, mean: 0.11108
[32m[0906 16-05-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01900, current rewards: 22.58667, mean: 0.10756
[32m[0906 16-05-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01903, current rewards: 31.12459, mean: 0.11971
[32m[0906 16-05-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01903, current rewards: 39.66251, mean: 0.12794
[32m[0906 16-05-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01905, current rewards: 48.20043, mean: 0.13389
[32m[0906 16-05-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01905, current rewards: 56.73835, mean: 0.13839
[32m[0906 16-05-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01905, current rewards: 65.27627, mean: 0.14190
[32m[0906 16-05-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01905, current rewards: 72.39524, mean: 0.14195
[32m[0906 16-05-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01902, current rewards: 54.26608, mean: 0.09690
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01902, current rewards: 4.26608, mean: 0.00699
[32m[0906 16-05-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01902, current rewards: -45.73392, mean: -0.06929
[32m[0906 16-05-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01902, current rewards: -95.73392, mean: -0.13484
[32m[0906 16-05-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01902, current rewards: -145.73392, mean: -0.19176
[32m[0906 16-05-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01902, current rewards: -195.73392, mean: -0.24165
[32m[0906 16-05-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01902, current rewards: -245.73392, mean: -0.28574
[32m[0906 16-05-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01903, current rewards: -295.73392, mean: -0.32498
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01904, current rewards: -345.73392, mean: -0.36014
[32m[0906 16-05-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01904, current rewards: -395.73392, mean: -0.39182
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01903, current rewards: -445.73392, mean: -0.42050
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01903, current rewards: -495.73392, mean: -0.44661
[32m[0906 16-05-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01904, current rewards: -545.73392, mean: -0.47046
[32m[0906 16-05-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01904, current rewards: -595.73392, mean: -0.49234
[32m[0906 16-05-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01904, current rewards: -645.73392, mean: -0.51249
[32m[0906 16-05-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01905, current rewards: -695.73392, mean: -0.53109
[32m[0906 16-05-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01905, current rewards: -745.73392, mean: -0.54833
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: -795.73392, mean: -0.56435
[32m[0906 16-05-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01906, current rewards: -845.73392, mean: -0.57927
[32m[0906 16-05-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01906, current rewards: -895.73392, mean: -0.59320
[32m[0906 16-05-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: -945.73392, mean: -0.60624
[32m[0906 16-05-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: -995.73392, mean: -0.61847
[32m[0906 16-05-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01902, current rewards: -1045.73392, mean: -0.62996
[32m[0906 16-05-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: -1095.73392, mean: -0.64078
[32m[0906 16-05-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01899, current rewards: -1145.73392, mean: -0.65099
[32m[0906 16-05-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: -1195.73392, mean: -0.66063
[32m[0906 16-05-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: -1245.73392, mean: -0.66975
[32m[0906 16-05-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01894, current rewards: -1295.73392, mean: -0.67839
[32m[0906 16-05-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01893, current rewards: -1345.73392, mean: -0.68660
[32m[0906 16-06-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01892, current rewards: -1395.73392, mean: -0.69439
[32m[0906 16-06-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01891, current rewards: -1445.73392, mean: -0.70181
[32m[0906 16-06-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01889, current rewards: -1495.73392, mean: -0.70888
[32m[0906 16-06-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01888, current rewards: -1545.73392, mean: -0.71562
[32m[0906 16-06-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01888, current rewards: -1595.73392, mean: -0.72205
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01886, current rewards: -1645.73392, mean: -0.72820
[32m[0906 16-06-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01885, current rewards: -1695.73392, mean: -0.73408
[32m[0906 16-06-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01884, current rewards: -1745.73392, mean: -0.73972
[32m[0906 16-06-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01883, current rewards: -1795.73392, mean: -0.74512
[32m[0906 16-06-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01882, current rewards: -1845.73392, mean: -0.75030
[32m[0906 16-06-09 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-06-09 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-06-09 @MBExp.py:227][0m Rewards obtained: [-1885.7339198258205], Lows: [1], Highs: [1960], Total time: 3390.0661139999997
[32m[0906 16-08-40 @MBExp.py:144][0m ####################################################################
[32m[0906 16-08-40 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-08-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01924, current rewards: 1.59153, mean: 0.15915
[32m[0906 16-08-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01898, current rewards: 7.03859, mean: 0.11731
[32m[0906 16-08-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01903, current rewards: 12.69510, mean: 0.11541
[32m[0906 16-08-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01904, current rewards: 18.22914, mean: 0.11393
[32m[0906 16-08-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 23.76524, mean: 0.11317
[32m[0906 16-08-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 29.30317, mean: 0.11270
[32m[0906 16-08-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.84360, mean: 0.11240
[32m[0906 16-08-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01912, current rewards: 40.47290, mean: 0.11242
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 45.92018, mean: 0.11200
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01909, current rewards: 51.36735, mean: 0.11167
[32m[0906 16-08-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01909, current rewards: 56.76851, mean: 0.11131
[32m[0906 16-08-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 62.33648, mean: 0.11132
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01910, current rewards: 67.99223, mean: 0.11146
[32m[0906 16-08-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01909, current rewards: 73.52418, mean: 0.11140
[32m[0906 16-08-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01909, current rewards: 79.10777, mean: 0.11142
[32m[0906 16-08-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 84.70181, mean: 0.11145
[32m[0906 16-08-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 90.29492, mean: 0.11148
[32m[0906 16-08-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01911, current rewards: 95.89064, mean: 0.11150
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 101.47877, mean: 0.11152
[32m[0906 16-08-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01912, current rewards: 107.07553, mean: 0.11154
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01913, current rewards: 112.66780, mean: 0.11155
[32m[0906 16-09-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01913, current rewards: 118.26634, mean: 0.11157
[32m[0906 16-09-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01913, current rewards: 123.86399, mean: 0.11159
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01913, current rewards: 129.45587, mean: 0.11160
[32m[0906 16-09-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01912, current rewards: 135.05010, mean: 0.11161
[32m[0906 16-09-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01912, current rewards: 140.58582, mean: 0.11158
[32m[0906 16-09-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01912, current rewards: 146.14453, mean: 0.11156
[32m[0906 16-09-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01912, current rewards: 151.82303, mean: 0.11163
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 157.38686, mean: 0.11162
[32m[0906 16-09-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01913, current rewards: 162.95364, mean: 0.11161
[32m[0906 16-09-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01913, current rewards: 168.51681, mean: 0.11160
[32m[0906 16-09-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01910, current rewards: 174.08323, mean: 0.11159
[32m[0906 16-09-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01910, current rewards: 179.62085, mean: 0.11157
[32m[0906 16-09-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01908, current rewards: 185.17563, mean: 0.11155
[32m[0906 16-09-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01906, current rewards: 190.73278, mean: 0.11154
[32m[0906 16-09-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01905, current rewards: 196.27892, mean: 0.11152
[32m[0906 16-09-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01903, current rewards: 201.82954, mean: 0.11151
[32m[0906 16-09-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01902, current rewards: 207.38531, mean: 0.11150
[32m[0906 16-09-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01901, current rewards: 212.93791, mean: 0.11149
[32m[0906 16-09-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01900, current rewards: 218.49491, mean: 0.11148
[32m[0906 16-09-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01899, current rewards: 224.04844, mean: 0.11147
[32m[0906 16-09-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01897, current rewards: 229.60245, mean: 0.11146
[32m[0906 16-09-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01896, current rewards: 235.15830, mean: 0.11145
[32m[0906 16-09-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: 240.65858, mean: 0.11142
[32m[0906 16-09-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01895, current rewards: 246.21927, mean: 0.11141
[32m[0906 16-09-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01894, current rewards: 251.77785, mean: 0.11141
[32m[0906 16-09-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01892, current rewards: 257.33677, mean: 0.11140
[32m[0906 16-09-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01891, current rewards: 262.88846, mean: 0.11139
[32m[0906 16-09-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 268.43785, mean: 0.11138
[32m[0906 16-09-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01890, current rewards: 273.99827, mean: 0.11138
[32m[0906 16-09-27 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-09-27 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-09-28 @MBExp.py:227][0m Rewards obtained: [278.4422452127499], Lows: [0], Highs: [0], Total time: 3438.0855859999997
[32m[0906 16-12-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-12-01 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-12-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01910, current rewards: -1.02395, mean: -0.10239
[32m[0906 16-12-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01909, current rewards: 4.48345, mean: 0.07472
[32m[0906 16-12-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 10.06338, mean: 0.09149
[32m[0906 16-12-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01914, current rewards: 15.59919, mean: 0.09749
[32m[0906 16-12-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: 21.13380, mean: 0.10064
[32m[0906 16-12-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01917, current rewards: 26.66738, mean: 0.10257
[32m[0906 16-12-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01917, current rewards: 32.20114, mean: 0.10387
[32m[0906 16-12-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 37.73553, mean: 0.10482
[32m[0906 16-12-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 43.26740, mean: 0.10553
[32m[0906 16-12-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01914, current rewards: 48.80089, mean: 0.10609
[32m[0906 16-12-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01915, current rewards: 54.23959, mean: 0.10635
[32m[0906 16-12-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01915, current rewards: 59.74902, mean: 0.10669
[32m[0906 16-12-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01915, current rewards: 65.29096, mean: 0.10703
[32m[0906 16-12-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01914, current rewards: 70.82556, mean: 0.10731
[32m[0906 16-12-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 76.36315, mean: 0.10755
[32m[0906 16-12-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 81.90156, mean: 0.10777
[32m[0906 16-12-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 87.43284, mean: 0.10794
[32m[0906 16-12-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 92.96924, mean: 0.10810
[32m[0906 16-12-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01913, current rewards: 98.50830, mean: 0.10825
[32m[0906 16-12-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01915, current rewards: 104.05095, mean: 0.10839
[32m[0906 16-12-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01915, current rewards: 109.58584, mean: 0.10850
[32m[0906 16-12-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01915, current rewards: 115.12037, mean: 0.10860
[32m[0906 16-12-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01915, current rewards: 120.75526, mean: 0.10879
[32m[0906 16-12-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01915, current rewards: 126.29610, mean: 0.10888
[32m[0906 16-12-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01915, current rewards: 131.83853, mean: 0.10896
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01916, current rewards: 137.37826, mean: 0.10903
[32m[0906 16-12-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01916, current rewards: 142.88354, mean: 0.10907
[32m[0906 16-12-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01916, current rewards: 148.39557, mean: 0.10911
[32m[0906 16-12-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01916, current rewards: 153.92812, mean: 0.10917
[32m[0906 16-12-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01912, current rewards: 159.46095, mean: 0.10922
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01910, current rewards: 164.99274, mean: 0.10927
[32m[0906 16-12-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01908, current rewards: 170.52348, mean: 0.10931
[32m[0906 16-12-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01906, current rewards: 176.05544, mean: 0.10935
[32m[0906 16-12-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01905, current rewards: 181.58896, mean: 0.10939
[32m[0906 16-12-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01903, current rewards: 187.12048, mean: 0.10943
[32m[0906 16-12-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01901, current rewards: 193.14266, mean: 0.10974
[32m[0906 16-12-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01900, current rewards: 199.75089, mean: 0.11036
[32m[0906 16-12-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01899, current rewards: 162.20470, mean: 0.08721
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01898, current rewards: 112.20470, mean: 0.05875
[32m[0906 16-12-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01896, current rewards: 62.20470, mean: 0.03174
[32m[0906 16-12-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01895, current rewards: 12.20470, mean: 0.00607
[32m[0906 16-12-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01894, current rewards: -37.79530, mean: -0.01835
[32m[0906 16-12-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01893, current rewards: -87.79530, mean: -0.04161
[32m[0906 16-12-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01893, current rewards: -137.79530, mean: -0.06379
[32m[0906 16-12-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01892, current rewards: -187.79530, mean: -0.08498
[32m[0906 16-12-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01891, current rewards: -237.79530, mean: -0.10522
[32m[0906 16-12-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01890, current rewards: -287.79530, mean: -0.12459
[32m[0906 16-12-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01889, current rewards: -337.79530, mean: -0.14313
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01889, current rewards: -387.79530, mean: -0.16091
[32m[0906 16-12-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01887, current rewards: -437.79530, mean: -0.17797
[32m[0906 16-12-49 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 16-12-49 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-12-49 @MBExp.py:227][0m Rewards obtained: [-477.79529512214316], Lows: [1], Highs: [679], Total time: 3486.0437989999996
[32m[0906 16-15-24 @MBExp.py:144][0m ####################################################################
[32m[0906 16-15-24 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-15-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01874, current rewards: -0.09087, mean: -0.00909
[32m[0906 16-15-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01890, current rewards: 5.43173, mean: 0.09053
[32m[0906 16-15-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01899, current rewards: 10.97394, mean: 0.09976
[32m[0906 16-15-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01900, current rewards: 16.50071, mean: 0.10313
[32m[0906 16-15-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01903, current rewards: 22.02891, mean: 0.10490
[32m[0906 16-15-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01902, current rewards: 27.55817, mean: 0.10599
[32m[0906 16-15-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01906, current rewards: 33.08389, mean: 0.10672
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01904, current rewards: 38.61067, mean: 0.10725
[32m[0906 16-15-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01905, current rewards: 44.13506, mean: 0.10765
[32m[0906 16-15-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01905, current rewards: 49.66188, mean: 0.10796
[32m[0906 16-15-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01906, current rewards: 56.76481, mean: 0.11130
[32m[0906 16-15-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01906, current rewards: 64.56626, mean: 0.11530
[32m[0906 16-15-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01908, current rewards: 69.53672, mean: 0.11399
[32m[0906 16-15-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01907, current rewards: 74.91392, mean: 0.11351
[32m[0906 16-15-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01907, current rewards: 80.28970, mean: 0.11308
[32m[0906 16-15-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01908, current rewards: 85.65455, mean: 0.11270
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01909, current rewards: 91.18885, mean: 0.11258
[32m[0906 16-15-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01909, current rewards: 96.71569, mean: 0.11246
[32m[0906 16-15-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01908, current rewards: 102.24144, mean: 0.11235
[32m[0906 16-15-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01909, current rewards: 107.76336, mean: 0.11225
[32m[0906 16-15-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 113.29764, mean: 0.11218
[32m[0906 16-15-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01909, current rewards: 118.86842, mean: 0.11214
[32m[0906 16-15-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01909, current rewards: 124.41432, mean: 0.11208
[32m[0906 16-15-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 129.95662, mean: 0.11203
[32m[0906 16-15-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 135.49736, mean: 0.11198
[32m[0906 16-15-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01909, current rewards: 141.03802, mean: 0.11193
[32m[0906 16-15-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01910, current rewards: 146.55928, mean: 0.11188
[32m[0906 16-15-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01906, current rewards: 152.10342, mean: 0.11184
[32m[0906 16-15-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01905, current rewards: 157.64969, mean: 0.11181
[32m[0906 16-15-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01904, current rewards: 163.19181, mean: 0.11178
[32m[0906 16-15-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01902, current rewards: 168.70594, mean: 0.11173
[32m[0906 16-15-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01900, current rewards: 174.16291, mean: 0.11164
[32m[0906 16-15-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01899, current rewards: 179.62633, mean: 0.11157
[32m[0906 16-15-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01897, current rewards: 185.08274, mean: 0.11150
[32m[0906 16-15-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01895, current rewards: 190.56893, mean: 0.11144
[32m[0906 16-15-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01894, current rewards: 196.09330, mean: 0.11142
[32m[0906 16-15-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01893, current rewards: 201.61635, mean: 0.11139
[32m[0906 16-15-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01891, current rewards: 207.13865, mean: 0.11136
[32m[0906 16-16-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01890, current rewards: 212.65697, mean: 0.11134
[32m[0906 16-16-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01890, current rewards: 218.17798, mean: 0.11132
[32m[0906 16-16-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01889, current rewards: 223.70229, mean: 0.11129
[32m[0906 16-16-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01888, current rewards: 229.22785, mean: 0.11128
[32m[0906 16-16-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01887, current rewards: 234.72326, mean: 0.11124
[32m[0906 16-16-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01886, current rewards: 240.25771, mean: 0.11123
[32m[0906 16-16-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01885, current rewards: 245.78776, mean: 0.11122
[32m[0906 16-16-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01885, current rewards: 251.33835, mean: 0.11121
[32m[0906 16-16-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01884, current rewards: 256.88479, mean: 0.11121
[32m[0906 16-16-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01883, current rewards: 262.43946, mean: 0.11120
[32m[0906 16-16-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01882, current rewards: 267.98740, mean: 0.11120
[32m[0906 16-16-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: 273.53486, mean: 0.11119
[32m[0906 16-16-11 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-16-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-16-12 @MBExp.py:227][0m Rewards obtained: [277.97385846308384], Lows: [0], Highs: [1], Total time: 3533.8522849999995
[32m[0906 16-18-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-18-49 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-18-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01855, current rewards: 1.05797, mean: 0.10580
[32m[0906 16-18-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01900, current rewards: 6.57962, mean: 0.10966
[32m[0906 16-18-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01902, current rewards: 12.10850, mean: 0.11008
[32m[0906 16-18-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01898, current rewards: 17.62828, mean: 0.11018
[32m[0906 16-18-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01901, current rewards: 23.15292, mean: 0.11025
[32m[0906 16-18-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01902, current rewards: 28.68497, mean: 0.11033
[32m[0906 16-18-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01899, current rewards: 34.20978, mean: 0.11035
[32m[0906 16-18-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01902, current rewards: 39.73531, mean: 0.11038
[32m[0906 16-18-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01904, current rewards: 45.26089, mean: 0.11039
[32m[0906 16-18-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01905, current rewards: 50.75428, mean: 0.11034
[32m[0906 16-18-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01906, current rewards: 56.28303, mean: 0.11036
[32m[0906 16-19-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01906, current rewards: 61.81358, mean: 0.11038
[32m[0906 16-19-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01906, current rewards: 67.34234, mean: 0.11040
[32m[0906 16-19-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01906, current rewards: 72.87328, mean: 0.11041
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01906, current rewards: 78.39993, mean: 0.11042
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01906, current rewards: 80.16674, mean: 0.10548
[32m[0906 16-19-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01906, current rewards: 85.38319, mean: 0.10541
[32m[0906 16-19-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01906, current rewards: 90.71667, mean: 0.10548
[32m[0906 16-19-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01907, current rewards: 96.00248, mean: 0.10550
[32m[0906 16-19-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01907, current rewards: 101.28920, mean: 0.10551
[32m[0906 16-19-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01907, current rewards: 106.57609, mean: 0.10552
[32m[0906 16-19-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01907, current rewards: 111.86353, mean: 0.10553
[32m[0906 16-19-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01907, current rewards: 117.26285, mean: 0.10564
[32m[0906 16-19-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01907, current rewards: 122.80996, mean: 0.10587
[32m[0906 16-19-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01908, current rewards: 128.36185, mean: 0.10608
[32m[0906 16-19-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01904, current rewards: 133.95547, mean: 0.10631
[32m[0906 16-19-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 139.50715, mean: 0.10649
[32m[0906 16-19-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01900, current rewards: 145.05794, mean: 0.10666
[32m[0906 16-19-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01899, current rewards: 150.60831, mean: 0.10681
[32m[0906 16-19-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01897, current rewards: 156.15758, mean: 0.10696
[32m[0906 16-19-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01896, current rewards: 161.71002, mean: 0.10709
[32m[0906 16-19-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01895, current rewards: 167.27616, mean: 0.10723
[32m[0906 16-19-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01894, current rewards: 172.81455, mean: 0.10734
[32m[0906 16-19-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01893, current rewards: 178.28927, mean: 0.10740
[32m[0906 16-19-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01892, current rewards: 183.82474, mean: 0.10750
[32m[0906 16-19-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01891, current rewards: 189.37835, mean: 0.10760
[32m[0906 16-19-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01890, current rewards: 194.91507, mean: 0.10769
[32m[0906 16-19-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01888, current rewards: 200.45968, mean: 0.10777
[32m[0906 16-19-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01887, current rewards: 206.00574, mean: 0.10786
[32m[0906 16-19-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01886, current rewards: 211.55572, mean: 0.10794
[32m[0906 16-19-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 217.10010, mean: 0.10801
[32m[0906 16-19-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 222.63965, mean: 0.10808
[32m[0906 16-19-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01884, current rewards: 228.28756, mean: 0.10819
[32m[0906 16-19-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01883, current rewards: 233.82596, mean: 0.10825
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 239.42176, mean: 0.10834
[32m[0906 16-19-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01882, current rewards: 245.01065, mean: 0.10841
[32m[0906 16-19-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 250.60031, mean: 0.10848
[32m[0906 16-19-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 256.18999, mean: 0.10856
[32m[0906 16-19-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01880, current rewards: 261.78036, mean: 0.10862
[32m[0906 16-19-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01879, current rewards: 267.36758, mean: 0.10869
[32m[0906 16-19-36 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-19-36 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-19-37 @MBExp.py:227][0m Rewards obtained: [271.79417688890373], Lows: [2], Highs: [0], Total time: 3581.6167389999996
[32m[0906 16-22-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-22-16 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 16-22-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01884, current rewards: 1.14041, mean: 0.11404
[32m[0906 16-22-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01910, current rewards: 6.69120, mean: 0.11152
[32m[0906 16-22-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 12.20873, mean: 0.11099
[32m[0906 16-22-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 17.72844, mean: 0.11080
[32m[0906 16-22-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01906, current rewards: 23.25129, mean: 0.11072
[32m[0906 16-22-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 28.77745, mean: 0.11068
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01914, current rewards: 34.29770, mean: 0.11064
[32m[0906 16-22-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.82016, mean: 0.11061
[32m[0906 16-22-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01913, current rewards: 45.33791, mean: 0.11058
[32m[0906 16-22-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01913, current rewards: 50.94839, mean: 0.11076
[32m[0906 16-22-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 56.46551, mean: 0.11072
[32m[0906 16-22-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01912, current rewards: 62.01175, mean: 0.11074
[32m[0906 16-22-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01912, current rewards: 67.56581, mean: 0.11076
[32m[0906 16-22-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01912, current rewards: 73.12033, mean: 0.11079
[32m[0906 16-22-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01912, current rewards: 78.67700, mean: 0.11081
[32m[0906 16-22-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01912, current rewards: 84.22603, mean: 0.11082
[32m[0906 16-22-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01912, current rewards: 89.77769, mean: 0.11084
[32m[0906 16-22-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01912, current rewards: 95.34555, mean: 0.11087
[32m[0906 16-22-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01912, current rewards: 100.87503, mean: 0.11085
[32m[0906 16-22-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01913, current rewards: 106.44064, mean: 0.11088
[32m[0906 16-22-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01914, current rewards: 112.00585, mean: 0.11090
[32m[0906 16-22-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01914, current rewards: 117.56616, mean: 0.11091
[32m[0906 16-22-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01914, current rewards: 123.12523, mean: 0.11092
[32m[0906 16-22-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01910, current rewards: 128.69045, mean: 0.11094
[32m[0906 16-22-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01909, current rewards: 134.25572, mean: 0.11096
[32m[0906 16-22-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01906, current rewards: 139.82180, mean: 0.11097
[32m[0906 16-22-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01904, current rewards: 145.51398, mean: 0.11108
[32m[0906 16-22-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01902, current rewards: 151.09292, mean: 0.11110
[32m[0906 16-22-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01900, current rewards: 156.66992, mean: 0.11111
[32m[0906 16-22-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01899, current rewards: 162.24411, mean: 0.11113
[32m[0906 16-22-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01897, current rewards: 167.82245, mean: 0.11114
[32m[0906 16-22-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01895, current rewards: 173.40341, mean: 0.11116
[32m[0906 16-22-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01894, current rewards: 179.05950, mean: 0.11122
[32m[0906 16-22-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01893, current rewards: 184.60933, mean: 0.11121
[32m[0906 16-22-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01892, current rewards: 190.17825, mean: 0.11122
[32m[0906 16-22-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01892, current rewards: 195.72493, mean: 0.11121
[32m[0906 16-22-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01891, current rewards: 201.27432, mean: 0.11120
[32m[0906 16-22-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01889, current rewards: 206.82749, mean: 0.11120
[32m[0906 16-22-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01888, current rewards: 212.37972, mean: 0.11119
[32m[0906 16-22-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01887, current rewards: 217.92386, mean: 0.11119
[32m[0906 16-22-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01886, current rewards: 223.47907, mean: 0.11118
[32m[0906 16-22-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01885, current rewards: 229.03337, mean: 0.11118
[32m[0906 16-22-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 234.57513, mean: 0.11117
[32m[0906 16-22-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01884, current rewards: 240.11994, mean: 0.11117
[32m[0906 16-22-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01883, current rewards: 243.46214, mean: 0.11016
[32m[0906 16-22-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01883, current rewards: 248.85102, mean: 0.11011
[32m[0906 16-23-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01882, current rewards: 254.24874, mean: 0.11006
[32m[0906 16-23-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 259.63934, mean: 0.11002
[32m[0906 16-23-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01881, current rewards: 265.02984, mean: 0.10997
[32m[0906 16-23-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01880, current rewards: 270.38777, mean: 0.10991
[32m[0906 16-23-04 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-23-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-23-04 @MBExp.py:227][0m Rewards obtained: [274.8553002734047], Lows: [1], Highs: [0], Total time: 3629.4083779999996
[32m[0906 16-25-45 @MBExp.py:144][0m ####################################################################
[32m[0906 16-25-45 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 16-25-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01872, current rewards: 1.12283, mean: 0.11228
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01901, current rewards: 6.69116, mean: 0.11152
[32m[0906 16-25-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.25648, mean: 0.11142
[32m[0906 16-25-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01918, current rewards: 17.82229, mean: 0.11139
[32m[0906 16-25-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01918, current rewards: 23.38540, mean: 0.11136
[32m[0906 16-25-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01916, current rewards: 28.95443, mean: 0.11136
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01918, current rewards: 34.51820, mean: 0.11135
[32m[0906 16-25-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01917, current rewards: 40.08372, mean: 0.11134
[32m[0906 16-25-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01916, current rewards: 45.65497, mean: 0.11135
[32m[0906 16-25-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01916, current rewards: 51.21362, mean: 0.11133
[32m[0906 16-25-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01913, current rewards: 56.77948, mean: 0.11133
[32m[0906 16-25-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01914, current rewards: 62.34633, mean: 0.11133
[32m[0906 16-25-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01914, current rewards: 67.91608, mean: 0.11134
[32m[0906 16-25-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01914, current rewards: 73.48333, mean: 0.11134
[32m[0906 16-25-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01914, current rewards: 79.04974, mean: 0.11134
[32m[0906 16-26-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01914, current rewards: 84.60471, mean: 0.11132
[32m[0906 16-26-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01913, current rewards: 90.11958, mean: 0.11126
[32m[0906 16-26-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 95.68189, mean: 0.11126
[32m[0906 16-26-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01915, current rewards: 101.24647, mean: 0.11126
[32m[0906 16-26-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01916, current rewards: 106.79792, mean: 0.11125
[32m[0906 16-26-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01916, current rewards: 112.36056, mean: 0.11125
[32m[0906 16-26-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01912, current rewards: 117.91374, mean: 0.11124
[32m[0906 16-26-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01910, current rewards: 123.46923, mean: 0.11123
[32m[0906 16-26-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01908, current rewards: 129.02105, mean: 0.11123
[32m[0906 16-26-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01906, current rewards: 134.59683, mean: 0.11124
[32m[0906 16-26-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01903, current rewards: 140.17655, mean: 0.11125
[32m[0906 16-26-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01902, current rewards: 145.73917, mean: 0.11125
[32m[0906 16-26-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01900, current rewards: 151.29770, mean: 0.11125
[32m[0906 16-26-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01899, current rewards: 156.86022, mean: 0.11125
[32m[0906 16-26-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01898, current rewards: 162.42672, mean: 0.11125
[32m[0906 16-26-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01896, current rewards: 167.99238, mean: 0.11125
[32m[0906 16-26-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01895, current rewards: 173.55394, mean: 0.11125
[32m[0906 16-26-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01893, current rewards: 179.11425, mean: 0.11125
[32m[0906 16-26-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01892, current rewards: 184.77607, mean: 0.11131
[32m[0906 16-26-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01891, current rewards: 190.31229, mean: 0.11129
[32m[0906 16-26-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01890, current rewards: 195.90116, mean: 0.11131
[32m[0906 16-26-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01889, current rewards: 201.49263, mean: 0.11132
[32m[0906 16-26-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01888, current rewards: 207.08592, mean: 0.11134
[32m[0906 16-26-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01887, current rewards: 212.67923, mean: 0.11135
[32m[0906 16-26-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01886, current rewards: 218.26572, mean: 0.11136
[32m[0906 16-26-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01885, current rewards: 223.85823, mean: 0.11137
[32m[0906 16-26-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01884, current rewards: 229.36443, mean: 0.11134
[32m[0906 16-26-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01883, current rewards: 234.94342, mean: 0.11135
[32m[0906 16-26-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01882, current rewards: 240.52334, mean: 0.11135
[32m[0906 16-26-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01881, current rewards: 246.10387, mean: 0.11136
[32m[0906 16-26-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01881, current rewards: 251.68623, mean: 0.11137
[32m[0906 16-26-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01881, current rewards: 257.27013, mean: 0.11137
[32m[0906 16-26-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01880, current rewards: 262.85162, mean: 0.11138
[32m[0906 16-26-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01879, current rewards: 268.42050, mean: 0.11138
[32m[0906 16-26-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01879, current rewards: 273.95931, mean: 0.11137
[32m[0906 16-26-33 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-26-33 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-26-33 @MBExp.py:227][0m Rewards obtained: [278.3902476092232], Lows: [0], Highs: [0], Total time: 3677.1608629999996
[32m[0906 16-29-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-29-16 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 16-29-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01871, current rewards: 1.11722, mean: 0.11172
[32m[0906 16-29-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01893, current rewards: 6.69351, mean: 0.11156
[32m[0906 16-29-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01907, current rewards: 12.17669, mean: 0.11070
[32m[0906 16-29-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 17.66887, mean: 0.11043
[32m[0906 16-29-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01908, current rewards: 23.16430, mean: 0.11031
[32m[0906 16-29-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01912, current rewards: 28.65676, mean: 0.11022
[32m[0906 16-29-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01915, current rewards: 34.14921, mean: 0.11016
[32m[0906 16-29-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01913, current rewards: 39.71204, mean: 0.11031
[32m[0906 16-29-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01912, current rewards: 45.10961, mean: 0.11002
[32m[0906 16-29-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01911, current rewards: 50.64560, mean: 0.11010
[32m[0906 16-29-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01911, current rewards: 56.17554, mean: 0.11015
[32m[0906 16-29-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 61.71153, mean: 0.11020
[32m[0906 16-29-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 67.24560, mean: 0.11024
[32m[0906 16-29-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01913, current rewards: 72.77151, mean: 0.11026
[32m[0906 16-29-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01913, current rewards: 78.30880, mean: 0.11029
[32m[0906 16-29-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01913, current rewards: 83.83407, mean: 0.11031
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01914, current rewards: 89.39318, mean: 0.11036
[32m[0906 16-29-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01913, current rewards: 95.03788, mean: 0.11051
[32m[0906 16-29-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01914, current rewards: 100.59033, mean: 0.11054
[32m[0906 16-29-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01914, current rewards: 106.14506, mean: 0.11057
[32m[0906 16-29-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01910, current rewards: 111.86353, mean: 0.11076
[32m[0906 16-29-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01906, current rewards: 117.42660, mean: 0.11078
[32m[0906 16-29-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01904, current rewards: 122.99073, mean: 0.11080
[32m[0906 16-29-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01901, current rewards: 128.55152, mean: 0.11082
[32m[0906 16-29-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01899, current rewards: 134.13321, mean: 0.11085
[32m[0906 16-29-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01898, current rewards: 139.56160, mean: 0.11076
[32m[0906 16-29-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01896, current rewards: 145.11265, mean: 0.11077
[32m[0906 16-29-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01895, current rewards: 150.64486, mean: 0.11077
[32m[0906 16-29-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01893, current rewards: 156.17426, mean: 0.11076
[32m[0906 16-29-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01892, current rewards: 161.70972, mean: 0.11076
[32m[0906 16-29-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01891, current rewards: 167.23449, mean: 0.11075
[32m[0906 16-29-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01890, current rewards: 172.76958, mean: 0.11075
[32m[0906 16-29-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01889, current rewards: 178.30043, mean: 0.11075
[32m[0906 16-29-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01888, current rewards: 183.84996, mean: 0.11075
[32m[0906 16-29-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01887, current rewards: 189.39182, mean: 0.11076
[32m[0906 16-29-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01886, current rewards: 194.93834, mean: 0.11076
[32m[0906 16-29-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01885, current rewards: 200.51000, mean: 0.11078
[32m[0906 16-29-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01884, current rewards: 206.08416, mean: 0.11080
[32m[0906 16-29-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01883, current rewards: 211.65744, mean: 0.11082
[32m[0906 16-29-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01883, current rewards: 217.23415, mean: 0.11083
[32m[0906 16-29-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01882, current rewards: 222.80725, mean: 0.11085
[32m[0906 16-29-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01882, current rewards: 228.38653, mean: 0.11087
[32m[0906 16-29-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01881, current rewards: 233.96471, mean: 0.11088
[32m[0906 16-29-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01881, current rewards: 237.53766, mean: 0.10997
[32m[0906 16-29-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01880, current rewards: 243.28384, mean: 0.11008
[32m[0906 16-29-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01880, current rewards: 249.03380, mean: 0.11019
[32m[0906 16-30-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: 254.78090, mean: 0.11029
[32m[0906 16-30-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01879, current rewards: 260.52517, mean: 0.11039
[32m[0906 16-30-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01878, current rewards: 266.27219, mean: 0.11049
[32m[0906 16-30-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01878, current rewards: 272.02145, mean: 0.11058
[32m[0906 16-30-04 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 16-30-04 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-30-04 @MBExp.py:227][0m Rewards obtained: [276.79664641688146], Lows: [1], Highs: [0], Total time: 3724.8815369999998
[32m[0906 16-32-50 @MBExp.py:144][0m ####################################################################
[32m[0906 16-32-50 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 16-32-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01852, current rewards: 1.13101, mean: 0.11310
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01898, current rewards: 6.67333, mean: 0.11122
[32m[0906 16-32-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01905, current rewards: 12.20976, mean: 0.11100
[32m[0906 16-32-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01907, current rewards: 17.74809, mean: 0.11093
[32m[0906 16-32-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.29251, mean: 0.11092
[32m[0906 16-32-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01909, current rewards: 28.83505, mean: 0.11090
[32m[0906 16-32-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01911, current rewards: 34.37070, mean: 0.11087
[32m[0906 16-32-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 39.91436, mean: 0.11087
[32m[0906 16-32-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01907, current rewards: 45.52405, mean: 0.11103
[32m[0906 16-32-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01907, current rewards: 51.07330, mean: 0.11103
[32m[0906 16-33-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 56.63202, mean: 0.11104
[32m[0906 16-33-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01911, current rewards: 62.17417, mean: 0.11103
[32m[0906 16-33-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 67.72916, mean: 0.11103
[32m[0906 16-33-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01911, current rewards: 73.28744, mean: 0.11104
[32m[0906 16-33-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01910, current rewards: 78.83654, mean: 0.11104
[32m[0906 16-33-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01910, current rewards: 84.39100, mean: 0.11104
[32m[0906 16-33-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01910, current rewards: 90.03749, mean: 0.11116
[32m[0906 16-33-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01910, current rewards: 95.47778, mean: 0.11102
[32m[0906 16-33-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01904, current rewards: 101.01464, mean: 0.11101
[32m[0906 16-33-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01901, current rewards: 106.55418, mean: 0.11099
[32m[0906 16-33-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01899, current rewards: 112.09123, mean: 0.11098
[32m[0906 16-33-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01897, current rewards: 117.62687, mean: 0.11097
[32m[0906 16-33-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01895, current rewards: 123.16628, mean: 0.11096
[32m[0906 16-33-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01893, current rewards: 128.70245, mean: 0.11095
[32m[0906 16-33-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01892, current rewards: 134.29472, mean: 0.11099
[32m[0906 16-33-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01891, current rewards: 139.84222, mean: 0.11099
[32m[0906 16-33-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01890, current rewards: 145.38085, mean: 0.11098
[32m[0906 16-33-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01888, current rewards: 150.92673, mean: 0.11098
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01887, current rewards: 156.47834, mean: 0.11098
[32m[0906 16-33-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01885, current rewards: 162.01666, mean: 0.11097
[32m[0906 16-33-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01884, current rewards: 167.74868, mean: 0.11109
[32m[0906 16-33-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01883, current rewards: 173.29790, mean: 0.11109
[32m[0906 16-33-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01882, current rewards: 178.85854, mean: 0.11109
[32m[0906 16-33-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01881, current rewards: 184.92400, mean: 0.11140
[32m[0906 16-33-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01880, current rewards: 192.57908, mean: 0.11262
[32m[0906 16-33-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01879, current rewards: 200.23416, mean: 0.11377
[32m[0906 16-33-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01877, current rewards: 174.92920, mean: 0.09665
[32m[0906 16-33-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01877, current rewards: 180.47125, mean: 0.09703
[32m[0906 16-33-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01876, current rewards: 186.01026, mean: 0.09739
[32m[0906 16-33-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01876, current rewards: 191.55314, mean: 0.09773
[32m[0906 16-33-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01875, current rewards: 197.09063, mean: 0.09806
[32m[0906 16-33-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01874, current rewards: 202.60817, mean: 0.09835
[32m[0906 16-33-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01875, current rewards: 208.15101, mean: 0.09865
[32m[0906 16-33-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01874, current rewards: 213.69842, mean: 0.09893
[32m[0906 16-33-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01873, current rewards: 219.24221, mean: 0.09920
[32m[0906 16-33-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01873, current rewards: 224.78816, mean: 0.09946
[32m[0906 16-33-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01872, current rewards: 230.32838, mean: 0.09971
[32m[0906 16-33-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01872, current rewards: 235.87204, mean: 0.09995
[32m[0906 16-33-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01871, current rewards: 241.41292, mean: 0.10017
[32m[0906 16-33-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01871, current rewards: 246.96193, mean: 0.10039
[32m[0906 16-33-37 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 16-33-37 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-33-37 @MBExp.py:227][0m Rewards obtained: [251.39550185390183], Lows: [0], Highs: [28], Total time: 3772.4244729999996
[32m[0906 16-36-25 @MBExp.py:144][0m ####################################################################
[32m[0906 16-36-25 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 16-36-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01829, current rewards: 1.15758, mean: 0.11576
[32m[0906 16-36-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01880, current rewards: 6.75195, mean: 0.11253
[32m[0906 16-36-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01895, current rewards: 12.31749, mean: 0.11198
[32m[0906 16-36-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01901, current rewards: 17.88644, mean: 0.11179
[32m[0906 16-36-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01901, current rewards: 23.45696, mean: 0.11170
[32m[0906 16-36-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01900, current rewards: 29.02166, mean: 0.11162
[32m[0906 16-36-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01904, current rewards: 34.59269, mean: 0.11159
[32m[0906 16-36-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01903, current rewards: 40.15757, mean: 0.11155
[32m[0906 16-36-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01903, current rewards: 45.72750, mean: 0.11153
[32m[0906 16-36-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01902, current rewards: 51.29089, mean: 0.11150
[32m[0906 16-36-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01904, current rewards: 56.85509, mean: 0.11148
[32m[0906 16-36-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01904, current rewards: 62.41473, mean: 0.11145
[32m[0906 16-36-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01907, current rewards: 67.98125, mean: 0.11144
[32m[0906 16-36-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01907, current rewards: 73.53200, mean: 0.11141
[32m[0906 16-36-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01907, current rewards: 79.10608, mean: 0.11142
[32m[0906 16-36-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01907, current rewards: 84.68209, mean: 0.11142
[32m[0906 16-36-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01901, current rewards: 90.31571, mean: 0.11150
[32m[0906 16-36-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01898, current rewards: 95.88830, mean: 0.11150
[32m[0906 16-36-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01895, current rewards: 101.45964, mean: 0.11149
[32m[0906 16-36-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01892, current rewards: 107.03316, mean: 0.11149
[32m[0906 16-36-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01890, current rewards: 112.60294, mean: 0.11149
[32m[0906 16-36-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01888, current rewards: 118.17384, mean: 0.11148
[32m[0906 16-36-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01885, current rewards: 123.74735, mean: 0.11148
[32m[0906 16-36-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01884, current rewards: 129.43882, mean: 0.11159
[32m[0906 16-36-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01883, current rewards: 134.90392, mean: 0.11149
[32m[0906 16-36-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01882, current rewards: 140.45394, mean: 0.11147
[32m[0906 16-36-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01882, current rewards: 145.99547, mean: 0.11145
[32m[0906 16-36-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01881, current rewards: 151.54601, mean: 0.11143
[32m[0906 16-36-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01879, current rewards: 157.09693, mean: 0.11142
[32m[0906 16-36-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01878, current rewards: 162.65345, mean: 0.11141
[32m[0906 16-36-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01877, current rewards: 168.20964, mean: 0.11140
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01877, current rewards: 173.76087, mean: 0.11139
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01876, current rewards: 179.32203, mean: 0.11138
[32m[0906 16-36-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01876, current rewards: 184.92749, mean: 0.11140
[32m[0906 16-36-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01875, current rewards: 190.46855, mean: 0.11139
[32m[0906 16-36-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01875, current rewards: 196.01597, mean: 0.11137
[32m[0906 16-36-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01874, current rewards: 201.55708, mean: 0.11136
[32m[0906 16-37-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01873, current rewards: 207.10244, mean: 0.11135
[32m[0906 16-37-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01873, current rewards: 212.66831, mean: 0.11134
[32m[0906 16-37-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01872, current rewards: 218.22467, mean: 0.11134
[32m[0906 16-37-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01871, current rewards: 223.78533, mean: 0.11134
[32m[0906 16-37-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01871, current rewards: 229.33696, mean: 0.11133
[32m[0906 16-37-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01871, current rewards: 234.89831, mean: 0.11133
[32m[0906 16-37-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01870, current rewards: 240.45768, mean: 0.11132
[32m[0906 16-37-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01869, current rewards: 246.01861, mean: 0.11132
[32m[0906 16-37-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01869, current rewards: 251.57733, mean: 0.11132
[32m[0906 16-37-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01869, current rewards: 257.13656, mean: 0.11131
[32m[0906 16-37-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01869, current rewards: 262.70395, mean: 0.11132
[32m[0906 16-37-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01869, current rewards: 268.28607, mean: 0.11132
[32m[0906 16-37-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01869, current rewards: 273.87464, mean: 0.11133
[32m[0906 16-37-12 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 16-37-12 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-37-12 @MBExp.py:227][0m Rewards obtained: [278.3455343759208], Lows: [0], Highs: [0], Total time: 3819.9160259999994
[32m[0906 16-40-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-40-03 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 16-40-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01892, current rewards: -0.01219, mean: -0.00122
[32m[0906 16-40-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01911, current rewards: 5.47860, mean: 0.09131
[32m[0906 16-40-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01914, current rewards: 10.95907, mean: 0.09963
[32m[0906 16-40-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01910, current rewards: 16.44014, mean: 0.10275
[32m[0906 16-40-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01914, current rewards: 21.92029, mean: 0.10438
[32m[0906 16-40-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 26.35825, mean: 0.10138
[32m[0906 16-40-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 31.96176, mean: 0.10310
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 37.50591, mean: 0.10418
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 43.10874, mean: 0.10514
[32m[0906 16-40-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01908, current rewards: 48.71108, mean: 0.10589
[32m[0906 16-40-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01910, current rewards: 54.31121, mean: 0.10649
[32m[0906 16-40-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01910, current rewards: 59.92373, mean: 0.10701
[32m[0906 16-40-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01911, current rewards: 65.53140, mean: 0.10743
[32m[0906 16-40-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01905, current rewards: 71.13083, mean: 0.10777
[32m[0906 16-40-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01902, current rewards: 76.73436, mean: 0.10808
[32m[0906 16-40-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01897, current rewards: 82.33371, mean: 0.10833
[32m[0906 16-40-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01895, current rewards: 87.93981, mean: 0.10857
[32m[0906 16-40-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01893, current rewards: 93.50287, mean: 0.10872
[32m[0906 16-40-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01890, current rewards: 99.06137, mean: 0.10886
[32m[0906 16-40-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01889, current rewards: 104.62311, mean: 0.10898
[32m[0906 16-40-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01888, current rewards: 110.18366, mean: 0.10909
[32m[0906 16-40-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01886, current rewards: 115.74387, mean: 0.10919
[32m[0906 16-40-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01884, current rewards: 121.30890, mean: 0.10929
[32m[0906 16-40-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01881, current rewards: 126.91973, mean: 0.10941
[32m[0906 16-40-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01880, current rewards: 132.63924, mean: 0.10962
[32m[0906 16-40-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01879, current rewards: 138.19675, mean: 0.10968
[32m[0906 16-40-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01879, current rewards: 143.75474, mean: 0.10974
[32m[0906 16-40-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01878, current rewards: 149.31255, mean: 0.10979
[32m[0906 16-40-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01877, current rewards: 154.87147, mean: 0.10984
[32m[0906 16-40-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01877, current rewards: 160.39138, mean: 0.10986
[32m[0906 16-40-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01876, current rewards: 165.93878, mean: 0.10989
[32m[0906 16-40-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01874, current rewards: 171.48527, mean: 0.10993
[32m[0906 16-40-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01873, current rewards: 176.97991, mean: 0.10993
[32m[0906 16-40-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01872, current rewards: 182.52294, mean: 0.10995
[32m[0906 16-40-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 188.06376, mean: 0.10998
[32m[0906 16-40-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01871, current rewards: 193.60480, mean: 0.11000
[32m[0906 16-40-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01870, current rewards: 199.14487, mean: 0.11002
[32m[0906 16-40-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01869, current rewards: 204.68606, mean: 0.11005
[32m[0906 16-40-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01868, current rewards: 210.19675, mean: 0.11005
[32m[0906 16-40-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01868, current rewards: 215.76855, mean: 0.11009
[32m[0906 16-40-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01868, current rewards: 221.27555, mean: 0.11009
[32m[0906 16-40-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01868, current rewards: 226.85525, mean: 0.11012
[32m[0906 16-40-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01867, current rewards: 232.44125, mean: 0.11016
[32m[0906 16-40-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01867, current rewards: 238.02613, mean: 0.11020
[32m[0906 16-40-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01867, current rewards: 243.60331, mean: 0.11023
[32m[0906 16-40-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01866, current rewards: 249.18474, mean: 0.11026
[32m[0906 16-40-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: 254.76114, mean: 0.11029
[32m[0906 16-40-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: 260.34797, mean: 0.11032
[32m[0906 16-40-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01866, current rewards: 265.94258, mean: 0.11035
[32m[0906 16-40-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01866, current rewards: 271.53810, mean: 0.11038
[32m[0906 16-40-50 @Agent.py:117][0m Average action selection time: 0.0187
[32m[0906 16-40-50 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-40-50 @MBExp.py:227][0m Rewards obtained: [276.00503549285764], Lows: [0], Highs: [2], Total time: 3867.3321959999994
[32m[0906 16-43-42 @MBExp.py:144][0m ####################################################################
[32m[0906 16-43-42 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 16-43-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01887, current rewards: 1.09904, mean: 0.10990
[32m[0906 16-43-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01904, current rewards: 6.61419, mean: 0.11024
[32m[0906 16-43-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01918, current rewards: 12.14239, mean: 0.11039
[32m[0906 16-43-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01913, current rewards: 17.66539, mean: 0.11041
[32m[0906 16-43-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01909, current rewards: 23.18540, mean: 0.11041
[32m[0906 16-43-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01908, current rewards: 28.70722, mean: 0.11041
[32m[0906 16-43-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01908, current rewards: 34.23765, mean: 0.11044
[32m[0906 16-43-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01908, current rewards: 39.78278, mean: 0.11051
[32m[0906 16-43-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 45.29843, mean: 0.11048
[32m[0906 16-43-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01912, current rewards: 46.51494, mean: 0.10112
[32m[0906 16-43-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01912, current rewards: 51.93194, mean: 0.10183
[32m[0906 16-43-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 57.34698, mean: 0.10241
[32m[0906 16-43-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01902, current rewards: 62.75942, mean: 0.10288
[32m[0906 16-43-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01898, current rewards: 68.17775, mean: 0.10330
[32m[0906 16-43-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01895, current rewards: 73.59230, mean: 0.10365
[32m[0906 16-43-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01891, current rewards: 79.00578, mean: 0.10395
[32m[0906 16-43-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01890, current rewards: 84.42026, mean: 0.10422
[32m[0906 16-43-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01888, current rewards: 89.83629, mean: 0.10446
[32m[0906 16-44-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01885, current rewards: 95.25333, mean: 0.10467
[32m[0906 16-44-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01884, current rewards: 100.72659, mean: 0.10492
[32m[0906 16-44-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01882, current rewards: 106.24863, mean: 0.10520
[32m[0906 16-44-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01881, current rewards: 111.77391, mean: 0.10545
[32m[0906 16-44-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01879, current rewards: 117.30017, mean: 0.10568
[32m[0906 16-44-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01877, current rewards: 122.81852, mean: 0.10588
[32m[0906 16-44-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01877, current rewards: 128.34006, mean: 0.10607
[32m[0906 16-44-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01875, current rewards: 133.85554, mean: 0.10623
[32m[0906 16-44-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01874, current rewards: 139.37433, mean: 0.10639
[32m[0906 16-44-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01874, current rewards: 144.89016, mean: 0.10654
[32m[0906 16-44-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01874, current rewards: 150.41470, mean: 0.10668
[32m[0906 16-44-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01873, current rewards: 155.93539, mean: 0.10681
[32m[0906 16-44-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01873, current rewards: 159.42352, mean: 0.10558
[32m[0906 16-44-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01873, current rewards: 165.01813, mean: 0.10578
[32m[0906 16-44-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01872, current rewards: 170.65105, mean: 0.10599
[32m[0906 16-44-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01871, current rewards: 176.28447, mean: 0.10620
[32m[0906 16-44-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01871, current rewards: 181.92260, mean: 0.10639
[32m[0906 16-44-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01870, current rewards: 187.55959, mean: 0.10657
[32m[0906 16-44-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01870, current rewards: 193.19476, mean: 0.10674
[32m[0906 16-44-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01870, current rewards: 198.82909, mean: 0.10690
[32m[0906 16-44-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01869, current rewards: 204.46480, mean: 0.10705
[32m[0906 16-44-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01869, current rewards: 210.13979, mean: 0.10721
[32m[0906 16-44-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01869, current rewards: 215.77638, mean: 0.10735
[32m[0906 16-44-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01869, current rewards: 221.41320, mean: 0.10748
[32m[0906 16-44-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01868, current rewards: 227.00609, mean: 0.10759
[32m[0906 16-44-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01868, current rewards: 232.61498, mean: 0.10769
[32m[0906 16-44-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01867, current rewards: 238.21962, mean: 0.10779
[32m[0906 16-44-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01867, current rewards: 243.81536, mean: 0.10788
[32m[0906 16-44-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01866, current rewards: 249.41517, mean: 0.10797
[32m[0906 16-44-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01866, current rewards: 255.01595, mean: 0.10806
[32m[0906 16-44-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01866, current rewards: 260.62029, mean: 0.10814
[32m[0906 16-44-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01865, current rewards: 266.21816, mean: 0.10822
[32m[0906 16-44-29 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-44-29 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-44-30 @MBExp.py:227][0m Rewards obtained: [270.7022896533558], Lows: [3], Highs: [0], Total time: 3914.7435449999994
[32m[0906 16-47-24 @MBExp.py:144][0m ####################################################################
[32m[0906 16-47-24 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01845, current rewards: 1.31404, mean: 0.13140
[32m[0906 16-47-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01889, current rewards: 6.89171, mean: 0.11486
[32m[0906 16-47-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01902, current rewards: 12.46726, mean: 0.11334
[32m[0906 16-47-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01908, current rewards: 18.05061, mean: 0.11282
[32m[0906 16-47-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01907, current rewards: 23.62711, mean: 0.11251
[32m[0906 16-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01907, current rewards: 29.16817, mean: 0.11219
[32m[0906 16-47-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01909, current rewards: 34.70048, mean: 0.11194
[32m[0906 16-47-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01909, current rewards: 40.28555, mean: 0.11190
[32m[0906 16-47-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01909, current rewards: 45.91871, mean: 0.11200
[32m[0906 16-47-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01901, current rewards: 51.66266, mean: 0.11231
[32m[0906 16-47-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01896, current rewards: 57.40332, mean: 0.11256
[32m[0906 16-47-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01893, current rewards: 63.14864, mean: 0.11277
[32m[0906 16-47-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01890, current rewards: 68.88943, mean: 0.11293
[32m[0906 16-47-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01887, current rewards: 74.63391, mean: 0.11308
[32m[0906 16-47-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01885, current rewards: 80.37740, mean: 0.11321
[32m[0906 16-47-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01883, current rewards: 86.11905, mean: 0.11331
[32m[0906 16-47-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01881, current rewards: 91.85928, mean: 0.11341
[32m[0906 16-47-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01880, current rewards: 97.60858, mean: 0.11350
[32m[0906 16-47-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01878, current rewards: 103.34887, mean: 0.11357
[32m[0906 16-47-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01877, current rewards: 109.09816, mean: 0.11364
[32m[0906 16-47-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01876, current rewards: 114.83886, mean: 0.11370
[32m[0906 16-47-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01874, current rewards: 120.58154, mean: 0.11376
[32m[0906 16-47-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01874, current rewards: 126.33888, mean: 0.11382
[32m[0906 16-47-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01873, current rewards: 132.05721, mean: 0.11384
[32m[0906 16-47-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01872, current rewards: 137.77035, mean: 0.11386
[32m[0906 16-47-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01871, current rewards: 143.42511, mean: 0.11383
[32m[0906 16-47-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01870, current rewards: 149.09081, mean: 0.11381
[32m[0906 16-47-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01869, current rewards: 154.76232, mean: 0.11380
[32m[0906 16-47-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01869, current rewards: 160.42609, mean: 0.11378
[32m[0906 16-47-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01869, current rewards: 166.09568, mean: 0.11376
[32m[0906 16-47-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01868, current rewards: 171.81074, mean: 0.11378
[32m[0906 16-47-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01867, current rewards: 177.45928, mean: 0.11376
[32m[0906 16-47-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01867, current rewards: 183.11528, mean: 0.11374
[32m[0906 16-47-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01867, current rewards: 188.69384, mean: 0.11367
[32m[0906 16-47-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01867, current rewards: 194.25006, mean: 0.11360
[32m[0906 16-47-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01866, current rewards: 199.80772, mean: 0.11353
[32m[0906 16-47-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01866, current rewards: 205.36446, mean: 0.11346
[32m[0906 16-47-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01867, current rewards: 210.92381, mean: 0.11340
[32m[0906 16-48-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01866, current rewards: 216.60425, mean: 0.11341
[32m[0906 16-48-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01866, current rewards: 222.42488, mean: 0.11348
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01866, current rewards: 228.24705, mean: 0.11356
[32m[0906 16-48-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01865, current rewards: 234.06892, mean: 0.11363
[32m[0906 16-48-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01865, current rewards: 239.88948, mean: 0.11369
[32m[0906 16-48-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01865, current rewards: 245.86534, mean: 0.11383
[32m[0906 16-48-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01865, current rewards: 251.58101, mean: 0.11384
[32m[0906 16-48-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01864, current rewards: 257.28303, mean: 0.11384
[32m[0906 16-48-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01864, current rewards: 262.99325, mean: 0.11385
[32m[0906 16-48-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01863, current rewards: 268.70023, mean: 0.11386
[32m[0906 16-48-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01863, current rewards: 274.40497, mean: 0.11386
[32m[0906 16-48-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01863, current rewards: 280.11810, mean: 0.11387
[32m[0906 16-48-11 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-48-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-48-11 @MBExp.py:227][0m Rewards obtained: [284.68013052744124], Lows: [0], Highs: [0], Total time: 3962.0989079999995
[32m[0906 16-51-07 @MBExp.py:144][0m ####################################################################
[32m[0906 16-51-07 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 16-51-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 1.08763, mean: 0.10876
[32m[0906 16-51-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01925, current rewards: 6.71221, mean: 0.11187
[32m[0906 16-51-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01917, current rewards: 12.31369, mean: 0.11194
[32m[0906 16-51-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01909, current rewards: 17.90631, mean: 0.11191
[32m[0906 16-51-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01910, current rewards: 23.50338, mean: 0.11192
[32m[0906 16-51-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01910, current rewards: 28.92241, mean: 0.11124
[32m[0906 16-51-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01910, current rewards: 34.49083, mean: 0.11126
[32m[0906 16-51-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01910, current rewards: 40.05705, mean: 0.11127
[32m[0906 16-51-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01894, current rewards: 45.61994, mean: 0.11127
[32m[0906 16-51-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01892, current rewards: 51.18561, mean: 0.11127
[32m[0906 16-51-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01886, current rewards: 56.74882, mean: 0.11127
[32m[0906 16-51-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01883, current rewards: 62.31381, mean: 0.11127
[32m[0906 16-51-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01880, current rewards: 67.88216, mean: 0.11128
[32m[0906 16-51-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01879, current rewards: 73.57352, mean: 0.11148
[32m[0906 16-51-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01877, current rewards: 79.15194, mean: 0.11148
[32m[0906 16-51-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01875, current rewards: 84.72366, mean: 0.11148
[32m[0906 16-51-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01873, current rewards: 90.30023, mean: 0.11148
[32m[0906 16-51-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01871, current rewards: 95.87022, mean: 0.11148
[32m[0906 16-51-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01870, current rewards: 101.44330, mean: 0.11148
[32m[0906 16-51-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01868, current rewards: 107.01680, mean: 0.11148
[32m[0906 16-51-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01868, current rewards: 112.58946, mean: 0.11147
[32m[0906 16-51-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01866, current rewards: 118.14027, mean: 0.11145
[32m[0906 16-51-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01866, current rewards: 123.67128, mean: 0.11142
[32m[0906 16-51-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01865, current rewards: 129.26913, mean: 0.11144
[32m[0906 16-51-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01865, current rewards: 134.86900, mean: 0.11146
[32m[0906 16-51-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01865, current rewards: 140.47001, mean: 0.11148
[32m[0906 16-51-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01864, current rewards: 146.06863, mean: 0.11150
[32m[0906 16-51-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01863, current rewards: 151.75238, mean: 0.11158
[32m[0906 16-51-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01862, current rewards: 157.31303, mean: 0.11157
[32m[0906 16-51-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01862, current rewards: 162.87519, mean: 0.11156
[32m[0906 16-51-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01862, current rewards: 168.45172, mean: 0.11156
[32m[0906 16-51-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01861, current rewards: 174.01565, mean: 0.11155
[32m[0906 16-51-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01861, current rewards: 179.58182, mean: 0.11154
[32m[0906 16-51-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01861, current rewards: 185.14244, mean: 0.11153
[32m[0906 16-51-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01862, current rewards: 190.70131, mean: 0.11152
[32m[0906 16-51-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: 196.26121, mean: 0.11151
[32m[0906 16-51-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01861, current rewards: 201.82320, mean: 0.11150
[32m[0906 16-51-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 207.37908, mean: 0.11149
[32m[0906 16-51-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01861, current rewards: 213.10756, mean: 0.11157
[32m[0906 16-51-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 216.55755, mean: 0.11049
[32m[0906 16-51-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01861, current rewards: 208.78837, mean: 0.10387
[32m[0906 16-51-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01860, current rewards: 214.35494, mean: 0.10406
[32m[0906 16-51-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 219.91951, mean: 0.10423
[32m[0906 16-51-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01860, current rewards: 225.48425, mean: 0.10439
[32m[0906 16-51-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01860, current rewards: 231.01777, mean: 0.10453
[32m[0906 16-51-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 236.59795, mean: 0.10469
[32m[0906 16-51-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01859, current rewards: 242.15760, mean: 0.10483
[32m[0906 16-51-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01859, current rewards: 247.73336, mean: 0.10497
[32m[0906 16-51-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01859, current rewards: 253.32547, mean: 0.10511
[32m[0906 16-51-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01858, current rewards: 258.91869, mean: 0.10525
[32m[0906 16-51-54 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-51-54 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-51-54 @MBExp.py:227][0m Rewards obtained: [263.3919717412994], Lows: [0], Highs: [14], Total time: 4009.3463329999995
[32m[0906 16-54-53 @MBExp.py:144][0m ####################################################################
[32m[0906 16-54-53 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 16-54-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01926, current rewards: 1.07927, mean: 0.10793
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01924, current rewards: 6.59649, mean: 0.10994
[32m[0906 16-54-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01919, current rewards: 12.11000, mean: 0.11009
[32m[0906 16-54-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01912, current rewards: 17.62425, mean: 0.11015
[32m[0906 16-54-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01915, current rewards: 23.13946, mean: 0.11019
[32m[0906 16-54-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01904, current rewards: 28.53791, mean: 0.10976
[32m[0906 16-54-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01896, current rewards: 34.00557, mean: 0.10970
[32m[0906 16-55-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01888, current rewards: 39.46989, mean: 0.10964
[32m[0906 16-55-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01883, current rewards: 44.93084, mean: 0.10959
[32m[0906 16-55-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01881, current rewards: 50.39194, mean: 0.10955
[32m[0906 16-55-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01877, current rewards: 55.85795, mean: 0.10953
[32m[0906 16-55-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01876, current rewards: 61.31904, mean: 0.10950
[32m[0906 16-55-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01876, current rewards: 66.78483, mean: 0.10948
[32m[0906 16-55-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01875, current rewards: 72.18276, mean: 0.10937
[32m[0906 16-55-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01872, current rewards: 77.65776, mean: 0.10938
[32m[0906 16-55-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01872, current rewards: 83.18370, mean: 0.10945
[32m[0906 16-55-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01871, current rewards: 88.74766, mean: 0.10957
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01870, current rewards: 94.31028, mean: 0.10966
[32m[0906 16-55-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01869, current rewards: 99.87744, mean: 0.10976
[32m[0906 16-55-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01868, current rewards: 105.44075, mean: 0.10983
[32m[0906 16-55-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01868, current rewards: 111.00196, mean: 0.10990
[32m[0906 16-55-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01867, current rewards: 116.69172, mean: 0.11009
[32m[0906 16-55-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01867, current rewards: 122.23847, mean: 0.11012
[32m[0906 16-55-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01867, current rewards: 127.77089, mean: 0.11015
[32m[0906 16-55-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01866, current rewards: 133.30621, mean: 0.11017
[32m[0906 16-55-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01865, current rewards: 138.83944, mean: 0.11019
[32m[0906 16-55-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01865, current rewards: 144.37501, mean: 0.11021
[32m[0906 16-55-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01865, current rewards: 150.10293, mean: 0.11037
[32m[0906 16-55-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01864, current rewards: 155.61246, mean: 0.11036
[32m[0906 16-55-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01864, current rewards: 161.12872, mean: 0.11036
[32m[0906 16-55-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01864, current rewards: 166.58553, mean: 0.11032
[32m[0906 16-55-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01864, current rewards: 172.14357, mean: 0.11035
[32m[0906 16-55-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01863, current rewards: 177.64719, mean: 0.11034
[32m[0906 16-55-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01863, current rewards: 183.15381, mean: 0.11033
[32m[0906 16-55-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01862, current rewards: 188.65950, mean: 0.11033
[32m[0906 16-55-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01862, current rewards: 194.16512, mean: 0.11032
[32m[0906 16-55-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01862, current rewards: 199.67216, mean: 0.11032
[32m[0906 16-55-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01861, current rewards: 205.17909, mean: 0.11031
[32m[0906 16-55-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01862, current rewards: 210.93621, mean: 0.11044
[32m[0906 16-55-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01862, current rewards: 216.45706, mean: 0.11044
[32m[0906 16-55-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01862, current rewards: 221.98201, mean: 0.11044
[32m[0906 16-55-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01862, current rewards: 227.50417, mean: 0.11044
[32m[0906 16-55-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 233.02388, mean: 0.11044
[32m[0906 16-55-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01862, current rewards: 236.44503, mean: 0.10947
[32m[0906 16-55-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01860, current rewards: 241.96621, mean: 0.10949
[32m[0906 16-55-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01860, current rewards: 247.48888, mean: 0.10951
[32m[0906 16-55-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01860, current rewards: 253.04632, mean: 0.10954
[32m[0906 16-55-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01860, current rewards: 258.61007, mean: 0.10958
[32m[0906 16-55-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01860, current rewards: 264.17297, mean: 0.10962
[32m[0906 16-55-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01861, current rewards: 269.73653, mean: 0.10965
[32m[0906 16-55-40 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 16-55-40 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-55-41 @MBExp.py:227][0m Rewards obtained: [274.1876493889776], Lows: [1], Highs: [0], Total time: 4056.6497019999997
[32m[0906 16-58-42 @MBExp.py:144][0m ####################################################################
[32m[0906 16-58-42 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 16-58-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01908, current rewards: 1.18920, mean: 0.11892
[32m[0906 16-58-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01902, current rewards: 6.77336, mean: 0.11289
[32m[0906 16-58-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01898, current rewards: 12.35760, mean: 0.11234
[32m[0906 16-58-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01885, current rewards: 17.93984, mean: 0.11212
[32m[0906 16-58-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01876, current rewards: 23.48613, mean: 0.11184
[32m[0906 16-58-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01871, current rewards: 29.06780, mean: 0.11180
[32m[0906 16-58-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01869, current rewards: 34.64592, mean: 0.11176
[32m[0906 16-58-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01867, current rewards: 35.77772, mean: 0.09938
[32m[0906 16-58-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01865, current rewards: 41.37476, mean: 0.10091
[32m[0906 16-58-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01864, current rewards: 46.97002, mean: 0.10211
[32m[0906 16-58-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01860, current rewards: 52.56284, mean: 0.10306
[32m[0906 16-58-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01860, current rewards: 58.15207, mean: 0.10384
[32m[0906 16-58-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01858, current rewards: 63.71010, mean: 0.10444
[32m[0906 16-58-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01859, current rewards: 69.26056, mean: 0.10494
[32m[0906 16-58-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01858, current rewards: 74.83257, mean: 0.10540
[32m[0906 16-58-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01858, current rewards: 80.39963, mean: 0.10579
[32m[0906 16-58-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01858, current rewards: 85.97459, mean: 0.10614
[32m[0906 16-58-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01858, current rewards: 91.54084, mean: 0.10644
[32m[0906 16-58-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01858, current rewards: 97.12188, mean: 0.10673
[32m[0906 16-59-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 102.70374, mean: 0.10698
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 108.28927, mean: 0.10722
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01856, current rewards: 113.86322, mean: 0.10742
[32m[0906 16-59-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 119.45193, mean: 0.10761
[32m[0906 16-59-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 125.04010, mean: 0.10779
[32m[0906 16-59-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 130.62451, mean: 0.10795
[32m[0906 16-59-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 136.20532, mean: 0.10810
[32m[0906 16-59-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01856, current rewards: 141.90112, mean: 0.10832
[32m[0906 16-59-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01855, current rewards: 147.40151, mean: 0.10838
[32m[0906 16-59-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 152.90205, mean: 0.10844
[32m[0906 16-59-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 158.46603, mean: 0.10854
[32m[0906 16-59-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 163.98515, mean: 0.10860
[32m[0906 16-59-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 169.50392, mean: 0.10866
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 175.02343, mean: 0.10871
[32m[0906 16-59-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01855, current rewards: 180.54280, mean: 0.10876
[32m[0906 16-59-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: 186.06213, mean: 0.10881
[32m[0906 16-59-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 191.58000, mean: 0.10885
[32m[0906 16-59-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01854, current rewards: 197.10053, mean: 0.10890
[32m[0906 16-59-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01853, current rewards: 202.59897, mean: 0.10892
[32m[0906 16-59-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01853, current rewards: 208.10822, mean: 0.10896
[32m[0906 16-59-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01853, current rewards: 213.61726, mean: 0.10899
[32m[0906 16-59-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01853, current rewards: 219.12575, mean: 0.10902
[32m[0906 16-59-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01852, current rewards: 224.66652, mean: 0.10906
[32m[0906 16-59-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01853, current rewards: 230.23528, mean: 0.10912
[32m[0906 16-59-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01853, current rewards: 235.80719, mean: 0.10917
[32m[0906 16-59-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01853, current rewards: 241.37848, mean: 0.10922
[32m[0906 16-59-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01852, current rewards: 247.07215, mean: 0.10932
[32m[0906 16-59-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01852, current rewards: 252.64590, mean: 0.10937
[32m[0906 16-59-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01852, current rewards: 258.22396, mean: 0.10942
[32m[0906 16-59-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01852, current rewards: 263.80116, mean: 0.10946
[32m[0906 16-59-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01852, current rewards: 269.37649, mean: 0.10950
[32m[0906 16-59-28 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 16-59-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 16-59-29 @MBExp.py:227][0m Rewards obtained: [273.8385603732359], Lows: [0], Highs: [4], Total time: 4103.738576
[32m[0906 17-02-32 @MBExp.py:144][0m ####################################################################
[32m[0906 17-02-32 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-02-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.13878, mean: 0.11388
[32m[0906 17-02-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01814, current rewards: 6.73387, mean: 0.11223
[32m[0906 17-02-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01826, current rewards: 12.29363, mean: 0.11176
[32m[0906 17-02-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01835, current rewards: 17.85744, mean: 0.11161
[32m[0906 17-02-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01839, current rewards: 23.36902, mean: 0.11128
[32m[0906 17-02-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01842, current rewards: 28.98367, mean: 0.11148
[32m[0906 17-02-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.59408, mean: 0.11159
[32m[0906 17-02-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 40.20752, mean: 0.11169
[32m[0906 17-02-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 45.81921, mean: 0.11175
[32m[0906 17-02-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 51.43289, mean: 0.11181
[32m[0906 17-02-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 57.04750, mean: 0.11186
[32m[0906 17-02-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 62.66179, mean: 0.11190
[32m[0906 17-02-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01850, current rewards: 68.35545, mean: 0.11206
[32m[0906 17-02-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 69.44525, mean: 0.10522
[32m[0906 17-02-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 74.99995, mean: 0.10563
[32m[0906 17-02-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 80.55092, mean: 0.10599
[32m[0906 17-02-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 86.10522, mean: 0.10630
[32m[0906 17-02-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 91.65899, mean: 0.10658
[32m[0906 17-02-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 97.25599, mean: 0.10687
[32m[0906 17-02-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 102.87304, mean: 0.10716
[32m[0906 17-02-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 108.47248, mean: 0.10740
[32m[0906 17-02-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 114.05479, mean: 0.10760
[32m[0906 17-02-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 119.68766, mean: 0.10783
[32m[0906 17-02-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 125.32046, mean: 0.10803
[32m[0906 17-02-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 130.94778, mean: 0.10822
[32m[0906 17-02-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01851, current rewards: 136.57375, mean: 0.10839
[32m[0906 17-02-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01850, current rewards: 142.19776, mean: 0.10855
[32m[0906 17-02-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01849, current rewards: 147.82863, mean: 0.10870
[32m[0906 17-02-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01849, current rewards: 153.45921, mean: 0.10884
[32m[0906 17-02-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01850, current rewards: 159.03985, mean: 0.10893
[32m[0906 17-03-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01850, current rewards: 164.60838, mean: 0.10901
[32m[0906 17-03-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01850, current rewards: 170.16724, mean: 0.10908
[32m[0906 17-03-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01850, current rewards: 175.72686, mean: 0.10915
[32m[0906 17-03-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01849, current rewards: 181.29074, mean: 0.10921
[32m[0906 17-03-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01850, current rewards: 186.85055, mean: 0.10927
[32m[0906 17-03-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01849, current rewards: 192.41233, mean: 0.10933
[32m[0906 17-03-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01849, current rewards: 197.95183, mean: 0.10937
[32m[0906 17-03-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01849, current rewards: 203.46958, mean: 0.10939
[32m[0906 17-03-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01849, current rewards: 209.03490, mean: 0.10944
[32m[0906 17-03-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01849, current rewards: 214.60202, mean: 0.10949
[32m[0906 17-03-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01849, current rewards: 220.16904, mean: 0.10954
[32m[0906 17-03-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01848, current rewards: 225.73972, mean: 0.10958
[32m[0906 17-03-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01849, current rewards: 231.30468, mean: 0.10962
[32m[0906 17-03-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01849, current rewards: 236.86999, mean: 0.10966
[32m[0906 17-03-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01849, current rewards: 242.43689, mean: 0.10970
[32m[0906 17-03-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01849, current rewards: 248.04811, mean: 0.10976
[32m[0906 17-03-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: 253.60643, mean: 0.10979
[32m[0906 17-03-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01849, current rewards: 259.16450, mean: 0.10982
[32m[0906 17-03-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01849, current rewards: 264.72606, mean: 0.10984
[32m[0906 17-03-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: 270.32276, mean: 0.10989
[32m[0906 17-03-19 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-03-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-03-19 @MBExp.py:227][0m Rewards obtained: [274.8283003252023], Lows: [0], Highs: [4], Total time: 4150.75192
[32m[0906 17-06-24 @MBExp.py:144][0m ####################################################################
[32m[0906 17-06-24 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-06-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01844, current rewards: 1.05687, mean: 0.10569
[32m[0906 17-06-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01851, current rewards: 6.62326, mean: 0.11039
[32m[0906 17-06-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01837, current rewards: 12.26431, mean: 0.11149
[32m[0906 17-06-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01836, current rewards: 17.90474, mean: 0.11190
[32m[0906 17-06-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01838, current rewards: 23.58336, mean: 0.11230
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01839, current rewards: 29.12631, mean: 0.11202
[32m[0906 17-06-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01840, current rewards: 34.65506, mean: 0.11179
[32m[0906 17-06-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01841, current rewards: 40.19267, mean: 0.11165
[32m[0906 17-06-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01841, current rewards: 45.69664, mean: 0.11146
[32m[0906 17-06-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01842, current rewards: 51.19681, mean: 0.11130
[32m[0906 17-06-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01842, current rewards: 56.70578, mean: 0.11119
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01843, current rewards: 62.21065, mean: 0.11109
[32m[0906 17-06-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01845, current rewards: 67.64437, mean: 0.11089
[32m[0906 17-06-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01845, current rewards: 73.13984, mean: 0.11082
[32m[0906 17-06-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01844, current rewards: 78.63270, mean: 0.11075
[32m[0906 17-06-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01845, current rewards: 84.12951, mean: 0.11070
[32m[0906 17-06-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01846, current rewards: 89.62571, mean: 0.11065
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 95.11434, mean: 0.11060
[32m[0906 17-06-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01846, current rewards: 100.60620, mean: 0.11056
[32m[0906 17-06-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01847, current rewards: 106.12447, mean: 0.11055
[32m[0906 17-06-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01847, current rewards: 111.65390, mean: 0.11055
[32m[0906 17-06-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01847, current rewards: 117.17234, mean: 0.11054
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01847, current rewards: 122.69894, mean: 0.11054
[32m[0906 17-06-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01848, current rewards: 126.13009, mean: 0.10873
[32m[0906 17-06-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01848, current rewards: 131.70619, mean: 0.10885
[32m[0906 17-06-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01849, current rewards: 137.28387, mean: 0.10896
[32m[0906 17-06-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01849, current rewards: 142.86182, mean: 0.10905
[32m[0906 17-06-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01849, current rewards: 148.43813, mean: 0.10915
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01849, current rewards: 154.22161, mean: 0.10938
[32m[0906 17-06-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01849, current rewards: 160.82984, mean: 0.11016
[32m[0906 17-06-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01849, current rewards: 167.43808, mean: 0.11089
[32m[0906 17-06-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01848, current rewards: 174.04631, mean: 0.11157
[32m[0906 17-06-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01848, current rewards: 180.65454, mean: 0.11221
[32m[0906 17-06-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01848, current rewards: 166.88381, mean: 0.10053
[32m[0906 17-06-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01847, current rewards: 116.88381, mean: 0.06835
[32m[0906 17-06-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01848, current rewards: 66.88381, mean: 0.03800
[32m[0906 17-06-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01849, current rewards: 16.88381, mean: 0.00933
[32m[0906 17-06-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01850, current rewards: -33.11619, mean: -0.01780
[32m[0906 17-07-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01850, current rewards: -83.11619, mean: -0.04352
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01850, current rewards: -133.11619, mean: -0.06792
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01850, current rewards: -183.11619, mean: -0.09110
[32m[0906 17-07-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01849, current rewards: -233.11619, mean: -0.11316
[32m[0906 17-07-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01849, current rewards: -283.11619, mean: -0.13418
[32m[0906 17-07-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01849, current rewards: -333.11619, mean: -0.15422
[32m[0906 17-07-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01850, current rewards: -383.11619, mean: -0.17336
[32m[0906 17-07-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01849, current rewards: -380.43269, mean: -0.16833
[32m[0906 17-07-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: -377.89022, mean: -0.16359
[32m[0906 17-07-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01850, current rewards: -375.34731, mean: -0.15905
[32m[0906 17-07-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01850, current rewards: -372.80448, mean: -0.15469
[32m[0906 17-07-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: -370.26129, mean: -0.15051
[32m[0906 17-07-11 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-07-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-07-11 @MBExp.py:227][0m Rewards obtained: [-368.2272850340126], Lows: [1], Highs: [568], Total time: 4197.8046699999995
[32m[0906 17-10-18 @MBExp.py:144][0m ####################################################################
[32m[0906 17-10-18 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-10-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01841, current rewards: 1.09633, mean: 0.10963
[32m[0906 17-10-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01841, current rewards: 6.88898, mean: 0.11482
[32m[0906 17-10-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.78161, mean: 0.11620
[32m[0906 17-10-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01841, current rewards: 18.67170, mean: 0.11670
[32m[0906 17-10-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01843, current rewards: 24.20619, mean: 0.11527
[32m[0906 17-10-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 29.71463, mean: 0.11429
[32m[0906 17-10-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 35.21891, mean: 0.11361
[32m[0906 17-10-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.72714, mean: 0.11313
[32m[0906 17-10-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 46.23544, mean: 0.11277
[32m[0906 17-10-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 51.74956, mean: 0.11250
[32m[0906 17-10-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 57.34490, mean: 0.11244
[32m[0906 17-10-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.94222, mean: 0.11240
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 68.54911, mean: 0.11238
[32m[0906 17-10-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 74.14696, mean: 0.11234
[32m[0906 17-10-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 79.74581, mean: 0.11232
[32m[0906 17-10-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01849, current rewards: 85.34580, mean: 0.11230
[32m[0906 17-10-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 90.85730, mean: 0.11217
[32m[0906 17-10-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: 96.13522, mean: 0.11179
[32m[0906 17-10-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 101.40831, mean: 0.11144
[32m[0906 17-10-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 106.68850, mean: 0.11113
[32m[0906 17-10-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01848, current rewards: 111.98452, mean: 0.11088
[32m[0906 17-10-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01847, current rewards: 117.26153, mean: 0.11062
[32m[0906 17-10-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01847, current rewards: 122.63459, mean: 0.11048
[32m[0906 17-10-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01848, current rewards: 128.00660, mean: 0.11035
[32m[0906 17-10-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01848, current rewards: 133.37874, mean: 0.11023
[32m[0906 17-10-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01848, current rewards: 138.74625, mean: 0.11012
[32m[0906 17-10-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01847, current rewards: 144.19009, mean: 0.11007
[32m[0906 17-10-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01847, current rewards: 149.66160, mean: 0.11005
[32m[0906 17-10-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01847, current rewards: 155.04491, mean: 0.10996
[32m[0906 17-10-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01847, current rewards: 160.46457, mean: 0.10991
[32m[0906 17-10-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01847, current rewards: 165.88330, mean: 0.10986
[32m[0906 17-10-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01847, current rewards: 171.30142, mean: 0.10981
[32m[0906 17-10-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01845, current rewards: 176.71651, mean: 0.10976
[32m[0906 17-10-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01846, current rewards: 182.13330, mean: 0.10972
[32m[0906 17-10-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01847, current rewards: 187.55120, mean: 0.10968
[32m[0906 17-10-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01846, current rewards: 192.97280, mean: 0.10964
[32m[0906 17-10-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01847, current rewards: 198.45862, mean: 0.10965
[32m[0906 17-10-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01847, current rewards: 204.02418, mean: 0.10969
[32m[0906 17-10-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01847, current rewards: 209.55017, mean: 0.10971
[32m[0906 17-10-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01847, current rewards: 215.18406, mean: 0.10979
[32m[0906 17-10-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01847, current rewards: 220.88007, mean: 0.10989
[32m[0906 17-10-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01847, current rewards: 226.57785, mean: 0.10999
[32m[0906 17-10-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01848, current rewards: 232.27571, mean: 0.11008
[32m[0906 17-10-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01848, current rewards: 237.97145, mean: 0.11017
[32m[0906 17-11-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01848, current rewards: 243.66841, mean: 0.11026
[32m[0906 17-11-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01848, current rewards: 249.38240, mean: 0.11035
[32m[0906 17-11-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01848, current rewards: 254.89111, mean: 0.11034
[32m[0906 17-11-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01848, current rewards: 260.31526, mean: 0.11030
[32m[0906 17-11-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01848, current rewards: 265.73884, mean: 0.11027
[32m[0906 17-11-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01848, current rewards: 271.15956, mean: 0.11023
[32m[0906 17-11-05 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-11-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-11-05 @MBExp.py:227][0m Rewards obtained: [276.98182925753486], Lows: [0], Highs: [0], Total time: 4244.807599999999
[32m[0906 17-14-14 @MBExp.py:144][0m ####################################################################
[32m[0906 17-14-14 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 17-14-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01823, current rewards: 1.14108, mean: 0.11411
[32m[0906 17-14-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01845, current rewards: 6.63186, mean: 0.11053
[32m[0906 17-14-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01838, current rewards: 12.15982, mean: 0.11054
[32m[0906 17-14-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01837, current rewards: 17.71006, mean: 0.11069
[32m[0906 17-14-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01837, current rewards: 23.24481, mean: 0.11069
[32m[0906 17-14-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01842, current rewards: 28.78061, mean: 0.11069
[32m[0906 17-14-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.31435, mean: 0.11069
[32m[0906 17-14-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.84409, mean: 0.11068
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 45.38074, mean: 0.11068
[32m[0906 17-14-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 50.91286, mean: 0.11068
[32m[0906 17-14-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 56.44314, mean: 0.11067
[32m[0906 17-14-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 61.99976, mean: 0.11071
[32m[0906 17-14-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 67.57652, mean: 0.11078
[32m[0906 17-14-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 73.11405, mean: 0.11078
[32m[0906 17-14-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 78.71770, mean: 0.11087
[32m[0906 17-14-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 84.25258, mean: 0.11086
[32m[0906 17-14-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 89.79089, mean: 0.11085
[32m[0906 17-14-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 95.32383, mean: 0.11084
[32m[0906 17-14-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 100.85604, mean: 0.11083
[32m[0906 17-14-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 106.39102, mean: 0.11082
[32m[0906 17-14-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01851, current rewards: 111.83298, mean: 0.11073
[32m[0906 17-14-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01852, current rewards: 117.36893, mean: 0.11073
[32m[0906 17-14-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 122.90123, mean: 0.11072
[32m[0906 17-14-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 128.43190, mean: 0.11072
[32m[0906 17-14-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 133.96458, mean: 0.11071
[32m[0906 17-14-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 139.53270, mean: 0.11074
[32m[0906 17-14-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 145.10967, mean: 0.11077
[32m[0906 17-14-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 150.68492, mean: 0.11080
[32m[0906 17-14-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: 156.37297, mean: 0.11090
[32m[0906 17-14-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 161.97665, mean: 0.11094
[32m[0906 17-14-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 167.55647, mean: 0.11096
[32m[0906 17-14-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 173.13301, mean: 0.11098
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 178.66450, mean: 0.11097
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01854, current rewards: 184.19658, mean: 0.11096
[32m[0906 17-14-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: 189.72495, mean: 0.11095
[32m[0906 17-14-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 195.25508, mean: 0.11094
[32m[0906 17-14-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01854, current rewards: 200.78519, mean: 0.11093
[32m[0906 17-14-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01854, current rewards: 206.27247, mean: 0.11090
[32m[0906 17-14-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: 211.79652, mean: 0.11089
[32m[0906 17-14-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: 217.32046, mean: 0.11088
[32m[0906 17-14-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: 222.84188, mean: 0.11087
[32m[0906 17-14-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 228.36607, mean: 0.11086
[32m[0906 17-14-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: 233.88932, mean: 0.11085
[32m[0906 17-14-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01855, current rewards: 239.41478, mean: 0.11084
[32m[0906 17-14-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: 244.94070, mean: 0.11083
[32m[0906 17-14-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: 250.60437, mean: 0.11089
[32m[0906 17-14-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01855, current rewards: 256.39960, mean: 0.11100
[32m[0906 17-14-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01856, current rewards: 262.19483, mean: 0.11110
[32m[0906 17-15-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 262.41053, mean: 0.10888
[32m[0906 17-15-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 212.41053, mean: 0.08635
[32m[0906 17-15-01 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 17-15-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-15-01 @MBExp.py:227][0m Rewards obtained: [172.41053259688948], Lows: [0], Highs: [95], Total time: 4292.0070319999995
[32m[0906 17-18-13 @MBExp.py:144][0m ####################################################################
[32m[0906 17-18-13 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 17-18-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01744, current rewards: -0.88527, mean: -0.08853
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01814, current rewards: 4.61585, mean: 0.07693
[32m[0906 17-18-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01837, current rewards: 10.11845, mean: 0.09199
[32m[0906 17-18-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01841, current rewards: 15.62186, mean: 0.09764
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 21.23323, mean: 0.10111
[32m[0906 17-18-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01843, current rewards: 26.62065, mean: 0.10239
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 32.00774, mean: 0.10325
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 37.38965, mean: 0.10386
[32m[0906 17-18-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01844, current rewards: 42.77614, mean: 0.10433
[32m[0906 17-18-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01845, current rewards: 48.16257, mean: 0.10470
[32m[0906 17-18-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01845, current rewards: 53.55028, mean: 0.10500
[32m[0906 17-18-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01845, current rewards: 58.99409, mean: 0.10535
[32m[0906 17-18-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01845, current rewards: 64.51745, mean: 0.10577
[32m[0906 17-18-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01843, current rewards: 70.03636, mean: 0.10612
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01843, current rewards: 75.55995, mean: 0.10642
[32m[0906 17-18-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01843, current rewards: 81.07741, mean: 0.10668
[32m[0906 17-18-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01843, current rewards: 86.60017, mean: 0.10691
[32m[0906 17-18-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01845, current rewards: 92.11998, mean: 0.10712
[32m[0906 17-18-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01845, current rewards: 97.64135, mean: 0.10730
[32m[0906 17-18-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01844, current rewards: 103.09060, mean: 0.10739
[32m[0906 17-18-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01844, current rewards: 108.47353, mean: 0.10740
[32m[0906 17-18-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01845, current rewards: 113.83006, mean: 0.10739
[32m[0906 17-18-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01845, current rewards: 119.18044, mean: 0.10737
[32m[0906 17-18-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01845, current rewards: 124.53098, mean: 0.10735
[32m[0906 17-18-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01845, current rewards: 127.89767, mean: 0.10570
[32m[0906 17-18-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01845, current rewards: 135.55462, mean: 0.10758
[32m[0906 17-18-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01846, current rewards: 143.20970, mean: 0.10932
[32m[0906 17-18-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01845, current rewards: 150.86478, mean: 0.11093
[32m[0906 17-18-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01846, current rewards: 156.51824, mean: 0.11101
[32m[0906 17-18-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01845, current rewards: 159.26493, mean: 0.10909
[32m[0906 17-18-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01845, current rewards: 146.18762, mean: 0.09681
[32m[0906 17-18-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01846, current rewards: 96.18762, mean: 0.06166
[32m[0906 17-18-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01845, current rewards: 46.18762, mean: 0.02869
[32m[0906 17-18-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01845, current rewards: -3.81238, mean: -0.00230
[32m[0906 17-18-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01845, current rewards: -53.81238, mean: -0.03147
[32m[0906 17-18-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01845, current rewards: -103.81238, mean: -0.05898
[32m[0906 17-18-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01845, current rewards: -153.81238, mean: -0.08498
[32m[0906 17-18-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01844, current rewards: -203.81238, mean: -0.10958
[32m[0906 17-18-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01844, current rewards: -253.81238, mean: -0.13289
[32m[0906 17-18-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01844, current rewards: -303.81238, mean: -0.15501
[32m[0906 17-18-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01845, current rewards: -353.81238, mean: -0.17603
[32m[0906 17-18-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01845, current rewards: -403.81238, mean: -0.19603
[32m[0906 17-18-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01844, current rewards: -453.81238, mean: -0.21508
[32m[0906 17-18-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01844, current rewards: -503.81238, mean: -0.23325
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01844, current rewards: -553.81238, mean: -0.25059
[32m[0906 17-18-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01844, current rewards: -603.81238, mean: -0.26717
[32m[0906 17-18-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01844, current rewards: -653.81238, mean: -0.28304
[32m[0906 17-18-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01844, current rewards: -703.81238, mean: -0.29823
[32m[0906 17-18-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01844, current rewards: -753.81238, mean: -0.31279
[32m[0906 17-18-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01844, current rewards: -803.81238, mean: -0.32675
[32m[0906 17-18-59 @Agent.py:117][0m Average action selection time: 0.0184
[32m[0906 17-18-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-19-00 @MBExp.py:227][0m Rewards obtained: [-843.812382639139], Lows: [2], Highs: [1005], Total time: 4338.899130999999
[32m[0906 17-22-12 @MBExp.py:144][0m ####################################################################
[32m[0906 17-22-12 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 17-22-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01818, current rewards: 1.04831, mean: 0.10483
[32m[0906 17-22-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01846, current rewards: 6.59742, mean: 0.10996
[32m[0906 17-22-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01843, current rewards: 12.14120, mean: 0.11037
[32m[0906 17-22-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01842, current rewards: 17.79780, mean: 0.11124
[32m[0906 17-22-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01841, current rewards: 23.35823, mean: 0.11123
[32m[0906 17-22-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01846, current rewards: 28.91431, mean: 0.11121
[32m[0906 17-22-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 34.47007, mean: 0.11119
[32m[0906 17-22-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 40.03131, mean: 0.11120
[32m[0906 17-22-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.58791, mean: 0.11119
[32m[0906 17-22-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 51.14415, mean: 0.11118
[32m[0906 17-22-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 56.69600, mean: 0.11117
[32m[0906 17-22-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01849, current rewards: 62.25498, mean: 0.11117
[32m[0906 17-22-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 67.81610, mean: 0.11117
[32m[0906 17-22-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 73.42559, mean: 0.11125
[32m[0906 17-22-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 79.03378, mean: 0.11132
[32m[0906 17-22-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 84.64083, mean: 0.11137
[32m[0906 17-22-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 90.24661, mean: 0.11142
[32m[0906 17-22-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01846, current rewards: 95.84933, mean: 0.11145
[32m[0906 17-22-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01846, current rewards: 101.45056, mean: 0.11148
[32m[0906 17-22-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01845, current rewards: 106.99531, mean: 0.11145
[32m[0906 17-22-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01846, current rewards: 112.67135, mean: 0.11156
[32m[0906 17-22-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01845, current rewards: 118.24976, mean: 0.11156
[32m[0906 17-22-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01847, current rewards: 123.82917, mean: 0.11156
[32m[0906 17-22-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01846, current rewards: 129.40446, mean: 0.11156
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01846, current rewards: 134.98368, mean: 0.11156
[32m[0906 17-22-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01846, current rewards: 140.56332, mean: 0.11156
[32m[0906 17-22-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01848, current rewards: 146.14215, mean: 0.11156
[32m[0906 17-22-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01848, current rewards: 151.71886, mean: 0.11156
[32m[0906 17-22-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01849, current rewards: 157.22136, mean: 0.11150
[32m[0906 17-22-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01849, current rewards: 162.78480, mean: 0.11150
[32m[0906 17-22-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01849, current rewards: 168.34857, mean: 0.11149
[32m[0906 17-22-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01848, current rewards: 173.90987, mean: 0.11148
[32m[0906 17-22-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01849, current rewards: 179.46971, mean: 0.11147
[32m[0906 17-22-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01849, current rewards: 185.02401, mean: 0.11146
[32m[0906 17-22-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01849, current rewards: 190.58480, mean: 0.11145
[32m[0906 17-22-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01849, current rewards: 196.14442, mean: 0.11145
[32m[0906 17-22-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01849, current rewards: 201.67056, mean: 0.11142
[32m[0906 17-22-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01848, current rewards: 207.25214, mean: 0.11143
[32m[0906 17-22-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01848, current rewards: 212.84782, mean: 0.11144
[32m[0906 17-22-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01849, current rewards: 218.44303, mean: 0.11145
[32m[0906 17-22-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01849, current rewards: 224.03914, mean: 0.11146
[32m[0906 17-22-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01849, current rewards: 229.63385, mean: 0.11147
[32m[0906 17-22-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01849, current rewards: 235.22804, mean: 0.11148
[32m[0906 17-22-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01849, current rewards: 240.82313, mean: 0.11149
[32m[0906 17-22-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01849, current rewards: 246.40916, mean: 0.11150
[32m[0906 17-22-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01850, current rewards: 251.92463, mean: 0.11147
[32m[0906 17-22-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01850, current rewards: 257.49098, mean: 0.11147
[32m[0906 17-22-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01850, current rewards: 263.05640, mean: 0.11146
[32m[0906 17-22-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01850, current rewards: 268.62061, mean: 0.11146
[32m[0906 17-22-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01850, current rewards: 274.18737, mean: 0.11146
[32m[0906 17-22-59 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-22-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-22-59 @MBExp.py:227][0m Rewards obtained: [278.6402194704184], Lows: [0], Highs: [0], Total time: 4385.971384999999
[32m[0906 17-26-14 @MBExp.py:144][0m ####################################################################
[32m[0906 17-26-14 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 17-26-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01804, current rewards: 1.17667, mean: 0.11767
[32m[0906 17-26-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01833, current rewards: 6.71068, mean: 0.11184
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.24169, mean: 0.11129
[32m[0906 17-26-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 17.76161, mean: 0.11101
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 23.29175, mean: 0.11091
[32m[0906 17-26-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.82510, mean: 0.11087
[32m[0906 17-26-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 34.39583, mean: 0.11095
[32m[0906 17-26-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01846, current rewards: 39.93538, mean: 0.11093
[32m[0906 17-26-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01843, current rewards: 45.47927, mean: 0.11093
[32m[0906 17-26-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01845, current rewards: 51.02091, mean: 0.11092
[32m[0906 17-26-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01845, current rewards: 56.55666, mean: 0.11090
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01846, current rewards: 62.23567, mean: 0.11114
[32m[0906 17-26-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01845, current rewards: 67.76584, mean: 0.11109
[32m[0906 17-26-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01845, current rewards: 73.30109, mean: 0.11106
[32m[0906 17-26-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01845, current rewards: 78.83612, mean: 0.11104
[32m[0906 17-26-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01845, current rewards: 84.37014, mean: 0.11101
[32m[0906 17-26-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 88.85311, mean: 0.10970
[32m[0906 17-26-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 94.37638, mean: 0.10974
[32m[0906 17-26-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01846, current rewards: 99.90021, mean: 0.10978
[32m[0906 17-26-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01846, current rewards: 105.42814, mean: 0.10982
[32m[0906 17-26-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01847, current rewards: 110.95507, mean: 0.10986
[32m[0906 17-26-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01848, current rewards: 116.48903, mean: 0.10990
[32m[0906 17-26-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01847, current rewards: 122.01246, mean: 0.10992
[32m[0906 17-26-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01847, current rewards: 127.53975, mean: 0.10995
[32m[0906 17-26-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01846, current rewards: 133.07312, mean: 0.10998
[32m[0906 17-26-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01846, current rewards: 138.58552, mean: 0.10999
[32m[0906 17-26-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01846, current rewards: 144.11441, mean: 0.11001
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01846, current rewards: 149.61717, mean: 0.11001
[32m[0906 17-26-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01845, current rewards: 155.14238, mean: 0.11003
[32m[0906 17-26-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01846, current rewards: 160.66320, mean: 0.11004
[32m[0906 17-26-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01846, current rewards: 166.19230, mean: 0.11006
[32m[0906 17-26-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01845, current rewards: 171.71912, mean: 0.11008
[32m[0906 17-26-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01846, current rewards: 177.24878, mean: 0.11009
[32m[0906 17-26-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01846, current rewards: 182.77508, mean: 0.11011
[32m[0906 17-26-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01847, current rewards: 188.30036, mean: 0.11012
[32m[0906 17-26-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01847, current rewards: 193.75481, mean: 0.11009
[32m[0906 17-26-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01846, current rewards: 199.28619, mean: 0.11010
[32m[0906 17-26-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01847, current rewards: 204.81672, mean: 0.11012
[32m[0906 17-26-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01847, current rewards: 208.21018, mean: 0.10901
[32m[0906 17-26-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01848, current rewards: 213.74557, mean: 0.10905
[32m[0906 17-26-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01848, current rewards: 219.28047, mean: 0.10909
[32m[0906 17-26-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01848, current rewards: 224.81803, mean: 0.10913
[32m[0906 17-26-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01848, current rewards: 230.34703, mean: 0.10917
[32m[0906 17-26-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01848, current rewards: 235.94133, mean: 0.10923
[32m[0906 17-26-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01848, current rewards: 241.54654, mean: 0.10930
[32m[0906 17-26-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01848, current rewards: 247.07711, mean: 0.10933
[32m[0906 17-26-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: 252.61021, mean: 0.10936
[32m[0906 17-26-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01849, current rewards: 258.10554, mean: 0.10937
[32m[0906 17-27-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01849, current rewards: 263.63168, mean: 0.10939
[32m[0906 17-27-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: 269.16054, mean: 0.10941
[32m[0906 17-27-01 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-27-01 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-27-01 @MBExp.py:227][0m Rewards obtained: [273.58594335726644], Lows: [1], Highs: [1], Total time: 4432.992622999999
[32m[0906 17-30-18 @MBExp.py:144][0m ####################################################################
[32m[0906 17-30-18 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 17-30-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.14744, mean: 0.11474
[32m[0906 17-30-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01852, current rewards: 6.70713, mean: 0.11179
[32m[0906 17-30-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 12.26953, mean: 0.11154
[32m[0906 17-30-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01843, current rewards: 17.83416, mean: 0.11146
[32m[0906 17-30-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.40617, mean: 0.11146
[32m[0906 17-30-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01846, current rewards: 28.96969, mean: 0.11142
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01845, current rewards: 34.53021, mean: 0.11139
[32m[0906 17-30-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01845, current rewards: 40.09334, mean: 0.11137
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 45.61882, mean: 0.11127
[32m[0906 17-30-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 51.18288, mean: 0.11127
[32m[0906 17-30-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01847, current rewards: 56.83865, mean: 0.11145
[32m[0906 17-30-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 62.41069, mean: 0.11145
[32m[0906 17-30-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01847, current rewards: 67.97892, mean: 0.11144
[32m[0906 17-30-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: 73.53924, mean: 0.11142
[32m[0906 17-30-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 79.13899, mean: 0.11146
[32m[0906 17-30-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 84.70071, mean: 0.11145
[32m[0906 17-30-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 90.26244, mean: 0.11144
[32m[0906 17-30-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01846, current rewards: 95.82326, mean: 0.11142
[32m[0906 17-30-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01845, current rewards: 101.53959, mean: 0.11158
[32m[0906 17-30-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01846, current rewards: 107.02361, mean: 0.11148
[32m[0906 17-30-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01846, current rewards: 112.59280, mean: 0.11148
[32m[0906 17-30-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01847, current rewards: 118.16614, mean: 0.11148
[32m[0906 17-30-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01848, current rewards: 123.74264, mean: 0.11148
[32m[0906 17-30-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01848, current rewards: 129.31464, mean: 0.11148
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01849, current rewards: 134.88316, mean: 0.11147
[32m[0906 17-30-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01849, current rewards: 140.45566, mean: 0.11147
[32m[0906 17-30-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01848, current rewards: 146.02557, mean: 0.11147
[32m[0906 17-30-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01849, current rewards: 151.66045, mean: 0.11152
[32m[0906 17-30-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01848, current rewards: 157.23347, mean: 0.11151
[32m[0906 17-30-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01848, current rewards: 162.80571, mean: 0.11151
[32m[0906 17-30-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01848, current rewards: 168.37984, mean: 0.11151
[32m[0906 17-30-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01849, current rewards: 173.95372, mean: 0.11151
[32m[0906 17-30-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01849, current rewards: 179.52695, mean: 0.11151
[32m[0906 17-30-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01849, current rewards: 185.10062, mean: 0.11151
[32m[0906 17-30-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01850, current rewards: 190.63693, mean: 0.11148
[32m[0906 17-30-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01850, current rewards: 196.26478, mean: 0.11151
[32m[0906 17-30-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01851, current rewards: 201.81997, mean: 0.11150
[32m[0906 17-30-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: 207.74359, mean: 0.11169
[32m[0906 17-30-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01851, current rewards: 213.28090, mean: 0.11167
[32m[0906 17-30-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01851, current rewards: 218.81823, mean: 0.11164
[32m[0906 17-30-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01850, current rewards: 224.35561, mean: 0.11162
[32m[0906 17-30-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01850, current rewards: 229.89298, mean: 0.11160
[32m[0906 17-30-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01850, current rewards: 235.43035, mean: 0.11158
[32m[0906 17-30-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01851, current rewards: 239.85701, mean: 0.11104
[32m[0906 17-30-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01851, current rewards: 243.15492, mean: 0.11002
[32m[0906 17-31-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01851, current rewards: 248.72303, mean: 0.11005
[32m[0906 17-31-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01851, current rewards: 254.29031, mean: 0.11008
[32m[0906 17-31-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01851, current rewards: 259.85270, mean: 0.11011
[32m[0906 17-31-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01851, current rewards: 265.41746, mean: 0.11013
[32m[0906 17-31-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01851, current rewards: 270.98067, mean: 0.11015
[32m[0906 17-31-05 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-31-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-31-05 @MBExp.py:227][0m Rewards obtained: [275.42992986688137], Lows: [0], Highs: [3], Total time: 4480.063192999999
[32m[0906 17-34-24 @MBExp.py:144][0m ####################################################################
[32m[0906 17-34-24 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 17-34-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01804, current rewards: 1.08540, mean: 0.10854
[32m[0906 17-34-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01841, current rewards: 6.62037, mean: 0.11034
[32m[0906 17-34-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 12.17130, mean: 0.11065
[32m[0906 17-34-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01847, current rewards: 17.70847, mean: 0.11068
[32m[0906 17-34-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01843, current rewards: 23.24933, mean: 0.11071
[32m[0906 17-34-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.78179, mean: 0.11070
[32m[0906 17-34-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01855, current rewards: 34.31622, mean: 0.11070
[32m[0906 17-34-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.85453, mean: 0.11071
[32m[0906 17-34-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 45.39262, mean: 0.11071
[32m[0906 17-34-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 50.92964, mean: 0.11072
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 56.42890, mean: 0.11064
[32m[0906 17-34-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01852, current rewards: 61.95981, mean: 0.11064
[32m[0906 17-34-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01854, current rewards: 67.48965, mean: 0.11064
[32m[0906 17-34-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01854, current rewards: 73.02021, mean: 0.11064
[32m[0906 17-34-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 78.54758, mean: 0.11063
[32m[0906 17-34-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 84.08969, mean: 0.11064
[32m[0906 17-34-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 89.63073, mean: 0.11066
[32m[0906 17-34-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 95.17103, mean: 0.11066
[32m[0906 17-34-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 100.66561, mean: 0.11062
[32m[0906 17-34-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01853, current rewards: 106.20235, mean: 0.11063
[32m[0906 17-34-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 111.73912, mean: 0.11063
[32m[0906 17-34-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 117.27599, mean: 0.11064
[32m[0906 17-34-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: 122.81422, mean: 0.11064
[32m[0906 17-34-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 128.35222, mean: 0.11065
[32m[0906 17-34-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 133.88865, mean: 0.11065
[32m[0906 17-34-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: 139.56005, mean: 0.11076
[32m[0906 17-34-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: 145.12580, mean: 0.11078
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 150.69242, mean: 0.11080
[32m[0906 17-34-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01851, current rewards: 156.25688, mean: 0.11082
[32m[0906 17-34-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01851, current rewards: 161.82125, mean: 0.11084
[32m[0906 17-34-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 167.38626, mean: 0.11085
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01851, current rewards: 172.94952, mean: 0.11087
[32m[0906 17-34-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01851, current rewards: 178.47819, mean: 0.11086
[32m[0906 17-34-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: 184.01814, mean: 0.11085
[32m[0906 17-34-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01851, current rewards: 189.57116, mean: 0.11086
[32m[0906 17-34-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01851, current rewards: 195.11286, mean: 0.11086
[32m[0906 17-34-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01852, current rewards: 200.65108, mean: 0.11086
[32m[0906 17-34-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01852, current rewards: 206.19612, mean: 0.11086
[32m[0906 17-35-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01852, current rewards: 211.73706, mean: 0.11086
[32m[0906 17-35-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01851, current rewards: 217.27709, mean: 0.11086
[32m[0906 17-35-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01851, current rewards: 222.81690, mean: 0.11085
[32m[0906 17-35-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01851, current rewards: 228.35452, mean: 0.11085
[32m[0906 17-35-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01851, current rewards: 234.06280, mean: 0.11093
[32m[0906 17-35-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01851, current rewards: 239.60970, mean: 0.11093
[32m[0906 17-35-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01851, current rewards: 245.15617, mean: 0.11093
[32m[0906 17-35-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01852, current rewards: 250.69552, mean: 0.11093
[32m[0906 17-35-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01852, current rewards: 256.22979, mean: 0.11092
[32m[0906 17-35-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01852, current rewards: 261.77716, mean: 0.11092
[32m[0906 17-35-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01852, current rewards: 267.31916, mean: 0.11092
[32m[0906 17-35-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01852, current rewards: 272.85861, mean: 0.11092
[32m[0906 17-35-11 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-35-11 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-35-11 @MBExp.py:227][0m Rewards obtained: [277.3462678740098], Lows: [0], Highs: [0], Total time: 4527.169143999999
[32m[0906 17-38-32 @MBExp.py:144][0m ####################################################################
[32m[0906 17-38-32 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 17-38-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01843, current rewards: 1.20965, mean: 0.12096
[32m[0906 17-38-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01839, current rewards: 6.72469, mean: 0.11208
[32m[0906 17-38-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01830, current rewards: 12.23719, mean: 0.11125
[32m[0906 17-38-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01831, current rewards: 17.75353, mean: 0.11096
[32m[0906 17-38-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01832, current rewards: 23.27131, mean: 0.11082
[32m[0906 17-38-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01837, current rewards: 28.78731, mean: 0.11072
[32m[0906 17-38-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01839, current rewards: 34.29515, mean: 0.11063
[32m[0906 17-38-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01838, current rewards: 39.81347, mean: 0.11059
[32m[0906 17-38-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01840, current rewards: 45.32352, mean: 0.11055
[32m[0906 17-38-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01840, current rewards: 50.73471, mean: 0.11029
[32m[0906 17-38-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01839, current rewards: 56.21119, mean: 0.11022
[32m[0906 17-38-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01840, current rewards: 61.73838, mean: 0.11025
[32m[0906 17-38-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01840, current rewards: 67.26100, mean: 0.11026
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01841, current rewards: 72.77650, mean: 0.11027
[32m[0906 17-38-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01843, current rewards: 78.29830, mean: 0.11028
[32m[0906 17-38-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01843, current rewards: 83.81990, mean: 0.11029
[32m[0906 17-38-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01843, current rewards: 89.34498, mean: 0.11030
[32m[0906 17-38-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01843, current rewards: 94.86178, mean: 0.11030
[32m[0906 17-38-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01842, current rewards: 100.37925, mean: 0.11031
[32m[0906 17-38-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01842, current rewards: 105.89856, mean: 0.11031
[32m[0906 17-38-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01842, current rewards: 111.42521, mean: 0.11032
[32m[0906 17-38-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01842, current rewards: 116.95004, mean: 0.11033
[32m[0906 17-38-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01842, current rewards: 122.46954, mean: 0.11033
[32m[0906 17-38-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01842, current rewards: 127.98449, mean: 0.11033
[32m[0906 17-38-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01843, current rewards: 133.50334, mean: 0.11033
[32m[0906 17-38-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01844, current rewards: 139.12656, mean: 0.11042
[32m[0906 17-38-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01844, current rewards: 144.67928, mean: 0.11044
[32m[0906 17-38-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01843, current rewards: 150.34420, mean: 0.11055
[32m[0906 17-38-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01845, current rewards: 155.99267, mean: 0.11063
[32m[0906 17-38-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01845, current rewards: 161.64110, mean: 0.11071
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01844, current rewards: 167.28909, mean: 0.11079
[32m[0906 17-39-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01845, current rewards: 172.93903, mean: 0.11086
[32m[0906 17-39-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01845, current rewards: 178.59365, mean: 0.11093
[32m[0906 17-39-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01845, current rewards: 184.25113, mean: 0.11099
[32m[0906 17-39-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01845, current rewards: 189.90467, mean: 0.11106
[32m[0906 17-39-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01845, current rewards: 195.55528, mean: 0.11111
[32m[0906 17-39-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01845, current rewards: 201.20621, mean: 0.11116
[32m[0906 17-39-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01844, current rewards: 206.85944, mean: 0.11121
[32m[0906 17-39-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01845, current rewards: 210.68863, mean: 0.11031
[32m[0906 17-39-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01845, current rewards: 216.68634, mean: 0.11055
[32m[0906 17-39-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01845, current rewards: 222.68695, mean: 0.11079
[32m[0906 17-39-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01844, current rewards: 228.62163, mean: 0.11098
[32m[0906 17-39-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01844, current rewards: 234.49509, mean: 0.11114
[32m[0906 17-39-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01845, current rewards: 240.41109, mean: 0.11130
[32m[0906 17-39-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01845, current rewards: 246.33021, mean: 0.11146
[32m[0906 17-39-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01845, current rewards: 252.24861, mean: 0.11161
[32m[0906 17-39-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01845, current rewards: 258.16767, mean: 0.11176
[32m[0906 17-39-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01846, current rewards: 264.08625, mean: 0.11190
[32m[0906 17-39-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01846, current rewards: 270.00814, mean: 0.11204
[32m[0906 17-39-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01845, current rewards: 275.92192, mean: 0.11216
[32m[0906 17-39-19 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-39-19 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-39-19 @MBExp.py:227][0m Rewards obtained: [280.81276150683976], Lows: [1], Highs: [0], Total time: 4574.108704999999
[32m[0906 17-42-42 @MBExp.py:144][0m ####################################################################
[32m[0906 17-42-42 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 17-42-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01826, current rewards: 1.04718, mean: 0.10472
[32m[0906 17-42-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01837, current rewards: 6.53625, mean: 0.10894
[32m[0906 17-42-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.07619, mean: 0.10978
[32m[0906 17-42-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01845, current rewards: 17.61861, mean: 0.11012
[32m[0906 17-42-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 23.15421, mean: 0.11026
[32m[0906 17-42-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.69918, mean: 0.11038
[32m[0906 17-42-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01860, current rewards: 35.00901, mean: 0.11293
[32m[0906 17-42-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01874, current rewards: 41.28924, mean: 0.11469
[32m[0906 17-42-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01882, current rewards: 47.58007, mean: 0.11605
[32m[0906 17-42-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01892, current rewards: 53.87490, mean: 0.11712
[32m[0906 17-42-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01896, current rewards: 60.11355, mean: 0.11787
[32m[0906 17-42-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01905, current rewards: 66.44014, mean: 0.11864
[32m[0906 17-42-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01913, current rewards: 72.87167, mean: 0.11946
[32m[0906 17-42-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01919, current rewards: 79.15283, mean: 0.11993
[32m[0906 17-42-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01926, current rewards: 85.50547, mean: 0.12043
[32m[0906 17-42-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01928, current rewards: 91.75322, mean: 0.12073
[32m[0906 17-42-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01930, current rewards: 98.01609, mean: 0.12101
[32m[0906 17-42-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01932, current rewards: 104.36445, mean: 0.12135
[32m[0906 17-43-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01934, current rewards: 110.59093, mean: 0.12153
[32m[0906 17-43-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01933, current rewards: 116.75657, mean: 0.12162
[32m[0906 17-43-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01935, current rewards: 122.95726, mean: 0.12174
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01932, current rewards: 128.82276, mean: 0.12153
[32m[0906 17-43-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01928, current rewards: 134.33103, mean: 0.12102
[32m[0906 17-43-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01925, current rewards: 139.83733, mean: 0.12055
[32m[0906 17-43-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01922, current rewards: 145.34205, mean: 0.12012
[32m[0906 17-43-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01919, current rewards: 150.82240, mean: 0.11970
[32m[0906 17-43-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01917, current rewards: 156.32517, mean: 0.11933
[32m[0906 17-43-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01915, current rewards: 161.82846, mean: 0.11899
[32m[0906 17-43-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01912, current rewards: 167.32996, mean: 0.11867
[32m[0906 17-43-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01910, current rewards: 172.82854, mean: 0.11838
[32m[0906 17-43-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01908, current rewards: 178.32984, mean: 0.11810
[32m[0906 17-43-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01906, current rewards: 183.83377, mean: 0.11784
[32m[0906 17-43-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01904, current rewards: 189.33573, mean: 0.11760
[32m[0906 17-43-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01903, current rewards: 194.98499, mean: 0.11746
[32m[0906 17-43-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01901, current rewards: 198.64990, mean: 0.11617
[32m[0906 17-43-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01900, current rewards: 204.43185, mean: 0.11615
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01898, current rewards: 210.21315, mean: 0.11614
[32m[0906 17-43-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01896, current rewards: 215.99536, mean: 0.11613
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01895, current rewards: 221.77716, mean: 0.11611
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01894, current rewards: 227.55968, mean: 0.11610
[32m[0906 17-43-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01893, current rewards: 233.34171, mean: 0.11609
[32m[0906 17-43-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01892, current rewards: 238.99715, mean: 0.11602
[32m[0906 17-43-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01891, current rewards: 243.50364, mean: 0.11540
[32m[0906 17-43-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01889, current rewards: 249.17006, mean: 0.11536
[32m[0906 17-43-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01889, current rewards: 254.83361, mean: 0.11531
[32m[0906 17-43-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01888, current rewards: 260.48035, mean: 0.11526
[32m[0906 17-43-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01887, current rewards: 266.14897, mean: 0.11522
[32m[0906 17-43-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01886, current rewards: 271.80939, mean: 0.11517
[32m[0906 17-43-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01886, current rewards: 277.46482, mean: 0.11513
[32m[0906 17-43-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01885, current rewards: 283.06017, mean: 0.11507
[32m[0906 17-43-30 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 17-43-30 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-43-30 @MBExp.py:227][0m Rewards obtained: [287.4779334637257], Lows: [1], Highs: [1], Total time: 4622.041773999998
[32m[0906 17-46-54 @MBExp.py:144][0m ####################################################################
[32m[0906 17-46-54 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 17-46-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02351, current rewards: 1.46708, mean: 0.14671
[32m[0906 17-46-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02508, current rewards: 9.86901, mean: 0.16448
[32m[0906 17-46-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02543, current rewards: 18.22175, mean: 0.16565
[32m[0906 17-46-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02584, current rewards: 25.73148, mean: 0.16082
[32m[0906 17-47-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02595, current rewards: 33.64540, mean: 0.16022
[32m[0906 17-47-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02572, current rewards: 37.31833, mean: 0.14353
[32m[0906 17-47-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02454, current rewards: 44.41489, mean: 0.14327
[32m[0906 17-47-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02372, current rewards: 51.51144, mean: 0.14309
[32m[0906 17-47-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02307, current rewards: 37.73768, mean: 0.09204
[32m[0906 17-47-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02257, current rewards: -12.26232, mean: -0.02666
[32m[0906 17-47-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02216, current rewards: -62.26232, mean: -0.12208
[32m[0906 17-47-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02184, current rewards: -112.26232, mean: -0.20047
[32m[0906 17-47-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02158, current rewards: -162.26232, mean: -0.26600
[32m[0906 17-47-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02136, current rewards: -212.26232, mean: -0.32161
[32m[0906 17-47-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02113, current rewards: -262.26232, mean: -0.36938
[32m[0906 17-47-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02096, current rewards: -312.26232, mean: -0.41087
[32m[0906 17-47-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02080, current rewards: -362.26232, mean: -0.44724
[32m[0906 17-47-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02067, current rewards: -412.26232, mean: -0.47937
[32m[0906 17-47-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02056, current rewards: -462.26232, mean: -0.50798
[32m[0906 17-47-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02044, current rewards: -512.26232, mean: -0.53361
[32m[0906 17-47-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02035, current rewards: -562.26232, mean: -0.55670
[32m[0906 17-47-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02027, current rewards: -612.26232, mean: -0.57761
[32m[0906 17-47-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02018, current rewards: -662.26232, mean: -0.59663
[32m[0906 17-47-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02011, current rewards: -712.26232, mean: -0.61402
[32m[0906 17-47-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02005, current rewards: -762.26232, mean: -0.62997
[32m[0906 17-47-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01998, current rewards: -812.26232, mean: -0.64465
[32m[0906 17-47-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01992, current rewards: -862.26232, mean: -0.65822
[32m[0906 17-47-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01987, current rewards: -912.26232, mean: -0.67078
[32m[0906 17-47-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01983, current rewards: -962.26232, mean: -0.68246
[32m[0906 17-47-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01978, current rewards: -1012.26232, mean: -0.69333
[32m[0906 17-47-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01974, current rewards: -1062.26232, mean: -0.70348
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01970, current rewards: -1112.26232, mean: -0.71299
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01966, current rewards: -1162.26232, mean: -0.72190
[32m[0906 17-47-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01963, current rewards: -1212.26232, mean: -0.73028
[32m[0906 17-47-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01960, current rewards: -1262.26232, mean: -0.73817
[32m[0906 17-47-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01956, current rewards: -1312.26232, mean: -0.74560
[32m[0906 17-47-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01953, current rewards: -1362.26232, mean: -0.75263
[32m[0906 17-47-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01951, current rewards: -1412.26232, mean: -0.75928
[32m[0906 17-47-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01948, current rewards: -1462.26232, mean: -0.76558
[32m[0906 17-47-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01946, current rewards: -1512.26232, mean: -0.77156
[32m[0906 17-47-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01944, current rewards: -1562.26232, mean: -0.77724
[32m[0906 17-47-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01941, current rewards: -1612.26232, mean: -0.78265
[32m[0906 17-47-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01939, current rewards: -1662.26232, mean: -0.78780
[32m[0906 17-47-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01938, current rewards: -1712.26232, mean: -0.79271
[32m[0906 17-47-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01936, current rewards: -1762.26232, mean: -0.79740
[32m[0906 17-47-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01935, current rewards: -1812.26232, mean: -0.80189
[32m[0906 17-47-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01933, current rewards: -1862.26232, mean: -0.80617
[32m[0906 17-47-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01931, current rewards: -1912.26232, mean: -0.81028
[32m[0906 17-47-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01930, current rewards: -1962.26232, mean: -0.81422
[32m[0906 17-47-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01928, current rewards: -2012.26232, mean: -0.81799
[32m[0906 17-47-43 @Agent.py:117][0m Average action selection time: 0.0193
[32m[0906 17-47-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-47-43 @MBExp.py:227][0m Rewards obtained: [-2052.2623223064356], Lows: [2], Highs: [2107], Total time: 4671.0453149999985
[32m[0906 17-51-12 @MBExp.py:144][0m ####################################################################
[32m[0906 17-51-12 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 17-51-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01819, current rewards: 1.02892, mean: 0.10289
[32m[0906 17-51-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01828, current rewards: 6.55107, mean: 0.10918
[32m[0906 17-51-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01836, current rewards: 12.07888, mean: 0.10981
[32m[0906 17-51-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01833, current rewards: 17.60292, mean: 0.11002
[32m[0906 17-51-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01837, current rewards: 23.12695, mean: 0.11013
[32m[0906 17-51-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01840, current rewards: 28.65526, mean: 0.11021
[32m[0906 17-51-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01840, current rewards: 34.18498, mean: 0.11027
[32m[0906 17-51-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01840, current rewards: 39.69389, mean: 0.11026
[32m[0906 17-51-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01841, current rewards: 45.28212, mean: 0.11044
[32m[0906 17-51-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01841, current rewards: 50.87344, mean: 0.11059
[32m[0906 17-51-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01841, current rewards: 56.46725, mean: 0.11072
[32m[0906 17-51-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01842, current rewards: 62.05912, mean: 0.11082
[32m[0906 17-51-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01842, current rewards: 67.64800, mean: 0.11090
[32m[0906 17-51-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01843, current rewards: 73.23804, mean: 0.11097
[32m[0906 17-51-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01842, current rewards: 78.82759, mean: 0.11102
[32m[0906 17-51-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01843, current rewards: 84.50777, mean: 0.11119
[32m[0906 17-51-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01843, current rewards: 88.86494, mean: 0.10971
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01844, current rewards: 94.38638, mean: 0.10975
[32m[0906 17-51-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01845, current rewards: 99.90820, mean: 0.10979
[32m[0906 17-51-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01845, current rewards: 105.43310, mean: 0.10983
[32m[0906 17-51-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01844, current rewards: 110.95749, mean: 0.10986
[32m[0906 17-51-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01844, current rewards: 116.24105, mean: 0.10966
[32m[0906 17-51-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01844, current rewards: 121.53084, mean: 0.10949
[32m[0906 17-51-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01843, current rewards: 126.81897, mean: 0.10933
[32m[0906 17-51-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01844, current rewards: 132.13490, mean: 0.10920
[32m[0906 17-51-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01844, current rewards: 137.42943, mean: 0.10907
[32m[0906 17-51-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01845, current rewards: 142.71625, mean: 0.10894
[32m[0906 17-51-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01845, current rewards: 148.01192, mean: 0.10883
[32m[0906 17-51-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01846, current rewards: 153.30037, mean: 0.10872
[32m[0906 17-51-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01845, current rewards: 158.59191, mean: 0.10862
[32m[0906 17-51-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01847, current rewards: 164.21648, mean: 0.10875
[32m[0906 17-51-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01847, current rewards: 169.75098, mean: 0.10881
[32m[0906 17-51-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01847, current rewards: 175.25849, mean: 0.10886
[32m[0906 17-51-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01847, current rewards: 180.78526, mean: 0.10891
[32m[0906 17-51-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01847, current rewards: 186.31282, mean: 0.10895
[32m[0906 17-51-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01847, current rewards: 191.84385, mean: 0.10900
[32m[0906 17-51-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01847, current rewards: 197.37402, mean: 0.10905
[32m[0906 17-51-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01847, current rewards: 202.90375, mean: 0.10909
[32m[0906 17-51-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01847, current rewards: 208.43483, mean: 0.10913
[32m[0906 17-51-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01847, current rewards: 213.95648, mean: 0.10916
[32m[0906 17-51-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01848, current rewards: 219.52357, mean: 0.10922
[32m[0906 17-51-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01848, current rewards: 225.06552, mean: 0.10926
[32m[0906 17-51-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01848, current rewards: 230.60447, mean: 0.10929
[32m[0906 17-51-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01848, current rewards: 236.14004, mean: 0.10932
[32m[0906 17-51-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01848, current rewards: 241.67332, mean: 0.10935
[32m[0906 17-51-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01848, current rewards: 247.21009, mean: 0.10938
[32m[0906 17-51-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: 252.74761, mean: 0.10941
[32m[0906 17-51-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01849, current rewards: 258.28609, mean: 0.10944
[32m[0906 17-51-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01849, current rewards: 263.88609, mean: 0.10950
[32m[0906 17-51-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: 269.41613, mean: 0.10952
[32m[0906 17-51-59 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 17-51-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-51-59 @MBExp.py:227][0m Rewards obtained: [273.8429911286618], Lows: [0], Highs: [1], Total time: 4718.088689999999
[32m[0906 17-55-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-55-28 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 17-55-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02284, current rewards: -3.21463, mean: -0.32146
[32m[0906 17-55-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02067, current rewards: -29.51978, mean: -0.49200
[32m[0906 17-55-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01973, current rewards: -71.72245, mean: -0.65202
[32m[0906 17-55-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01934, current rewards: -112.77887, mean: -0.70487
[32m[0906 17-55-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01916, current rewards: -156.42224, mean: -0.74487
[32m[0906 17-55-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01906, current rewards: -198.56324, mean: -0.76370
[32m[0906 17-55-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01939, current rewards: -195.58011, mean: -0.63090
[32m[0906 17-55-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01962, current rewards: -199.92025, mean: -0.55533
[32m[0906 17-55-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01981, current rewards: -194.47615, mean: -0.47433
[32m[0906 17-55-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01999, current rewards: -189.05074, mean: -0.41098
[32m[0906 17-55-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02015, current rewards: -183.60659, mean: -0.36001
[32m[0906 17-55-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02030, current rewards: -178.17188, mean: -0.31816
[32m[0906 17-55-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02041, current rewards: -172.72120, mean: -0.28315
[32m[0906 17-55-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02051, current rewards: -167.27471, mean: -0.25345
[32m[0906 17-55-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02058, current rewards: -161.84746, mean: -0.22795
[32m[0906 17-55-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02060, current rewards: -164.11887, mean: -0.21595
[32m[0906 17-55-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02048, current rewards: -214.11887, mean: -0.26434
[32m[0906 17-55-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02036, current rewards: -264.11887, mean: -0.30711
[32m[0906 17-55-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02025, current rewards: -314.11887, mean: -0.34519
[32m[0906 17-55-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02015, current rewards: -364.11887, mean: -0.37929
[32m[0906 17-55-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02007, current rewards: -414.11887, mean: -0.41002
[32m[0906 17-55-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01999, current rewards: -464.11887, mean: -0.43785
[32m[0906 17-55-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01993, current rewards: -514.11887, mean: -0.46317
[32m[0906 17-55-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01987, current rewards: -564.11887, mean: -0.48631
[32m[0906 17-55-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01982, current rewards: -587.02465, mean: -0.48514
[32m[0906 17-55-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01980, current rewards: -610.43271, mean: -0.48447
[32m[0906 17-55-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01978, current rewards: -632.63511, mean: -0.48293
[32m[0906 17-55-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01978, current rewards: -656.08217, mean: -0.48241
[32m[0906 17-55-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01978, current rewards: -649.81665, mean: -0.46086
[32m[0906 17-55-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01977, current rewards: -643.36918, mean: -0.44066
[32m[0906 17-55-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01974, current rewards: -638.14226, mean: -0.42261
[32m[0906 17-55-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01970, current rewards: -633.38617, mean: -0.40602
[32m[0906 17-56-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01983, current rewards: -616.56576, mean: -0.38296
[32m[0906 17-56-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02003, current rewards: -601.96567, mean: -0.36263
[32m[0906 17-56-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02015, current rewards: -588.56563, mean: -0.34419
[32m[0906 17-56-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02034, current rewards: -569.53957, mean: -0.32360
[32m[0906 17-56-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02046, current rewards: -561.59807, mean: -0.31028
[32m[0906 17-56-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02062, current rewards: -545.18105, mean: -0.29311
[32m[0906 17-56-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02070, current rewards: -537.48794, mean: -0.28141
[32m[0906 17-56-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02075, current rewards: -577.48967, mean: -0.29464
[32m[0906 17-56-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02069, current rewards: -677.48967, mean: -0.33706
[32m[0906 17-56-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02064, current rewards: -777.48967, mean: -0.37742
[32m[0906 17-56-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02058, current rewards: -877.48967, mean: -0.41587
[32m[0906 17-56-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02054, current rewards: -977.48967, mean: -0.45254
[32m[0906 17-56-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02049, current rewards: -1077.48967, mean: -0.48755
[32m[0906 17-56-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02045, current rewards: -1177.48967, mean: -0.52101
[32m[0906 17-56-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02041, current rewards: -1277.48967, mean: -0.55303
[32m[0906 17-56-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02037, current rewards: -1377.48967, mean: -0.58368
[32m[0906 17-56-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02033, current rewards: -1477.48967, mean: -0.61307
[32m[0906 17-56-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02029, current rewards: -1577.48967, mean: -0.64126
[32m[0906 17-56-20 @Agent.py:117][0m Average action selection time: 0.0203
[32m[0906 17-56-20 @Agent.py:118][0m Rollout length: 2500
[32m[0906 17-56-20 @MBExp.py:227][0m Rewards obtained: [-1657.4896741303107], Lows: [681], Highs: [554], Total time: 4769.565933999998
[32m[0906 17-59-52 @MBExp.py:144][0m ####################################################################
[32m[0906 17-59-52 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 17-59-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01802, current rewards: 1.13583, mean: 0.11358
[32m[0906 17-59-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01854, current rewards: 6.69702, mean: 0.11162
[32m[0906 17-59-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01846, current rewards: 12.25639, mean: 0.11142
[32m[0906 17-59-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01845, current rewards: 17.82141, mean: 0.11138
[32m[0906 17-59-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.38518, mean: 0.11136
[32m[0906 17-59-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01846, current rewards: 28.94941, mean: 0.11134
[32m[0906 17-59-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01844, current rewards: 34.46726, mean: 0.11118
[32m[0906 17-59-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01844, current rewards: 40.02839, mean: 0.11119
[32m[0906 18-00-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01843, current rewards: 45.58907, mean: 0.11119
[32m[0906 18-00-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01841, current rewards: 51.14631, mean: 0.11119
[32m[0906 18-00-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01841, current rewards: 56.70326, mean: 0.11118
[32m[0906 18-00-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01842, current rewards: 62.26589, mean: 0.11119
[32m[0906 18-00-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01844, current rewards: 67.82072, mean: 0.11118
[32m[0906 18-00-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01844, current rewards: 73.38105, mean: 0.11118
[32m[0906 18-00-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01844, current rewards: 78.91252, mean: 0.11114
[32m[0906 18-00-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01845, current rewards: 85.10651, mean: 0.11198
[32m[0906 18-00-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01845, current rewards: 90.67739, mean: 0.11195
[32m[0906 18-00-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01845, current rewards: 96.23916, mean: 0.11191
[32m[0906 18-00-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01845, current rewards: 101.80229, mean: 0.11187
[32m[0906 18-00-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01845, current rewards: 107.36772, mean: 0.11184
[32m[0906 18-00-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01846, current rewards: 112.92641, mean: 0.11181
[32m[0906 18-00-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01846, current rewards: 118.48937, mean: 0.11178
[32m[0906 18-00-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01846, current rewards: 124.12376, mean: 0.11182
[32m[0906 18-00-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01845, current rewards: 129.75417, mean: 0.11186
[32m[0906 18-00-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01846, current rewards: 135.30791, mean: 0.11182
[32m[0906 18-00-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01846, current rewards: 140.79430, mean: 0.11174
[32m[0906 18-00-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01846, current rewards: 146.23397, mean: 0.11163
[32m[0906 18-00-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01845, current rewards: 151.66928, mean: 0.11152
[32m[0906 18-00-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01846, current rewards: 157.11524, mean: 0.11143
[32m[0906 18-00-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01846, current rewards: 162.55154, mean: 0.11134
[32m[0906 18-00-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01845, current rewards: 167.98947, mean: 0.11125
[32m[0906 18-00-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01845, current rewards: 173.35978, mean: 0.11113
[32m[0906 18-00-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01844, current rewards: 178.89084, mean: 0.11111
[32m[0906 18-00-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01844, current rewards: 182.31498, mean: 0.10983
[32m[0906 18-00-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01844, current rewards: 187.93026, mean: 0.10990
[32m[0906 18-00-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01844, current rewards: 193.54254, mean: 0.10997
[32m[0906 18-00-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01845, current rewards: 199.15701, mean: 0.11003
[32m[0906 18-00-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01845, current rewards: 204.77345, mean: 0.11009
[32m[0906 18-00-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01845, current rewards: 210.39222, mean: 0.11015
[32m[0906 18-00-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01845, current rewards: 216.06174, mean: 0.11024
[32m[0906 18-00-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01844, current rewards: 222.47240, mean: 0.11068
[32m[0906 18-00-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01844, current rewards: 229.23644, mean: 0.11128
[32m[0906 18-00-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01844, current rewards: 220.36715, mean: 0.10444
[32m[0906 18-00-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01843, current rewards: 225.92845, mean: 0.10460
[32m[0906 18-00-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01843, current rewards: 231.49775, mean: 0.10475
[32m[0906 18-00-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01844, current rewards: 237.06730, mean: 0.10490
[32m[0906 18-00-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01844, current rewards: 242.63358, mean: 0.10504
[32m[0906 18-00-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01844, current rewards: 248.19987, mean: 0.10517
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01844, current rewards: 253.63511, mean: 0.10524
[32m[0906 18-00-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01844, current rewards: 259.18388, mean: 0.10536
[32m[0906 18-00-39 @Agent.py:117][0m Average action selection time: 0.0184
[32m[0906 18-00-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-00-39 @MBExp.py:227][0m Rewards obtained: [263.63400865341754], Lows: [1], Highs: [13], Total time: 4816.474701999999
[32m[0906 18-04-12 @MBExp.py:144][0m ####################################################################
[32m[0906 18-04-12 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-04-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01854, current rewards: -1.05526, mean: -0.10553
[32m[0906 18-04-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01852, current rewards: 4.71859, mean: 0.07864
[32m[0906 18-04-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01852, current rewards: 10.46094, mean: 0.09510
[32m[0906 18-04-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 16.20017, mean: 0.10125
[32m[0906 18-04-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 21.94391, mean: 0.10449
[32m[0906 18-04-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01850, current rewards: 27.68613, mean: 0.10649
[32m[0906 18-04-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01849, current rewards: 33.42487, mean: 0.10782
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 39.13642, mean: 0.10871
[32m[0906 18-04-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01844, current rewards: 39.21699, mean: 0.09565
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01845, current rewards: 44.55651, mean: 0.09686
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01844, current rewards: 49.89523, mean: 0.09783
[32m[0906 18-04-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01844, current rewards: 55.22818, mean: 0.09862
[32m[0906 18-04-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01844, current rewards: 60.56547, mean: 0.09929
[32m[0906 18-04-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01845, current rewards: 65.91145, mean: 0.09987
[32m[0906 18-04-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01845, current rewards: 71.24931, mean: 0.10035
[32m[0906 18-04-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01844, current rewards: 76.64760, mean: 0.10085
[32m[0906 18-04-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01845, current rewards: 81.86230, mean: 0.10106
[32m[0906 18-04-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01845, current rewards: 87.07038, mean: 0.10124
[32m[0906 18-04-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01847, current rewards: 90.49289, mean: 0.09944
[32m[0906 18-04-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01847, current rewards: 95.99788, mean: 0.10000
[32m[0906 18-04-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01847, current rewards: 101.50252, mean: 0.10050
[32m[0906 18-04-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01847, current rewards: 107.01162, mean: 0.10095
[32m[0906 18-04-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01848, current rewards: 112.51936, mean: 0.10137
[32m[0906 18-04-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01848, current rewards: 118.00318, mean: 0.10173
[32m[0906 18-04-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01849, current rewards: 123.35638, mean: 0.10195
[32m[0906 18-04-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01849, current rewards: 128.83634, mean: 0.10225
[32m[0906 18-04-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01848, current rewards: 134.37269, mean: 0.10257
[32m[0906 18-04-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01848, current rewards: 139.92126, mean: 0.10288
[32m[0906 18-04-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01848, current rewards: 145.47136, mean: 0.10317
[32m[0906 18-04-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01847, current rewards: 151.02220, mean: 0.10344
[32m[0906 18-04-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01847, current rewards: 156.58013, mean: 0.10370
[32m[0906 18-04-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01848, current rewards: 162.12906, mean: 0.10393
[32m[0906 18-04-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01848, current rewards: 167.66893, mean: 0.10414
[32m[0906 18-04-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01848, current rewards: 173.21549, mean: 0.10435
[32m[0906 18-04-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01848, current rewards: 178.78736, mean: 0.10455
[32m[0906 18-04-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01848, current rewards: 184.34555, mean: 0.10474
[32m[0906 18-04-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01849, current rewards: 189.89600, mean: 0.10491
[32m[0906 18-04-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01849, current rewards: 195.45192, mean: 0.10508
[32m[0906 18-04-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01849, current rewards: 200.99801, mean: 0.10523
[32m[0906 18-04-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01850, current rewards: 206.56441, mean: 0.10539
[32m[0906 18-04-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01849, current rewards: 212.20637, mean: 0.10558
[32m[0906 18-04-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01849, current rewards: 217.76202, mean: 0.10571
[32m[0906 18-04-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01849, current rewards: 223.25463, mean: 0.10581
[32m[0906 18-04-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01849, current rewards: 228.73699, mean: 0.10590
[32m[0906 18-04-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01849, current rewards: 234.21421, mean: 0.10598
[32m[0906 18-04-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01849, current rewards: 239.69299, mean: 0.10606
[32m[0906 18-04-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: 245.17578, mean: 0.10614
[32m[0906 18-04-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01850, current rewards: 250.96560, mean: 0.10634
[32m[0906 18-04-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01850, current rewards: 256.55449, mean: 0.10645
[32m[0906 18-04-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01850, current rewards: 262.09039, mean: 0.10654
[32m[0906 18-04-59 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-04-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-04-59 @MBExp.py:227][0m Rewards obtained: [266.5513290423198], Lows: [3], Highs: [3], Total time: 4863.536864999998
[32m[0906 18-08-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-08-34 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 18-08-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01836, current rewards: 1.04589, mean: 0.10459
[32m[0906 18-08-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01839, current rewards: 6.59183, mean: 0.10986
[32m[0906 18-08-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 12.13918, mean: 0.11036
[32m[0906 18-08-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 17.68581, mean: 0.11054
[32m[0906 18-08-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01849, current rewards: 23.23558, mean: 0.11065
[32m[0906 18-08-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 28.78194, mean: 0.11070
[32m[0906 18-08-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.32446, mean: 0.11072
[32m[0906 18-08-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 39.78823, mean: 0.11052
[32m[0906 18-08-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 45.28285, mean: 0.11045
[32m[0906 18-08-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 50.77802, mean: 0.11039
[32m[0906 18-08-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 56.27572, mean: 0.11034
[32m[0906 18-08-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01848, current rewards: 61.77245, mean: 0.11031
[32m[0906 18-08-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 67.27052, mean: 0.11028
[32m[0906 18-08-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 71.70051, mean: 0.10864
[32m[0906 18-08-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01847, current rewards: 77.28868, mean: 0.10886
[32m[0906 18-08-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 82.91147, mean: 0.10909
[32m[0906 18-08-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 88.49661, mean: 0.10926
[32m[0906 18-08-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 94.08298, mean: 0.10940
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01847, current rewards: 99.67095, mean: 0.10953
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01847, current rewards: 105.26001, mean: 0.10965
[32m[0906 18-08-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01847, current rewards: 110.84873, mean: 0.10975
[32m[0906 18-08-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01847, current rewards: 116.43678, mean: 0.10985
[32m[0906 18-08-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01847, current rewards: 122.01996, mean: 0.10993
[32m[0906 18-08-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01847, current rewards: 127.60839, mean: 0.11001
[32m[0906 18-08-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01847, current rewards: 133.19717, mean: 0.11008
[32m[0906 18-08-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01847, current rewards: 136.76365, mean: 0.10854
[32m[0906 18-08-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01847, current rewards: 142.25779, mean: 0.10859
[32m[0906 18-09-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01847, current rewards: 147.78223, mean: 0.10866
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01847, current rewards: 153.30951, mean: 0.10873
[32m[0906 18-09-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01848, current rewards: 158.83137, mean: 0.10879
[32m[0906 18-09-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01848, current rewards: 164.35861, mean: 0.10885
[32m[0906 18-09-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01848, current rewards: 169.88314, mean: 0.10890
[32m[0906 18-09-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01848, current rewards: 175.38943, mean: 0.10894
[32m[0906 18-09-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01847, current rewards: 180.91529, mean: 0.10899
[32m[0906 18-09-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01848, current rewards: 186.44242, mean: 0.10903
[32m[0906 18-09-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01848, current rewards: 191.97210, mean: 0.10908
[32m[0906 18-09-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01849, current rewards: 197.49396, mean: 0.10911
[32m[0906 18-09-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01849, current rewards: 203.01933, mean: 0.10915
[32m[0906 18-09-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01849, current rewards: 208.54949, mean: 0.10919
[32m[0906 18-09-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01848, current rewards: 214.07865, mean: 0.10922
[32m[0906 18-09-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01851, current rewards: 217.00708, mean: 0.10796
[32m[0906 18-09-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01857, current rewards: 221.02437, mean: 0.10729
[32m[0906 18-09-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01861, current rewards: 226.93115, mean: 0.10755
[32m[0906 18-09-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01866, current rewards: 232.85577, mean: 0.10780
[32m[0906 18-09-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01870, current rewards: 238.75868, mean: 0.10804
[32m[0906 18-09-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01876, current rewards: 242.73128, mean: 0.10740
[32m[0906 18-09-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01879, current rewards: 248.65268, mean: 0.10764
[32m[0906 18-09-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01881, current rewards: 254.57352, mean: 0.10787
[32m[0906 18-09-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01881, current rewards: 258.40815, mean: 0.10722
[32m[0906 18-09-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01881, current rewards: 264.27576, mean: 0.10743
[32m[0906 18-09-22 @Agent.py:117][0m Average action selection time: 0.0188
[32m[0906 18-09-22 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-09-22 @MBExp.py:227][0m Rewards obtained: [268.73368911543696], Lows: [5], Highs: [2], Total time: 4911.3541559999985
[32m[0906 18-13-00 @MBExp.py:144][0m ####################################################################
[32m[0906 18-13-00 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 18-13-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01820, current rewards: 1.17512, mean: 0.11751
[32m[0906 18-13-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01832, current rewards: 6.71618, mean: 0.11194
[32m[0906 18-13-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01839, current rewards: 12.26487, mean: 0.11150
[32m[0906 18-13-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 17.81230, mean: 0.11133
[32m[0906 18-13-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 23.35510, mean: 0.11121
[32m[0906 18-13-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.89870, mean: 0.11115
[32m[0906 18-13-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.41208, mean: 0.11101
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01853, current rewards: 37.90773, mean: 0.10530
[32m[0906 18-13-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 43.42863, mean: 0.10592
[32m[0906 18-13-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01848, current rewards: 48.95597, mean: 0.10643
[32m[0906 18-13-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 54.48241, mean: 0.10683
[32m[0906 18-13-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 60.00405, mean: 0.10715
[32m[0906 18-13-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01847, current rewards: 65.53040, mean: 0.10743
[32m[0906 18-13-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01846, current rewards: 71.05549, mean: 0.10766
[32m[0906 18-13-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01846, current rewards: 76.58271, mean: 0.10786
[32m[0906 18-13-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 82.11354, mean: 0.10804
[32m[0906 18-13-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 87.63995, mean: 0.10820
[32m[0906 18-13-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01847, current rewards: 93.16370, mean: 0.10833
[32m[0906 18-13-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01848, current rewards: 98.69423, mean: 0.10846
[32m[0906 18-13-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01847, current rewards: 102.13960, mean: 0.10640
[32m[0906 18-13-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01847, current rewards: 107.68977, mean: 0.10662
[32m[0906 18-13-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01847, current rewards: 113.23707, mean: 0.10683
[32m[0906 18-13-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01848, current rewards: 118.77856, mean: 0.10701
[32m[0906 18-13-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01848, current rewards: 124.32875, mean: 0.10718
[32m[0906 18-13-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01848, current rewards: 129.87449, mean: 0.10733
[32m[0906 18-13-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01847, current rewards: 135.42369, mean: 0.10748
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01846, current rewards: 140.97259, mean: 0.10761
[32m[0906 18-13-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01846, current rewards: 146.51950, mean: 0.10773
[32m[0906 18-13-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01847, current rewards: 152.06593, mean: 0.10785
[32m[0906 18-13-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01847, current rewards: 157.61592, mean: 0.10796
[32m[0906 18-13-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01848, current rewards: 163.14222, mean: 0.10804
[32m[0906 18-13-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01847, current rewards: 167.56982, mean: 0.10742
[32m[0906 18-13-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01847, current rewards: 173.07323, mean: 0.10750
[32m[0906 18-13-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01848, current rewards: 178.56817, mean: 0.10757
[32m[0906 18-13-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01848, current rewards: 184.07578, mean: 0.10765
[32m[0906 18-13-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01848, current rewards: 189.57981, mean: 0.10772
[32m[0906 18-13-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01847, current rewards: 195.00315, mean: 0.10774
[32m[0906 18-13-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01847, current rewards: 200.36272, mean: 0.10772
[32m[0906 18-13-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01847, current rewards: 205.71753, mean: 0.10771
[32m[0906 18-13-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01847, current rewards: 211.08546, mean: 0.10770
[32m[0906 18-13-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01848, current rewards: 216.44900, mean: 0.10769
[32m[0906 18-13-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01848, current rewards: 221.81940, mean: 0.10768
[32m[0906 18-13-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01848, current rewards: 227.19042, mean: 0.10767
[32m[0906 18-13-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01848, current rewards: 232.56236, mean: 0.10767
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01848, current rewards: 237.93455, mean: 0.10766
[32m[0906 18-13-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01848, current rewards: 243.30058, mean: 0.10766
[32m[0906 18-13-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01848, current rewards: 248.70592, mean: 0.10766
[32m[0906 18-13-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01848, current rewards: 254.06425, mean: 0.10765
[32m[0906 18-13-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01848, current rewards: 259.42714, mean: 0.10765
[32m[0906 18-13-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: 264.78346, mean: 0.10764
[32m[0906 18-13-46 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-13-46 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-13-47 @MBExp.py:227][0m Rewards obtained: [267.0691116575413], Lows: [3], Highs: [1], Total time: 4958.416455999998
[32m[0906 18-17-27 @MBExp.py:144][0m ####################################################################
[32m[0906 18-17-27 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 18-17-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01864, current rewards: 1.01586, mean: 0.10159
[32m[0906 18-17-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01859, current rewards: 6.45038, mean: 0.10751
[32m[0906 18-17-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01863, current rewards: 11.99148, mean: 0.10901
[32m[0906 18-17-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01858, current rewards: 17.52952, mean: 0.10956
[32m[0906 18-17-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 23.07406, mean: 0.10988
[32m[0906 18-17-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01854, current rewards: 28.75800, mean: 0.11061
[32m[0906 18-17-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 34.33327, mean: 0.11075
[32m[0906 18-17-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 39.88232, mean: 0.11078
[32m[0906 18-17-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01849, current rewards: 45.43434, mean: 0.11082
[32m[0906 18-17-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 50.93828, mean: 0.11074
[32m[0906 18-17-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.49784, mean: 0.11078
[32m[0906 18-17-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01845, current rewards: 62.05939, mean: 0.11082
[32m[0906 18-17-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01847, current rewards: 67.62448, mean: 0.11086
[32m[0906 18-17-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 73.17704, mean: 0.11087
[32m[0906 18-17-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01848, current rewards: 78.71773, mean: 0.11087
[32m[0906 18-17-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 84.27598, mean: 0.11089
[32m[0906 18-17-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01847, current rewards: 89.83040, mean: 0.11090
[32m[0906 18-17-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01848, current rewards: 95.56583, mean: 0.11112
[32m[0906 18-17-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01848, current rewards: 101.11912, mean: 0.11112
[32m[0906 18-17-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 106.67313, mean: 0.11112
[32m[0906 18-17-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 112.23084, mean: 0.11112
[32m[0906 18-17-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01849, current rewards: 117.78529, mean: 0.11112
[32m[0906 18-17-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01849, current rewards: 123.33694, mean: 0.11111
[32m[0906 18-17-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01849, current rewards: 129.25326, mean: 0.11143
[32m[0906 18-17-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01849, current rewards: 134.81641, mean: 0.11142
[32m[0906 18-17-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01849, current rewards: 140.37956, mean: 0.11141
[32m[0906 18-17-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01849, current rewards: 145.94271, mean: 0.11141
[32m[0906 18-17-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01849, current rewards: 151.50586, mean: 0.11140
[32m[0906 18-17-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01850, current rewards: 125.95365, mean: 0.08933
[32m[0906 18-17-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01850, current rewards: 75.95365, mean: 0.05202
[32m[0906 18-17-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01849, current rewards: 25.95365, mean: 0.01719
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01850, current rewards: -24.04635, mean: -0.01541
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01849, current rewards: -74.04635, mean: -0.04599
[32m[0906 18-17-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01850, current rewards: -124.04635, mean: -0.07473
[32m[0906 18-17-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01850, current rewards: -174.04635, mean: -0.10178
[32m[0906 18-18-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01850, current rewards: -224.04635, mean: -0.12730
[32m[0906 18-18-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01851, current rewards: -274.04635, mean: -0.15141
[32m[0906 18-18-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: -324.04635, mean: -0.17422
[32m[0906 18-18-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01850, current rewards: -374.04635, mean: -0.19584
[32m[0906 18-18-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01850, current rewards: -424.04635, mean: -0.21635
[32m[0906 18-18-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01850, current rewards: -474.04635, mean: -0.23584
[32m[0906 18-18-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01849, current rewards: -524.04635, mean: -0.25439
[32m[0906 18-18-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01850, current rewards: -574.04635, mean: -0.27206
[32m[0906 18-18-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01850, current rewards: -624.04635, mean: -0.28891
[32m[0906 18-18-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01850, current rewards: -674.04635, mean: -0.30500
[32m[0906 18-18-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01849, current rewards: -724.04635, mean: -0.32037
[32m[0906 18-18-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01849, current rewards: -774.04635, mean: -0.33509
[32m[0906 18-18-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01849, current rewards: -824.04635, mean: -0.34917
[32m[0906 18-18-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01849, current rewards: -874.04635, mean: -0.36267
[32m[0906 18-18-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01849, current rewards: -924.04635, mean: -0.37563
[32m[0906 18-18-14 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-18-14 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-18-14 @MBExp.py:227][0m Rewards obtained: [-964.0463518226368], Lows: [0], Highs: [1118], Total time: 5005.462726999998
[32m[0906 18-21-56 @MBExp.py:144][0m ####################################################################
[32m[0906 18-21-56 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 18-21-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01880, current rewards: 1.03131, mean: 0.10313
[32m[0906 18-21-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01840, current rewards: 6.56821, mean: 0.10947
[32m[0906 18-21-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01841, current rewards: 12.10594, mean: 0.11005
[32m[0906 18-21-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 17.64234, mean: 0.11026
[32m[0906 18-22-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01854, current rewards: 23.19107, mean: 0.11043
[32m[0906 18-22-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 28.79086, mean: 0.11073
[32m[0906 18-22-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01857, current rewards: 34.31347, mean: 0.11069
[32m[0906 18-22-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01853, current rewards: 39.83759, mean: 0.11066
[32m[0906 18-22-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 45.35928, mean: 0.11063
[32m[0906 18-22-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01846, current rewards: 50.88319, mean: 0.11062
[32m[0906 18-22-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01846, current rewards: 56.40475, mean: 0.11060
[32m[0906 18-22-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01847, current rewards: 61.93098, mean: 0.11059
[32m[0906 18-22-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01848, current rewards: 67.46512, mean: 0.11060
[32m[0906 18-22-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01849, current rewards: 72.98702, mean: 0.11059
[32m[0906 18-22-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01849, current rewards: 78.55746, mean: 0.11064
[32m[0906 18-22-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 84.12355, mean: 0.11069
[32m[0906 18-22-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 89.69694, mean: 0.11074
[32m[0906 18-22-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01851, current rewards: 95.26140, mean: 0.11077
[32m[0906 18-22-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01851, current rewards: 100.82822, mean: 0.11080
[32m[0906 18-22-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01851, current rewards: 106.39767, mean: 0.11083
[32m[0906 18-22-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01852, current rewards: 111.96065, mean: 0.11085
[32m[0906 18-22-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 117.52701, mean: 0.11087
[32m[0906 18-22-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 123.09625, mean: 0.11090
[32m[0906 18-22-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 128.67024, mean: 0.11092
[32m[0906 18-22-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 134.24071, mean: 0.11094
[32m[0906 18-22-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 137.81758, mean: 0.10938
[32m[0906 18-22-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01852, current rewards: 143.57202, mean: 0.10960
[32m[0906 18-22-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01852, current rewards: 149.32097, mean: 0.10979
[32m[0906 18-22-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: 155.06803, mean: 0.10998
[32m[0906 18-22-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01852, current rewards: 160.80733, mean: 0.11014
[32m[0906 18-22-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01852, current rewards: 168.60237, mean: 0.11166
[32m[0906 18-22-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01851, current rewards: 176.46192, mean: 0.11312
[32m[0906 18-22-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01852, current rewards: 184.32146, mean: 0.11449
[32m[0906 18-22-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: 192.18100, mean: 0.11577
[32m[0906 18-22-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01851, current rewards: 196.56897, mean: 0.11495
[32m[0906 18-22-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01852, current rewards: 146.56897, mean: 0.08328
[32m[0906 18-22-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01852, current rewards: 96.56897, mean: 0.05335
[32m[0906 18-22-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01852, current rewards: 46.56897, mean: 0.02504
[32m[0906 18-22-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01853, current rewards: 13.33983, mean: 0.00698
[32m[0906 18-22-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01853, current rewards: 18.90953, mean: 0.00965
[32m[0906 18-22-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01852, current rewards: 24.47585, mean: 0.01218
[32m[0906 18-22-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01853, current rewards: 30.05524, mean: 0.01459
[32m[0906 18-22-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01853, current rewards: 35.62842, mean: 0.01689
[32m[0906 18-22-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01853, current rewards: 41.20482, mean: 0.01908
[32m[0906 18-22-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01853, current rewards: 46.78006, mean: 0.02117
[32m[0906 18-22-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01853, current rewards: 52.35347, mean: 0.02317
[32m[0906 18-22-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01853, current rewards: 57.97737, mean: 0.02510
[32m[0906 18-22-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01853, current rewards: 64.18417, mean: 0.02720
[32m[0906 18-22-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01854, current rewards: 69.39126, mean: 0.02879
[32m[0906 18-22-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01853, current rewards: 74.62069, mean: 0.03033
[32m[0906 18-22-43 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-22-43 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-22-43 @MBExp.py:227][0m Rewards obtained: [78.78299352011045], Lows: [2], Highs: [186], Total time: 5052.630543999998
[32m[0906 18-26-28 @MBExp.py:144][0m ####################################################################
[32m[0906 18-26-28 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 18-26-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01831, current rewards: 1.09531, mean: 0.10953
[32m[0906 18-26-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01853, current rewards: 6.63139, mean: 0.11052
[32m[0906 18-26-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 12.09627, mean: 0.10997
[32m[0906 18-26-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01854, current rewards: 17.56410, mean: 0.10978
[32m[0906 18-26-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 23.03315, mean: 0.10968
[32m[0906 18-26-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 28.48197, mean: 0.10955
[32m[0906 18-26-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01851, current rewards: 33.83687, mean: 0.10915
[32m[0906 18-26-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 39.24509, mean: 0.10901
[32m[0906 18-26-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 44.64743, mean: 0.10890
[32m[0906 18-26-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01851, current rewards: 50.05151, mean: 0.10881
[32m[0906 18-26-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 53.47617, mean: 0.10486
[32m[0906 18-26-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 59.31000, mean: 0.10591
[32m[0906 18-26-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 65.14953, mean: 0.10680
[32m[0906 18-26-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 70.99392, mean: 0.10757
[32m[0906 18-26-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 76.68491, mean: 0.10801
[32m[0906 18-26-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 82.16177, mean: 0.10811
[32m[0906 18-26-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 87.66403, mean: 0.10823
[32m[0906 18-26-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 93.12780, mean: 0.10829
[32m[0906 18-26-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 98.60431, mean: 0.10836
[32m[0906 18-26-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 104.09182, mean: 0.10843
[32m[0906 18-26-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 109.57233, mean: 0.10849
[32m[0906 18-26-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 115.06919, mean: 0.10856
[32m[0906 18-26-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 120.60793, mean: 0.10866
[32m[0906 18-26-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 121.79298, mean: 0.10499
[32m[0906 18-26-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 127.44548, mean: 0.10533
[32m[0906 18-26-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 133.09180, mean: 0.10563
[32m[0906 18-26-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 138.74242, mean: 0.10591
[32m[0906 18-26-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01854, current rewards: 144.39440, mean: 0.10617
[32m[0906 18-26-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: 150.04724, mean: 0.10642
[32m[0906 18-26-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 155.69939, mean: 0.10664
[32m[0906 18-26-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: 161.27901, mean: 0.10681
[32m[0906 18-26-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: 166.84513, mean: 0.10695
[32m[0906 18-26-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01854, current rewards: 172.41899, mean: 0.10709
[32m[0906 18-26-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01855, current rewards: 177.98726, mean: 0.10722
[32m[0906 18-27-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: 183.56079, mean: 0.10735
[32m[0906 18-27-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 187.15431, mean: 0.10634
[32m[0906 18-27-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01853, current rewards: 192.46688, mean: 0.10634
[32m[0906 18-27-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01853, current rewards: 197.76604, mean: 0.10633
[32m[0906 18-27-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01854, current rewards: 203.07695, mean: 0.10632
[32m[0906 18-27-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01854, current rewards: 208.58968, mean: 0.10642
[32m[0906 18-27-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01854, current rewards: 214.13666, mean: 0.10654
[32m[0906 18-27-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01853, current rewards: 219.68436, mean: 0.10664
[32m[0906 18-27-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01853, current rewards: 225.22873, mean: 0.10674
[32m[0906 18-27-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01853, current rewards: 230.77173, mean: 0.10684
[32m[0906 18-27-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01854, current rewards: 236.31775, mean: 0.10693
[32m[0906 18-27-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01853, current rewards: 241.86340, mean: 0.10702
[32m[0906 18-27-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01853, current rewards: 247.40845, mean: 0.10710
[32m[0906 18-27-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01853, current rewards: 252.96117, mean: 0.10719
[32m[0906 18-27-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01853, current rewards: 258.51339, mean: 0.10727
[32m[0906 18-27-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01853, current rewards: 264.11207, mean: 0.10736
[32m[0906 18-27-15 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-27-15 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-27-15 @MBExp.py:227][0m Rewards obtained: [268.58475752113713], Lows: [2], Highs: [4], Total time: 5099.791931999998
[32m[0906 18-31-01 @MBExp.py:144][0m ####################################################################
[32m[0906 18-31-01 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 18-31-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01819, current rewards: 1.03620, mean: 0.10362
[32m[0906 18-31-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01859, current rewards: 6.58343, mean: 0.10972
[32m[0906 18-31-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01857, current rewards: 12.13495, mean: 0.11032
[32m[0906 18-31-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01849, current rewards: 17.68267, mean: 0.11052
[32m[0906 18-31-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01850, current rewards: 23.22574, mean: 0.11060
[32m[0906 18-31-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01849, current rewards: 28.77434, mean: 0.11067
[32m[0906 18-31-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 34.32172, mean: 0.11072
[32m[0906 18-31-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01844, current rewards: 39.86511, mean: 0.11074
[32m[0906 18-31-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01846, current rewards: 45.41038, mean: 0.11076
[32m[0906 18-31-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01847, current rewards: 50.95536, mean: 0.11077
[32m[0906 18-31-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01845, current rewards: 56.50432, mean: 0.11079
[32m[0906 18-31-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01845, current rewards: 59.98754, mean: 0.10712
[32m[0906 18-31-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01846, current rewards: 65.53118, mean: 0.10743
[32m[0906 18-31-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01847, current rewards: 71.10115, mean: 0.10773
[32m[0906 18-31-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01847, current rewards: 76.64271, mean: 0.10795
[32m[0906 18-31-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01848, current rewards: 82.18393, mean: 0.10814
[32m[0906 18-31-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 87.72371, mean: 0.10830
[32m[0906 18-31-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01849, current rewards: 93.27032, mean: 0.10845
[32m[0906 18-31-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01849, current rewards: 98.81060, mean: 0.10858
[32m[0906 18-31-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 104.35089, mean: 0.10870
[32m[0906 18-31-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 109.89451, mean: 0.10881
[32m[0906 18-31-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 114.92422, mean: 0.10842
[32m[0906 18-31-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 120.45619, mean: 0.10852
[32m[0906 18-31-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01852, current rewards: 125.99253, mean: 0.10861
[32m[0906 18-31-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 131.52558, mean: 0.10870
[32m[0906 18-31-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 137.05854, mean: 0.10878
[32m[0906 18-31-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01851, current rewards: 142.58921, mean: 0.10885
[32m[0906 18-31-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01851, current rewards: 148.12723, mean: 0.10892
[32m[0906 18-31-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01850, current rewards: 153.66349, mean: 0.10898
[32m[0906 18-31-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01851, current rewards: 159.23228, mean: 0.10906
[32m[0906 18-31-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01851, current rewards: 164.72852, mean: 0.10909
[32m[0906 18-31-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01851, current rewards: 170.22130, mean: 0.10912
[32m[0906 18-31-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01851, current rewards: 173.77423, mean: 0.10793
[32m[0906 18-31-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: 179.31398, mean: 0.10802
[32m[0906 18-31-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01851, current rewards: 184.85145, mean: 0.10810
[32m[0906 18-31-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01850, current rewards: 190.38811, mean: 0.10818
[32m[0906 18-31-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01851, current rewards: 196.16908, mean: 0.10838
[32m[0906 18-31-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01851, current rewards: 201.68531, mean: 0.10843
[32m[0906 18-31-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01851, current rewards: 207.26474, mean: 0.10852
[32m[0906 18-31-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01851, current rewards: 212.88724, mean: 0.10862
[32m[0906 18-31-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01851, current rewards: 218.51211, mean: 0.10871
[32m[0906 18-31-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01851, current rewards: 224.12922, mean: 0.10880
[32m[0906 18-31-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01851, current rewards: 229.74774, mean: 0.10889
[32m[0906 18-31-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01851, current rewards: 235.36729, mean: 0.10897
[32m[0906 18-31-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01852, current rewards: 238.88835, mean: 0.10809
[32m[0906 18-31-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01852, current rewards: 244.41012, mean: 0.10815
[32m[0906 18-31-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01852, current rewards: 249.95053, mean: 0.10820
[32m[0906 18-31-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01852, current rewards: 255.47196, mean: 0.10825
[32m[0906 18-31-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01852, current rewards: 260.99210, mean: 0.10830
[32m[0906 18-31-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01852, current rewards: 266.50801, mean: 0.10834
[32m[0906 18-31-48 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-31-48 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-31-48 @MBExp.py:227][0m Rewards obtained: [270.92838621674485], Lows: [3], Highs: [1], Total time: 5146.924130999998
[32m[0906 18-35-37 @MBExp.py:144][0m ####################################################################
[32m[0906 18-35-37 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 18-35-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01822, current rewards: 1.10259, mean: 0.11026
[32m[0906 18-35-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01843, current rewards: 6.60698, mean: 0.11012
[32m[0906 18-35-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01849, current rewards: 12.09856, mean: 0.10999
[32m[0906 18-35-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 17.61055, mean: 0.11007
[32m[0906 18-35-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01846, current rewards: 23.03862, mean: 0.10971
[32m[0906 18-35-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.51178, mean: 0.10966
[32m[0906 18-35-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 33.98234, mean: 0.10962
[32m[0906 18-35-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01847, current rewards: 39.45005, mean: 0.10958
[32m[0906 18-35-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01847, current rewards: 44.90783, mean: 0.10953
[32m[0906 18-35-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01843, current rewards: 50.37409, mean: 0.10951
[32m[0906 18-35-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01845, current rewards: 55.85543, mean: 0.10952
[32m[0906 18-35-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01844, current rewards: 61.32166, mean: 0.10950
[32m[0906 18-35-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01845, current rewards: 66.76781, mean: 0.10946
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01846, current rewards: 68.02543, mean: 0.10307
[32m[0906 18-35-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01846, current rewards: 73.54175, mean: 0.10358
[32m[0906 18-35-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01847, current rewards: 79.05649, mean: 0.10402
[32m[0906 18-35-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01848, current rewards: 84.56905, mean: 0.10441
[32m[0906 18-35-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01848, current rewards: 90.08328, mean: 0.10475
[32m[0906 18-35-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01848, current rewards: 95.59677, mean: 0.10505
[32m[0906 18-35-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01849, current rewards: 101.11054, mean: 0.10532
[32m[0906 18-35-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01849, current rewards: 106.64203, mean: 0.10559
[32m[0906 18-35-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01850, current rewards: 111.22626, mean: 0.10493
[32m[0906 18-35-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01850, current rewards: 116.90761, mean: 0.10532
[32m[0906 18-35-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01851, current rewards: 122.58834, mean: 0.10568
[32m[0906 18-36-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 128.26227, mean: 0.10600
[32m[0906 18-36-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01853, current rewards: 133.93894, mean: 0.10630
[32m[0906 18-36-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 139.62305, mean: 0.10658
[32m[0906 18-36-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: 145.30471, mean: 0.10684
[32m[0906 18-36-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01852, current rewards: 150.99590, mean: 0.10709
[32m[0906 18-36-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 156.68039, mean: 0.10732
[32m[0906 18-36-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: 162.37175, mean: 0.10753
[32m[0906 18-36-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01853, current rewards: 168.06012, mean: 0.10773
[32m[0906 18-36-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01857, current rewards: 173.74940, mean: 0.10792
[32m[0906 18-36-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01865, current rewards: 179.13661, mean: 0.10791
[32m[0906 18-36-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01874, current rewards: 184.52009, mean: 0.10791
[32m[0906 18-36-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01883, current rewards: 189.90682, mean: 0.10790
[32m[0906 18-36-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01890, current rewards: 195.25908, mean: 0.10788
[32m[0906 18-36-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01900, current rewards: 200.65154, mean: 0.10788
[32m[0906 18-36-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01906, current rewards: 206.04272, mean: 0.10788
[32m[0906 18-36-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01914, current rewards: 211.42947, mean: 0.10787
[32m[0906 18-36-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01920, current rewards: 216.82792, mean: 0.10787
[32m[0906 18-36-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01921, current rewards: 218.09506, mean: 0.10587
[32m[0906 18-36-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01919, current rewards: 223.67229, mean: 0.10601
[32m[0906 18-36-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01917, current rewards: 229.25581, mean: 0.10614
[32m[0906 18-36-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01916, current rewards: 234.85706, mean: 0.10627
[32m[0906 18-36-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01915, current rewards: 240.43165, mean: 0.10639
[32m[0906 18-36-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01914, current rewards: 246.01568, mean: 0.10650
[32m[0906 18-36-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: 251.59530, mean: 0.10661
[32m[0906 18-36-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01912, current rewards: 257.16812, mean: 0.10671
[32m[0906 18-36-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01910, current rewards: 262.74559, mean: 0.10681
[32m[0906 18-36-25 @Agent.py:117][0m Average action selection time: 0.0191
[32m[0906 18-36-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-36-25 @MBExp.py:227][0m Rewards obtained: [267.2110005071999], Lows: [4], Highs: [1], Total time: 5195.492415999998
[32m[0906 18-40-15 @MBExp.py:144][0m ####################################################################
[32m[0906 18-40-15 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 18-40-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02136, current rewards: 1.16903, mean: 0.11690
[32m[0906 18-40-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02320, current rewards: 7.96492, mean: 0.13275
[32m[0906 18-40-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02346, current rewards: 14.24966, mean: 0.12954
[32m[0906 18-40-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02354, current rewards: 21.07943, mean: 0.13175
[32m[0906 18-40-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02363, current rewards: 27.35928, mean: 0.13028
[32m[0906 18-40-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02356, current rewards: 33.98667, mean: 0.13072
[32m[0906 18-40-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02354, current rewards: 40.32440, mean: 0.13008
[32m[0906 18-40-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02351, current rewards: 46.99837, mean: 0.13055
[32m[0906 18-40-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02354, current rewards: 53.37126, mean: 0.13017
[32m[0906 18-40-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02352, current rewards: 59.96385, mean: 0.13036
[32m[0906 18-40-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02351, current rewards: 66.22104, mean: 0.12985
[32m[0906 18-40-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02353, current rewards: 72.97388, mean: 0.13031
[32m[0906 18-40-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02353, current rewards: 79.51368, mean: 0.13035
[32m[0906 18-40-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02352, current rewards: 86.34693, mean: 0.13083
[32m[0906 18-40-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02354, current rewards: 92.96235, mean: 0.13093
[32m[0906 18-40-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02337, current rewards: 98.02883, mean: 0.12899
[32m[0906 18-40-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02307, current rewards: 103.87075, mean: 0.12824
[32m[0906 18-40-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02280, current rewards: 109.70929, mean: 0.12757
[32m[0906 18-40-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02256, current rewards: 115.55947, mean: 0.12699
[32m[0906 18-40-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02235, current rewards: 121.44513, mean: 0.12651
[32m[0906 18-40-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02216, current rewards: 127.27514, mean: 0.12601
[32m[0906 18-40-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02200, current rewards: 133.12420, mean: 0.12559
[32m[0906 18-40-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02184, current rewards: 138.95643, mean: 0.12519
[32m[0906 18-40-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02170, current rewards: 144.79159, mean: 0.12482
[32m[0906 18-40-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02158, current rewards: 150.63264, mean: 0.12449
[32m[0906 18-40-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02146, current rewards: 156.58118, mean: 0.12427
[32m[0906 18-40-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02135, current rewards: 162.19850, mean: 0.12382
[32m[0906 18-40-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02124, current rewards: 167.82754, mean: 0.12340
[32m[0906 18-40-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02114, current rewards: 173.47213, mean: 0.12303
[32m[0906 18-40-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02105, current rewards: 179.08751, mean: 0.12266
[32m[0906 18-40-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02097, current rewards: 184.71351, mean: 0.12233
[32m[0906 18-40-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02089, current rewards: 190.34640, mean: 0.12202
[32m[0906 18-40-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02082, current rewards: 195.97117, mean: 0.12172
[32m[0906 18-40-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02076, current rewards: 201.60298, mean: 0.12145
[32m[0906 18-40-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02069, current rewards: 207.23095, mean: 0.12119
[32m[0906 18-40-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02063, current rewards: 212.86107, mean: 0.12094
[32m[0906 18-40-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02058, current rewards: 218.59528, mean: 0.12077
[32m[0906 18-40-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02052, current rewards: 224.14364, mean: 0.12051
[32m[0906 18-40-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02046, current rewards: 229.69022, mean: 0.12026
[32m[0906 18-40-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02041, current rewards: 235.24618, mean: 0.12002
[32m[0906 18-40-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02036, current rewards: 240.79841, mean: 0.11980
[32m[0906 18-40-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02032, current rewards: 246.34742, mean: 0.11959
[32m[0906 18-40-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02028, current rewards: 251.89974, mean: 0.11938
[32m[0906 18-40-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02024, current rewards: 257.45500, mean: 0.11919
[32m[0906 18-41-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02020, current rewards: 263.00768, mean: 0.11901
[32m[0906 18-41-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02016, current rewards: 268.56038, mean: 0.11883
[32m[0906 18-41-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02013, current rewards: 274.10624, mean: 0.11866
[32m[0906 18-41-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02009, current rewards: 279.66417, mean: 0.11850
[32m[0906 18-41-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02006, current rewards: 285.21318, mean: 0.11835
[32m[0906 18-41-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02003, current rewards: 290.76205, mean: 0.11820
[32m[0906 18-41-05 @Agent.py:117][0m Average action selection time: 0.0200
[32m[0906 18-41-05 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-41-06 @MBExp.py:227][0m Rewards obtained: [293.0442646336517], Lows: [1], Highs: [1], Total time: 5246.344240999998
[32m[0906 18-44-58 @MBExp.py:144][0m ####################################################################
[32m[0906 18-44-58 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 18-44-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02104, current rewards: 1.12282, mean: 0.11228
[32m[0906 18-44-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01954, current rewards: 7.83913, mean: 0.13065
[32m[0906 18-45-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01900, current rewards: 14.62995, mean: 0.13300
[32m[0906 18-45-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01884, current rewards: 20.80532, mean: 0.13003
[32m[0906 18-45-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01875, current rewards: 27.04251, mean: 0.12877
[32m[0906 18-45-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01875, current rewards: 33.22659, mean: 0.12779
[32m[0906 18-45-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01870, current rewards: 39.42875, mean: 0.12719
[32m[0906 18-45-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01869, current rewards: 42.16976, mean: 0.11714
[32m[0906 18-45-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01869, current rewards: 47.42125, mean: 0.11566
[32m[0906 18-45-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01876, current rewards: 50.81901, mean: 0.11048
[32m[0906 18-45-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01885, current rewards: 56.78128, mean: 0.11134
[32m[0906 18-45-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01882, current rewards: 61.94901, mean: 0.11062
[32m[0906 18-45-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01879, current rewards: 67.13911, mean: 0.11006
[32m[0906 18-45-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01876, current rewards: 72.32444, mean: 0.10958
[32m[0906 18-45-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01874, current rewards: 77.52945, mean: 0.10920
[32m[0906 18-45-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01871, current rewards: 82.71346, mean: 0.10883
[32m[0906 18-45-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01870, current rewards: 87.89930, mean: 0.10852
[32m[0906 18-45-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01869, current rewards: 93.09091, mean: 0.10825
[32m[0906 18-45-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01867, current rewards: 98.28636, mean: 0.10801
[32m[0906 18-45-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01868, current rewards: 103.52001, mean: 0.10783
[32m[0906 18-45-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01869, current rewards: 108.99482, mean: 0.10792
[32m[0906 18-45-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01884, current rewards: 115.91335, mean: 0.10935
[32m[0906 18-45-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01897, current rewards: 122.73737, mean: 0.11057
[32m[0906 18-45-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01909, current rewards: 129.69253, mean: 0.11180
[32m[0906 18-45-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01920, current rewards: 136.61491, mean: 0.11290
[32m[0906 18-45-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01928, current rewards: 143.55793, mean: 0.11393
[32m[0906 18-45-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01936, current rewards: 150.39080, mean: 0.11480
[32m[0906 18-45-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01948, current rewards: 159.87676, mean: 0.11756
[32m[0906 18-45-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01959, current rewards: 169.08165, mean: 0.11992
[32m[0906 18-45-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01969, current rewards: 178.25763, mean: 0.12209
[32m[0906 18-45-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01978, current rewards: 187.11529, mean: 0.12392
[32m[0906 18-45-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01988, current rewards: 196.28563, mean: 0.12582
[32m[0906 18-45-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01995, current rewards: 203.06510, mean: 0.12613
[32m[0906 18-45-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01995, current rewards: 208.96263, mean: 0.12588
[32m[0906 18-45-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01996, current rewards: 214.99491, mean: 0.12573
[32m[0906 18-45-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01994, current rewards: 220.78613, mean: 0.12545
[32m[0906 18-45-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01990, current rewards: 226.23938, mean: 0.12499
[32m[0906 18-45-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01986, current rewards: 231.69263, mean: 0.12457
[32m[0906 18-45-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01983, current rewards: 237.14588, mean: 0.12416
[32m[0906 18-45-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01979, current rewards: 242.59913, mean: 0.12378
[32m[0906 18-45-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01976, current rewards: 248.05238, mean: 0.12341
[32m[0906 18-45-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01973, current rewards: 253.50563, mean: 0.12306
[32m[0906 18-45-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01970, current rewards: 220.14160, mean: 0.10433
[32m[0906 18-45-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01967, current rewards: 170.14160, mean: 0.07877
[32m[0906 18-45-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01965, current rewards: 120.14160, mean: 0.05436
[32m[0906 18-45-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01962, current rewards: 70.14160, mean: 0.03104
[32m[0906 18-45-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01960, current rewards: 20.14160, mean: 0.00872
[32m[0906 18-45-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01957, current rewards: -29.85840, mean: -0.01265
[32m[0906 18-45-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01955, current rewards: -79.85840, mean: -0.03314
[32m[0906 18-45-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01953, current rewards: -129.85840, mean: -0.05279
[32m[0906 18-45-47 @Agent.py:117][0m Average action selection time: 0.0195
[32m[0906 18-45-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-45-47 @MBExp.py:227][0m Rewards obtained: [-169.85840020076424], Lows: [3], Highs: [426], Total time: 5295.960749999998
[32m[0906 18-49-41 @MBExp.py:144][0m ####################################################################
[32m[0906 18-49-41 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 18-49-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01850, current rewards: 1.16225, mean: 0.11622
[32m[0906 18-49-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01855, current rewards: 8.71093, mean: 0.14518
[32m[0906 18-49-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01859, current rewards: 16.57048, mean: 0.15064
[32m[0906 18-49-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01857, current rewards: 24.43004, mean: 0.15269
[32m[0906 18-49-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01857, current rewards: 32.28959, mean: 0.15376
[32m[0906 18-49-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01855, current rewards: 40.14914, mean: 0.15442
[32m[0906 18-49-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 48.00869, mean: 0.15487
[32m[0906 18-49-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01855, current rewards: 39.50023, mean: 0.10972
[32m[0906 18-49-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01855, current rewards: 45.79312, mean: 0.11169
[32m[0906 18-49-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01854, current rewards: 52.07020, mean: 0.11320
[32m[0906 18-49-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01854, current rewards: 58.45200, mean: 0.11461
[32m[0906 18-49-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01854, current rewards: 57.74555, mean: 0.10312
[32m[0906 18-49-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01855, current rewards: 52.82370, mean: 0.08660
[32m[0906 18-49-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 50.46574, mean: 0.07646
[32m[0906 18-49-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01853, current rewards: 45.68091, mean: 0.06434
[32m[0906 18-49-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01854, current rewards: 44.63524, mean: 0.05873
[32m[0906 18-49-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01854, current rewards: 42.64488, mean: 0.05265
[32m[0906 18-49-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01854, current rewards: 40.65274, mean: 0.04727
[32m[0906 18-49-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 40.22490, mean: 0.04420
[32m[0906 18-49-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 34.30687, mean: 0.03574
[32m[0906 18-50-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01854, current rewards: 30.03634, mean: 0.02974
[32m[0906 18-50-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01854, current rewards: 25.36554, mean: 0.02393
[32m[0906 18-50-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01854, current rewards: 22.25154, mean: 0.02005
[32m[0906 18-50-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 15.67981, mean: 0.01352
[32m[0906 18-50-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01854, current rewards: 9.90207, mean: 0.00818
[32m[0906 18-50-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01854, current rewards: 5.33567, mean: 0.00423
[32m[0906 18-50-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 11.26890, mean: 0.00860
[32m[0906 18-50-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01855, current rewards: 17.25555, mean: 0.01269
[32m[0906 18-50-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 23.14507, mean: 0.01641
[32m[0906 18-50-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 29.03595, mean: 0.01989
[32m[0906 18-50-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 34.92647, mean: 0.02313
[32m[0906 18-50-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 40.81594, mean: 0.02616
[32m[0906 18-50-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 46.70764, mean: 0.02901
[32m[0906 18-50-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01855, current rewards: 52.59351, mean: 0.03168
[32m[0906 18-50-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: 58.74508, mean: 0.03435
[32m[0906 18-50-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 65.35952, mean: 0.03714
[32m[0906 18-50-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 72.46450, mean: 0.04004
[32m[0906 18-50-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: 79.59690, mean: 0.04279
[32m[0906 18-50-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: 86.72396, mean: 0.04541
[32m[0906 18-50-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: 93.86426, mean: 0.04789
[32m[0906 18-50-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01855, current rewards: 101.00764, mean: 0.05025
[32m[0906 18-50-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01855, current rewards: 108.14709, mean: 0.05250
[32m[0906 18-50-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01855, current rewards: 115.28127, mean: 0.05464
[32m[0906 18-50-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01855, current rewards: 122.42094, mean: 0.05668
[32m[0906 18-50-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01855, current rewards: 129.48750, mean: 0.05859
[32m[0906 18-50-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01855, current rewards: 136.50870, mean: 0.06040
[32m[0906 18-50-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01855, current rewards: 143.52209, mean: 0.06213
[32m[0906 18-50-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01855, current rewards: 150.55579, mean: 0.06379
[32m[0906 18-50-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01855, current rewards: 157.57500, mean: 0.06538
[32m[0906 18-50-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01855, current rewards: 164.60345, mean: 0.06691
[32m[0906 18-50-28 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 18-50-28 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-50-28 @MBExp.py:227][0m Rewards obtained: [170.2344668658826], Lows: [45], Highs: [88], Total time: 5343.166320999999
[32m[0906 18-54-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-54-24 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 18-54-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01820, current rewards: 0.15465, mean: 0.01547
[32m[0906 18-54-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01855, current rewards: 5.88870, mean: 0.09815
[32m[0906 18-54-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01847, current rewards: 11.55625, mean: 0.10506
[32m[0906 18-54-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01845, current rewards: 17.36868, mean: 0.10855
[32m[0906 18-54-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01842, current rewards: 23.17731, mean: 0.11037
[32m[0906 18-54-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01844, current rewards: 28.98836, mean: 0.11149
[32m[0906 18-54-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 34.79534, mean: 0.11224
[32m[0906 18-54-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 40.58723, mean: 0.11274
[32m[0906 18-54-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01851, current rewards: 46.56982, mean: 0.11358
[32m[0906 18-54-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 52.55572, mean: 0.11425
[32m[0906 18-54-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 58.56064, mean: 0.11482
[32m[0906 18-54-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01853, current rewards: 64.54994, mean: 0.11527
[32m[0906 18-54-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 70.53104, mean: 0.11562
[32m[0906 18-54-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01853, current rewards: 76.51894, mean: 0.11594
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 82.50765, mean: 0.11621
[32m[0906 18-54-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 88.49654, mean: 0.11644
[32m[0906 18-54-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 94.48993, mean: 0.11665
[32m[0906 18-54-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01856, current rewards: 100.47185, mean: 0.11683
[32m[0906 18-54-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01857, current rewards: 106.44891, mean: 0.11698
[32m[0906 18-54-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 110.14398, mean: 0.11473
[32m[0906 18-54-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01857, current rewards: 115.94896, mean: 0.11480
[32m[0906 18-54-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 121.75237, mean: 0.11486
[32m[0906 18-54-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01857, current rewards: 127.54846, mean: 0.11491
[32m[0906 18-54-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 133.34867, mean: 0.11496
[32m[0906 18-54-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 139.15545, mean: 0.11500
[32m[0906 18-54-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 144.95387, mean: 0.11504
[32m[0906 18-54-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 150.78312, mean: 0.11510
[32m[0906 18-54-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01855, current rewards: 156.72363, mean: 0.11524
[32m[0906 18-54-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01855, current rewards: 162.58701, mean: 0.11531
[32m[0906 18-54-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01854, current rewards: 168.44873, mean: 0.11538
[32m[0906 18-54-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 173.96848, mean: 0.11521
[32m[0906 18-54-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 179.54169, mean: 0.11509
[32m[0906 18-54-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 185.11702, mean: 0.11498
[32m[0906 18-54-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01855, current rewards: 190.69148, mean: 0.11487
[32m[0906 18-54-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01854, current rewards: 196.26976, mean: 0.11478
[32m[0906 18-54-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01854, current rewards: 201.79832, mean: 0.11466
[32m[0906 18-54-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 207.38876, mean: 0.11458
[32m[0906 18-54-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01855, current rewards: 212.97807, mean: 0.11450
[32m[0906 18-55-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: 218.57672, mean: 0.11444
[32m[0906 18-55-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01861, current rewards: 225.60116, mean: 0.11510
[32m[0906 18-55-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01869, current rewards: 234.06148, mean: 0.11645
[32m[0906 18-55-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01876, current rewards: 242.47917, mean: 0.11771
[32m[0906 18-55-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01885, current rewards: 250.92571, mean: 0.11892
[32m[0906 18-55-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01892, current rewards: 258.60891, mean: 0.11973
[32m[0906 18-55-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01899, current rewards: 265.48215, mean: 0.12013
[32m[0906 18-55-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01904, current rewards: 272.40145, mean: 0.12053
[32m[0906 18-55-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01909, current rewards: 279.33791, mean: 0.12093
[32m[0906 18-55-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01913, current rewards: 286.26953, mean: 0.12130
[32m[0906 18-55-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01914, current rewards: 293.29995, mean: 0.12170
[32m[0906 18-55-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01918, current rewards: 300.22497, mean: 0.12204
[32m[0906 18-55-13 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 18-55-13 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-55-13 @MBExp.py:227][0m Rewards obtained: [305.79647192087276], Lows: [1], Highs: [1], Total time: 5392.056234999999
[32m[0906 18-59-12 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-12 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 18-59-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01859, current rewards: 1.06192, mean: 0.10619
[32m[0906 18-59-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01854, current rewards: 6.54308, mean: 0.10905
[32m[0906 18-59-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01861, current rewards: 12.21988, mean: 0.11109
[32m[0906 18-59-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01866, current rewards: 17.75795, mean: 0.11099
[32m[0906 18-59-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01862, current rewards: 23.29463, mean: 0.11093
[32m[0906 18-59-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01861, current rewards: 26.70172, mean: 0.10270
[32m[0906 18-59-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01859, current rewards: 32.15236, mean: 0.10372
[32m[0906 18-59-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01861, current rewards: 37.60250, mean: 0.10445
[32m[0906 18-59-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01858, current rewards: 43.04879, mean: 0.10500
[32m[0906 18-59-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01857, current rewards: 48.49763, mean: 0.10543
[32m[0906 18-59-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01857, current rewards: 53.85832, mean: 0.10560
[32m[0906 18-59-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01857, current rewards: 59.30364, mean: 0.10590
[32m[0906 18-59-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01857, current rewards: 64.79618, mean: 0.10622
[32m[0906 18-59-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01855, current rewards: 70.28957, mean: 0.10650
[32m[0906 18-59-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01855, current rewards: 73.49148, mean: 0.10351
[32m[0906 18-59-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01855, current rewards: 78.76815, mean: 0.10364
[32m[0906 18-59-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01855, current rewards: 84.04261, mean: 0.10376
[32m[0906 18-59-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01855, current rewards: 89.31710, mean: 0.10386
[32m[0906 18-59-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01855, current rewards: 94.58961, mean: 0.10394
[32m[0906 18-59-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01857, current rewards: 99.93839, mean: 0.10410
[32m[0906 18-59-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01856, current rewards: 105.23198, mean: 0.10419
[32m[0906 18-59-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01857, current rewards: 110.52362, mean: 0.10427
[32m[0906 18-59-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01856, current rewards: 115.81501, mean: 0.10434
[32m[0906 18-59-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01855, current rewards: 118.16149, mean: 0.10186
[32m[0906 18-59-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01856, current rewards: 123.67886, mean: 0.10221
[32m[0906 18-59-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01855, current rewards: 129.20248, mean: 0.10254
[32m[0906 18-59-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01855, current rewards: 134.72474, mean: 0.10284
[32m[0906 18-59-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01856, current rewards: 140.20672, mean: 0.10309
[32m[0906 18-59-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01856, current rewards: 145.78879, mean: 0.10340
[32m[0906 18-59-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 151.36359, mean: 0.10367
[32m[0906 18-59-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01856, current rewards: 156.94373, mean: 0.10394
[32m[0906 18-59-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01856, current rewards: 162.52411, mean: 0.10418
[32m[0906 18-59-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01856, current rewards: 168.10351, mean: 0.10441
[32m[0906 18-59-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01856, current rewards: 173.68217, mean: 0.10463
[32m[0906 18-59-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: 179.26280, mean: 0.10483
[32m[0906 18-59-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01856, current rewards: 184.92979, mean: 0.10507
[32m[0906 18-59-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01856, current rewards: 190.51460, mean: 0.10526
[32m[0906 18-59-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01857, current rewards: 196.09589, mean: 0.10543
[32m[0906 18-59-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01857, current rewards: 201.67876, mean: 0.10559
[32m[0906 18-59-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01857, current rewards: 207.26692, mean: 0.10575
[32m[0906 18-59-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01857, current rewards: 212.70704, mean: 0.10582
[32m[0906 18-59-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01857, current rewards: 218.20260, mean: 0.10592
[32m[0906 18-59-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01856, current rewards: 223.70078, mean: 0.10602
[32m[0906 18-59-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01857, current rewards: 229.20654, mean: 0.10611
[32m[0906 18-59-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01857, current rewards: 234.71607, mean: 0.10621
[32m[0906 18-59-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01856, current rewards: 240.20006, mean: 0.10628
[32m[0906 18-59-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01857, current rewards: 245.72620, mean: 0.10637
[32m[0906 18-59-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01857, current rewards: 251.17067, mean: 0.10643
[32m[0906 18-59-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 256.61100, mean: 0.10648
[32m[0906 18-59-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01857, current rewards: 262.05436, mean: 0.10653
[32m[0906 18-59-59 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 18-59-59 @Agent.py:118][0m Rollout length: 2500
[32m[0906 18-59-59 @MBExp.py:227][0m Rewards obtained: [266.41244538258286], Lows: [3], Highs: [1], Total time: 5439.358867999999
[32m[0906 19-04-00 @MBExp.py:144][0m ####################################################################
[32m[0906 19-04-00 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 19-04-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01855, current rewards: 0.19764, mean: 0.01976
[32m[0906 19-04-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01854, current rewards: 5.70644, mean: 0.09511
[32m[0906 19-04-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01851, current rewards: 11.38032, mean: 0.10346
[32m[0906 19-04-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 16.94959, mean: 0.10593
[32m[0906 19-04-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01856, current rewards: 22.52195, mean: 0.10725
[32m[0906 19-04-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 28.09035, mean: 0.10804
[32m[0906 19-04-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01854, current rewards: 33.66415, mean: 0.10859
[32m[0906 19-04-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01857, current rewards: 39.23132, mean: 0.10898
[32m[0906 19-04-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01858, current rewards: 44.80765, mean: 0.10929
[32m[0906 19-04-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01858, current rewards: 50.80673, mean: 0.11045
[32m[0906 19-04-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01858, current rewards: 56.35254, mean: 0.11050
[32m[0906 19-04-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01859, current rewards: 61.94516, mean: 0.11062
[32m[0906 19-04-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01860, current rewards: 67.53329, mean: 0.11071
[32m[0906 19-04-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01859, current rewards: 73.11784, mean: 0.11078
[32m[0906 19-04-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01860, current rewards: 78.71078, mean: 0.11086
[32m[0906 19-04-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01859, current rewards: 84.30424, mean: 0.11093
[32m[0906 19-04-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01860, current rewards: 89.89121, mean: 0.11098
[32m[0906 19-04-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01861, current rewards: 95.48059, mean: 0.11102
[32m[0906 19-04-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01862, current rewards: 101.05626, mean: 0.11105
[32m[0906 19-04-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01861, current rewards: 106.64310, mean: 0.11109
[32m[0906 19-04-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01860, current rewards: 112.21520, mean: 0.11110
[32m[0906 19-04-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01861, current rewards: 117.78820, mean: 0.11112
[32m[0906 19-04-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01860, current rewards: 123.36782, mean: 0.11114
[32m[0906 19-04-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01861, current rewards: 128.93753, mean: 0.11115
[32m[0906 19-04-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01860, current rewards: 134.51197, mean: 0.11117
[32m[0906 19-04-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01860, current rewards: 140.08743, mean: 0.11118
[32m[0906 19-04-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01859, current rewards: 145.67053, mean: 0.11120
[32m[0906 19-04-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01859, current rewards: 149.31996, mean: 0.10979
[32m[0906 19-04-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01858, current rewards: 155.03634, mean: 0.10995
[32m[0906 19-04-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01858, current rewards: 160.75357, mean: 0.11011
[32m[0906 19-04-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01858, current rewards: 166.47054, mean: 0.11025
[32m[0906 19-04-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01858, current rewards: 172.18816, mean: 0.11038
[32m[0906 19-04-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01858, current rewards: 177.90811, mean: 0.11050
[32m[0906 19-04-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01857, current rewards: 183.63043, mean: 0.11062
[32m[0906 19-04-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01858, current rewards: 189.34912, mean: 0.11073
[32m[0906 19-04-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 194.94950, mean: 0.11077
[32m[0906 19-04-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01857, current rewards: 200.52795, mean: 0.11079
[32m[0906 19-04-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01857, current rewards: 206.10667, mean: 0.11081
[32m[0906 19-04-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01858, current rewards: 211.68673, mean: 0.11083
[32m[0906 19-04-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01858, current rewards: 217.26611, mean: 0.11085
[32m[0906 19-04-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01858, current rewards: 222.84364, mean: 0.11087
[32m[0906 19-04-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01858, current rewards: 228.42619, mean: 0.11089
[32m[0906 19-04-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01858, current rewards: 234.00461, mean: 0.11090
[32m[0906 19-04-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01857, current rewards: 239.50332, mean: 0.11088
[32m[0906 19-04-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01857, current rewards: 245.09007, mean: 0.11090
[32m[0906 19-04-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01857, current rewards: 248.55320, mean: 0.10998
[32m[0906 19-04-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01857, current rewards: 254.10885, mean: 0.11000
[32m[0906 19-04-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01857, current rewards: 259.66578, mean: 0.11003
[32m[0906 19-04-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01858, current rewards: 265.22466, mean: 0.11005
[32m[0906 19-04-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01858, current rewards: 270.78189, mean: 0.11007
[32m[0906 19-04-47 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-04-47 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-04-47 @MBExp.py:227][0m Rewards obtained: [275.2253787799706], Lows: [2], Highs: [1], Total time: 5486.6954399999995
[32m[0906 19-08-52 @MBExp.py:144][0m ####################################################################
[32m[0906 19-08-52 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 19-08-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01847, current rewards: 0.03365, mean: 0.00337
[32m[0906 19-08-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01848, current rewards: 5.45637, mean: 0.09094
[32m[0906 19-08-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01839, current rewards: 11.06506, mean: 0.10059
[32m[0906 19-08-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01844, current rewards: 16.72095, mean: 0.10451
[32m[0906 19-08-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01845, current rewards: 22.37518, mean: 0.10655
[32m[0906 19-08-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01845, current rewards: 28.03162, mean: 0.10781
[32m[0906 19-08-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01846, current rewards: 33.68769, mean: 0.10867
[32m[0906 19-08-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01848, current rewards: 36.11891, mean: 0.10033
[32m[0906 19-09-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 41.35599, mean: 0.10087
[32m[0906 19-09-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01852, current rewards: 46.60777, mean: 0.10132
[32m[0906 19-09-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01853, current rewards: 51.99153, mean: 0.10194
[32m[0906 19-09-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 57.28741, mean: 0.10230
[32m[0906 19-09-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 62.58759, mean: 0.10260
[32m[0906 19-09-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 67.88491, mean: 0.10286
[32m[0906 19-09-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 73.18447, mean: 0.10308
[32m[0906 19-09-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01850, current rewards: 78.47998, mean: 0.10326
[32m[0906 19-09-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 83.78089, mean: 0.10343
[32m[0906 19-09-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01850, current rewards: 89.66403, mean: 0.10426
[32m[0906 19-09-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01850, current rewards: 95.31233, mean: 0.10474
[32m[0906 19-09-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01850, current rewards: 100.83732, mean: 0.10504
[32m[0906 19-09-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01850, current rewards: 106.41465, mean: 0.10536
[32m[0906 19-09-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01851, current rewards: 111.99752, mean: 0.10566
[32m[0906 19-09-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01851, current rewards: 117.69695, mean: 0.10603
[32m[0906 19-09-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01850, current rewards: 123.39557, mean: 0.10638
[32m[0906 19-09-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01851, current rewards: 129.08355, mean: 0.10668
[32m[0906 19-09-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 134.77387, mean: 0.10696
[32m[0906 19-09-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 140.45837, mean: 0.10722
[32m[0906 19-09-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: 146.35414, mean: 0.10761
[32m[0906 19-09-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: 151.87119, mean: 0.10771
[32m[0906 19-09-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01854, current rewards: 157.39769, mean: 0.10781
[32m[0906 19-09-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01854, current rewards: 162.98682, mean: 0.10794
[32m[0906 19-09-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01854, current rewards: 168.59961, mean: 0.10808
[32m[0906 19-09-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01853, current rewards: 174.21410, mean: 0.10821
[32m[0906 19-09-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01853, current rewards: 179.82818, mean: 0.10833
[32m[0906 19-09-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01853, current rewards: 185.44055, mean: 0.10844
[32m[0906 19-09-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01853, current rewards: 191.05670, mean: 0.10855
[32m[0906 19-09-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01852, current rewards: 196.56067, mean: 0.10860
[32m[0906 19-09-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01852, current rewards: 202.15863, mean: 0.10869
[32m[0906 19-09-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01852, current rewards: 205.64866, mean: 0.10767
[32m[0906 19-09-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01852, current rewards: 211.23349, mean: 0.10777
[32m[0906 19-09-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01852, current rewards: 216.81428, mean: 0.10787
[32m[0906 19-09-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01852, current rewards: 222.39542, mean: 0.10796
[32m[0906 19-09-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01852, current rewards: 227.97533, mean: 0.10805
[32m[0906 19-09-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01852, current rewards: 233.55203, mean: 0.10813
[32m[0906 19-09-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01852, current rewards: 239.22961, mean: 0.10825
[32m[0906 19-09-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01852, current rewards: 244.73800, mean: 0.10829
[32m[0906 19-09-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01852, current rewards: 250.24394, mean: 0.10833
[32m[0906 19-09-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01852, current rewards: 255.74835, mean: 0.10837
[32m[0906 19-09-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01852, current rewards: 261.26029, mean: 0.10841
[32m[0906 19-09-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01852, current rewards: 266.76823, mean: 0.10844
[32m[0906 19-09-39 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 19-09-39 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-09-40 @MBExp.py:227][0m Rewards obtained: [271.1728892548907], Lows: [2], Highs: [2], Total time: 5533.852543999999
[32m[0906 19-13-45 @MBExp.py:144][0m ####################################################################
[32m[0906 19-13-45 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 19-13-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01833, current rewards: 0.86007, mean: 0.08601
[32m[0906 19-13-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01856, current rewards: 5.40571, mean: 0.09010
[32m[0906 19-13-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01864, current rewards: 9.95270, mean: 0.09048
[32m[0906 19-13-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01863, current rewards: 14.53472, mean: 0.09084
[32m[0906 19-13-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01855, current rewards: 19.17467, mean: 0.09131
[32m[0906 19-13-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01854, current rewards: 23.80691, mean: 0.09157
[32m[0906 19-13-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01853, current rewards: 25.28688, mean: 0.08157
[32m[0906 19-13-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01853, current rewards: 30.83764, mean: 0.08566
[32m[0906 19-13-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 36.38650, mean: 0.08875
[32m[0906 19-13-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 41.93539, mean: 0.09116
[32m[0906 19-13-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01848, current rewards: 47.48762, mean: 0.09311
[32m[0906 19-13-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 53.03817, mean: 0.09471
[32m[0906 19-13-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 58.59413, mean: 0.09606
[32m[0906 19-13-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01848, current rewards: 64.13690, mean: 0.09718
[32m[0906 19-13-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 69.68231, mean: 0.09814
[32m[0906 19-13-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 75.21314, mean: 0.09896
[32m[0906 19-14-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01851, current rewards: 80.76090, mean: 0.09970
[32m[0906 19-14-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 86.31570, mean: 0.10037
[32m[0906 19-14-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 91.86558, mean: 0.10095
[32m[0906 19-14-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01854, current rewards: 97.38388, mean: 0.10144
[32m[0906 19-14-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 102.92857, mean: 0.10191
[32m[0906 19-14-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 105.23286, mean: 0.09928
[32m[0906 19-14-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01852, current rewards: 110.81931, mean: 0.09984
[32m[0906 19-14-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 116.40289, mean: 0.10035
[32m[0906 19-14-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01852, current rewards: 121.98017, mean: 0.10081
[32m[0906 19-14-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01852, current rewards: 127.55672, mean: 0.10124
[32m[0906 19-14-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 133.12880, mean: 0.10163
[32m[0906 19-14-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: 138.78361, mean: 0.10205
[32m[0906 19-14-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01853, current rewards: 144.39097, mean: 0.10240
[32m[0906 19-14-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01853, current rewards: 149.96492, mean: 0.10272
[32m[0906 19-14-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01852, current rewards: 155.54146, mean: 0.10301
[32m[0906 19-14-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01852, current rewards: 161.11603, mean: 0.10328
[32m[0906 19-14-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01851, current rewards: 166.68977, mean: 0.10353
[32m[0906 19-14-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01851, current rewards: 172.40859, mean: 0.10386
[32m[0906 19-14-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01852, current rewards: 178.50162, mean: 0.10439
[32m[0906 19-14-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01853, current rewards: 184.60967, mean: 0.10489
[32m[0906 19-14-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01853, current rewards: 190.30652, mean: 0.10514
[32m[0906 19-14-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01853, current rewards: 195.85096, mean: 0.10530
[32m[0906 19-14-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01854, current rewards: 201.39269, mean: 0.10544
[32m[0906 19-14-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01853, current rewards: 206.92953, mean: 0.10558
[32m[0906 19-14-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01853, current rewards: 212.47642, mean: 0.10571
[32m[0906 19-14-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01853, current rewards: 218.01909, mean: 0.10583
[32m[0906 19-14-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01853, current rewards: 223.56018, mean: 0.10595
[32m[0906 19-14-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01853, current rewards: 229.10385, mean: 0.10607
[32m[0906 19-14-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01853, current rewards: 234.70095, mean: 0.10620
[32m[0906 19-14-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01853, current rewards: 236.75908, mean: 0.10476
[32m[0906 19-14-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01853, current rewards: 242.02126, mean: 0.10477
[32m[0906 19-14-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01853, current rewards: 247.27712, mean: 0.10478
[32m[0906 19-14-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01854, current rewards: 252.53205, mean: 0.10479
[32m[0906 19-14-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01854, current rewards: 257.78784, mean: 0.10479
[32m[0906 19-14-32 @Agent.py:117][0m Average action selection time: 0.0185
[32m[0906 19-14-32 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-14-32 @MBExp.py:227][0m Rewards obtained: [261.99359458673865], Lows: [3], Highs: [3], Total time: 5581.0385209999995
[32m[0906 19-18-38 @MBExp.py:144][0m ####################################################################
[32m[0906 19-18-38 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 19-18-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01814, current rewards: -1.05606, mean: -0.10561
[32m[0906 19-18-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01840, current rewards: 4.43085, mean: 0.07385
[32m[0906 19-18-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01848, current rewards: 9.97395, mean: 0.09067
[32m[0906 19-18-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01846, current rewards: 15.50439, mean: 0.09690
[32m[0906 19-18-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01852, current rewards: 21.05362, mean: 0.10026
[32m[0906 19-18-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01847, current rewards: 26.60253, mean: 0.10232
[32m[0906 19-18-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01850, current rewards: 32.15119, mean: 0.10371
[32m[0906 19-18-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 37.69826, mean: 0.10472
[32m[0906 19-18-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01848, current rewards: 43.23984, mean: 0.10546
[32m[0906 19-18-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01849, current rewards: 48.78735, mean: 0.10606
[32m[0906 19-18-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01849, current rewards: 52.15339, mean: 0.10226
[32m[0906 19-18-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 57.72018, mean: 0.10307
[32m[0906 19-18-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01851, current rewards: 63.27141, mean: 0.10372
[32m[0906 19-18-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01851, current rewards: 68.82516, mean: 0.10428
[32m[0906 19-18-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01850, current rewards: 74.38602, mean: 0.10477
[32m[0906 19-18-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01852, current rewards: 79.94210, mean: 0.10519
[32m[0906 19-18-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 85.50071, mean: 0.10556
[32m[0906 19-18-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 91.05332, mean: 0.10588
[32m[0906 19-18-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01852, current rewards: 96.60624, mean: 0.10616
[32m[0906 19-18-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 102.21762, mean: 0.10648
[32m[0906 19-18-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 105.69393, mean: 0.10465
[32m[0906 19-18-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01853, current rewards: 111.26767, mean: 0.10497
[32m[0906 19-18-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01853, current rewards: 116.83894, mean: 0.10526
[32m[0906 19-19-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01853, current rewards: 122.41304, mean: 0.10553
[32m[0906 19-19-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01853, current rewards: 127.98609, mean: 0.10577
[32m[0906 19-19-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01854, current rewards: 133.55984, mean: 0.10600
[32m[0906 19-19-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01853, current rewards: 139.13182, mean: 0.10621
[32m[0906 19-19-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01853, current rewards: 144.66331, mean: 0.10637
[32m[0906 19-19-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01854, current rewards: 146.96314, mean: 0.10423
[32m[0906 19-19-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01855, current rewards: 152.45586, mean: 0.10442
[32m[0906 19-19-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01855, current rewards: 157.95027, mean: 0.10460
[32m[0906 19-19-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01855, current rewards: 163.44909, mean: 0.10478
[32m[0906 19-19-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01855, current rewards: 168.94350, mean: 0.10493
[32m[0906 19-19-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01855, current rewards: 174.43571, mean: 0.10508
[32m[0906 19-19-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01855, current rewards: 179.93014, mean: 0.10522
[32m[0906 19-19-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01855, current rewards: 185.42722, mean: 0.10536
[32m[0906 19-19-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01855, current rewards: 189.03890, mean: 0.10444
[32m[0906 19-19-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01856, current rewards: 195.09127, mean: 0.10489
[32m[0906 19-19-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01855, current rewards: 201.14343, mean: 0.10531
[32m[0906 19-19-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01855, current rewards: 207.18255, mean: 0.10571
[32m[0906 19-19-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01856, current rewards: 213.22997, mean: 0.10608
[32m[0906 19-19-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01856, current rewards: 219.28016, mean: 0.10645
[32m[0906 19-19-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01856, current rewards: 225.32929, mean: 0.10679
[32m[0906 19-19-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01856, current rewards: 231.40970, mean: 0.10713
[32m[0906 19-19-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01856, current rewards: 237.42105, mean: 0.10743
[32m[0906 19-19-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01857, current rewards: 243.42835, mean: 0.10771
[32m[0906 19-19-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01856, current rewards: 249.44734, mean: 0.10799
[32m[0906 19-19-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01856, current rewards: 255.45357, mean: 0.10824
[32m[0906 19-19-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01856, current rewards: 261.14760, mean: 0.10836
[32m[0906 19-19-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01856, current rewards: 266.71794, mean: 0.10842
[32m[0906 19-19-25 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-19-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-19-25 @MBExp.py:227][0m Rewards obtained: [271.1660466035018], Lows: [5], Highs: [1], Total time: 5628.284204
[32m[0906 19-23-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-23-35 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 19-23-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01824, current rewards: -2.04721, mean: -0.20472
[32m[0906 19-23-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01846, current rewards: 4.14912, mean: 0.06915
[32m[0906 19-23-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01842, current rewards: 10.18593, mean: 0.09260
[32m[0906 19-23-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01843, current rewards: 16.32859, mean: 0.10205
[32m[0906 19-23-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01847, current rewards: 22.47678, mean: 0.10703
[32m[0906 19-23-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01848, current rewards: 28.62533, mean: 0.11010
[32m[0906 19-23-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01847, current rewards: 34.77378, mean: 0.11217
[32m[0906 19-23-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01849, current rewards: 40.91761, mean: 0.11366
[32m[0906 19-23-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01850, current rewards: 47.06050, mean: 0.11478
[32m[0906 19-23-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01850, current rewards: 53.20223, mean: 0.11566
[32m[0906 19-23-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01852, current rewards: 58.25440, mean: 0.11422
[32m[0906 19-23-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01850, current rewards: 63.97608, mean: 0.11424
[32m[0906 19-23-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01849, current rewards: 69.66992, mean: 0.11421
[32m[0906 19-23-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01850, current rewards: 75.36917, mean: 0.11420
[32m[0906 19-23-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01851, current rewards: 81.06863, mean: 0.11418
[32m[0906 19-23-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01851, current rewards: 86.75725, mean: 0.11415
[32m[0906 19-23-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01852, current rewards: 92.46244, mean: 0.11415
[32m[0906 19-23-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01852, current rewards: 98.15816, mean: 0.11414
[32m[0906 19-23-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01853, current rewards: 103.84490, mean: 0.11412
[32m[0906 19-23-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01852, current rewards: 109.53799, mean: 0.11410
[32m[0906 19-23-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01853, current rewards: 112.10235, mean: 0.11099
[32m[0906 19-23-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01859, current rewards: 117.93002, mean: 0.11125
[32m[0906 19-23-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01863, current rewards: 123.79413, mean: 0.11153
[32m[0906 19-23-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01867, current rewards: 129.64747, mean: 0.11177
[32m[0906 19-23-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01874, current rewards: 135.47114, mean: 0.11196
[32m[0906 19-23-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01878, current rewards: 141.30656, mean: 0.11215
[32m[0906 19-24-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01883, current rewards: 147.13357, mean: 0.11232
[32m[0906 19-24-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01890, current rewards: 153.03836, mean: 0.11253
[32m[0906 19-24-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01895, current rewards: 158.84799, mean: 0.11266
[32m[0906 19-24-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01898, current rewards: 164.67430, mean: 0.11279
[32m[0906 19-24-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01901, current rewards: 170.48974, mean: 0.11291
[32m[0906 19-24-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01899, current rewards: 176.60836, mean: 0.11321
[32m[0906 19-24-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01900, current rewards: 182.71886, mean: 0.11349
[32m[0906 19-24-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01899, current rewards: 188.83358, mean: 0.11376
[32m[0906 19-24-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01898, current rewards: 194.97163, mean: 0.11402
[32m[0906 19-24-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01898, current rewards: 201.13261, mean: 0.11428
[32m[0906 19-24-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01897, current rewards: 207.22232, mean: 0.11449
[32m[0906 19-24-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01897, current rewards: 213.28851, mean: 0.11467
[32m[0906 19-24-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01896, current rewards: 219.39874, mean: 0.11487
[32m[0906 19-24-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01896, current rewards: 225.53061, mean: 0.11507
[32m[0906 19-24-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01897, current rewards: 231.66491, mean: 0.11526
[32m[0906 19-24-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01896, current rewards: 238.05200, mean: 0.11556
[32m[0906 19-24-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01896, current rewards: 244.39080, mean: 0.11583
[32m[0906 19-24-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01895, current rewards: 250.69313, mean: 0.11606
[32m[0906 19-24-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01894, current rewards: 257.19432, mean: 0.11638
[32m[0906 19-24-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01894, current rewards: 263.81253, mean: 0.11673
[32m[0906 19-24-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01893, current rewards: 270.34368, mean: 0.11703
[32m[0906 19-24-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01892, current rewards: 276.92005, mean: 0.11734
[32m[0906 19-24-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01891, current rewards: 283.49374, mean: 0.11763
[32m[0906 19-24-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01891, current rewards: 290.05168, mean: 0.11791
[32m[0906 19-24-23 @Agent.py:117][0m Average action selection time: 0.0189
[32m[0906 19-24-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-24-23 @MBExp.py:227][0m Rewards obtained: [294.95126351625015], Lows: [2], Highs: [3], Total time: 5676.434128
[32m[0906 19-28-36 @MBExp.py:144][0m ####################################################################
[32m[0906 19-28-36 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 19-28-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01870, current rewards: -0.03730, mean: -0.00373
[32m[0906 19-28-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01851, current rewards: 5.06525, mean: 0.08442
[32m[0906 19-28-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01850, current rewards: 10.08798, mean: 0.09171
[32m[0906 19-28-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01848, current rewards: 15.21277, mean: 0.09508
[32m[0906 19-28-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01844, current rewards: 20.33524, mean: 0.09683
[32m[0906 19-28-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01843, current rewards: 25.45579, mean: 0.09791
[32m[0906 19-28-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01848, current rewards: 30.58263, mean: 0.09865
[32m[0906 19-28-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01850, current rewards: 35.70798, mean: 0.09919
[32m[0906 19-28-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01852, current rewards: 40.83749, mean: 0.09960
[32m[0906 19-28-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01853, current rewards: 45.12699, mean: 0.09810
[32m[0906 19-28-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01851, current rewards: 50.44059, mean: 0.09890
[32m[0906 19-28-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01851, current rewards: 55.74984, mean: 0.09955
[32m[0906 19-28-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.01853, current rewards: 61.06271, mean: 0.10010
[32m[0906 19-28-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.01852, current rewards: 66.37728, mean: 0.10057
[32m[0906 19-28-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.01852, current rewards: 71.69569, mean: 0.10098
[32m[0906 19-28-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.01853, current rewards: 77.01479, mean: 0.10134
[32m[0906 19-28-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.01853, current rewards: 82.32387, mean: 0.10163
[32m[0906 19-28-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.01853, current rewards: 84.46269, mean: 0.09821
[32m[0906 19-28-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.01854, current rewards: 90.30883, mean: 0.09924
[32m[0906 19-28-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.01855, current rewards: 96.24846, mean: 0.10026
[32m[0906 19-28-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.01855, current rewards: 102.14115, mean: 0.10113
[32m[0906 19-28-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.01855, current rewards: 108.02891, mean: 0.10191
[32m[0906 19-28-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.01855, current rewards: 113.92056, mean: 0.10263
[32m[0906 19-28-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01856, current rewards: 119.80855, mean: 0.10328
[32m[0906 19-28-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01855, current rewards: 125.69146, mean: 0.10388
[32m[0906 19-28-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01856, current rewards: 131.57815, mean: 0.10443
[32m[0906 19-29-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01857, current rewards: 135.51685, mean: 0.10345
[32m[0906 19-29-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01857, current rewards: 140.63198, mean: 0.10341
[32m[0906 19-29-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01857, current rewards: 145.55051, mean: 0.10323
[32m[0906 19-29-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01856, current rewards: 150.47111, mean: 0.10306
[32m[0906 19-29-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01856, current rewards: 155.39164, mean: 0.10291
[32m[0906 19-29-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01856, current rewards: 160.30698, mean: 0.10276
[32m[0906 19-29-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01856, current rewards: 165.22609, mean: 0.10262
[32m[0906 19-29-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01857, current rewards: 170.14356, mean: 0.10250
[32m[0906 19-29-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01857, current rewards: 175.06048, mean: 0.10237
[32m[0906 19-29-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01857, current rewards: 180.09203, mean: 0.10233
[32m[0906 19-29-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01856, current rewards: 187.90090, mean: 0.10381
[32m[0906 19-29-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01857, current rewards: 195.97519, mean: 0.10536
[32m[0906 19-29-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01856, current rewards: 204.04947, mean: 0.10683
[32m[0906 19-29-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01856, current rewards: 167.98730, mean: 0.08571
[32m[0906 19-29-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01856, current rewards: 117.98730, mean: 0.05870
[32m[0906 19-29-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01857, current rewards: 67.98730, mean: 0.03300
[32m[0906 19-29-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01857, current rewards: 17.98730, mean: 0.00852
[32m[0906 19-29-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01857, current rewards: -32.01270, mean: -0.01482
[32m[0906 19-29-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01857, current rewards: -82.01270, mean: -0.03711
[32m[0906 19-29-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01857, current rewards: -132.01270, mean: -0.05841
[32m[0906 19-29-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01858, current rewards: -182.01270, mean: -0.07879
[32m[0906 19-29-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01858, current rewards: -232.01270, mean: -0.09831
[32m[0906 19-29-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01858, current rewards: -282.01270, mean: -0.11702
[32m[0906 19-29-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01858, current rewards: -332.01270, mean: -0.13496
[32m[0906 19-29-23 @Agent.py:117][0m Average action selection time: 0.0186
[32m[0906 19-29-23 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-29-23 @MBExp.py:227][0m Rewards obtained: [-372.01269640647956], Lows: [2], Highs: [581], Total time: 5723.734518
[32m[0906 19-33-37 @MBExp.py:144][0m ####################################################################
[32m[0906 19-33-37 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 19-33-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.01881, current rewards: -2.10853, mean: -0.21085
[32m[0906 19-33-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.01876, current rewards: 3.49738, mean: 0.05829
[32m[0906 19-33-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.01853, current rewards: 9.03206, mean: 0.08211
[32m[0906 19-33-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.01852, current rewards: 14.56840, mean: 0.09105
[32m[0906 19-33-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.01858, current rewards: 20.10510, mean: 0.09574
[32m[0906 19-33-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.01856, current rewards: 25.64174, mean: 0.09862
[32m[0906 19-33-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.01859, current rewards: 31.17850, mean: 0.10058
[32m[0906 19-33-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.01856, current rewards: 36.71619, mean: 0.10199
[32m[0906 19-33-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.01883, current rewards: 39.93683, mean: 0.09741
[32m[0906 19-33-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.01930, current rewards: 40.98463, mean: 0.08910
[32m[0906 19-33-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.01964, current rewards: 50.31340, mean: 0.09865
[32m[0906 19-33-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.01990, current rewards: 59.92001, mean: 0.10700
[32m[0906 19-33-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02010, current rewards: 66.82325, mean: 0.10955
[32m[0906 19-33-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02031, current rewards: 71.10852, mean: 0.10774
[32m[0906 19-33-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02045, current rewards: 80.16154, mean: 0.11290
[32m[0906 19-33-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02058, current rewards: 85.85727, mean: 0.11297
[32m[0906 19-33-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02052, current rewards: 91.44214, mean: 0.11289
[32m[0906 19-33-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02041, current rewards: 98.71635, mean: 0.11479
[32m[0906 19-33-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02031, current rewards: 105.99056, mean: 0.11647
[32m[0906 19-33-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02023, current rewards: 111.92862, mean: 0.11659
[32m[0906 19-33-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02015, current rewards: 116.88583, mean: 0.11573
[32m[0906 19-33-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02008, current rewards: 121.84304, mean: 0.11495
[32m[0906 19-33-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02002, current rewards: 123.50281, mean: 0.11126
[32m[0906 19-34-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.01996, current rewards: 73.50281, mean: 0.06336
[32m[0906 19-34-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.01990, current rewards: 23.50281, mean: 0.01942
[32m[0906 19-34-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.01985, current rewards: -26.49719, mean: -0.02103
[32m[0906 19-34-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.01980, current rewards: -76.49719, mean: -0.05839
[32m[0906 19-34-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.01975, current rewards: -126.49719, mean: -0.09301
[32m[0906 19-34-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.01971, current rewards: -176.49719, mean: -0.12518
[32m[0906 19-34-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.01966, current rewards: -226.49719, mean: -0.15514
[32m[0906 19-34-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.01963, current rewards: -276.49719, mean: -0.18311
[32m[0906 19-34-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.01959, current rewards: -326.49719, mean: -0.20929
[32m[0906 19-34-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.01956, current rewards: -376.49719, mean: -0.23385
[32m[0906 19-34-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.01953, current rewards: -426.49719, mean: -0.25693
[32m[0906 19-34-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.01949, current rewards: -476.49719, mean: -0.27865
[32m[0906 19-34-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.01947, current rewards: -526.49719, mean: -0.29915
[32m[0906 19-34-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.01943, current rewards: -576.49719, mean: -0.31851
[32m[0906 19-34-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.01941, current rewards: -626.49719, mean: -0.33683
[32m[0906 19-34-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.01939, current rewards: -676.49719, mean: -0.35419
[32m[0906 19-34-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.01937, current rewards: -726.49719, mean: -0.37066
[32m[0906 19-34-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.01936, current rewards: -776.49719, mean: -0.38632
[32m[0906 19-34-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.01934, current rewards: -826.49719, mean: -0.40121
[32m[0906 19-34-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.01932, current rewards: -876.49719, mean: -0.41540
[32m[0906 19-34-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.01931, current rewards: -926.49719, mean: -0.42893
[32m[0906 19-34-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.01929, current rewards: -976.49719, mean: -0.44185
[32m[0906 19-34-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.01927, current rewards: -1026.49719, mean: -0.45420
[32m[0906 19-34-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.01926, current rewards: -1076.49719, mean: -0.46602
[32m[0906 19-34-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.01924, current rewards: -1126.49719, mean: -0.47733
[32m[0906 19-34-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.01922, current rewards: -1176.49719, mean: -0.48817
[32m[0906 19-34-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.01922, current rewards: -1226.49719, mean: -0.49858
[32m[0906 19-34-25 @Agent.py:117][0m Average action selection time: 0.0192
[32m[0906 19-34-25 @Agent.py:118][0m Rollout length: 2500
[32m[0906 19-34-26 @MBExp.py:227][0m Rewards obtained: [-1266.4971861535128], Lows: [13], Highs: [1394], Total time: 5772.665219
