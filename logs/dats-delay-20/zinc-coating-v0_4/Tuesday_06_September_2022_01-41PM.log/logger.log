[32m[0906 13-41-24 @logger.py:99][0m Log file set to /app/logs/dats-delay-20/zinc-coating-v0_4/Tuesday_06_September_2022_01-41PM.log
[32m[0906 13-41-24 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -61.42139, mean: -1.02369
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -111.87380, mean: -1.01703
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -156.57604, mean: -0.97860
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -218.28421, mean: -1.03945
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -274.86655, mean: -1.05718
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -333.93994, mean: -1.07723
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -380.33297, mean: -1.05648
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -432.03828, mean: -1.05375
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -481.12750, mean: -1.04593
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -530.67171, mean: -1.04053
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -581.61657, mean: -1.03860
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -633.36380, mean: -1.03830
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -690.13063, mean: -1.04565
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -753.44375, mean: -1.06119
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -804.08246, mean: -1.05800
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -858.92385, mean: -1.06040
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -924.47436, mean: -1.07497
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -967.12024, mean: -1.06277
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1017.59143, mean: -1.05999
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1075.95790, mean: -1.06530
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1134.00399, mean: -1.06982
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1196.43007, mean: -1.07786
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1254.09988, mean: -1.08112
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1302.26185, mean: -1.07625
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1353.96155, mean: -1.07457
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1405.37042, mean: -1.07280
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1458.09735, mean: -1.07213
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1515.90759, mean: -1.07511
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1570.00531, mean: -1.07535
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1617.86418, mean: -1.07143
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1675.95043, mean: -1.07433
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1744.85285, mean: -1.08376
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1792.44627, mean: -1.07979
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1844.27326, mean: -1.07852
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -1900.08626, mean: -1.07959
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -1962.71301, mean: -1.08437
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2018.83740, mean: -1.08540
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2081.05069, mean: -1.08956
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2152.42247, mean: -1.09817
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2215.44970, mean: -1.10221
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2294.64522, mean: -1.11391
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2356.23033, mean: -1.11670
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2415.26676, mean: -1.11818
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2482.99006, mean: -1.12352
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2553.74240, mean: -1.12997
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2609.06704, mean: -1.12947
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2649.07691, mean: -1.12249
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2692.05587, mean: -1.11704
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2746.74119, mean: -1.11656
[32m[0906 13-41-25 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-41-25 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-41-28 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-28 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39055, current rewards: 0.85260, mean: 0.08526
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37628, current rewards: -78.29914, mean: -1.30499
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37428, current rewards: -178.29914, mean: -1.62090
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37374, current rewards: -278.29914, mean: -1.73937
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37311, current rewards: -378.29914, mean: -1.80142
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37257, current rewards: -478.29914, mean: -1.83961
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37135, current rewards: -578.29914, mean: -1.86548
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37061, current rewards: -678.29914, mean: -1.88416
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37016, current rewards: -778.29914, mean: -1.89829
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36993, current rewards: -878.29914, mean: -1.90935
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36987, current rewards: -978.29914, mean: -1.91823
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36985, current rewards: -1078.29914, mean: -1.92553
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36972, current rewards: -1178.29914, mean: -1.93164
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36969, current rewards: -1271.77895, mean: -1.92694
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36949, current rewards: -1334.85115, mean: -1.88007
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36936, current rewards: -1434.85115, mean: -1.88796
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36916, current rewards: -1534.85115, mean: -1.89488
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36903, current rewards: -1634.85115, mean: -1.90099
[32m[0906 13-47-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36863, current rewards: -1734.85115, mean: -1.90643
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36824, current rewards: -1834.85115, mean: -1.91130
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36787, current rewards: -1934.85115, mean: -1.91569
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36761, current rewards: -2034.85115, mean: -1.91967
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36740, current rewards: -2134.85115, mean: -1.92329
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36719, current rewards: -2234.85115, mean: -1.92660
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36704, current rewards: -2334.85115, mean: -1.92963
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36688, current rewards: -2434.85115, mean: -1.93242
[32m[0906 13-49-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36676, current rewards: -2534.85115, mean: -1.93500
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36678, current rewards: -2634.85115, mean: -1.93739
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36675, current rewards: -2734.85115, mean: -1.93961
[32m[0906 13-50-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36672, current rewards: -2834.85115, mean: -1.94168
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36668, current rewards: -2934.85115, mean: -1.94361
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36660, current rewards: -3034.85115, mean: -1.94542
[32m[0906 13-51-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36657, current rewards: -3134.85115, mean: -1.94711
[32m[0906 13-51-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36653, current rewards: -3234.85115, mean: -1.94871
[32m[0906 13-51-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36648, current rewards: -3334.85115, mean: -1.95021
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36645, current rewards: -3434.85115, mean: -1.95162
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36644, current rewards: -3534.85115, mean: -1.95296
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36636, current rewards: -3634.85115, mean: -1.95422
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36617, current rewards: -3734.85115, mean: -1.95542
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36605, current rewards: -3834.85115, mean: -1.95656
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36589, current rewards: -3934.85115, mean: -1.95764
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36584, current rewards: -4034.85115, mean: -1.95867
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36575, current rewards: -4134.85115, mean: -1.95965
[32m[0906 13-54-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36572, current rewards: -4234.85115, mean: -1.96058
[32m[0906 13-54-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36568, current rewards: -4334.85115, mean: -1.96147
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36566, current rewards: -4434.85115, mean: -1.96232
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36567, current rewards: -4534.85115, mean: -1.96314
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36563, current rewards: -4634.85115, mean: -1.96392
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36566, current rewards: -4734.85115, mean: -1.96467
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36566, current rewards: -4834.85115, mean: -1.96539
[32m[0906 13-56-42 @Agent.py:117][0m Average action selection time: 0.3656
[32m[0906 13-56-42 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-56-42 @MBExp.py:227][0m Rewards obtained: [-4914.851146353496], Lows: [2460], Highs: [0], Total time: 914.670083
[32m[0906 13-56-47 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-47 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35965, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35827, current rewards: -36.95974, mean: -0.61600
[32m[0906 13-57-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35815, current rewards: -15.36499, mean: -0.13968
[32m[0906 13-57-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35792, current rewards: 3.01621, mean: 0.01885
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35781, current rewards: 21.43434, mean: 0.10207
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35835, current rewards: 39.84479, mean: 0.15325
[32m[0906 13-58-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35892, current rewards: 58.22689, mean: 0.18783
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35950, current rewards: 76.61795, mean: 0.21283
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35994, current rewards: 88.42846, mean: 0.21568
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36024, current rewards: 100.56263, mean: 0.21861
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36043, current rewards: 112.70093, mean: 0.22098
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36066, current rewards: 124.85543, mean: 0.22296
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36057, current rewards: 137.00396, mean: 0.22460
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36063, current rewards: 149.14980, mean: 0.22598
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36083, current rewards: 155.09452, mean: 0.21844
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36087, current rewards: 141.17570, mean: 0.18576
[32m[0906 14-01-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36066, current rewards: 145.43371, mean: 0.17955
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36060, current rewards: 149.70679, mean: 0.17408
[32m[0906 14-02-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36047, current rewards: 153.98459, mean: 0.16921
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36039, current rewards: 158.26455, mean: 0.16486
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36027, current rewards: 162.54369, mean: 0.16093
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36015, current rewards: 166.81761, mean: 0.15738
[32m[0906 14-03-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36028, current rewards: 171.09443, mean: 0.15414
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36038, current rewards: 175.37204, mean: 0.15118
[32m[0906 14-04-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36064, current rewards: 130.59290, mean: 0.10793
[32m[0906 14-04-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36097, current rewards: 106.93800, mean: 0.08487
[32m[0906 14-04-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36115, current rewards: 137.99133, mean: 0.10534
[32m[0906 14-04-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36123, current rewards: 173.24346, mean: 0.12738
[32m[0906 14-05-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36130, current rewards: 208.41534, mean: 0.14781
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36121, current rewards: 243.63359, mean: 0.16687
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36109, current rewards: 278.80810, mean: 0.18464
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36096, current rewards: 314.01888, mean: 0.20129
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36084, current rewards: 343.41238, mean: 0.21330
[32m[0906 14-06-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36077, current rewards: 340.34941, mean: 0.20503
[32m[0906 14-07-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36070, current rewards: 337.48841, mean: 0.19736
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36087, current rewards: 342.53326, mean: 0.19462
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36100, current rewards: 347.59758, mean: 0.19204
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36113, current rewards: 352.65510, mean: 0.18960
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36108, current rewards: 357.71419, mean: 0.18728
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36099, current rewards: 362.77130, mean: 0.18509
[32m[0906 14-08-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36084, current rewards: 367.76296, mean: 0.18297
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36082, current rewards: 371.10988, mean: 0.18015
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36077, current rewards: 374.55994, mean: 0.17752
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36071, current rewards: 378.02551, mean: 0.17501
[32m[0906 14-10-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36067, current rewards: 381.49003, mean: 0.17262
[32m[0906 14-10-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36066, current rewards: 363.49746, mean: 0.16084
[32m[0906 14-10-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36072, current rewards: 367.47898, mean: 0.15908
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36076, current rewards: 371.33536, mean: 0.15735
[32m[0906 14-11-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36091, current rewards: 375.20058, mean: 0.15568
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36105, current rewards: 378.68367, mean: 0.15394
[32m[0906 14-11-50 @Agent.py:117][0m Average action selection time: 0.3611
[32m[0906 14-11-50 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-11-50 @MBExp.py:227][0m Rewards obtained: [381.4382623825608], Lows: [50], Highs: [88], Total time: 1818.168364
[32m[0906 14-11-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-57 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36441, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-12-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36212, current rewards: -11.98744, mean: -0.19979
[32m[0906 14-12-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36152, current rewards: -2.17452, mean: -0.01977
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36012, current rewards: 7.63522, mean: 0.04772
[32m[0906 14-13-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36029, current rewards: 17.46364, mean: 0.08316
[32m[0906 14-13-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35984, current rewards: 27.27956, mean: 0.10492
[32m[0906 14-13-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35946, current rewards: 37.09850, mean: 0.11967
[32m[0906 14-14-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35925, current rewards: 48.20615, mean: 0.13391
[32m[0906 14-14-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35920, current rewards: 47.83142, mean: 0.11666
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35897, current rewards: -20.08647, mean: -0.04367
[32m[0906 14-15-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35881, current rewards: -85.29361, mean: -0.16724
[32m[0906 14-15-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35870, current rewards: -156.15534, mean: -0.27885
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35858, current rewards: -212.70278, mean: -0.34869
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35866, current rewards: -286.63281, mean: -0.43429
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35867, current rewards: -361.08887, mean: -0.50858
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35882, current rewards: -458.29508, mean: -0.60302
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35903, current rewards: -558.29508, mean: -0.68925
[32m[0906 14-17-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35930, current rewards: -658.29508, mean: -0.76546
[32m[0906 14-17-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35954, current rewards: -758.29508, mean: -0.83329
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35969, current rewards: -858.29508, mean: -0.89406
[32m[0906 14-18-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35987, current rewards: -958.29508, mean: -0.94881
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36001, current rewards: -1016.04015, mean: -0.95853
[32m[0906 14-18-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36005, current rewards: -1116.04015, mean: -1.00544
[32m[0906 14-18-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36008, current rewards: -1207.97770, mean: -1.04136
[32m[0906 14-19-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35990, current rewards: -1198.30719, mean: -0.99034
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35976, current rewards: -1208.38599, mean: -0.95904
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35961, current rewards: -1215.46890, mean: -0.92784
[32m[0906 14-20-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35957, current rewards: -1209.30642, mean: -0.88920
[32m[0906 14-20-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35949, current rewards: -1203.16740, mean: -0.85331
[32m[0906 14-20-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35936, current rewards: -1197.03049, mean: -0.81988
[32m[0906 14-21-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35924, current rewards: -1190.88610, mean: -0.78867
[32m[0906 14-21-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35916, current rewards: -1184.74099, mean: -0.75945
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35905, current rewards: -1220.10138, mean: -0.75783
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35898, current rewards: -1300.72863, mean: -0.78357
[32m[0906 14-22-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35891, current rewards: -1400.72863, mean: -0.81914
[32m[0906 14-22-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35884, current rewards: -1500.72863, mean: -0.85269
[32m[0906 14-22-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35876, current rewards: -1600.72863, mean: -0.88438
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35869, current rewards: -1698.35662, mean: -0.91309
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35860, current rewards: -1798.35662, mean: -0.94155
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35864, current rewards: -1898.35662, mean: -0.96855
[32m[0906 14-23-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35859, current rewards: -1979.49579, mean: -0.98482
[32m[0906 14-24-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35866, current rewards: -1968.50941, mean: -0.95559
[32m[0906 14-24-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35872, current rewards: -1956.24766, mean: -0.92713
[32m[0906 14-24-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35874, current rewards: -1943.98037, mean: -0.89999
[32m[0906 14-25-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35871, current rewards: -1931.69937, mean: -0.87407
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35861, current rewards: -1919.44542, mean: -0.84931
[32m[0906 14-25-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35857, current rewards: -1907.16109, mean: -0.82561
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35843, current rewards: -1894.90811, mean: -0.80293
[32m[0906 14-26-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35838, current rewards: -1884.26344, mean: -0.78185
[32m[0906 14-26-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35835, current rewards: -1880.51383, mean: -0.76444
[32m[0906 14-26-54 @Agent.py:117][0m Average action selection time: 0.3583
[32m[0906 14-26-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-26-54 @MBExp.py:227][0m Rewards obtained: [-1877.32361649701], Lows: [1064], Highs: [61], Total time: 2714.6376410000003
[32m[0906 14-27-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-02 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-27-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35988, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-27-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35845, current rewards: -26.31151, mean: -0.43853
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35741, current rewards: -7.83671, mean: -0.07124
[32m[0906 14-28-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35701, current rewards: 10.50319, mean: 0.06564
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35687, current rewards: 28.81267, mean: 0.13720
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35671, current rewards: 47.14788, mean: 0.18134
[32m[0906 14-28-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35652, current rewards: 65.46399, mean: 0.21117
[32m[0906 14-29-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35640, current rewards: 52.03553, mean: 0.14454
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35640, current rewards: 61.53206, mean: 0.15008
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35630, current rewards: 70.89551, mean: 0.15412
[32m[0906 14-30-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35672, current rewards: 80.25962, mean: 0.15737
[32m[0906 14-30-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35724, current rewards: 89.63261, mean: 0.16006
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35710, current rewards: 99.01851, mean: 0.16233
[32m[0906 14-30-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35698, current rewards: 108.40824, mean: 0.16425
[32m[0906 14-31-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35691, current rewards: 92.88311, mean: 0.13082
[32m[0906 14-31-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35684, current rewards: 102.31664, mean: 0.13463
[32m[0906 14-31-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35671, current rewards: 111.69777, mean: 0.13790
[32m[0906 14-32-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35666, current rewards: 121.09540, mean: 0.14081
[32m[0906 14-32-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35655, current rewards: 130.47125, mean: 0.14338
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35638, current rewards: 139.86483, mean: 0.14569
[32m[0906 14-33-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35636, current rewards: 91.18769, mean: 0.09028
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35635, current rewards: 43.06321, mean: 0.04063
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35630, current rewards: 1.03444, mean: 0.00093
[32m[0906 14-33-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35626, current rewards: -28.63502, mean: -0.02469
[32m[0906 14-34-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35620, current rewards: -17.74430, mean: -0.01466
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35614, current rewards: -5.99975, mean: -0.00476
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35613, current rewards: 5.72494, mean: 0.00437
[32m[0906 14-35-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35614, current rewards: 17.45842, mean: 0.01284
[32m[0906 14-35-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35615, current rewards: 29.17769, mean: 0.02069
[32m[0906 14-35-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35615, current rewards: 14.05183, mean: 0.00962
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35616, current rewards: 21.92063, mean: 0.01452
[32m[0906 14-36-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35618, current rewards: 29.48335, mean: 0.01890
[32m[0906 14-36-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35619, current rewards: 38.33136, mean: 0.02381
[32m[0906 14-36-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35620, current rewards: 46.91570, mean: 0.02826
[32m[0906 14-37-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35624, current rewards: 55.49230, mean: 0.03245
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35624, current rewards: 64.04768, mean: 0.03639
[32m[0906 14-37-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35623, current rewards: 72.61647, mean: 0.04012
[32m[0906 14-38-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35624, current rewards: 16.39063, mean: 0.00881
[32m[0906 14-38-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35622, current rewards: -83.60937, mean: -0.04377
[32m[0906 14-38-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35623, current rewards: -183.60937, mean: -0.09368
[32m[0906 14-38-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35611, current rewards: -283.60937, mean: -0.14110
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35619, current rewards: -383.60937, mean: -0.18622
[32m[0906 14-39-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35629, current rewards: -483.60937, mean: -0.22920
[32m[0906 14-39-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35640, current rewards: -583.60937, mean: -0.27019
[32m[0906 14-40-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35638, current rewards: -683.60937, mean: -0.30933
[32m[0906 14-40-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35636, current rewards: -783.60937, mean: -0.34673
[32m[0906 14-40-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35645, current rewards: -883.60937, mean: -0.38251
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35634, current rewards: -954.29881, mean: -0.40436
[32m[0906 14-41-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35634, current rewards: -948.71231, mean: -0.39366
[32m[0906 14-41-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35634, current rewards: -943.70066, mean: -0.38362
[32m[0906 14-41-54 @Agent.py:117][0m Average action selection time: 0.3563
[32m[0906 14-41-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-41-54 @MBExp.py:227][0m Rewards obtained: [-939.6742447064935], Lows: [633], Highs: [93], Total time: 3606.125884
[32m[0906 14-42-05 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-05 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-42-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35820, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-42-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35572, current rewards: -37.87213, mean: -0.63120
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35554, current rewards: -65.73562, mean: -0.59760
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35504, current rewards: -87.22091, mean: -0.54513
[32m[0906 14-43-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35472, current rewards: -106.66452, mean: -0.50793
[32m[0906 14-43-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35476, current rewards: -127.18229, mean: -0.48916
[32m[0906 14-43-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35467, current rewards: -156.09346, mean: -0.50353
[32m[0906 14-44-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35441, current rewards: -187.14378, mean: -0.51984
[32m[0906 14-44-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35427, current rewards: -224.33474, mean: -0.54716
[32m[0906 14-44-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35451, current rewards: -269.17184, mean: -0.58516
[32m[0906 14-45-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35461, current rewards: -296.99317, mean: -0.58234
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35489, current rewards: -318.46223, mean: -0.56868
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35503, current rewards: -337.82863, mean: -0.55382
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35509, current rewards: -358.27511, mean: -0.54284
[32m[0906 14-46-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35545, current rewards: -386.09556, mean: -0.54380
[32m[0906 14-46-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35579, current rewards: -410.55607, mean: -0.54021
[32m[0906 14-46-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35617, current rewards: -425.44240, mean: -0.52524
[32m[0906 14-47-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35664, current rewards: -417.67507, mean: -0.48567
[32m[0906 14-47-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35684, current rewards: -413.21632, mean: -0.45408
[32m[0906 14-47-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35699, current rewards: -408.75757, mean: -0.42579
[32m[0906 14-48-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35715, current rewards: -404.29883, mean: -0.40030
[32m[0906 14-48-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35730, current rewards: -399.84008, mean: -0.37721
[32m[0906 14-48-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35743, current rewards: -395.38134, mean: -0.35620
[32m[0906 14-49-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35761, current rewards: -392.15254, mean: -0.33806
[32m[0906 14-49-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35781, current rewards: -389.26645, mean: -0.32171
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35806, current rewards: -392.72670, mean: -0.31169
[32m[0906 14-49-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35835, current rewards: -442.72670, mean: -0.33796
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35860, current rewards: -492.72670, mean: -0.36230
[32m[0906 14-50-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35888, current rewards: -542.72670, mean: -0.38491
[32m[0906 14-50-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35913, current rewards: -592.72670, mean: -0.40598
[32m[0906 14-51-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35947, current rewards: -642.72670, mean: -0.42565
[32m[0906 14-51-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35961, current rewards: -692.72670, mean: -0.44406
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35963, current rewards: -742.72670, mean: -0.46132
[32m[0906 14-52-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35963, current rewards: -792.72670, mean: -0.47755
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35960, current rewards: -842.72670, mean: -0.49282
[32m[0906 14-52-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35945, current rewards: -892.72670, mean: -0.50723
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35929, current rewards: -942.72670, mean: -0.52084
[32m[0906 14-53-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35914, current rewards: -992.72670, mean: -0.53372
[32m[0906 14-53-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35898, current rewards: -1042.72670, mean: -0.54593
[32m[0906 14-53-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35891, current rewards: -1092.72670, mean: -0.55751
[32m[0906 14-54-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35874, current rewards: -1142.72670, mean: -0.56852
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35876, current rewards: -1192.72670, mean: -0.57899
[32m[0906 14-54-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35877, current rewards: -1242.72670, mean: -0.58897
[32m[0906 14-55-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35878, current rewards: -1292.72670, mean: -0.59848
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35854, current rewards: -1342.72670, mean: -0.60757
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35833, current rewards: -1392.72670, mean: -0.61625
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35837, current rewards: -1442.72670, mean: -0.62456
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35827, current rewards: -1492.72670, mean: -0.63251
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35832, current rewards: -1542.72670, mean: -0.64014
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35836, current rewards: -1592.72670, mean: -0.64745
[32m[0906 14-57-01 @Agent.py:117][0m Average action selection time: 0.3584
[32m[0906 14-57-01 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-57-01 @MBExp.py:227][0m Rewards obtained: [-1632.7266996122867], Lows: [20], Highs: [1657], Total time: 4502.707161
[32m[0906 14-57-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-57-15 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-57-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36037, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-57-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36522, current rewards: -71.20967, mean: -1.18683
[32m[0906 14-57-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36523, current rewards: -120.96359, mean: -1.09967
[32m[0906 14-58-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36241, current rewards: -166.35228, mean: -1.03970
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36078, current rewards: -224.35669, mean: -1.06837
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36008, current rewards: -267.67605, mean: -1.02952
[32m[0906 14-59-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35930, current rewards: -319.36035, mean: -1.03019
[32m[0906 14-59-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35885, current rewards: -373.17365, mean: -1.03659
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35892, current rewards: -415.60797, mean: -1.01368
[32m[0906 15-00-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35885, current rewards: -448.05116, mean: -0.97402
[32m[0906 15-00-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35910, current rewards: -489.44536, mean: -0.95970
[32m[0906 15-00-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35935, current rewards: -533.07000, mean: -0.95191
[32m[0906 15-00-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35960, current rewards: -566.14077, mean: -0.92810
[32m[0906 15-01-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35990, current rewards: -613.88392, mean: -0.93013
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36006, current rewards: -651.60806, mean: -0.91776
[32m[0906 15-01-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35989, current rewards: -689.14368, mean: -0.90677
[32m[0906 15-02-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35970, current rewards: -737.15063, mean: -0.91006
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35950, current rewards: -770.59431, mean: -0.89604
[32m[0906 15-02-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35943, current rewards: -814.39201, mean: -0.89494
[32m[0906 15-03-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35931, current rewards: -864.46086, mean: -0.90048
[32m[0906 15-03-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35915, current rewards: -892.78605, mean: -0.88395
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35906, current rewards: -889.08211, mean: -0.83876
[32m[0906 15-03-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35906, current rewards: -882.53019, mean: -0.79507
[32m[0906 15-04-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35940, current rewards: -878.60402, mean: -0.75742
[32m[0906 15-04-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35972, current rewards: -874.61874, mean: -0.72283
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36000, current rewards: -870.63347, mean: -0.69098
[32m[0906 15-05-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36024, current rewards: -909.11922, mean: -0.69398
[32m[0906 15-05-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36045, current rewards: -930.30812, mean: -0.68405
[32m[0906 15-05-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36033, current rewards: -941.17370, mean: -0.66750
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36024, current rewards: -941.83955, mean: -0.64510
[32m[0906 15-06-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36026, current rewards: -940.97815, mean: -0.62316
[32m[0906 15-06-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36012, current rewards: -942.14883, mean: -0.60394
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36000, current rewards: -941.25291, mean: -0.58463
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35990, current rewards: -950.26858, mean: -0.57245
[32m[0906 15-07-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35985, current rewards: -1035.07779, mean: -0.60531
[32m[0906 15-07-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35984, current rewards: -1135.07779, mean: -0.64493
[32m[0906 15-08-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35981, current rewards: -1235.07779, mean: -0.68236
[32m[0906 15-08-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35978, current rewards: -1335.07779, mean: -0.71778
[32m[0906 15-08-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35985, current rewards: -1430.71890, mean: -0.74907
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35989, current rewards: -1455.69705, mean: -0.74270
[32m[0906 15-09-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35977, current rewards: -1496.50931, mean: -0.74453
[32m[0906 15-09-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35983, current rewards: -1540.34926, mean: -0.74774
[32m[0906 15-09-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35982, current rewards: -1566.53371, mean: -0.74243
[32m[0906 15-10-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35981, current rewards: -1611.63016, mean: -0.74613
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35962, current rewards: -1651.18934, mean: -0.74714
[32m[0906 15-10-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35955, current rewards: -1677.40318, mean: -0.74221
[32m[0906 15-11-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35956, current rewards: -1727.27159, mean: -0.74774
[32m[0906 15-11-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35940, current rewards: -1763.09913, mean: -0.74708
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35942, current rewards: -1789.86966, mean: -0.74268
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35943, current rewards: -1844.26513, mean: -0.74970
[32m[0906 15-12-14 @Agent.py:117][0m Average action selection time: 0.3595
[32m[0906 15-12-14 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-12-14 @MBExp.py:227][0m Rewards obtained: [-1875.210569069173], Lows: [992], Highs: [77], Total time: 5402.075393
[32m[0906 15-12-30 @MBExp.py:144][0m ####################################################################
[32m[0906 15-12-30 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 15-12-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36023, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-12-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36058, current rewards: -45.51555, mean: -0.75859
[32m[0906 15-13-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36022, current rewards: -29.80017, mean: -0.27091
[32m[0906 15-13-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36151, current rewards: -13.22598, mean: -0.08266
[32m[0906 15-13-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36170, current rewards: 3.37792, mean: 0.01609
[32m[0906 15-14-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36108, current rewards: 20.01445, mean: 0.07698
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36058, current rewards: 9.45714, mean: 0.03051
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36028, current rewards: 21.77997, mean: 0.06050
[32m[0906 15-14-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35998, current rewards: 34.21032, mean: 0.08344
[32m[0906 15-15-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35969, current rewards: 46.59209, mean: 0.10129
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35960, current rewards: 58.98426, mean: 0.11566
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35968, current rewards: 71.40326, mean: 0.12751
[32m[0906 15-16-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36006, current rewards: 78.96074, mean: 0.12944
[32m[0906 15-16-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36033, current rewards: 69.09075, mean: 0.10468
[32m[0906 15-16-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36067, current rewards: 72.67100, mean: 0.10235
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36118, current rewards: 76.28329, mean: 0.10037
[32m[0906 15-17-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36150, current rewards: 79.89664, mean: 0.09864
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36149, current rewards: 83.50981, mean: 0.09710
[32m[0906 15-17-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36140, current rewards: 87.12258, mean: 0.09574
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36148, current rewards: 90.73310, mean: 0.09451
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36147, current rewards: 94.34970, mean: 0.09342
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36136, current rewards: 100.43175, mean: 0.09475
[32m[0906 15-19-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36117, current rewards: 64.65207, mean: 0.05825
[32m[0906 15-19-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36101, current rewards: 72.49808, mean: 0.06250
[32m[0906 15-19-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36083, current rewards: 79.64095, mean: 0.06582
[32m[0906 15-20-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36070, current rewards: 86.77435, mean: 0.06887
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36064, current rewards: 93.91165, mean: 0.07169
[32m[0906 15-20-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36061, current rewards: 14.78557, mean: 0.01087
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36052, current rewards: 28.87316, mean: 0.02048
[32m[0906 15-21-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36044, current rewards: 40.80762, mean: 0.02795
[32m[0906 15-21-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36034, current rewards: 52.74510, mean: 0.03493
[32m[0906 15-21-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36025, current rewards: 64.66768, mean: 0.04145
[32m[0906 15-22-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36019, current rewards: 76.60510, mean: 0.04758
[32m[0906 15-22-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36016, current rewards: 88.53974, mean: 0.05334
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36008, current rewards: 100.48177, mean: 0.05876
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36006, current rewards: 88.31128, mean: 0.05018
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36000, current rewards: 100.30404, mean: 0.05542
[32m[0906 15-23-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35998, current rewards: 107.14648, mean: 0.05761
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35990, current rewards: 111.25207, mean: 0.05825
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35986, current rewards: 117.12450, mean: 0.05976
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35961, current rewards: 122.98027, mean: 0.06118
[32m[0906 15-24-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35959, current rewards: 128.84351, mean: 0.06255
[32m[0906 15-25-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35959, current rewards: 134.70358, mean: 0.06384
[32m[0906 15-25-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35953, current rewards: 140.55774, mean: 0.06507
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35929, current rewards: 146.41657, mean: 0.06625
[32m[0906 15-26-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35918, current rewards: 152.27857, mean: 0.06738
[32m[0906 15-26-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35911, current rewards: 77.68443, mean: 0.03363
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35902, current rewards: 50.55844, mean: 0.02142
[32m[0906 15-26-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35905, current rewards: 63.57588, mean: 0.02638
[32m[0906 15-27-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35908, current rewards: 76.39895, mean: 0.03106
[32m[0906 15-27-28 @Agent.py:117][0m Average action selection time: 0.3591
[32m[0906 15-27-28 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-27-28 @MBExp.py:227][0m Rewards obtained: [86.65952394611598], Lows: [135], Highs: [73], Total time: 6300.509509
[32m[0906 15-27-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-27-46 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 15-27-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36049, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36016, current rewards: -60.00000, mean: -1.00000
[32m[0906 15-28-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36032, current rewards: -110.00000, mean: -1.00000
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36039, current rewards: -160.00000, mean: -1.00000
[32m[0906 15-29-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36002, current rewards: -210.00000, mean: -1.00000
[32m[0906 15-29-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35983, current rewards: -229.37041, mean: -0.88219
[32m[0906 15-29-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35967, current rewards: -226.68109, mean: -0.73123
[32m[0906 15-29-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35951, current rewards: -236.63781, mean: -0.65733
[32m[0906 15-30-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35962, current rewards: -286.63781, mean: -0.69912
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35947, current rewards: -336.63781, mean: -0.73182
[32m[0906 15-30-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35930, current rewards: -386.63781, mean: -0.75811
[32m[0906 15-31-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35936, current rewards: -436.63781, mean: -0.77971
[32m[0906 15-31-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35948, current rewards: -465.50863, mean: -0.76313
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35974, current rewards: -515.50863, mean: -0.78107
[32m[0906 15-32-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35979, current rewards: -565.50863, mean: -0.79649
[32m[0906 15-32-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36008, current rewards: -615.50863, mean: -0.80988
[32m[0906 15-32-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36035, current rewards: -665.50863, mean: -0.82162
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36061, current rewards: -715.50863, mean: -0.83199
[32m[0906 15-33-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36085, current rewards: -765.50863, mean: -0.84122
[32m[0906 15-33-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36103, current rewards: -815.50863, mean: -0.84949
[32m[0906 15-33-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36111, current rewards: -865.50863, mean: -0.85694
[32m[0906 15-34-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36095, current rewards: -915.50863, mean: -0.86369
[32m[0906 15-34-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36085, current rewards: -945.47035, mean: -0.85178
[32m[0906 15-34-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36071, current rewards: -995.47035, mean: -0.85816
[32m[0906 15-35-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36068, current rewards: -1045.47035, mean: -0.86403
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36044, current rewards: -1095.47035, mean: -0.86942
[32m[0906 15-35-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36035, current rewards: -1145.47035, mean: -0.87440
[32m[0906 15-35-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36022, current rewards: -1192.24235, mean: -0.87665
[32m[0906 15-36-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36009, current rewards: -1188.80782, mean: -0.84313
[32m[0906 15-36-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35999, current rewards: -1185.55691, mean: -0.81203
[32m[0906 15-36-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35990, current rewards: -1182.53530, mean: -0.78314
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35983, current rewards: -1179.46109, mean: -0.75606
[32m[0906 15-37-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35978, current rewards: -1176.39234, mean: -0.73068
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35979, current rewards: -1173.32264, mean: -0.70682
[32m[0906 15-38-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35967, current rewards: -1170.25133, mean: -0.68436
[32m[0906 15-38-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35946, current rewards: -1167.18171, mean: -0.66317
[32m[0906 15-38-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35925, current rewards: -1164.11077, mean: -0.64316
[32m[0906 15-38-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35878, current rewards: -1202.42385, mean: -0.64646
[32m[0906 15-39-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35764, current rewards: -1199.56819, mean: -0.62805
[32m[0906 15-39-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35650, current rewards: -1195.98745, mean: -0.61020
[32m[0906 15-39-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35535, current rewards: -1192.40671, mean: -0.59324
[32m[0906 15-39-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35438, current rewards: -1188.82597, mean: -0.57710
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35346, current rewards: -1185.24524, mean: -0.56173
[32m[0906 15-40-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35254, current rewards: -1181.66450, mean: -0.54707
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35147, current rewards: -1178.08376, mean: -0.53307
[32m[0906 15-40-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35062, current rewards: -1174.50302, mean: -0.51969
[32m[0906 15-41-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34982, current rewards: -1172.13091, mean: -0.50742
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34908, current rewards: -1222.13091, mean: -0.51785
[32m[0906 15-41-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34843, current rewards: -1272.13091, mean: -0.52786
[32m[0906 15-42-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34779, current rewards: -1322.13091, mean: -0.53745
[32m[0906 15-42-15 @Agent.py:117][0m Average action selection time: 0.3473
[32m[0906 15-42-15 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-42-15 @MBExp.py:227][0m Rewards obtained: [-1362.1309081146048], Lows: [20], Highs: [1392], Total time: 7169.345090000001
[32m[0906 15-42-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-42-32 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 15-42-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31929, current rewards: 0.72046, mean: 0.07205
[32m[0906 15-42-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31764, current rewards: 0.44501, mean: 0.00742
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31744, current rewards: 7.63853, mean: 0.06944
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31752, current rewards: 14.84055, mean: 0.09275
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31727, current rewards: 22.03937, mean: 0.10495
[32m[0906 15-43-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31730, current rewards: -1.11564, mean: -0.00429
[32m[0906 15-44-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31770, current rewards: 8.42733, mean: 0.02718
[32m[0906 15-44-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31751, current rewards: 15.99925, mean: 0.04444
[32m[0906 15-44-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31753, current rewards: 23.56583, mean: 0.05748
[32m[0906 15-44-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31742, current rewards: 31.13770, mean: 0.06769
[32m[0906 15-45-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31731, current rewards: 18.22460, mean: 0.03573
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31732, current rewards: 26.28009, mean: 0.04693
[32m[0906 15-45-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31726, current rewards: 34.12917, mean: 0.05595
[32m[0906 15-46-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31720, current rewards: 42.51651, mean: 0.06442
[32m[0906 15-46-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31721, current rewards: 52.30350, mean: 0.07367
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31713, current rewards: 60.98026, mean: 0.08024
[32m[0906 15-46-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31709, current rewards: 69.63937, mean: 0.08597
[32m[0906 15-47-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31710, current rewards: 78.29827, mean: 0.09104
[32m[0906 15-47-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31702, current rewards: 86.95428, mean: 0.09555
[32m[0906 15-47-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31700, current rewards: 92.10231, mean: 0.09594
[32m[0906 15-47-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31706, current rewards: 75.09004, mean: 0.07435
[32m[0906 15-48-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31702, current rewards: 78.28861, mean: 0.07386
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31695, current rewards: 81.35274, mean: 0.07329
[32m[0906 15-48-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31692, current rewards: 86.05083, mean: 0.07418
[32m[0906 15-48-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31693, current rewards: 90.83203, mean: 0.07507
[32m[0906 15-49-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31690, current rewards: 95.57561, mean: 0.07585
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31687, current rewards: 100.32466, mean: 0.07658
[32m[0906 15-49-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31686, current rewards: 84.12586, mean: 0.06186
[32m[0906 15-49-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31682, current rewards: 67.54634, mean: 0.04791
[32m[0906 15-50-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31681, current rewards: 73.31870, mean: 0.05022
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31685, current rewards: 87.61564, mean: 0.05802
[32m[0906 15-50-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31682, current rewards: 93.81626, mean: 0.06014
[32m[0906 15-51-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31684, current rewards: 100.02669, mean: 0.06213
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31682, current rewards: 106.23563, mean: 0.06400
[32m[0906 15-51-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31679, current rewards: 112.42926, mean: 0.06575
[32m[0906 15-51-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31677, current rewards: 118.64591, mean: 0.06741
[32m[0906 15-52-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31675, current rewards: 124.85601, mean: 0.06898
[32m[0906 15-52-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31672, current rewards: 129.97383, mean: 0.06988
[32m[0906 15-52-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31673, current rewards: 81.88725, mean: 0.04287
[32m[0906 15-52-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31665, current rewards: 25.50641, mean: 0.01301
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31645, current rewards: -30.85493, mean: -0.01535
[32m[0906 15-53-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31648, current rewards: -72.61496, mean: -0.03525
[32m[0906 15-53-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31648, current rewards: -136.90397, mean: -0.06488
[32m[0906 15-53-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31643, current rewards: -127.28351, mean: -0.05893
[32m[0906 15-54-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31614, current rewards: -119.59496, mean: -0.05412
[32m[0906 15-54-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31607, current rewards: -112.04122, mean: -0.04958
[32m[0906 15-54-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31601, current rewards: -105.31862, mean: -0.04559
[32m[0906 15-54-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31593, current rewards: -99.16164, mean: -0.04202
[32m[0906 15-55-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31595, current rewards: -90.95288, mean: -0.03774
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31597, current rewards: -82.72213, mean: -0.03363
[32m[0906 15-55-43 @Agent.py:117][0m Average action selection time: 0.3160
[32m[0906 15-55-43 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-55-43 @MBExp.py:227][0m Rewards obtained: [-76.13364579592577], Lows: [179], Highs: [45], Total time: 7960.000300000001
[32m[0906 15-56-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-56-02 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 15-56-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32046, current rewards: 0.96778, mean: 0.09678
[32m[0906 15-56-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31888, current rewards: -73.59732, mean: -1.22662
[32m[0906 15-56-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31810, current rewards: -173.59732, mean: -1.57816
[32m[0906 15-56-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31788, current rewards: -273.59732, mean: -1.70998
[32m[0906 15-57-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31781, current rewards: -373.59732, mean: -1.77903
[32m[0906 15-57-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31783, current rewards: -473.59732, mean: -1.82153
[32m[0906 15-57-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31775, current rewards: -573.59732, mean: -1.85031
[32m[0906 15-57-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31757, current rewards: -673.59732, mean: -1.87110
[32m[0906 15-58-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31763, current rewards: -773.59732, mean: -1.88682
[32m[0906 15-58-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31754, current rewards: -873.59732, mean: -1.89912
[32m[0906 15-58-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31742, current rewards: -973.59732, mean: -1.90901
[32m[0906 15-59-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31723, current rewards: -999.35353, mean: -1.78456
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31703, current rewards: -992.93499, mean: -1.62776
[32m[0906 15-59-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31697, current rewards: -987.21434, mean: -1.49578
[32m[0906 15-59-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31695, current rewards: -981.60613, mean: -1.38254
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31686, current rewards: -975.90612, mean: -1.28409
[32m[0906 16-00-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31678, current rewards: -970.18953, mean: -1.19776
[32m[0906 16-00-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31674, current rewards: -964.47729, mean: -1.12149
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31666, current rewards: -1000.28321, mean: -1.09921
[32m[0906 16-01-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31663, current rewards: -991.63389, mean: -1.03295
[32m[0906 16-01-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31658, current rewards: -982.61311, mean: -0.97288
[32m[0906 16-01-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31651, current rewards: -971.85642, mean: -0.91685
[32m[0906 16-01-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31643, current rewards: -959.93428, mean: -0.86481
[32m[0906 16-02-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31639, current rewards: -949.28382, mean: -0.81835
[32m[0906 16-02-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31642, current rewards: -938.67460, mean: -0.77576
[32m[0906 16-02-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31638, current rewards: -928.04005, mean: -0.73654
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31634, current rewards: -917.40063, mean: -0.70031
[32m[0906 16-03-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31629, current rewards: -926.17396, mean: -0.68101
[32m[0906 16-03-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31625, current rewards: -928.68550, mean: -0.65864
[32m[0906 16-03-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31625, current rewards: -925.75116, mean: -0.63408
[32m[0906 16-04-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31619, current rewards: -922.89934, mean: -0.61119
[32m[0906 16-04-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31615, current rewards: -919.93600, mean: -0.58970
[32m[0906 16-04-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31612, current rewards: -916.97226, mean: -0.56955
[32m[0906 16-04-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31607, current rewards: -934.99064, mean: -0.56325
[32m[0906 16-05-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31602, current rewards: -930.95447, mean: -0.54442
[32m[0906 16-05-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31599, current rewards: -926.85047, mean: -0.52662
[32m[0906 16-05-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31602, current rewards: -922.74287, mean: -0.50980
[32m[0906 16-05-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31598, current rewards: -918.62839, mean: -0.49389
[32m[0906 16-06-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31597, current rewards: -914.52022, mean: -0.47881
[32m[0906 16-06-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31588, current rewards: -910.41161, mean: -0.46450
[32m[0906 16-06-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31570, current rewards: -906.30069, mean: -0.45090
[32m[0906 16-06-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31574, current rewards: -902.19245, mean: -0.43796
[32m[0906 16-07-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31574, current rewards: -898.08095, mean: -0.42563
[32m[0906 16-07-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31565, current rewards: -893.97329, mean: -0.41388
[32m[0906 16-07-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31534, current rewards: -931.69920, mean: -0.42158
[32m[0906 16-07-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31531, current rewards: -926.93349, mean: -0.41015
[32m[0906 16-08-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31525, current rewards: -921.39509, mean: -0.39887
[32m[0906 16-08-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31520, current rewards: -916.39094, mean: -0.38830
[32m[0906 16-08-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31528, current rewards: -934.48694, mean: -0.38775
[32m[0906 16-08-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31533, current rewards: -946.93348, mean: -0.38493
[32m[0906 16-09-11 @Agent.py:117][0m Average action selection time: 0.3154
[32m[0906 16-09-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-09-11 @MBExp.py:227][0m Rewards obtained: [-938.2153724325583], Lows: [553], Highs: [61], Total time: 8749.001982
[32m[0906 16-09-32 @MBExp.py:144][0m ####################################################################
[32m[0906 16-09-32 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 16-09-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32134, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-09-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31786, current rewards: -45.81622, mean: -0.76360
[32m[0906 16-10-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31725, current rewards: -37.70302, mean: -0.34275
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31744, current rewards: -29.13140, mean: -0.18207
[32m[0906 16-10-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31746, current rewards: -57.19777, mean: -0.27237
[32m[0906 16-10-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31738, current rewards: -39.38621, mean: -0.15149
[32m[0906 16-11-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31744, current rewards: -18.95291, mean: -0.06114
[32m[0906 16-11-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31766, current rewards: 1.43514, mean: 0.00399
[32m[0906 16-11-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31764, current rewards: 21.76839, mean: 0.05309
[32m[0906 16-11-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31750, current rewards: 42.16177, mean: 0.09166
[32m[0906 16-12-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31736, current rewards: 62.53017, mean: 0.12261
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31726, current rewards: 57.54978, mean: 0.10277
[32m[0906 16-12-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31718, current rewards: 59.99039, mean: 0.09834
[32m[0906 16-13-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31704, current rewards: 65.88766, mean: 0.09983
[32m[0906 16-13-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31698, current rewards: 75.25823, mean: 0.10600
[32m[0906 16-13-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31695, current rewards: 84.65092, mean: 0.11138
[32m[0906 16-13-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31695, current rewards: 94.04112, mean: 0.11610
[32m[0906 16-14-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31685, current rewards: 103.43960, mean: 0.12028
[32m[0906 16-14-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31679, current rewards: 112.83660, mean: 0.12400
[32m[0906 16-14-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31670, current rewards: 122.23695, mean: 0.12733
[32m[0906 16-14-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31667, current rewards: 132.62082, mean: 0.13131
[32m[0906 16-15-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31660, current rewards: 143.21725, mean: 0.13511
[32m[0906 16-15-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31656, current rewards: 149.23620, mean: 0.13445
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31654, current rewards: 131.96389, mean: 0.11376
[32m[0906 16-15-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31655, current rewards: 135.51587, mean: 0.11200
[32m[0906 16-16-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31649, current rewards: 138.81071, mean: 0.11017
[32m[0906 16-16-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31645, current rewards: 142.10479, mean: 0.10848
[32m[0906 16-16-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31640, current rewards: 145.40103, mean: 0.10691
[32m[0906 16-16-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31639, current rewards: 148.75364, mean: 0.10550
[32m[0906 16-17-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31637, current rewards: 153.38022, mean: 0.10505
[32m[0906 16-17-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31635, current rewards: 156.95432, mean: 0.10394
[32m[0906 16-17-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31635, current rewards: 160.51903, mean: 0.10290
[32m[0906 16-18-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31633, current rewards: 164.08347, mean: 0.10192
[32m[0906 16-18-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31630, current rewards: 144.85967, mean: 0.08726
[32m[0906 16-18-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31632, current rewards: 129.12319, mean: 0.07551
[32m[0906 16-18-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31628, current rewards: 148.55950, mean: 0.08441
[32m[0906 16-19-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31624, current rewards: 164.79982, mean: 0.09105
[32m[0906 16-19-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31621, current rewards: 129.12510, mean: 0.06942
[32m[0906 16-19-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31619, current rewards: 93.62625, mean: 0.04902
[32m[0906 16-19-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31612, current rewards: 73.29914, mean: 0.03740
[32m[0906 16-20-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31593, current rewards: 43.42370, mean: 0.02160
[32m[0906 16-20-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31594, current rewards: 9.68145, mean: 0.00470
[32m[0906 16-20-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31592, current rewards: -9.75167, mean: -0.00462
[32m[0906 16-20-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31579, current rewards: -46.52053, mean: -0.02154
[32m[0906 16-21-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31545, current rewards: -69.62197, mean: -0.03150
[32m[0906 16-21-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31542, current rewards: -63.90433, mean: -0.02828
[32m[0906 16-21-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31532, current rewards: -58.42290, mean: -0.02529
[32m[0906 16-21-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31524, current rewards: -52.91205, mean: -0.02242
[32m[0906 16-22-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31528, current rewards: -47.42605, mean: -0.01968
[32m[0906 16-22-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31531, current rewards: -42.03652, mean: -0.01709
[32m[0906 16-22-41 @Agent.py:117][0m Average action selection time: 0.3153
[32m[0906 16-22-41 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-22-41 @MBExp.py:227][0m Rewards obtained: [-37.83527520283892], Lows: [186], Highs: [81], Total time: 9537.936378
[32m[0906 16-23-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-04 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32002, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-23-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31679, current rewards: -24.64644, mean: -0.41077
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31705, current rewards: -19.32456, mean: -0.17568
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31720, current rewards: -12.64053, mean: -0.07900
[32m[0906 16-24-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31703, current rewards: -6.19053, mean: -0.02948
[32m[0906 16-24-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31701, current rewards: -0.25525, mean: -0.00098
[32m[0906 16-24-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31695, current rewards: 5.67605, mean: 0.01831
[32m[0906 16-24-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31697, current rewards: 11.60307, mean: 0.03223
[32m[0906 16-25-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31685, current rewards: 17.53581, mean: 0.04277
[32m[0906 16-25-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31674, current rewards: 23.46916, mean: 0.05102
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31672, current rewards: 29.40372, mean: 0.05765
[32m[0906 16-26-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31658, current rewards: 35.23045, mean: 0.06291
[32m[0906 16-26-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31649, current rewards: -3.71453, mean: -0.00609
[32m[0906 16-26-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31644, current rewards: -38.34033, mean: -0.05809
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31651, current rewards: -91.79356, mean: -0.12929
[32m[0906 16-27-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31639, current rewards: -145.26962, mean: -0.19114
[32m[0906 16-27-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31637, current rewards: -192.23639, mean: -0.23733
[32m[0906 16-27-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31638, current rewards: -228.23266, mean: -0.26539
[32m[0906 16-27-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31633, current rewards: -263.80563, mean: -0.28990
[32m[0906 16-28-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31630, current rewards: -312.57887, mean: -0.32560
[32m[0906 16-28-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31629, current rewards: -389.15996, mean: -0.38531
[32m[0906 16-28-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31623, current rewards: -421.99640, mean: -0.39811
[32m[0906 16-28-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31617, current rewards: -504.18492, mean: -0.45422
[32m[0906 16-29-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31614, current rewards: -567.83631, mean: -0.48951
[32m[0906 16-29-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31607, current rewards: -632.56506, mean: -0.52278
[32m[0906 16-29-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31602, current rewards: -680.59243, mean: -0.54015
[32m[0906 16-29-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31597, current rewards: -753.43739, mean: -0.57514
[32m[0906 16-30-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31590, current rewards: -774.68017, mean: -0.56962
[32m[0906 16-30-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31582, current rewards: -766.36545, mean: -0.54352
[32m[0906 16-30-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31580, current rewards: -759.44368, mean: -0.52017
[32m[0906 16-31-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31575, current rewards: -752.23190, mean: -0.49817
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31572, current rewards: -745.02481, mean: -0.47758
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31567, current rewards: -737.82934, mean: -0.45828
[32m[0906 16-31-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31569, current rewards: -730.62255, mean: -0.44013
[32m[0906 16-32-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31566, current rewards: -766.43272, mean: -0.44821
[32m[0906 16-32-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31560, current rewards: -758.28986, mean: -0.43085
[32m[0906 16-32-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31560, current rewards: -749.46052, mean: -0.41407
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31558, current rewards: -776.78651, mean: -0.41763
[32m[0906 16-33-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31553, current rewards: -764.33473, mean: -0.40018
[32m[0906 16-33-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31541, current rewards: -752.30269, mean: -0.38383
[32m[0906 16-33-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31523, current rewards: -740.26038, mean: -0.36829
[32m[0906 16-33-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31524, current rewards: -728.22548, mean: -0.35351
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31526, current rewards: -716.19979, mean: -0.33943
[32m[0906 16-34-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31515, current rewards: -704.16347, mean: -0.32600
[32m[0906 16-34-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31481, current rewards: -715.69368, mean: -0.32384
[32m[0906 16-34-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31481, current rewards: -710.68700, mean: -0.31446
[32m[0906 16-35-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31469, current rewards: -703.63915, mean: -0.30461
[32m[0906 16-35-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31462, current rewards: -697.19131, mean: -0.29542
[32m[0906 16-35-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31467, current rewards: -690.75767, mean: -0.28662
[32m[0906 16-35-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31471, current rewards: -684.32947, mean: -0.27818
[32m[0906 16-36-11 @Agent.py:117][0m Average action selection time: 0.3147
[32m[0906 16-36-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-36-11 @MBExp.py:227][0m Rewards obtained: [-679.1837951181788], Lows: [483], Highs: [69], Total time: 10325.394824
[32m[0906 16-36-36 @MBExp.py:144][0m ####################################################################
[32m[0906 16-36-36 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 16-36-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31937, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-36-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31850, current rewards: -23.12689, mean: -0.38545
[32m[0906 16-37-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31795, current rewards: -18.79807, mean: -0.17089
[32m[0906 16-37-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31783, current rewards: -14.47906, mean: -0.09049
[32m[0906 16-37-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31817, current rewards: -52.25997, mean: -0.24886
[32m[0906 16-37-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31789, current rewards: -47.60340, mean: -0.18309
[32m[0906 16-38-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31774, current rewards: -42.87530, mean: -0.13831
[32m[0906 16-38-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31757, current rewards: -38.14086, mean: -0.10595
[32m[0906 16-38-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31749, current rewards: -33.40795, mean: -0.08148
[32m[0906 16-39-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31742, current rewards: -28.67378, mean: -0.06233
[32m[0906 16-39-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31742, current rewards: -23.94082, mean: -0.04694
[32m[0906 16-39-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31731, current rewards: -19.20734, mean: -0.03430
[32m[0906 16-39-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31723, current rewards: -14.76189, mean: -0.02420
[32m[0906 16-40-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31712, current rewards: -10.23140, mean: -0.01550
[32m[0906 16-40-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31705, current rewards: -5.67870, mean: -0.00800
[32m[0906 16-40-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31696, current rewards: -1.12287, mean: -0.00148
[32m[0906 16-40-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31693, current rewards: 3.43779, mean: 0.00424
[32m[0906 16-41-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31700, current rewards: -33.63228, mean: -0.03911
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31695, current rewards: -22.81981, mean: -0.02508
[32m[0906 16-41-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31690, current rewards: -12.05272, mean: -0.01255
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31688, current rewards: -4.14814, mean: -0.00411
[32m[0906 16-42-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31681, current rewards: 4.63944, mean: 0.00438
[32m[0906 16-42-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31674, current rewards: 13.23028, mean: 0.01192
[32m[0906 16-42-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31667, current rewards: 21.83487, mean: 0.01882
[32m[0906 16-43-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31660, current rewards: 30.43646, mean: 0.02515
[32m[0906 16-43-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31653, current rewards: 39.03163, mean: 0.03098
[32m[0906 16-43-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31653, current rewards: 47.63551, mean: 0.03636
[32m[0906 16-43-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31648, current rewards: 56.22623, mean: 0.04134
[32m[0906 16-44-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31643, current rewards: 41.24527, mean: 0.02925
[32m[0906 16-44-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31636, current rewards: 46.38225, mean: 0.03177
[32m[0906 16-44-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31632, current rewards: 51.30603, mean: 0.03398
[32m[0906 16-44-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31628, current rewards: 56.23125, mean: 0.03605
[32m[0906 16-45-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31621, current rewards: 61.15713, mean: 0.03799
[32m[0906 16-45-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31623, current rewards: 66.08106, mean: 0.03981
[32m[0906 16-45-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31621, current rewards: 71.00383, mean: 0.04152
[32m[0906 16-45-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31618, current rewards: 75.92686, mean: 0.04314
[32m[0906 16-46-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31616, current rewards: 81.71547, mean: 0.04515
[32m[0906 16-46-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31614, current rewards: 87.07107, mean: 0.04681
[32m[0906 16-46-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31610, current rewards: 92.22615, mean: 0.04829
[32m[0906 16-46-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31599, current rewards: 97.38427, mean: 0.04969
[32m[0906 16-47-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31581, current rewards: 102.53993, mean: 0.05101
[32m[0906 16-47-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31580, current rewards: 107.69702, mean: 0.05228
[32m[0906 16-47-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31584, current rewards: 70.88327, mean: 0.03359
[32m[0906 16-47-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31568, current rewards: 76.51795, mean: 0.03542
[32m[0906 16-48-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31534, current rewards: 81.73525, mean: 0.03698
[32m[0906 16-48-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31535, current rewards: 86.84819, mean: 0.03843
[32m[0906 16-48-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31522, current rewards: 92.03991, mean: 0.03984
[32m[0906 16-49-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31515, current rewards: 97.21317, mean: 0.04119
[32m[0906 16-49-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31523, current rewards: 102.38581, mean: 0.04248
[32m[0906 16-49-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31530, current rewards: 104.24816, mean: 0.04238
[32m[0906 16-49-45 @Agent.py:117][0m Average action selection time: 0.3153
[32m[0906 16-49-45 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-49-45 @MBExp.py:227][0m Rewards obtained: [88.65812547855113], Lows: [65], Highs: [62], Total time: 11114.348324
[32m[0906 16-50-12 @MBExp.py:144][0m ####################################################################
[32m[0906 16-50-12 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 16-50-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31903, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-50-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31825, current rewards: -18.64143, mean: -0.31069
[32m[0906 16-50-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31790, current rewards: -38.70317, mean: -0.35185
[32m[0906 16-51-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31786, current rewards: -65.17291, mean: -0.40733
[32m[0906 16-51-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31791, current rewards: -91.72306, mean: -0.43678
[32m[0906 16-51-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31788, current rewards: -117.21650, mean: -0.45083
[32m[0906 16-51-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31780, current rewards: -135.12195, mean: -0.43588
[32m[0906 16-52-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31764, current rewards: -163.78300, mean: -0.45495
[32m[0906 16-52-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31752, current rewards: -157.12624, mean: -0.38323
[32m[0906 16-52-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31745, current rewards: -150.14520, mean: -0.32640
[32m[0906 16-52-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31732, current rewards: -143.19297, mean: -0.28077
[32m[0906 16-53-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31720, current rewards: -137.37949, mean: -0.24532
[32m[0906 16-53-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31710, current rewards: -130.85233, mean: -0.21451
[32m[0906 16-53-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31705, current rewards: -123.67118, mean: -0.18738
[32m[0906 16-53-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31702, current rewards: -117.12852, mean: -0.16497
[32m[0906 16-54-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31694, current rewards: -110.04553, mean: -0.14480
[32m[0906 16-54-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31685, current rewards: -103.49344, mean: -0.12777
[32m[0906 16-54-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31678, current rewards: -96.43415, mean: -0.11213
[32m[0906 16-55-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31670, current rewards: -121.60574, mean: -0.13363
[32m[0906 16-55-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31659, current rewards: -128.48154, mean: -0.13383
[32m[0906 16-55-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31651, current rewards: -125.10977, mean: -0.12387
[32m[0906 16-55-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31645, current rewards: -121.73957, mean: -0.11485
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31638, current rewards: -118.37210, mean: -0.10664
[32m[0906 16-56-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31634, current rewards: -115.00192, mean: -0.09914
[32m[0906 16-56-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31630, current rewards: -111.63370, mean: -0.09226
[32m[0906 16-56-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31622, current rewards: -108.26278, mean: -0.08592
[32m[0906 16-57-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31611, current rewards: -104.89197, mean: -0.08007
[32m[0906 16-57-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31604, current rewards: -99.15342, mean: -0.07291
[32m[0906 16-57-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31600, current rewards: -93.86334, mean: -0.06657
[32m[0906 16-57-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31598, current rewards: -90.59296, mean: -0.06205
[32m[0906 16-58-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31592, current rewards: -92.68223, mean: -0.06138
[32m[0906 16-58-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31587, current rewards: -106.91091, mean: -0.06853
[32m[0906 16-58-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31582, current rewards: -138.97718, mean: -0.08632
[32m[0906 16-58-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31575, current rewards: -167.87751, mean: -0.10113
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31569, current rewards: -191.97561, mean: -0.11227
[32m[0906 16-59-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31567, current rewards: -185.43413, mean: -0.10536
[32m[0906 16-59-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31563, current rewards: -181.74822, mean: -0.10041
[32m[0906 17-00-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31560, current rewards: -175.73513, mean: -0.09448
[32m[0906 17-00-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31558, current rewards: -169.43700, mean: -0.08871
[32m[0906 17-00-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31544, current rewards: -205.58239, mean: -0.10489
[32m[0906 17-00-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31525, current rewards: -201.64521, mean: -0.10032
[32m[0906 17-01-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31525, current rewards: -197.65436, mean: -0.09595
[32m[0906 17-01-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31525, current rewards: -193.66283, mean: -0.09178
[32m[0906 17-01-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31497, current rewards: -189.67155, mean: -0.08781
[32m[0906 17-01-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31462, current rewards: -183.83728, mean: -0.08318
[32m[0906 17-02-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31461, current rewards: -177.71549, mean: -0.07864
[32m[0906 17-02-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31449, current rewards: -174.02824, mean: -0.07534
[32m[0906 17-02-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31443, current rewards: -170.34100, mean: -0.07218
[32m[0906 17-02-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31450, current rewards: -166.65375, mean: -0.06915
[32m[0906 17-03-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31454, current rewards: -162.96651, mean: -0.06625
[32m[0906 17-03-19 @Agent.py:117][0m Average action selection time: 0.3146
[32m[0906 17-03-19 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-03-19 @MBExp.py:227][0m Rewards obtained: [-160.01670878669458], Lows: [48], Highs: [277], Total time: 11901.403835000001
[32m[0906 17-03-48 @MBExp.py:144][0m ####################################################################
[32m[0906 17-03-48 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31849, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31598, current rewards: -6.92946, mean: -0.11549
[32m[0906 17-04-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31654, current rewards: 16.57336, mean: 0.15067
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31679, current rewards: 32.44277, mean: 0.20277
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31678, current rewards: 56.34953, mean: 0.26833
[32m[0906 17-05-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31684, current rewards: 80.38240, mean: 0.30916
[32m[0906 17-05-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31668, current rewards: 104.40076, mean: 0.33678
[32m[0906 17-05-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31664, current rewards: 128.55462, mean: 0.35710
[32m[0906 17-05-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31653, current rewards: 152.55497, mean: 0.37209
[32m[0906 17-06-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31647, current rewards: 176.60714, mean: 0.38393
[32m[0906 17-06-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31645, current rewards: 200.67074, mean: 0.39347
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31638, current rewards: 213.41807, mean: 0.38110
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31637, current rewards: 201.58553, mean: 0.33047
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31640, current rewards: 210.62692, mean: 0.31913
[32m[0906 17-07-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31638, current rewards: 219.50447, mean: 0.30916
[32m[0906 17-07-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31634, current rewards: 228.38459, mean: 0.30051
[32m[0906 17-08-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31626, current rewards: 237.25367, mean: 0.29291
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31618, current rewards: 246.11282, mean: 0.28618
[32m[0906 17-08-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31618, current rewards: 254.98420, mean: 0.28020
[32m[0906 17-08-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31612, current rewards: 266.35703, mean: 0.27746
[32m[0906 17-09-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31605, current rewards: 275.45138, mean: 0.27272
[32m[0906 17-09-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31603, current rewards: 284.67515, mean: 0.26856
[32m[0906 17-09-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31600, current rewards: 293.90481, mean: 0.26478
[32m[0906 17-09-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31592, current rewards: 303.13105, mean: 0.26132
[32m[0906 17-10-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31582, current rewards: 312.35962, mean: 0.25815
[32m[0906 17-10-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31574, current rewards: 321.57786, mean: 0.25522
[32m[0906 17-10-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31566, current rewards: 288.34083, mean: 0.22011
[32m[0906 17-10-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31561, current rewards: 298.65320, mean: 0.21960
[32m[0906 17-11-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31557, current rewards: 310.00540, mean: 0.21986
[32m[0906 17-11-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31553, current rewards: 321.68997, mean: 0.22034
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31548, current rewards: 333.34413, mean: 0.22076
[32m[0906 17-12-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31546, current rewards: 345.01107, mean: 0.22116
[32m[0906 17-12-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31542, current rewards: 356.63993, mean: 0.22152
[32m[0906 17-12-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31541, current rewards: 368.30171, mean: 0.22187
[32m[0906 17-12-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31540, current rewards: 379.95352, mean: 0.22220
[32m[0906 17-13-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31539, current rewards: 391.22388, mean: 0.22229
[32m[0906 17-13-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31534, current rewards: 402.23583, mean: 0.22223
[32m[0906 17-13-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31532, current rewards: 413.84591, mean: 0.22250
[32m[0906 17-13-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31533, current rewards: 380.84590, mean: 0.19940
[32m[0906 17-14-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31517, current rewards: 392.49293, mean: 0.20025
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31499, current rewards: 406.48105, mean: 0.20223
[32m[0906 17-14-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31497, current rewards: 420.41819, mean: 0.20409
[32m[0906 17-14-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31498, current rewards: 434.39497, mean: 0.20587
[32m[0906 17-15-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31465, current rewards: 448.80021, mean: 0.20778
[32m[0906 17-15-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31426, current rewards: 384.83555, mean: 0.17413
[32m[0906 17-15-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31425, current rewards: 398.42360, mean: 0.17629
[32m[0906 17-15-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31414, current rewards: 411.79972, mean: 0.17827
[32m[0906 17-16-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31409, current rewards: 425.20291, mean: 0.18017
[32m[0906 17-16-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31416, current rewards: 438.60735, mean: 0.18199
[32m[0906 17-16-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31422, current rewards: 451.99099, mean: 0.18374
[32m[0906 17-16-54 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0906 17-16-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-16-54 @MBExp.py:227][0m Rewards obtained: [462.7032783016078], Lows: [75], Highs: [40], Total time: 12687.664067000002
[32m[0906 17-17-25 @MBExp.py:144][0m ####################################################################
[32m[0906 17-17-25 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 17-17-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31922, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-17-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31836, current rewards: -36.37829, mean: -0.60630
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31798, current rewards: -31.78350, mean: -0.28894
[32m[0906 17-18-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31810, current rewards: -34.59871, mean: -0.21624
[32m[0906 17-18-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31811, current rewards: -30.29805, mean: -0.14428
[32m[0906 17-18-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31777, current rewards: -26.24929, mean: -0.10096
[32m[0906 17-19-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31771, current rewards: -21.21142, mean: -0.06842
[32m[0906 17-19-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31743, current rewards: -16.57613, mean: -0.04604
[32m[0906 17-19-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31737, current rewards: -12.29571, mean: -0.02999
[32m[0906 17-19-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31717, current rewards: -7.85189, mean: -0.01707
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31710, current rewards: -2.58967, mean: -0.00508
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31700, current rewards: 4.31060, mean: 0.00770
[32m[0906 17-20-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31690, current rewards: 8.35831, mean: 0.01370
[32m[0906 17-20-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31685, current rewards: -12.78127, mean: -0.01937
[32m[0906 17-21-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31674, current rewards: -2.51629, mean: -0.00354
[32m[0906 17-21-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31662, current rewards: 2.16484, mean: 0.00285
[32m[0906 17-21-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31654, current rewards: 6.84090, mean: 0.00845
[32m[0906 17-21-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31646, current rewards: 11.51949, mean: 0.01339
[32m[0906 17-22-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31639, current rewards: 25.73383, mean: 0.02828
[32m[0906 17-22-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31636, current rewards: 31.28194, mean: 0.03259
[32m[0906 17-22-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31629, current rewards: 36.08252, mean: 0.03573
[32m[0906 17-23-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31625, current rewards: 41.05610, mean: 0.03873
[32m[0906 17-23-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31618, current rewards: 46.03031, mean: 0.04147
[32m[0906 17-23-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31615, current rewards: 51.00516, mean: 0.04397
[32m[0906 17-23-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31612, current rewards: 49.68432, mean: 0.04106
[32m[0906 17-24-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31609, current rewards: 21.22283, mean: 0.01684
[32m[0906 17-24-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31608, current rewards: 25.28190, mean: 0.01930
[32m[0906 17-24-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31604, current rewards: 29.23885, mean: 0.02150
[32m[0906 17-24-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31599, current rewards: 18.76412, mean: 0.01331
[32m[0906 17-25-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31597, current rewards: 22.12522, mean: 0.01515
[32m[0906 17-25-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31595, current rewards: 25.51305, mean: 0.01690
[32m[0906 17-25-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31591, current rewards: 28.90068, mean: 0.01853
[32m[0906 17-25-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31588, current rewards: 4.11372, mean: 0.00256
[32m[0906 17-26-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31585, current rewards: 8.32135, mean: 0.00501
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31585, current rewards: 11.71038, mean: 0.00685
[32m[0906 17-26-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31581, current rewards: 15.13761, mean: 0.00860
[32m[0906 17-26-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31579, current rewards: 19.40356, mean: 0.01072
[32m[0906 17-27-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31577, current rewards: 22.92650, mean: 0.01233
[32m[0906 17-27-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31573, current rewards: 26.51663, mean: 0.01388
[32m[0906 17-27-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31554, current rewards: -9.21979, mean: -0.00470
[32m[0906 17-27-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31533, current rewards: -2.01393, mean: -0.00100
[32m[0906 17-28-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31529, current rewards: 5.16776, mean: 0.00251
[32m[0906 17-28-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31530, current rewards: 12.34634, mean: 0.00585
[32m[0906 17-28-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31494, current rewards: 19.52984, mean: 0.00904
[32m[0906 17-29-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31458, current rewards: 25.73842, mean: 0.01165
[32m[0906 17-29-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31454, current rewards: 29.79990, mean: 0.01319
[32m[0906 17-29-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31442, current rewards: 34.19505, mean: 0.01480
[32m[0906 17-29-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31437, current rewards: 38.67642, mean: 0.01639
[32m[0906 17-30-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31444, current rewards: 43.17193, mean: 0.01791
[32m[0906 17-30-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31449, current rewards: 47.66807, mean: 0.01938
[32m[0906 17-30-32 @Agent.py:117][0m Average action selection time: 0.3145
[32m[0906 17-30-32 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-30-32 @MBExp.py:227][0m Rewards obtained: [51.2652946055717], Lows: [50], Highs: [94], Total time: 13474.583028000001
[32m[0906 17-31-05 @MBExp.py:144][0m ####################################################################
[32m[0906 17-31-05 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 17-31-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31894, current rewards: 0.87057, mean: 0.08706
[32m[0906 17-31-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31777, current rewards: -28.54643, mean: -0.47577
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31732, current rewards: -61.26168, mean: -0.55692
[32m[0906 17-31-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31688, current rewards: -89.00135, mean: -0.55626
[32m[0906 17-32-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31687, current rewards: -116.11180, mean: -0.55291
[32m[0906 17-32-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31695, current rewards: -134.61562, mean: -0.51775
[32m[0906 17-32-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31676, current rewards: -161.68865, mean: -0.52158
[32m[0906 17-32-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31663, current rewards: -184.33663, mean: -0.51205
[32m[0906 17-33-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31657, current rewards: -202.88893, mean: -0.49485
[32m[0906 17-33-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31645, current rewards: -222.17230, mean: -0.48298
[32m[0906 17-33-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31636, current rewards: -218.57564, mean: -0.42858
[32m[0906 17-34-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31625, current rewards: -212.48957, mean: -0.37945
[32m[0906 17-34-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31615, current rewards: -207.57493, mean: -0.34029
[32m[0906 17-34-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31609, current rewards: -203.05582, mean: -0.30766
[32m[0906 17-34-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31609, current rewards: -198.59311, mean: -0.27971
[32m[0906 17-35-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31606, current rewards: -194.10305, mean: -0.25540
[32m[0906 17-35-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31601, current rewards: -189.61657, mean: -0.23409
[32m[0906 17-35-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31600, current rewards: -185.13585, mean: -0.21527
[32m[0906 17-35-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31604, current rewards: -180.65424, mean: -0.19852
[32m[0906 17-36-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31601, current rewards: -197.90123, mean: -0.20615
[32m[0906 17-36-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31600, current rewards: -211.38257, mean: -0.20929
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31597, current rewards: -207.91934, mean: -0.19615
[32m[0906 17-36-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31594, current rewards: -204.40107, mean: -0.18415
[32m[0906 17-37-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31594, current rewards: -200.88478, mean: -0.17318
[32m[0906 17-37-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31592, current rewards: -197.36539, mean: -0.16311
[32m[0906 17-37-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31590, current rewards: -193.84770, mean: -0.15385
[32m[0906 17-37-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31586, current rewards: -190.32783, mean: -0.14529
[32m[0906 17-38-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31579, current rewards: -186.80952, mean: -0.13736
[32m[0906 17-38-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31573, current rewards: -181.16357, mean: -0.12848
[32m[0906 17-38-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31571, current rewards: -175.88559, mean: -0.12047
[32m[0906 17-39-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31571, current rewards: -171.94534, mean: -0.11387
[32m[0906 17-39-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31569, current rewards: -168.00425, mean: -0.10770
[32m[0906 17-39-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31570, current rewards: -205.54470, mean: -0.12767
[32m[0906 17-39-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31568, current rewards: -207.04110, mean: -0.12472
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31566, current rewards: -210.83252, mean: -0.12329
[32m[0906 17-40-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31565, current rewards: -214.67837, mean: -0.12198
[32m[0906 17-40-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31565, current rewards: -216.39940, mean: -0.11956
[32m[0906 17-40-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31565, current rewards: -215.39654, mean: -0.11580
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31561, current rewards: -209.87926, mean: -0.10988
[32m[0906 17-41-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31544, current rewards: -204.31446, mean: -0.10424
[32m[0906 17-41-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31525, current rewards: -198.74512, mean: -0.09888
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31525, current rewards: -215.60750, mean: -0.10466
[32m[0906 17-42-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31523, current rewards: -212.27213, mean: -0.10060
[32m[0906 17-42-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31486, current rewards: -208.93670, mean: -0.09673
[32m[0906 17-42-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31450, current rewards: -205.59498, mean: -0.09303
[32m[0906 17-42-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31445, current rewards: -202.48496, mean: -0.08960
[32m[0906 17-43-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31434, current rewards: -199.13307, mean: -0.08620
[32m[0906 17-43-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31429, current rewards: -195.88205, mean: -0.08300
[32m[0906 17-43-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31437, current rewards: -192.63264, mean: -0.07993
[32m[0906 17-43-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31443, current rewards: -189.38312, mean: -0.07699
[32m[0906 17-44-11 @Agent.py:117][0m Average action selection time: 0.3145
[32m[0906 17-44-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-44-11 @MBExp.py:227][0m Rewards obtained: [-186.78329184523884], Lows: [167], Highs: [72], Total time: 14261.358871
[32m[0906 17-44-46 @MBExp.py:144][0m ####################################################################
[32m[0906 17-44-46 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 17-44-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31978, current rewards: 1.57191, mean: 0.15719
[32m[0906 17-45-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31755, current rewards: -65.23709, mean: -1.08728
[32m[0906 17-45-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31708, current rewards: -140.67044, mean: -1.27882
[32m[0906 17-45-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31716, current rewards: -223.32739, mean: -1.39580
[32m[0906 17-45-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31726, current rewards: -310.25189, mean: -1.47739
[32m[0906 17-46-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31702, current rewards: -392.37706, mean: -1.50914
[32m[0906 17-46-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31692, current rewards: -487.69090, mean: -1.57320
[32m[0906 17-46-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31689, current rewards: -571.33453, mean: -1.58704
[32m[0906 17-46-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31684, current rewards: -608.28457, mean: -1.48362
[32m[0906 17-47-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31675, current rewards: -602.99771, mean: -1.31086
[32m[0906 17-47-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31670, current rewards: -599.38848, mean: -1.17527
[32m[0906 17-47-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31665, current rewards: -595.78687, mean: -1.06391
[32m[0906 17-47-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31652, current rewards: -592.18477, mean: -0.97079
[32m[0906 17-48-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31644, current rewards: -628.92544, mean: -0.95292
[32m[0906 17-48-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31637, current rewards: -692.31067, mean: -0.97509
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31635, current rewards: -792.31067, mean: -1.04251
[32m[0906 17-49-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31636, current rewards: -892.31067, mean: -1.10162
[32m[0906 17-49-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31636, current rewards: -992.31067, mean: -1.15385
[32m[0906 17-49-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31634, current rewards: -1092.31067, mean: -1.20034
[32m[0906 17-49-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31627, current rewards: -1192.31067, mean: -1.24199
[32m[0906 17-50-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31620, current rewards: -1292.31067, mean: -1.27952
[32m[0906 17-50-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31614, current rewards: -1392.31067, mean: -1.31350
[32m[0906 17-50-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31611, current rewards: -1492.31067, mean: -1.34442
[32m[0906 17-50-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31610, current rewards: -1592.31067, mean: -1.37268
[32m[0906 17-51-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31608, current rewards: -1692.31067, mean: -1.39860
[32m[0906 17-51-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31605, current rewards: -1792.31067, mean: -1.42247
[32m[0906 17-51-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31601, current rewards: -1892.31067, mean: -1.44451
[32m[0906 17-51-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31596, current rewards: -1992.31067, mean: -1.46493
[32m[0906 17-52-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31590, current rewards: -2092.31067, mean: -1.48391
[32m[0906 17-52-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31586, current rewards: -2192.31067, mean: -1.50158
[32m[0906 17-52-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31583, current rewards: -2292.31067, mean: -1.51809
[32m[0906 17-52-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31579, current rewards: -2392.31067, mean: -1.53353
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31577, current rewards: -2492.31067, mean: -1.54802
[32m[0906 17-53-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31572, current rewards: -2592.31067, mean: -1.56163
[32m[0906 17-53-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31569, current rewards: -2692.31067, mean: -1.57445
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31563, current rewards: -2792.31067, mean: -1.58654
[32m[0906 17-54-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31560, current rewards: -2892.31067, mean: -1.59796
[32m[0906 17-54-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31559, current rewards: -2992.31067, mean: -1.60877
[32m[0906 17-54-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31557, current rewards: -3092.31067, mean: -1.61901
[32m[0906 17-55-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31539, current rewards: -3192.31067, mean: -1.62873
[32m[0906 17-55-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31521, current rewards: -3292.31067, mean: -1.63797
[32m[0906 17-55-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31520, current rewards: -3392.31067, mean: -1.64675
[32m[0906 17-55-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31510, current rewards: -3492.31067, mean: -1.65512
[32m[0906 17-56-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31475, current rewards: -3592.31067, mean: -1.66311
[32m[0906 17-56-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31438, current rewards: -3692.31067, mean: -1.67073
[32m[0906 17-56-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31432, current rewards: -3792.31067, mean: -1.67801
[32m[0906 17-56-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31419, current rewards: -3892.31067, mean: -1.68498
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31413, current rewards: -3992.31067, mean: -1.69166
[32m[0906 17-57-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31421, current rewards: -4092.31067, mean: -1.69805
[32m[0906 17-57-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31427, current rewards: -4192.31067, mean: -1.70419
[32m[0906 17-57-52 @Agent.py:117][0m Average action selection time: 0.3144
[32m[0906 17-57-52 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-57-52 @MBExp.py:227][0m Rewards obtained: [-4272.310671680312], Lows: [2145], Highs: [30], Total time: 15047.840912
[32m[0906 17-58-28 @MBExp.py:144][0m ####################################################################
[32m[0906 17-58-28 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 17-58-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31810, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-58-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31818, current rewards: -15.99401, mean: -0.26657
[32m[0906 17-59-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31693, current rewards: -4.57795, mean: -0.04162
[32m[0906 17-59-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31631, current rewards: 4.21010, mean: 0.02631
[32m[0906 17-59-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31597, current rewards: 18.77739, mean: 0.08942
[32m[0906 17-59-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31579, current rewards: 34.55066, mean: 0.13289
[32m[0906 18-00-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31566, current rewards: 31.80819, mean: 0.10261
[32m[0906 18-00-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31570, current rewards: 11.62751, mean: 0.03230
[32m[0906 18-00-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31559, current rewards: 16.91138, mean: 0.04125
[32m[0906 18-00-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31552, current rewards: 22.20596, mean: 0.04827
[32m[0906 18-01-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31546, current rewards: 27.48999, mean: 0.05390
[32m[0906 18-01-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31543, current rewards: 32.10118, mean: 0.05732
[32m[0906 18-01-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31545, current rewards: 37.72348, mean: 0.06184
[32m[0906 18-01-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31545, current rewards: 43.19208, mean: 0.06544
[32m[0906 18-02-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31541, current rewards: 48.66122, mean: 0.06854
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31544, current rewards: 54.12831, mean: 0.07122
[32m[0906 18-02-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31541, current rewards: 59.59469, mean: 0.07357
[32m[0906 18-03-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31535, current rewards: 65.06561, mean: 0.07566
[32m[0906 18-03-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31532, current rewards: 70.54048, mean: 0.07752
[32m[0906 18-03-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31528, current rewards: 76.00730, mean: 0.07917
[32m[0906 18-03-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31525, current rewards: 58.10154, mean: 0.05753
[32m[0906 18-04-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31525, current rewards: 63.74603, mean: 0.06014
[32m[0906 18-04-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31517, current rewards: 69.04975, mean: 0.06221
[32m[0906 18-04-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31514, current rewards: 74.35870, mean: 0.06410
[32m[0906 18-04-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31516, current rewards: 79.65384, mean: 0.06583
[32m[0906 18-05-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31517, current rewards: 84.95462, mean: 0.06742
[32m[0906 18-05-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31515, current rewards: 90.25306, mean: 0.06890
[32m[0906 18-05-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31515, current rewards: 95.55594, mean: 0.07026
[32m[0906 18-05-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31515, current rewards: 96.64637, mean: 0.06854
[32m[0906 18-06-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31511, current rewards: 42.75404, mean: 0.02928
[32m[0906 18-06-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31513, current rewards: -57.24596, mean: -0.03791
[32m[0906 18-06-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31514, current rewards: -157.24596, mean: -0.10080
[32m[0906 18-06-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31512, current rewards: -257.24596, mean: -0.15978
[32m[0906 18-07-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31511, current rewards: -357.24596, mean: -0.21521
[32m[0906 18-07-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31509, current rewards: -457.24596, mean: -0.26740
[32m[0906 18-07-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31509, current rewards: -557.24596, mean: -0.31662
[32m[0906 18-07-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31507, current rewards: -619.99889, mean: -0.34254
[32m[0906 18-08-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31506, current rewards: -719.99889, mean: -0.38710
[32m[0906 18-08-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31499, current rewards: -802.99889, mean: -0.42042
[32m[0906 18-08-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31482, current rewards: -803.78053, mean: -0.41009
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31465, current rewards: -800.70581, mean: -0.39836
[32m[0906 18-09-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31465, current rewards: -797.66276, mean: -0.38721
[32m[0906 18-09-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31452, current rewards: -794.61472, mean: -0.37659
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31415, current rewards: -791.66465, mean: -0.36651
[32m[0906 18-10-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31381, current rewards: -788.61452, mean: -0.35684
[32m[0906 18-10-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31374, current rewards: -785.58245, mean: -0.34760
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31364, current rewards: -782.57454, mean: -0.33878
[32m[0906 18-10-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31362, current rewards: -779.57663, mean: -0.33033
[32m[0906 18-11-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31372, current rewards: -776.57031, mean: -0.32223
[32m[0906 18-11-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31376, current rewards: -773.56817, mean: -0.31446
[32m[0906 18-11-33 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0906 18-11-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-11-33 @MBExp.py:227][0m Rewards obtained: [-771.1667663812086], Lows: [469], Highs: [63], Total time: 15832.985531999999
[32m[0906 18-12-12 @MBExp.py:144][0m ####################################################################
[32m[0906 18-12-12 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 18-12-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31849, current rewards: 0.65220, mean: 0.06522
[32m[0906 18-12-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31869, current rewards: -5.13235, mean: -0.08554
[32m[0906 18-12-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33501, current rewards: 9.68109, mean: 0.08801
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34139, current rewards: 20.79825, mean: 0.12999
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34496, current rewards: 31.30484, mean: 0.14907
[32m[0906 18-13-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34701, current rewards: 44.00007, mean: 0.16923
[32m[0906 18-14-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34890, current rewards: 54.11668, mean: 0.17457
[32m[0906 18-14-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35028, current rewards: 66.88436, mean: 0.18579
[32m[0906 18-14-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35131, current rewards: 71.38768, mean: 0.17412
[32m[0906 18-14-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35210, current rewards: 76.16833, mean: 0.16558
[32m[0906 18-15-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35273, current rewards: 80.02619, mean: 0.15691
[32m[0906 18-15-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35318, current rewards: 85.31144, mean: 0.15234
[32m[0906 18-15-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35362, current rewards: 90.62416, mean: 0.14856
[32m[0906 18-16-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35403, current rewards: 95.93611, mean: 0.14536
[32m[0906 18-16-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35434, current rewards: 101.24917, mean: 0.14260
[32m[0906 18-16-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35500, current rewards: 106.56194, mean: 0.14021
[32m[0906 18-17-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35565, current rewards: 111.87355, mean: 0.13812
[32m[0906 18-17-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35627, current rewards: 117.18938, mean: 0.13627
[32m[0906 18-17-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35635, current rewards: 106.36488, mean: 0.11688
[32m[0906 18-17-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35627, current rewards: 89.78726, mean: 0.09353
[32m[0906 18-18-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35624, current rewards: 94.35845, mean: 0.09342
[32m[0906 18-18-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35618, current rewards: 98.61167, mean: 0.09303
[32m[0906 18-18-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35611, current rewards: 102.86641, mean: 0.09267
[32m[0906 18-19-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35607, current rewards: 107.12162, mean: 0.09235
[32m[0906 18-19-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35600, current rewards: 111.37456, mean: 0.09205
[32m[0906 18-19-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35598, current rewards: 115.63022, mean: 0.09177
[32m[0906 18-19-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35599, current rewards: 119.86915, mean: 0.09150
[32m[0906 18-20-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35594, current rewards: 123.50812, mean: 0.09081
[32m[0906 18-20-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35588, current rewards: 127.70830, mean: 0.09057
[32m[0906 18-20-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35586, current rewards: 108.08872, mean: 0.07403
[32m[0906 18-21-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35578, current rewards: 82.33362, mean: 0.05453
[32m[0906 18-21-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35580, current rewards: 51.30864, mean: 0.03289
[32m[0906 18-21-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35591, current rewards: 1.30864, mean: 0.00081
[32m[0906 18-22-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35598, current rewards: -48.69136, mean: -0.02933
[32m[0906 18-22-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35601, current rewards: -88.06515, mean: -0.05150
[32m[0906 18-22-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35604, current rewards: -85.05786, mean: -0.04833
[32m[0906 18-22-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35609, current rewards: -83.87698, mean: -0.04634
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35615, current rewards: -81.60980, mean: -0.04388
[32m[0906 18-23-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35613, current rewards: -80.48073, mean: -0.04214
[32m[0906 18-23-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35595, current rewards: -78.18578, mean: -0.03989
[32m[0906 18-24-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35572, current rewards: -75.94378, mean: -0.03778
[32m[0906 18-24-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35574, current rewards: -74.79030, mean: -0.03631
[32m[0906 18-24-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35556, current rewards: -72.51910, mean: -0.03437
[32m[0906 18-24-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35516, current rewards: -71.08813, mean: -0.03291
[32m[0906 18-25-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35476, current rewards: -104.21636, mean: -0.04716
[32m[0906 18-25-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35465, current rewards: -98.08836, mean: -0.04340
[32m[0906 18-25-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35462, current rewards: -91.95877, mean: -0.03981
[32m[0906 18-26-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35472, current rewards: -85.82784, mean: -0.03637
[32m[0906 18-26-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35480, current rewards: -79.69918, mean: -0.03307
[32m[0906 18-26-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35479, current rewards: -73.57124, mean: -0.02991
[32m[0906 18-26-59 @Agent.py:117][0m Average action selection time: 0.3548
[32m[0906 18-26-59 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-26-59 @MBExp.py:227][0m Rewards obtained: [-68.66896059296332], Lows: [39], Highs: [262], Total time: 16720.660032
[32m[0906 18-27-44 @MBExp.py:144][0m ####################################################################
[32m[0906 18-27-44 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 18-27-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35646, current rewards: -7.90255, mean: -0.79026
[32m[0906 18-28-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35598, current rewards: -17.30320, mean: -0.28839
[32m[0906 18-28-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35539, current rewards: -10.57612, mean: -0.09615
[32m[0906 18-28-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35653, current rewards: -6.35830, mean: -0.03974
[32m[0906 18-28-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35718, current rewards: -2.16053, mean: -0.01029
[32m[0906 18-29-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35766, current rewards: 2.03879, mean: 0.00784
[32m[0906 18-29-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35807, current rewards: 6.23127, mean: 0.02010
[32m[0906 18-29-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35827, current rewards: -9.23043, mean: -0.02564
[32m[0906 18-30-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35784, current rewards: -4.22085, mean: -0.01029
[32m[0906 18-30-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35756, current rewards: 0.78670, mean: 0.00171
[32m[0906 18-30-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35729, current rewards: 5.44238, mean: 0.01067
[32m[0906 18-31-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35701, current rewards: 10.38976, mean: 0.01855
[32m[0906 18-31-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35665, current rewards: 15.29672, mean: 0.02508
[32m[0906 18-31-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35637, current rewards: 20.20698, mean: 0.03062
[32m[0906 18-31-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35611, current rewards: 25.11880, mean: 0.03538
[32m[0906 18-32-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35466, current rewards: 30.02582, mean: 0.03951
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35221, current rewards: 34.93612, mean: 0.04313
[32m[0906 18-32-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35008, current rewards: 39.84288, mean: 0.04633
[32m[0906 18-33-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34828, current rewards: 45.21685, mean: 0.04969
[32m[0906 18-33-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34664, current rewards: 7.69325, mean: 0.00801
[32m[0906 18-33-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34513, current rewards: 12.01308, mean: 0.01189
[32m[0906 18-33-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34380, current rewards: 16.24510, mean: 0.01533
[32m[0906 18-34-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34254, current rewards: 20.48271, mean: 0.01845
[32m[0906 18-34-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34140, current rewards: 24.71790, mean: 0.02131
[32m[0906 18-34-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34031, current rewards: 3.83012, mean: 0.00317
[32m[0906 18-34-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33929, current rewards: 8.48954, mean: 0.00674
[32m[0906 18-35-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33836, current rewards: 13.00335, mean: 0.00993
[32m[0906 18-35-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33750, current rewards: 17.81628, mean: 0.01310
[32m[0906 18-35-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33666, current rewards: 22.38789, mean: 0.01588
[32m[0906 18-35-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33591, current rewards: 26.98963, mean: 0.01849
[32m[0906 18-36-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33523, current rewards: 31.60688, mean: 0.02093
[32m[0906 18-36-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33459, current rewards: 36.19382, mean: 0.02320
[32m[0906 18-36-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33397, current rewards: 40.79035, mean: 0.02534
[32m[0906 18-36-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33335, current rewards: 45.38875, mean: 0.02734
[32m[0906 18-37-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33282, current rewards: 54.30137, mean: 0.03176
[32m[0906 18-37-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33230, current rewards: 50.05553, mean: 0.02844
[32m[0906 18-37-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33185, current rewards: 53.86563, mean: 0.02976
[32m[0906 18-38-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33141, current rewards: 57.64894, mean: 0.03099
[32m[0906 18-38-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33098, current rewards: 61.43228, mean: 0.03216
[32m[0906 18-38-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33037, current rewards: 65.21543, mean: 0.03327
[32m[0906 18-38-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32979, current rewards: 68.99735, mean: 0.03433
[32m[0906 18-39-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32939, current rewards: 72.78357, mean: 0.03533
[32m[0906 18-39-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32881, current rewards: 76.57336, mean: 0.03629
[32m[0906 18-39-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32810, current rewards: 80.41248, mean: 0.03723
[32m[0906 18-39-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32742, current rewards: 84.19954, mean: 0.03810
[32m[0906 18-40-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32698, current rewards: 87.98658, mean: 0.03893
[32m[0906 18-40-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32658, current rewards: 91.77534, mean: 0.03973
[32m[0906 18-40-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32624, current rewards: 95.56401, mean: 0.04049
[32m[0906 18-40-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32605, current rewards: 99.35184, mean: 0.04122
[32m[0906 18-41-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32587, current rewards: 61.62261, mean: 0.02505
[32m[0906 18-41-19 @Agent.py:117][0m Average action selection time: 0.3257
[32m[0906 18-41-19 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-41-19 @MBExp.py:227][0m Rewards obtained: [65.73419227234845], Lows: [43], Highs: [68], Total time: 17535.556591
[32m[0906 18-42-01 @MBExp.py:144][0m ####################################################################
[32m[0906 18-42-01 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 18-42-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31978, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31655, current rewards: -16.22334, mean: -0.27039
[32m[0906 18-42-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31643, current rewards: -12.17439, mean: -0.11068
[32m[0906 18-42-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31650, current rewards: -8.13252, mean: -0.05083
[32m[0906 18-43-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31654, current rewards: -4.08276, mean: -0.01944
[32m[0906 18-43-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31665, current rewards: -0.01955, mean: -0.00008
[32m[0906 18-43-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31668, current rewards: 4.05375, mean: 0.01308
[32m[0906 18-43-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31671, current rewards: 8.12975, mean: 0.02258
[32m[0906 18-44-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31654, current rewards: -9.56125, mean: -0.02332
[32m[0906 18-44-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31654, current rewards: -5.67756, mean: -0.01234
[32m[0906 18-44-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31650, current rewards: -1.74236, mean: -0.00342
[32m[0906 18-44-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31645, current rewards: 2.42632, mean: 0.00433
[32m[0906 18-45-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31641, current rewards: 6.59067, mean: 0.01080
[32m[0906 18-45-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31632, current rewards: 10.76060, mean: 0.01630
[32m[0906 18-45-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31624, current rewards: 14.92407, mean: 0.02102
[32m[0906 18-46-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31617, current rewards: 19.08686, mean: 0.02511
[32m[0906 18-46-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31613, current rewards: -18.09608, mean: -0.02234
[32m[0906 18-46-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31612, current rewards: -13.42532, mean: -0.01561
[32m[0906 18-46-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31612, current rewards: -1.60264, mean: -0.00176
[32m[0906 18-47-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31610, current rewards: 4.85618, mean: 0.00506
[32m[0906 18-47-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31604, current rewards: -15.78523, mean: -0.01563
[32m[0906 18-47-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31600, current rewards: -65.78523, mean: -0.06206
[32m[0906 18-47-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31599, current rewards: -115.78523, mean: -0.10431
[32m[0906 18-48-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31592, current rewards: -165.78523, mean: -0.14292
[32m[0906 18-48-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31591, current rewards: -190.84962, mean: -0.15773
[32m[0906 18-48-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31584, current rewards: -184.62286, mean: -0.14653
[32m[0906 18-48-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31585, current rewards: -179.06586, mean: -0.13669
[32m[0906 18-49-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31582, current rewards: -172.57260, mean: -0.12689
[32m[0906 18-49-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31580, current rewards: -166.07330, mean: -0.11778
[32m[0906 18-49-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31573, current rewards: -159.57062, mean: -0.10929
[32m[0906 18-49-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31571, current rewards: -178.32341, mean: -0.11809
[32m[0906 18-50-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31570, current rewards: -172.85293, mean: -0.11080
[32m[0906 18-50-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31569, current rewards: -167.37194, mean: -0.10396
[32m[0906 18-50-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31568, current rewards: -161.88860, mean: -0.09752
[32m[0906 18-51-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31566, current rewards: -156.07494, mean: -0.09127
[32m[0906 18-51-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31565, current rewards: -150.64551, mean: -0.08559
[32m[0906 18-51-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31560, current rewards: -145.19153, mean: -0.08022
[32m[0906 18-51-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31557, current rewards: -139.73293, mean: -0.07513
[32m[0906 18-52-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31547, current rewards: -157.47475, mean: -0.08245
[32m[0906 18-52-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31526, current rewards: -171.50621, mean: -0.08750
[32m[0906 18-52-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31505, current rewards: -166.39841, mean: -0.08279
[32m[0906 18-52-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31499, current rewards: -161.28501, mean: -0.07829
[32m[0906 18-53-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31470, current rewards: -156.99513, mean: -0.07441
[32m[0906 18-53-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31433, current rewards: -190.00414, mean: -0.08796
[32m[0906 18-53-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31398, current rewards: -190.14268, mean: -0.08604
[32m[0906 18-53-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31382, current rewards: -185.93739, mean: -0.08227
[32m[0906 18-54-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31372, current rewards: -181.68396, mean: -0.07865
[32m[0906 18-54-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31361, current rewards: -177.44216, mean: -0.07519
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31368, current rewards: -173.27783, mean: -0.07190
[32m[0906 18-54-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31373, current rewards: -169.15918, mean: -0.06876
[32m[0906 18-55-06 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0906 18-55-06 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-55-06 @MBExp.py:227][0m Rewards obtained: [-165.71747535393465], Lows: [62], Highs: [262], Total time: 18320.60291
[32m[0906 18-55-50 @MBExp.py:144][0m ####################################################################
[32m[0906 18-55-50 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31665, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-56-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31680, current rewards: -28.97941, mean: -0.48299
[32m[0906 18-56-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31671, current rewards: -43.92389, mean: -0.39931
[32m[0906 18-56-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31691, current rewards: -36.71238, mean: -0.22945
[32m[0906 18-56-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31697, current rewards: -29.42591, mean: -0.14012
[32m[0906 18-57-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31676, current rewards: -22.13888, mean: -0.08515
[32m[0906 18-57-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31656, current rewards: -14.85591, mean: -0.04792
[32m[0906 18-57-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31649, current rewards: -7.56677, mean: -0.02102
[32m[0906 18-58-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31639, current rewards: -0.27771, mean: -0.00068
[32m[0906 18-58-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31639, current rewards: 5.07063, mean: 0.01102
[32m[0906 18-58-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31632, current rewards: 14.24969, mean: 0.02794
[32m[0906 18-58-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31632, current rewards: 26.27801, mean: 0.04693
[32m[0906 18-59-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31629, current rewards: 37.88679, mean: 0.06211
[32m[0906 18-59-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31633, current rewards: 49.59575, mean: 0.07515
[32m[0906 18-59-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31634, current rewards: 61.30770, mean: 0.08635
[32m[0906 18-59-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31629, current rewards: 73.00712, mean: 0.09606
[32m[0906 19-00-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31623, current rewards: 68.68196, mean: 0.08479
[32m[0906 19-00-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31621, current rewards: 67.49615, mean: 0.07848
[32m[0906 19-00-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31613, current rewards: 77.44041, mean: 0.08510
[32m[0906 19-00-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31612, current rewards: 83.48237, mean: 0.08696
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31600, current rewards: 89.84821, mean: 0.08896
[32m[0906 19-01-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31595, current rewards: 96.19339, mean: 0.09075
[32m[0906 19-01-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31589, current rewards: 59.80184, mean: 0.05388
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31586, current rewards: 67.10068, mean: 0.05785
[32m[0906 19-02-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31587, current rewards: 74.01014, mean: 0.06117
[32m[0906 19-02-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31585, current rewards: 80.91319, mean: 0.06422
[32m[0906 19-02-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31578, current rewards: 44.00334, mean: 0.03359
[32m[0906 19-03-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31577, current rewards: 57.74540, mean: 0.04246
[32m[0906 19-03-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31571, current rewards: 70.75743, mean: 0.05018
[32m[0906 19-03-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31566, current rewards: 83.75634, mean: 0.05737
[32m[0906 19-03-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31561, current rewards: 96.76440, mean: 0.06408
[32m[0906 19-04-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31560, current rewards: 107.24519, mean: 0.06875
[32m[0906 19-04-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31555, current rewards: 92.19897, mean: 0.05727
[32m[0906 19-04-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31552, current rewards: 100.35902, mean: 0.06046
[32m[0906 19-04-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31549, current rewards: 107.57756, mean: 0.06291
[32m[0906 19-05-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31545, current rewards: 113.74400, mean: 0.06463
[32m[0906 19-05-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31540, current rewards: 121.80600, mean: 0.06730
[32m[0906 19-05-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31538, current rewards: 129.86350, mean: 0.06982
[32m[0906 19-05-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31527, current rewards: 137.91785, mean: 0.07221
[32m[0906 19-06-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31508, current rewards: 145.98737, mean: 0.07448
[32m[0906 19-06-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31490, current rewards: 154.06697, mean: 0.07665
[32m[0906 19-06-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31488, current rewards: 162.14716, mean: 0.07871
[32m[0906 19-06-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31455, current rewards: 170.19218, mean: 0.08066
[32m[0906 19-07-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31421, current rewards: 178.55346, mean: 0.08266
[32m[0906 19-07-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31385, current rewards: 186.64652, mean: 0.08446
[32m[0906 19-07-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31370, current rewards: 194.74810, mean: 0.08617
[32m[0906 19-07-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31360, current rewards: 201.30121, mean: 0.08714
[32m[0906 19-08-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31353, current rewards: 207.59240, mean: 0.08796
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31362, current rewards: 214.08780, mean: 0.08883
[32m[0906 19-08-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31368, current rewards: 220.64219, mean: 0.08969
[32m[0906 19-08-55 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0906 19-08-55 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-08-55 @MBExp.py:227][0m Rewards obtained: [225.84815435074142], Lows: [58], Highs: [62], Total time: 19105.487596000003
[32m[0906 19-09-40 @MBExp.py:144][0m ####################################################################
[32m[0906 19-09-40 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 19-09-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34041, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-10-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32119, current rewards: -42.63139, mean: -0.71052
[32m[0906 19-10-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31937, current rewards: -43.79841, mean: -0.39817
[32m[0906 19-10-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31873, current rewards: -26.95759, mean: -0.16848
[32m[0906 19-10-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31832, current rewards: -9.86118, mean: -0.04696
[32m[0906 19-11-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31813, current rewards: 7.20629, mean: 0.02772
[32m[0906 19-11-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31786, current rewards: 24.29421, mean: 0.07837
[32m[0906 19-11-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31767, current rewards: 41.49745, mean: 0.11527
[32m[0906 19-11-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31743, current rewards: 58.55584, mean: 0.14282
[32m[0906 19-12-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31730, current rewards: 60.27024, mean: 0.13102
[32m[0906 19-12-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31719, current rewards: 43.52771, mean: 0.08535
[32m[0906 19-12-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31709, current rewards: 64.03414, mean: 0.11435
[32m[0906 19-12-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31701, current rewards: 77.43153, mean: 0.12694
[32m[0906 19-13-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31692, current rewards: 82.07688, mean: 0.12436
[32m[0906 19-13-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31686, current rewards: 87.06246, mean: 0.12262
[32m[0906 19-13-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31676, current rewards: 92.24133, mean: 0.12137
[32m[0906 19-13-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31665, current rewards: 63.83345, mean: 0.07881
[32m[0906 19-14-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31658, current rewards: 61.66706, mean: 0.07171
[32m[0906 19-14-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31650, current rewards: 66.81780, mean: 0.07343
[32m[0906 19-14-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31647, current rewards: 70.95273, mean: 0.07391
[32m[0906 19-15-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31638, current rewards: 75.07924, mean: 0.07434
[32m[0906 19-15-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31632, current rewards: 79.20687, mean: 0.07472
[32m[0906 19-15-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31627, current rewards: 83.33335, mean: 0.07508
[32m[0906 19-15-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31621, current rewards: 65.80941, mean: 0.05673
[32m[0906 19-16-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31620, current rewards: 66.65490, mean: 0.05509
[32m[0906 19-16-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31618, current rewards: 69.66799, mean: 0.05529
[32m[0906 19-16-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31614, current rewards: 56.74424, mean: 0.04332
[32m[0906 19-16-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31609, current rewards: 59.86320, mean: 0.04402
[32m[0906 19-17-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31604, current rewards: 63.06420, mean: 0.04473
[32m[0906 19-17-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31598, current rewards: 66.25373, mean: 0.04538
[32m[0906 19-17-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31593, current rewards: 69.45360, mean: 0.04600
[32m[0906 19-17-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31587, current rewards: 66.48737, mean: 0.04262
[32m[0906 19-18-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31582, current rewards: -4.50921, mean: -0.00280
[32m[0906 19-18-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31579, current rewards: 12.57500, mean: 0.00758
[32m[0906 19-18-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31575, current rewards: 32.32419, mean: 0.01890
[32m[0906 19-18-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31572, current rewards: 52.04605, mean: 0.02957
[32m[0906 19-19-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31569, current rewards: 71.77241, mean: 0.03965
[32m[0906 19-19-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31569, current rewards: 91.47826, mean: 0.04918
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31554, current rewards: 86.12015, mean: 0.04509
[32m[0906 19-19-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31535, current rewards: 87.16411, mean: 0.04447
[32m[0906 19-20-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31518, current rewards: 90.76206, mean: 0.04516
[32m[0906 19-20-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31513, current rewards: 94.18959, mean: 0.04572
[32m[0906 19-20-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31478, current rewards: 84.05221, mean: 0.03984
[32m[0906 19-21-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31441, current rewards: 78.68087, mean: 0.03643
[32m[0906 19-21-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31402, current rewards: 82.51229, mean: 0.03734
[32m[0906 19-21-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31385, current rewards: 86.15276, mean: 0.03812
[32m[0906 19-21-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31373, current rewards: 89.74498, mean: 0.03885
[32m[0906 19-22-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31366, current rewards: 93.48273, mean: 0.03961
[32m[0906 19-22-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31374, current rewards: 97.03018, mean: 0.04026
[32m[0906 19-22-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31379, current rewards: 100.70088, mean: 0.04094
[32m[0906 19-22-46 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0906 19-22-46 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-22-46 @MBExp.py:227][0m Rewards obtained: [103.62900036465531], Lows: [104], Highs: [92], Total time: 19890.758435000003
[32m[0906 19-23-33 @MBExp.py:144][0m ####################################################################
[32m[0906 19-23-33 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 19-23-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32049, current rewards: 0.48461, mean: 0.04846
[32m[0906 19-23-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31834, current rewards: 5.69643, mean: 0.09494
[32m[0906 19-24-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31732, current rewards: 10.61202, mean: 0.09647
[32m[0906 19-24-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31702, current rewards: 15.50803, mean: 0.09693
[32m[0906 19-24-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31698, current rewards: 20.40449, mean: 0.09716
[32m[0906 19-24-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31683, current rewards: 25.30153, mean: 0.09731
[32m[0906 19-25-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31696, current rewards: 30.20172, mean: 0.09742
[32m[0906 19-25-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31684, current rewards: 35.09546, mean: 0.09749
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31672, current rewards: 40.29129, mean: 0.09827
[32m[0906 19-25-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31669, current rewards: 24.40257, mean: 0.05305
[32m[0906 19-26-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31676, current rewards: 31.63188, mean: 0.06202
[32m[0906 19-26-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31672, current rewards: 38.76941, mean: 0.06923
[32m[0906 19-26-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31676, current rewards: 45.91097, mean: 0.07526
[32m[0906 19-27-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31677, current rewards: 53.05222, mean: 0.08038
[32m[0906 19-27-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31671, current rewards: 60.19401, mean: 0.08478
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31674, current rewards: 67.32648, mean: 0.08859
[32m[0906 19-27-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31669, current rewards: 74.46881, mean: 0.09194
[32m[0906 19-28-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31662, current rewards: 68.79370, mean: 0.07999
[32m[0906 19-28-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31665, current rewards: 63.57120, mean: 0.06986
[32m[0906 19-28-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31658, current rewards: 69.60327, mean: 0.07250
[32m[0906 19-28-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31653, current rewards: 75.64315, mean: 0.07489
[32m[0906 19-29-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31655, current rewards: 81.67526, mean: 0.07705
[32m[0906 19-29-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31657, current rewards: 87.72276, mean: 0.07903
[32m[0906 19-29-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31655, current rewards: 57.70345, mean: 0.04974
[32m[0906 19-29-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31770, current rewards: 59.85703, mean: 0.04947
[32m[0906 19-30-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31914, current rewards: 64.28963, mean: 0.05102
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32042, current rewards: 70.45565, mean: 0.05378
[32m[0906 19-30-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32161, current rewards: 76.63043, mean: 0.05635
[32m[0906 19-31-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32267, current rewards: 82.80525, mean: 0.05873
[32m[0906 19-31-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32366, current rewards: 88.98108, mean: 0.06095
[32m[0906 19-31-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32459, current rewards: 95.16398, mean: 0.06302
[32m[0906 19-32-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32550, current rewards: 101.33849, mean: 0.06496
[32m[0906 19-32-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32633, current rewards: 107.51816, mean: 0.06678
[32m[0906 19-32-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32711, current rewards: 116.41614, mean: 0.07013
[32m[0906 19-32-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32781, current rewards: 123.06481, mean: 0.07197
[32m[0906 19-33-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32853, current rewards: 129.68898, mean: 0.07369
[32m[0906 19-33-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32920, current rewards: 136.31317, mean: 0.07531
[32m[0906 19-33-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32985, current rewards: 142.93207, mean: 0.07685
[32m[0906 19-34-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33025, current rewards: 149.55794, mean: 0.07830
[32m[0906 19-34-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33060, current rewards: 156.17626, mean: 0.07968
[32m[0906 19-34-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33093, current rewards: 162.80140, mean: 0.08100
[32m[0906 19-34-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33137, current rewards: 149.96096, mean: 0.07280
[32m[0906 19-35-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33142, current rewards: 153.85669, mean: 0.07292
[32m[0906 19-35-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33148, current rewards: 157.74778, mean: 0.07303
[32m[0906 19-35-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33145, current rewards: 161.63825, mean: 0.07314
[32m[0906 19-36-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33169, current rewards: 165.53002, mean: 0.07324
[32m[0906 19-36-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33198, current rewards: 169.42390, mean: 0.07334
[32m[0906 19-36-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33229, current rewards: 173.31764, mean: 0.07344
[32m[0906 19-36-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33276, current rewards: 177.21146, mean: 0.07353
[32m[0906 19-37-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33321, current rewards: 181.37892, mean: 0.07373
[32m[0906 19-37-28 @Agent.py:117][0m Average action selection time: 0.3335
[32m[0906 19-37-28 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-37-28 @MBExp.py:227][0m Rewards obtained: [188.02590100665003], Lows: [22], Highs: [60], Total time: 20725.230492000002
[32m[0906 19-38-23 @MBExp.py:144][0m ####################################################################
[32m[0906 19-38-23 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 19-38-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35555, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-38-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35366, current rewards: -32.66957, mean: -0.54449
[32m[0906 19-39-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35370, current rewards: -82.66957, mean: -0.75154
[32m[0906 19-39-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35348, current rewards: -132.66957, mean: -0.82918
[32m[0906 19-39-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35311, current rewards: -182.66957, mean: -0.86986
[32m[0906 19-39-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35323, current rewards: -232.66957, mean: -0.89488
[32m[0906 19-40-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35319, current rewards: -282.66957, mean: -0.91184
[32m[0906 19-40-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35329, current rewards: -332.66957, mean: -0.92408
[32m[0906 19-40-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35346, current rewards: -382.66957, mean: -0.93334
[32m[0906 19-41-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35333, current rewards: -432.66957, mean: -0.94059
[32m[0906 19-41-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35329, current rewards: -482.66957, mean: -0.94641
[32m[0906 19-41-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35323, current rewards: -532.66957, mean: -0.95120
[32m[0906 19-41-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35321, current rewards: -582.66957, mean: -0.95520
[32m[0906 19-42-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35326, current rewards: -632.66957, mean: -0.95859
[32m[0906 19-42-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35318, current rewards: -682.66957, mean: -0.96151
[32m[0906 19-42-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35314, current rewards: -735.66957, mean: -0.96799
[32m[0906 19-43-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35310, current rewards: -826.33373, mean: -1.02017
[32m[0906 19-43-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35304, current rewards: -876.87997, mean: -1.01963
[32m[0906 19-43-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35292, current rewards: -938.59760, mean: -1.03143
[32m[0906 19-44-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35285, current rewards: -1002.59516, mean: -1.04437
[32m[0906 19-44-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35288, current rewards: -1053.84868, mean: -1.04341
[32m[0906 19-44-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35166, current rewards: -1119.93646, mean: -1.05654
[32m[0906 19-44-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35006, current rewards: -1177.54111, mean: -1.06085
[32m[0906 19-45-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34861, current rewards: -1235.11452, mean: -1.06475
[32m[0906 19-45-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34725, current rewards: -1302.00150, mean: -1.07603
[32m[0906 19-45-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34600, current rewards: -1295.03370, mean: -1.02780
[32m[0906 19-45-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34485, current rewards: -1289.35664, mean: -0.98424
[32m[0906 19-46-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34375, current rewards: -1283.67957, mean: -0.94388
[32m[0906 19-46-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34273, current rewards: -1278.00250, mean: -0.90638
[32m[0906 19-46-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34178, current rewards: -1272.32544, mean: -0.87146
[32m[0906 19-46-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34092, current rewards: -1266.64837, mean: -0.83884
[32m[0906 19-47-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34008, current rewards: -1297.71817, mean: -0.83187
[32m[0906 19-47-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33932, current rewards: -1347.71817, mean: -0.83709
[32m[0906 19-47-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33857, current rewards: -1397.71817, mean: -0.84200
[32m[0906 19-48-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33787, current rewards: -1447.71817, mean: -0.84662
[32m[0906 19-48-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33724, current rewards: -1497.71817, mean: -0.85098
[32m[0906 19-48-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33662, current rewards: -1547.71817, mean: -0.85509
[32m[0906 19-48-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33605, current rewards: -1597.71817, mean: -0.85899
[32m[0906 19-49-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33535, current rewards: -1647.71817, mean: -0.86268
[32m[0906 19-49-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33465, current rewards: -1697.71817, mean: -0.86618
[32m[0906 19-49-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33398, current rewards: -1737.27160, mean: -0.86431
[32m[0906 19-49-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33340, current rewards: -1731.01761, mean: -0.84030
[32m[0906 19-50-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33259, current rewards: -1725.77315, mean: -0.81790
[32m[0906 19-50-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33183, current rewards: -1720.52681, mean: -0.79654
[32m[0906 19-50-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33101, current rewards: -1715.28131, mean: -0.77615
[32m[0906 19-50-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33045, current rewards: -1710.03332, mean: -0.75665
[32m[0906 19-51-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32998, current rewards: -1728.19203, mean: -0.74814
[32m[0906 19-51-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32954, current rewards: -1723.70838, mean: -0.73038
[32m[0906 19-51-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32927, current rewards: -1719.44690, mean: -0.71346
[32m[0906 19-51-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32902, current rewards: -1744.22593, mean: -0.70903
[32m[0906 19-52-05 @Agent.py:117][0m Average action selection time: 0.3288
[32m[0906 19-52-05 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-52-05 @MBExp.py:227][0m Rewards obtained: [-1780.0424723421547], Lows: [327], Highs: [1238], Total time: 21547.922914000002
[32m[0906 19-52-57 @MBExp.py:144][0m ####################################################################
[32m[0906 19-52-57 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 19-53-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32003, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-53-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31694, current rewards: -15.57628, mean: -0.25960
[32m[0906 19-53-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31687, current rewards: -7.69801, mean: -0.06998
[32m[0906 19-53-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31697, current rewards: 0.19934, mean: 0.00125
[32m[0906 19-54-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31690, current rewards: 8.10026, mean: 0.03857
[32m[0906 19-54-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31688, current rewards: 15.98578, mean: 0.06148
[32m[0906 19-54-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31682, current rewards: 23.87405, mean: 0.07701
[32m[0906 19-54-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31670, current rewards: -12.02845, mean: -0.03341
[32m[0906 19-55-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31648, current rewards: -7.67693, mean: -0.01872
[32m[0906 19-55-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31631, current rewards: -1.32958, mean: -0.00289
[32m[0906 19-55-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31620, current rewards: 5.00724, mean: 0.00982
[32m[0906 19-55-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31600, current rewards: 11.33820, mean: 0.02025
[32m[0906 19-56-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31589, current rewards: 17.66152, mean: 0.02895
[32m[0906 19-56-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31583, current rewards: 23.99167, mean: 0.03635
[32m[0906 19-56-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31581, current rewards: 30.32848, mean: 0.04272
[32m[0906 19-56-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31576, current rewards: 36.64969, mean: 0.04822
[32m[0906 19-57-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31579, current rewards: 43.16881, mean: 0.05329
[32m[0906 19-57-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31579, current rewards: 49.54574, mean: 0.05761
[32m[0906 19-57-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31574, current rewards: 55.92798, mean: 0.06146
[32m[0906 19-58-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31577, current rewards: 62.29681, mean: 0.06489
[32m[0906 19-58-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31573, current rewards: 68.67994, mean: 0.06800
[32m[0906 19-58-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31570, current rewards: 75.06458, mean: 0.07082
[32m[0906 19-58-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31566, current rewards: 81.43314, mean: 0.07336
[32m[0906 19-59-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31563, current rewards: 87.81655, mean: 0.07570
[32m[0906 19-59-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31561, current rewards: 93.87255, mean: 0.07758
[32m[0906 19-59-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31559, current rewards: 100.16335, mean: 0.07949
[32m[0906 19-59-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31559, current rewards: 103.58550, mean: 0.07907
[32m[0906 20-00-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31556, current rewards: 106.54747, mean: 0.07834
[32m[0906 20-00-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31554, current rewards: 109.57777, mean: 0.07771
[32m[0906 20-00-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31548, current rewards: 112.64053, mean: 0.07715
[32m[0906 20-00-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31542, current rewards: 115.71534, mean: 0.07663
[32m[0906 20-01-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31538, current rewards: 118.80508, mean: 0.07616
[32m[0906 20-01-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31537, current rewards: 122.36675, mean: 0.07600
[32m[0906 20-01-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31536, current rewards: 126.09314, mean: 0.07596
[32m[0906 20-01-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31535, current rewards: 129.75843, mean: 0.07588
[32m[0906 20-02-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31532, current rewards: 133.42129, mean: 0.07581
[32m[0906 20-02-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31531, current rewards: 137.08402, mean: 0.07574
[32m[0906 20-02-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31530, current rewards: 140.74236, mean: 0.07567
[32m[0906 20-02-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31513, current rewards: 144.40198, mean: 0.07560
[32m[0906 20-03-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31496, current rewards: 148.05315, mean: 0.07554
[32m[0906 20-03-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31481, current rewards: 152.33566, mean: 0.07579
[32m[0906 20-03-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31463, current rewards: 157.45574, mean: 0.07643
[32m[0906 20-04-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31427, current rewards: 120.42907, mean: 0.05708
[32m[0906 20-04-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: 125.01978, mean: 0.05788
[32m[0906 20-04-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31352, current rewards: 129.54693, mean: 0.05862
[32m[0906 20-04-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31335, current rewards: 134.07451, mean: 0.05933
[32m[0906 20-05-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31326, current rewards: 138.60431, mean: 0.06000
[32m[0906 20-05-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31318, current rewards: 143.13251, mean: 0.06065
[32m[0906 20-05-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31330, current rewards: 147.62018, mean: 0.06125
[32m[0906 20-05-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31341, current rewards: 151.03791, mean: 0.06140
[32m[0906 20-06-01 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0906 20-06-01 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-06-01 @MBExp.py:227][0m Rewards obtained: [154.54271043356482], Lows: [40], Highs: [21], Total time: 22332.252777
[32m[0906 20-06-54 @MBExp.py:144][0m ####################################################################
[32m[0906 20-06-54 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 20-06-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31736, current rewards: 0.77710, mean: 0.07771
[32m[0906 20-07-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31755, current rewards: 6.46341, mean: 0.10772
[32m[0906 20-07-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31719, current rewards: 13.61684, mean: 0.12379
[32m[0906 20-07-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31696, current rewards: 20.77510, mean: 0.12984
[32m[0906 20-08-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31671, current rewards: 27.93104, mean: 0.13300
[32m[0906 20-08-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31664, current rewards: 35.08757, mean: 0.13495
[32m[0906 20-08-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31665, current rewards: 42.23598, mean: 0.13625
[32m[0906 20-08-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31674, current rewards: 48.49468, mean: 0.13471
[32m[0906 20-09-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31661, current rewards: 55.82425, mean: 0.13616
[32m[0906 20-09-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31663, current rewards: 63.22228, mean: 0.13744
[32m[0906 20-09-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31661, current rewards: 70.62191, mean: 0.13847
[32m[0906 20-09-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31666, current rewards: 78.02133, mean: 0.13932
[32m[0906 20-10-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31664, current rewards: 85.42090, mean: 0.14003
[32m[0906 20-10-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31655, current rewards: 92.81079, mean: 0.14062
[32m[0906 20-10-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31651, current rewards: 100.20371, mean: 0.14113
[32m[0906 20-10-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31653, current rewards: 78.81181, mean: 0.10370
[32m[0906 20-11-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31657, current rewards: 85.95710, mean: 0.10612
[32m[0906 20-11-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31659, current rewards: 91.54966, mean: 0.10645
[32m[0906 20-11-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31658, current rewards: 97.14958, mean: 0.10676
[32m[0906 20-11-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31655, current rewards: 102.45351, mean: 0.10672
[32m[0906 20-12-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31646, current rewards: 107.54085, mean: 0.10648
[32m[0906 20-12-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31636, current rewards: 113.38927, mean: 0.10697
[32m[0906 20-12-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31634, current rewards: 119.23250, mean: 0.10742
[32m[0906 20-13-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31631, current rewards: 124.99146, mean: 0.10775
[32m[0906 20-13-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31624, current rewards: 129.65042, mean: 0.10715
[32m[0906 20-13-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31690, current rewards: 134.85986, mean: 0.10703
[32m[0906 20-13-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31826, current rewards: 140.09594, mean: 0.10694
[32m[0906 20-14-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31952, current rewards: 145.34129, mean: 0.10687
[32m[0906 20-14-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32069, current rewards: 150.57662, mean: 0.10679
[32m[0906 20-14-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32178, current rewards: 113.48655, mean: 0.07773
[32m[0906 20-15-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32279, current rewards: 120.18962, mean: 0.07960
[32m[0906 20-15-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32374, current rewards: 126.94156, mean: 0.08137
[32m[0906 20-15-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32464, current rewards: 138.77674, mean: 0.08620
[32m[0906 20-15-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32549, current rewards: 145.46046, mean: 0.08763
[32m[0906 20-16-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32626, current rewards: 152.20781, mean: 0.08901
[32m[0906 20-16-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32700, current rewards: 158.96345, mean: 0.09032
[32m[0906 20-16-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32769, current rewards: 165.71976, mean: 0.09156
[32m[0906 20-17-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32830, current rewards: 172.47429, mean: 0.09273
[32m[0906 20-17-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32870, current rewards: 136.79559, mean: 0.07162
[32m[0906 20-17-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32909, current rewards: 144.26768, mean: 0.07361
[32m[0906 20-17-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32946, current rewards: 155.09335, mean: 0.07716
[32m[0906 20-18-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32973, current rewards: 162.53548, mean: 0.07890
[32m[0906 20-18-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32981, current rewards: 170.17472, mean: 0.08065
[32m[0906 20-18-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32991, current rewards: 177.81977, mean: 0.08232
[32m[0906 20-19-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32984, current rewards: 185.45395, mean: 0.08392
[32m[0906 20-19-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33007, current rewards: 193.08811, mean: 0.08544
[32m[0906 20-19-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33038, current rewards: 200.73959, mean: 0.08690
[32m[0906 20-19-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33070, current rewards: 208.37573, mean: 0.08829
[32m[0906 20-20-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33124, current rewards: 215.14222, mean: 0.08927
[32m[0906 20-20-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33171, current rewards: 222.19974, mean: 0.09033
[32m[0906 20-20-45 @Agent.py:117][0m Average action selection time: 0.3321
[32m[0906 20-20-45 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-20-45 @MBExp.py:227][0m Rewards obtained: [228.19303931669927], Lows: [45], Highs: [20], Total time: 23163.095346000002
[32m[0906 20-21-47 @MBExp.py:144][0m ####################################################################
[32m[0906 20-21-47 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 20-21-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35571, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-22-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35546, current rewards: -19.43105, mean: -0.32385
[32m[0906 20-22-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35466, current rewards: -12.87950, mean: -0.11709
[32m[0906 20-22-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35421, current rewards: -6.50941, mean: -0.04068
[32m[0906 20-23-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35393, current rewards: -0.14941, mean: -0.00071
[32m[0906 20-23-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35368, current rewards: 6.22120, mean: 0.02393
[32m[0906 20-23-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35343, current rewards: 12.58644, mean: 0.04060
[32m[0906 20-23-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35359, current rewards: 20.96885, mean: 0.05825
[32m[0906 20-24-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35346, current rewards: 28.00511, mean: 0.06831
[32m[0906 20-24-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35332, current rewards: 34.95797, mean: 0.07600
[32m[0906 20-24-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35324, current rewards: 41.92069, mean: 0.08220
[32m[0906 20-25-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35324, current rewards: 48.88648, mean: 0.08730
[32m[0906 20-25-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35317, current rewards: 55.85675, mean: 0.09157
[32m[0906 20-25-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35304, current rewards: 43.44489, mean: 0.06583
[32m[0906 20-25-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35295, current rewards: 50.54378, mean: 0.07119
[32m[0906 20-26-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35292, current rewards: 54.86839, mean: 0.07220
[32m[0906 20-26-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35287, current rewards: 58.41468, mean: 0.07212
[32m[0906 20-26-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35281, current rewards: 63.74992, mean: 0.07413
[32m[0906 20-27-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35279, current rewards: 67.48719, mean: 0.07416
[32m[0906 20-27-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35277, current rewards: 71.25404, mean: 0.07422
[32m[0906 20-27-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35275, current rewards: 75.01027, mean: 0.07427
[32m[0906 20-28-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35271, current rewards: 78.76132, mean: 0.07430
[32m[0906 20-28-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35266, current rewards: 82.51492, mean: 0.07434
[32m[0906 20-28-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35260, current rewards: 86.39837, mean: 0.07448
[32m[0906 20-28-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35257, current rewards: 92.34352, mean: 0.07632
[32m[0906 20-29-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35258, current rewards: 71.99706, mean: 0.05714
[32m[0906 20-29-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35255, current rewards: 59.98855, mean: 0.04579
[32m[0906 20-29-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35251, current rewards: 65.73695, mean: 0.04834
[32m[0906 20-30-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35251, current rewards: 71.47547, mean: 0.05069
[32m[0906 20-30-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35247, current rewards: 77.18213, mean: 0.05286
[32m[0906 20-30-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35248, current rewards: 82.90365, mean: 0.05490
[32m[0906 20-30-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35248, current rewards: 88.62588, mean: 0.05681
[32m[0906 20-31-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35245, current rewards: 97.34161, mean: 0.06046
[32m[0906 20-31-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35244, current rewards: 103.61112, mean: 0.06242
[32m[0906 20-31-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35241, current rewards: 109.89912, mean: 0.06427
[32m[0906 20-32-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35242, current rewards: 116.32054, mean: 0.06609
[32m[0906 20-32-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35241, current rewards: 122.50418, mean: 0.06768
[32m[0906 20-32-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35233, current rewards: 115.33323, mean: 0.06201
[32m[0906 20-33-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35210, current rewards: 117.98345, mean: 0.06177
[32m[0906 20-33-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35188, current rewards: 127.35788, mean: 0.06498
[32m[0906 20-33-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35165, current rewards: 148.39411, mean: 0.07383
[32m[0906 20-33-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35133, current rewards: 142.65716, mean: 0.06925
[32m[0906 20-34-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35088, current rewards: 157.97684, mean: 0.07487
[32m[0906 20-34-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35047, current rewards: 139.40057, mean: 0.06454
[32m[0906 20-34-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34991, current rewards: 146.92890, mean: 0.06648
[32m[0906 20-34-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34968, current rewards: 153.84264, mean: 0.06807
[32m[0906 20-35-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34958, current rewards: 160.77751, mean: 0.06960
[32m[0906 20-35-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34949, current rewards: 167.71607, mean: 0.07107
[32m[0906 20-35-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34959, current rewards: 173.34580, mean: 0.07193
[32m[0906 20-36-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34970, current rewards: 179.94556, mean: 0.07315
[32m[0906 20-36-22 @Agent.py:117][0m Average action selection time: 0.3498
[32m[0906 20-36-22 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-36-22 @MBExp.py:227][0m Rewards obtained: [185.02254932895391], Lows: [47], Highs: [60], Total time: 24038.16283
[32m[0906 20-37-27 @MBExp.py:144][0m ####################################################################
[32m[0906 20-37-27 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 20-37-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35450, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-37-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35391, current rewards: -21.93386, mean: -0.36556
[32m[0906 20-38-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35362, current rewards: -41.34833, mean: -0.37589
[32m[0906 20-38-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35378, current rewards: -60.81119, mean: -0.38007
[32m[0906 20-38-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35354, current rewards: -80.30646, mean: -0.38241
[32m[0906 20-38-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35358, current rewards: -93.43203, mean: -0.35935
[32m[0906 20-39-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35339, current rewards: -136.71955, mean: -0.44103
[32m[0906 20-39-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35337, current rewards: -130.67050, mean: -0.36297
[32m[0906 20-39-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35347, current rewards: -122.90979, mean: -0.29978
[32m[0906 20-40-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35338, current rewards: -115.14126, mean: -0.25031
[32m[0906 20-40-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35326, current rewards: -107.35691, mean: -0.21050
[32m[0906 20-40-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35319, current rewards: -123.34168, mean: -0.22025
[32m[0906 20-41-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35314, current rewards: -116.20691, mean: -0.19050
[32m[0906 20-41-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35310, current rewards: -109.35862, mean: -0.16569
[32m[0906 20-41-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35309, current rewards: -102.52446, mean: -0.14440
[32m[0906 20-41-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35295, current rewards: -95.68105, mean: -0.12590
[32m[0906 20-42-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35291, current rewards: -88.81609, mean: -0.10965
[32m[0906 20-42-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35284, current rewards: -81.98293, mean: -0.09533
[32m[0906 20-42-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35279, current rewards: -75.13313, mean: -0.08256
[32m[0906 20-43-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35272, current rewards: -68.29086, mean: -0.07114
[32m[0906 20-43-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35267, current rewards: -61.43717, mean: -0.06083
[32m[0906 20-43-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35268, current rewards: -54.59842, mean: -0.05151
[32m[0906 20-43-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35265, current rewards: -47.75914, mean: -0.04303
[32m[0906 20-44-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35262, current rewards: -82.49481, mean: -0.07112
[32m[0906 20-44-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35262, current rewards: -79.26028, mean: -0.06550
[32m[0906 20-44-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35321, current rewards: -75.06633, mean: -0.05958
[32m[0906 20-45-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35400, current rewards: -70.83286, mean: -0.05407
[32m[0906 20-45-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35478, current rewards: -66.61532, mean: -0.04898
[32m[0906 20-45-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35552, current rewards: -62.40452, mean: -0.04426
[32m[0906 20-46-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35615, current rewards: -58.18795, mean: -0.03985
[32m[0906 20-46-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35676, current rewards: -53.95482, mean: -0.03573
[32m[0906 20-46-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35736, current rewards: -71.43570, mean: -0.04579
[32m[0906 20-47-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35794, current rewards: -63.77901, mean: -0.03961
[32m[0906 20-47-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35848, current rewards: -57.20058, mean: -0.03446
[32m[0906 20-47-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35907, current rewards: -50.60475, mean: -0.02959
[32m[0906 20-48-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35952, current rewards: -44.04031, mean: -0.02502
[32m[0906 20-48-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35935, current rewards: -37.46437, mean: -0.02070
[32m[0906 20-48-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35908, current rewards: -30.87624, mean: -0.01660
[32m[0906 20-48-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35868, current rewards: -62.67395, mean: -0.03281
[32m[0906 20-49-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35829, current rewards: -71.88370, mean: -0.03668
[32m[0906 20-49-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35793, current rewards: -103.92073, mean: -0.05170
[32m[0906 20-49-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35744, current rewards: -153.92073, mean: -0.07472
[32m[0906 20-50-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35687, current rewards: -193.22577, mean: -0.09158
[32m[0906 20-50-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35632, current rewards: -182.29435, mean: -0.08440
[32m[0906 20-50-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35560, current rewards: -175.36769, mean: -0.07935
[32m[0906 20-50-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35524, current rewards: -168.44103, mean: -0.07453
[32m[0906 20-51-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35502, current rewards: -169.48410, mean: -0.07337
[32m[0906 20-51-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35480, current rewards: -219.48410, mean: -0.09300
[32m[0906 20-51-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35478, current rewards: -269.48410, mean: -0.11182
[32m[0906 20-52-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35474, current rewards: -319.48410, mean: -0.12987
[32m[0906 20-52-14 @Agent.py:117][0m Average action selection time: 0.3547
[32m[0906 20-52-14 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-52-14 @MBExp.py:227][0m Rewards obtained: [-359.4841024506818], Lows: [60], Highs: [477], Total time: 24925.664950000002
[32m[0906 20-53-19 @MBExp.py:144][0m ####################################################################
[32m[0906 20-53-19 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 20-53-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35470, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-53-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35395, current rewards: -9.15792, mean: -0.15263
[32m[0906 20-53-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35370, current rewards: 3.55779, mean: 0.03234
[32m[0906 20-54-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35329, current rewards: 19.33219, mean: 0.12083
[32m[0906 20-54-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35301, current rewards: 31.77757, mean: 0.15132
[32m[0906 20-54-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35305, current rewards: 45.87303, mean: 0.17643
[32m[0906 20-55-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35301, current rewards: -8.61066, mean: -0.02778
[32m[0906 20-55-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35301, current rewards: -42.31349, mean: -0.11754
[32m[0906 20-55-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35297, current rewards: -61.71966, mean: -0.15054
[32m[0906 20-56-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35300, current rewards: -56.57115, mean: -0.12298
[32m[0906 20-56-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35301, current rewards: -52.02081, mean: -0.10200
[32m[0906 20-56-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35304, current rewards: -47.46168, mean: -0.08475
[32m[0906 20-56-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35306, current rewards: -42.90306, mean: -0.07033
[32m[0906 20-57-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35303, current rewards: -33.43147, mean: -0.05065
[32m[0906 20-57-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35294, current rewards: -29.85331, mean: -0.04205
[32m[0906 20-57-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35289, current rewards: -40.60141, mean: -0.05342
[32m[0906 20-58-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35285, current rewards: -36.79472, mean: -0.04543
[32m[0906 20-58-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35278, current rewards: -33.08720, mean: -0.03847
[32m[0906 20-58-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35278, current rewards: -29.37266, mean: -0.03228
[32m[0906 20-58-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35274, current rewards: -25.66401, mean: -0.02673
[32m[0906 20-59-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35271, current rewards: -21.95503, mean: -0.02174
[32m[0906 20-59-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35269, current rewards: -18.24337, mean: -0.01721
[32m[0906 20-59-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35264, current rewards: -14.53200, mean: -0.01309
[32m[0906 21-00-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35261, current rewards: -8.17839, mean: -0.00705
[32m[0906 21-00-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35253, current rewards: -44.47802, mean: -0.03676
[32m[0906 21-00-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35248, current rewards: -39.82229, mean: -0.03160
[32m[0906 21-01-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35244, current rewards: -35.15897, mean: -0.02684
[32m[0906 21-01-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35237, current rewards: -30.49626, mean: -0.02242
[32m[0906 21-01-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35230, current rewards: -25.83214, mean: -0.01832
[32m[0906 21-01-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35227, current rewards: -47.72778, mean: -0.03269
[32m[0906 21-02-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35224, current rewards: -44.26600, mean: -0.02932
[32m[0906 21-02-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35223, current rewards: -40.66769, mean: -0.02607
[32m[0906 21-02-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35219, current rewards: -47.17715, mean: -0.02930
[32m[0906 21-03-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35218, current rewards: -43.48157, mean: -0.02619
[32m[0906 21-03-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35217, current rewards: -39.78400, mean: -0.02327
[32m[0906 21-03-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35217, current rewards: -36.08535, mean: -0.02050
[32m[0906 21-03-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35214, current rewards: -73.37235, mean: -0.04054
[32m[0906 21-04-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35205, current rewards: -69.05556, mean: -0.03713
[32m[0906 21-04-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35184, current rewards: -64.74619, mean: -0.03390
[32m[0906 21-04-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35162, current rewards: -60.43382, mean: -0.03083
[32m[0906 21-05-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35142, current rewards: -56.17575, mean: -0.02795
[32m[0906 21-05-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35101, current rewards: -51.86217, mean: -0.02518
[32m[0906 21-05-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35059, current rewards: -47.47261, mean: -0.02250
[32m[0906 21-05-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35019, current rewards: -43.08310, mean: -0.01995
[32m[0906 21-06-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34958, current rewards: -38.69191, mean: -0.01751
[32m[0906 21-06-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34932, current rewards: -48.44375, mean: -0.02144
[32m[0906 21-06-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34921, current rewards: -58.76023, mean: -0.02544
[32m[0906 21-07-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34911, current rewards: -55.02917, mean: -0.02332
[32m[0906 21-07-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34922, current rewards: -51.14407, mean: -0.02122
[32m[0906 21-07-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34935, current rewards: -47.38289, mean: -0.01926
[32m[0906 21-07-54 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0906 21-07-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-07-54 @MBExp.py:227][0m Rewards obtained: [-44.37005190282506], Lows: [104], Highs: [115], Total time: 25799.809587000003
[32m[0906 21-09-01 @MBExp.py:144][0m ####################################################################
[32m[0906 21-09-01 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 21-09-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35672, current rewards: -7.90255, mean: -0.79026
[32m[0906 21-09-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35482, current rewards: -23.97251, mean: -0.39954
[32m[0906 21-09-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35432, current rewards: -18.56817, mean: -0.16880
[32m[0906 21-09-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35414, current rewards: -13.08566, mean: -0.08179
[32m[0906 21-10-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35393, current rewards: -7.61491, mean: -0.03626
[32m[0906 21-10-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35390, current rewards: -2.13916, mean: -0.00823
[32m[0906 21-10-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35374, current rewards: 3.34723, mean: 0.01080
[32m[0906 21-11-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35352, current rewards: 11.71234, mean: 0.03253
[32m[0906 21-11-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35360, current rewards: 17.37570, mean: 0.04238
[32m[0906 21-11-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35349, current rewards: 23.04009, mean: 0.05009
[32m[0906 21-12-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35349, current rewards: 28.69979, mean: 0.05627
[32m[0906 21-12-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35339, current rewards: 34.36352, mean: 0.06136
[32m[0906 21-12-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35324, current rewards: 40.02384, mean: 0.06561
[32m[0906 21-12-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35309, current rewards: 31.21289, mean: 0.04729
[32m[0906 21-13-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35301, current rewards: 29.58515, mean: 0.04167
[32m[0906 21-13-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35289, current rewards: 36.64616, mean: 0.04822
[32m[0906 21-13-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35292, current rewards: 43.29178, mean: 0.05345
[32m[0906 21-14-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35290, current rewards: 49.89064, mean: 0.05801
[32m[0906 21-14-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35286, current rewards: 56.26664, mean: 0.06183
[32m[0906 21-14-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35280, current rewards: 61.55874, mean: 0.06412
[32m[0906 21-14-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35281, current rewards: 67.75217, mean: 0.06708
[32m[0906 21-15-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35280, current rewards: 73.93630, mean: 0.06975
[32m[0906 21-15-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35280, current rewards: 80.10380, mean: 0.07217
[32m[0906 21-15-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35280, current rewards: 86.26794, mean: 0.07437
[32m[0906 21-16-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35278, current rewards: 52.08760, mean: 0.04305
[32m[0906 21-16-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35269, current rewards: 56.79464, mean: 0.04508
[32m[0906 21-16-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35266, current rewards: 62.95646, mean: 0.04806
[32m[0906 21-17-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35259, current rewards: 69.11913, mean: 0.05082
[32m[0906 21-17-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35259, current rewards: 75.27916, mean: 0.05339
[32m[0906 21-17-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35257, current rewards: 81.44084, mean: 0.05578
[32m[0906 21-17-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35253, current rewards: 87.60107, mean: 0.05801
[32m[0906 21-18-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35250, current rewards: 92.57234, mean: 0.05934
[32m[0906 21-18-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35250, current rewards: 97.45890, mean: 0.06053
[32m[0906 21-18-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35250, current rewards: 102.21430, mean: 0.06157
[32m[0906 21-19-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35245, current rewards: 106.97260, mean: 0.06256
[32m[0906 21-19-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35242, current rewards: 111.72274, mean: 0.06348
[32m[0906 21-19-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35240, current rewards: 116.47218, mean: 0.06435
[32m[0906 21-19-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35229, current rewards: 121.22001, mean: 0.06517
[32m[0906 21-20-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35206, current rewards: 125.97366, mean: 0.06595
[32m[0906 21-20-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35185, current rewards: 131.74995, mean: 0.06722
[32m[0906 21-20-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35161, current rewards: 136.76547, mean: 0.06804
[32m[0906 21-21-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35116, current rewards: 116.49467, mean: 0.05655
[32m[0906 21-21-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35072, current rewards: 111.80623, mean: 0.05299
[32m[0906 21-21-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35030, current rewards: 118.62294, mean: 0.05492
[32m[0906 21-21-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34967, current rewards: 125.43403, mean: 0.05676
[32m[0906 21-22-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34940, current rewards: 132.24511, mean: 0.05852
[32m[0906 21-22-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34930, current rewards: 139.05622, mean: 0.06020
[32m[0906 21-22-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34920, current rewards: 144.04140, mean: 0.06103
[32m[0906 21-23-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34930, current rewards: 149.32403, mean: 0.06196
[32m[0906 21-23-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34940, current rewards: 154.94264, mean: 0.06298
[32m[0906 21-23-36 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0906 21-23-36 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-23-36 @MBExp.py:227][0m Rewards obtained: [159.43372356826518], Lows: [41], Highs: [47], Total time: 26674.189885000003
[32m[0906 21-24-45 @MBExp.py:144][0m ####################################################################
[32m[0906 21-24-45 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 21-24-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35719, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-25-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35470, current rewards: -13.94580, mean: -0.23243
[32m[0906 21-25-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35398, current rewards: -8.02215, mean: -0.07293
[32m[0906 21-25-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35383, current rewards: -2.08080, mean: -0.01300
[32m[0906 21-26-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35397, current rewards: 3.85626, mean: 0.01836
[32m[0906 21-26-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35393, current rewards: 9.79689, mean: 0.03768
[32m[0906 21-26-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35392, current rewards: 14.32458, mean: 0.04621
[32m[0906 21-26-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35376, current rewards: 20.32832, mean: 0.05647
[32m[0906 21-27-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35383, current rewards: 26.17164, mean: 0.06383
[32m[0906 21-27-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35376, current rewards: 32.02314, mean: 0.06962
[32m[0906 21-27-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35371, current rewards: 18.88078, mean: 0.03702
[32m[0906 21-28-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35367, current rewards: 20.80030, mean: 0.03714
[32m[0906 21-28-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35361, current rewards: 26.25078, mean: 0.04303
[32m[0906 21-28-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35360, current rewards: 31.69594, mean: 0.04802
[32m[0906 21-28-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35351, current rewards: 39.65653, mean: 0.05585
[32m[0906 21-29-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35351, current rewards: 48.17434, mean: 0.06339
[32m[0906 21-29-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35348, current rewards: 53.66949, mean: 0.06626
[32m[0906 21-29-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35341, current rewards: 50.72626, mean: 0.05898
[32m[0906 21-30-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35337, current rewards: 23.30132, mean: 0.02561
[32m[0906 21-30-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35336, current rewards: 28.75246, mean: 0.02995
[32m[0906 21-30-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35329, current rewards: 34.19078, mean: 0.03385
[32m[0906 21-31-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35326, current rewards: 39.63003, mean: 0.03739
[32m[0906 21-31-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35325, current rewards: 45.06533, mean: 0.04060
[32m[0906 21-31-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35320, current rewards: 49.30354, mean: 0.04250
[32m[0906 21-31-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35315, current rewards: 16.63978, mean: 0.01375
[32m[0906 21-32-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35306, current rewards: 19.03722, mean: 0.01511
[32m[0906 21-32-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35302, current rewards: 24.77693, mean: 0.01891
[32m[0906 21-32-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35294, current rewards: 30.50410, mean: 0.02243
[32m[0906 21-33-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35291, current rewards: 36.23026, mean: 0.02570
[32m[0906 21-33-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35287, current rewards: 18.06399, mean: 0.01237
[32m[0906 21-33-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35283, current rewards: 23.44434, mean: 0.01553
[32m[0906 21-33-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35279, current rewards: 28.70777, mean: 0.01840
[32m[0906 21-34-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35279, current rewards: 34.04024, mean: 0.02114
[32m[0906 21-34-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35278, current rewards: 39.36623, mean: 0.02371
[32m[0906 21-34-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35277, current rewards: 44.69528, mean: 0.02614
[32m[0906 21-35-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35280, current rewards: 7.93196, mean: 0.00451
[32m[0906 21-35-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35281, current rewards: 12.67986, mean: 0.00701
[32m[0906 21-35-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35269, current rewards: 17.39542, mean: 0.00935
[32m[0906 21-35-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35247, current rewards: 22.10327, mean: 0.01157
[32m[0906 21-36-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35225, current rewards: 25.85550, mean: 0.01319
[32m[0906 21-36-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35200, current rewards: 30.28619, mean: 0.01507
[32m[0906 21-36-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35151, current rewards: 34.31942, mean: 0.01666
[32m[0906 21-37-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35108, current rewards: 38.34957, mean: 0.01818
[32m[0906 21-37-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35065, current rewards: 42.38322, mean: 0.01962
[32m[0906 21-37-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35000, current rewards: 46.41412, mean: 0.02100
[32m[0906 21-37-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34968, current rewards: 50.43860, mean: 0.02232
[32m[0906 21-38-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34958, current rewards: 54.46960, mean: 0.02358
[32m[0906 21-38-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34947, current rewards: 60.21717, mean: 0.02552
[32m[0906 21-38-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34954, current rewards: 55.09436, mean: 0.02286
[32m[0906 21-39-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34960, current rewards: 20.02092, mean: 0.00814
[32m[0906 21-39-20 @Agent.py:117][0m Average action selection time: 0.3497
[32m[0906 21-39-20 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-39-20 @MBExp.py:227][0m Rewards obtained: [32.258888831968825], Lows: [89], Highs: [61], Total time: 27549.032462000003
[32m[0906 21-40-32 @MBExp.py:144][0m ####################################################################
[32m[0906 21-40-32 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 21-40-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35288, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-40-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35374, current rewards: -37.21887, mean: -0.62031
[32m[0906 21-41-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35395, current rewards: -32.71314, mean: -0.29739
[32m[0906 21-41-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35390, current rewards: -28.21586, mean: -0.17635
[32m[0906 21-41-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35367, current rewards: -23.71822, mean: -0.11294
[32m[0906 21-42-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35349, current rewards: -19.22091, mean: -0.07393
[32m[0906 21-42-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35337, current rewards: -14.72605, mean: -0.04750
[32m[0906 21-42-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35337, current rewards: -10.23071, mean: -0.02842
[32m[0906 21-42-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35323, current rewards: -27.67247, mean: -0.06749
[32m[0906 21-43-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35324, current rewards: -24.10778, mean: -0.05241
[32m[0906 21-43-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35327, current rewards: -20.74223, mean: -0.04067
[32m[0906 21-43-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35328, current rewards: -17.37946, mean: -0.03103
[32m[0906 21-44-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35326, current rewards: -14.00948, mean: -0.02297
[32m[0906 21-44-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35325, current rewards: -10.64270, mean: -0.01613
[32m[0906 21-44-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35325, current rewards: -7.04131, mean: -0.00992
[32m[0906 21-45-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35329, current rewards: -1.93817, mean: -0.00255
[32m[0906 21-45-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35325, current rewards: 1.41258, mean: 0.00174
[32m[0906 21-45-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35324, current rewards: 4.75376, mean: 0.00553
[32m[0906 21-45-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35322, current rewards: 8.09726, mean: 0.00890
[32m[0906 21-46-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35326, current rewards: 11.44324, mean: 0.01192
[32m[0906 21-46-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35324, current rewards: -1.21567, mean: -0.00120
[32m[0906 21-46-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35320, current rewards: -2.87089, mean: -0.00271
[32m[0906 21-47-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35320, current rewards: 0.20416, mean: 0.00018
[32m[0906 21-47-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35315, current rewards: -12.23173, mean: -0.01054
[32m[0906 21-47-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35315, current rewards: -8.83426, mean: -0.00730
[32m[0906 21-47-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35310, current rewards: -5.44279, mean: -0.00432
[32m[0906 21-48-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35307, current rewards: -2.06819, mean: -0.00158
[32m[0906 21-48-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35309, current rewards: 1.30714, mean: 0.00096
[32m[0906 21-48-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35309, current rewards: 4.68152, mean: 0.00332
[32m[0906 21-49-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35308, current rewards: 8.05621, mean: 0.00552
[32m[0906 21-49-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35303, current rewards: -29.83492, mean: -0.01976
[32m[0906 21-49-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35299, current rewards: -22.87277, mean: -0.01466
[32m[0906 21-50-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35296, current rewards: -17.62469, mean: -0.01095
[32m[0906 21-50-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35294, current rewards: -13.65544, mean: -0.00823
[32m[0906 21-50-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35289, current rewards: -9.68441, mean: -0.00566
[32m[0906 21-50-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35287, current rewards: -27.54250, mean: -0.01565
[32m[0906 21-51-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35283, current rewards: -33.27976, mean: -0.01839
[32m[0906 21-51-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35268, current rewards: -30.04042, mean: -0.01615
[32m[0906 21-51-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35243, current rewards: -26.84209, mean: -0.01405
[32m[0906 21-52-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35219, current rewards: -23.65778, mean: -0.01207
[32m[0906 21-52-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35192, current rewards: -31.00270, mean: -0.01542
[32m[0906 21-52-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35141, current rewards: -27.52965, mean: -0.01336
[32m[0906 21-52-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35098, current rewards: -24.25861, mean: -0.01150
[32m[0906 21-53-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35054, current rewards: -58.69751, mean: -0.02717
[32m[0906 21-53-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34990, current rewards: -52.80733, mean: -0.02389
[32m[0906 21-53-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34955, current rewards: -48.17781, mean: -0.02132
[32m[0906 21-54-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34945, current rewards: -43.55604, mean: -0.01886
[32m[0906 21-54-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34933, current rewards: -38.92911, mean: -0.01650
[32m[0906 21-54-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34943, current rewards: -37.36978, mean: -0.01551
[32m[0906 21-54-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34952, current rewards: -36.63496, mean: -0.01489
[32m[0906 21-55-06 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 21-55-06 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-55-06 @MBExp.py:227][0m Rewards obtained: [-32.907754826619765], Lows: [45], Highs: [133], Total time: 28423.672427
[32m[0906 21-56-20 @MBExp.py:144][0m ####################################################################
[32m[0906 21-56-20 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 21-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35506, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-56-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35438, current rewards: -68.22831, mean: -1.13714
[32m[0906 21-56-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35426, current rewards: -168.22831, mean: -1.52935
[32m[0906 21-57-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35348, current rewards: -268.22831, mean: -1.67643
[32m[0906 21-57-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35339, current rewards: -368.22831, mean: -1.75347
[32m[0906 21-57-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35327, current rewards: -468.22831, mean: -1.80088
[32m[0906 21-58-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35346, current rewards: -568.22831, mean: -1.83299
[32m[0906 21-58-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35352, current rewards: -602.24016, mean: -1.67289
[32m[0906 21-58-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35353, current rewards: -642.04369, mean: -1.56596
[32m[0906 21-59-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35352, current rewards: -686.21652, mean: -1.49178
[32m[0906 21-59-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35343, current rewards: -737.25410, mean: -1.44560
[32m[0906 21-59-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35338, current rewards: -796.16087, mean: -1.42172
[32m[0906 21-59-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35325, current rewards: -858.15649, mean: -1.40681
[32m[0906 22-00-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35315, current rewards: -905.93747, mean: -1.37263
[32m[0906 22-00-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35313, current rewards: -962.91415, mean: -1.35622
[32m[0906 22-00-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35307, current rewards: -1031.44795, mean: -1.35717
[32m[0906 22-01-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35299, current rewards: -1106.22531, mean: -1.36571
[32m[0906 22-01-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35299, current rewards: -1167.88234, mean: -1.35800
[32m[0906 22-01-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35294, current rewards: -1199.35708, mean: -1.31797
[32m[0906 22-01-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35282, current rewards: -1268.72128, mean: -1.32158
[32m[0906 22-02-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35274, current rewards: -1323.00388, mean: -1.30990
[32m[0906 22-02-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35263, current rewards: -1392.53692, mean: -1.31371
[32m[0906 22-02-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35256, current rewards: -1454.70452, mean: -1.31054
[32m[0906 22-03-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35251, current rewards: -1524.65426, mean: -1.31436
[32m[0906 22-03-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35248, current rewards: -1539.09646, mean: -1.27198
[32m[0906 22-03-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35246, current rewards: -1530.11556, mean: -1.21438
[32m[0906 22-04-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35243, current rewards: -1521.24923, mean: -1.16126
[32m[0906 22-04-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35239, current rewards: -1540.69456, mean: -1.13286
[32m[0906 22-04-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35236, current rewards: -1571.15000, mean: -1.11429
[32m[0906 22-04-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35232, current rewards: -1566.09820, mean: -1.07267
[32m[0906 22-05-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35227, current rewards: -1561.24339, mean: -1.03394
[32m[0906 22-05-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35226, current rewards: -1602.79867, mean: -1.02744
[32m[0906 22-05-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35223, current rewards: -1652.79867, mean: -1.02658
[32m[0906 22-06-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35215, current rewards: -1702.79867, mean: -1.02578
[32m[0906 22-06-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35212, current rewards: -1752.79867, mean: -1.02503
[32m[0906 22-06-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35209, current rewards: -1802.79867, mean: -1.02432
[32m[0906 22-06-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35207, current rewards: -1852.79867, mean: -1.02365
[32m[0906 22-07-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35190, current rewards: -1902.79867, mean: -1.02301
[32m[0906 22-07-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35166, current rewards: -1952.79867, mean: -1.02241
[32m[0906 22-07-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35146, current rewards: -2002.79867, mean: -1.02184
[32m[0906 22-08-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35119, current rewards: -2052.79867, mean: -1.02129
[32m[0906 22-08-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35067, current rewards: -2102.79867, mean: -1.02078
[32m[0906 22-08-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35027, current rewards: -2152.79867, mean: -1.02028
[32m[0906 22-08-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34981, current rewards: -2202.79867, mean: -1.01981
[32m[0906 22-09-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34917, current rewards: -2252.79867, mean: -1.01937
[32m[0906 22-09-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34879, current rewards: -2302.79867, mean: -1.01894
[32m[0906 22-09-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34870, current rewards: -2352.79867, mean: -1.01853
[32m[0906 22-10-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34861, current rewards: -2381.24650, mean: -1.00900
[32m[0906 22-10-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34869, current rewards: -2374.32920, mean: -0.98520
[32m[0906 22-10-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34880, current rewards: -2367.40254, mean: -0.96236
[32m[0906 22-10-53 @Agent.py:117][0m Average action selection time: 0.3489
[32m[0906 22-10-53 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-10-53 @MBExp.py:227][0m Rewards obtained: [-2361.8612104884432], Lows: [848], Highs: [862], Total time: 29296.579051
[32m[0906 22-12-09 @MBExp.py:144][0m ####################################################################
[32m[0906 22-12-09 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 22-12-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35494, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-12-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35326, current rewards: -27.00776, mean: -0.45013
[32m[0906 22-12-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35313, current rewards: -13.24520, mean: -0.12041
[32m[0906 22-13-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35312, current rewards: 0.70297, mean: 0.00439
[32m[0906 22-13-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35323, current rewards: 14.64729, mean: 0.06975
[32m[0906 22-13-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35308, current rewards: 28.58786, mean: 0.10995
[32m[0906 22-13-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35284, current rewards: 43.28697, mean: 0.13964
[32m[0906 22-14-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35272, current rewards: 56.97605, mean: 0.15827
[32m[0906 22-14-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35285, current rewards: 70.75372, mean: 0.17257
[32m[0906 22-14-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35281, current rewards: 84.53962, mean: 0.18378
[32m[0906 22-15-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35284, current rewards: 98.29075, mean: 0.19273
[32m[0906 22-15-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35274, current rewards: 108.96476, mean: 0.19458
[32m[0906 22-15-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35267, current rewards: 119.14561, mean: 0.19532
[32m[0906 22-16-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35264, current rewards: 130.28505, mean: 0.19740
[32m[0906 22-16-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35263, current rewards: 125.09178, mean: 0.17619
[32m[0906 22-16-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35259, current rewards: 138.18902, mean: 0.18183
[32m[0906 22-16-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35253, current rewards: 147.26190, mean: 0.18180
[32m[0906 22-17-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35253, current rewards: 157.20677, mean: 0.18280
[32m[0906 22-17-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35251, current rewards: 167.41534, mean: 0.18397
[32m[0906 22-17-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35249, current rewards: 176.84955, mean: 0.18422
[32m[0906 22-18-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35248, current rewards: 185.46035, mean: 0.18362
[32m[0906 22-18-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35246, current rewards: 194.39586, mean: 0.18339
[32m[0906 22-18-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35243, current rewards: 202.91427, mean: 0.18281
[32m[0906 22-18-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35240, current rewards: 209.81495, mean: 0.18087
[32m[0906 22-19-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35244, current rewards: 218.85654, mean: 0.18087
[32m[0906 22-19-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35241, current rewards: 228.06368, mean: 0.18100
[32m[0906 22-19-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35234, current rewards: 237.27164, mean: 0.18112
[32m[0906 22-20-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35232, current rewards: 246.47297, mean: 0.18123
[32m[0906 22-20-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35229, current rewards: 255.70714, mean: 0.18135
[32m[0906 22-20-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35226, current rewards: 221.11099, mean: 0.15145
[32m[0906 22-21-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35222, current rewards: 231.45971, mean: 0.15328
[32m[0906 22-21-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35220, current rewards: 248.39389, mean: 0.15923
[32m[0906 22-21-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35218, current rewards: 260.46434, mean: 0.16178
[32m[0906 22-21-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35214, current rewards: 272.53938, mean: 0.16418
[32m[0906 22-22-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35214, current rewards: 284.63639, mean: 0.16645
[32m[0906 22-22-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35213, current rewards: 296.71703, mean: 0.16859
[32m[0906 22-22-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35212, current rewards: 308.80058, mean: 0.17061
[32m[0906 22-23-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35194, current rewards: 320.88533, mean: 0.17252
[32m[0906 22-23-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35173, current rewards: 332.96946, mean: 0.17433
[32m[0906 22-23-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35152, current rewards: 342.08966, mean: 0.17454
[32m[0906 22-23-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35124, current rewards: 353.09539, mean: 0.17567
[32m[0906 22-24-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35069, current rewards: 366.88527, mean: 0.17810
[32m[0906 22-24-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35027, current rewards: 380.92461, mean: 0.18053
[32m[0906 22-24-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34980, current rewards: 394.92191, mean: 0.18283
[32m[0906 22-25-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34918, current rewards: 408.92067, mean: 0.18503
[32m[0906 22-25-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34878, current rewards: 422.92083, mean: 0.18713
[32m[0906 22-25-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34869, current rewards: 436.92027, mean: 0.18914
[32m[0906 22-25-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34861, current rewards: 397.66161, mean: 0.16850
[32m[0906 22-26-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34867, current rewards: 402.13538, mean: 0.16686
[32m[0906 22-26-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34878, current rewards: 387.24550, mean: 0.15742
[32m[0906 22-26-42 @Agent.py:117][0m Average action selection time: 0.3488
[32m[0906 22-26-42 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-26-42 @MBExp.py:227][0m Rewards obtained: [397.46357385801696], Lows: [64], Highs: [40], Total time: 30169.369857
[32m[0906 22-28-00 @MBExp.py:144][0m ####################################################################
[32m[0906 22-28-00 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 22-28-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35324, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-28-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35400, current rewards: -16.92705, mean: -0.28212
[32m[0906 22-28-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35384, current rewards: -12.32784, mean: -0.11207
[32m[0906 22-28-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35371, current rewards: -7.73503, mean: -0.04834
[32m[0906 22-29-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35375, current rewards: -3.14215, mean: -0.01496
[32m[0906 22-29-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35360, current rewards: 1.44698, mean: 0.00557
[32m[0906 22-29-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35346, current rewards: -7.81430, mean: -0.02521
[32m[0906 22-30-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35350, current rewards: -19.06985, mean: -0.05297
[32m[0906 22-30-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35344, current rewards: -15.13385, mean: -0.03691
[32m[0906 22-30-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35335, current rewards: -29.89349, mean: -0.06499
[32m[0906 22-31-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35325, current rewards: -48.89150, mean: -0.09587
[32m[0906 22-31-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35316, current rewards: -44.80289, mean: -0.08001
[32m[0906 22-31-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35312, current rewards: -40.68558, mean: -0.06670
[32m[0906 22-31-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35309, current rewards: -36.57244, mean: -0.05541
[32m[0906 22-32-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35307, current rewards: -32.18897, mean: -0.04534
[32m[0906 22-32-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35304, current rewards: -22.21010, mean: -0.02922
[32m[0906 22-32-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35301, current rewards: -17.78448, mean: -0.02196
[32m[0906 22-33-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35301, current rewards: -13.38146, mean: -0.01556
[32m[0906 22-33-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35296, current rewards: -8.97672, mean: -0.00986
[32m[0906 22-33-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35293, current rewards: -28.01606, mean: -0.02918
[32m[0906 22-33-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35291, current rewards: -23.53045, mean: -0.02330
[32m[0906 22-34-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35293, current rewards: -19.24184, mean: -0.01815
[32m[0906 22-34-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35289, current rewards: -14.95237, mean: -0.01347
[32m[0906 22-34-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35282, current rewards: -11.18260, mean: -0.00964
[32m[0906 22-35-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35278, current rewards: -7.08745, mean: -0.00586
[32m[0906 22-35-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35275, current rewards: -3.09720, mean: -0.00246
[32m[0906 22-35-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35275, current rewards: 0.89147, mean: 0.00068
[32m[0906 22-36-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35275, current rewards: 4.87982, mean: 0.00359
[32m[0906 22-36-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35273, current rewards: -13.66239, mean: -0.00969
[32m[0906 22-36-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35267, current rewards: -9.86350, mean: -0.00676
[32m[0906 22-36-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35263, current rewards: -6.16909, mean: -0.00409
[32m[0906 22-37-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35261, current rewards: -2.72273, mean: -0.00175
[32m[0906 22-37-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35263, current rewards: 0.93227, mean: 0.00058
[32m[0906 22-37-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35259, current rewards: 4.54293, mean: 0.00274
[32m[0906 22-38-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35260, current rewards: 8.15175, mean: 0.00477
[32m[0906 22-38-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35257, current rewards: 11.75684, mean: 0.00668
[32m[0906 22-38-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35257, current rewards: 15.36668, mean: 0.00849
[32m[0906 22-38-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35236, current rewards: 18.97478, mean: 0.01020
[32m[0906 22-39-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35213, current rewards: 22.58071, mean: 0.01182
[32m[0906 22-39-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35190, current rewards: 27.16992, mean: 0.01386
[32m[0906 22-39-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35157, current rewards: 31.69306, mean: 0.01577
[32m[0906 22-40-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35099, current rewards: -2.85621, mean: -0.00139
[32m[0906 22-40-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35057, current rewards: 1.88204, mean: 0.00089
[32m[0906 22-40-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35007, current rewards: 6.42012, mean: 0.00297
[32m[0906 22-40-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34944, current rewards: 10.95812, mean: 0.00496
[32m[0906 22-41-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34902, current rewards: 15.49626, mean: 0.00686
[32m[0906 22-41-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34891, current rewards: 20.03433, mean: 0.00867
[32m[0906 22-41-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34882, current rewards: 24.62718, mean: 0.01044
[32m[0906 22-42-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34888, current rewards: 31.96682, mean: 0.01326
[32m[0906 22-42-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34899, current rewards: 23.07634, mean: 0.00938
[32m[0906 22-42-33 @Agent.py:117][0m Average action selection time: 0.3491
[32m[0906 22-42-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-42-33 @MBExp.py:227][0m Rewards obtained: [-16.923658965180195], Lows: [50], Highs: [127], Total time: 31042.720156000003
[32m[0906 22-43-54 @MBExp.py:144][0m ####################################################################
[32m[0906 22-43-54 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 22-43-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35438, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-44-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35478, current rewards: -75.71754, mean: -1.26196
[32m[0906 22-44-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35380, current rewards: -172.85765, mean: -1.57143
[32m[0906 22-44-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35379, current rewards: -268.17531, mean: -1.67610
[32m[0906 22-45-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35335, current rewards: -340.52783, mean: -1.62156
[32m[0906 22-45-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35337, current rewards: -437.64674, mean: -1.68326
[32m[0906 22-45-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35310, current rewards: -535.35338, mean: -1.72695
[32m[0906 22-46-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35291, current rewards: -627.07342, mean: -1.74187
[32m[0906 22-46-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35285, current rewards: -622.94035, mean: -1.51937
[32m[0906 22-46-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35267, current rewards: -618.39662, mean: -1.34434
[32m[0906 22-46-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35266, current rewards: -613.85239, mean: -1.20363
[32m[0906 22-47-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35261, current rewards: -609.30371, mean: -1.08804
[32m[0906 22-47-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35268, current rewards: -604.75698, mean: -0.99140
[32m[0906 22-47-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35275, current rewards: -600.20875, mean: -0.90941
[32m[0906 22-48-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35269, current rewards: -635.71183, mean: -0.89537
[32m[0906 22-48-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35263, current rewards: -630.94087, mean: -0.83019
[32m[0906 22-48-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35259, current rewards: -626.86799, mean: -0.77391
[32m[0906 22-48-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35257, current rewards: -622.82645, mean: -0.72422
[32m[0906 22-49-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35255, current rewards: -618.78492, mean: -0.67998
[32m[0906 22-49-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35256, current rewards: -668.78492, mean: -0.69665
[32m[0906 22-49-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35254, current rewards: -718.78492, mean: -0.71167
[32m[0906 22-50-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35249, current rewards: -768.78492, mean: -0.72527
[32m[0906 22-50-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35251, current rewards: -818.78492, mean: -0.73764
[32m[0906 22-50-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35249, current rewards: -868.78492, mean: -0.74895
[32m[0906 22-51-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35246, current rewards: -918.78492, mean: -0.75933
[32m[0906 22-51-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35242, current rewards: -968.78492, mean: -0.76888
[32m[0906 22-51-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35239, current rewards: -1018.78492, mean: -0.77770
[32m[0906 22-51-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35240, current rewards: -1068.78492, mean: -0.78587
[32m[0906 22-52-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35239, current rewards: -1118.78492, mean: -0.79346
[32m[0906 22-52-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35241, current rewards: -1168.78492, mean: -0.80054
[32m[0906 22-52-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35242, current rewards: -1218.78492, mean: -0.80714
[32m[0906 22-53-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35243, current rewards: -1268.78492, mean: -0.81332
[32m[0906 22-53-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35243, current rewards: -1318.78492, mean: -0.81912
[32m[0906 22-53-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35241, current rewards: -1368.78492, mean: -0.82457
[32m[0906 22-53-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35241, current rewards: -1418.78492, mean: -0.82970
[32m[0906 22-54-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35244, current rewards: -1468.78492, mean: -0.83454
[32m[0906 22-54-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35244, current rewards: -1518.78492, mean: -0.83911
[32m[0906 22-54-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35224, current rewards: -1568.78492, mean: -0.84343
[32m[0906 22-55-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35205, current rewards: -1618.78492, mean: -0.84753
[32m[0906 22-55-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35186, current rewards: -1668.78492, mean: -0.85142
[32m[0906 22-55-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35154, current rewards: -1718.78492, mean: -0.85512
[32m[0906 22-55-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35097, current rewards: -1768.78492, mean: -0.85863
[32m[0906 22-56-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35057, current rewards: -1818.78492, mean: -0.86198
[32m[0906 22-56-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35004, current rewards: -1868.78492, mean: -0.86518
[32m[0906 22-56-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34943, current rewards: -1918.78492, mean: -0.86823
[32m[0906 22-57-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34900, current rewards: -1968.78492, mean: -0.87114
[32m[0906 22-57-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34887, current rewards: -2018.78492, mean: -0.87393
[32m[0906 22-57-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34880, current rewards: -2068.78492, mean: -0.87660
[32m[0906 22-57-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34887, current rewards: -2118.78492, mean: -0.87916
[32m[0906 22-58-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34898, current rewards: -2168.78492, mean: -0.88162
[32m[0906 22-58-27 @Agent.py:117][0m Average action selection time: 0.3491
[32m[0906 22-58-27 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-58-27 @MBExp.py:227][0m Rewards obtained: [-2208.7849197557057], Lows: [328], Highs: [1610], Total time: 31916.085275000005
[32m[0906 22-59-49 @MBExp.py:144][0m ####################################################################
[32m[0906 22-59-49 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 22-59-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35411, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-00-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35319, current rewards: -37.96930, mean: -0.63282
[32m[0906 23-00-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35323, current rewards: -24.09152, mean: -0.21901
[32m[0906 23-00-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35381, current rewards: -10.48556, mean: -0.06553
[32m[0906 23-01-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35346, current rewards: 3.02684, mean: 0.01441
[32m[0906 23-01-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35329, current rewards: 16.59551, mean: 0.06383
[32m[0906 23-01-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35327, current rewards: -12.46866, mean: -0.04022
[32m[0906 23-01-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35323, current rewards: -32.52847, mean: -0.09036
[32m[0906 23-02-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35332, current rewards: -39.61142, mean: -0.09661
[32m[0906 23-02-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35331, current rewards: -34.05049, mean: -0.07402
[32m[0906 23-02-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35331, current rewards: -28.48804, mean: -0.05586
[32m[0906 23-03-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35337, current rewards: -22.92687, mean: -0.04094
[32m[0906 23-03-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35340, current rewards: -17.36767, mean: -0.02847
[32m[0906 23-03-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35338, current rewards: -11.80725, mean: -0.01789
[32m[0906 23-04-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35333, current rewards: -5.14749, mean: -0.00725
[32m[0906 23-04-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35329, current rewards: -21.61137, mean: -0.02844
[32m[0906 23-04-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35325, current rewards: -15.80921, mean: -0.01952
[32m[0906 23-04-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35322, current rewards: -11.25947, mean: -0.01309
[32m[0906 23-05-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35317, current rewards: -6.69895, mean: -0.00736
[32m[0906 23-05-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35316, current rewards: -2.14032, mean: -0.00223
[32m[0906 23-05-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35314, current rewards: 2.41670, mean: 0.00239
[32m[0906 23-06-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35311, current rewards: 6.97532, mean: 0.00658
[32m[0906 23-06-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35310, current rewards: 11.62378, mean: 0.01047
[32m[0906 23-06-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35307, current rewards: 16.19857, mean: 0.01396
[32m[0906 23-06-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35305, current rewards: 20.76862, mean: 0.01716
[32m[0906 23-07-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35305, current rewards: 33.63951, mean: 0.02670
[32m[0906 23-07-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35304, current rewards: 38.95401, mean: 0.02974
[32m[0906 23-07-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35302, current rewards: 44.20012, mean: 0.03250
[32m[0906 23-08-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35300, current rewards: 49.45104, mean: 0.03507
[32m[0906 23-08-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35299, current rewards: 54.69495, mean: 0.03746
[32m[0906 23-08-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35299, current rewards: 61.27198, mean: 0.04058
[32m[0906 23-09-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35297, current rewards: 25.12192, mean: 0.01610
[32m[0906 23-09-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35296, current rewards: 30.14039, mean: 0.01872
[32m[0906 23-09-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35294, current rewards: 35.11604, mean: 0.02115
[32m[0906 23-09-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35293, current rewards: 40.09363, mean: 0.02345
[32m[0906 23-10-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35292, current rewards: 5.94037, mean: 0.00338
[32m[0906 23-10-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35289, current rewards: 14.44336, mean: 0.00798
[32m[0906 23-10-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35265, current rewards: 22.30291, mean: 0.01199
[32m[0906 23-11-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35242, current rewards: 28.37270, mean: 0.01485
[32m[0906 23-11-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35221, current rewards: -33.57864, mean: -0.01713
[32m[0906 23-11-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35186, current rewards: -28.92875, mean: -0.01439
[32m[0906 23-11-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35128, current rewards: -24.47409, mean: -0.01188
[32m[0906 23-12-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35085, current rewards: -20.01630, mean: -0.00949
[32m[0906 23-12-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35030, current rewards: -15.55998, mean: -0.00720
[32m[0906 23-12-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34965, current rewards: -11.11072, mean: -0.00503
[32m[0906 23-12-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34922, current rewards: -6.64831, mean: -0.00294
[32m[0906 23-13-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34908, current rewards: -2.20012, mean: -0.00095
[32m[0906 23-13-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34900, current rewards: -13.36104, mean: -0.00566
[32m[0906 23-13-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34906, current rewards: -32.88053, mean: -0.01364
[32m[0906 23-14-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34913, current rewards: -40.65980, mean: -0.01653
[32m[0906 23-14-23 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0906 23-14-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-14-23 @MBExp.py:227][0m Rewards obtained: [-35.79741374764122], Lows: [143], Highs: [64], Total time: 32789.730962
[32m[0906 23-15-47 @MBExp.py:144][0m ####################################################################
[32m[0906 23-15-47 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 23-15-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35419, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-16-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35451, current rewards: -17.19614, mean: -0.28660
[32m[0906 23-16-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35438, current rewards: -12.16070, mean: -0.11055
[32m[0906 23-16-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35421, current rewards: -7.12644, mean: -0.04454
[32m[0906 23-17-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35423, current rewards: -2.09188, mean: -0.00996
[32m[0906 23-17-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35404, current rewards: 2.93988, mean: 0.01131
[32m[0906 23-17-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35409, current rewards: -3.05144, mean: -0.00984
[32m[0906 23-17-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35400, current rewards: 2.34084, mean: 0.00650
[32m[0906 23-18-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35386, current rewards: 7.71067, mean: 0.01881
[32m[0906 23-18-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35372, current rewards: 13.07633, mean: 0.02843
[32m[0906 23-18-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35366, current rewards: 18.44945, mean: 0.03618
[32m[0906 23-19-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35361, current rewards: -18.44418, mean: -0.03294
[32m[0906 23-19-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35361, current rewards: -13.03640, mean: -0.02137
[32m[0906 23-19-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35355, current rewards: -7.69175, mean: -0.01165
[32m[0906 23-19-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35345, current rewards: -2.34467, mean: -0.00330
[32m[0906 23-20-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35338, current rewards: 1.88757, mean: 0.00248
[32m[0906 23-20-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35340, current rewards: -14.20362, mean: -0.01754
[32m[0906 23-20-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35339, current rewards: -8.63187, mean: -0.01004
[32m[0906 23-21-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35330, current rewards: -3.04789, mean: -0.00335
[32m[0906 23-21-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35325, current rewards: 2.53584, mean: 0.00264
[32m[0906 23-21-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35321, current rewards: 8.11710, mean: 0.00804
[32m[0906 23-22-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35316, current rewards: 13.69512, mean: 0.01292
[32m[0906 23-22-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35313, current rewards: 18.27379, mean: 0.01646
[32m[0906 23-22-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35308, current rewards: 8.61684, mean: 0.00743
[32m[0906 23-22-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35299, current rewards: 13.11349, mean: 0.01084
[32m[0906 23-23-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35293, current rewards: 17.27988, mean: 0.01371
[32m[0906 23-23-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35288, current rewards: 21.46231, mean: 0.01638
[32m[0906 23-23-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35283, current rewards: 25.64775, mean: 0.01886
[32m[0906 23-24-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35278, current rewards: 29.83278, mean: 0.02116
[32m[0906 23-24-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35275, current rewards: 34.01356, mean: 0.02330
[32m[0906 23-24-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35271, current rewards: 38.20071, mean: 0.02530
[32m[0906 23-24-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35269, current rewards: 46.41224, mean: 0.02975
[32m[0906 23-25-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35268, current rewards: 50.78891, mean: 0.03155
[32m[0906 23-25-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35266, current rewards: 55.17899, mean: 0.03324
[32m[0906 23-25-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35265, current rewards: 59.56736, mean: 0.03483
[32m[0906 23-26-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35262, current rewards: 21.27644, mean: 0.01209
[32m[0906 23-26-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35256, current rewards: 32.40142, mean: 0.01790
[32m[0906 23-26-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35234, current rewards: 39.86161, mean: 0.02143
[32m[0906 23-27-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35211, current rewards: 47.32180, mean: 0.02478
[32m[0906 23-27-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35190, current rewards: 47.47301, mean: 0.02422
[32m[0906 23-27-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35151, current rewards: -2.52699, mean: -0.00126
[32m[0906 23-27-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35089, current rewards: -52.52699, mean: -0.02550
[32m[0906 23-28-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35047, current rewards: -102.52699, mean: -0.04859
[32m[0906 23-28-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34991, current rewards: -152.52699, mean: -0.07061
[32m[0906 23-28-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34929, current rewards: -202.52699, mean: -0.09164
[32m[0906 23-28-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34884, current rewards: -252.52699, mean: -0.11174
[32m[0906 23-29-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34866, current rewards: -302.52699, mean: -0.13096
[32m[0906 23-29-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34857, current rewards: -352.52699, mean: -0.14938
[32m[0906 23-29-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34861, current rewards: -402.52699, mean: -0.16702
[32m[0906 23-30-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34873, current rewards: -452.52699, mean: -0.18395
[32m[0906 23-30-20 @Agent.py:117][0m Average action selection time: 0.3488
[32m[0906 23-30-20 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-30-20 @MBExp.py:227][0m Rewards obtained: [-492.5269863831268], Lows: [52], Highs: [593], Total time: 33662.378942
[32m[0906 23-31-47 @MBExp.py:144][0m ####################################################################
[32m[0906 23-31-47 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 23-31-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35622, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-32-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35500, current rewards: -16.18584, mean: -0.26976
[32m[0906 23-32-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35445, current rewards: -10.84029, mean: -0.09855
[32m[0906 23-32-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35432, current rewards: -5.48246, mean: -0.03427
[32m[0906 23-33-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35412, current rewards: -0.12852, mean: -0.00061
[32m[0906 23-33-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35379, current rewards: 5.22390, mean: 0.02009
[32m[0906 23-33-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35377, current rewards: 9.55924, mean: 0.03084
[32m[0906 23-33-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35359, current rewards: 14.99196, mean: 0.04164
[32m[0906 23-34-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35359, current rewards: 20.41044, mean: 0.04978
[32m[0906 23-34-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35363, current rewards: 25.83220, mean: 0.05616
[32m[0906 23-34-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35358, current rewards: 14.62368, mean: 0.02867
[32m[0906 23-35-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35348, current rewards: 14.98741, mean: 0.02676
[32m[0906 23-35-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35342, current rewards: 21.04378, mean: 0.03450
[32m[0906 23-35-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35325, current rewards: 27.10543, mean: 0.04107
[32m[0906 23-35-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35316, current rewards: 35.13347, mean: 0.04948
[32m[0906 23-36-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35313, current rewards: 0.13118, mean: 0.00017
[32m[0906 23-36-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35309, current rewards: 13.03836, mean: 0.01610
[32m[0906 23-36-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35311, current rewards: 21.39059, mean: 0.02487
[32m[0906 23-37-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35308, current rewards: 29.63032, mean: 0.03256
[32m[0906 23-37-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35310, current rewards: 37.86517, mean: 0.03944
[32m[0906 23-37-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35309, current rewards: 46.10696, mean: 0.04565
[32m[0906 23-38-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35308, current rewards: 54.34158, mean: 0.05127
[32m[0906 23-38-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35309, current rewards: 58.03066, mean: 0.05228
[32m[0906 23-38-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35308, current rewards: 43.20734, mean: 0.03725
[32m[0906 23-38-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35306, current rewards: 49.15126, mean: 0.04062
[32m[0906 23-39-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35302, current rewards: 55.08766, mean: 0.04372
[32m[0906 23-39-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35300, current rewards: 61.01879, mean: 0.04658
[32m[0906 23-39-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35298, current rewards: 66.95055, mean: 0.04923
[32m[0906 23-40-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35294, current rewards: 72.43753, mean: 0.05137
[32m[0906 23-40-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35293, current rewards: 77.68093, mean: 0.05321
[32m[0906 23-40-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35288, current rewards: 83.51881, mean: 0.05531
[32m[0906 23-40-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35283, current rewards: 89.39464, mean: 0.05730
[32m[0906 23-41-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35278, current rewards: 95.15105, mean: 0.05910
[32m[0906 23-41-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35276, current rewards: 100.90566, mean: 0.06079
[32m[0906 23-41-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35276, current rewards: 106.65239, mean: 0.06237
[32m[0906 23-42-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35274, current rewards: 112.40397, mean: 0.06387
[32m[0906 23-42-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35269, current rewards: 118.15771, mean: 0.06528
[32m[0906 23-42-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35247, current rewards: 123.91136, mean: 0.06662
[32m[0906 23-43-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35225, current rewards: 129.49511, mean: 0.06780
[32m[0906 23-43-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35203, current rewards: 134.32190, mean: 0.06853
[32m[0906 23-43-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35163, current rewards: 97.50218, mean: 0.04851
[32m[0906 23-43-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35100, current rewards: 103.34237, mean: 0.05017
[32m[0906 23-44-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35058, current rewards: 110.80666, mean: 0.05252
[32m[0906 23-44-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35001, current rewards: 118.23024, mean: 0.05474
[32m[0906 23-44-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34939, current rewards: 125.68577, mean: 0.05687
[32m[0906 23-44-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34892, current rewards: 133.13376, mean: 0.05891
[32m[0906 23-45-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34873, current rewards: 140.59440, mean: 0.06086
[32m[0906 23-45-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34866, current rewards: 118.18237, mean: 0.05008
[32m[0906 23-45-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34871, current rewards: 127.02703, mean: 0.05271
[32m[0906 23-46-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34881, current rewards: 136.37150, mean: 0.05544
[32m[0906 23-46-19 @Agent.py:117][0m Average action selection time: 0.3489
[32m[0906 23-46-19 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-46-19 @MBExp.py:227][0m Rewards obtained: [143.85915215808663], Lows: [57], Highs: [61], Total time: 34535.295939
[32m[0906 23-47-48 @MBExp.py:144][0m ####################################################################
[32m[0906 23-47-48 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 23-47-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35542, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-48-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35390, current rewards: -15.59656, mean: -0.25994
[32m[0906 23-48-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35354, current rewards: -2.63407, mean: -0.02395
[32m[0906 23-48-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35339, current rewards: 11.65098, mean: 0.07282
[32m[0906 23-49-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35335, current rewards: 25.95927, mean: 0.12362
[32m[0906 23-49-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35331, current rewards: 39.59573, mean: 0.15229
[32m[0906 23-49-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35331, current rewards: 45.18151, mean: 0.14575
[32m[0906 23-49-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35340, current rewards: 54.28460, mean: 0.15079
[32m[0906 23-50-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35345, current rewards: 64.84808, mean: 0.15817
[32m[0906 23-50-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35348, current rewards: 75.68849, mean: 0.16454
[32m[0906 23-50-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35339, current rewards: 62.30886, mean: 0.12217
[32m[0906 23-51-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35336, current rewards: 68.68750, mean: 0.12266
[32m[0906 23-51-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35338, current rewards: 74.08341, mean: 0.12145
[32m[0906 23-51-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35339, current rewards: 79.47458, mean: 0.12042
[32m[0906 23-51-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35340, current rewards: 88.07412, mean: 0.12405
[32m[0906 23-52-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35339, current rewards: 93.85306, mean: 0.12349
[32m[0906 23-52-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35338, current rewards: 99.60485, mean: 0.12297
[32m[0906 23-52-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35339, current rewards: 105.36741, mean: 0.12252
[32m[0906 23-53-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35334, current rewards: 111.12899, mean: 0.12212
[32m[0906 23-53-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35331, current rewards: 116.88004, mean: 0.12175
[32m[0906 23-53-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35325, current rewards: 122.63848, mean: 0.12142
[32m[0906 23-54-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35320, current rewards: 128.39339, mean: 0.12113
[32m[0906 23-54-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35317, current rewards: 133.19624, mean: 0.12000
[32m[0906 23-54-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35312, current rewards: 96.22082, mean: 0.08295
[32m[0906 23-54-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35306, current rewards: 102.27534, mean: 0.08453
[32m[0906 23-55-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35301, current rewards: 108.49451, mean: 0.08611
[32m[0906 23-55-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35296, current rewards: 114.71082, mean: 0.08757
[32m[0906 23-55-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35293, current rewards: 120.93172, mean: 0.08892
[32m[0906 23-56-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35290, current rewards: 127.15129, mean: 0.09018
[32m[0906 23-56-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35285, current rewards: 133.36510, mean: 0.09135
[32m[0906 23-56-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35284, current rewards: 139.98706, mean: 0.09271
[32m[0906 23-56-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35283, current rewards: 146.37916, mean: 0.09383
[32m[0906 23-57-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35279, current rewards: 133.55779, mean: 0.08296
[32m[0906 23-57-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35276, current rewards: 116.56021, mean: 0.07022
[32m[0906 23-57-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35271, current rewards: 121.22996, mean: 0.07089
[32m[0906 23-58-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35269, current rewards: 125.87539, mean: 0.07152
[32m[0906 23-58-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35260, current rewards: 130.51803, mean: 0.07211
[32m[0906 23-58-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35235, current rewards: 135.16463, mean: 0.07267
[32m[0906 23-59-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35213, current rewards: 141.24033, mean: 0.07395
[32m[0906 23-59-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35189, current rewards: 158.53453, mean: 0.08088
[32m[0906 23-59-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35149, current rewards: 164.24027, mean: 0.08171
[32m[0906 23-59-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35083, current rewards: 169.46843, mean: 0.08227
[32m[0907 00-00-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35041, current rewards: 174.69483, mean: 0.08279
[32m[0907 00-00-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34979, current rewards: 179.92055, mean: 0.08330
[32m[0907 00-00-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34916, current rewards: 180.94562, mean: 0.08188
[32m[0907 00-00-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34867, current rewards: 148.80013, mean: 0.06584
[32m[0907 00-01-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34845, current rewards: 155.96092, mean: 0.06752
[32m[0907 00-01-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34837, current rewards: 165.74740, mean: 0.07023
[32m[0907 00-01-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34843, current rewards: 174.55648, mean: 0.07243
[32m[0907 00-02-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34854, current rewards: 183.69384, mean: 0.07467
[32m[0907 00-02-20 @Agent.py:117][0m Average action selection time: 0.3486
[32m[0907 00-02-20 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-02-20 @MBExp.py:227][0m Rewards obtained: [170.90100846278582], Lows: [51], Highs: [78], Total time: 35407.551213000006
[32m[0907 00-03-51 @MBExp.py:144][0m ####################################################################
[32m[0907 00-03-51 @MBExp.py:145][0m Starting training iteration 43.
[32m[0907 00-03-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35497, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-04-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35324, current rewards: -15.11613, mean: -0.25194
[32m[0907 00-04-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35316, current rewards: -6.16517, mean: -0.05605
[32m[0907 00-04-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35296, current rewards: 3.02981, mean: 0.01894
[32m[0907 00-05-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35298, current rewards: 12.26483, mean: 0.05840
[32m[0907 00-05-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35290, current rewards: 19.56480, mean: 0.07525
[32m[0907 00-05-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35302, current rewards: 26.80328, mean: 0.08646
[32m[0907 00-05-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35294, current rewards: 34.54169, mean: 0.09595
[32m[0907 00-06-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35291, current rewards: 42.35031, mean: 0.10329
[32m[0907 00-06-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35281, current rewards: 50.14272, mean: 0.10901
[32m[0907 00-06-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35278, current rewards: 57.93548, mean: 0.11360
[32m[0907 00-07-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35269, current rewards: 54.16391, mean: 0.09672
[32m[0907 00-07-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35270, current rewards: 48.52687, mean: 0.07955
[32m[0907 00-07-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35272, current rewards: 53.07610, mean: 0.08042
[32m[0907 00-08-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35263, current rewards: 57.61866, mean: 0.08115
[32m[0907 00-08-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35260, current rewards: 62.16131, mean: 0.08179
[32m[0907 00-08-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35259, current rewards: 66.70447, mean: 0.08235
[32m[0907 00-08-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35256, current rewards: 60.07869, mean: 0.06986
[32m[0907 00-09-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35258, current rewards: 42.88860, mean: 0.04713
[32m[0907 00-09-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35253, current rewards: 47.50241, mean: 0.04948
[32m[0907 00-09-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35259, current rewards: 52.10770, mean: 0.05159
[32m[0907 00-10-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35255, current rewards: 56.11219, mean: 0.05294
[32m[0907 00-10-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35250, current rewards: 60.39925, mean: 0.05441
[32m[0907 00-10-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35251, current rewards: 64.60881, mean: 0.05570
[32m[0907 00-10-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35251, current rewards: 68.81088, mean: 0.05687
[32m[0907 00-11-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35254, current rewards: 73.01297, mean: 0.05795
[32m[0907 00-11-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35255, current rewards: 77.21251, mean: 0.05894
[32m[0907 00-11-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35250, current rewards: 81.41472, mean: 0.05986
[32m[0907 00-12-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35250, current rewards: 85.61794, mean: 0.06072
[32m[0907 00-12-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35247, current rewards: 89.81926, mean: 0.06152
[32m[0907 00-12-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35246, current rewards: 94.02390, mean: 0.06227
[32m[0907 00-13-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35246, current rewards: 98.21977, mean: 0.06296
[32m[0907 00-13-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35243, current rewards: 60.82468, mean: 0.03778
[32m[0907 00-13-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35244, current rewards: 65.26250, mean: 0.03931
[32m[0907 00-13-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35241, current rewards: 69.69847, mean: 0.04076
[32m[0907 00-14-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35238, current rewards: 74.13923, mean: 0.04212
[32m[0907 00-14-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35230, current rewards: 78.57616, mean: 0.04341
[32m[0907 00-14-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35208, current rewards: 83.46306, mean: 0.04487
[32m[0907 00-15-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35187, current rewards: 98.41814, mean: 0.05153
[32m[0907 00-15-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35166, current rewards: 103.99186, mean: 0.05306
[32m[0907 00-15-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35126, current rewards: 73.93187, mean: 0.03678
[32m[0907 00-15-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35062, current rewards: 88.35160, mean: 0.04289
[32m[0907 00-16-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35019, current rewards: 99.29284, mean: 0.04706
[32m[0907 00-16-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34960, current rewards: 93.02410, mean: 0.04307
[32m[0907 00-16-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34900, current rewards: 89.54435, mean: 0.04052
[32m[0907 00-16-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34849, current rewards: 93.74875, mean: 0.04148
[32m[0907 00-17-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34827, current rewards: 97.74252, mean: 0.04231
[32m[0907 00-17-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34821, current rewards: 102.03824, mean: 0.04324
[32m[0907 00-17-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34825, current rewards: 105.89406, mean: 0.04394
[32m[0907 00-18-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34837, current rewards: 109.75188, mean: 0.04461
[32m[0907 00-18-23 @Agent.py:117][0m Average action selection time: 0.3485
[32m[0907 00-18-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-18-23 @MBExp.py:227][0m Rewards obtained: [112.83972078153455], Lows: [51], Highs: [75], Total time: 36279.415487000006
[32m[0907 00-19-56 @MBExp.py:144][0m ####################################################################
[32m[0907 00-19-56 @MBExp.py:145][0m Starting training iteration 44.
[32m[0907 00-19-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35690, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-20-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35445, current rewards: -15.37785, mean: -0.25630
[32m[0907 00-20-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35433, current rewards: -10.71053, mean: -0.09737
[32m[0907 00-20-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35389, current rewards: -6.03377, mean: -0.03771
[32m[0907 00-21-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35353, current rewards: -1.35942, mean: -0.00647
[32m[0907 00-21-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35352, current rewards: 1.46328, mean: 0.00563
[32m[0907 00-21-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35331, current rewards: 6.09716, mean: 0.01967
[32m[0907 00-22-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35328, current rewards: 10.71180, mean: 0.02975
[32m[0907 00-22-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35336, current rewards: 15.32406, mean: 0.03738
[32m[0907 00-22-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35362, current rewards: 20.37824, mean: 0.04430
[32m[0907 00-22-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35357, current rewards: 24.76144, mean: 0.04855
[32m[0907 00-23-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35349, current rewards: 29.24765, mean: 0.05223
[32m[0907 00-23-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35346, current rewards: 33.73224, mean: 0.05530
[32m[0907 00-23-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35339, current rewards: 38.91401, mean: 0.05896
[32m[0907 00-24-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35334, current rewards: 43.43764, mean: 0.06118
[32m[0907 00-24-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35328, current rewards: 5.89842, mean: 0.00776
[32m[0907 00-24-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35324, current rewards: 10.24423, mean: 0.01265
[32m[0907 00-25-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35319, current rewards: 14.70519, mean: 0.01710
[32m[0907 00-25-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35317, current rewards: 19.16583, mean: 0.02106
[32m[0907 00-25-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35317, current rewards: 23.62175, mean: 0.02461
[32m[0907 00-25-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35312, current rewards: 28.08157, mean: 0.02780
[32m[0907 00-26-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35308, current rewards: 34.47456, mean: 0.03252
[32m[0907 00-26-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35309, current rewards: 39.43817, mean: 0.03553
[32m[0907 00-26-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35310, current rewards: 43.96937, mean: 0.03790
[32m[0907 00-27-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35303, current rewards: 48.49845, mean: 0.04008
[32m[0907 00-27-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35300, current rewards: 56.00374, mean: 0.04445
[32m[0907 00-27-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35293, current rewards: 60.93883, mean: 0.04652
[32m[0907 00-27-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35291, current rewards: 65.33221, mean: 0.04804
[32m[0907 00-28-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35288, current rewards: 69.72999, mean: 0.04945
[32m[0907 00-28-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35285, current rewards: 32.55393, mean: 0.02230
[32m[0907 00-28-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35286, current rewards: 23.58063, mean: 0.01562
[32m[0907 00-29-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35284, current rewards: 28.06375, mean: 0.01799
[32m[0907 00-29-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35280, current rewards: 32.56084, mean: 0.02022
[32m[0907 00-29-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35279, current rewards: 37.05430, mean: 0.02232
[32m[0907 00-29-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35278, current rewards: 41.54924, mean: 0.02430
[32m[0907 00-30-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35273, current rewards: 46.04338, mean: 0.02616
[32m[0907 00-30-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35263, current rewards: 50.53843, mean: 0.02792
[32m[0907 00-30-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35241, current rewards: 55.03212, mean: 0.02959
[32m[0907 00-31-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35217, current rewards: 66.27834, mean: 0.03470
[32m[0907 00-31-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35192, current rewards: 32.07846, mean: 0.01637
[32m[0907 00-31-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35160, current rewards: 38.24132, mean: 0.01903
[32m[0907 00-31-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35094, current rewards: 43.44071, mean: 0.02109
[32m[0907 00-32-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35045, current rewards: 48.63442, mean: 0.02305
[32m[0907 00-32-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34982, current rewards: 53.82877, mean: 0.02492
[32m[0907 00-32-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34920, current rewards: 59.02249, mean: 0.02671
[32m[0907 00-33-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34860, current rewards: 64.21608, mean: 0.02841
[32m[0907 00-33-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34828, current rewards: 69.23670, mean: 0.02997
[32m[0907 00-33-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34820, current rewards: 74.15456, mean: 0.03142
[32m[0907 00-33-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34820, current rewards: 79.24352, mean: 0.03288
[32m[0907 00-34-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34831, current rewards: 84.33469, mean: 0.03428
[32m[0907 00-34-27 @Agent.py:117][0m Average action selection time: 0.3484
[32m[0907 00-34-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-34-27 @MBExp.py:227][0m Rewards obtained: [88.4079106112488], Lows: [67], Highs: [33], Total time: 37151.139965
[32m[0907 00-36-03 @MBExp.py:144][0m ####################################################################
[32m[0907 00-36-03 @MBExp.py:145][0m Starting training iteration 45.
[32m[0907 00-36-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35566, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-36-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35435, current rewards: -14.66445, mean: -0.24441
[32m[0907 00-36-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35374, current rewards: -8.02092, mean: -0.07292
[32m[0907 00-36-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35398, current rewards: -1.36950, mean: -0.00856
[32m[0907 00-37-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35356, current rewards: 5.40733, mean: 0.02575
[32m[0907 00-37-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35356, current rewards: 12.76497, mean: 0.04910
[32m[0907 00-37-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35337, current rewards: 19.56756, mean: 0.06312
[32m[0907 00-38-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35341, current rewards: 26.36574, mean: 0.07324
[32m[0907 00-38-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35334, current rewards: 33.16061, mean: 0.08088
[32m[0907 00-38-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35321, current rewards: 39.95585, mean: 0.08686
[32m[0907 00-39-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35324, current rewards: 31.98124, mean: 0.06271
[32m[0907 00-39-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35315, current rewards: 32.07733, mean: 0.05728
[32m[0907 00-39-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35308, current rewards: 39.79030, mean: 0.06523
[32m[0907 00-39-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35306, current rewards: 45.92394, mean: 0.06958
[32m[0907 00-40-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35305, current rewards: 53.25920, mean: 0.07501
[32m[0907 00-40-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35301, current rewards: 60.61195, mean: 0.07975
[32m[0907 00-40-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35301, current rewards: 67.96243, mean: 0.08390
[32m[0907 00-41-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35292, current rewards: 75.31338, mean: 0.08757
[32m[0907 00-41-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35299, current rewards: 82.65686, mean: 0.09083
[32m[0907 00-41-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35299, current rewards: 79.25812, mean: 0.08256
[32m[0907 00-41-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35298, current rewards: 53.24808, mean: 0.05272
[32m[0907 00-42-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35291, current rewards: 60.71950, mean: 0.05728
[32m[0907 00-42-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35285, current rewards: 68.02766, mean: 0.06129
[32m[0907 00-42-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35286, current rewards: 75.33236, mean: 0.06494
[32m[0907 00-43-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35287, current rewards: 82.62206, mean: 0.06828
[32m[0907 00-43-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35286, current rewards: 47.02812, mean: 0.03732
[32m[0907 00-43-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35283, current rewards: 55.02343, mean: 0.04200
[32m[0907 00-44-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35280, current rewards: 62.48194, mean: 0.04594
[32m[0907 00-44-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35278, current rewards: 69.93528, mean: 0.04960
[32m[0907 00-44-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35277, current rewards: 77.38850, mean: 0.05301
[32m[0907 00-44-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35276, current rewards: 84.85267, mean: 0.05619
[32m[0907 00-45-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35273, current rewards: 92.31349, mean: 0.05918
[32m[0907 00-45-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35266, current rewards: 99.76332, mean: 0.06196
[32m[0907 00-45-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35264, current rewards: 107.22436, mean: 0.06459
[32m[0907 00-46-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35261, current rewards: 73.23549, mean: 0.04283
[32m[0907 00-46-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35258, current rewards: 83.10815, mean: 0.04722
[32m[0907 00-46-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35247, current rewards: 90.17941, mean: 0.04982
[32m[0907 00-46-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35223, current rewards: 99.01369, mean: 0.05323
[32m[0907 00-47-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35200, current rewards: 106.15930, mean: 0.05558
[32m[0907 00-47-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35177, current rewards: 113.30356, mean: 0.05781
[32m[0907 00-47-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35146, current rewards: 120.44241, mean: 0.05992
[32m[0907 00-48-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35080, current rewards: 127.58084, mean: 0.06193
[32m[0907 00-48-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35032, current rewards: 105.31191, mean: 0.04991
[32m[0907 00-48-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34969, current rewards: 93.00473, mean: 0.04306
[32m[0907 00-48-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34908, current rewards: 63.01028, mean: 0.02851
[32m[0907 00-49-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34849, current rewards: 34.41358, mean: 0.01523
[32m[0907 00-49-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34811, current rewards: 13.63938, mean: 0.00590
[32m[0907 00-49-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34804, current rewards: -22.48602, mean: -0.00953
[32m[0907 00-50-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34805, current rewards: -43.22847, mean: -0.01794
[32m[0907 00-50-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34815, current rewards: -68.50637, mean: -0.02785
[32m[0907 00-50-34 @Agent.py:117][0m Average action selection time: 0.3482
[32m[0907 00-50-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-50-34 @MBExp.py:227][0m Rewards obtained: [-87.01930696481476], Lows: [187], Highs: [61], Total time: 38022.415699000005
[32m[0907 00-52-11 @MBExp.py:144][0m ####################################################################
[32m[0907 00-52-11 @MBExp.py:145][0m Starting training iteration 46.
[32m[0907 00-52-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35430, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-52-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35439, current rewards: -17.76844, mean: -0.29614
[32m[0907 00-52-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35376, current rewards: -11.32951, mean: -0.10300
[32m[0907 00-53-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35397, current rewards: -2.86884, mean: -0.01793
[32m[0907 00-53-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35094, current rewards: 4.50365, mean: 0.02145
[32m[0907 00-53-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34463, current rewards: 10.94884, mean: 0.04211
[32m[0907 00-53-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34010, current rewards: 17.36890, mean: 0.05603
[32m[0907 00-54-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33670, current rewards: 23.79070, mean: 0.06609
[32m[0907 00-54-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33415, current rewards: -12.35175, mean: -0.03013
[32m[0907 00-54-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33216, current rewards: -5.87024, mean: -0.01276
[32m[0907 00-55-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33054, current rewards: -0.68093, mean: -0.00134
[32m[0907 00-55-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32925, current rewards: 4.95773, mean: 0.00885
[32m[0907 00-55-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32812, current rewards: 10.58052, mean: 0.01735
[32m[0907 00-55-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32718, current rewards: 3.41552, mean: 0.00518
[32m[0907 00-56-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32638, current rewards: -44.71211, mean: -0.06297
[32m[0907 00-56-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32563, current rewards: -95.78013, mean: -0.12603
[32m[0907 00-56-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32503, current rewards: -162.98005, mean: -0.20121
[32m[0907 00-56-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32450, current rewards: -209.95618, mean: -0.24414
[32m[0907 00-57-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32400, current rewards: -281.32337, mean: -0.30915
[32m[0907 00-57-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32358, current rewards: -328.69577, mean: -0.34239
[32m[0907 00-57-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32317, current rewards: -399.66716, mean: -0.39571
[32m[0907 00-57-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32281, current rewards: -450.21138, mean: -0.42473
[32m[0907 00-58-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32246, current rewards: -489.54824, mean: -0.44103
[32m[0907 00-58-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32213, current rewards: -536.89612, mean: -0.46284
[32m[0907 00-58-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32183, current rewards: -584.05280, mean: -0.48269
[32m[0907 00-58-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32155, current rewards: -634.06098, mean: -0.50322
[32m[0907 00-59-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32132, current rewards: -666.90348, mean: -0.50909
[32m[0907 00-59-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32106, current rewards: -702.50991, mean: -0.51655
[32m[0907 00-59-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32085, current rewards: -714.96707, mean: -0.50707
[32m[0907 00-59-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32067, current rewards: -751.09983, mean: -0.51445
[32m[0907 01-00-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32049, current rewards: -745.27434, mean: -0.49356
[32m[0907 01-00-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32031, current rewards: -739.96027, mean: -0.47433
[32m[0907 01-00-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32015, current rewards: -734.64858, mean: -0.45630
[32m[0907 01-01-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32000, current rewards: -729.33405, mean: -0.43936
[32m[0907 01-01-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31985, current rewards: -730.65392, mean: -0.42728
[32m[0907 01-01-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31969, current rewards: -741.80032, mean: -0.42148
[32m[0907 01-01-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31945, current rewards: -737.69710, mean: -0.40757
[32m[0907 01-02-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31914, current rewards: -734.63603, mean: -0.39497
[32m[0907 01-02-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31886, current rewards: -730.84231, mean: -0.38264
[32m[0907 01-02-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31857, current rewards: -726.45415, mean: -0.37064
[32m[0907 01-02-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31818, current rewards: -721.97668, mean: -0.35919
[32m[0907 01-03-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31754, current rewards: -717.49019, mean: -0.34830
[32m[0907 01-03-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31703, current rewards: -713.00887, mean: -0.33792
[32m[0907 01-03-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31641, current rewards: -708.52002, mean: -0.32802
[32m[0907 01-03-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31583, current rewards: -703.61722, mean: -0.31838
[32m[0907 01-04-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31527, current rewards: -728.55019, mean: -0.32237
[32m[0907 01-04-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31483, current rewards: -722.88528, mean: -0.31294
[32m[0907 01-04-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31468, current rewards: -717.32884, mean: -0.30395
[32m[0907 01-04-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31459, current rewards: -711.77542, mean: -0.29534
[32m[0907 01-05-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31460, current rewards: -728.86969, mean: -0.29629
[32m[0907 01-05-18 @Agent.py:117][0m Average action selection time: 0.3146
[32m[0907 01-05-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-05-18 @MBExp.py:227][0m Rewards obtained: [-767.1713856340936], Lows: [474], Highs: [81], Total time: 38809.637518
[32m[0907 01-06-48 @MBExp.py:144][0m ####################################################################
[32m[0907 01-06-48 @MBExp.py:145][0m Starting training iteration 47.
[32m[0907 01-06-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31779, current rewards: -7.90255, mean: -0.79026
[32m[0907 01-07-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31633, current rewards: -28.65776, mean: -0.47763
[32m[0907 01-07-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31639, current rewards: -24.68133, mean: -0.22438
[32m[0907 01-07-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31637, current rewards: -20.39642, mean: -0.12748
[32m[0907 01-07-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31642, current rewards: -16.66524, mean: -0.07936
[32m[0907 01-08-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31638, current rewards: -12.59951, mean: -0.04846
[32m[0907 01-08-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31635, current rewards: -8.41724, mean: -0.02715
[32m[0907 01-08-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31634, current rewards: -4.50455, mean: -0.01251
[32m[0907 01-08-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31630, current rewards: -23.85677, mean: -0.05819
[32m[0907 01-09-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31615, current rewards: -34.22434, mean: -0.07440
[32m[0907 01-09-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31617, current rewards: -84.22434, mean: -0.16515
[32m[0907 01-09-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31616, current rewards: -109.01040, mean: -0.19466
[32m[0907 01-10-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31608, current rewards: -133.74819, mean: -0.21926
[32m[0907 01-10-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31599, current rewards: -183.74819, mean: -0.27841
[32m[0907 01-10-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31588, current rewards: -233.74819, mean: -0.32922
[32m[0907 01-10-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31581, current rewards: -283.74819, mean: -0.37335
[32m[0907 01-11-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31573, current rewards: -307.51034, mean: -0.37964
[32m[0907 01-11-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31568, current rewards: -357.51034, mean: -0.41571
[32m[0907 01-11-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31560, current rewards: -382.32095, mean: -0.42013
[32m[0907 01-11-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31558, current rewards: -448.03812, mean: -0.46671
[32m[0907 01-12-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31556, current rewards: -457.13898, mean: -0.45261
[32m[0907 01-12-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31553, current rewards: -453.97242, mean: -0.42828
[32m[0907 01-12-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31548, current rewards: -450.88146, mean: -0.40620
[32m[0907 01-12-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31543, current rewards: -447.82859, mean: -0.38606
[32m[0907 01-13-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31537, current rewards: -444.79624, mean: -0.36760
[32m[0907 01-13-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31534, current rewards: -441.76714, mean: -0.35061
[32m[0907 01-13-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31532, current rewards: -438.73824, mean: -0.33491
[32m[0907 01-13-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31531, current rewards: -462.52586, mean: -0.34009
[32m[0907 01-14-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31527, current rewards: -464.43886, mean: -0.32939
[32m[0907 01-14-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31528, current rewards: -465.73557, mean: -0.31900
[32m[0907 01-14-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31524, current rewards: -467.00715, mean: -0.30928
[32m[0907 01-15-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31521, current rewards: -470.44291, mean: -0.30157
[32m[0907 01-15-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31517, current rewards: -471.73493, mean: -0.29300
[32m[0907 01-15-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31516, current rewards: -513.10902, mean: -0.30910
[32m[0907 01-15-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31515, current rewards: -499.21799, mean: -0.29194
[32m[0907 01-16-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31511, current rewards: -484.52760, mean: -0.27530
[32m[0907 01-16-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31498, current rewards: -493.54741, mean: -0.27268
[32m[0907 01-16-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31477, current rewards: -546.53262, mean: -0.29383
[32m[0907 01-16-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31459, current rewards: -601.32868, mean: -0.31483
[32m[0907 01-17-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31441, current rewards: -659.91794, mean: -0.33669
[32m[0907 01-17-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31414, current rewards: -701.52641, mean: -0.34902
[32m[0907 01-17-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31358, current rewards: -753.27810, mean: -0.36567
[32m[0907 01-17-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31313, current rewards: -813.71582, mean: -0.38565
[32m[0907 01-18-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31261, current rewards: -851.02258, mean: -0.39399
[32m[0907 01-18-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31237, current rewards: -905.34610, mean: -0.40966
[32m[0907 01-18-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31190, current rewards: -899.18424, mean: -0.39787
[32m[0907 01-18-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31152, current rewards: -893.38420, mean: -0.38675
[32m[0907 01-19-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31143, current rewards: -887.58757, mean: -0.37610
[32m[0907 01-19-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31137, current rewards: -881.78720, mean: -0.36589
[32m[0907 01-19-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31151, current rewards: -918.19205, mean: -0.37325
[32m[0907 01-19-47 @Agent.py:117][0m Average action selection time: 0.3116
[32m[0907 01-19-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-19-47 @MBExp.py:227][0m Rewards obtained: [-914.831504217165], Lows: [295], Highs: [528], Total time: 39589.247587000005
[32m[0907 01-21-18 @MBExp.py:144][0m ####################################################################
[32m[0907 01-21-18 @MBExp.py:145][0m Starting training iteration 48.
[32m[0907 01-21-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31608, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-21-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31681, current rewards: -14.96716, mean: -0.24945
[32m[0907 01-21-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31664, current rewards: -7.15145, mean: -0.06501
[32m[0907 01-22-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31647, current rewards: 3.82388, mean: 0.02390
[32m[0907 01-22-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31632, current rewards: 11.33435, mean: 0.05397
[32m[0907 01-22-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31612, current rewards: 18.75301, mean: 0.07213
[32m[0907 01-22-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31613, current rewards: 26.16987, mean: 0.08442
[32m[0907 01-23-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31613, current rewards: 23.24892, mean: 0.06458
[32m[0907 01-23-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31613, current rewards: 18.82958, mean: 0.04593
[32m[0907 01-23-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31609, current rewards: -8.80271, mean: -0.01914
[32m[0907 01-24-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31618, current rewards: -23.54987, mean: -0.04618
[32m[0907 01-24-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31612, current rewards: -34.82941, mean: -0.06220
[32m[0907 01-24-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31613, current rewards: -29.19459, mean: -0.04786
[32m[0907 01-24-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31598, current rewards: -22.51595, mean: -0.03412
[32m[0907 01-25-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31595, current rewards: -59.22863, mean: -0.08342
[32m[0907 01-25-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31596, current rewards: -50.37147, mean: -0.06628
[32m[0907 01-25-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31597, current rewards: -41.81145, mean: -0.05162
[32m[0907 01-25-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31596, current rewards: -33.31631, mean: -0.03874
[32m[0907 01-26-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31595, current rewards: -24.82399, mean: -0.02728
[32m[0907 01-26-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31582, current rewards: -16.21717, mean: -0.01689
[32m[0907 01-26-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31577, current rewards: 2.58376, mean: 0.00256
[32m[0907 01-26-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31568, current rewards: 10.96158, mean: 0.01034
[32m[0907 01-27-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31563, current rewards: 19.30450, mean: 0.01739
[32m[0907 01-27-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31557, current rewards: 27.65276, mean: 0.02384
[32m[0907 01-27-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31555, current rewards: 35.99514, mean: 0.02975
[32m[0907 01-27-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31552, current rewards: 44.33871, mean: 0.03519
[32m[0907 01-28-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31552, current rewards: 52.67163, mean: 0.04021
[32m[0907 01-28-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31552, current rewards: 28.51173, mean: 0.02096
[32m[0907 01-28-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31563, current rewards: 7.88064, mean: 0.00559
[32m[0907 01-29-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31573, current rewards: -8.77274, mean: -0.00601
[32m[0907 01-29-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31568, current rewards: -1.62041, mean: -0.00107
[32m[0907 01-29-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31561, current rewards: 5.16998, mean: 0.00331
[32m[0907 01-29-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31555, current rewards: 11.96292, mean: 0.00743
[32m[0907 01-30-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31551, current rewards: 18.75833, mean: 0.01130
[32m[0907 01-30-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31549, current rewards: 25.55306, mean: 0.01494
[32m[0907 01-30-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31547, current rewards: 32.34815, mean: 0.01838
[32m[0907 01-30-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31530, current rewards: 38.84750, mean: 0.02146
[32m[0907 01-31-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31509, current rewards: 45.64252, mean: 0.02454
[32m[0907 01-31-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31487, current rewards: 45.63432, mean: 0.02389
[32m[0907 01-31-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31467, current rewards: 35.56350, mean: 0.01814
[32m[0907 01-31-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31435, current rewards: 45.15998, mean: 0.02247
[32m[0907 01-32-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31379, current rewards: 54.72348, mean: 0.02656
[32m[0907 01-32-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31334, current rewards: 64.28039, mean: 0.03046
[32m[0907 01-32-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31280, current rewards: 73.82191, mean: 0.03418
[32m[0907 01-32-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31228, current rewards: 39.78094, mean: 0.01800
[32m[0907 01-33-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31178, current rewards: 17.25939, mean: 0.00764
[32m[0907 01-33-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31138, current rewards: 27.57931, mean: 0.01194
[32m[0907 01-33-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31128, current rewards: 37.54316, mean: 0.01591
[32m[0907 01-33-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31121, current rewards: 27.70014, mean: 0.01149
[32m[0907 01-34-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31147, current rewards: -22.26546, mean: -0.00905
[32m[0907 01-34-18 @Agent.py:117][0m Average action selection time: 0.3115
[32m[0907 01-34-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-34-18 @MBExp.py:227][0m Rewards obtained: [-14.013689526172001], Lows: [175], Highs: [63], Total time: 40368.766605000004
[32m[0907 01-35-51 @MBExp.py:144][0m ####################################################################
[32m[0907 01-35-51 @MBExp.py:145][0m Starting training iteration 49.
[32m[0907 01-35-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31548, current rewards: 1.07551, mean: 0.10755
[32m[0907 01-36-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31598, current rewards: 6.76821, mean: 0.11280
[32m[0907 01-36-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31632, current rewards: 12.44527, mean: 0.11314
[32m[0907 01-36-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31613, current rewards: 16.16891, mean: 0.10106
[32m[0907 01-36-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31611, current rewards: 19.74965, mean: 0.09405
[32m[0907 01-37-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31596, current rewards: 20.11554, mean: 0.07737
[32m[0907 01-37-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31594, current rewards: -29.88446, mean: -0.09640
[32m[0907 01-37-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31576, current rewards: -79.88446, mean: -0.22190
[32m[0907 01-38-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31570, current rewards: -129.88446, mean: -0.31679
[32m[0907 01-38-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31559, current rewards: -179.88446, mean: -0.39105
[32m[0907 01-38-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31553, current rewards: -229.88446, mean: -0.45075
[32m[0907 01-38-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31561, current rewards: -279.88446, mean: -0.49979
[32m[0907 01-39-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31563, current rewards: -329.88446, mean: -0.54079
[32m[0907 01-39-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31569, current rewards: -379.88446, mean: -0.57558
[32m[0907 01-39-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31569, current rewards: -429.88446, mean: -0.60547
[32m[0907 01-39-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31568, current rewards: -479.88446, mean: -0.63143
[32m[0907 01-40-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31566, current rewards: -529.88446, mean: -0.65418
[32m[0907 01-40-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31571, current rewards: -579.88446, mean: -0.67428
[32m[0907 01-40-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31573, current rewards: -629.88446, mean: -0.69218
[32m[0907 01-40-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31573, current rewards: -679.88446, mean: -0.70821
[32m[0907 01-41-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31566, current rewards: -729.88446, mean: -0.72266
[32m[0907 01-41-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31562, current rewards: -779.88446, mean: -0.73574
[32m[0907 01-41-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31557, current rewards: -829.88446, mean: -0.74764
[32m[0907 01-41-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31554, current rewards: -879.88446, mean: -0.75852
[32m[0907 01-42-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31554, current rewards: -929.88446, mean: -0.76850
[32m[0907 01-42-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31551, current rewards: -979.88446, mean: -0.77769
[32m[0907 01-42-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31551, current rewards: -1029.88446, mean: -0.78617
[32m[0907 01-43-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31545, current rewards: -1051.57549, mean: -0.77322
[32m[0907 01-43-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31542, current rewards: -1049.15148, mean: -0.74408
[32m[0907 01-43-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31538, current rewards: -1050.92139, mean: -0.71981
[32m[0907 01-43-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31535, current rewards: -1100.92139, mean: -0.72909
[32m[0907 01-44-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31530, current rewards: -1150.92139, mean: -0.73777
[32m[0907 01-44-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31524, current rewards: -1200.92139, mean: -0.74591
[32m[0907 01-44-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31521, current rewards: -1250.92139, mean: -0.75357
[32m[0907 01-44-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31519, current rewards: -1300.92139, mean: -0.76077
[32m[0907 01-45-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31515, current rewards: -1350.92139, mean: -0.76757
[32m[0907 01-45-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31498, current rewards: -1400.92139, mean: -0.77399
[32m[0907 01-45-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31476, current rewards: -1450.92139, mean: -0.78007
[32m[0907 01-45-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31458, current rewards: -1500.92139, mean: -0.78582
[32m[0907 01-46-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31441, current rewards: -1550.92139, mean: -0.79129
[32m[0907 01-46-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31411, current rewards: -1600.92139, mean: -0.79648
[32m[0907 01-46-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31355, current rewards: -1650.92139, mean: -0.80142
[32m[0907 01-46-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31308, current rewards: -1700.92139, mean: -0.80612
[32m[0907 01-47-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31256, current rewards: -1750.92139, mean: -0.81061
[32m[0907 01-47-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31206, current rewards: -1800.92139, mean: -0.81490
[32m[0907 01-47-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31159, current rewards: -1850.92139, mean: -0.81899
[32m[0907 01-47-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31119, current rewards: -1900.92139, mean: -0.82291
[32m[0907 01-48-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31104, current rewards: -1950.92139, mean: -0.82666
[32m[0907 01-48-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31098, current rewards: -1985.07690, mean: -0.82368
[32m[0907 01-48-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31107, current rewards: -1982.26191, mean: -0.80580
[32m[0907 01-48-49 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 01-48-49 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-48-49 @MBExp.py:227][0m Rewards obtained: [-1980.0099261495016], Lows: [0], Highs: [2015], Total time: 41147.306993000006
[32m[0907 01-50-24 @MBExp.py:144][0m ####################################################################
[32m[0907 01-50-24 @MBExp.py:145][0m Starting training iteration 50.
[32m[0907 01-50-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31829, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-50-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31732, current rewards: -19.87224, mean: -0.33120
[32m[0907 01-50-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31694, current rewards: -111.57882, mean: -1.01435
[32m[0907 01-51-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31661, current rewards: -211.57882, mean: -1.32237
[32m[0907 01-51-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31624, current rewards: -311.57882, mean: -1.48371
[32m[0907 01-51-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31623, current rewards: -411.57882, mean: -1.58300
[32m[0907 01-52-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31617, current rewards: -511.57882, mean: -1.65025
[32m[0907 01-52-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31609, current rewards: -611.57882, mean: -1.69883
[32m[0907 01-52-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31603, current rewards: -710.57882, mean: -1.73312
[32m[0907 01-52-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31592, current rewards: -784.59802, mean: -1.70565
[32m[0907 01-53-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31583, current rewards: -884.59802, mean: -1.73451
[32m[0907 01-53-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31573, current rewards: -984.59802, mean: -1.75821
[32m[0907 01-53-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31565, current rewards: -1084.59802, mean: -1.77803
[32m[0907 01-53-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31562, current rewards: -1184.59802, mean: -1.79485
[32m[0907 01-54-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31559, current rewards: -1284.59802, mean: -1.80929
[32m[0907 01-54-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31562, current rewards: -1384.59802, mean: -1.82184
[32m[0907 01-54-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31561, current rewards: -1484.59802, mean: -1.83284
[32m[0907 01-54-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31564, current rewards: -1584.59802, mean: -1.84256
[32m[0907 01-55-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31562, current rewards: -1684.59802, mean: -1.85121
[32m[0907 01-55-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31559, current rewards: -1784.59802, mean: -1.85896
[32m[0907 01-55-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31552, current rewards: -1884.59802, mean: -1.86594
[32m[0907 01-55-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31546, current rewards: -1984.59802, mean: -1.87226
[32m[0907 01-56-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31542, current rewards: -2084.59802, mean: -1.87802
[32m[0907 01-56-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31538, current rewards: -2184.59802, mean: -1.88327
[32m[0907 01-56-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31538, current rewards: -2284.59802, mean: -1.88810
[32m[0907 01-57-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31533, current rewards: -2384.59802, mean: -1.89254
[32m[0907 01-57-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31530, current rewards: -2484.59802, mean: -1.89664
[32m[0907 01-57-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31527, current rewards: -2584.59802, mean: -1.90044
[32m[0907 01-57-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31521, current rewards: -2684.59802, mean: -1.90397
[32m[0907 01-58-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31520, current rewards: -2784.59802, mean: -1.90726
[32m[0907 01-58-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31522, current rewards: -2884.59802, mean: -1.91033
[32m[0907 01-58-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31524, current rewards: -2984.59802, mean: -1.91320
[32m[0907 01-58-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31523, current rewards: -3084.59802, mean: -1.91590
[32m[0907 01-59-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31524, current rewards: -3184.59802, mean: -1.91843
[32m[0907 01-59-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31523, current rewards: -3284.59802, mean: -1.92082
[32m[0907 01-59-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31522, current rewards: -3384.59802, mean: -1.92307
[32m[0907 01-59-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31505, current rewards: -3484.59802, mean: -1.92519
[32m[0907 02-00-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31484, current rewards: -3584.59802, mean: -1.92720
[32m[0907 02-00-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31463, current rewards: -3684.59802, mean: -1.92911
[32m[0907 02-00-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31444, current rewards: -3784.59802, mean: -1.93092
[32m[0907 02-00-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31415, current rewards: -3884.59802, mean: -1.93264
[32m[0907 02-01-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31359, current rewards: -3984.59802, mean: -1.93427
[32m[0907 02-01-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31311, current rewards: -4064.59802, mean: -1.92635
[32m[0907 02-01-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31257, current rewards: -4162.20506, mean: -1.92695
[32m[0907 02-01-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31208, current rewards: -4218.07088, mean: -1.90863
[32m[0907 02-02-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31160, current rewards: -4273.34320, mean: -1.89086
[32m[0907 02-02-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31115, current rewards: -4341.61149, mean: -1.87949
[32m[0907 02-02-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31098, current rewards: -4396.29478, mean: -1.86284
[32m[0907 02-02-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31092, current rewards: -4441.36341, mean: -1.84289
[32m[0907 02-03-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31099, current rewards: -4511.16009, mean: -1.83380
[32m[0907 02-03-22 @Agent.py:117][0m Average action selection time: 0.3110
[32m[0907 02-03-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-03-23 @MBExp.py:227][0m Rewards obtained: [-4564.001537888673], Lows: [2286], Highs: [65], Total time: 41925.587442000004
[32m[0907 02-05-00 @MBExp.py:144][0m ####################################################################
[32m[0907 02-05-00 @MBExp.py:145][0m Starting training iteration 51.
[32m[0907 02-05-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31612, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-05-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31587, current rewards: -16.42161, mean: -0.27369
[32m[0907 02-05-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31584, current rewards: -6.08856, mean: -0.05535
[32m[0907 02-05-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31585, current rewards: 0.56384, mean: 0.00352
[32m[0907 02-06-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31599, current rewards: -12.29564, mean: -0.05855
[32m[0907 02-06-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31595, current rewards: -28.76476, mean: -0.11063
[32m[0907 02-06-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31600, current rewards: -19.72620, mean: -0.06363
[32m[0907 02-06-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31602, current rewards: -10.60632, mean: -0.02946
[32m[0907 02-07-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31598, current rewards: -4.41404, mean: -0.01077
[32m[0907 02-07-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31591, current rewards: 2.43314, mean: 0.00529
[32m[0907 02-07-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31589, current rewards: 8.88814, mean: 0.01743
[32m[0907 02-07-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31586, current rewards: 14.55572, mean: 0.02599
[32m[0907 02-08-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31589, current rewards: 20.68218, mean: 0.03391
[32m[0907 02-08-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31590, current rewards: 26.80937, mean: 0.04062
[32m[0907 02-08-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31588, current rewards: -9.19866, mean: -0.01296
[32m[0907 02-09-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31585, current rewards: -2.61693, mean: -0.00344
[32m[0907 02-09-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31582, current rewards: 4.38526, mean: 0.00541
[32m[0907 02-09-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31580, current rewards: 11.38665, mean: 0.01324
[32m[0907 02-09-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31575, current rewards: 18.37403, mean: 0.02019
[32m[0907 02-10-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31574, current rewards: 23.68222, mean: 0.02467
[32m[0907 02-10-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31574, current rewards: 30.35244, mean: 0.03005
[32m[0907 02-10-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31571, current rewards: 37.11525, mean: 0.03501
[32m[0907 02-10-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31572, current rewards: 43.86184, mean: 0.03952
[32m[0907 02-11-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31575, current rewards: 50.60901, mean: 0.04363
[32m[0907 02-11-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31569, current rewards: 57.35612, mean: 0.04740
[32m[0907 02-11-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31565, current rewards: 21.41030, mean: 0.01699
[32m[0907 02-11-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31559, current rewards: 27.84210, mean: 0.02125
[32m[0907 02-12-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31558, current rewards: 34.96572, mean: 0.02571
[32m[0907 02-12-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31559, current rewards: 42.09186, mean: 0.02985
[32m[0907 02-12-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31558, current rewards: 49.22375, mean: 0.03371
[32m[0907 02-12-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31558, current rewards: 56.35565, mean: 0.03732
[32m[0907 02-13-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31552, current rewards: 63.47908, mean: 0.04069
[32m[0907 02-13-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31546, current rewards: 70.61076, mean: 0.04386
[32m[0907 02-13-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31544, current rewards: 77.73947, mean: 0.04683
[32m[0907 02-13-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31541, current rewards: 84.86141, mean: 0.04963
[32m[0907 02-14-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31539, current rewards: 52.16128, mean: 0.02964
[32m[0907 02-14-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31521, current rewards: 57.85532, mean: 0.03196
[32m[0907 02-14-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31501, current rewards: 63.59512, mean: 0.03419
[32m[0907 02-15-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31484, current rewards: 46.94460, mean: 0.02458
[32m[0907 02-15-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31465, current rewards: 55.40783, mean: 0.02827
[32m[0907 02-15-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31435, current rewards: 64.26284, mean: 0.03197
[32m[0907 02-15-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31383, current rewards: 73.12100, mean: 0.03550
[32m[0907 02-16-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31333, current rewards: 81.99231, mean: 0.03886
[32m[0907 02-16-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31280, current rewards: 89.91564, mean: 0.04163
[32m[0907 02-16-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31229, current rewards: 96.32951, mean: 0.04359
[32m[0907 02-16-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31181, current rewards: 104.71472, mean: 0.04633
[32m[0907 02-16-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31135, current rewards: 113.02356, mean: 0.04893
[32m[0907 02-17-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31116, current rewards: 95.99811, mean: 0.04068
[32m[0907 02-17-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31111, current rewards: 103.62133, mean: 0.04300
[32m[0907 02-17-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31116, current rewards: 108.97082, mean: 0.04430
[32m[0907 02-17-58 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 02-17-58 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-17-58 @MBExp.py:227][0m Rewards obtained: [113.2591954142073], Lows: [81], Highs: [61], Total time: 42704.361559000004
[32m[0907 02-19-37 @MBExp.py:144][0m ####################################################################
[32m[0907 02-19-37 @MBExp.py:145][0m Starting training iteration 52.
[32m[0907 02-19-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31717, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-19-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31683, current rewards: -34.50316, mean: -0.57505
[32m[0907 02-20-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31593, current rewards: -38.88242, mean: -0.35348
[32m[0907 02-20-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31571, current rewards: -46.02824, mean: -0.28768
[32m[0907 02-20-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31556, current rewards: -40.67247, mean: -0.19368
[32m[0907 02-21-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31566, current rewards: -35.30895, mean: -0.13580
[32m[0907 02-21-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31545, current rewards: -29.94683, mean: -0.09660
[32m[0907 02-21-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31534, current rewards: -24.58143, mean: -0.06828
[32m[0907 02-21-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31538, current rewards: -19.21254, mean: -0.04686
[32m[0907 02-22-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31535, current rewards: -13.85337, mean: -0.03012
[32m[0907 02-22-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31539, current rewards: -49.92007, mean: -0.09788
[32m[0907 02-22-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31548, current rewards: -54.84256, mean: -0.09793
[32m[0907 02-22-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31547, current rewards: -49.19325, mean: -0.08064
[32m[0907 02-23-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31551, current rewards: -43.77029, mean: -0.06632
[32m[0907 02-23-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31550, current rewards: -38.35394, mean: -0.05402
[32m[0907 02-23-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31547, current rewards: -32.93751, mean: -0.04334
[32m[0907 02-23-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31545, current rewards: -27.51988, mean: -0.03398
[32m[0907 02-24-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31547, current rewards: -63.53828, mean: -0.07388
[32m[0907 02-24-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31549, current rewards: -57.97044, mean: -0.06370
[32m[0907 02-24-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31541, current rewards: -51.80957, mean: -0.05397
[32m[0907 02-24-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31539, current rewards: -37.05572, mean: -0.03669
[32m[0907 02-25-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31539, current rewards: -27.06871, mean: -0.02554
[32m[0907 02-25-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31536, current rewards: -21.32035, mean: -0.01921
[32m[0907 02-25-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31534, current rewards: -15.90085, mean: -0.01371
[32m[0907 02-25-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31532, current rewards: -10.47820, mean: -0.00866
[32m[0907 02-26-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31528, current rewards: -5.05863, mean: -0.00401
[32m[0907 02-26-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31523, current rewards: 0.36502, mean: 0.00028
[32m[0907 02-26-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31516, current rewards: 5.79307, mean: 0.00426
[32m[0907 02-27-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31516, current rewards: 10.82531, mean: 0.00768
[32m[0907 02-27-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31518, current rewards: 16.28788, mean: 0.01116
[32m[0907 02-27-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31517, current rewards: 0.67102, mean: 0.00044
[32m[0907 02-27-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31517, current rewards: 5.36737, mean: 0.00344
[32m[0907 02-28-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31513, current rewards: 10.45693, mean: 0.00649
[32m[0907 02-28-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31510, current rewards: 15.53526, mean: 0.00936
[32m[0907 02-28-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31506, current rewards: 20.63451, mean: 0.01207
[32m[0907 02-28-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31504, current rewards: 25.71986, mean: 0.01461
[32m[0907 02-29-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31489, current rewards: 31.44837, mean: 0.01737
[32m[0907 02-29-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31471, current rewards: 36.61003, mean: 0.01968
[32m[0907 02-29-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31454, current rewards: 41.64920, mean: 0.02181
[32m[0907 02-29-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31437, current rewards: 47.52298, mean: 0.02425
[32m[0907 02-30-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31412, current rewards: 52.54269, mean: 0.02614
[32m[0907 02-30-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31364, current rewards: 57.59606, mean: 0.02796
[32m[0907 02-30-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31313, current rewards: 62.63977, mean: 0.02969
[32m[0907 02-30-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31262, current rewards: 67.68704, mean: 0.03134
[32m[0907 02-31-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31213, current rewards: 72.09775, mean: 0.03262
[32m[0907 02-31-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31166, current rewards: 77.32719, mean: 0.03422
[32m[0907 02-31-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31123, current rewards: 82.35665, mean: 0.03565
[32m[0907 02-31-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31094, current rewards: 87.36681, mean: 0.03702
[32m[0907 02-32-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31090, current rewards: 92.38645, mean: 0.03833
[32m[0907 02-32-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31095, current rewards: 97.41159, mean: 0.03960
[32m[0907 02-32-36 @Agent.py:117][0m Average action selection time: 0.3111
[32m[0907 02-32-36 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-32-36 @MBExp.py:227][0m Rewards obtained: [101.43353960124112], Lows: [53], Highs: [65], Total time: 43482.68655600001
[32m[0907 02-34-17 @MBExp.py:144][0m ####################################################################
[32m[0907 02-34-17 @MBExp.py:145][0m Starting training iteration 53.
[32m[0907 02-34-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31906, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-34-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31729, current rewards: -17.25987, mean: -0.28766
[32m[0907 02-34-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31653, current rewards: -29.84602, mean: -0.27133
[32m[0907 02-35-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31644, current rewards: -22.21763, mean: -0.13886
[32m[0907 02-35-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31635, current rewards: -16.03908, mean: -0.07638
[32m[0907 02-35-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31605, current rewards: -9.83731, mean: -0.03784
[32m[0907 02-35-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31612, current rewards: -3.63874, mean: -0.01174
[32m[0907 02-36-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31607, current rewards: 2.55832, mean: 0.00711
[32m[0907 02-36-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31598, current rewards: 6.79289, mean: 0.01657
[32m[0907 02-36-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31592, current rewards: 14.02297, mean: 0.03048
[32m[0907 02-36-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31596, current rewards: 19.23471, mean: 0.03772
[32m[0907 02-37-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31592, current rewards: 23.89701, mean: 0.04267
[32m[0907 02-37-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31592, current rewards: 29.79636, mean: 0.04885
[32m[0907 02-37-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31587, current rewards: 35.70165, mean: 0.05409
[32m[0907 02-38-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31587, current rewards: 41.60412, mean: 0.05860
[32m[0907 02-38-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31580, current rewards: 47.50687, mean: 0.06251
[32m[0907 02-38-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31573, current rewards: 53.41170, mean: 0.06594
[32m[0907 02-38-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31572, current rewards: 57.92693, mean: 0.06736
[32m[0907 02-39-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31566, current rewards: 64.11008, mean: 0.07045
[32m[0907 02-39-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31559, current rewards: 70.22968, mean: 0.07316
[32m[0907 02-39-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31558, current rewards: 76.34898, mean: 0.07559
[32m[0907 02-39-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31558, current rewards: 82.46860, mean: 0.07780
[32m[0907 02-40-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31561, current rewards: 88.58915, mean: 0.07981
[32m[0907 02-40-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31559, current rewards: 94.70875, mean: 0.08165
[32m[0907 02-40-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31559, current rewards: 100.82792, mean: 0.08333
[32m[0907 02-40-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31557, current rewards: 46.60968, mean: 0.03699
[32m[0907 02-41-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31557, current rewards: 58.43085, mean: 0.04460
[32m[0907 02-41-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31554, current rewards: 69.54924, mean: 0.05114
[32m[0907 02-41-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31553, current rewards: 81.06804, mean: 0.05750
[32m[0907 02-41-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31550, current rewards: 92.57231, mean: 0.06341
[32m[0907 02-42-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31549, current rewards: 104.08304, mean: 0.06893
[32m[0907 02-42-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31547, current rewards: 115.57624, mean: 0.07409
[32m[0907 02-42-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31547, current rewards: 127.06830, mean: 0.07892
[32m[0907 02-43-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31545, current rewards: 138.56795, mean: 0.08347
[32m[0907 02-43-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31544, current rewards: 150.07301, mean: 0.08776
[32m[0907 02-43-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31543, current rewards: 136.59932, mean: 0.07761
[32m[0907 02-43-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31528, current rewards: 125.79783, mean: 0.06950
[32m[0907 02-44-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31508, current rewards: 95.84859, mean: 0.05153
[32m[0907 02-44-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31489, current rewards: 82.40455, mean: 0.04314
[32m[0907 02-44-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31473, current rewards: 72.90639, mean: 0.03720
[32m[0907 02-44-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31447, current rewards: 54.81326, mean: 0.02727
[32m[0907 02-45-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31398, current rewards: 45.34940, mean: 0.02201
[32m[0907 02-45-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31344, current rewards: -0.72757, mean: -0.00034
[32m[0907 02-45-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31291, current rewards: -27.66808, mean: -0.01281
[32m[0907 02-45-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31241, current rewards: -21.59366, mean: -0.00977
[32m[0907 02-46-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31192, current rewards: -15.68630, mean: -0.00694
[32m[0907 02-46-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31145, current rewards: -9.78274, mean: -0.00423
[32m[0907 02-46-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31113, current rewards: -3.87854, mean: -0.00164
[32m[0907 02-46-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31105, current rewards: 2.02454, mean: 0.00084
[32m[0907 02-47-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31107, current rewards: 7.92780, mean: 0.00322
[32m[0907 02-47-15 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 02-47-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-47-15 @MBExp.py:227][0m Rewards obtained: [12.6507808574134], Lows: [152], Highs: [42], Total time: 44261.294224000005
[32m[0907 02-48-58 @MBExp.py:144][0m ####################################################################
[32m[0907 02-48-58 @MBExp.py:145][0m Starting training iteration 54.
[32m[0907 02-49-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31933, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-49-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31669, current rewards: -16.39614, mean: -0.27327
[32m[0907 02-49-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31644, current rewards: -20.28248, mean: -0.18439
[32m[0907 02-49-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31607, current rewards: -52.89540, mean: -0.33060
[32m[0907 02-50-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31586, current rewards: -93.41674, mean: -0.44484
[32m[0907 02-50-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31586, current rewards: -125.41470, mean: -0.48236
[32m[0907 02-50-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31605, current rewards: -161.24574, mean: -0.52015
[32m[0907 02-50-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31603, current rewards: -198.85062, mean: -0.55236
[32m[0907 02-51-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31595, current rewards: -234.83801, mean: -0.57278
[32m[0907 02-51-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31598, current rewards: -252.49703, mean: -0.54891
[32m[0907 02-51-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31602, current rewards: -293.25427, mean: -0.57501
[32m[0907 02-51-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31595, current rewards: -328.65715, mean: -0.58689
[32m[0907 02-52-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31591, current rewards: -378.14806, mean: -0.61991
[32m[0907 02-52-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31595, current rewards: -373.43657, mean: -0.56581
[32m[0907 02-52-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31597, current rewards: -366.12465, mean: -0.51567
[32m[0907 02-52-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31591, current rewards: -358.82388, mean: -0.47214
[32m[0907 02-53-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31593, current rewards: -351.51752, mean: -0.43397
[32m[0907 02-53-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31586, current rewards: -346.50444, mean: -0.40291
[32m[0907 02-53-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31588, current rewards: -360.75174, mean: -0.39643
[32m[0907 02-54-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31591, current rewards: -354.63287, mean: -0.36941
[32m[0907 02-54-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31595, current rewards: -348.38069, mean: -0.34493
[32m[0907 02-54-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31592, current rewards: -342.14457, mean: -0.32278
[32m[0907 02-54-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31591, current rewards: -335.90534, mean: -0.30262
[32m[0907 02-55-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31595, current rewards: -329.66742, mean: -0.28420
[32m[0907 02-55-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31595, current rewards: -323.42686, mean: -0.26729
[32m[0907 02-55-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31595, current rewards: -314.27062, mean: -0.24942
[32m[0907 02-55-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31592, current rewards: -305.32847, mean: -0.23308
[32m[0907 02-56-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31587, current rewards: -299.34184, mean: -0.22010
[32m[0907 02-56-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31583, current rewards: -293.35586, mean: -0.20805
[32m[0907 02-56-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31578, current rewards: -309.76168, mean: -0.21217
[32m[0907 02-56-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31575, current rewards: -302.66822, mean: -0.20044
[32m[0907 02-57-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31575, current rewards: -294.71865, mean: -0.18892
[32m[0907 02-57-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31569, current rewards: -286.78021, mean: -0.17812
[32m[0907 02-57-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31567, current rewards: -278.79869, mean: -0.16795
[32m[0907 02-57-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31563, current rewards: -270.66404, mean: -0.15828
[32m[0907 02-58-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31561, current rewards: -262.73523, mean: -0.14928
[32m[0907 02-58-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31544, current rewards: -254.80183, mean: -0.14077
[32m[0907 02-58-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31524, current rewards: -246.87474, mean: -0.13273
[32m[0907 02-59-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31505, current rewards: -238.93524, mean: -0.12510
[32m[0907 02-59-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31488, current rewards: -230.99072, mean: -0.11785
[32m[0907 02-59-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31461, current rewards: -224.69205, mean: -0.11179
[32m[0907 02-59-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31417, current rewards: -213.95090, mean: -0.10386
[32m[0907 03-00-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31360, current rewards: -205.63547, mean: -0.09746
[32m[0907 03-00-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31307, current rewards: -194.89299, mean: -0.09023
[32m[0907 03-00-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31256, current rewards: -184.20081, mean: -0.08335
[32m[0907 03-00-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31206, current rewards: -173.49345, mean: -0.07677
[32m[0907 03-00-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31159, current rewards: -162.75167, mean: -0.07046
[32m[0907 03-01-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31124, current rewards: -189.67859, mean: -0.08037
[32m[0907 03-01-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31107, current rewards: -189.54629, mean: -0.07865
[32m[0907 03-01-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31109, current rewards: -183.10392, mean: -0.07443
[32m[0907 03-01-57 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 03-01-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-01-57 @MBExp.py:227][0m Rewards obtained: [-174.2225592231009], Lows: [239], Highs: [61], Total time: 45040.006155
[32m[0907 03-03-42 @MBExp.py:144][0m ####################################################################
[32m[0907 03-03-42 @MBExp.py:145][0m Starting training iteration 55.
[32m[0907 03-03-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31779, current rewards: -0.48947, mean: -0.04895
[32m[0907 03-04-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31670, current rewards: -7.99045, mean: -0.13317
[32m[0907 03-04-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31693, current rewards: -0.82977, mean: -0.00754
[32m[0907 03-04-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31698, current rewards: 6.37838, mean: 0.03986
[32m[0907 03-04-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31705, current rewards: 13.51503, mean: 0.06436
[32m[0907 03-05-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31700, current rewards: 20.66778, mean: 0.07949
[32m[0907 03-05-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31708, current rewards: 27.80705, mean: 0.08970
[32m[0907 03-05-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31697, current rewards: 34.95010, mean: 0.09708
[32m[0907 03-05-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31685, current rewards: 42.95815, mean: 0.10478
[32m[0907 03-06-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31686, current rewards: 50.22801, mean: 0.10919
[32m[0907 03-06-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31676, current rewards: 57.28926, mean: 0.11233
[32m[0907 03-06-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31660, current rewards: 37.06107, mean: 0.06618
[32m[0907 03-06-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31648, current rewards: 44.21984, mean: 0.07249
[32m[0907 03-07-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31641, current rewards: 50.81513, mean: 0.07699
[32m[0907 03-07-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31637, current rewards: 57.40463, mean: 0.08085
[32m[0907 03-07-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31636, current rewards: 63.99827, mean: 0.08421
[32m[0907 03-07-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31625, current rewards: 69.93147, mean: 0.08634
[32m[0907 03-08-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31621, current rewards: 76.08458, mean: 0.08847
[32m[0907 03-08-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31617, current rewards: 82.60323, mean: 0.09077
[32m[0907 03-08-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31614, current rewards: 89.11958, mean: 0.09283
[32m[0907 03-09-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31612, current rewards: 95.63894, mean: 0.09469
[32m[0907 03-09-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31610, current rewards: 102.16209, mean: 0.09638
[32m[0907 03-09-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31611, current rewards: 108.67715, mean: 0.09791
[32m[0907 03-09-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31611, current rewards: 115.19344, mean: 0.09930
[32m[0907 03-10-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31609, current rewards: 121.91694, mean: 0.10076
[32m[0907 03-10-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31609, current rewards: 128.60505, mean: 0.10207
[32m[0907 03-10-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31603, current rewards: 135.14557, mean: 0.10316
[32m[0907 03-10-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31599, current rewards: 104.15204, mean: 0.07658
[32m[0907 03-11-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31595, current rewards: 89.71253, mean: 0.06363
[32m[0907 03-11-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31593, current rewards: 95.82201, mean: 0.06563
[32m[0907 03-11-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31594, current rewards: 101.95038, mean: 0.06752
[32m[0907 03-11-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31594, current rewards: 108.08619, mean: 0.06929
[32m[0907 03-12-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31593, current rewards: 114.02138, mean: 0.07082
[32m[0907 03-12-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31591, current rewards: 119.77078, mean: 0.07215
[32m[0907 03-12-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31587, current rewards: 125.89720, mean: 0.07362
[32m[0907 03-12-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31587, current rewards: 132.02071, mean: 0.07501
[32m[0907 03-13-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31566, current rewards: 138.14229, mean: 0.07632
[32m[0907 03-13-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31543, current rewards: 144.26198, mean: 0.07756
[32m[0907 03-13-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31521, current rewards: 150.37865, mean: 0.07873
[32m[0907 03-14-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31502, current rewards: 156.50224, mean: 0.07985
[32m[0907 03-14-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31470, current rewards: 162.62262, mean: 0.08091
[32m[0907 03-14-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31423, current rewards: 171.32864, mean: 0.08317
[32m[0907 03-14-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31365, current rewards: 177.47831, mean: 0.08411
[32m[0907 03-14-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31310, current rewards: 183.61228, mean: 0.08501
[32m[0907 03-15-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31258, current rewards: 146.25244, mean: 0.06618
[32m[0907 03-15-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31208, current rewards: 151.23072, mean: 0.06692
[32m[0907 03-15-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31160, current rewards: 156.15349, mean: 0.06760
[32m[0907 03-15-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31122, current rewards: 161.07831, mean: 0.06825
[32m[0907 03-16-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31101, current rewards: 166.01121, mean: 0.06888
[32m[0907 03-16-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31100, current rewards: 173.35453, mean: 0.07047
[32m[0907 03-16-40 @Agent.py:117][0m Average action selection time: 0.3111
[32m[0907 03-16-40 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-16-40 @MBExp.py:227][0m Rewards obtained: [177.41684018046203], Lows: [39], Highs: [52], Total time: 45818.444032
[32m[0907 03-18-27 @MBExp.py:144][0m ####################################################################
[32m[0907 03-18-27 @MBExp.py:145][0m Starting training iteration 56.
[32m[0907 03-18-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31820, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-18-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31577, current rewards: -71.13162, mean: -1.18553
[32m[0907 03-19-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31620, current rewards: -108.55316, mean: -0.98685
[32m[0907 03-19-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31644, current rewards: -141.18461, mean: -0.88240
[32m[0907 03-19-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31644, current rewards: -186.58182, mean: -0.88848
[32m[0907 03-19-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31650, current rewards: -220.56312, mean: -0.84832
[32m[0907 03-20-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31649, current rewards: -246.93555, mean: -0.79657
[32m[0907 03-20-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31639, current rewards: -242.03640, mean: -0.67232
[32m[0907 03-20-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31616, current rewards: -234.72248, mean: -0.57249
[32m[0907 03-20-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31609, current rewards: -227.83456, mean: -0.49529
[32m[0907 03-21-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31604, current rewards: -220.94172, mean: -0.43322
[32m[0907 03-21-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31599, current rewards: -214.06176, mean: -0.38225
[32m[0907 03-21-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31584, current rewards: -207.17422, mean: -0.33963
[32m[0907 03-21-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31576, current rewards: -200.27940, mean: -0.30345
[32m[0907 03-22-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31576, current rewards: -193.38450, mean: -0.27237
[32m[0907 03-22-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31569, current rewards: -210.56650, mean: -0.27706
[32m[0907 03-22-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31563, current rewards: -216.07601, mean: -0.26676
[32m[0907 03-22-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31560, current rewards: -230.80724, mean: -0.26838
[32m[0907 03-23-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31557, current rewards: -249.76482, mean: -0.27447
[32m[0907 03-23-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31554, current rewards: -268.73775, mean: -0.27994
[32m[0907 03-23-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31551, current rewards: -287.75481, mean: -0.28491
[32m[0907 03-24-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31549, current rewards: -306.84867, mean: -0.28948
[32m[0907 03-24-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31544, current rewards: -325.94597, mean: -0.29365
[32m[0907 03-24-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31543, current rewards: -345.02328, mean: -0.29743
[32m[0907 03-24-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31541, current rewards: -364.10510, mean: -0.30091
[32m[0907 03-25-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31539, current rewards: -383.10382, mean: -0.30405
[32m[0907 03-25-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31535, current rewards: -402.12608, mean: -0.30697
[32m[0907 03-25-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31530, current rewards: -421.14118, mean: -0.30966
[32m[0907 03-25-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31529, current rewards: -440.14389, mean: -0.31216
[32m[0907 03-26-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31525, current rewards: -459.16394, mean: -0.31450
[32m[0907 03-26-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31523, current rewards: -505.44312, mean: -0.33473
[32m[0907 03-26-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31520, current rewards: -500.29433, mean: -0.32070
[32m[0907 03-26-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31519, current rewards: -495.23318, mean: -0.30760
[32m[0907 03-27-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31516, current rewards: -490.17336, mean: -0.29529
[32m[0907 03-27-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31512, current rewards: -485.11521, mean: -0.28369
[32m[0907 03-27-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31513, current rewards: -480.05658, mean: -0.27276
[32m[0907 03-27-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31493, current rewards: -474.99459, mean: -0.26243
[32m[0907 03-28-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31472, current rewards: -469.93708, mean: -0.25265
[32m[0907 03-28-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31452, current rewards: -464.87882, mean: -0.24339
[32m[0907 03-28-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31434, current rewards: -459.82070, mean: -0.23460
[32m[0907 03-28-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31407, current rewards: -454.12636, mean: -0.22593
[32m[0907 03-29-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31368, current rewards: -488.93553, mean: -0.23735
[32m[0907 03-29-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31312, current rewards: -518.37409, mean: -0.24567
[32m[0907 03-29-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31258, current rewards: -511.72862, mean: -0.23691
[32m[0907 03-29-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31210, current rewards: -505.58704, mean: -0.22877
[32m[0907 03-30-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31161, current rewards: -499.43233, mean: -0.22099
[32m[0907 03-30-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31115, current rewards: -493.27471, mean: -0.21354
[32m[0907 03-30-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31077, current rewards: -487.11660, mean: -0.20641
[32m[0907 03-30-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31052, current rewards: -494.41119, mean: -0.20515
[32m[0907 03-31-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31046, current rewards: -511.24809, mean: -0.20782
[32m[0907 03-31-24 @Agent.py:117][0m Average action selection time: 0.3106
[32m[0907 03-31-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-31-24 @MBExp.py:227][0m Rewards obtained: [-532.5018681544908], Lows: [214], Highs: [347], Total time: 46595.575206
[32m[0907 03-33-12 @MBExp.py:144][0m ####################################################################
[32m[0907 03-33-12 @MBExp.py:145][0m Starting training iteration 57.
[32m[0907 03-33-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31728, current rewards: 0.62608, mean: 0.06261
[32m[0907 03-33-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31646, current rewards: -31.40370, mean: -0.52339
[32m[0907 03-33-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31672, current rewards: -25.32802, mean: -0.23025
[32m[0907 03-34-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31638, current rewards: -19.18585, mean: -0.11991
[32m[0907 03-34-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31633, current rewards: -12.95106, mean: -0.06167
[32m[0907 03-34-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31644, current rewards: -6.63817, mean: -0.02553
[32m[0907 03-34-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31641, current rewards: -22.33771, mean: -0.07206
[32m[0907 03-35-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31638, current rewards: -14.59171, mean: -0.04053
[32m[0907 03-35-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31630, current rewards: -6.37648, mean: -0.01555
[32m[0907 03-35-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31626, current rewards: 1.84024, mean: 0.00400
[32m[0907 03-35-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31635, current rewards: 10.06291, mean: 0.01973
[32m[0907 03-36-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31627, current rewards: 18.28392, mean: 0.03265
[32m[0907 03-36-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31625, current rewards: 26.49112, mean: 0.04343
[32m[0907 03-36-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31620, current rewards: 34.71277, mean: 0.05260
[32m[0907 03-36-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31622, current rewards: 45.22967, mean: 0.06370
[32m[0907 03-37-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31623, current rewards: 37.39874, mean: 0.04921
[32m[0907 03-37-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31636, current rewards: 27.65285, mean: 0.03414
[32m[0907 03-37-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31642, current rewards: -7.50190, mean: -0.00872
[32m[0907 03-38-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31655, current rewards: -27.45696, mean: -0.03017
[32m[0907 03-38-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31674, current rewards: -59.27471, mean: -0.06174
[32m[0907 03-38-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31677, current rewards: -75.82349, mean: -0.07507
[32m[0907 03-38-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31691, current rewards: -102.03502, mean: -0.09626
[32m[0907 03-39-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31689, current rewards: -117.71042, mean: -0.10605
[32m[0907 03-39-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31701, current rewards: -132.43629, mean: -0.11417
[32m[0907 03-39-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31699, current rewards: -165.80977, mean: -0.13703
[32m[0907 03-39-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31695, current rewards: -179.39813, mean: -0.14238
[32m[0907 03-40-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31694, current rewards: -172.93464, mean: -0.13201
[32m[0907 03-40-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31692, current rewards: -166.43219, mean: -0.12238
[32m[0907 03-40-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31691, current rewards: -159.93824, mean: -0.11343
[32m[0907 03-40-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31686, current rewards: -153.44225, mean: -0.10510
[32m[0907 03-41-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31681, current rewards: -146.94057, mean: -0.09731
[32m[0907 03-41-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31678, current rewards: -140.45343, mean: -0.09003
[32m[0907 03-41-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31675, current rewards: -133.94497, mean: -0.08320
[32m[0907 03-41-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31676, current rewards: -170.09631, mean: -0.10247
[32m[0907 03-42-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31673, current rewards: -164.11393, mean: -0.09597
[32m[0907 03-42-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31667, current rewards: -159.61974, mean: -0.09069
[32m[0907 03-42-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31644, current rewards: -155.18934, mean: -0.08574
[32m[0907 03-43-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31624, current rewards: -150.76308, mean: -0.08106
[32m[0907 03-43-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31605, current rewards: -146.33777, mean: -0.07662
[32m[0907 03-43-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31586, current rewards: -145.59642, mean: -0.07428
[32m[0907 03-43-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31556, current rewards: -155.57739, mean: -0.07740
[32m[0907 03-44-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31517, current rewards: -164.07485, mean: -0.07965
[32m[0907 03-44-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31456, current rewards: -178.99007, mean: -0.08483
[32m[0907 03-44-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31400, current rewards: -186.87200, mean: -0.08651
[32m[0907 03-44-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31348, current rewards: -212.67795, mean: -0.09623
[32m[0907 03-45-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31298, current rewards: -214.09497, mean: -0.09473
[32m[0907 03-45-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31250, current rewards: -207.82621, mean: -0.08997
[32m[0907 03-45-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31208, current rewards: -201.60336, mean: -0.08543
[32m[0907 03-45-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31185, current rewards: -196.59425, mean: -0.08157
[32m[0907 03-46-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31176, current rewards: -190.33232, mean: -0.07737
[32m[0907 03-46-13 @Agent.py:117][0m Average action selection time: 0.3119
[32m[0907 03-46-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-46-13 @MBExp.py:227][0m Rewards obtained: [-185.31802978686844], Lows: [240], Highs: [58], Total time: 47375.92228
[32m[0907 03-48-03 @MBExp.py:144][0m ####################################################################
[32m[0907 03-48-03 @MBExp.py:145][0m Starting training iteration 58.
[32m[0907 03-48-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31710, current rewards: 1.11627, mean: 0.11163
[32m[0907 03-48-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31755, current rewards: 7.37452, mean: 0.12291
[32m[0907 03-48-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31704, current rewards: 13.05159, mean: 0.11865
[32m[0907 03-48-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31684, current rewards: 18.72866, mean: 0.11705
[32m[0907 03-49-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31679, current rewards: 24.40572, mean: 0.11622
[32m[0907 03-49-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31660, current rewards: 30.08279, mean: 0.11570
[32m[0907 03-49-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31655, current rewards: 34.99224, mean: 0.11288
[32m[0907 03-49-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31662, current rewards: 39.52783, mean: 0.10980
[32m[0907 03-50-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31665, current rewards: 44.06342, mean: 0.10747
[32m[0907 03-50-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31666, current rewards: 48.59901, mean: 0.10565
[32m[0907 03-50-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31665, current rewards: 41.13676, mean: 0.08066
[32m[0907 03-51-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31666, current rewards: -8.86324, mean: -0.01583
[32m[0907 03-51-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31663, current rewards: -58.86324, mean: -0.09650
[32m[0907 03-51-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31648, current rewards: -108.86324, mean: -0.16494
[32m[0907 03-51-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31638, current rewards: -158.86324, mean: -0.22375
[32m[0907 03-52-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31634, current rewards: -208.86324, mean: -0.27482
[32m[0907 03-52-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31631, current rewards: -258.86324, mean: -0.31958
[32m[0907 03-52-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31630, current rewards: -308.86324, mean: -0.35914
[32m[0907 03-52-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31619, current rewards: -358.86324, mean: -0.39436
[32m[0907 03-53-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31608, current rewards: -408.86324, mean: -0.42590
[32m[0907 03-53-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31606, current rewards: -458.86324, mean: -0.45432
[32m[0907 03-53-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31600, current rewards: -508.86324, mean: -0.48006
[32m[0907 03-53-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31598, current rewards: -558.86324, mean: -0.50348
[32m[0907 03-54-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31593, current rewards: -608.86324, mean: -0.52488
[32m[0907 03-54-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31590, current rewards: -658.86324, mean: -0.54452
[32m[0907 03-54-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31585, current rewards: -708.86324, mean: -0.56259
[32m[0907 03-54-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31583, current rewards: -758.86324, mean: -0.57928
[32m[0907 03-55-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31578, current rewards: -808.86324, mean: -0.59475
[32m[0907 03-55-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31573, current rewards: -858.86324, mean: -0.60912
[32m[0907 03-55-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31568, current rewards: -908.86324, mean: -0.62251
[32m[0907 03-56-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31563, current rewards: -958.86324, mean: -0.63501
[32m[0907 03-56-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31562, current rewards: -1008.86324, mean: -0.64671
[32m[0907 03-56-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31558, current rewards: -1058.86324, mean: -0.65768
[32m[0907 03-56-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31556, current rewards: -1108.86324, mean: -0.66799
[32m[0907 03-57-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31553, current rewards: -1158.86324, mean: -0.67770
[32m[0907 03-57-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31550, current rewards: -1208.86324, mean: -0.68685
[32m[0907 03-57-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31543, current rewards: -1258.86324, mean: -0.69550
[32m[0907 03-57-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31521, current rewards: -1308.86324, mean: -0.70369
[32m[0907 03-58-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31502, current rewards: -1358.86324, mean: -0.71145
[32m[0907 03-58-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31483, current rewards: -1408.86324, mean: -0.71881
[32m[0907 03-58-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31456, current rewards: -1458.86324, mean: -0.72580
[32m[0907 03-58-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31418, current rewards: -1508.86324, mean: -0.73246
[32m[0907 03-59-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31364, current rewards: -1558.86324, mean: -0.73880
[32m[0907 03-59-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31303, current rewards: -1608.86324, mean: -0.74484
[32m[0907 03-59-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31251, current rewards: -1658.86324, mean: -0.75062
[32m[0907 03-59-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31202, current rewards: -1708.86324, mean: -0.75613
[32m[0907 04-00-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31156, current rewards: -1758.86324, mean: -0.76141
[32m[0907 04-00-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31112, current rewards: -1808.86324, mean: -0.76647
[32m[0907 04-00-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31089, current rewards: -1858.86324, mean: -0.77131
[32m[0907 04-00-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31074, current rewards: -1908.86324, mean: -0.77596
[32m[0907 04-01-01 @Agent.py:117][0m Average action selection time: 0.3108
[32m[0907 04-01-01 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-01-01 @MBExp.py:227][0m Rewards obtained: [-1948.863235049494], Lows: [0], Highs: [2001], Total time: 48153.630561
[32m[0907 04-02-53 @MBExp.py:144][0m ####################################################################
[32m[0907 04-02-53 @MBExp.py:145][0m Starting training iteration 59.
[32m[0907 04-02-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31946, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-03-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31747, current rewards: -79.17412, mean: -1.31957
[32m[0907 04-03-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31694, current rewards: -72.55832, mean: -0.65962
[32m[0907 04-03-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31663, current rewards: -65.60359, mean: -0.41002
[32m[0907 04-04-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31643, current rewards: -58.66009, mean: -0.27933
[32m[0907 04-04-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31639, current rewards: -51.97268, mean: -0.19989
[32m[0907 04-04-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31648, current rewards: -45.04557, mean: -0.14531
[32m[0907 04-04-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31625, current rewards: -38.11945, mean: -0.10589
[32m[0907 04-05-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31632, current rewards: -31.19849, mean: -0.07609
[32m[0907 04-05-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31666, current rewards: -45.65148, mean: -0.09924
[32m[0907 04-05-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31655, current rewards: -58.95496, mean: -0.11560
[32m[0907 04-05-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31653, current rewards: -51.79255, mean: -0.09249
[32m[0907 04-06-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31647, current rewards: -44.66011, mean: -0.07321
[32m[0907 04-06-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31637, current rewards: -37.98782, mean: -0.05756
[32m[0907 04-06-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31626, current rewards: -30.88870, mean: -0.04351
[32m[0907 04-06-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31620, current rewards: -23.79899, mean: -0.03131
[32m[0907 04-07-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31613, current rewards: -29.26424, mean: -0.03613
[32m[0907 04-07-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31606, current rewards: -76.13005, mean: -0.08852
[32m[0907 04-07-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31604, current rewards: -68.37107, mean: -0.07513
[32m[0907 04-07-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31598, current rewards: -60.90104, mean: -0.06344
[32m[0907 04-08-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31592, current rewards: -53.43976, mean: -0.05291
[32m[0907 04-08-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31588, current rewards: -46.67950, mean: -0.04404
[32m[0907 04-08-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31588, current rewards: -39.33231, mean: -0.03543
[32m[0907 04-09-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31589, current rewards: -31.96328, mean: -0.02755
[32m[0907 04-09-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31588, current rewards: -24.59976, mean: -0.02033
[32m[0907 04-09-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31586, current rewards: -60.74604, mean: -0.04821
[32m[0907 04-09-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31580, current rewards: -54.11161, mean: -0.04131
[32m[0907 04-10-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31578, current rewards: -47.53302, mean: -0.03495
[32m[0907 04-10-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31577, current rewards: -40.95622, mean: -0.02905
[32m[0907 04-10-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31576, current rewards: -34.53733, mean: -0.02366
[32m[0907 04-10-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31575, current rewards: -27.98222, mean: -0.01853
[32m[0907 04-11-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31576, current rewards: -21.41729, mean: -0.01373
[32m[0907 04-11-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31575, current rewards: -14.85466, mean: -0.00923
[32m[0907 04-11-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31573, current rewards: -8.28719, mean: -0.00499
[32m[0907 04-11-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31573, current rewards: -1.72333, mean: -0.00101
[32m[0907 04-12-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31572, current rewards: 4.84283, mean: 0.00275
[32m[0907 04-12-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31564, current rewards: 11.40441, mean: 0.00630
[32m[0907 04-12-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31544, current rewards: 6.54615, mean: 0.00352
[32m[0907 04-12-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31523, current rewards: -38.04497, mean: -0.01992
[32m[0907 04-13-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31503, current rewards: -27.00528, mean: -0.01378
[32m[0907 04-13-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31475, current rewards: -17.64218, mean: -0.00878
[32m[0907 04-13-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31435, current rewards: -8.29695, mean: -0.00403
[32m[0907 04-13-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31378, current rewards: 1.08294, mean: 0.00051
[32m[0907 04-14-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31313, current rewards: 10.44525, mean: 0.00484
[32m[0907 04-14-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31261, current rewards: 19.83555, mean: 0.00898
[32m[0907 04-14-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31213, current rewards: -9.84480, mean: -0.00436
[32m[0907 04-14-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31166, current rewards: -41.20319, mean: -0.01784
[32m[0907 04-15-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31120, current rewards: -106.23565, mean: -0.04502
[32m[0907 04-15-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31094, current rewards: -99.16563, mean: -0.04115
[32m[0907 04-15-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31076, current rewards: -92.29383, mean: -0.03752
[32m[0907 04-15-51 @Agent.py:117][0m Average action selection time: 0.3108
[32m[0907 04-15-51 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-15-51 @MBExp.py:227][0m Rewards obtained: [-86.7973059559742], Lows: [191], Highs: [60], Total time: 48931.342040999996
[32m[0907 04-17-46 @MBExp.py:144][0m ####################################################################
[32m[0907 04-17-46 @MBExp.py:145][0m Starting training iteration 60.
[32m[0907 04-17-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31856, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-18-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31707, current rewards: -10.82455, mean: -0.18041
[32m[0907 04-18-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31699, current rewards: 5.70258, mean: 0.05184
[32m[0907 04-18-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31722, current rewards: 22.67006, mean: 0.14169
[32m[0907 04-18-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31709, current rewards: 39.64244, mean: 0.18877
[32m[0907 04-19-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31717, current rewards: 56.59313, mean: 0.21767
[32m[0907 04-19-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31717, current rewards: 73.54269, mean: 0.23723
[32m[0907 04-19-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31719, current rewards: 90.47449, mean: 0.25132
[32m[0907 04-19-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31704, current rewards: 107.40418, mean: 0.26196
[32m[0907 04-20-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31692, current rewards: 120.39547, mean: 0.26173
[32m[0907 04-20-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31680, current rewards: 127.43232, mean: 0.24987
[32m[0907 04-20-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31674, current rewards: 134.13907, mean: 0.23953
[32m[0907 04-20-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31668, current rewards: 138.58665, mean: 0.22719
[32m[0907 04-21-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31665, current rewards: 145.29434, mean: 0.22014
[32m[0907 04-21-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31654, current rewards: 152.04568, mean: 0.21415
[32m[0907 04-21-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31646, current rewards: 158.79146, mean: 0.20894
[32m[0907 04-22-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31645, current rewards: 165.53322, mean: 0.20436
[32m[0907 04-22-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31638, current rewards: 162.05935, mean: 0.18844
[32m[0907 04-22-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31630, current rewards: 118.58224, mean: 0.13031
[32m[0907 04-22-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31622, current rewards: 124.48340, mean: 0.12967
[32m[0907 04-23-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31615, current rewards: 122.90322, mean: 0.12169
[32m[0907 04-23-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31610, current rewards: 107.02991, mean: 0.10097
[32m[0907 04-23-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31607, current rewards: 112.49118, mean: 0.10134
[32m[0907 04-23-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31601, current rewards: 76.17774, mean: 0.06567
[32m[0907 04-24-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31596, current rewards: 61.68673, mean: 0.05098
[32m[0907 04-24-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31590, current rewards: 11.68673, mean: 0.00928
[32m[0907 04-24-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31594, current rewards: -0.65847, mean: -0.00050
[32m[0907 04-24-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31590, current rewards: 7.25139, mean: 0.00533
[32m[0907 04-25-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31587, current rewards: -27.56685, mean: -0.01955
[32m[0907 04-25-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31583, current rewards: -20.16629, mean: -0.01381
[32m[0907 04-25-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31581, current rewards: -13.55805, mean: -0.00898
[32m[0907 04-25-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31581, current rewards: -6.94982, mean: -0.00446
[32m[0907 04-26-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31578, current rewards: -0.34159, mean: -0.00021
[32m[0907 04-26-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31577, current rewards: -14.11232, mean: -0.00850
[32m[0907 04-26-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31574, current rewards: -64.11232, mean: -0.03749
[32m[0907 04-27-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31572, current rewards: -114.11232, mean: -0.06484
[32m[0907 04-27-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31565, current rewards: -164.11232, mean: -0.09067
[32m[0907 04-27-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31543, current rewards: -214.11232, mean: -0.11511
[32m[0907 04-27-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31521, current rewards: -264.11232, mean: -0.13828
[32m[0907 04-28-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31503, current rewards: -314.11232, mean: -0.16026
[32m[0907 04-28-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31476, current rewards: -364.11232, mean: -0.18115
[32m[0907 04-28-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31435, current rewards: -414.11232, mean: -0.20103
[32m[0907 04-28-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31379, current rewards: -464.11232, mean: -0.21996
[32m[0907 04-29-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31314, current rewards: -514.11232, mean: -0.23801
[32m[0907 04-29-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31259, current rewards: -564.11232, mean: -0.25525
[32m[0907 04-29-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31210, current rewards: -614.11232, mean: -0.27173
[32m[0907 04-29-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31164, current rewards: -664.11232, mean: -0.28749
[32m[0907 04-30-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31118, current rewards: -714.11232, mean: -0.30259
[32m[0907 04-30-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31086, current rewards: -764.11232, mean: -0.31706
[32m[0907 04-30-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31063, current rewards: -814.11232, mean: -0.33094
[32m[0907 04-30-43 @Agent.py:117][0m Average action selection time: 0.3106
[32m[0907 04-30-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-30-43 @MBExp.py:227][0m Rewards obtained: [-854.112317689134], Lows: [80], Highs: [982], Total time: 49708.646836
[32m[0907 04-32-39 @MBExp.py:144][0m ####################################################################
[32m[0907 04-32-39 @MBExp.py:145][0m Starting training iteration 61.
[32m[0907 04-32-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31778, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-32-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31791, current rewards: -53.62914, mean: -0.89382
[32m[0907 04-33-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31720, current rewards: -56.43201, mean: -0.51302
[32m[0907 04-33-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31728, current rewards: -54.08032, mean: -0.33800
[32m[0907 04-33-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31719, current rewards: -53.12526, mean: -0.25298
[32m[0907 04-34-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31719, current rewards: -74.18051, mean: -0.28531
[32m[0907 04-34-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31699, current rewards: -70.75356, mean: -0.22824
[32m[0907 04-34-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31679, current rewards: -63.91453, mean: -0.17754
[32m[0907 04-34-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31658, current rewards: -100.58092, mean: -0.24532
[32m[0907 04-35-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31651, current rewards: -92.98046, mean: -0.20213
[32m[0907 04-35-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31649, current rewards: -85.79533, mean: -0.16823
[32m[0907 04-35-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31645, current rewards: -78.68691, mean: -0.14051
[32m[0907 04-35-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31641, current rewards: -71.56983, mean: -0.11733
[32m[0907 04-36-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31630, current rewards: -64.45434, mean: -0.09766
[32m[0907 04-36-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31626, current rewards: -57.35274, mean: -0.08078
[32m[0907 04-36-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31617, current rewards: -50.21831, mean: -0.06608
[32m[0907 04-36-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31612, current rewards: -43.11721, mean: -0.05323
[32m[0907 04-37-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31599, current rewards: -35.99750, mean: -0.04186
[32m[0907 04-37-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31586, current rewards: -28.87444, mean: -0.03173
[32m[0907 04-37-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31574, current rewards: -63.88256, mean: -0.06654
[32m[0907 04-37-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31571, current rewards: -116.73544, mean: -0.11558
[32m[0907 04-38-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31564, current rewards: -216.73544, mean: -0.20447
[32m[0907 04-38-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31559, current rewards: -316.73544, mean: -0.28535
[32m[0907 04-38-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31554, current rewards: -382.29755, mean: -0.32957
[32m[0907 04-39-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31545, current rewards: -374.67373, mean: -0.30965
[32m[0907 04-39-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31546, current rewards: -368.61837, mean: -0.29255
[32m[0907 04-39-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31545, current rewards: -362.57236, mean: -0.27677
[32m[0907 04-39-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31542, current rewards: -356.53037, mean: -0.26215
[32m[0907 04-40-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31538, current rewards: -388.19747, mean: -0.27532
[32m[0907 04-40-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31538, current rewards: -383.51434, mean: -0.26268
[32m[0907 04-40-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31535, current rewards: -378.09046, mean: -0.25039
[32m[0907 04-40-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31534, current rewards: -372.70031, mean: -0.23891
[32m[0907 04-41-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31533, current rewards: -367.31499, mean: -0.22815
[32m[0907 04-41-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31532, current rewards: -361.92783, mean: -0.21803
[32m[0907 04-41-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31531, current rewards: -396.30875, mean: -0.23176
[32m[0907 04-41-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31528, current rewards: -390.38621, mean: -0.22181
[32m[0907 04-42-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31519, current rewards: -384.61888, mean: -0.21250
[32m[0907 04-42-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31500, current rewards: -379.53524, mean: -0.20405
[32m[0907 04-42-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31481, current rewards: -373.68680, mean: -0.19565
[32m[0907 04-42-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31463, current rewards: -367.80730, mean: -0.18766
[32m[0907 04-43-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31441, current rewards: -361.91886, mean: -0.18006
[32m[0907 04-43-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31404, current rewards: -356.02238, mean: -0.17283
[32m[0907 04-43-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31365, current rewards: -350.13311, mean: -0.16594
[32m[0907 04-43-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31311, current rewards: -344.23783, mean: -0.15937
[32m[0907 04-44-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31257, current rewards: -338.34960, mean: -0.15310
[32m[0907 04-44-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31208, current rewards: -351.13462, mean: -0.15537
[32m[0907 04-44-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31162, current rewards: -394.30965, mean: -0.17070
[32m[0907 04-44-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31118, current rewards: -384.97621, mean: -0.16313
[32m[0907 04-45-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31084, current rewards: -375.64277, mean: -0.15587
[32m[0907 04-45-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31061, current rewards: -398.34939, mean: -0.16193
[32m[0907 04-45-36 @Agent.py:117][0m Average action selection time: 0.3105
[32m[0907 04-45-36 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-45-36 @MBExp.py:227][0m Rewards obtained: [-438.3493896210373], Lows: [304], Highs: [128], Total time: 50485.454223
[32m[0907 04-47-34 @MBExp.py:144][0m ####################################################################
[32m[0907 04-47-34 @MBExp.py:145][0m Starting training iteration 62.
[32m[0907 04-47-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31864, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-47-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31765, current rewards: -17.13807, mean: -0.28563
[32m[0907 04-48-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31758, current rewards: -11.18881, mean: -0.10172
[32m[0907 04-48-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31738, current rewards: -6.18155, mean: -0.03863
[32m[0907 04-48-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31709, current rewards: -4.58452, mean: -0.02183
[32m[0907 04-48-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31687, current rewards: 1.84501, mean: 0.00710
[32m[0907 04-49-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31675, current rewards: 6.77905, mean: 0.02187
[32m[0907 04-49-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31659, current rewards: 11.70343, mean: 0.03251
[32m[0907 04-49-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31642, current rewards: 16.62616, mean: 0.04055
[32m[0907 04-49-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31649, current rewards: 13.15577, mean: 0.02860
[32m[0907 04-50-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31642, current rewards: -19.08629, mean: -0.03742
[32m[0907 04-50-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31623, current rewards: -41.72536, mean: -0.07451
[32m[0907 04-50-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31622, current rewards: -82.95123, mean: -0.13599
[32m[0907 04-51-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31620, current rewards: -152.83867, mean: -0.23157
[32m[0907 04-51-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31620, current rewards: -206.14507, mean: -0.29035
[32m[0907 04-51-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31616, current rewards: -248.54136, mean: -0.32703
[32m[0907 04-51-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31610, current rewards: -302.33831, mean: -0.37326
[32m[0907 04-52-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31601, current rewards: -317.33712, mean: -0.36900
[32m[0907 04-52-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31592, current rewards: -310.37310, mean: -0.34107
[32m[0907 04-52-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31589, current rewards: -304.95875, mean: -0.31767
[32m[0907 04-52-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31582, current rewards: -299.54668, mean: -0.29658
[32m[0907 04-53-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31578, current rewards: -294.95134, mean: -0.27826
[32m[0907 04-53-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31575, current rewards: -289.42487, mean: -0.26074
[32m[0907 04-53-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31574, current rewards: -283.88617, mean: -0.24473
[32m[0907 04-53-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31570, current rewards: -278.35342, mean: -0.23004
[32m[0907 04-54-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31567, current rewards: -272.81549, mean: -0.21652
[32m[0907 04-54-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31568, current rewards: -274.81360, mean: -0.20978
[32m[0907 04-54-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31566, current rewards: -269.35085, mean: -0.19805
[32m[0907 04-54-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31563, current rewards: -263.89622, mean: -0.18716
[32m[0907 04-55-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31563, current rewards: -255.23384, mean: -0.17482
[32m[0907 04-55-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31560, current rewards: -249.70212, mean: -0.16537
[32m[0907 04-55-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31557, current rewards: -244.19280, mean: -0.15653
[32m[0907 04-56-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31551, current rewards: -238.68724, mean: -0.14825
[32m[0907 04-56-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31548, current rewards: -273.27657, mean: -0.16462
[32m[0907 04-56-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31544, current rewards: -268.90549, mean: -0.15725
[32m[0907 04-56-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31543, current rewards: -259.87620, mean: -0.14766
[32m[0907 04-57-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31540, current rewards: -254.20461, mean: -0.14044
[32m[0907 04-57-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31518, current rewards: -249.47685, mean: -0.13413
[32m[0907 04-57-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31498, current rewards: -260.49730, mean: -0.13639
[32m[0907 04-57-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31482, current rewards: -254.78521, mean: -0.12999
[32m[0907 04-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31460, current rewards: -249.01482, mean: -0.12389
[32m[0907 04-58-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31420, current rewards: -243.26090, mean: -0.11809
[32m[0907 04-58-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31382, current rewards: -237.51751, mean: -0.11257
[32m[0907 04-58-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31327, current rewards: -231.76272, mean: -0.10730
[32m[0907 04-59-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31273, current rewards: -226.02204, mean: -0.10227
[32m[0907 04-59-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31224, current rewards: -283.77383, mean: -0.12556
[32m[0907 04-59-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31177, current rewards: -284.45019, mean: -0.12314
[32m[0907 04-59-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31132, current rewards: -278.32139, mean: -0.11793
[32m[0907 05-00-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31093, current rewards: -272.53894, mean: -0.11309
[32m[0907 05-00-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31070, current rewards: -266.41475, mean: -0.10830
[32m[0907 05-00-31 @Agent.py:117][0m Average action selection time: 0.3105
[32m[0907 05-00-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-00-31 @MBExp.py:227][0m Rewards obtained: [-261.7063438585626], Lows: [256], Highs: [57], Total time: 51262.39804
[32m[0907 05-02-30 @MBExp.py:144][0m ####################################################################
[32m[0907 05-02-30 @MBExp.py:145][0m Starting training iteration 63.
[32m[0907 05-02-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32000, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-02-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31720, current rewards: -44.55080, mean: -0.74251
[32m[0907 05-03-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31675, current rewards: -84.52617, mean: -0.76842
[32m[0907 05-03-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31655, current rewards: -103.38174, mean: -0.64614
[32m[0907 05-03-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31640, current rewards: -136.97231, mean: -0.65225
[32m[0907 05-03-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31652, current rewards: -153.53353, mean: -0.59051
[32m[0907 05-04-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31656, current rewards: -200.07217, mean: -0.64539
[32m[0907 05-04-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31646, current rewards: -242.00399, mean: -0.67223
[32m[0907 05-04-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31652, current rewards: -280.91837, mean: -0.68517
[32m[0907 05-04-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31641, current rewards: -312.55433, mean: -0.67947
[32m[0907 05-05-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31643, current rewards: -331.23470, mean: -0.64948
[32m[0907 05-05-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31644, current rewards: -349.19618, mean: -0.62356
[32m[0907 05-05-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31638, current rewards: -397.10088, mean: -0.65099
[32m[0907 05-05-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31638, current rewards: -451.99884, mean: -0.68485
[32m[0907 05-06-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31631, current rewards: -481.99703, mean: -0.67887
[32m[0907 05-06-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31623, current rewards: -521.49458, mean: -0.68618
[32m[0907 05-06-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31619, current rewards: -550.28938, mean: -0.67937
[32m[0907 05-07-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31614, current rewards: -590.07561, mean: -0.68613
[32m[0907 05-07-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31610, current rewards: -641.09052, mean: -0.70450
[32m[0907 05-07-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31605, current rewards: -676.27934, mean: -0.70446
[32m[0907 05-07-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31598, current rewards: -687.62328, mean: -0.68082
[32m[0907 05-08-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31604, current rewards: -705.99166, mean: -0.66603
[32m[0907 05-08-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31603, current rewards: -723.07949, mean: -0.65142
[32m[0907 05-08-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31601, current rewards: -747.03713, mean: -0.64400
[32m[0907 05-08-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31600, current rewards: -771.99254, mean: -0.63801
[32m[0907 05-09-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31598, current rewards: -788.75122, mean: -0.62599
[32m[0907 05-09-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31594, current rewards: -820.25133, mean: -0.62615
[32m[0907 05-09-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31594, current rewards: -879.07811, mean: -0.64638
[32m[0907 05-09-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31590, current rewards: -947.69913, mean: -0.67213
[32m[0907 05-10-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31588, current rewards: -987.71485, mean: -0.67652
[32m[0907 05-10-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31586, current rewards: -1027.32459, mean: -0.68035
[32m[0907 05-10-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31589, current rewards: -1079.02240, mean: -0.69168
[32m[0907 05-10-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31588, current rewards: -1121.39759, mean: -0.69652
[32m[0907 05-11-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31588, current rewards: -1145.34318, mean: -0.68997
[32m[0907 05-11-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31584, current rewards: -1179.92349, mean: -0.69001
[32m[0907 05-11-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31582, current rewards: -1237.35276, mean: -0.70304
[32m[0907 05-12-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31582, current rewards: -1298.87453, mean: -0.71761
[32m[0907 05-12-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31563, current rewards: -1345.97569, mean: -0.72364
[32m[0907 05-12-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31543, current rewards: -1352.22255, mean: -0.70797
[32m[0907 05-12-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31525, current rewards: -1378.00593, mean: -0.70306
[32m[0907 05-13-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31508, current rewards: -1408.17490, mean: -0.70058
[32m[0907 05-13-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31469, current rewards: -1453.88332, mean: -0.70577
[32m[0907 05-13-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31431, current rewards: -1483.60564, mean: -0.70313
[32m[0907 05-13-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31374, current rewards: -1522.70917, mean: -0.70496
[32m[0907 05-14-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31322, current rewards: -1549.93345, mean: -0.70133
[32m[0907 05-14-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31284, current rewards: -1585.92014, mean: -0.70173
[32m[0907 05-14-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31237, current rewards: -1600.18855, mean: -0.69272
[32m[0907 05-14-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31190, current rewards: -1610.93982, mean: -0.68260
[32m[0907 05-15-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31147, current rewards: -1638.65436, mean: -0.67994
[32m[0907 05-15-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31120, current rewards: -1684.09941, mean: -0.68459
[32m[0907 05-15-28 @Agent.py:117][0m Average action selection time: 0.3110
[32m[0907 05-15-28 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-15-28 @MBExp.py:227][0m Rewards obtained: [-1710.5130112339093], Lows: [947], Highs: [74], Total time: 52040.595436
[32m[0907 05-17-29 @MBExp.py:144][0m ####################################################################
[32m[0907 05-17-29 @MBExp.py:145][0m Starting training iteration 64.
[32m[0907 05-17-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31840, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-17-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31671, current rewards: -16.83482, mean: -0.28058
[32m[0907 05-18-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31686, current rewards: -9.98665, mean: -0.09079
[32m[0907 05-18-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31646, current rewards: -0.26697, mean: -0.00167
[32m[0907 05-18-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31645, current rewards: -33.01088, mean: -0.15719
[32m[0907 05-18-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31657, current rewards: -44.94710, mean: -0.17287
[32m[0907 05-19-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31659, current rewards: -44.58538, mean: -0.14382
[32m[0907 05-19-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31645, current rewards: -53.65684, mean: -0.14905
[32m[0907 05-19-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31651, current rewards: -49.57791, mean: -0.12092
[32m[0907 05-19-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31651, current rewards: -82.41091, mean: -0.17915
[32m[0907 05-20-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31654, current rewards: -75.10430, mean: -0.14726
[32m[0907 05-20-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31652, current rewards: -67.57321, mean: -0.12067
[32m[0907 05-20-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31643, current rewards: -84.64537, mean: -0.13876
[32m[0907 05-20-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31633, current rewards: -77.98026, mean: -0.11815
[32m[0907 05-21-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31629, current rewards: -70.22773, mean: -0.09891
[32m[0907 05-21-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31618, current rewards: -62.45387, mean: -0.08218
[32m[0907 05-21-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31610, current rewards: -109.86596, mean: -0.13564
[32m[0907 05-22-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31608, current rewards: -119.83734, mean: -0.13935
[32m[0907 05-22-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31605, current rewards: -129.58855, mean: -0.14241
[32m[0907 05-22-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31603, current rewards: -135.80923, mean: -0.14147
[32m[0907 05-22-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31596, current rewards: -172.34331, mean: -0.17064
[32m[0907 05-23-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31594, current rewards: -176.06378, mean: -0.16610
[32m[0907 05-23-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31594, current rewards: -183.02508, mean: -0.16489
[32m[0907 05-23-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31594, current rewards: -190.00621, mean: -0.16380
[32m[0907 05-23-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31600, current rewards: -196.95327, mean: -0.16277
[32m[0907 05-24-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31597, current rewards: -203.92292, mean: -0.16184
[32m[0907 05-24-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31595, current rewards: -208.83484, mean: -0.15942
[32m[0907 05-24-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31592, current rewards: -215.79303, mean: -0.15867
[32m[0907 05-24-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31589, current rewards: -221.40137, mean: -0.15702
[32m[0907 05-25-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31585, current rewards: -225.31533, mean: -0.15433
[32m[0907 05-25-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31580, current rewards: -231.54431, mean: -0.15334
[32m[0907 05-25-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31580, current rewards: -237.77384, mean: -0.15242
[32m[0907 05-25-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31575, current rewards: -243.96520, mean: -0.15153
[32m[0907 05-26-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31571, current rewards: -250.17233, mean: -0.15071
[32m[0907 05-26-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31572, current rewards: -254.30749, mean: -0.14872
[32m[0907 05-26-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31569, current rewards: -260.51744, mean: -0.14802
[32m[0907 05-27-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31566, current rewards: -266.73845, mean: -0.14737
[32m[0907 05-27-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31546, current rewards: -272.91548, mean: -0.14673
[32m[0907 05-27-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31528, current rewards: -268.47303, mean: -0.14056
[32m[0907 05-27-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31509, current rewards: -267.73343, mean: -0.13660
[32m[0907 05-28-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31491, current rewards: -264.49012, mean: -0.13159
[32m[0907 05-28-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31454, current rewards: -263.14638, mean: -0.12774
[32m[0907 05-28-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31417, current rewards: -260.05431, mean: -0.12325
[32m[0907 05-28-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31363, current rewards: -256.61411, mean: -0.11880
[32m[0907 05-29-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31312, current rewards: -253.95479, mean: -0.11491
[32m[0907 05-29-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31279, current rewards: -247.69994, mean: -0.10960
[32m[0907 05-29-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31234, current rewards: -240.93153, mean: -0.10430
[32m[0907 05-29-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31188, current rewards: -277.35786, mean: -0.11752
[32m[0907 05-30-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31143, current rewards: -271.36259, mean: -0.11260
[32m[0907 05-30-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31113, current rewards: -265.39096, mean: -0.10788
[32m[0907 05-30-26 @Agent.py:117][0m Average action selection time: 0.3109
[32m[0907 05-30-26 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-30-27 @MBExp.py:227][0m Rewards obtained: [-260.6119381249874], Lows: [243], Highs: [63], Total time: 52818.647776000005
[32m[0907 05-32-29 @MBExp.py:144][0m ####################################################################
[32m[0907 05-32-29 @MBExp.py:145][0m Starting training iteration 65.
[32m[0907 05-32-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31852, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-32-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31762, current rewards: -16.72979, mean: -0.27883
[32m[0907 05-33-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31708, current rewards: -8.64119, mean: -0.07856
[32m[0907 05-33-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31697, current rewards: -41.52615, mean: -0.25954
[32m[0907 05-33-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31697, current rewards: -33.92574, mean: -0.16155
[32m[0907 05-33-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31685, current rewards: -32.15288, mean: -0.12366
[32m[0907 05-34-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31750, current rewards: -50.90898, mean: -0.16422
[32m[0907 05-34-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31732, current rewards: -46.03181, mean: -0.12787
[32m[0907 05-34-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31722, current rewards: -41.52416, mean: -0.10128
[32m[0907 05-34-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31714, current rewards: -60.01070, mean: -0.13046
[32m[0907 05-35-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31700, current rewards: -76.55302, mean: -0.15010
[32m[0907 05-35-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31683, current rewards: -70.76731, mean: -0.12637
[32m[0907 05-35-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31673, current rewards: -65.59952, mean: -0.10754
[32m[0907 05-35-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31663, current rewards: -60.42936, mean: -0.09156
[32m[0907 05-36-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31658, current rewards: -80.50153, mean: -0.11338
[32m[0907 05-36-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31652, current rewards: -96.02914, mean: -0.12635
[32m[0907 05-36-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31645, current rewards: -102.88675, mean: -0.12702
[32m[0907 05-37-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31645, current rewards: -114.34084, mean: -0.13295
[32m[0907 05-37-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31638, current rewards: -121.51423, mean: -0.13353
[32m[0907 05-37-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31637, current rewards: -158.73670, mean: -0.16535
[32m[0907 05-37-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31628, current rewards: -150.25567, mean: -0.14877
[32m[0907 05-38-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31625, current rewards: -144.21040, mean: -0.13605
[32m[0907 05-38-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31620, current rewards: -138.16514, mean: -0.12447
[32m[0907 05-38-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31617, current rewards: -132.11987, mean: -0.11390
[32m[0907 05-38-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31614, current rewards: -126.07461, mean: -0.10419
[32m[0907 05-39-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31609, current rewards: -120.02934, mean: -0.09526
[32m[0907 05-39-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31603, current rewards: -113.98408, mean: -0.08701
[32m[0907 05-39-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31598, current rewards: -109.18341, mean: -0.08028
[32m[0907 05-39-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31598, current rewards: -105.60267, mean: -0.07490
[32m[0907 05-40-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31595, current rewards: -138.45683, mean: -0.09483
[32m[0907 05-40-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31590, current rewards: -188.45683, mean: -0.12481
[32m[0907 05-40-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31587, current rewards: -238.45683, mean: -0.15286
[32m[0907 05-40-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31588, current rewards: -288.45683, mean: -0.17917
[32m[0907 05-41-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31587, current rewards: -338.45683, mean: -0.20389
[32m[0907 05-41-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31587, current rewards: -388.45683, mean: -0.22717
[32m[0907 05-41-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31585, current rewards: -438.45683, mean: -0.24912
[32m[0907 05-42-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31584, current rewards: -488.45683, mean: -0.26987
[32m[0907 05-42-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31564, current rewards: -538.45683, mean: -0.28949
[32m[0907 05-42-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31545, current rewards: -588.45683, mean: -0.30809
[32m[0907 05-42-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31527, current rewards: -638.45683, mean: -0.32574
[32m[0907 05-43-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31508, current rewards: -688.45683, mean: -0.34252
[32m[0907 05-43-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31474, current rewards: -738.45683, mean: -0.35847
[32m[0907 05-43-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31435, current rewards: -788.45683, mean: -0.37368
[32m[0907 05-43-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31382, current rewards: -838.45683, mean: -0.38817
[32m[0907 05-44-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31330, current rewards: -888.45683, mean: -0.40202
[32m[0907 05-44-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31295, current rewards: -938.45683, mean: -0.41525
[32m[0907 05-44-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31257, current rewards: -988.45683, mean: -0.42790
[32m[0907 05-44-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31211, current rewards: -1038.45683, mean: -0.44002
[32m[0907 05-45-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31167, current rewards: -1088.45683, mean: -0.45164
[32m[0907 05-45-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31132, current rewards: -1138.45683, mean: -0.46279
[32m[0907 05-45-27 @Agent.py:117][0m Average action selection time: 0.3111
[32m[0907 05-45-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-45-27 @MBExp.py:227][0m Rewards obtained: [-1178.4568346666047], Lows: [121], Highs: [1116], Total time: 53597.17535500001
[32m[0907 05-47-31 @MBExp.py:144][0m ####################################################################
[32m[0907 05-47-31 @MBExp.py:145][0m Starting training iteration 66.
[32m[0907 05-47-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31685, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-47-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31698, current rewards: -38.81227, mean: -0.64687
[32m[0907 05-48-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31675, current rewards: -64.43607, mean: -0.58578
[32m[0907 05-48-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31666, current rewards: -106.64353, mean: -0.66652
[32m[0907 05-48-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31643, current rewards: -126.82916, mean: -0.60395
[32m[0907 05-48-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31659, current rewards: -118.34222, mean: -0.45516
[32m[0907 05-49-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31641, current rewards: -111.49954, mean: -0.35968
[32m[0907 05-49-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31644, current rewards: -104.74051, mean: -0.29095
[32m[0907 05-49-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31632, current rewards: -97.98581, mean: -0.23899
[32m[0907 05-49-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31622, current rewards: -91.22447, mean: -0.19831
[32m[0907 05-50-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31643, current rewards: -154.18046, mean: -0.30231
[32m[0907 05-50-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31631, current rewards: -204.80673, mean: -0.36573
[32m[0907 05-50-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31624, current rewards: -253.67684, mean: -0.41586
[32m[0907 05-50-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31610, current rewards: -243.35394, mean: -0.36872
[32m[0907 05-51-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31612, current rewards: -234.85486, mean: -0.33078
[32m[0907 05-51-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31600, current rewards: -226.44927, mean: -0.29796
[32m[0907 05-51-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31598, current rewards: -218.01261, mean: -0.26915
[32m[0907 05-52-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31593, current rewards: -209.58701, mean: -0.24371
[32m[0907 05-52-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31585, current rewards: -201.26831, mean: -0.22117
[32m[0907 05-52-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31583, current rewards: -194.16455, mean: -0.20225
[32m[0907 05-52-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31579, current rewards: -183.71522, mean: -0.18190
[32m[0907 05-53-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31575, current rewards: -172.84354, mean: -0.16306
[32m[0907 05-53-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31572, current rewards: -161.99484, mean: -0.14594
[32m[0907 05-53-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31573, current rewards: -151.12022, mean: -0.13028
[32m[0907 05-53-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31574, current rewards: -140.24744, mean: -0.11591
[32m[0907 05-54-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31572, current rewards: -129.37868, mean: -0.10268
[32m[0907 05-54-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31566, current rewards: -118.49981, mean: -0.09046
[32m[0907 05-54-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31566, current rewards: -107.11680, mean: -0.07876
[32m[0907 05-54-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31564, current rewards: -96.38907, mean: -0.06836
[32m[0907 05-55-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31562, current rewards: -85.55837, mean: -0.05860
[32m[0907 05-55-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31560, current rewards: -74.74889, mean: -0.04950
[32m[0907 05-55-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31556, current rewards: -63.92632, mean: -0.04098
[32m[0907 05-55-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31552, current rewards: -53.10287, mean: -0.03298
[32m[0907 05-56-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31548, current rewards: -42.28746, mean: -0.02547
[32m[0907 05-56-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31547, current rewards: -31.50234, mean: -0.01842
[32m[0907 05-56-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31546, current rewards: -40.66860, mean: -0.02311
[32m[0907 05-57-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31548, current rewards: -68.46771, mean: -0.03783
[32m[0907 05-57-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31543, current rewards: -105.86782, mean: -0.05692
[32m[0907 05-57-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31527, current rewards: -100.39403, mean: -0.05256
[32m[0907 05-57-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31510, current rewards: -94.74874, mean: -0.04834
[32m[0907 05-58-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31492, current rewards: -89.10533, mean: -0.04433
[32m[0907 05-58-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31468, current rewards: -83.45896, mean: -0.04051
[32m[0907 05-58-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31427, current rewards: -77.81776, mean: -0.03688
[32m[0907 05-58-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31371, current rewards: -82.40620, mean: -0.03815
[32m[0907 05-59-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31317, current rewards: -94.68635, mean: -0.04284
[32m[0907 05-59-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31267, current rewards: -143.56280, mean: -0.06352
[32m[0907 05-59-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31220, current rewards: -193.56280, mean: -0.08379
[32m[0907 05-59-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31175, current rewards: -243.56280, mean: -0.10320
[32m[0907 06-00-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31130, current rewards: -293.56280, mean: -0.12181
[32m[0907 06-00-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31089, current rewards: -343.56280, mean: -0.13966
[32m[0907 06-00-28 @Agent.py:117][0m Average action selection time: 0.3107
[32m[0907 06-00-28 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-00-28 @MBExp.py:227][0m Rewards obtained: [-383.56279640932104], Lows: [204], Highs: [343], Total time: 54374.58752100001
[32m[0907 06-02-34 @MBExp.py:144][0m ####################################################################
[32m[0907 06-02-34 @MBExp.py:145][0m Starting training iteration 67.
[32m[0907 06-02-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31877, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-02-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32605, current rewards: -76.86918, mean: -1.28115
[32m[0907 06-03-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32194, current rewards: -176.86918, mean: -1.60790
[32m[0907 06-03-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32042, current rewards: -276.86918, mean: -1.73043
[32m[0907 06-03-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31961, current rewards: -376.86918, mean: -1.79462
[32m[0907 06-03-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31907, current rewards: -476.86918, mean: -1.83411
[32m[0907 06-04-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31857, current rewards: -576.86918, mean: -1.86087
[32m[0907 06-04-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31820, current rewards: -676.86918, mean: -1.88019
[32m[0907 06-04-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31799, current rewards: -776.86918, mean: -1.89480
[32m[0907 06-05-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31782, current rewards: -876.86918, mean: -1.90624
[32m[0907 06-05-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31770, current rewards: -976.86918, mean: -1.91543
[32m[0907 06-05-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31748, current rewards: -1076.86918, mean: -1.92298
[32m[0907 06-05-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31733, current rewards: -1176.86918, mean: -1.92929
[32m[0907 06-06-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31723, current rewards: -1276.86918, mean: -1.93465
[32m[0907 06-06-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31717, current rewards: -1376.86918, mean: -1.93925
[32m[0907 06-06-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31711, current rewards: -1476.86918, mean: -1.94325
[32m[0907 06-06-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31704, current rewards: -1576.86918, mean: -1.94675
[32m[0907 06-07-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31692, current rewards: -1676.86918, mean: -1.94985
[32m[0907 06-07-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31682, current rewards: -1776.86918, mean: -1.95260
[32m[0907 06-07-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31668, current rewards: -1876.86918, mean: -1.95507
[32m[0907 06-07-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31665, current rewards: -1976.86918, mean: -1.95730
[32m[0907 06-08-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31651, current rewards: -2076.86918, mean: -1.95931
[32m[0907 06-08-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31645, current rewards: -2176.86918, mean: -1.96114
[32m[0907 06-08-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31637, current rewards: -2276.86918, mean: -1.96282
[32m[0907 06-08-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31635, current rewards: -2376.86918, mean: -1.96435
[32m[0907 06-09-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31632, current rewards: -2476.86918, mean: -1.96577
[32m[0907 06-09-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31628, current rewards: -2576.86918, mean: -1.96708
[32m[0907 06-09-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31627, current rewards: -2676.86918, mean: -1.96829
[32m[0907 06-10-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31620, current rewards: -2776.86918, mean: -1.96941
[32m[0907 06-10-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31616, current rewards: -2876.86918, mean: -1.97046
[32m[0907 06-10-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31615, current rewards: -2976.86918, mean: -1.97144
[32m[0907 06-10-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31612, current rewards: -3076.86918, mean: -1.97235
[32m[0907 06-11-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31612, current rewards: -3176.86918, mean: -1.97321
[32m[0907 06-11-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31610, current rewards: -3276.86918, mean: -1.97402
[32m[0907 06-11-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31605, current rewards: -3376.86918, mean: -1.97478
[32m[0907 06-11-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31603, current rewards: -3476.86918, mean: -1.97549
[32m[0907 06-12-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31600, current rewards: -3576.86918, mean: -1.97617
[32m[0907 06-12-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31596, current rewards: -3676.86918, mean: -1.97681
[32m[0907 06-12-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31584, current rewards: -3776.86918, mean: -1.97742
[32m[0907 06-12-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31562, current rewards: -3876.86918, mean: -1.97799
[32m[0907 06-13-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31543, current rewards: -3976.86918, mean: -1.97854
[32m[0907 06-13-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31526, current rewards: -4076.86918, mean: -1.97906
[32m[0907 06-13-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31507, current rewards: -4176.86918, mean: -1.97956
[32m[0907 06-13-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31459, current rewards: -4276.86918, mean: -1.98003
[32m[0907 06-14-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31404, current rewards: -4376.86918, mean: -1.98048
[32m[0907 06-14-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31352, current rewards: -4476.86918, mean: -1.98092
[32m[0907 06-14-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31300, current rewards: -4576.86918, mean: -1.98133
[32m[0907 06-14-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31259, current rewards: -4676.86918, mean: -1.98172
[32m[0907 06-15-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31213, current rewards: -4776.86918, mean: -1.98210
[32m[0907 06-15-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31170, current rewards: -4876.86918, mean: -1.98247
[32m[0907 06-15-33 @Agent.py:117][0m Average action selection time: 0.3114
[32m[0907 06-15-33 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-15-33 @MBExp.py:227][0m Rewards obtained: [-4956.869176135653], Lows: [2470], Highs: [20], Total time: 55153.67240200001
[32m[0907 06-17-40 @MBExp.py:144][0m ####################################################################
[32m[0907 06-17-40 @MBExp.py:145][0m Starting training iteration 68.
[32m[0907 06-17-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32868, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-17-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31829, current rewards: -85.13080, mean: -1.41885
[32m[0907 06-18-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31679, current rewards: -104.69623, mean: -0.95178
[32m[0907 06-18-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31671, current rewards: -99.31192, mean: -0.62070
[32m[0907 06-18-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31644, current rewards: -91.99161, mean: -0.43806
[32m[0907 06-19-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31605, current rewards: -84.62862, mean: -0.32549
[32m[0907 06-19-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31581, current rewards: -77.31269, mean: -0.24940
[32m[0907 06-19-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31562, current rewards: -69.97417, mean: -0.19437
[32m[0907 06-19-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31550, current rewards: -62.60301, mean: -0.15269
[32m[0907 06-20-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31548, current rewards: -55.30615, mean: -0.12023
[32m[0907 06-20-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31548, current rewards: -48.85544, mean: -0.09579
[32m[0907 06-20-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31541, current rewards: -68.23559, mean: -0.12185
[32m[0907 06-20-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31536, current rewards: -96.72769, mean: -0.15857
[32m[0907 06-21-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31528, current rewards: -127.44992, mean: -0.19311
[32m[0907 06-21-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31526, current rewards: -175.33471, mean: -0.24695
[32m[0907 06-21-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31525, current rewards: -210.19599, mean: -0.27657
[32m[0907 06-21-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31524, current rewards: -204.87309, mean: -0.25293
[32m[0907 06-22-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31523, current rewards: -198.16404, mean: -0.23042
[32m[0907 06-22-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31523, current rewards: -190.21475, mean: -0.20903
[32m[0907 06-22-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31516, current rewards: -184.07765, mean: -0.19175
[32m[0907 06-23-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31665, current rewards: -177.67512, mean: -0.17592
[32m[0907 06-23-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31835, current rewards: -171.19410, mean: -0.16150
[32m[0907 06-23-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31989, current rewards: -164.69971, mean: -0.14838
[32m[0907 06-23-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32194, current rewards: -201.82476, mean: -0.17399
[32m[0907 06-24-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32366, current rewards: -190.96765, mean: -0.15782
[32m[0907 06-24-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32482, current rewards: -179.99431, mean: -0.14285
[32m[0907 06-24-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32589, current rewards: -172.24989, mean: -0.13149
[32m[0907 06-25-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32675, current rewards: -167.53246, mean: -0.12319
[32m[0907 06-25-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32640, current rewards: -158.26903, mean: -0.11225
[32m[0907 06-25-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32597, current rewards: -148.28813, mean: -0.10157
[32m[0907 06-25-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32560, current rewards: -138.20368, mean: -0.09153
[32m[0907 06-26-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32526, current rewards: -128.11095, mean: -0.08212
[32m[0907 06-26-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32493, current rewards: -118.02570, mean: -0.07331
[32m[0907 06-26-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32465, current rewards: -107.94048, mean: -0.06502
[32m[0907 06-26-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32435, current rewards: -111.61540, mean: -0.06527
[32m[0907 06-27-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32409, current rewards: -131.38077, mean: -0.07465
[32m[0907 06-27-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32383, current rewards: -145.33390, mean: -0.08029
[32m[0907 06-27-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32361, current rewards: -143.84305, mean: -0.07733
[32m[0907 06-27-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32333, current rewards: -135.76241, mean: -0.07108
[32m[0907 06-28-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32293, current rewards: -127.52592, mean: -0.06506
[32m[0907 06-28-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32254, current rewards: -119.28723, mean: -0.05935
[32m[0907 06-28-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32218, current rewards: -114.12350, mean: -0.05540
[32m[0907 06-29-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32180, current rewards: -105.99760, mean: -0.05024
[32m[0907 06-29-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32129, current rewards: -97.91862, mean: -0.04533
[32m[0907 06-29-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32071, current rewards: -89.82275, mean: -0.04064
[32m[0907 06-29-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32004, current rewards: -81.76128, mean: -0.03618
[32m[0907 06-29-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31939, current rewards: -73.67885, mean: -0.03190
[32m[0907 06-30-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31880, current rewards: -65.59539, mean: -0.02779
[32m[0907 06-30-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31821, current rewards: -57.51249, mean: -0.02386
[32m[0907 06-30-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31763, current rewards: -49.42224, mean: -0.02009
[32m[0907 06-30-54 @Agent.py:117][0m Average action selection time: 0.3172
[32m[0907 06-30-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-30-54 @MBExp.py:227][0m Rewards obtained: [-42.96202560743465], Lows: [152], Highs: [107], Total time: 55947.35328700001
[32m[0907 06-33-03 @MBExp.py:144][0m ####################################################################
[32m[0907 06-33-03 @MBExp.py:145][0m Starting training iteration 69.
[32m[0907 06-33-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31679, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-33-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31696, current rewards: -59.98507, mean: -0.99975
[32m[0907 06-33-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31722, current rewards: -118.47922, mean: -1.07708
[32m[0907 06-33-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31835, current rewards: -173.15659, mean: -1.08223
[32m[0907 06-34-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31780, current rewards: -224.13328, mean: -1.06730
[32m[0907 06-34-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31773, current rewards: -285.69815, mean: -1.09884
[32m[0907 06-34-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31737, current rewards: -357.37788, mean: -1.15283
[32m[0907 06-34-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31720, current rewards: -419.58840, mean: -1.16552
[32m[0907 06-35-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31722, current rewards: -472.97368, mean: -1.15359
[32m[0907 06-35-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31719, current rewards: -513.12834, mean: -1.11550
[32m[0907 06-35-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31711, current rewards: -555.90977, mean: -1.09002
[32m[0907 06-36-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31700, current rewards: -582.75617, mean: -1.04064
[32m[0907 06-36-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31689, current rewards: -592.62531, mean: -0.97152
[32m[0907 06-36-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31683, current rewards: -595.38943, mean: -0.90211
[32m[0907 06-36-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31669, current rewards: -605.59823, mean: -0.85296
[32m[0907 06-37-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31654, current rewards: -618.08137, mean: -0.81326
[32m[0907 06-37-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31644, current rewards: -613.66032, mean: -0.75761
[32m[0907 06-37-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31639, current rewards: -606.28604, mean: -0.70498
[32m[0907 06-37-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31634, current rewards: -616.31563, mean: -0.67727
[32m[0907 06-38-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31627, current rewards: -618.21283, mean: -0.64397
[32m[0907 06-38-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31623, current rewards: -630.63933, mean: -0.62440
[32m[0907 06-38-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31614, current rewards: -649.76531, mean: -0.61299
[32m[0907 06-38-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31608, current rewards: -679.46812, mean: -0.61213
[32m[0907 06-39-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31607, current rewards: -728.17154, mean: -0.62773
[32m[0907 06-39-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31601, current rewards: -770.27430, mean: -0.63659
[32m[0907 06-39-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31593, current rewards: -806.04375, mean: -0.63972
[32m[0907 06-39-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31588, current rewards: -800.56269, mean: -0.61112
[32m[0907 06-40-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31581, current rewards: -795.42661, mean: -0.58487
[32m[0907 06-40-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31574, current rewards: -832.48258, mean: -0.59041
[32m[0907 06-40-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31587, current rewards: -856.86435, mean: -0.58689
[32m[0907 06-41-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31583, current rewards: -877.64473, mean: -0.58122
[32m[0907 06-41-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31579, current rewards: -911.08103, mean: -0.58403
[32m[0907 06-41-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31574, current rewards: -956.51901, mean: -0.59411
[32m[0907 06-41-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31574, current rewards: -992.16020, mean: -0.59769
[32m[0907 06-42-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31572, current rewards: -1046.11455, mean: -0.61176
[32m[0907 06-42-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31569, current rewards: -1086.90206, mean: -0.61756
[32m[0907 06-42-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31566, current rewards: -1090.11308, mean: -0.60227
[32m[0907 06-42-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31565, current rewards: -1090.55263, mean: -0.58632
[32m[0907 06-43-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31564, current rewards: -1083.61468, mean: -0.56734
[32m[0907 06-43-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31560, current rewards: -1076.69998, mean: -0.54934
[32m[0907 06-43-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31549, current rewards: -1069.77061, mean: -0.53222
[32m[0907 06-43-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31531, current rewards: -1062.84260, mean: -0.51594
[32m[0907 06-44-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31507, current rewards: -1056.00743, mean: -0.50048
[32m[0907 06-44-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31469, current rewards: -1049.19138, mean: -0.48574
[32m[0907 06-44-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31421, current rewards: -1042.24465, mean: -0.47160
[32m[0907 06-44-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31369, current rewards: -1035.30554, mean: -0.45810
[32m[0907 06-45-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31318, current rewards: -1087.45749, mean: -0.47076
[32m[0907 06-45-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31266, current rewards: -1079.15368, mean: -0.45727
[32m[0907 06-45-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31212, current rewards: -1073.02394, mean: -0.44524
[32m[0907 06-45-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31167, current rewards: -1066.90135, mean: -0.43370
[32m[0907 06-46-01 @Agent.py:117][0m Average action selection time: 0.3113
[32m[0907 06-46-01 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-46-02 @MBExp.py:227][0m Rewards obtained: [-1062.0086225275675], Lows: [639], Highs: [94], Total time: 56726.35953500001
[32m[0907 06-48-12 @MBExp.py:144][0m ####################################################################
[32m[0907 06-48-12 @MBExp.py:145][0m Starting training iteration 70.
[32m[0907 06-48-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31743, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-48-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31717, current rewards: -33.79813, mean: -0.56330
[32m[0907 06-48-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31705, current rewards: -28.59885, mean: -0.25999
[32m[0907 06-49-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31723, current rewards: -23.53620, mean: -0.14710
[32m[0907 06-49-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31707, current rewards: -18.47613, mean: -0.08798
[32m[0907 06-49-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31692, current rewards: -13.41522, mean: -0.05160
[32m[0907 06-49-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31684, current rewards: -8.35476, mean: -0.02695
[32m[0907 06-50-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31688, current rewards: -3.29696, mean: -0.00916
[32m[0907 06-50-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31676, current rewards: -4.84428, mean: -0.01182
[32m[0907 06-50-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31777, current rewards: -62.54065, mean: -0.13596
[32m[0907 06-50-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31846, current rewards: -136.22745, mean: -0.26711
[32m[0907 06-51-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31954, current rewards: -210.63126, mean: -0.37613
[32m[0907 06-51-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31998, current rewards: -292.93968, mean: -0.48023
[32m[0907 06-51-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32123, current rewards: -373.35572, mean: -0.56569
[32m[0907 06-52-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32086, current rewards: -398.81163, mean: -0.56171
[32m[0907 06-52-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32050, current rewards: -394.08930, mean: -0.51854
[32m[0907 06-52-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32019, current rewards: -389.50289, mean: -0.48087
[32m[0907 06-52-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31989, current rewards: -384.91923, mean: -0.44758
[32m[0907 06-53-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31971, current rewards: -380.33567, mean: -0.41795
[32m[0907 06-53-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31951, current rewards: -382.30005, mean: -0.39823
[32m[0907 06-53-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32057, current rewards: -436.30544, mean: -0.43199
[32m[0907 06-53-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32030, current rewards: -430.83736, mean: -0.40645
[32m[0907 06-54-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32006, current rewards: -425.80092, mean: -0.38360
[32m[0907 06-54-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31983, current rewards: -420.75678, mean: -0.36272
[32m[0907 06-54-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31964, current rewards: -415.71419, mean: -0.34357
[32m[0907 06-54-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31944, current rewards: -411.81821, mean: -0.32684
[32m[0907 06-55-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32047, current rewards: -466.42942, mean: -0.35605
[32m[0907 06-55-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32024, current rewards: -566.42942, mean: -0.41649
[32m[0907 06-55-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32004, current rewards: -666.42942, mean: -0.47264
[32m[0907 06-55-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31988, current rewards: -766.42942, mean: -0.52495
[32m[0907 06-56-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31970, current rewards: -866.42942, mean: -0.57379
[32m[0907 06-56-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31954, current rewards: -966.42942, mean: -0.61951
[32m[0907 06-56-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31941, current rewards: -1066.42942, mean: -0.66238
[32m[0907 06-57-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31926, current rewards: -1166.42942, mean: -0.70267
[32m[0907 06-57-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31912, current rewards: -1266.42942, mean: -0.74060
[32m[0907 06-57-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31900, current rewards: -1366.42942, mean: -0.77638
[32m[0907 06-57-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31887, current rewards: -1466.42942, mean: -0.81018
[32m[0907 06-58-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31876, current rewards: -1566.42942, mean: -0.84217
[32m[0907 06-58-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31865, current rewards: -1666.42942, mean: -0.87248
[32m[0907 06-58-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31854, current rewards: -1766.42942, mean: -0.90124
[32m[0907 06-58-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31845, current rewards: -1866.42942, mean: -0.92857
[32m[0907 06-59-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31831, current rewards: -1966.42942, mean: -0.95458
[32m[0907 06-59-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31793, current rewards: -2066.42942, mean: -0.97935
[32m[0907 06-59-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31747, current rewards: -2166.42942, mean: -1.00298
[32m[0907 06-59-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31703, current rewards: -2266.42942, mean: -1.02553
[32m[0907 07-00-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31662, current rewards: -2366.42942, mean: -1.04709
[32m[0907 07-00-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31613, current rewards: -2466.42942, mean: -1.06772
[32m[0907 07-00-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31552, current rewards: -2566.42942, mean: -1.08747
[32m[0907 07-00-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31490, current rewards: -2666.42942, mean: -1.10640
[32m[0907 07-01-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31433, current rewards: -2766.42942, mean: -1.12456
[32m[0907 07-01-17 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0907 07-01-17 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-01-18 @MBExp.py:227][0m Rewards obtained: [-2846.429420335446], Lows: [1448], Highs: [60], Total time: 57511.84097700001
[32m[0907 07-03-30 @MBExp.py:144][0m ####################################################################
[32m[0907 07-03-30 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 07-03-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31835, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-03-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33366, current rewards: -64.23047, mean: -1.07051
[32m[0907 07-04-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32596, current rewards: -84.94798, mean: -0.77225
[32m[0907 07-04-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32436, current rewards: -95.04465, mean: -0.59403
[32m[0907 07-04-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32262, current rewards: -112.12526, mean: -0.53393
[32m[0907 07-04-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32234, current rewards: -157.85519, mean: -0.60714
[32m[0907 07-05-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32138, current rewards: -193.15273, mean: -0.62307
[32m[0907 07-05-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32075, current rewards: -211.52893, mean: -0.58758
[32m[0907 07-05-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32024, current rewards: -227.61229, mean: -0.55515
[32m[0907 07-05-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31999, current rewards: -238.14712, mean: -0.51771
[32m[0907 07-06-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31970, current rewards: -251.96646, mean: -0.49405
[32m[0907 07-06-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31930, current rewards: -266.78244, mean: -0.47640
[32m[0907 07-06-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31907, current rewards: -277.29637, mean: -0.45458
[32m[0907 07-07-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31884, current rewards: -295.39310, mean: -0.44757
[32m[0907 07-07-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31862, current rewards: -305.91766, mean: -0.43087
[32m[0907 07-07-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31852, current rewards: -315.15976, mean: -0.41468
[32m[0907 07-07-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32050, current rewards: -339.73979, mean: -0.41943
[32m[0907 07-08-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32371, current rewards: -426.36801, mean: -0.49578
[32m[0907 07-08-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32537, current rewards: -526.36801, mean: -0.57843
[32m[0907 07-08-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32687, current rewards: -626.36801, mean: -0.65247
[32m[0907 07-09-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32823, current rewards: -726.36801, mean: -0.71918
[32m[0907 07-09-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32942, current rewards: -826.36801, mean: -0.77959
[32m[0907 07-09-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33046, current rewards: -926.36801, mean: -0.83457
[32m[0907 07-09-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33138, current rewards: -1026.36801, mean: -0.88480
[32m[0907 07-10-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33232, current rewards: -1126.36801, mean: -0.93088
[32m[0907 07-10-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33316, current rewards: -1226.36801, mean: -0.97331
[32m[0907 07-10-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33394, current rewards: -1326.36801, mean: -1.01249
[32m[0907 07-11-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33465, current rewards: -1426.36801, mean: -1.04880
[32m[0907 07-11-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33528, current rewards: -1526.36801, mean: -1.08253
[32m[0907 07-11-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33584, current rewards: -1626.36801, mean: -1.11395
[32m[0907 07-11-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33639, current rewards: -1726.36801, mean: -1.14329
[32m[0907 07-12-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33694, current rewards: -1826.36801, mean: -1.17075
[32m[0907 07-12-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33747, current rewards: -1926.36801, mean: -1.19650
[32m[0907 07-12-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33797, current rewards: -2026.36801, mean: -1.22070
[32m[0907 07-13-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33844, current rewards: -2126.36801, mean: -1.24349
[32m[0907 07-13-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33885, current rewards: -2226.36801, mean: -1.26498
[32m[0907 07-13-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33923, current rewards: -2326.36801, mean: -1.28529
[32m[0907 07-14-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33961, current rewards: -2426.36801, mean: -1.30450
[32m[0907 07-14-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33899, current rewards: -2526.36801, mean: -1.32271
[32m[0907 07-14-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33842, current rewards: -2626.36801, mean: -1.33998
[32m[0907 07-14-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33786, current rewards: -2726.36801, mean: -1.35640
[32m[0907 07-15-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33732, current rewards: -2826.36801, mean: -1.37202
[32m[0907 07-15-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33667, current rewards: -2926.36801, mean: -1.38690
[32m[0907 07-15-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33601, current rewards: -3026.36801, mean: -1.40110
[32m[0907 07-15-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33536, current rewards: -3126.36801, mean: -1.41465
[32m[0907 07-16-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33462, current rewards: -3226.36801, mean: -1.42760
[32m[0907 07-16-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33372, current rewards: -3326.36801, mean: -1.43999
[32m[0907 07-16-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33276, current rewards: -3426.36801, mean: -1.45185
[32m[0907 07-16-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33180, current rewards: -3526.36801, mean: -1.46322
[32m[0907 07-17-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33089, current rewards: -3626.36801, mean: -1.47413
[32m[0907 07-17-16 @Agent.py:117][0m Average action selection time: 0.3302
[32m[0907 07-17-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-17-16 @MBExp.py:227][0m Rewards obtained: [-3706.3680138725335], Lows: [1770], Highs: [226], Total time: 58338.00212800001
[32m[0907 07-19-29 @MBExp.py:144][0m ####################################################################
[32m[0907 07-19-29 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 07-19-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31826, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-19-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33894, current rewards: -84.95408, mean: -1.41590
[32m[0907 07-20-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32922, current rewards: -184.95408, mean: -1.68140
[32m[0907 07-20-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32558, current rewards: -284.95408, mean: -1.78096
[32m[0907 07-20-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32358, current rewards: -384.95408, mean: -1.83311
[32m[0907 07-20-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32239, current rewards: -484.95408, mean: -1.86521
[32m[0907 07-21-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32151, current rewards: -584.95408, mean: -1.88695
[32m[0907 07-21-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32083, current rewards: -684.95408, mean: -1.90265
[32m[0907 07-21-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32035, current rewards: -784.95408, mean: -1.91452
[32m[0907 07-21-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32005, current rewards: -884.95408, mean: -1.92381
[32m[0907 07-22-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31984, current rewards: -984.95408, mean: -1.93128
[32m[0907 07-22-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31967, current rewards: -1084.95408, mean: -1.93742
[32m[0907 07-22-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31951, current rewards: -1184.95408, mean: -1.94255
[32m[0907 07-23-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31934, current rewards: -1284.95408, mean: -1.94690
[32m[0907 07-23-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31920, current rewards: -1384.95408, mean: -1.95064
[32m[0907 07-23-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31905, current rewards: -1484.95408, mean: -1.95389
[32m[0907 07-23-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31887, current rewards: -1584.95408, mean: -1.95673
[32m[0907 07-24-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31880, current rewards: -1684.95408, mean: -1.95925
[32m[0907 07-24-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31866, current rewards: -1784.95408, mean: -1.96149
[32m[0907 07-24-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31852, current rewards: -1884.95408, mean: -1.96349
[32m[0907 07-24-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31838, current rewards: -1984.95408, mean: -1.96530
[32m[0907 07-25-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31825, current rewards: -2084.95408, mean: -1.96694
[32m[0907 07-25-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31814, current rewards: -2184.95408, mean: -1.96843
[32m[0907 07-25-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31808, current rewards: -2284.95408, mean: -1.96979
[32m[0907 07-25-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31804, current rewards: -2384.95408, mean: -1.97104
[32m[0907 07-26-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31796, current rewards: -2484.95408, mean: -1.97219
[32m[0907 07-26-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31789, current rewards: -2584.95408, mean: -1.97325
[32m[0907 07-26-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31780, current rewards: -2684.95408, mean: -1.97423
[32m[0907 07-26-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31772, current rewards: -2784.95408, mean: -1.97514
[32m[0907 07-27-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31765, current rewards: -2884.95408, mean: -1.97600
[32m[0907 07-27-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31759, current rewards: -2984.95408, mean: -1.97679
[32m[0907 07-27-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31754, current rewards: -3084.95408, mean: -1.97753
[32m[0907 07-28-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31749, current rewards: -3184.95408, mean: -1.97823
[32m[0907 07-28-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31742, current rewards: -3284.95408, mean: -1.97889
[32m[0907 07-28-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31735, current rewards: -3384.95408, mean: -1.97951
[32m[0907 07-28-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31731, current rewards: -3484.95408, mean: -1.98009
[32m[0907 07-29-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31729, current rewards: -3584.95408, mean: -1.98064
[32m[0907 07-29-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31721, current rewards: -3684.95408, mean: -1.98116
[32m[0907 07-29-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31717, current rewards: -3784.95408, mean: -1.98165
[32m[0907 07-29-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31712, current rewards: -3884.95408, mean: -1.98212
[32m[0907 07-30-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31708, current rewards: -3984.95408, mean: -1.98256
[32m[0907 07-30-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31704, current rewards: -4084.95408, mean: -1.98299
[32m[0907 07-30-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31682, current rewards: -4184.95408, mean: -1.98339
[32m[0907 07-30-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31661, current rewards: -4284.95408, mean: -1.98378
[32m[0907 07-31-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31642, current rewards: -4384.95408, mean: -1.98414
[32m[0907 07-31-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31623, current rewards: -4484.95408, mean: -1.98449
[32m[0907 07-31-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31589, current rewards: -4584.95408, mean: -1.98483
[32m[0907 07-31-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31535, current rewards: -4684.95408, mean: -1.98515
[32m[0907 07-32-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31482, current rewards: -4784.95408, mean: -1.98546
[32m[0907 07-32-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31429, current rewards: -4884.95408, mean: -1.98575
[32m[0907 07-32-35 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0907 07-32-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-32-35 @MBExp.py:227][0m Rewards obtained: [-4964.954082744498], Lows: [2473], Highs: [20], Total time: 59123.27526100001
[32m[0907 07-34-49 @MBExp.py:144][0m ####################################################################
[32m[0907 07-34-49 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 07-34-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32850, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-35-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32080, current rewards: -55.62085, mean: -0.92701
[32m[0907 07-35-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31902, current rewards: -64.36246, mean: -0.58511
[32m[0907 07-35-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32790, current rewards: -69.89359, mean: -0.43683
[32m[0907 07-36-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33417, current rewards: -78.75566, mean: -0.37503
[32m[0907 07-36-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33792, current rewards: -85.56085, mean: -0.32908
[32m[0907 07-36-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34062, current rewards: -91.14144, mean: -0.29400
[32m[0907 07-36-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34248, current rewards: -125.33952, mean: -0.34817
[32m[0907 07-37-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34060, current rewards: -160.78951, mean: -0.39217
[32m[0907 07-37-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33817, current rewards: -204.51596, mean: -0.44460
[32m[0907 07-37-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33598, current rewards: -226.41057, mean: -0.44394
[32m[0907 07-37-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33438, current rewards: -234.17421, mean: -0.41817
[32m[0907 07-38-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33286, current rewards: -241.81109, mean: -0.39641
[32m[0907 07-38-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33165, current rewards: -248.37184, mean: -0.37632
[32m[0907 07-38-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33058, current rewards: -255.99034, mean: -0.36055
[32m[0907 07-39-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32962, current rewards: -262.05110, mean: -0.34480
[32m[0907 07-39-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32876, current rewards: -268.68906, mean: -0.33171
[32m[0907 07-39-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32803, current rewards: -277.46547, mean: -0.32263
[32m[0907 07-39-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32736, current rewards: -284.14229, mean: -0.31224
[32m[0907 07-40-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32676, current rewards: -301.79495, mean: -0.31437
[32m[0907 07-40-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32622, current rewards: -297.48785, mean: -0.29454
[32m[0907 07-40-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32572, current rewards: -293.11470, mean: -0.27652
[32m[0907 07-40-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32524, current rewards: -288.74670, mean: -0.26013
[32m[0907 07-41-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32481, current rewards: -282.97950, mean: -0.24395
[32m[0907 07-41-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32439, current rewards: -278.41713, mean: -0.23010
[32m[0907 07-41-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32406, current rewards: -273.81465, mean: -0.21731
[32m[0907 07-41-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32372, current rewards: -269.21305, mean: -0.20551
[32m[0907 07-42-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32340, current rewards: -264.61386, mean: -0.19457
[32m[0907 07-42-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32310, current rewards: -260.01057, mean: -0.18440
[32m[0907 07-42-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32286, current rewards: -296.77582, mean: -0.20327
[32m[0907 07-42-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32261, current rewards: -290.67284, mean: -0.19250
[32m[0907 07-43-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32238, current rewards: -285.20344, mean: -0.18282
[32m[0907 07-43-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32214, current rewards: -279.84029, mean: -0.17381
[32m[0907 07-43-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32190, current rewards: -274.10992, mean: -0.16513
[32m[0907 07-44-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32170, current rewards: -283.98641, mean: -0.16607
[32m[0907 07-44-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32152, current rewards: -313.79485, mean: -0.17829
[32m[0907 07-44-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32132, current rewards: -333.10703, mean: -0.18404
[32m[0907 07-44-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32115, current rewards: -356.65951, mean: -0.19175
[32m[0907 07-45-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32099, current rewards: -379.12515, mean: -0.19849
[32m[0907 07-45-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32099, current rewards: -435.20129, mean: -0.22204
[32m[0907 07-45-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32082, current rewards: -469.32082, mean: -0.23349
[32m[0907 07-45-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32066, current rewards: -462.22427, mean: -0.22438
[32m[0907 07-46-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32036, current rewards: -455.12772, mean: -0.21570
[32m[0907 07-46-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32006, current rewards: -448.03117, mean: -0.20742
[32m[0907 07-46-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31976, current rewards: -440.93462, mean: -0.19952
[32m[0907 07-46-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31952, current rewards: -433.83807, mean: -0.19196
[32m[0907 07-47-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31927, current rewards: -481.55421, mean: -0.20847
[32m[0907 07-47-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31890, current rewards: -531.55421, mean: -0.22523
[32m[0907 07-47-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31831, current rewards: -581.55421, mean: -0.24131
[32m[0907 07-47-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31771, current rewards: -631.55421, mean: -0.25673
[32m[0907 07-48-03 @Agent.py:117][0m Average action selection time: 0.3172
[32m[0907 07-48-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-48-03 @MBExp.py:227][0m Rewards obtained: [-671.5542078551871], Lows: [91], Highs: [652], Total time: 59917.01752300001
[32m[0907 07-50-20 @MBExp.py:144][0m ####################################################################
[32m[0907 07-50-20 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 07-50-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33979, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-50-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33965, current rewards: -68.64645, mean: -1.14411
[32m[0907 07-50-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32841, current rewards: -63.93466, mean: -0.58122
[32m[0907 07-51-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32478, current rewards: -58.14892, mean: -0.36343
[32m[0907 07-51-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32295, current rewards: -52.36506, mean: -0.24936
[32m[0907 07-51-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32197, current rewards: -46.57929, mean: -0.17915
[32m[0907 07-51-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32099, current rewards: -38.37312, mean: -0.12378
[32m[0907 07-52-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32040, current rewards: -31.71701, mean: -0.08810
[32m[0907 07-52-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31992, current rewards: -25.92198, mean: -0.06322
[32m[0907 07-52-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31946, current rewards: -20.11636, mean: -0.04373
[32m[0907 07-53-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31918, current rewards: -14.31531, mean: -0.02807
[32m[0907 07-53-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31897, current rewards: -8.50577, mean: -0.01519
[32m[0907 07-53-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31869, current rewards: -2.70110, mean: -0.00443
[32m[0907 07-53-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31850, current rewards: -6.94451, mean: -0.01052
[32m[0907 07-54-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31904, current rewards: -13.37523, mean: -0.01884
[32m[0907 07-54-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31894, current rewards: -39.68815, mean: -0.05222
[32m[0907 07-54-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32068, current rewards: -98.12007, mean: -0.12114
[32m[0907 07-54-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32266, current rewards: -176.02642, mean: -0.20468
[32m[0907 07-55-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32345, current rewards: -244.12431, mean: -0.26827
[32m[0907 07-55-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32527, current rewards: -317.97006, mean: -0.33122
[32m[0907 07-55-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32562, current rewards: -363.26890, mean: -0.35967
[32m[0907 07-56-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32751, current rewards: -439.09941, mean: -0.41424
[32m[0907 07-56-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32904, current rewards: -504.26669, mean: -0.45429
[32m[0907 07-56-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32919, current rewards: -558.86875, mean: -0.48178
[32m[0907 07-56-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32882, current rewards: -588.86975, mean: -0.48667
[32m[0907 07-57-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32824, current rewards: -581.43668, mean: -0.46146
[32m[0907 07-57-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32907, current rewards: -575.79067, mean: -0.43953
[32m[0907 07-57-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32990, current rewards: -570.11560, mean: -0.41920
[32m[0907 07-58-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33072, current rewards: -564.43919, mean: -0.40031
[32m[0907 07-58-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33198, current rewards: -558.76745, mean: -0.38272
[32m[0907 07-58-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33292, current rewards: -553.09504, mean: -0.36629
[32m[0907 07-59-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33359, current rewards: -546.57907, mean: -0.35037
[32m[0907 07-59-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33421, current rewards: -540.92045, mean: -0.33598
[32m[0907 07-59-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33477, current rewards: -535.25227, mean: -0.32244
[32m[0907 07-59-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33474, current rewards: -529.58696, mean: -0.30970
[32m[0907 08-00-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33418, current rewards: -523.91766, mean: -0.29768
[32m[0907 08-00-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33368, current rewards: -518.25286, mean: -0.28633
[32m[0907 08-00-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33342, current rewards: -537.87639, mean: -0.28918
[32m[0907 08-00-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33362, current rewards: -591.07083, mean: -0.30946
[32m[0907 08-01-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33462, current rewards: -660.58522, mean: -0.33703
[32m[0907 08-01-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33448, current rewards: -717.91942, mean: -0.35717
[32m[0907 08-01-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33384, current rewards: -735.05959, mean: -0.35683
[32m[0907 08-02-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33376, current rewards: -775.69759, mean: -0.36763
[32m[0907 08-02-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33318, current rewards: -838.56439, mean: -0.38822
[32m[0907 08-02-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33263, current rewards: -831.40233, mean: -0.37620
[32m[0907 08-02-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33207, current rewards: -825.61287, mean: -0.36532
[32m[0907 08-03-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33143, current rewards: -819.82869, mean: -0.35490
[32m[0907 08-03-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33070, current rewards: -813.40594, mean: -0.34466
[32m[0907 08-03-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33016, current rewards: -846.35275, mean: -0.35118
[32m[0907 08-03-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33016, current rewards: -909.57996, mean: -0.36975
[32m[0907 08-04-05 @Agent.py:117][0m Average action selection time: 0.3297
[32m[0907 08-04-05 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-04-05 @MBExp.py:227][0m Rewards obtained: [-964.4687367653232], Lows: [447], Highs: [293], Total time: 60742.07035600001
[32m[0907 08-06-24 @MBExp.py:144][0m ####################################################################
[32m[0907 08-06-24 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 08-06-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31806, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-06-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31770, current rewards: -97.94280, mean: -1.63238
[32m[0907 08-06-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31732, current rewards: -197.94280, mean: -1.79948
[32m[0907 08-07-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31756, current rewards: -297.94280, mean: -1.86214
[32m[0907 08-07-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31735, current rewards: -397.94280, mean: -1.89497
[32m[0907 08-07-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31735, current rewards: -497.94280, mean: -1.91516
[32m[0907 08-08-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31729, current rewards: -597.94280, mean: -1.92885
[32m[0907 08-08-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31723, current rewards: -697.94280, mean: -1.93873
[32m[0907 08-08-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31715, current rewards: -797.94280, mean: -1.94620
[32m[0907 08-08-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31708, current rewards: -897.94280, mean: -1.95205
[32m[0907 08-09-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31702, current rewards: -997.94280, mean: -1.95675
[32m[0907 08-09-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31701, current rewards: -1097.94280, mean: -1.96061
[32m[0907 08-09-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31692, current rewards: -1197.94280, mean: -1.96384
[32m[0907 08-09-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31692, current rewards: -1297.94280, mean: -1.96658
[32m[0907 08-10-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31687, current rewards: -1397.94280, mean: -1.96893
[32m[0907 08-10-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31679, current rewards: -1497.94280, mean: -1.97098
[32m[0907 08-10-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31677, current rewards: -1597.94280, mean: -1.97277
[32m[0907 08-10-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31672, current rewards: -1697.94280, mean: -1.97435
[32m[0907 08-11-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31667, current rewards: -1797.94280, mean: -1.97576
[32m[0907 08-11-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31665, current rewards: -1897.94280, mean: -1.97702
[32m[0907 08-11-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31660, current rewards: -1997.94280, mean: -1.97816
[32m[0907 08-12-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31656, current rewards: -2097.94280, mean: -1.97919
[32m[0907 08-12-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31647, current rewards: -2197.94280, mean: -1.98013
[32m[0907 08-12-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31646, current rewards: -2297.94280, mean: -1.98099
[32m[0907 08-12-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31644, current rewards: -2397.94280, mean: -1.98177
[32m[0907 08-13-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31636, current rewards: -2497.94280, mean: -1.98249
[32m[0907 08-13-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31632, current rewards: -2597.94280, mean: -1.98316
[32m[0907 08-13-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31629, current rewards: -2697.94280, mean: -1.98378
[32m[0907 08-13-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31622, current rewards: -2797.94280, mean: -1.98436
[32m[0907 08-14-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31620, current rewards: -2897.94280, mean: -1.98489
[32m[0907 08-14-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31616, current rewards: -2997.94280, mean: -1.98539
[32m[0907 08-14-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31614, current rewards: -3097.94280, mean: -1.98586
[32m[0907 08-14-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31610, current rewards: -3197.94280, mean: -1.98630
[32m[0907 08-15-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31605, current rewards: -3297.94280, mean: -1.98671
[32m[0907 08-15-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31601, current rewards: -3397.94280, mean: -1.98710
[32m[0907 08-15-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31597, current rewards: -3497.94280, mean: -1.98747
[32m[0907 08-15-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31596, current rewards: -3597.94280, mean: -1.98781
[32m[0907 08-16-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31593, current rewards: -3697.94280, mean: -1.98814
[32m[0907 08-16-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31590, current rewards: -3797.94280, mean: -1.98845
[32m[0907 08-16-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31578, current rewards: -3897.94280, mean: -1.98875
[32m[0907 08-16-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31558, current rewards: -3997.94280, mean: -1.98903
[32m[0907 08-17-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31539, current rewards: -4097.94280, mean: -1.98929
[32m[0907 08-17-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31522, current rewards: -4197.94280, mean: -1.98955
[32m[0907 08-17-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31505, current rewards: -4297.94280, mean: -1.98979
[32m[0907 08-18-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31488, current rewards: -4397.94280, mean: -1.99002
[32m[0907 08-18-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31473, current rewards: -4497.94280, mean: -1.99024
[32m[0907 08-18-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31447, current rewards: -4597.94280, mean: -1.99045
[32m[0907 08-18-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31403, current rewards: -4697.94280, mean: -1.99065
[32m[0907 08-19-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31353, current rewards: -4797.94280, mean: -1.99085
[32m[0907 08-19-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31306, current rewards: -4897.94280, mean: -1.99103
[32m[0907 08-19-26 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 08-19-26 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-19-26 @MBExp.py:227][0m Rewards obtained: [-4977.942796010685], Lows: [2479], Highs: [20], Total time: 61524.51001200001
[32m[0907 08-21-47 @MBExp.py:144][0m ####################################################################
[32m[0907 08-21-47 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 08-21-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31820, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-22-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31715, current rewards: -74.37798, mean: -1.23963
[32m[0907 08-22-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31703, current rewards: -134.37058, mean: -1.22155
[32m[0907 08-22-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31725, current rewards: -188.20343, mean: -1.17627
[32m[0907 08-22-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31736, current rewards: -202.91060, mean: -0.96624
[32m[0907 08-23-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31727, current rewards: -265.67353, mean: -1.02182
[32m[0907 08-23-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31724, current rewards: -348.46981, mean: -1.12410
[32m[0907 08-23-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31840, current rewards: -415.27290, mean: -1.15354
[32m[0907 08-23-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31829, current rewards: -485.32737, mean: -1.18373
[32m[0907 08-24-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31881, current rewards: -546.29173, mean: -1.18759
[32m[0907 08-24-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31893, current rewards: -623.13972, mean: -1.22184
[32m[0907 08-24-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32021, current rewards: -679.44190, mean: -1.21329
[32m[0907 08-25-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32003, current rewards: -721.87013, mean: -1.18339
[32m[0907 08-25-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31974, current rewards: -770.82845, mean: -1.16792
[32m[0907 08-25-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31940, current rewards: -812.76125, mean: -1.14473
[32m[0907 08-25-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31921, current rewards: -862.87542, mean: -1.13536
[32m[0907 08-26-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31894, current rewards: -889.96352, mean: -1.09872
[32m[0907 08-26-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31872, current rewards: -924.79771, mean: -1.07535
[32m[0907 08-26-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31881, current rewards: -933.14294, mean: -1.02543
[32m[0907 08-26-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31862, current rewards: -931.43338, mean: -0.97024
[32m[0907 08-27-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31862, current rewards: -931.24701, mean: -0.92203
[32m[0907 08-27-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31867, current rewards: -934.19664, mean: -0.88132
[32m[0907 08-27-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31867, current rewards: -931.32469, mean: -0.83903
[32m[0907 08-27-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31876, current rewards: -937.43769, mean: -0.80814
[32m[0907 08-28-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31891, current rewards: -939.94188, mean: -0.77681
[32m[0907 08-28-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31941, current rewards: -945.53717, mean: -0.75043
[32m[0907 08-28-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32052, current rewards: -993.88192, mean: -0.75869
[32m[0907 08-29-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32034, current rewards: -1039.56885, mean: -0.76439
[32m[0907 08-29-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32027, current rewards: -1090.03921, mean: -0.77308
[32m[0907 08-29-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32017, current rewards: -1146.04357, mean: -0.78496
[32m[0907 08-29-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32001, current rewards: -1177.93668, mean: -0.78009
[32m[0907 08-30-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31983, current rewards: -1170.45954, mean: -0.75029
[32m[0907 08-30-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31967, current rewards: -1165.33228, mean: -0.72381
[32m[0907 08-30-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31954, current rewards: -1160.21072, mean: -0.69892
[32m[0907 08-30-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31941, current rewards: -1155.08819, mean: -0.67549
[32m[0907 08-31-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31928, current rewards: -1149.96724, mean: -0.65339
[32m[0907 08-31-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31917, current rewards: -1144.85180, mean: -0.63251
[32m[0907 08-31-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31905, current rewards: -1139.72866, mean: -0.61276
[32m[0907 08-31-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31889, current rewards: -1134.20579, mean: -0.59383
[32m[0907 08-32-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31862, current rewards: -1127.88559, mean: -0.57545
[32m[0907 08-32-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31836, current rewards: -1122.46421, mean: -0.55844
[32m[0907 08-32-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31812, current rewards: -1171.94560, mean: -0.56891
[32m[0907 08-32-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31804, current rewards: -1192.23768, mean: -0.56504
[32m[0907 08-33-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31809, current rewards: -1186.98505, mean: -0.54953
[32m[0907 08-33-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31789, current rewards: -1183.32201, mean: -0.53544
[32m[0907 08-33-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31803, current rewards: -1175.67041, mean: -0.52021
[32m[0907 08-34-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31788, current rewards: -1169.80401, mean: -0.50641
[32m[0907 08-34-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31759, current rewards: -1163.92393, mean: -0.49319
[32m[0907 08-34-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31733, current rewards: -1177.84333, mean: -0.48873
[32m[0907 08-34-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31684, current rewards: -1254.54023, mean: -0.50998
[32m[0907 08-34-59 @Agent.py:117][0m Average action selection time: 0.3165
[32m[0907 08-34-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-34-59 @MBExp.py:227][0m Rewards obtained: [-1292.6590937040696], Lows: [772], Highs: [62], Total time: 62316.47660200001
[32m[0907 08-37-21 @MBExp.py:144][0m ####################################################################
[32m[0907 08-37-21 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 08-37-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.43342, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-37-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36390, current rewards: -61.82790, mean: -1.03047
[32m[0907 08-37-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34244, current rewards: -59.30311, mean: -0.53912
[32m[0907 08-38-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33437, current rewards: -43.25979, mean: -0.27037
[32m[0907 08-38-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33012, current rewards: -22.16891, mean: -0.10557
[32m[0907 08-38-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32756, current rewards: 5.15845, mean: 0.01984
[32m[0907 08-39-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32571, current rewards: 30.52790, mean: 0.09848
[32m[0907 08-39-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32453, current rewards: 54.54287, mean: 0.15151
[32m[0907 08-39-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32354, current rewards: 78.25264, mean: 0.19086
[32m[0907 08-39-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32281, current rewards: 101.95197, mean: 0.22163
[32m[0907 08-40-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32212, current rewards: 125.44568, mean: 0.24597
[32m[0907 08-40-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32165, current rewards: 144.70194, mean: 0.25840
[32m[0907 08-40-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32524, current rewards: 79.11583, mean: 0.12970
[32m[0907 08-41-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33398, current rewards: 51.96441, mean: 0.07873
[32m[0907 08-41-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33584, current rewards: -10.34900, mean: -0.01458
[32m[0907 08-41-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33673, current rewards: -66.47953, mean: -0.08747
[32m[0907 08-41-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33626, current rewards: -136.69168, mean: -0.16876
[32m[0907 08-42-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33649, current rewards: -203.98517, mean: -0.23719
[32m[0907 08-42-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33558, current rewards: -275.64256, mean: -0.30290
[32m[0907 08-42-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33642, current rewards: -331.86588, mean: -0.34569
[32m[0907 08-43-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33690, current rewards: -350.07346, mean: -0.34661
[32m[0907 08-43-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33610, current rewards: -355.18770, mean: -0.33508
[32m[0907 08-43-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33573, current rewards: -445.74244, mean: -0.40157
[32m[0907 08-43-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33534, current rewards: -518.93390, mean: -0.44736
[32m[0907 08-44-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33572, current rewards: -567.60836, mean: -0.46910
[32m[0907 08-44-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33796, current rewards: -595.89969, mean: -0.47294
[32m[0907 08-44-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33711, current rewards: -617.59502, mean: -0.47145
[32m[0907 08-44-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33629, current rewards: -612.12919, mean: -0.45009
[32m[0907 08-45-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33554, current rewards: -606.63021, mean: -0.43023
[32m[0907 08-45-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33486, current rewards: -601.90404, mean: -0.41226
[32m[0907 08-45-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33422, current rewards: -596.55311, mean: -0.39507
[32m[0907 08-46-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33362, current rewards: -591.15749, mean: -0.37895
[32m[0907 08-46-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33305, current rewards: -585.75923, mean: -0.36383
[32m[0907 08-46-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33249, current rewards: -580.35871, mean: -0.34961
[32m[0907 08-46-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33197, current rewards: -574.96168, mean: -0.33623
[32m[0907 08-47-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33150, current rewards: -569.56761, mean: -0.32362
[32m[0907 08-47-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33096, current rewards: -564.16938, mean: -0.31170
[32m[0907 08-47-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33033, current rewards: -557.78035, mean: -0.29988
[32m[0907 08-47-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33037, current rewards: -569.85962, mean: -0.29836
[32m[0907 08-48-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33088, current rewards: -632.12775, mean: -0.32251
[32m[0907 08-48-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33083, current rewards: -679.15446, mean: -0.33789
[32m[0907 08-48-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33185, current rewards: -722.21014, mean: -0.35059
[32m[0907 08-49-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33213, current rewards: -759.00197, mean: -0.35972
[32m[0907 08-49-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33325, current rewards: -800.04604, mean: -0.37039
[32m[0907 08-49-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33391, current rewards: -834.67289, mean: -0.37768
[32m[0907 08-49-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33389, current rewards: -887.24655, mean: -0.39259
[32m[0907 08-50-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33484, current rewards: -909.62589, mean: -0.39378
[32m[0907 08-50-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33580, current rewards: -964.36839, mean: -0.40863
[32m[0907 08-50-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33539, current rewards: -1041.90707, mean: -0.43233
[32m[0907 08-51-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33591, current rewards: -1103.08777, mean: -0.44841
[32m[0907 08-51-22 @Agent.py:117][0m Average action selection time: 0.3361
[32m[0907 08-51-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-51-23 @MBExp.py:227][0m Rewards obtained: [-1144.9583795000112], Lows: [531], Highs: [426], Total time: 63157.50988700001
[32m[0907 08-53-47 @MBExp.py:144][0m ####################################################################
[32m[0907 08-53-47 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 08-53-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31879, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-54-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32545, current rewards: -60.72810, mean: -1.01214
[32m[0907 08-54-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32270, current rewards: -124.83717, mean: -1.13488
[32m[0907 08-54-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32484, current rewards: -135.09802, mean: -0.84436
[32m[0907 08-54-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32484, current rewards: -132.86986, mean: -0.63271
[32m[0907 08-55-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32322, current rewards: -127.78144, mean: -0.49147
[32m[0907 08-55-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32200, current rewards: -123.22930, mean: -0.39751
[32m[0907 08-55-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32126, current rewards: -118.67710, mean: -0.32966
[32m[0907 08-56-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32503, current rewards: -114.12819, mean: -0.27836
[32m[0907 08-56-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32811, current rewards: -109.57324, mean: -0.23820
[32m[0907 08-56-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33061, current rewards: -105.02210, mean: -0.20593
[32m[0907 08-56-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33279, current rewards: -97.37699, mean: -0.17389
[32m[0907 08-57-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33454, current rewards: -92.36467, mean: -0.15142
[32m[0907 08-57-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33614, current rewards: -87.97643, mean: -0.13330
[32m[0907 08-57-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33740, current rewards: -83.63893, mean: -0.11780
[32m[0907 08-58-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33843, current rewards: -79.30201, mean: -0.10434
[32m[0907 08-58-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33931, current rewards: -74.96089, mean: -0.09254
[32m[0907 08-58-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34009, current rewards: -89.40691, mean: -0.10396
[32m[0907 08-58-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34079, current rewards: -154.28225, mean: -0.16954
[32m[0907 08-59-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34151, current rewards: -198.82931, mean: -0.20711
[32m[0907 08-59-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34212, current rewards: -280.50953, mean: -0.27773
[32m[0907 08-59-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34261, current rewards: -343.01494, mean: -0.32360
[32m[0907 09-00-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34330, current rewards: -419.11344, mean: -0.37758
[32m[0907 09-00-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34371, current rewards: -484.35169, mean: -0.41754
[32m[0907 09-00-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34429, current rewards: -552.93998, mean: -0.45698
[32m[0907 09-01-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34457, current rewards: -606.78494, mean: -0.48158
[32m[0907 09-01-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34499, current rewards: -672.91233, mean: -0.51367
[32m[0907 09-01-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34528, current rewards: -753.85960, mean: -0.55431
[32m[0907 09-01-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34554, current rewards: -756.91723, mean: -0.53682
[32m[0907 09-02-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34574, current rewards: -816.10832, mean: -0.55898
[32m[0907 09-02-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34663, current rewards: -871.64063, mean: -0.57725
[32m[0907 09-02-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34714, current rewards: -909.03225, mean: -0.58271
[32m[0907 09-03-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34785, current rewards: -946.65777, mean: -0.58799
[32m[0907 09-03-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34819, current rewards: -979.85823, mean: -0.59028
[32m[0907 09-03-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34854, current rewards: -1030.61780, mean: -0.60270
[32m[0907 09-04-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34837, current rewards: -1026.34956, mean: -0.58315
[32m[0907 09-04-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34825, current rewards: -1020.10663, mean: -0.56359
[32m[0907 09-04-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34814, current rewards: -1015.67117, mean: -0.54606
[32m[0907 09-04-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34801, current rewards: -1009.53253, mean: -0.52855
[32m[0907 09-05-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34790, current rewards: -1003.22650, mean: -0.51185
[32m[0907 09-05-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34781, current rewards: -996.90437, mean: -0.49597
[32m[0907 09-05-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34770, current rewards: -990.58635, mean: -0.48087
[32m[0907 09-06-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34762, current rewards: -1006.85798, mean: -0.47718
[32m[0907 09-06-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34740, current rewards: -1001.60799, mean: -0.46371
[32m[0907 09-06-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34731, current rewards: -996.47637, mean: -0.45089
[32m[0907 09-06-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34716, current rewards: -991.50253, mean: -0.43872
[32m[0907 09-07-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34685, current rewards: -1002.04622, mean: -0.43379
[32m[0907 09-07-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34654, current rewards: -1016.66576, mean: -0.43079
[32m[0907 09-07-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34626, current rewards: -1018.53195, mean: -0.42263
[32m[0907 09-07-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34584, current rewards: -1039.20388, mean: -0.42244
[32m[0907 09-08-11 @Agent.py:117][0m Average action selection time: 0.3455
[32m[0907 09-08-11 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-08-11 @MBExp.py:227][0m Rewards obtained: [-1034.8112945273194], Lows: [633], Highs: [44], Total time: 64021.93725200001
[32m[0907 09-10-52 @MBExp.py:144][0m ####################################################################
[32m[0907 09-10-52 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 09-10-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35632, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-11-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35522, current rewards: -21.72332, mean: -0.36206
[32m[0907 09-11-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35557, current rewards: -18.71108, mean: -0.17010
[32m[0907 09-11-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35623, current rewards: -15.76441, mean: -0.09853
[32m[0907 09-12-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35646, current rewards: -12.82026, mean: -0.06105
[32m[0907 09-12-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35666, current rewards: -9.87399, mean: -0.03798
[32m[0907 09-12-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35677, current rewards: -6.92821, mean: -0.02235
[32m[0907 09-13-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35691, current rewards: -9.27784, mean: -0.02577
[32m[0907 09-13-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35709, current rewards: -22.44671, mean: -0.05475
[32m[0907 09-13-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35724, current rewards: -15.79908, mean: -0.03435
[32m[0907 09-13-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35740, current rewards: -8.76070, mean: -0.01718
[32m[0907 09-14-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35751, current rewards: -1.53504, mean: -0.00274
[32m[0907 09-14-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35758, current rewards: 5.63950, mean: 0.00925
[32m[0907 09-14-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35763, current rewards: 12.68932, mean: 0.01923
[32m[0907 09-15-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35762, current rewards: 19.73551, mean: 0.02780
[32m[0907 09-15-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35763, current rewards: 26.78582, mean: 0.03524
[32m[0907 09-15-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35757, current rewards: 6.00354, mean: 0.00741
[32m[0907 09-16-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35771, current rewards: -27.47145, mean: -0.03194
[32m[0907 09-16-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35767, current rewards: -46.24389, mean: -0.05082
[32m[0907 09-16-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35767, current rewards: -71.31864, mean: -0.07429
[32m[0907 09-16-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35770, current rewards: -106.24397, mean: -0.10519
[32m[0907 09-17-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35762, current rewards: -141.68221, mean: -0.13366
[32m[0907 09-17-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35763, current rewards: -185.13204, mean: -0.16679
[32m[0907 09-17-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35767, current rewards: -195.59553, mean: -0.16862
[32m[0907 09-18-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35764, current rewards: -190.27131, mean: -0.15725
[32m[0907 09-18-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35766, current rewards: -182.02025, mean: -0.14446
[32m[0907 09-18-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35770, current rewards: -176.07507, mean: -0.13441
[32m[0907 09-18-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35767, current rewards: -170.31763, mean: -0.12523
[32m[0907 09-19-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35763, current rewards: -165.88213, mean: -0.11765
[32m[0907 09-19-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35762, current rewards: -158.23270, mean: -0.10838
[32m[0907 09-19-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35761, current rewards: -150.88652, mean: -0.09992
[32m[0907 09-20-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35760, current rewards: -144.47964, mean: -0.09262
[32m[0907 09-20-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35759, current rewards: -137.24679, mean: -0.08525
[32m[0907 09-20-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35754, current rewards: -131.90852, mean: -0.07946
[32m[0907 09-21-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35729, current rewards: -125.79109, mean: -0.07356
[32m[0907 09-21-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35704, current rewards: -119.78375, mean: -0.06806
[32m[0907 09-21-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35682, current rewards: -110.49374, mean: -0.06105
[32m[0907 09-21-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35658, current rewards: -143.93438, mean: -0.07738
[32m[0907 09-22-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35636, current rewards: -141.98456, mean: -0.07434
[32m[0907 09-22-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35608, current rewards: -186.27519, mean: -0.09504
[32m[0907 09-22-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35597, current rewards: -246.90264, mean: -0.12284
[32m[0907 09-23-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35568, current rewards: -238.17903, mean: -0.11562
[32m[0907 09-23-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35540, current rewards: -232.55444, mean: -0.11022
[32m[0907 09-23-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35498, current rewards: -227.15135, mean: -0.10516
[32m[0907 09-23-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35474, current rewards: -221.85193, mean: -0.10039
[32m[0907 09-24-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35452, current rewards: -216.55921, mean: -0.09582
[32m[0907 09-24-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35431, current rewards: -211.19644, mean: -0.09143
[32m[0907 09-24-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35410, current rewards: -205.83214, mean: -0.08722
[32m[0907 09-25-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35375, current rewards: -200.46398, mean: -0.08318
[32m[0907 09-25-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35335, current rewards: -195.09950, mean: -0.07931
[32m[0907 09-25-35 @Agent.py:117][0m Average action selection time: 0.3529
[32m[0907 09-25-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-25-35 @MBExp.py:227][0m Rewards obtained: [-190.8040488970935], Lows: [214], Highs: [67], Total time: 64904.89320700001
[32m[0907 09-28-17 @MBExp.py:144][0m ####################################################################
[32m[0907 09-28-17 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 09-28-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35683, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-28-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35436, current rewards: -39.31823, mean: -0.65530
[32m[0907 09-28-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35491, current rewards: -33.71055, mean: -0.30646
[32m[0907 09-29-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35485, current rewards: -50.48388, mean: -0.31552
[32m[0907 09-29-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35493, current rewards: -64.03061, mean: -0.30491
[32m[0907 09-29-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35482, current rewards: -58.40821, mean: -0.22465
[32m[0907 09-30-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35454, current rewards: -52.72764, mean: -0.17009
[32m[0907 09-30-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35442, current rewards: -70.22308, mean: -0.19506
[32m[0907 09-30-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35429, current rewards: -63.59903, mean: -0.15512
[32m[0907 09-31-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35415, current rewards: -59.39457, mean: -0.12912
[32m[0907 09-31-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35416, current rewards: -55.19133, mean: -0.10822
[32m[0907 09-31-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35421, current rewards: -50.99347, mean: -0.09106
[32m[0907 09-31-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35412, current rewards: -47.35608, mean: -0.07763
[32m[0907 09-32-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35412, current rewards: -43.14640, mean: -0.06537
[32m[0907 09-32-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35416, current rewards: -61.86103, mean: -0.08713
[32m[0907 09-32-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35406, current rewards: -76.61573, mean: -0.10081
[32m[0907 09-33-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35400, current rewards: -69.75262, mean: -0.08611
[32m[0907 09-33-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35402, current rewards: -63.04906, mean: -0.07331
[32m[0907 09-33-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35400, current rewards: -56.34817, mean: -0.06192
[32m[0907 09-33-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35396, current rewards: -49.64907, mean: -0.05172
[32m[0907 09-34-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35396, current rewards: -36.83448, mean: -0.03647
[32m[0907 09-34-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35396, current rewards: -53.32007, mean: -0.05030
[32m[0907 09-34-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35393, current rewards: -48.30533, mean: -0.04352
[32m[0907 09-35-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35384, current rewards: -43.28152, mean: -0.03731
[32m[0907 09-35-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35383, current rewards: -60.45149, mean: -0.04996
[32m[0907 09-35-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35376, current rewards: -78.64936, mean: -0.06242
[32m[0907 09-36-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35371, current rewards: -94.91381, mean: -0.07245
[32m[0907 09-36-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35364, current rewards: -114.85811, mean: -0.08445
[32m[0907 09-36-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35368, current rewards: -145.67355, mean: -0.10331
[32m[0907 09-36-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35361, current rewards: -138.03451, mean: -0.09454
[32m[0907 09-37-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35366, current rewards: -166.21874, mean: -0.11008
[32m[0907 09-37-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35360, current rewards: -200.99993, mean: -0.12885
[32m[0907 09-37-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35358, current rewards: -200.56696, mean: -0.12458
[32m[0907 09-38-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35356, current rewards: -243.43714, mean: -0.14665
[32m[0907 09-38-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35327, current rewards: -234.10159, mean: -0.13690
[32m[0907 09-38-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35300, current rewards: -227.32893, mean: -0.12916
[32m[0907 09-38-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35282, current rewards: -220.54589, mean: -0.12185
[32m[0907 09-39-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35268, current rewards: -213.50726, mean: -0.11479
[32m[0907 09-39-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35254, current rewards: -206.67066, mean: -0.10820
[32m[0907 09-39-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35242, current rewards: -199.83180, mean: -0.10195
[32m[0907 09-40-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35231, current rewards: -192.98274, mean: -0.09601
[32m[0907 09-40-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35218, current rewards: -186.13687, mean: -0.09036
[32m[0907 09-40-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35202, current rewards: -179.29527, mean: -0.08497
[32m[0907 09-40-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35167, current rewards: -172.45233, mean: -0.07984
[32m[0907 09-41-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35159, current rewards: -165.60885, mean: -0.07494
[32m[0907 09-41-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35148, current rewards: -148.38306, mean: -0.06566
[32m[0907 09-41-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35139, current rewards: -140.80844, mean: -0.06096
[32m[0907 09-42-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35131, current rewards: -133.23400, mean: -0.05646
[32m[0907 09-42-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35116, current rewards: -125.65670, mean: -0.05214
[32m[0907 09-42-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35087, current rewards: -145.79765, mean: -0.05927
[32m[0907 09-42-54 @Agent.py:117][0m Average action selection time: 0.3506
[32m[0907 09-42-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-42-54 @MBExp.py:227][0m Rewards obtained: [-155.13197519901522], Lows: [175], Highs: [145], Total time: 65782.099184
[32m[0907 09-45-41 @MBExp.py:144][0m ####################################################################
[32m[0907 09-45-41 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 09-45-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35795, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-46-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36309, current rewards: -87.90365, mean: -1.46506
[32m[0907 09-46-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35986, current rewards: -132.43708, mean: -1.20397
[32m[0907 09-46-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35908, current rewards: -178.91866, mean: -1.11824
[32m[0907 09-46-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35873, current rewards: -220.95610, mean: -1.05217
[32m[0907 09-47-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35840, current rewards: -247.50785, mean: -0.95195
[32m[0907 09-47-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35811, current rewards: -279.08230, mean: -0.90027
[32m[0907 09-47-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35792, current rewards: -328.30909, mean: -0.91197
[32m[0907 09-48-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35900, current rewards: -400.94516, mean: -0.97792
[32m[0907 09-48-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35932, current rewards: -421.66422, mean: -0.91666
[32m[0907 09-48-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35931, current rewards: -437.13639, mean: -0.85713
[32m[0907 09-49-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35925, current rewards: -453.75778, mean: -0.81028
[32m[0907 09-49-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35908, current rewards: -484.47270, mean: -0.79422
[32m[0907 09-49-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35892, current rewards: -495.41456, mean: -0.75063
[32m[0907 09-49-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35877, current rewards: -517.72074, mean: -0.72918
[32m[0907 09-50-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35864, current rewards: -563.21991, mean: -0.74108
[32m[0907 09-50-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35880, current rewards: -559.41209, mean: -0.69063
[32m[0907 09-50-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35896, current rewards: -535.51903, mean: -0.62270
[32m[0907 09-51-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35911, current rewards: -523.25488, mean: -0.57501
[32m[0907 09-51-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35918, current rewards: -537.64684, mean: -0.56005
[32m[0907 09-51-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35903, current rewards: -551.49811, mean: -0.54604
[32m[0907 09-52-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35941, current rewards: -552.57217, mean: -0.52129
[32m[0907 09-52-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36081, current rewards: -579.79078, mean: -0.52233
[32m[0907 09-52-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36083, current rewards: -614.02114, mean: -0.52933
[32m[0907 09-52-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36079, current rewards: -654.15134, mean: -0.54062
[32m[0907 09-53-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36111, current rewards: -682.83708, mean: -0.54193
[32m[0907 09-53-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36106, current rewards: -708.24604, mean: -0.54065
[32m[0907 09-53-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36110, current rewards: -738.71615, mean: -0.54317
[32m[0907 09-54-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36092, current rewards: -775.40613, mean: -0.54993
[32m[0907 09-54-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36075, current rewards: -805.48061, mean: -0.55170
[32m[0907 09-54-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36070, current rewards: -845.23337, mean: -0.55976
[32m[0907 09-55-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36065, current rewards: -876.60753, mean: -0.56193
[32m[0907 09-55-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36062, current rewards: -908.61789, mean: -0.56436
[32m[0907 09-55-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36044, current rewards: -962.54764, mean: -0.57985
[32m[0907 09-55-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36023, current rewards: -983.31708, mean: -0.57504
[32m[0907 09-56-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35999, current rewards: -1014.78652, mean: -0.57658
[32m[0907 09-56-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35971, current rewards: -1048.47317, mean: -0.57927
[32m[0907 09-56-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35945, current rewards: -1087.04560, mean: -0.58443
[32m[0907 09-57-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35925, current rewards: -1124.00845, mean: -0.58849
[32m[0907 09-57-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35909, current rewards: -1157.44942, mean: -0.59054
[32m[0907 09-57-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35887, current rewards: -1181.42744, mean: -0.58777
[32m[0907 09-58-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35867, current rewards: -1199.58872, mean: -0.58232
[32m[0907 09-58-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35847, current rewards: -1220.54121, mean: -0.57846
[32m[0907 09-58-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35814, current rewards: -1226.67052, mean: -0.56790
[32m[0907 09-58-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35797, current rewards: -1234.08693, mean: -0.55841
[32m[0907 09-59-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35774, current rewards: -1246.52027, mean: -0.55156
[32m[0907 09-59-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35745, current rewards: -1254.85841, mean: -0.54323
[32m[0907 09-59-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35716, current rewards: -1277.34602, mean: -0.54125
[32m[0907 10-00-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35677, current rewards: -1310.76877, mean: -0.54389
[32m[0907 10-00-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35630, current rewards: -1365.55339, mean: -0.55510
[32m[0907 10-00-31 @Agent.py:117][0m Average action selection time: 0.3558
[32m[0907 10-00-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-00-32 @MBExp.py:227][0m Rewards obtained: [-1405.4902837520756], Lows: [491], Highs: [631], Total time: 66672.31301700001
[32m[0907 10-03-22 @MBExp.py:144][0m ####################################################################
[32m[0907 10-03-22 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 10-03-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35916, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-03-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35696, current rewards: -99.00000, mean: -1.65000
[32m[0907 10-04-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35637, current rewards: -199.00000, mean: -1.80909
[32m[0907 10-04-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35610, current rewards: -299.00000, mean: -1.86875
[32m[0907 10-04-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35613, current rewards: -399.00000, mean: -1.90000
[32m[0907 10-04-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35618, current rewards: -499.00000, mean: -1.91923
[32m[0907 10-05-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35639, current rewards: -599.00000, mean: -1.93226
[32m[0907 10-05-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35707, current rewards: -699.00000, mean: -1.94167
[32m[0907 10-05-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35758, current rewards: -799.00000, mean: -1.94878
[32m[0907 10-06-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35835, current rewards: -899.00000, mean: -1.95435
[32m[0907 10-06-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35867, current rewards: -999.00000, mean: -1.95882
[32m[0907 10-06-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35869, current rewards: -1099.00000, mean: -1.96250
[32m[0907 10-07-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35900, current rewards: -1199.00000, mean: -1.96557
[32m[0907 10-07-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35902, current rewards: -1299.00000, mean: -1.96818
[32m[0907 10-07-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35919, current rewards: -1399.00000, mean: -1.97042
[32m[0907 10-07-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35928, current rewards: -1499.00000, mean: -1.97237
[32m[0907 10-08-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35945, current rewards: -1599.00000, mean: -1.97407
[32m[0907 10-08-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35948, current rewards: -1699.00000, mean: -1.97558
[32m[0907 10-08-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35943, current rewards: -1799.00000, mean: -1.97692
[32m[0907 10-09-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35960, current rewards: -1899.00000, mean: -1.97812
[32m[0907 10-09-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35963, current rewards: -1999.00000, mean: -1.97921
[32m[0907 10-09-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35965, current rewards: -2099.00000, mean: -1.98019
[32m[0907 10-10-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35968, current rewards: -2199.00000, mean: -1.98108
[32m[0907 10-10-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35968, current rewards: -2299.00000, mean: -1.98190
[32m[0907 10-10-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35957, current rewards: -2399.00000, mean: -1.98264
[32m[0907 10-10-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35931, current rewards: -2499.00000, mean: -1.98333
[32m[0907 10-11-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35908, current rewards: -2599.00000, mean: -1.98397
[32m[0907 10-11-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35887, current rewards: -2699.00000, mean: -1.98456
[32m[0907 10-11-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35866, current rewards: -2799.00000, mean: -1.98511
[32m[0907 10-12-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35845, current rewards: -2899.00000, mean: -1.98562
[32m[0907 10-12-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35825, current rewards: -2999.00000, mean: -1.98609
[32m[0907 10-12-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35808, current rewards: -3099.00000, mean: -1.98654
[32m[0907 10-12-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35792, current rewards: -3199.00000, mean: -1.98696
[32m[0907 10-13-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35754, current rewards: -3299.00000, mean: -1.98735
[32m[0907 10-13-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35715, current rewards: -3399.00000, mean: -1.98772
[32m[0907 10-13-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35678, current rewards: -3499.00000, mean: -1.98807
[32m[0907 10-14-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35641, current rewards: -3599.00000, mean: -1.98840
[32m[0907 10-14-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35606, current rewards: -3699.00000, mean: -1.98871
[32m[0907 10-14-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35573, current rewards: -3799.00000, mean: -1.98901
[32m[0907 10-14-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35543, current rewards: -3899.00000, mean: -1.98929
[32m[0907 10-15-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35514, current rewards: -3999.00000, mean: -1.98955
[32m[0907 10-15-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35486, current rewards: -4099.00000, mean: -1.98981
[32m[0907 10-15-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35461, current rewards: -4199.00000, mean: -1.99005
[32m[0907 10-16-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35432, current rewards: -4299.00000, mean: -1.99028
[32m[0907 10-16-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35407, current rewards: -4399.00000, mean: -1.99050
[32m[0907 10-16-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35382, current rewards: -4499.00000, mean: -1.99071
[32m[0907 10-16-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35337, current rewards: -4599.00000, mean: -1.99091
[32m[0907 10-17-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35242, current rewards: -4699.00000, mean: -1.99110
[32m[0907 10-17-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35139, current rewards: -4799.00000, mean: -1.99129
[32m[0907 10-17-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35032, current rewards: -4899.00000, mean: -1.99146
[32m[0907 10-17-56 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0907 10-17-56 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-17-56 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 67546.673964
[32m[0907 10-20-29 @MBExp.py:144][0m ####################################################################
[32m[0907 10-20-29 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 10-20-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32779, current rewards: 0.63468, mean: 0.06347
[32m[0907 10-20-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31905, current rewards: 4.68631, mean: 0.07811
[32m[0907 10-21-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31817, current rewards: 10.63713, mean: 0.09670
[32m[0907 10-21-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31757, current rewards: 15.35162, mean: 0.09595
[32m[0907 10-21-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31721, current rewards: 21.42181, mean: 0.10201
[32m[0907 10-21-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31714, current rewards: 27.54735, mean: 0.10595
[32m[0907 10-22-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31689, current rewards: 33.67105, mean: 0.10862
[32m[0907 10-22-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31689, current rewards: 39.79410, mean: 0.11054
[32m[0907 10-22-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31680, current rewards: 45.91974, mean: 0.11200
[32m[0907 10-22-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31659, current rewards: 52.04496, mean: 0.11314
[32m[0907 10-23-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31649, current rewards: 58.16732, mean: 0.11405
[32m[0907 10-23-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31645, current rewards: 64.29161, mean: 0.11481
[32m[0907 10-23-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31637, current rewards: 70.42077, mean: 0.11544
[32m[0907 10-23-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31632, current rewards: 76.54674, mean: 0.11598
[32m[0907 10-24-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31651, current rewards: 58.85719, mean: 0.08290
[32m[0907 10-24-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31641, current rewards: 64.08551, mean: 0.08432
[32m[0907 10-24-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31634, current rewards: 70.24115, mean: 0.08672
[32m[0907 10-25-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31628, current rewards: 76.39680, mean: 0.08883
[32m[0907 10-25-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31619, current rewards: 82.54893, mean: 0.09071
[32m[0907 10-25-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31610, current rewards: 91.36920, mean: 0.09518
[32m[0907 10-25-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31606, current rewards: 97.67313, mean: 0.09671
[32m[0907 10-26-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31602, current rewards: 103.90242, mean: 0.09802
[32m[0907 10-26-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31597, current rewards: 88.22687, mean: 0.07948
[32m[0907 10-26-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31591, current rewards: 90.47333, mean: 0.07799
[32m[0907 10-26-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31583, current rewards: 94.92521, mean: 0.07845
[32m[0907 10-27-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31578, current rewards: 101.02462, mean: 0.08018
[32m[0907 10-27-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31574, current rewards: 107.12630, mean: 0.08178
[32m[0907 10-27-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31572, current rewards: 113.22044, mean: 0.08325
[32m[0907 10-27-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31571, current rewards: 119.32547, mean: 0.08463
[32m[0907 10-28-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31567, current rewards: 125.43173, mean: 0.08591
[32m[0907 10-28-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31565, current rewards: 131.53158, mean: 0.08711
[32m[0907 10-28-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31562, current rewards: 136.28044, mean: 0.08736
[32m[0907 10-28-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31553, current rewards: 144.03231, mean: 0.08946
[32m[0907 10-29-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31530, current rewards: 152.39545, mean: 0.09180
[32m[0907 10-29-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31508, current rewards: 160.78214, mean: 0.09402
[32m[0907 10-29-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31488, current rewards: 179.08047, mean: 0.10175
[32m[0907 10-29-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31466, current rewards: 162.40538, mean: 0.08973
[32m[0907 10-30-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31446, current rewards: 148.53074, mean: 0.07986
[32m[0907 10-30-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31428, current rewards: 154.58619, mean: 0.08094
[32m[0907 10-30-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31412, current rewards: 160.92035, mean: 0.08210
[32m[0907 10-31-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31394, current rewards: 167.28654, mean: 0.08323
[32m[0907 10-31-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31380, current rewards: 173.64996, mean: 0.08430
[32m[0907 10-31-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31364, current rewards: 97.39710, mean: 0.04616
[32m[0907 10-31-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31356, current rewards: 106.17629, mean: 0.04916
[32m[0907 10-32-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31343, current rewards: 111.62118, mean: 0.05051
[32m[0907 10-32-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31331, current rewards: 117.99954, mean: 0.05221
[32m[0907 10-32-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31318, current rewards: 99.71087, mean: 0.04316
[32m[0907 10-32-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31306, current rewards: 79.34716, mean: 0.03362
[32m[0907 10-33-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31293, current rewards: 87.24841, mean: 0.03620
[32m[0907 10-33-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31272, current rewards: 95.48498, mean: 0.03882
[32m[0907 10-33-30 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 10-33-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-33-30 @MBExp.py:227][0m Rewards obtained: [102.08272097320027], Lows: [76], Highs: [64], Total time: 68328.539448
[32m[0907 10-36-04 @MBExp.py:144][0m ####################################################################
[32m[0907 10-36-04 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 10-36-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31574, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-36-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31662, current rewards: -28.48256, mean: -0.47471
[32m[0907 10-36-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31690, current rewards: -21.95348, mean: -0.19958
[32m[0907 10-36-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31686, current rewards: -15.80032, mean: -0.09875
[32m[0907 10-37-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31704, current rewards: -9.84126, mean: -0.04686
[32m[0907 10-37-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31713, current rewards: -3.87665, mean: -0.01491
[32m[0907 10-37-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31725, current rewards: 2.08242, mean: 0.00672
[32m[0907 10-37-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31726, current rewards: -34.03911, mean: -0.09455
[32m[0907 10-38-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31714, current rewards: -50.40542, mean: -0.12294
[32m[0907 10-38-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31711, current rewards: -47.15606, mean: -0.10251
[32m[0907 10-38-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31714, current rewards: -58.79710, mean: -0.11529
[32m[0907 10-39-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31703, current rewards: -115.81285, mean: -0.20681
[32m[0907 10-39-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31691, current rewards: -118.40482, mean: -0.19411
[32m[0907 10-39-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31904, current rewards: -114.06429, mean: -0.17282
[32m[0907 10-39-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32139, current rewards: -109.52748, mean: -0.15426
[32m[0907 10-40-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32349, current rewards: -107.44952, mean: -0.14138
[32m[0907 10-40-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32549, current rewards: -103.35486, mean: -0.12760
[32m[0907 10-40-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32961, current rewards: -121.71513, mean: -0.14153
[32m[0907 10-41-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33339, current rewards: -129.51968, mean: -0.14233
[32m[0907 10-41-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33713, current rewards: -122.84701, mean: -0.12797
[32m[0907 10-41-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34045, current rewards: -117.50925, mean: -0.11635
[32m[0907 10-42-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34355, current rewards: -112.15214, mean: -0.10580
[32m[0907 10-42-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34635, current rewards: -106.79596, mean: -0.09621
[32m[0907 10-42-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34836, current rewards: -101.43734, mean: -0.08745
[32m[0907 10-43-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34895, current rewards: -96.08680, mean: -0.07941
[32m[0907 10-43-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34918, current rewards: -90.72957, mean: -0.07201
[32m[0907 10-43-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34933, current rewards: -133.83882, mean: -0.10217
[32m[0907 10-44-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34947, current rewards: -167.67853, mean: -0.12329
[32m[0907 10-44-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34958, current rewards: -157.74017, mean: -0.11187
[32m[0907 10-44-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34971, current rewards: -155.54366, mean: -0.10654
[32m[0907 10-44-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34978, current rewards: -147.69081, mean: -0.09781
[32m[0907 10-45-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34990, current rewards: -139.81942, mean: -0.08963
[32m[0907 10-45-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34996, current rewards: -132.18853, mean: -0.08210
[32m[0907 10-45-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35028, current rewards: -124.10519, mean: -0.07476
[32m[0907 10-46-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35169, current rewards: -139.53879, mean: -0.08160
[32m[0907 10-46-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35279, current rewards: -164.79988, mean: -0.09364
[32m[0907 10-46-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35384, current rewards: -183.66311, mean: -0.10147
[32m[0907 10-47-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35487, current rewards: -248.90264, mean: -0.13382
[32m[0907 10-47-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35587, current rewards: -322.12850, mean: -0.16865
[32m[0907 10-47-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35681, current rewards: -415.13584, mean: -0.21180
[32m[0907 10-48-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35772, current rewards: -490.95290, mean: -0.24426
[32m[0907 10-48-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35859, current rewards: -572.97280, mean: -0.27814
[32m[0907 10-48-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35895, current rewards: -655.60942, mean: -0.31072
[32m[0907 10-49-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35927, current rewards: -697.13554, mean: -0.32275
[32m[0907 10-49-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35981, current rewards: -758.77913, mean: -0.34334
[32m[0907 10-49-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36073, current rewards: -835.05243, mean: -0.36949
[32m[0907 10-50-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36157, current rewards: -923.90094, mean: -0.39996
[32m[0907 10-50-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36221, current rewards: -1005.37184, mean: -0.42601
[32m[0907 10-50-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36192, current rewards: -1095.92990, mean: -0.45474
[32m[0907 10-50-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36159, current rewards: -1139.34036, mean: -0.46315
[32m[0907 10-51-08 @Agent.py:117][0m Average action selection time: 0.3613
[32m[0907 10-51-08 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-51-08 @MBExp.py:227][0m Rewards obtained: [-1202.57536028992], Lows: [712], Highs: [77], Total time: 69232.71478699999
[32m[0907 10-53-56 @MBExp.py:144][0m ####################################################################
[32m[0907 10-53-56 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 10-54-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37020, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-54-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35720, current rewards: -24.80751, mean: -0.41346
[32m[0907 10-54-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34715, current rewards: -24.80841, mean: -0.22553
[32m[0907 10-54-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33990, current rewards: -23.41243, mean: -0.14633
[32m[0907 10-55-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33468, current rewards: -17.80010, mean: -0.08476
[32m[0907 10-55-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33123, current rewards: -11.95076, mean: -0.04596
[32m[0907 10-55-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32904, current rewards: -6.08953, mean: -0.01964
[32m[0907 10-55-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32731, current rewards: -0.23426, mean: -0.00065
[32m[0907 10-56-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32599, current rewards: 5.61880, mean: 0.01370
[32m[0907 10-56-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32501, current rewards: 11.47424, mean: 0.02494
[32m[0907 10-56-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32415, current rewards: 17.69408, mean: 0.03469
[32m[0907 10-56-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32419, current rewards: -2.44705, mean: -0.00437
[32m[0907 10-57-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32697, current rewards: -27.65624, mean: -0.04534
[32m[0907 10-57-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32801, current rewards: -65.39105, mean: -0.09908
[32m[0907 10-57-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33030, current rewards: -94.67894, mean: -0.13335
[32m[0907 10-58-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33275, current rewards: -128.09373, mean: -0.16854
[32m[0907 10-58-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33325, current rewards: -167.04977, mean: -0.20623
[32m[0907 10-58-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33502, current rewards: -216.27733, mean: -0.25149
[32m[0907 10-59-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33775, current rewards: -255.50622, mean: -0.28078
[32m[0907 10-59-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33741, current rewards: -284.57386, mean: -0.29643
[32m[0907 10-59-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33659, current rewards: -308.75496, mean: -0.30570
[32m[0907 10-59-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33633, current rewards: -332.12942, mean: -0.31333
[32m[0907 11-00-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33549, current rewards: -348.60947, mean: -0.31406
[32m[0907 11-00-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33591, current rewards: -356.61657, mean: -0.30743
[32m[0907 11-00-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33729, current rewards: -375.70316, mean: -0.31050
[32m[0907 11-01-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33904, current rewards: -395.10387, mean: -0.31357
[32m[0907 11-01-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34000, current rewards: -416.68102, mean: -0.31808
[32m[0907 11-01-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34150, current rewards: -446.67103, mean: -0.32843
[32m[0907 11-01-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34061, current rewards: -476.46207, mean: -0.33792
[32m[0907 11-02-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33979, current rewards: -471.41220, mean: -0.32289
[32m[0907 11-02-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33889, current rewards: -466.36232, mean: -0.30885
[32m[0907 11-02-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33787, current rewards: -464.61543, mean: -0.29783
[32m[0907 11-02-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33711, current rewards: -507.99021, mean: -0.31552
[32m[0907 11-03-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33672, current rewards: -520.42569, mean: -0.31351
[32m[0907 11-03-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33664, current rewards: -536.23649, mean: -0.31359
[32m[0907 11-03-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33616, current rewards: -557.53625, mean: -0.31678
[32m[0907 11-04-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33600, current rewards: -572.28945, mean: -0.31618
[32m[0907 11-04-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33584, current rewards: -598.22131, mean: -0.32162
[32m[0907 11-04-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33558, current rewards: -619.54628, mean: -0.32437
[32m[0907 11-04-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33513, current rewards: -633.93790, mean: -0.32344
[32m[0907 11-05-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33550, current rewards: -703.34113, mean: -0.34992
[32m[0907 11-05-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33690, current rewards: -724.47372, mean: -0.35169
[32m[0907 11-05-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33725, current rewards: -731.31434, mean: -0.34659
[32m[0907 11-06-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33676, current rewards: -729.22161, mean: -0.33760
[32m[0907 11-06-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33611, current rewards: -723.43623, mean: -0.32735
[32m[0907 11-06-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33546, current rewards: -717.56188, mean: -0.31751
[32m[0907 11-06-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33484, current rewards: -711.69548, mean: -0.30809
[32m[0907 11-07-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33442, current rewards: -732.22516, mean: -0.31026
[32m[0907 11-07-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33397, current rewards: -739.53012, mean: -0.30686
[32m[0907 11-07-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33447, current rewards: -791.93134, mean: -0.32192
[32m[0907 11-07-54 @Agent.py:117][0m Average action selection time: 0.3350
[32m[0907 11-07-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-07-55 @MBExp.py:227][0m Rewards obtained: [-815.2867243017298], Lows: [170], Highs: [657], Total time: 70071.05295299999
[32m[0907 11-10-34 @MBExp.py:144][0m ####################################################################
[32m[0907 11-10-34 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 11-10-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31816, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-10-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31662, current rewards: -100.00000, mean: -1.66667
[32m[0907 11-11-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31699, current rewards: -200.00000, mean: -1.81818
[32m[0907 11-11-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31666, current rewards: -300.00000, mean: -1.87500
[32m[0907 11-11-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31652, current rewards: -400.00000, mean: -1.90476
[32m[0907 11-11-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31655, current rewards: -500.00000, mean: -1.92308
[32m[0907 11-12-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31644, current rewards: -600.00000, mean: -1.93548
[32m[0907 11-12-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31649, current rewards: -700.00000, mean: -1.94444
[32m[0907 11-12-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31641, current rewards: -800.00000, mean: -1.95122
[32m[0907 11-12-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31626, current rewards: -900.00000, mean: -1.95652
[32m[0907 11-13-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31622, current rewards: -1000.00000, mean: -1.96078
[32m[0907 11-13-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31619, current rewards: -1100.00000, mean: -1.96429
[32m[0907 11-13-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31613, current rewards: -1200.00000, mean: -1.96721
[32m[0907 11-14-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31613, current rewards: -1300.00000, mean: -1.96970
[32m[0907 11-14-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31612, current rewards: -1400.00000, mean: -1.97183
[32m[0907 11-14-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31611, current rewards: -1500.00000, mean: -1.97368
[32m[0907 11-14-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31612, current rewards: -1600.00000, mean: -1.97531
[32m[0907 11-15-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31610, current rewards: -1700.00000, mean: -1.97674
[32m[0907 11-15-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31611, current rewards: -1800.00000, mean: -1.97802
[32m[0907 11-15-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31606, current rewards: -1900.00000, mean: -1.97917
[32m[0907 11-15-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31609, current rewards: -2000.00000, mean: -1.98020
[32m[0907 11-16-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31608, current rewards: -2100.00000, mean: -1.98113
[32m[0907 11-16-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31605, current rewards: -2200.00000, mean: -1.98198
[32m[0907 11-16-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31600, current rewards: -2300.00000, mean: -1.98276
[32m[0907 11-16-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31596, current rewards: -2400.00000, mean: -1.98347
[32m[0907 11-17-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31593, current rewards: -2500.00000, mean: -1.98413
[32m[0907 11-17-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31592, current rewards: -2600.00000, mean: -1.98473
[32m[0907 11-17-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31593, current rewards: -2700.00000, mean: -1.98529
[32m[0907 11-18-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31592, current rewards: -2800.00000, mean: -1.98582
[32m[0907 11-18-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31593, current rewards: -2900.00000, mean: -1.98630
[32m[0907 11-18-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31570, current rewards: -3000.00000, mean: -1.98675
[32m[0907 11-18-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31544, current rewards: -3100.00000, mean: -1.98718
[32m[0907 11-19-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31522, current rewards: -3200.00000, mean: -1.98758
[32m[0907 11-19-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31499, current rewards: -3300.00000, mean: -1.98795
[32m[0907 11-19-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31479, current rewards: -3400.00000, mean: -1.98830
[32m[0907 11-19-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31462, current rewards: -3500.00000, mean: -1.98864
[32m[0907 11-20-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31443, current rewards: -3600.00000, mean: -1.98895
[32m[0907 11-20-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31429, current rewards: -3700.00000, mean: -1.98925
[32m[0907 11-20-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31413, current rewards: -3800.00000, mean: -1.98953
[32m[0907 11-20-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31398, current rewards: -3900.00000, mean: -1.98980
[32m[0907 11-21-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31388, current rewards: -4000.00000, mean: -1.99005
[32m[0907 11-21-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31394, current rewards: -4100.00000, mean: -1.99029
[32m[0907 11-21-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31400, current rewards: -4200.00000, mean: -1.99052
[32m[0907 11-21-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31405, current rewards: -4300.00000, mean: -1.99074
[32m[0907 11-22-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31409, current rewards: -4400.00000, mean: -1.99095
[32m[0907 11-22-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31413, current rewards: -4500.00000, mean: -1.99115
[32m[0907 11-22-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31408, current rewards: -4600.00000, mean: -1.99134
[32m[0907 11-22-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31397, current rewards: -4700.00000, mean: -1.99153
[32m[0907 11-23-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31386, current rewards: -4800.00000, mean: -1.99170
[32m[0907 11-23-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31367, current rewards: -4900.00000, mean: -1.99187
[32m[0907 11-23-38 @Agent.py:117][0m Average action selection time: 0.3134
[32m[0907 11-23-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-23-38 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 70855.36525799999
[32m[0907 11-26-17 @MBExp.py:144][0m ####################################################################
[32m[0907 11-26-17 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 11-26-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32973, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-26-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31483, current rewards: -67.87077, mean: -1.13118
[32m[0907 11-26-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31620, current rewards: -83.61007, mean: -0.76009
[32m[0907 11-27-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31615, current rewards: -82.23297, mean: -0.51396
[32m[0907 11-27-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31638, current rewards: -78.24938, mean: -0.37262
[32m[0907 11-27-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31652, current rewards: -74.14630, mean: -0.28518
[32m[0907 11-27-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31663, current rewards: -70.04147, mean: -0.22594
[32m[0907 11-28-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31661, current rewards: -65.85104, mean: -0.18292
[32m[0907 11-28-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31706, current rewards: -103.33955, mean: -0.25205
[32m[0907 11-28-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31697, current rewards: -117.17774, mean: -0.25473
[32m[0907 11-28-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31686, current rewards: -112.64215, mean: -0.22087
[32m[0907 11-29-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31680, current rewards: -108.10656, mean: -0.19305
[32m[0907 11-29-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31674, current rewards: -103.57097, mean: -0.16979
[32m[0907 11-29-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31672, current rewards: -99.03538, mean: -0.15005
[32m[0907 11-30-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31667, current rewards: -133.76542, mean: -0.18840
[32m[0907 11-30-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31659, current rewards: -183.76542, mean: -0.24180
[32m[0907 11-30-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31655, current rewards: -233.76542, mean: -0.28860
[32m[0907 11-30-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31652, current rewards: -283.76542, mean: -0.32996
[32m[0907 11-31-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31649, current rewards: -333.76542, mean: -0.36678
[32m[0907 11-31-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31646, current rewards: -383.76542, mean: -0.39976
[32m[0907 11-31-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31643, current rewards: -433.76542, mean: -0.42947
[32m[0907 11-31-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31640, current rewards: -483.76542, mean: -0.45638
[32m[0907 11-32-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31637, current rewards: -533.76542, mean: -0.48087
[32m[0907 11-32-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31629, current rewards: -583.76542, mean: -0.50325
[32m[0907 11-32-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31621, current rewards: -633.76542, mean: -0.52377
[32m[0907 11-32-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31615, current rewards: -683.76542, mean: -0.54267
[32m[0907 11-33-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31613, current rewards: -733.76542, mean: -0.56013
[32m[0907 11-33-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31614, current rewards: -783.76542, mean: -0.57630
[32m[0907 11-33-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31612, current rewards: -833.76542, mean: -0.59132
[32m[0907 11-33-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31607, current rewards: -883.76542, mean: -0.60532
[32m[0907 11-34-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31581, current rewards: -933.76542, mean: -0.61839
[32m[0907 11-34-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31555, current rewards: -983.76542, mean: -0.63062
[32m[0907 11-34-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31529, current rewards: -1033.76542, mean: -0.64209
[32m[0907 11-35-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31505, current rewards: -1083.76542, mean: -0.65287
[32m[0907 11-35-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31484, current rewards: -1133.76542, mean: -0.66302
[32m[0907 11-35-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31465, current rewards: -1183.76542, mean: -0.67259
[32m[0907 11-35-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31446, current rewards: -1233.76542, mean: -0.68164
[32m[0907 11-36-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31427, current rewards: -1283.76542, mean: -0.69020
[32m[0907 11-36-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31410, current rewards: -1333.76542, mean: -0.69831
[32m[0907 11-36-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31394, current rewards: -1383.76542, mean: -0.70600
[32m[0907 11-36-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31388, current rewards: -1433.76542, mean: -0.71332
[32m[0907 11-37-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31391, current rewards: -1483.76542, mean: -0.72027
[32m[0907 11-37-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31392, current rewards: -1533.76542, mean: -0.72690
[32m[0907 11-37-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: -1583.76542, mean: -0.73322
[32m[0907 11-37-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31399, current rewards: -1633.76542, mean: -0.73926
[32m[0907 11-38-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31404, current rewards: -1683.76542, mean: -0.74503
[32m[0907 11-38-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31405, current rewards: -1733.76542, mean: -0.75055
[32m[0907 11-38-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31399, current rewards: -1783.76542, mean: -0.75583
[32m[0907 11-38-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31386, current rewards: -1833.76542, mean: -0.76090
[32m[0907 11-39-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31369, current rewards: -1883.76542, mean: -0.76576
[32m[0907 11-39-22 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0907 11-39-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-39-22 @MBExp.py:227][0m Rewards obtained: [-1923.7654162117024], Lows: [49], Highs: [1875], Total time: 71639.74044699999
[32m[0907 11-42-03 @MBExp.py:144][0m ####################################################################
[32m[0907 11-42-03 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 11-42-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30819, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-42-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31048, current rewards: -17.27953, mean: -0.28799
[32m[0907 11-42-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31344, current rewards: -12.36383, mean: -0.11240
[32m[0907 11-42-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31428, current rewards: -7.23627, mean: -0.04523
[32m[0907 11-43-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31466, current rewards: -2.10178, mean: -0.01001
[32m[0907 11-43-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31860, current rewards: 3.03215, mean: 0.01166
[32m[0907 11-43-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32418, current rewards: 7.59449, mean: 0.02450
[32m[0907 11-44-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32828, current rewards: -31.38557, mean: -0.08718
[32m[0907 11-44-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33134, current rewards: -24.11053, mean: -0.05881
[32m[0907 11-44-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33359, current rewards: -20.63119, mean: -0.04485
[32m[0907 11-44-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33564, current rewards: -17.15186, mean: -0.03363
[32m[0907 11-45-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33734, current rewards: -13.67253, mean: -0.02442
[32m[0907 11-45-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33919, current rewards: -10.19319, mean: -0.01671
[32m[0907 11-45-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34097, current rewards: -40.94063, mean: -0.06203
[32m[0907 11-46-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34247, current rewards: -90.94063, mean: -0.12809
[32m[0907 11-46-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34376, current rewards: -140.94063, mean: -0.18545
[32m[0907 11-46-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34500, current rewards: -190.94063, mean: -0.23573
[32m[0907 11-47-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34598, current rewards: -240.94063, mean: -0.28016
[32m[0907 11-47-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34663, current rewards: -290.94063, mean: -0.31971
[32m[0907 11-47-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34774, current rewards: -340.94063, mean: -0.35515
[32m[0907 11-47-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34867, current rewards: -390.94063, mean: -0.38707
[32m[0907 11-48-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34931, current rewards: -440.94063, mean: -0.41598
[32m[0907 11-48-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34977, current rewards: -490.94063, mean: -0.44229
[32m[0907 11-48-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35015, current rewards: -540.94063, mean: -0.46633
[32m[0907 11-49-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35046, current rewards: -590.94063, mean: -0.48838
[32m[0907 11-49-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35061, current rewards: -640.94063, mean: -0.50868
[32m[0907 11-49-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35068, current rewards: -690.94063, mean: -0.52744
[32m[0907 11-50-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35070, current rewards: -740.94063, mean: -0.54481
[32m[0907 11-50-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35077, current rewards: -790.94063, mean: -0.56095
[32m[0907 11-50-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35063, current rewards: -840.94063, mean: -0.57599
[32m[0907 11-50-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35040, current rewards: -890.94063, mean: -0.59003
[32m[0907 11-51-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35018, current rewards: -940.94063, mean: -0.60317
[32m[0907 11-51-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35000, current rewards: -990.94063, mean: -0.61549
[32m[0907 11-51-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34981, current rewards: -1040.94063, mean: -0.62707
[32m[0907 11-52-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34965, current rewards: -1090.94063, mean: -0.63798
[32m[0907 11-52-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34947, current rewards: -1140.94063, mean: -0.64826
[32m[0907 11-52-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34930, current rewards: -1190.94063, mean: -0.65798
[32m[0907 11-52-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34916, current rewards: -1240.94063, mean: -0.66717
[32m[0907 11-53-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34901, current rewards: -1290.94063, mean: -0.67589
[32m[0907 11-53-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34887, current rewards: -1340.94063, mean: -0.68415
[32m[0907 11-53-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34893, current rewards: -1390.94063, mean: -0.69201
[32m[0907 11-54-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34902, current rewards: -1440.94063, mean: -0.69949
[32m[0907 11-54-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34911, current rewards: -1490.94063, mean: -0.70661
[32m[0907 11-54-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34920, current rewards: -1540.94063, mean: -0.71340
[32m[0907 11-54-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34930, current rewards: -1590.94063, mean: -0.71988
[32m[0907 11-55-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34939, current rewards: -1640.94063, mean: -0.72608
[32m[0907 11-55-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34946, current rewards: -1690.94063, mean: -0.73201
[32m[0907 11-55-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34939, current rewards: -1740.94063, mean: -0.73769
[32m[0907 11-56-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34928, current rewards: -1790.94063, mean: -0.74313
[32m[0907 11-56-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34911, current rewards: -1840.94063, mean: -0.74835
[32m[0907 11-56-35 @Agent.py:117][0m Average action selection time: 0.3488
[32m[0907 11-56-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-56-36 @MBExp.py:227][0m Rewards obtained: [-1880.9406328632572], Lows: [21], Highs: [1893], Total time: 72512.64557999998
[32m[0907 11-59-33 @MBExp.py:144][0m ####################################################################
[32m[0907 11-59-33 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 11-59-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38982, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-59-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35172, current rewards: -97.85222, mean: -1.63087
[32m[0907 12-00-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35307, current rewards: -197.85222, mean: -1.79866
[32m[0907 12-00-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35327, current rewards: -297.85222, mean: -1.86158
[32m[0907 12-00-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35364, current rewards: -397.85222, mean: -1.89453
[32m[0907 12-01-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35368, current rewards: -497.85222, mean: -1.91482
[32m[0907 12-01-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35387, current rewards: -597.85222, mean: -1.92856
[32m[0907 12-01-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35393, current rewards: -697.85222, mean: -1.93848
[32m[0907 12-01-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35392, current rewards: -797.85222, mean: -1.94598
[32m[0907 12-02-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35380, current rewards: -897.85222, mean: -1.95185
[32m[0907 12-02-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35374, current rewards: -997.85222, mean: -1.95657
[32m[0907 12-02-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35366, current rewards: -1097.85222, mean: -1.96045
[32m[0907 12-03-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35369, current rewards: -1197.85222, mean: -1.96369
[32m[0907 12-03-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35374, current rewards: -1297.85222, mean: -1.96644
[32m[0907 12-03-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35374, current rewards: -1397.85222, mean: -1.96881
[32m[0907 12-04-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35344, current rewards: -1497.85222, mean: -1.97086
[32m[0907 12-04-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35122, current rewards: -1597.85222, mean: -1.97266
[32m[0907 12-04-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34925, current rewards: -1697.85222, mean: -1.97425
[32m[0907 12-04-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34741, current rewards: -1797.85222, mean: -1.97566
[32m[0907 12-05-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34580, current rewards: -1897.85222, mean: -1.97693
[32m[0907 12-05-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34434, current rewards: -1997.85222, mean: -1.97807
[32m[0907 12-05-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34296, current rewards: -2097.85222, mean: -1.97911
[32m[0907 12-05-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34168, current rewards: -2197.85222, mean: -1.98005
[32m[0907 12-06-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34050, current rewards: -2297.85222, mean: -1.98091
[32m[0907 12-06-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33944, current rewards: -2397.85222, mean: -1.98170
[32m[0907 12-06-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33847, current rewards: -2497.85222, mean: -1.98242
[32m[0907 12-06-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33755, current rewards: -2597.85222, mean: -1.98309
[32m[0907 12-07-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33673, current rewards: -2697.85222, mean: -1.98371
[32m[0907 12-07-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33595, current rewards: -2797.85222, mean: -1.98429
[32m[0907 12-07-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33520, current rewards: -2897.85222, mean: -1.98483
[32m[0907 12-07-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33427, current rewards: -2997.85222, mean: -1.98533
[32m[0907 12-08-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33346, current rewards: -3097.85222, mean: -1.98580
[32m[0907 12-08-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33267, current rewards: -3197.85222, mean: -1.98624
[32m[0907 12-08-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33194, current rewards: -3297.85222, mean: -1.98666
[32m[0907 12-09-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33122, current rewards: -3397.85222, mean: -1.98705
[32m[0907 12-09-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33057, current rewards: -3497.85222, mean: -1.98742
[32m[0907 12-09-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32994, current rewards: -3597.85222, mean: -1.98776
[32m[0907 12-09-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32934, current rewards: -3697.85222, mean: -1.98809
[32m[0907 12-10-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32876, current rewards: -3797.85222, mean: -1.98840
[32m[0907 12-10-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32820, current rewards: -3897.85222, mean: -1.98870
[32m[0907 12-10-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32773, current rewards: -3997.85222, mean: -1.98898
[32m[0907 12-10-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32745, current rewards: -4097.85222, mean: -1.98925
[32m[0907 12-11-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32716, current rewards: -4197.85222, mean: -1.98950
[32m[0907 12-11-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32689, current rewards: -4297.85222, mean: -1.98975
[32m[0907 12-11-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32665, current rewards: -4397.85222, mean: -1.98998
[32m[0907 12-11-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32637, current rewards: -4497.85222, mean: -1.99020
[32m[0907 12-12-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32611, current rewards: -4597.85222, mean: -1.99041
[32m[0907 12-12-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32580, current rewards: -4697.85222, mean: -1.99062
[32m[0907 12-12-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32543, current rewards: -4797.85222, mean: -1.99081
[32m[0907 12-12-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32508, current rewards: -4897.85222, mean: -1.99100
[32m[0907 12-13-06 @Agent.py:117][0m Average action selection time: 0.3248
[32m[0907 12-13-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-13-06 @MBExp.py:227][0m Rewards obtained: [-4977.852215661943], Lows: [2479], Highs: [20], Total time: 73325.42263999998
[32m[0907 12-15-50 @MBExp.py:144][0m ####################################################################
[32m[0907 12-15-50 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 12-15-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29985, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-16-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30656, current rewards: -94.33279, mean: -1.57221
[32m[0907 12-16-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31113, current rewards: -194.33279, mean: -1.76666
[32m[0907 12-16-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31309, current rewards: -294.33279, mean: -1.83958
[32m[0907 12-16-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31378, current rewards: -394.33279, mean: -1.87778
[32m[0907 12-17-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31415, current rewards: -494.33279, mean: -1.90128
[32m[0907 12-17-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31456, current rewards: -594.33279, mean: -1.91720
[32m[0907 12-17-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31487, current rewards: -694.33279, mean: -1.92870
[32m[0907 12-18-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31522, current rewards: -794.33279, mean: -1.93740
[32m[0907 12-18-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31542, current rewards: -894.33279, mean: -1.94420
[32m[0907 12-18-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31557, current rewards: -994.33279, mean: -1.94967
[32m[0907 12-18-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31553, current rewards: -1094.33279, mean: -1.95417
[32m[0907 12-19-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31568, current rewards: -1194.33279, mean: -1.95792
[32m[0907 12-19-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31574, current rewards: -1294.33279, mean: -1.96111
[32m[0907 12-19-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31582, current rewards: -1394.33279, mean: -1.96385
[32m[0907 12-19-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31580, current rewards: -1494.33279, mean: -1.96623
[32m[0907 12-20-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31578, current rewards: -1594.33279, mean: -1.96831
[32m[0907 12-20-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31572, current rewards: -1694.33279, mean: -1.97015
[32m[0907 12-20-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31573, current rewards: -1794.33279, mean: -1.97179
[32m[0907 12-20-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31578, current rewards: -1894.33279, mean: -1.97326
[32m[0907 12-21-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31579, current rewards: -1994.33279, mean: -1.97459
[32m[0907 12-21-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31583, current rewards: -2094.33279, mean: -1.97579
[32m[0907 12-21-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31581, current rewards: -2194.33279, mean: -1.97688
[32m[0907 12-21-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31585, current rewards: -2294.33279, mean: -1.97787
[32m[0907 12-22-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31585, current rewards: -2394.33279, mean: -1.97879
[32m[0907 12-22-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31585, current rewards: -2494.33279, mean: -1.97963
[32m[0907 12-22-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31588, current rewards: -2594.33279, mean: -1.98041
[32m[0907 12-23-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31587, current rewards: -2694.33279, mean: -1.98113
[32m[0907 12-23-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31586, current rewards: -2794.33279, mean: -1.98180
[32m[0907 12-23-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31587, current rewards: -2894.33279, mean: -1.98242
[32m[0907 12-23-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31574, current rewards: -2994.33279, mean: -1.98300
[32m[0907 12-24-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31549, current rewards: -3094.33279, mean: -1.98355
[32m[0907 12-24-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31526, current rewards: -3194.33279, mean: -1.98406
[32m[0907 12-24-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31503, current rewards: -3294.33279, mean: -1.98454
[32m[0907 12-24-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31483, current rewards: -3394.33279, mean: -1.98499
[32m[0907 12-25-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31462, current rewards: -3494.33279, mean: -1.98542
[32m[0907 12-25-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31445, current rewards: -3594.33279, mean: -1.98582
[32m[0907 12-25-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31427, current rewards: -3694.33279, mean: -1.98620
[32m[0907 12-25-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31411, current rewards: -3794.33279, mean: -1.98656
[32m[0907 12-26-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31396, current rewards: -3894.33279, mean: -1.98690
[32m[0907 12-26-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31383, current rewards: -3994.33279, mean: -1.98723
[32m[0907 12-26-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31379, current rewards: -4094.33279, mean: -1.98754
[32m[0907 12-26-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31388, current rewards: -4194.33279, mean: -1.98784
[32m[0907 12-27-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31394, current rewards: -4294.33279, mean: -1.98812
[32m[0907 12-27-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31398, current rewards: -4394.33279, mean: -1.98839
[32m[0907 12-27-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31402, current rewards: -4494.33279, mean: -1.98864
[32m[0907 12-27-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31407, current rewards: -4594.33279, mean: -1.98889
[32m[0907 12-28-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31404, current rewards: -4694.33279, mean: -1.98912
[32m[0907 12-28-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31393, current rewards: -4794.33279, mean: -1.98935
[32m[0907 12-28-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31382, current rewards: -4894.33279, mean: -1.98957
[32m[0907 12-28-55 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0907 12-28-55 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-28-55 @MBExp.py:227][0m Rewards obtained: [-4974.332789758806], Lows: [2476], Highs: [23], Total time: 74110.51982699998
[32m[0907 12-31-42 @MBExp.py:144][0m ####################################################################
[32m[0907 12-31-42 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 12-31-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29874, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-32-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30036, current rewards: -60.00000, mean: -1.00000
[32m[0907 12-32-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30864, current rewards: -110.00000, mean: -1.00000
[32m[0907 12-32-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31124, current rewards: -160.00000, mean: -1.00000
[32m[0907 12-32-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31259, current rewards: -210.00000, mean: -1.00000
[32m[0907 12-33-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31324, current rewards: -260.00000, mean: -1.00000
[32m[0907 12-33-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31493, current rewards: -313.00000, mean: -1.00968
[32m[0907 12-33-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31514, current rewards: -383.45149, mean: -1.06514
[32m[0907 12-33-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31526, current rewards: -441.54609, mean: -1.07694
[32m[0907 12-34-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31539, current rewards: -507.07633, mean: -1.10234
[32m[0907 12-34-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31551, current rewards: -607.07633, mean: -1.19035
[32m[0907 12-34-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31561, current rewards: -707.07633, mean: -1.26264
[32m[0907 12-34-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31570, current rewards: -807.07633, mean: -1.32308
[32m[0907 12-35-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31571, current rewards: -907.07633, mean: -1.37436
[32m[0907 12-35-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31575, current rewards: -1007.07633, mean: -1.41842
[32m[0907 12-35-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31582, current rewards: -1107.07633, mean: -1.45668
[32m[0907 12-35-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31586, current rewards: -1207.07633, mean: -1.49022
[32m[0907 12-36-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31587, current rewards: -1307.07633, mean: -1.51986
[32m[0907 12-36-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31582, current rewards: -1407.07633, mean: -1.54624
[32m[0907 12-36-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31583, current rewards: -1507.07633, mean: -1.56987
[32m[0907 12-37-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31581, current rewards: -1607.07633, mean: -1.59116
[32m[0907 12-37-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31586, current rewards: -1707.07633, mean: -1.61045
[32m[0907 12-37-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31581, current rewards: -1807.07633, mean: -1.62800
[32m[0907 12-37-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31583, current rewards: -1907.07633, mean: -1.64403
[32m[0907 12-38-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31582, current rewards: -2007.07633, mean: -1.65874
[32m[0907 12-38-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31578, current rewards: -2107.07633, mean: -1.67228
[32m[0907 12-38-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31580, current rewards: -2207.07633, mean: -1.68479
[32m[0907 12-38-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31573, current rewards: -2307.07633, mean: -1.69638
[32m[0907 12-39-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31570, current rewards: -2407.07633, mean: -1.70715
[32m[0907 12-39-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31569, current rewards: -2507.07633, mean: -1.71718
[32m[0907 12-39-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31551, current rewards: -2607.07633, mean: -1.72654
[32m[0907 12-39-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31527, current rewards: -2707.07633, mean: -1.73531
[32m[0907 12-40-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31504, current rewards: -2807.07633, mean: -1.74353
[32m[0907 12-40-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31484, current rewards: -2907.07633, mean: -1.75125
[32m[0907 12-40-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31463, current rewards: -3007.07633, mean: -1.75852
[32m[0907 12-40-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31445, current rewards: -3107.07633, mean: -1.76538
[32m[0907 12-41-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31428, current rewards: -3207.07633, mean: -1.77187
[32m[0907 12-41-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31412, current rewards: -3307.07633, mean: -1.77800
[32m[0907 12-41-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31396, current rewards: -3407.07633, mean: -1.78381
[32m[0907 12-41-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31382, current rewards: -3507.07633, mean: -1.78932
[32m[0907 12-42-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31367, current rewards: -3607.07633, mean: -1.79457
[32m[0907 12-42-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31365, current rewards: -3707.07633, mean: -1.79955
[32m[0907 12-42-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31371, current rewards: -3807.07633, mean: -1.80430
[32m[0907 12-43-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31375, current rewards: -3907.07633, mean: -1.80883
[32m[0907 12-43-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31378, current rewards: -4007.07633, mean: -1.81316
[32m[0907 12-43-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31381, current rewards: -4107.07633, mean: -1.81729
[32m[0907 12-43-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31382, current rewards: -4207.07633, mean: -1.82125
[32m[0907 12-44-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31382, current rewards: -4307.07633, mean: -1.82503
[32m[0907 12-44-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31370, current rewards: -4407.07633, mean: -1.82866
[32m[0907 12-44-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31358, current rewards: -4507.07633, mean: -1.83214
[32m[0907 12-44-46 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0907 12-44-46 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-44-46 @MBExp.py:227][0m Rewards obtained: [-4587.076334081901], Lows: [2148], Highs: [308], Total time: 74894.95739099999
[32m[0907 12-47-35 @MBExp.py:144][0m ####################################################################
[32m[0907 12-47-35 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 12-47-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29960, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-47-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29934, current rewards: -47.82840, mean: -0.79714
[32m[0907 12-48-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30301, current rewards: -77.61925, mean: -0.70563
[32m[0907 12-48-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30639, current rewards: -111.06935, mean: -0.69418
[32m[0907 12-48-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30896, current rewards: -163.89604, mean: -0.78046
[32m[0907 12-48-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31047, current rewards: -199.54580, mean: -0.76748
[32m[0907 12-49-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31137, current rewards: -248.42623, mean: -0.80137
[32m[0907 12-49-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31210, current rewards: -296.04424, mean: -0.82235
[32m[0907 12-49-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31338, current rewards: -339.67020, mean: -0.82846
[32m[0907 12-49-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31373, current rewards: -383.00007, mean: -0.83261
[32m[0907 12-50-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31401, current rewards: -439.59951, mean: -0.86196
[32m[0907 12-50-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31459, current rewards: -494.17323, mean: -0.88245
[32m[0907 12-50-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31476, current rewards: -544.41517, mean: -0.89248
[32m[0907 12-51-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31483, current rewards: -591.83680, mean: -0.89672
[32m[0907 12-51-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31523, current rewards: -664.46615, mean: -0.93587
[32m[0907 12-51-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31526, current rewards: -738.93697, mean: -0.97229
[32m[0907 12-51-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31524, current rewards: -798.04602, mean: -0.98524
[32m[0907 12-52-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31616, current rewards: -867.46800, mean: -1.00868
[32m[0907 12-52-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31644, current rewards: -936.46800, mean: -1.02909
[32m[0907 12-52-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31659, current rewards: -1012.40214, mean: -1.05459
[32m[0907 12-52-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31656, current rewards: -1077.89994, mean: -1.06723
[32m[0907 12-53-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31692, current rewards: -1150.40791, mean: -1.08529
[32m[0907 12-53-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31717, current rewards: -1223.21371, mean: -1.10199
[32m[0907 12-53-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31728, current rewards: -1272.92358, mean: -1.09735
[32m[0907 12-53-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31732, current rewards: -1315.81812, mean: -1.08745
[32m[0907 12-54-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31723, current rewards: -1311.68647, mean: -1.04102
[32m[0907 12-54-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31714, current rewards: -1307.29467, mean: -0.99793
[32m[0907 12-54-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31709, current rewards: -1303.08849, mean: -0.95815
[32m[0907 12-55-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31705, current rewards: -1308.66453, mean: -0.92813
[32m[0907 12-55-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31709, current rewards: -1352.76775, mean: -0.92655
[32m[0907 12-55-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31691, current rewards: -1402.76775, mean: -0.92899
[32m[0907 12-55-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31662, current rewards: -1452.76775, mean: -0.93126
[32m[0907 12-56-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31634, current rewards: -1502.76775, mean: -0.93340
[32m[0907 12-56-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31607, current rewards: -1552.76775, mean: -0.93540
[32m[0907 12-56-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31585, current rewards: -1602.76775, mean: -0.93729
[32m[0907 12-56-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31564, current rewards: -1652.76775, mean: -0.93907
[32m[0907 12-57-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31543, current rewards: -1702.76775, mean: -0.94076
[32m[0907 12-57-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31521, current rewards: -1752.76775, mean: -0.94235
[32m[0907 12-57-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31502, current rewards: -1802.76775, mean: -0.94386
[32m[0907 12-57-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31484, current rewards: -1852.76775, mean: -0.94529
[32m[0907 12-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31467, current rewards: -1902.76775, mean: -0.94665
[32m[0907 12-58-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31453, current rewards: -1952.76775, mean: -0.94795
[32m[0907 12-58-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31459, current rewards: -2002.76775, mean: -0.94918
[32m[0907 12-58-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31460, current rewards: -2052.76775, mean: -0.95036
[32m[0907 12-59-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31465, current rewards: -2102.76775, mean: -0.95148
[32m[0907 12-59-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31471, current rewards: -2152.76775, mean: -0.95255
[32m[0907 12-59-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31475, current rewards: -2202.76775, mean: -0.95358
[32m[0907 12-59-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31468, current rewards: -2252.76775, mean: -0.95456
[32m[0907 13-00-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31456, current rewards: -2302.76775, mean: -0.95551
[32m[0907 13-00-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31443, current rewards: -2352.76775, mean: -0.95641
[32m[0907 13-00-41 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0907 13-00-41 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-00-41 @MBExp.py:227][0m Rewards obtained: [-2392.7677475988257], Lows: [297], Highs: [1836], Total time: 75681.539081
[32m[0907 13-03-31 @MBExp.py:144][0m ####################################################################
[32m[0907 13-03-31 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 13-03-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30703, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-03-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30087, current rewards: -98.00000, mean: -1.63333
[32m[0907 13-04-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30496, current rewards: -198.00000, mean: -1.80000
[32m[0907 13-04-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30637, current rewards: -298.00000, mean: -1.86250
[32m[0907 13-04-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30844, current rewards: -398.00000, mean: -1.89524
[32m[0907 13-04-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31014, current rewards: -498.00000, mean: -1.91538
[32m[0907 13-05-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31124, current rewards: -598.00000, mean: -1.92903
[32m[0907 13-05-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31211, current rewards: -698.00000, mean: -1.93889
[32m[0907 13-05-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31257, current rewards: -798.00000, mean: -1.94634
[32m[0907 13-05-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31299, current rewards: -898.00000, mean: -1.95217
[32m[0907 13-06-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31339, current rewards: -998.00000, mean: -1.95686
[32m[0907 13-06-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31375, current rewards: -1098.00000, mean: -1.96071
[32m[0907 13-06-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31404, current rewards: -1198.00000, mean: -1.96393
[32m[0907 13-06-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31423, current rewards: -1298.00000, mean: -1.96667
[32m[0907 13-07-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31438, current rewards: -1398.00000, mean: -1.96901
[32m[0907 13-07-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31514, current rewards: -1498.00000, mean: -1.97105
[32m[0907 13-07-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31748, current rewards: -1598.00000, mean: -1.97284
[32m[0907 13-08-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31961, current rewards: -1698.00000, mean: -1.97442
[32m[0907 13-08-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32157, current rewards: -1798.00000, mean: -1.97582
[32m[0907 13-08-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32338, current rewards: -1898.00000, mean: -1.97708
[32m[0907 13-08-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32502, current rewards: -1998.00000, mean: -1.97822
[32m[0907 13-09-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32653, current rewards: -2098.00000, mean: -1.97925
[32m[0907 13-09-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32784, current rewards: -2198.00000, mean: -1.98018
[32m[0907 13-09-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32914, current rewards: -2298.00000, mean: -1.98103
[32m[0907 13-10-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33039, current rewards: -2398.00000, mean: -1.98182
[32m[0907 13-10-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33152, current rewards: -2498.00000, mean: -1.98254
[32m[0907 13-10-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33256, current rewards: -2598.00000, mean: -1.98321
[32m[0907 13-11-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33352, current rewards: -2698.00000, mean: -1.98382
[32m[0907 13-11-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33445, current rewards: -2798.00000, mean: -1.98440
[32m[0907 13-11-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33527, current rewards: -2898.00000, mean: -1.98493
[32m[0907 13-11-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33570, current rewards: -2998.00000, mean: -1.98543
[32m[0907 13-12-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33617, current rewards: -3098.00000, mean: -1.98590
[32m[0907 13-12-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33651, current rewards: -3198.00000, mean: -1.98634
[32m[0907 13-12-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33690, current rewards: -3298.00000, mean: -1.98675
[32m[0907 13-13-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33722, current rewards: -3398.00000, mean: -1.98713
[32m[0907 13-13-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33746, current rewards: -3498.00000, mean: -1.98750
[32m[0907 13-13-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33772, current rewards: -3598.00000, mean: -1.98785
[32m[0907 13-14-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33788, current rewards: -3698.00000, mean: -1.98817
[32m[0907 13-14-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33804, current rewards: -3798.00000, mean: -1.98848
[32m[0907 13-14-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33749, current rewards: -3898.00000, mean: -1.98878
[32m[0907 13-14-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33674, current rewards: -3998.00000, mean: -1.98905
[32m[0907 13-15-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33613, current rewards: -4098.00000, mean: -1.98932
[32m[0907 13-15-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33566, current rewards: -4198.00000, mean: -1.98957
[32m[0907 13-15-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33522, current rewards: -4298.00000, mean: -1.98981
[32m[0907 13-15-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33479, current rewards: -4398.00000, mean: -1.99005
[32m[0907 13-16-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33437, current rewards: -4498.00000, mean: -1.99027
[32m[0907 13-16-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33395, current rewards: -4598.00000, mean: -1.99048
[32m[0907 13-16-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33356, current rewards: -4698.00000, mean: -1.99068
[32m[0907 13-16-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33319, current rewards: -4798.00000, mean: -1.99087
[32m[0907 13-17-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33284, current rewards: -4898.00000, mean: -1.99106
[32m[0907 13-17-23 @Agent.py:117][0m Average action selection time: 0.3325
[32m[0907 13-17-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-17-23 @MBExp.py:227][0m Rewards obtained: [-4978], Lows: [2478], Highs: [22], Total time: 76513.571801
[32m[0907 13-20-15 @MBExp.py:144][0m ####################################################################
[32m[0907 13-20-15 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 13-20-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31842, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-20-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31260, current rewards: -83.62374, mean: -1.39373
[32m[0907 13-20-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31107, current rewards: -183.62374, mean: -1.66931
[32m[0907 13-21-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31075, current rewards: -283.62374, mean: -1.77265
[32m[0907 13-21-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31196, current rewards: -383.62374, mean: -1.82678
[32m[0907 13-21-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31293, current rewards: -483.62374, mean: -1.86009
[32m[0907 13-21-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31365, current rewards: -583.62374, mean: -1.88266
[32m[0907 13-22-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31412, current rewards: -683.62374, mean: -1.89895
[32m[0907 13-22-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31456, current rewards: -783.62374, mean: -1.91128
[32m[0907 13-22-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31489, current rewards: -883.62374, mean: -1.92092
[32m[0907 13-22-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31510, current rewards: -983.62374, mean: -1.92867
[32m[0907 13-23-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31520, current rewards: -1083.62374, mean: -1.93504
[32m[0907 13-23-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31526, current rewards: -1183.62374, mean: -1.94037
[32m[0907 13-23-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31532, current rewards: -1283.62374, mean: -1.94488
[32m[0907 13-23-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31536, current rewards: -1383.62374, mean: -1.94877
[32m[0907 13-24-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31545, current rewards: -1483.62374, mean: -1.95214
[32m[0907 13-24-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31555, current rewards: -1583.62374, mean: -1.95509
[32m[0907 13-24-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31561, current rewards: -1683.62374, mean: -1.95770
[32m[0907 13-25-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31562, current rewards: -1783.62374, mean: -1.96003
[32m[0907 13-25-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31564, current rewards: -1883.62374, mean: -1.96211
[32m[0907 13-25-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31567, current rewards: -1983.62374, mean: -1.96398
[32m[0907 13-25-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31569, current rewards: -2083.62374, mean: -1.96568
[32m[0907 13-26-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31572, current rewards: -2183.62374, mean: -1.96723
[32m[0907 13-26-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31573, current rewards: -2283.62374, mean: -1.96864
[32m[0907 13-26-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31572, current rewards: -2383.62374, mean: -1.96994
[32m[0907 13-26-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31575, current rewards: -2483.62374, mean: -1.97113
[32m[0907 13-27-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31578, current rewards: -2583.62374, mean: -1.97223
[32m[0907 13-27-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31579, current rewards: -2683.62374, mean: -1.97325
[32m[0907 13-27-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31578, current rewards: -2783.62374, mean: -1.97420
[32m[0907 13-27-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31578, current rewards: -2883.62374, mean: -1.97508
[32m[0907 13-28-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31576, current rewards: -2983.62374, mean: -1.97591
[32m[0907 13-28-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31579, current rewards: -3083.62374, mean: -1.97668
[32m[0907 13-28-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31559, current rewards: -3183.62374, mean: -1.97741
[32m[0907 13-28-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31538, current rewards: -3283.62374, mean: -1.97809
[32m[0907 13-29-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31516, current rewards: -3383.62374, mean: -1.97873
[32m[0907 13-29-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31497, current rewards: -3483.62374, mean: -1.97933
[32m[0907 13-29-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31478, current rewards: -3583.62374, mean: -1.97990
[32m[0907 13-30-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31459, current rewards: -3683.62374, mean: -1.98044
[32m[0907 13-30-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31442, current rewards: -3783.62374, mean: -1.98095
[32m[0907 13-30-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31426, current rewards: -3883.62374, mean: -1.98144
[32m[0907 13-30-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31410, current rewards: -3983.62374, mean: -1.98190
[32m[0907 13-31-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31395, current rewards: -4083.62374, mean: -1.98234
[32m[0907 13-31-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31379, current rewards: -4183.62374, mean: -1.98276
[32m[0907 13-31-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31370, current rewards: -4283.62374, mean: -1.98316
[32m[0907 13-31-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31374, current rewards: -4383.62374, mean: -1.98354
[32m[0907 13-32-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31378, current rewards: -4483.62374, mean: -1.98390
[32m[0907 13-32-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31380, current rewards: -4583.62374, mean: -1.98425
[32m[0907 13-32-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31382, current rewards: -4683.62374, mean: -1.98459
[32m[0907 13-32-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31385, current rewards: -4783.62374, mean: -1.98491
[32m[0907 13-33-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31386, current rewards: -4883.62374, mean: -1.98521
[32m[0907 13-33-20 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0907 13-33-20 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-33-21 @MBExp.py:227][0m Rewards obtained: [-4963.623738611655], Lows: [2472], Highs: [21], Total time: 77298.852033
[32m[0907 13-36-15 @MBExp.py:144][0m ####################################################################
[32m[0907 13-36-15 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 13-36-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30870, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-36-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30282, current rewards: -77.75036, mean: -1.29584
[32m[0907 13-36-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30557, current rewards: -127.75036, mean: -1.16137
[32m[0907 13-37-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30669, current rewards: -177.75036, mean: -1.11094
[32m[0907 13-37-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30739, current rewards: -227.75036, mean: -1.08453
[32m[0907 13-37-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30927, current rewards: -277.75036, mean: -1.06827
[32m[0907 13-37-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31064, current rewards: -327.75036, mean: -1.05726
[32m[0907 13-38-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31140, current rewards: -377.75036, mean: -1.04931
[32m[0907 13-38-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31189, current rewards: -427.75036, mean: -1.04329
[32m[0907 13-38-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31240, current rewards: -477.75036, mean: -1.03859
[32m[0907 13-38-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31270, current rewards: -527.75036, mean: -1.03480
[32m[0907 13-39-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31296, current rewards: -577.75036, mean: -1.03170
[32m[0907 13-39-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31309, current rewards: -627.75036, mean: -1.02910
[32m[0907 13-39-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31328, current rewards: -677.75036, mean: -1.02689
[32m[0907 13-39-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31348, current rewards: -727.75036, mean: -1.02500
[32m[0907 13-40-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31365, current rewards: -777.75036, mean: -1.02336
[32m[0907 13-40-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31377, current rewards: -827.75036, mean: -1.02191
[32m[0907 13-40-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31388, current rewards: -877.75036, mean: -1.02064
[32m[0907 13-41-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31398, current rewards: -927.75036, mean: -1.01951
[32m[0907 13-41-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31404, current rewards: -977.75036, mean: -1.01849
[32m[0907 13-41-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31410, current rewards: -1027.75036, mean: -1.01757
[32m[0907 13-41-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31414, current rewards: -1077.75036, mean: -1.01675
[32m[0907 13-42-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31417, current rewards: -1127.75036, mean: -1.01599
[32m[0907 13-42-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31427, current rewards: -1177.75036, mean: -1.01530
[32m[0907 13-42-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31427, current rewards: -1227.75036, mean: -1.01467
[32m[0907 13-42-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31431, current rewards: -1277.75036, mean: -1.01409
[32m[0907 13-43-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31433, current rewards: -1327.75036, mean: -1.01355
[32m[0907 13-43-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31436, current rewards: -1377.75036, mean: -1.01305
[32m[0907 13-43-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31437, current rewards: -1427.75036, mean: -1.01259
[32m[0907 13-43-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31441, current rewards: -1477.75036, mean: -1.01216
[32m[0907 13-44-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31445, current rewards: -1527.75036, mean: -1.01176
[32m[0907 13-44-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31445, current rewards: -1577.75036, mean: -1.01138
[32m[0907 13-44-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31438, current rewards: -1627.75036, mean: -1.01103
[32m[0907 13-44-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31421, current rewards: -1677.75036, mean: -1.01069
[32m[0907 13-45-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31401, current rewards: -1727.75036, mean: -1.01038
[32m[0907 13-45-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31384, current rewards: -1777.75036, mean: -1.01009
[32m[0907 13-45-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31369, current rewards: -1827.75036, mean: -1.00981
[32m[0907 13-45-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31353, current rewards: -1877.75036, mean: -1.00954
[32m[0907 13-46-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31340, current rewards: -1927.75036, mean: -1.00929
[32m[0907 13-46-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31326, current rewards: -1977.75036, mean: -1.00906
[32m[0907 13-46-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31313, current rewards: -2027.75036, mean: -1.00883
[32m[0907 13-47-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31302, current rewards: -2077.75036, mean: -1.00862
[32m[0907 13-47-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31292, current rewards: -2127.75036, mean: -1.00841
[32m[0907 13-47-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31281, current rewards: -2177.75036, mean: -1.00822
[32m[0907 13-47-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31285, current rewards: -2227.75036, mean: -1.00803
[32m[0907 13-48-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31293, current rewards: -2277.75036, mean: -1.00785
[32m[0907 13-48-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31299, current rewards: -2312.88782, mean: -1.00125
[32m[0907 13-48-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31303, current rewards: -2308.71499, mean: -0.97827
[32m[0907 13-48-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31308, current rewards: -2304.54215, mean: -0.95624
[32m[0907 13-49-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31313, current rewards: -2300.36932, mean: -0.93511
[32m[0907 13-49-18 @Agent.py:117][0m Average action selection time: 0.3132
[32m[0907 13-49-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-49-18 @MBExp.py:227][0m Rewards obtained: [-2297.0310497394526], Lows: [21], Highs: [2272], Total time: 78082.520919
[32m[0907 13-52-13 @MBExp.py:144][0m ####################################################################
[32m[0907 13-52-13 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 13-52-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29829, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-52-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30105, current rewards: -100.00000, mean: -1.66667
[32m[0907 13-52-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30497, current rewards: -200.00000, mean: -1.81818
[32m[0907 13-53-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30627, current rewards: -300.00000, mean: -1.87500
[32m[0907 13-53-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30688, current rewards: -400.00000, mean: -1.90476
[32m[0907 13-53-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30722, current rewards: -500.00000, mean: -1.92308
[32m[0907 13-53-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30849, current rewards: -600.00000, mean: -1.93548
[32m[0907 13-54-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30987, current rewards: -700.00000, mean: -1.94444
[32m[0907 13-54-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31073, current rewards: -800.00000, mean: -1.95122
[32m[0907 13-54-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31138, current rewards: -900.00000, mean: -1.95652
[32m[0907 13-54-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31191, current rewards: -1000.00000, mean: -1.96078
[32m[0907 13-55-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31243, current rewards: -1100.00000, mean: -1.96429
[32m[0907 13-55-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31271, current rewards: -1200.00000, mean: -1.96721
[32m[0907 13-55-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31297, current rewards: -1300.00000, mean: -1.96970
[32m[0907 13-55-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31320, current rewards: -1400.00000, mean: -1.97183
[32m[0907 13-56-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31338, current rewards: -1500.00000, mean: -1.97368
[32m[0907 13-56-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31353, current rewards: -1600.00000, mean: -1.97531
[32m[0907 13-56-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31368, current rewards: -1700.00000, mean: -1.97674
[32m[0907 13-56-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31384, current rewards: -1800.00000, mean: -1.97802
[32m[0907 13-57-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31396, current rewards: -1900.00000, mean: -1.97917
[32m[0907 13-57-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31405, current rewards: -2000.00000, mean: -1.98020
[32m[0907 13-57-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31413, current rewards: -2100.00000, mean: -1.98113
[32m[0907 13-58-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31420, current rewards: -2200.00000, mean: -1.98198
[32m[0907 13-58-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31426, current rewards: -2300.00000, mean: -1.98276
[32m[0907 13-58-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31433, current rewards: -2400.00000, mean: -1.98347
[32m[0907 13-58-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31436, current rewards: -2500.00000, mean: -1.98413
[32m[0907 13-59-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31441, current rewards: -2600.00000, mean: -1.98473
[32m[0907 13-59-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31447, current rewards: -2700.00000, mean: -1.98529
[32m[0907 13-59-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31450, current rewards: -2800.00000, mean: -1.98582
[32m[0907 13-59-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31454, current rewards: -2900.00000, mean: -1.98630
[32m[0907 14-00-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31455, current rewards: -3000.00000, mean: -1.98675
[32m[0907 14-00-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31456, current rewards: -3100.00000, mean: -1.98718
[32m[0907 14-00-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31441, current rewards: -3200.00000, mean: -1.98758
[32m[0907 14-00-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31423, current rewards: -3300.00000, mean: -1.98795
[32m[0907 14-01-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31404, current rewards: -3400.00000, mean: -1.98830
[32m[0907 14-01-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31387, current rewards: -3500.00000, mean: -1.98864
[32m[0907 14-01-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31374, current rewards: -3600.00000, mean: -1.98895
[32m[0907 14-01-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31358, current rewards: -3700.00000, mean: -1.98925
[32m[0907 14-02-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31343, current rewards: -3800.00000, mean: -1.98953
[32m[0907 14-02-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31328, current rewards: -3900.00000, mean: -1.98980
[32m[0907 14-02-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31317, current rewards: -4000.00000, mean: -1.99005
[32m[0907 14-02-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31304, current rewards: -4100.00000, mean: -1.99029
[32m[0907 14-03-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31291, current rewards: -4200.00000, mean: -1.99052
[32m[0907 14-03-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31279, current rewards: -4300.00000, mean: -1.99074
[32m[0907 14-03-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31283, current rewards: -4400.00000, mean: -1.99095
[32m[0907 14-04-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31288, current rewards: -4500.00000, mean: -1.99115
[32m[0907 14-04-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31295, current rewards: -4600.00000, mean: -1.99134
[32m[0907 14-04-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31302, current rewards: -4700.00000, mean: -1.99153
[32m[0907 14-04-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31308, current rewards: -4800.00000, mean: -1.99170
[32m[0907 14-05-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31313, current rewards: -4900.00000, mean: -1.99187
[32m[0907 14-05-17 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0907 14-05-17 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-05-17 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 78866.11760700001
[32m[0907 14-08-15 @MBExp.py:144][0m ####################################################################
[32m[0907 14-08-15 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 14-08-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29855, current rewards: -7.90304, mean: -0.79030
[32m[0907 14-08-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29825, current rewards: -87.41824, mean: -1.45697
[32m[0907 14-08-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29828, current rewards: -187.41824, mean: -1.70380
[32m[0907 14-09-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29845, current rewards: -287.41824, mean: -1.79636
[32m[0907 14-09-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29859, current rewards: -363.32031, mean: -1.73010
[32m[0907 14-09-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29869, current rewards: -413.32031, mean: -1.58969
[32m[0907 14-09-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29878, current rewards: -510.16703, mean: -1.64570
[32m[0907 14-10-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30014, current rewards: -610.16703, mean: -1.69491
[32m[0907 14-10-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30185, current rewards: -710.16703, mean: -1.73211
[32m[0907 14-10-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30344, current rewards: -810.16703, mean: -1.76123
[32m[0907 14-10-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30472, current rewards: -910.16703, mean: -1.78464
[32m[0907 14-11-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30577, current rewards: -1010.16703, mean: -1.80387
[32m[0907 14-11-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30667, current rewards: -1110.16703, mean: -1.81995
[32m[0907 14-11-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30736, current rewards: -1210.16703, mean: -1.83359
[32m[0907 14-11-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30793, current rewards: -1310.16703, mean: -1.84531
[32m[0907 14-12-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30843, current rewards: -1410.16703, mean: -1.85548
[32m[0907 14-12-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30884, current rewards: -1510.16703, mean: -1.86440
[32m[0907 14-12-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30919, current rewards: -1610.16703, mean: -1.87229
[32m[0907 14-12-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30952, current rewards: -1710.16703, mean: -1.87930
[32m[0907 14-13-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30980, current rewards: -1810.16703, mean: -1.88559
[32m[0907 14-13-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31001, current rewards: -1910.16703, mean: -1.89125
[32m[0907 14-13-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31025, current rewards: -2010.16703, mean: -1.89638
[32m[0907 14-13-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31048, current rewards: -2110.16703, mean: -1.90105
[32m[0907 14-14-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31068, current rewards: -2210.16703, mean: -1.90532
[32m[0907 14-14-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31084, current rewards: -2310.16703, mean: -1.90923
[32m[0907 14-14-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31100, current rewards: -2410.16703, mean: -1.91283
[32m[0907 14-15-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31112, current rewards: -2510.16703, mean: -1.91616
[32m[0907 14-15-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31127, current rewards: -2610.16703, mean: -1.91924
[32m[0907 14-15-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31138, current rewards: -2710.16703, mean: -1.92210
[32m[0907 14-15-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31149, current rewards: -2810.16703, mean: -1.92477
[32m[0907 14-16-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31161, current rewards: -2910.16703, mean: -1.92726
[32m[0907 14-16-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31170, current rewards: -3010.16703, mean: -1.92959
[32m[0907 14-16-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31157, current rewards: -3110.16703, mean: -1.93178
[32m[0907 14-16-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31144, current rewards: -3210.16703, mean: -1.93384
[32m[0907 14-17-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31131, current rewards: -3310.16703, mean: -1.93577
[32m[0907 14-17-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31120, current rewards: -3410.16703, mean: -1.93759
[32m[0907 14-17-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31109, current rewards: -3510.16703, mean: -1.93932
[32m[0907 14-17-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31097, current rewards: -3610.16703, mean: -1.94095
[32m[0907 14-18-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31089, current rewards: -3710.16703, mean: -1.94250
[32m[0907 14-18-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31082, current rewards: -3810.16703, mean: -1.94396
[32m[0907 14-18-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31072, current rewards: -3910.16703, mean: -1.94536
[32m[0907 14-18-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31065, current rewards: -4010.16703, mean: -1.94668
[32m[0907 14-19-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31056, current rewards: -4110.16703, mean: -1.94795
[32m[0907 14-19-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31048, current rewards: -4210.16703, mean: -1.94915
[32m[0907 14-19-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31061, current rewards: -4310.16703, mean: -1.95030
[32m[0907 14-19-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31076, current rewards: -4410.16703, mean: -1.95140
[32m[0907 14-20-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31084, current rewards: -4510.16703, mean: -1.95245
[32m[0907 14-20-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31091, current rewards: -4610.16703, mean: -1.95346
[32m[0907 14-20-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31099, current rewards: -4710.16703, mean: -1.95443
[32m[0907 14-21-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31106, current rewards: -4810.16703, mean: -1.95535
[32m[0907 14-21-13 @Agent.py:117][0m Average action selection time: 0.3111
[32m[0907 14-21-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-21-13 @MBExp.py:227][0m Rewards obtained: [-4890.1670347914915], Lows: [2405], Highs: [81], Total time: 79644.64720200001
[32m[0907 14-24-13 @MBExp.py:144][0m ####################################################################
[32m[0907 14-24-13 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 14-24-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29841, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-24-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29915, current rewards: -100.00000, mean: -1.66667
[32m[0907 14-24-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29944, current rewards: -200.00000, mean: -1.81818
[32m[0907 14-25-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29954, current rewards: -300.00000, mean: -1.87500
[32m[0907 14-25-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29947, current rewards: -400.00000, mean: -1.90476
[32m[0907 14-25-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29939, current rewards: -500.00000, mean: -1.92308
[32m[0907 14-25-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29936, current rewards: -600.00000, mean: -1.93548
[32m[0907 14-26-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30030, current rewards: -700.00000, mean: -1.94444
[32m[0907 14-26-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30195, current rewards: -800.00000, mean: -1.95122
[32m[0907 14-26-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30369, current rewards: -900.00000, mean: -1.95652
[32m[0907 14-26-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30506, current rewards: -1000.00000, mean: -1.96078
[32m[0907 14-27-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30608, current rewards: -1100.00000, mean: -1.96429
[32m[0907 14-27-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30695, current rewards: -1200.00000, mean: -1.96721
[32m[0907 14-27-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30769, current rewards: -1300.00000, mean: -1.96970
[32m[0907 14-27-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30832, current rewards: -1400.00000, mean: -1.97183
[32m[0907 14-28-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30885, current rewards: -1500.00000, mean: -1.97368
[32m[0907 14-28-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30928, current rewards: -1600.00000, mean: -1.97531
[32m[0907 14-28-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30965, current rewards: -1700.00000, mean: -1.97674
[32m[0907 14-28-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30993, current rewards: -1800.00000, mean: -1.97802
[32m[0907 14-29-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31016, current rewards: -1900.00000, mean: -1.97917
[32m[0907 14-29-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31042, current rewards: -2000.00000, mean: -1.98020
[32m[0907 14-29-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31069, current rewards: -2100.00000, mean: -1.98113
[32m[0907 14-29-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31095, current rewards: -2200.00000, mean: -1.98198
[32m[0907 14-30-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31119, current rewards: -2300.00000, mean: -1.98276
[32m[0907 14-30-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31136, current rewards: -2400.00000, mean: -1.98347
[32m[0907 14-30-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31152, current rewards: -2500.00000, mean: -1.98413
[32m[0907 14-31-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31167, current rewards: -2600.00000, mean: -1.98473
[32m[0907 14-31-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31180, current rewards: -2700.00000, mean: -1.98529
[32m[0907 14-31-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31189, current rewards: -2800.00000, mean: -1.98582
[32m[0907 14-31-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31196, current rewards: -2900.00000, mean: -1.98630
[32m[0907 14-32-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31203, current rewards: -3000.00000, mean: -1.98675
[32m[0907 14-32-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31209, current rewards: -3100.00000, mean: -1.98718
[32m[0907 14-32-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31197, current rewards: -3200.00000, mean: -1.98758
[32m[0907 14-32-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31186, current rewards: -3300.00000, mean: -1.98795
[32m[0907 14-33-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31175, current rewards: -3400.00000, mean: -1.98830
[32m[0907 14-33-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31163, current rewards: -3500.00000, mean: -1.98864
[32m[0907 14-33-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31153, current rewards: -3600.00000, mean: -1.98895
[32m[0907 14-33-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31144, current rewards: -3700.00000, mean: -1.98925
[32m[0907 14-34-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31135, current rewards: -3800.00000, mean: -1.98953
[32m[0907 14-34-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31125, current rewards: -3900.00000, mean: -1.98980
[32m[0907 14-34-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31118, current rewards: -4000.00000, mean: -1.99005
[32m[0907 14-34-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31113, current rewards: -4100.00000, mean: -1.99029
[32m[0907 14-35-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31105, current rewards: -4200.00000, mean: -1.99052
[32m[0907 14-35-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31097, current rewards: -4300.00000, mean: -1.99074
[32m[0907 14-35-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31111, current rewards: -4400.00000, mean: -1.99095
[32m[0907 14-35-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31121, current rewards: -4500.00000, mean: -1.99115
[32m[0907 14-36-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31131, current rewards: -4600.00000, mean: -1.99134
[32m[0907 14-36-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31141, current rewards: -4700.00000, mean: -1.99153
[32m[0907 14-36-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31150, current rewards: -4800.00000, mean: -1.99170
[32m[0907 14-37-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31160, current rewards: -4900.00000, mean: -1.99187
[32m[0907 14-37-13 @Agent.py:117][0m Average action selection time: 0.3117
[32m[0907 14-37-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-37-13 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 80424.528642
[32m[0907 14-40-15 @MBExp.py:144][0m ####################################################################
[32m[0907 14-40-15 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 14-40-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29378, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-40-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29899, current rewards: -94.83870, mean: -1.58064
[32m[0907 14-40-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29930, current rewards: -148.83870, mean: -1.35308
[32m[0907 14-41-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29922, current rewards: -198.83870, mean: -1.24274
[32m[0907 14-41-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29919, current rewards: -248.83870, mean: -1.18495
[32m[0907 14-41-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29925, current rewards: -298.83870, mean: -1.14938
[32m[0907 14-41-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29923, current rewards: -348.83870, mean: -1.12529
[32m[0907 14-42-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30016, current rewards: -381.41190, mean: -1.05948
[32m[0907 14-42-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30182, current rewards: -376.95315, mean: -0.91940
[32m[0907 14-42-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30338, current rewards: -372.49441, mean: -0.80977
[32m[0907 14-42-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30456, current rewards: -368.03566, mean: -0.72164
[32m[0907 14-43-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30566, current rewards: -363.57691, mean: -0.64924
[32m[0907 14-43-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30653, current rewards: -360.18797, mean: -0.59047
[32m[0907 14-43-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30726, current rewards: -357.06989, mean: -0.54101
[32m[0907 14-43-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30786, current rewards: -353.95182, mean: -0.49852
[32m[0907 14-44-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30843, current rewards: -350.83375, mean: -0.46162
[32m[0907 14-44-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30891, current rewards: -347.71567, mean: -0.42928
[32m[0907 14-44-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30932, current rewards: -392.40387, mean: -0.45628
[32m[0907 14-44-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30965, current rewards: -442.40387, mean: -0.48616
[32m[0907 14-45-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30998, current rewards: -492.40387, mean: -0.51292
[32m[0907 14-45-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31027, current rewards: -542.40387, mean: -0.53703
[32m[0907 14-45-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31052, current rewards: -592.40387, mean: -0.55887
[32m[0907 14-46-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31075, current rewards: -642.40387, mean: -0.57874
[32m[0907 14-46-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31099, current rewards: -692.40387, mean: -0.59690
[32m[0907 14-46-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31119, current rewards: -742.40387, mean: -0.61356
[32m[0907 14-46-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31138, current rewards: -792.40387, mean: -0.62889
[32m[0907 14-47-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31153, current rewards: -842.40387, mean: -0.64306
[32m[0907 14-47-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31167, current rewards: -892.40387, mean: -0.65618
[32m[0907 14-47-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31180, current rewards: -942.40387, mean: -0.66837
[32m[0907 14-47-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31192, current rewards: -992.40387, mean: -0.67973
[32m[0907 14-48-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31202, current rewards: -1042.40387, mean: -0.69033
[32m[0907 14-48-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31205, current rewards: -1092.40387, mean: -0.70026
[32m[0907 14-48-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31194, current rewards: -1142.40387, mean: -0.70957
[32m[0907 14-48-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31184, current rewards: -1192.40387, mean: -0.71832
[32m[0907 14-49-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31174, current rewards: -1242.40387, mean: -0.72655
[32m[0907 14-49-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31165, current rewards: -1292.40387, mean: -0.73432
[32m[0907 14-49-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31156, current rewards: -1342.40387, mean: -0.74166
[32m[0907 14-49-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31149, current rewards: -1392.40387, mean: -0.74860
[32m[0907 14-50-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31141, current rewards: -1442.40387, mean: -0.75519
[32m[0907 14-50-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31131, current rewards: -1487.16380, mean: -0.75876
[32m[0907 14-50-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31124, current rewards: -1484.76312, mean: -0.73869
[32m[0907 14-50-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31119, current rewards: -1482.36245, mean: -0.71959
[32m[0907 14-51-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31111, current rewards: -1479.96177, mean: -0.70140
[32m[0907 14-51-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31106, current rewards: -1477.56110, mean: -0.68406
[32m[0907 14-51-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31121, current rewards: -1492.97665, mean: -0.67556
[32m[0907 14-51-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31131, current rewards: -1542.97665, mean: -0.68273
[32m[0907 14-52-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31142, current rewards: -1592.97665, mean: -0.68960
[32m[0907 14-52-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31151, current rewards: -1642.97665, mean: -0.69618
[32m[0907 14-52-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31165, current rewards: -1692.97665, mean: -0.70248
[32m[0907 14-53-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31174, current rewards: -1742.97665, mean: -0.70853
[32m[0907 14-53-15 @Agent.py:117][0m Average action selection time: 0.3118
[32m[0907 14-53-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-53-15 @MBExp.py:227][0m Rewards obtained: [-1782.9766525224472], Lows: [40], Highs: [1750], Total time: 81204.860562
[32m[0907 14-56-20 @MBExp.py:144][0m ####################################################################
[32m[0907 14-56-20 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 14-56-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33565, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-56-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34296, current rewards: -58.89593, mean: -0.98160
[32m[0907 14-56-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31933, current rewards: -121.81709, mean: -1.10743
[32m[0907 14-57-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31217, current rewards: -221.81709, mean: -1.38636
[32m[0907 14-57-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30923, current rewards: -321.81709, mean: -1.53246
[32m[0907 14-57-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30723, current rewards: -421.81709, mean: -1.62237
[32m[0907 14-57-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30599, current rewards: -521.81709, mean: -1.68328
[32m[0907 14-58-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30615, current rewards: -621.81709, mean: -1.72727
[32m[0907 14-58-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30716, current rewards: -721.81709, mean: -1.76053
[32m[0907 14-58-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30816, current rewards: -821.81709, mean: -1.78656
[32m[0907 14-58-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30899, current rewards: -921.81709, mean: -1.80748
[32m[0907 14-59-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30976, current rewards: -1021.81709, mean: -1.82467
[32m[0907 14-59-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31036, current rewards: -1121.81709, mean: -1.83904
[32m[0907 14-59-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31085, current rewards: -1221.81709, mean: -1.85124
[32m[0907 15-00-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31130, current rewards: -1321.81709, mean: -1.86171
[32m[0907 15-00-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31173, current rewards: -1421.81709, mean: -1.87081
[32m[0907 15-00-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31203, current rewards: -1521.81709, mean: -1.87879
[32m[0907 15-00-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31233, current rewards: -1621.81709, mean: -1.88583
[32m[0907 15-01-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31254, current rewards: -1721.81709, mean: -1.89211
[32m[0907 15-01-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31276, current rewards: -1821.81709, mean: -1.89773
[32m[0907 15-01-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31287, current rewards: -1921.81709, mean: -1.90279
[32m[0907 15-01-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31296, current rewards: -2021.81709, mean: -1.90737
[32m[0907 15-02-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31308, current rewards: -2121.81709, mean: -1.91155
[32m[0907 15-02-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31318, current rewards: -2221.81709, mean: -1.91536
[32m[0907 15-02-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31329, current rewards: -2321.81709, mean: -1.91886
[32m[0907 15-02-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31337, current rewards: -2421.81709, mean: -1.92208
[32m[0907 15-03-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31344, current rewards: -2521.81709, mean: -1.92505
[32m[0907 15-03-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31350, current rewards: -2621.81709, mean: -1.92781
[32m[0907 15-03-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31354, current rewards: -2721.81709, mean: -1.93037
[32m[0907 15-03-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31360, current rewards: -2821.81709, mean: -1.93275
[32m[0907 15-04-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31362, current rewards: -2921.81709, mean: -1.93498
[32m[0907 15-04-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31347, current rewards: -3021.81709, mean: -1.93706
[32m[0907 15-04-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31327, current rewards: -3121.81709, mean: -1.93902
[32m[0907 15-05-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31309, current rewards: -3221.81709, mean: -1.94085
[32m[0907 15-05-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31293, current rewards: -3321.81709, mean: -1.94258
[32m[0907 15-05-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31278, current rewards: -3421.81709, mean: -1.94421
[32m[0907 15-05-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31265, current rewards: -3521.81709, mean: -1.94576
[32m[0907 15-06-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31252, current rewards: -3621.81709, mean: -1.94721
[32m[0907 15-06-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31240, current rewards: -3721.81709, mean: -1.94860
[32m[0907 15-06-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31228, current rewards: -3821.81709, mean: -1.94991
[32m[0907 15-06-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31216, current rewards: -3921.81709, mean: -1.95115
[32m[0907 15-07-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31203, current rewards: -4021.81709, mean: -1.95234
[32m[0907 15-07-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31193, current rewards: -4121.81709, mean: -1.95347
[32m[0907 15-07-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31190, current rewards: -4221.81709, mean: -1.95454
[32m[0907 15-07-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31200, current rewards: -4321.81709, mean: -1.95557
[32m[0907 15-08-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31210, current rewards: -4421.81709, mean: -1.95656
[32m[0907 15-08-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31217, current rewards: -4521.81709, mean: -1.95750
[32m[0907 15-08-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31223, current rewards: -4621.81709, mean: -1.95840
[32m[0907 15-08-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31230, current rewards: -4721.81709, mean: -1.95926
[32m[0907 15-09-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31237, current rewards: -4821.81709, mean: -1.96009
[32m[0907 15-09-21 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 15-09-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-09-22 @MBExp.py:227][0m Rewards obtained: [-4901.817085879591], Lows: [2424], Highs: [61], Total time: 81986.655624
[32m[0907 15-12-29 @MBExp.py:144][0m ####################################################################
[32m[0907 15-12-29 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 15-12-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31763, current rewards: -8.95105, mean: -0.89510
[32m[0907 15-12-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30025, current rewards: -89.76707, mean: -1.49612
[32m[0907 15-13-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29673, current rewards: -177.47635, mean: -1.61342
[32m[0907 15-13-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29534, current rewards: -264.26801, mean: -1.65168
[32m[0907 15-13-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29638, current rewards: -349.13780, mean: -1.66256
[32m[0907 15-13-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29704, current rewards: -431.32626, mean: -1.65895
[32m[0907 15-14-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29847, current rewards: -516.99310, mean: -1.66772
[32m[0907 15-14-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29862, current rewards: -616.99310, mean: -1.71387
[32m[0907 15-14-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30020, current rewards: -716.99310, mean: -1.74876
[32m[0907 15-14-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30196, current rewards: -816.99310, mean: -1.77607
[32m[0907 15-15-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30332, current rewards: -916.99310, mean: -1.79803
[32m[0907 15-15-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30454, current rewards: -1016.99310, mean: -1.81606
[32m[0907 15-15-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30554, current rewards: -1116.99310, mean: -1.83114
[32m[0907 15-15-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30637, current rewards: -1216.99310, mean: -1.84393
[32m[0907 15-16-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30705, current rewards: -1316.99310, mean: -1.85492
[32m[0907 15-16-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30763, current rewards: -1416.99310, mean: -1.86446
[32m[0907 15-16-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30809, current rewards: -1516.99310, mean: -1.87283
[32m[0907 15-16-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30855, current rewards: -1616.99310, mean: -1.88022
[32m[0907 15-17-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30891, current rewards: -1716.99310, mean: -1.88681
[32m[0907 15-17-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30925, current rewards: -1816.99310, mean: -1.89270
[32m[0907 15-17-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30956, current rewards: -1916.99310, mean: -1.89801
[32m[0907 15-17-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30984, current rewards: -2016.99310, mean: -1.90282
[32m[0907 15-18-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31011, current rewards: -2116.99310, mean: -1.90720
[32m[0907 15-18-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31037, current rewards: -2216.99310, mean: -1.91120
[32m[0907 15-18-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31059, current rewards: -2316.99310, mean: -1.91487
[32m[0907 15-19-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31079, current rewards: -2416.99310, mean: -1.91825
[32m[0907 15-19-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31099, current rewards: -2516.99310, mean: -1.92137
[32m[0907 15-19-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31120, current rewards: -2616.99310, mean: -1.92426
[32m[0907 15-19-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31134, current rewards: -2716.99310, mean: -1.92695
[32m[0907 15-20-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31147, current rewards: -2816.99310, mean: -1.92945
[32m[0907 15-20-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31159, current rewards: -2916.99310, mean: -1.93178
[32m[0907 15-20-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31146, current rewards: -3016.99310, mean: -1.93397
[32m[0907 15-20-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31131, current rewards: -3116.99310, mean: -1.93602
[32m[0907 15-21-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31119, current rewards: -3216.99310, mean: -1.93795
[32m[0907 15-21-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31111, current rewards: -3316.99310, mean: -1.93976
[32m[0907 15-21-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31100, current rewards: -3416.99310, mean: -1.94147
[32m[0907 15-21-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31090, current rewards: -3516.99310, mean: -1.94309
[32m[0907 15-22-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31079, current rewards: -3616.99310, mean: -1.94462
[32m[0907 15-22-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31071, current rewards: -3716.99310, mean: -1.94607
[32m[0907 15-22-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31063, current rewards: -3816.99310, mean: -1.94745
[32m[0907 15-22-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31056, current rewards: -3916.99310, mean: -1.94875
[32m[0907 15-23-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31049, current rewards: -4016.99310, mean: -1.95000
[32m[0907 15-23-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31041, current rewards: -4116.99310, mean: -1.95118
[32m[0907 15-23-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31045, current rewards: -4216.99310, mean: -1.95231
[32m[0907 15-23-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31060, current rewards: -4316.99310, mean: -1.95339
[32m[0907 15-24-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31072, current rewards: -4416.99310, mean: -1.95442
[32m[0907 15-24-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31083, current rewards: -4516.99310, mean: -1.95541
[32m[0907 15-24-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31094, current rewards: -4616.99310, mean: -1.95635
[32m[0907 15-24-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31105, current rewards: -4716.99310, mean: -1.95726
[32m[0907 15-25-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31114, current rewards: -4816.99310, mean: -1.95813
[32m[0907 15-25-27 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 15-25-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-25-27 @MBExp.py:227][0m Rewards obtained: [-4896.993096644834], Lows: [2416], Highs: [67], Total time: 82765.49414600001
[32m[0907 15-28-36 @MBExp.py:144][0m ####################################################################
[32m[0907 15-28-36 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 15-28-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28738, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-28-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29034, current rewards: -62.00000, mean: -1.03333
[32m[0907 15-29-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29081, current rewards: -112.00000, mean: -1.01818
[32m[0907 15-29-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29076, current rewards: -162.00000, mean: -1.01250
[32m[0907 15-29-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29294, current rewards: -212.00000, mean: -1.00952
[32m[0907 15-29-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29404, current rewards: -262.00000, mean: -1.00769
[32m[0907 15-30-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29490, current rewards: -312.00000, mean: -1.00645
[32m[0907 15-30-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29548, current rewards: -362.00000, mean: -1.00556
[32m[0907 15-30-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29705, current rewards: -412.00000, mean: -1.00488
[32m[0907 15-30-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29939, current rewards: -457.57223, mean: -0.99472
[32m[0907 15-31-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30100, current rewards: -452.40012, mean: -0.88706
[32m[0907 15-31-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30232, current rewards: -449.45284, mean: -0.80259
[32m[0907 15-31-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30348, current rewards: -446.53010, mean: -0.73202
[32m[0907 15-31-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30446, current rewards: -443.60736, mean: -0.67213
[32m[0907 15-32-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30532, current rewards: -440.68462, mean: -0.62068
[32m[0907 15-32-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30600, current rewards: -437.76188, mean: -0.57600
[32m[0907 15-32-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30749, current rewards: -450.71596, mean: -0.55644
[32m[0907 15-33-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31016, current rewards: -500.71596, mean: -0.58223
[32m[0907 15-33-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31256, current rewards: -550.71596, mean: -0.60518
[32m[0907 15-33-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31464, current rewards: -600.71596, mean: -0.62575
[32m[0907 15-33-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31654, current rewards: -650.71596, mean: -0.64427
[32m[0907 15-34-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31829, current rewards: -700.71596, mean: -0.66105
[32m[0907 15-34-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31986, current rewards: -750.71596, mean: -0.67632
[32m[0907 15-34-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32129, current rewards: -800.71596, mean: -0.69027
[32m[0907 15-35-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32262, current rewards: -850.71596, mean: -0.70307
[32m[0907 15-35-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32411, current rewards: -900.71596, mean: -0.71485
[32m[0907 15-35-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32552, current rewards: -950.71596, mean: -0.72574
[32m[0907 15-36-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32653, current rewards: -1000.71596, mean: -0.73582
[32m[0907 15-36-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32754, current rewards: -1050.71596, mean: -0.74519
[32m[0907 15-36-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32847, current rewards: -1100.71596, mean: -0.75392
[32m[0907 15-36-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32927, current rewards: -1150.71596, mean: -0.76206
[32m[0907 15-37-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32977, current rewards: -1200.71596, mean: -0.76969
[32m[0907 15-37-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33021, current rewards: -1250.71596, mean: -0.77684
[32m[0907 15-37-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33064, current rewards: -1300.71596, mean: -0.78356
[32m[0907 15-38-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33105, current rewards: -1350.71596, mean: -0.78989
[32m[0907 15-38-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33145, current rewards: -1400.71596, mean: -0.79586
[32m[0907 15-38-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33182, current rewards: -1450.71596, mean: -0.80150
[32m[0907 15-38-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33218, current rewards: -1500.71596, mean: -0.80684
[32m[0907 15-39-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33249, current rewards: -1550.71596, mean: -0.81189
[32m[0907 15-39-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33278, current rewards: -1600.71596, mean: -0.81669
[32m[0907 15-39-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33309, current rewards: -1650.71596, mean: -0.82125
[32m[0907 15-40-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33335, current rewards: -1700.71596, mean: -0.82559
[32m[0907 15-40-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33362, current rewards: -1750.71596, mean: -0.82972
[32m[0907 15-40-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33399, current rewards: -1800.71596, mean: -0.83366
[32m[0907 15-40-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33444, current rewards: -1850.71596, mean: -0.83743
[32m[0907 15-41-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33484, current rewards: -1900.71596, mean: -0.84102
[32m[0907 15-41-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33526, current rewards: -1950.71596, mean: -0.84447
[32m[0907 15-41-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33564, current rewards: -2000.71596, mean: -0.84776
[32m[0907 15-42-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33600, current rewards: -2050.71596, mean: -0.85092
[32m[0907 15-42-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33634, current rewards: -2100.71596, mean: -0.85395
[32m[0907 15-42-38 @Agent.py:117][0m Average action selection time: 0.3366
[32m[0907 15-42-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-42-38 @MBExp.py:227][0m Rewards obtained: [-2140.715956198196], Lows: [2], Highs: [2159], Total time: 83607.78001000002
[32m[0907 15-46-19 @MBExp.py:144][0m ####################################################################
[32m[0907 15-46-19 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 15-46-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35617, current rewards: -3.68678, mean: -0.36868
[32m[0907 15-46-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34093, current rewards: -91.57993, mean: -1.52633
[32m[0907 15-46-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33878, current rewards: -191.57993, mean: -1.74164
[32m[0907 15-47-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33827, current rewards: -291.57993, mean: -1.82237
[32m[0907 15-47-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33788, current rewards: -391.57993, mean: -1.86467
[32m[0907 15-47-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33777, current rewards: -491.57993, mean: -1.89069
[32m[0907 15-48-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33759, current rewards: -591.57993, mean: -1.90832
[32m[0907 15-48-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33822, current rewards: -691.57993, mean: -1.92106
[32m[0907 15-48-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33957, current rewards: -791.57993, mean: -1.93068
[32m[0907 15-48-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34234, current rewards: -891.57993, mean: -1.93822
[32m[0907 15-49-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34458, current rewards: -991.57993, mean: -1.94427
[32m[0907 15-49-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34651, current rewards: -1091.57993, mean: -1.94925
[32m[0907 15-49-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34819, current rewards: -1191.57993, mean: -1.95341
[32m[0907 15-50-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34944, current rewards: -1291.57993, mean: -1.95694
[32m[0907 15-50-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35055, current rewards: -1391.57993, mean: -1.95997
[32m[0907 15-50-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35149, current rewards: -1491.57993, mean: -1.96261
[32m[0907 15-51-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35237, current rewards: -1591.57993, mean: -1.96491
[32m[0907 15-51-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35310, current rewards: -1691.57993, mean: -1.96695
[32m[0907 15-51-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35377, current rewards: -1791.57993, mean: -1.96877
[32m[0907 15-51-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35438, current rewards: -1891.57993, mean: -1.97040
[32m[0907 15-52-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35498, current rewards: -1991.57993, mean: -1.97186
[32m[0907 15-52-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35539, current rewards: -2091.57993, mean: -1.97319
[32m[0907 15-52-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35582, current rewards: -2191.57993, mean: -1.97440
[32m[0907 15-53-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35620, current rewards: -2291.57993, mean: -1.97550
[32m[0907 15-53-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35656, current rewards: -2391.57993, mean: -1.97651
[32m[0907 15-53-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35689, current rewards: -2491.57993, mean: -1.97744
[32m[0907 15-54-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35721, current rewards: -2591.57993, mean: -1.97831
[32m[0907 15-54-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35745, current rewards: -2691.57993, mean: -1.97910
[32m[0907 15-54-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35772, current rewards: -2791.57993, mean: -1.97984
[32m[0907 15-55-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35792, current rewards: -2891.57993, mean: -1.98053
[32m[0907 15-55-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35800, current rewards: -2991.57993, mean: -1.98118
[32m[0907 15-55-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35796, current rewards: -3091.57993, mean: -1.98178
[32m[0907 15-55-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35792, current rewards: -3191.57993, mean: -1.98235
[32m[0907 15-56-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35786, current rewards: -3291.57993, mean: -1.98288
[32m[0907 15-56-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35781, current rewards: -3391.57993, mean: -1.98338
[32m[0907 15-56-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35776, current rewards: -3491.57993, mean: -1.98385
[32m[0907 15-57-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35772, current rewards: -3591.57993, mean: -1.98430
[32m[0907 15-57-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35767, current rewards: -3691.57993, mean: -1.98472
[32m[0907 15-57-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35763, current rewards: -3791.57993, mean: -1.98512
[32m[0907 15-58-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35759, current rewards: -3891.57993, mean: -1.98550
[32m[0907 15-58-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35755, current rewards: -3991.57993, mean: -1.98586
[32m[0907 15-58-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35750, current rewards: -4091.57993, mean: -1.98620
[32m[0907 15-58-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35746, current rewards: -4191.57993, mean: -1.98653
[32m[0907 15-59-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35752, current rewards: -4291.57993, mean: -1.98684
[32m[0907 15-59-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35771, current rewards: -4391.57993, mean: -1.98714
[32m[0907 15-59-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35789, current rewards: -4491.57993, mean: -1.98742
[32m[0907 16-00-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35804, current rewards: -4591.57993, mean: -1.98770
[32m[0907 16-00-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35818, current rewards: -4691.57993, mean: -1.98796
[32m[0907 16-00-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35832, current rewards: -4791.57993, mean: -1.98821
[32m[0907 16-01-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35845, current rewards: -4891.57993, mean: -1.98845
[32m[0907 16-01-16 @Agent.py:117][0m Average action selection time: 0.3585
[32m[0907 16-01-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-01-16 @MBExp.py:227][0m Rewards obtained: [-4971.579934406747], Lows: [2479], Highs: [14], Total time: 84504.98492400002
[32m[0907 16-05-07 @MBExp.py:144][0m ####################################################################
[32m[0907 16-05-07 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 16-05-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33585, current rewards: 0.93331, mean: 0.09333
[32m[0907 16-05-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33775, current rewards: -77.64123, mean: -1.29402
[32m[0907 16-05-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33803, current rewards: -177.64123, mean: -1.61492
[32m[0907 16-06-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33862, current rewards: -277.64123, mean: -1.73526
[32m[0907 16-06-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33927, current rewards: -377.64123, mean: -1.79829
[32m[0907 16-06-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33899, current rewards: -477.64123, mean: -1.83708
[32m[0907 16-06-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33919, current rewards: -577.64123, mean: -1.86336
[32m[0907 16-07-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33913, current rewards: -677.64123, mean: -1.88234
[32m[0907 16-07-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34009, current rewards: -777.64123, mean: -1.89669
[32m[0907 16-07-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34258, current rewards: -877.64123, mean: -1.90792
[32m[0907 16-08-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34478, current rewards: -977.64123, mean: -1.91694
[32m[0907 16-08-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34664, current rewards: -1077.64123, mean: -1.92436
[32m[0907 16-08-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34822, current rewards: -1177.64123, mean: -1.93056
[32m[0907 16-08-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34949, current rewards: -1277.64123, mean: -1.93582
[32m[0907 16-09-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35057, current rewards: -1377.64123, mean: -1.94034
[32m[0907 16-09-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35151, current rewards: -1477.64123, mean: -1.94426
[32m[0907 16-09-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35231, current rewards: -1577.64123, mean: -1.94771
[32m[0907 16-10-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35305, current rewards: -1677.64123, mean: -1.95075
[32m[0907 16-10-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35366, current rewards: -1777.64123, mean: -1.95345
[32m[0907 16-10-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35428, current rewards: -1877.64123, mean: -1.95588
[32m[0907 16-11-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35483, current rewards: -1977.64123, mean: -1.95806
[32m[0907 16-11-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35532, current rewards: -2077.64123, mean: -1.96004
[32m[0907 16-11-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35569, current rewards: -2177.64123, mean: -1.96184
[32m[0907 16-12-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35606, current rewards: -2277.64123, mean: -1.96348
[32m[0907 16-12-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35642, current rewards: -2377.64123, mean: -1.96499
[32m[0907 16-12-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35674, current rewards: -2477.64123, mean: -1.96638
[32m[0907 16-12-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35705, current rewards: -2577.64123, mean: -1.96767
[32m[0907 16-13-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35728, current rewards: -2677.64123, mean: -1.96885
[32m[0907 16-13-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35752, current rewards: -2777.64123, mean: -1.96996
[32m[0907 16-13-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35776, current rewards: -2877.64123, mean: -1.97099
[32m[0907 16-14-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35775, current rewards: -2977.64123, mean: -1.97195
[32m[0907 16-14-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35769, current rewards: -3077.64123, mean: -1.97285
[32m[0907 16-14-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35765, current rewards: -3177.64123, mean: -1.97369
[32m[0907 16-15-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35758, current rewards: -3277.64123, mean: -1.97448
[32m[0907 16-15-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35755, current rewards: -3377.64123, mean: -1.97523
[32m[0907 16-15-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35753, current rewards: -3477.64123, mean: -1.97593
[32m[0907 16-15-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35750, current rewards: -3577.64123, mean: -1.97660
[32m[0907 16-16-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35749, current rewards: -3677.64123, mean: -1.97723
[32m[0907 16-16-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35742, current rewards: -3777.64123, mean: -1.97782
[32m[0907 16-16-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35739, current rewards: -3877.64123, mean: -1.97839
[32m[0907 16-17-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35736, current rewards: -3977.64123, mean: -1.97893
[32m[0907 16-17-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35730, current rewards: -4077.64123, mean: -1.97944
[32m[0907 16-17-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35726, current rewards: -4177.64123, mean: -1.97992
[32m[0907 16-17-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35739, current rewards: -4277.64123, mean: -1.98039
[32m[0907 16-18-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35757, current rewards: -4377.64123, mean: -1.98083
[32m[0907 16-18-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35773, current rewards: -4477.64123, mean: -1.98126
[32m[0907 16-18-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35788, current rewards: -4577.64123, mean: -1.98166
[32m[0907 16-19-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35805, current rewards: -4677.64123, mean: -1.98205
[32m[0907 16-19-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35818, current rewards: -4777.64123, mean: -1.98242
[32m[0907 16-19-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35833, current rewards: -4877.64123, mean: -1.98278
[32m[0907 16-20-03 @Agent.py:117][0m Average action selection time: 0.3585
[32m[0907 16-20-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-20-04 @MBExp.py:227][0m Rewards obtained: [-4957.641225134668], Lows: [2480], Highs: [0], Total time: 85402.02162500002
[32m[0907 16-24-01 @MBExp.py:144][0m ####################################################################
[32m[0907 16-24-01 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 16-24-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38528, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-24-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35027, current rewards: -85.94100, mean: -1.43235
[32m[0907 16-24-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34699, current rewards: -185.94100, mean: -1.69037
[32m[0907 16-24-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34906, current rewards: -257.87139, mean: -1.61170
[32m[0907 16-25-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34788, current rewards: -346.60559, mean: -1.65050
[32m[0907 16-25-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34689, current rewards: -446.60559, mean: -1.71771
[32m[0907 16-25-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34635, current rewards: -546.60559, mean: -1.76324
[32m[0907 16-26-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34586, current rewards: -646.60559, mean: -1.79613
[32m[0907 16-26-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34667, current rewards: -746.60559, mean: -1.82099
[32m[0907 16-26-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34881, current rewards: -846.60559, mean: -1.84045
[32m[0907 16-27-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35117, current rewards: -946.60559, mean: -1.85609
[32m[0907 16-27-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35309, current rewards: -1046.60559, mean: -1.86894
[32m[0907 16-27-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35470, current rewards: -1146.60559, mean: -1.87968
[32m[0907 16-27-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35606, current rewards: -1246.60559, mean: -1.88880
[32m[0907 16-28-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35722, current rewards: -1346.60559, mean: -1.89663
[32m[0907 16-28-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35824, current rewards: -1446.60559, mean: -1.90343
[32m[0907 16-28-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35908, current rewards: -1546.60559, mean: -1.90939
[32m[0907 16-29-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35979, current rewards: -1646.60559, mean: -1.91466
[32m[0907 16-29-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36042, current rewards: -1746.60559, mean: -1.91935
[32m[0907 16-29-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36098, current rewards: -1846.60559, mean: -1.92355
[32m[0907 16-30-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36141, current rewards: -1946.60559, mean: -1.92733
[32m[0907 16-30-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36187, current rewards: -2046.60559, mean: -1.93076
[32m[0907 16-30-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36225, current rewards: -2146.60559, mean: -1.93388
[32m[0907 16-31-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36263, current rewards: -2246.60559, mean: -1.93673
[32m[0907 16-31-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36299, current rewards: -2346.60559, mean: -1.93934
[32m[0907 16-31-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36332, current rewards: -2446.60559, mean: -1.94175
[32m[0907 16-31-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36359, current rewards: -2546.60559, mean: -1.94397
[32m[0907 16-32-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36381, current rewards: -2646.60559, mean: -1.94603
[32m[0907 16-32-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36410, current rewards: -2746.60559, mean: -1.94795
[32m[0907 16-32-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36433, current rewards: -2846.60559, mean: -1.94973
[32m[0907 16-33-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36457, current rewards: -2946.60559, mean: -1.95139
[32m[0907 16-33-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36455, current rewards: -3046.60559, mean: -1.95295
[32m[0907 16-33-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36449, current rewards: -3146.60559, mean: -1.95441
[32m[0907 16-34-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36442, current rewards: -3246.60559, mean: -1.95579
[32m[0907 16-34-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36435, current rewards: -3346.60559, mean: -1.95708
[32m[0907 16-34-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36429, current rewards: -3446.60559, mean: -1.95830
[32m[0907 16-35-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36424, current rewards: -3546.60559, mean: -1.95945
[32m[0907 16-35-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36418, current rewards: -3646.60559, mean: -1.96054
[32m[0907 16-35-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36415, current rewards: -3746.60559, mean: -1.96157
[32m[0907 16-35-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36411, current rewards: -3846.60559, mean: -1.96255
[32m[0907 16-36-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36408, current rewards: -3946.60559, mean: -1.96349
[32m[0907 16-36-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36405, current rewards: -4046.60559, mean: -1.96437
[32m[0907 16-36-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36400, current rewards: -4146.60559, mean: -1.96522
[32m[0907 16-37-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36394, current rewards: -4246.60559, mean: -1.96602
[32m[0907 16-37-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36396, current rewards: -4346.60559, mean: -1.96679
[32m[0907 16-37-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36412, current rewards: -4446.60559, mean: -1.96752
[32m[0907 16-38-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36425, current rewards: -4546.60559, mean: -1.96823
[32m[0907 16-38-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36439, current rewards: -4646.60559, mean: -1.96890
[32m[0907 16-38-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36454, current rewards: -4746.60559, mean: -1.96955
[32m[0907 16-38-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36466, current rewards: -4846.60559, mean: -1.97016
[32m[0907 16-39-14 @Agent.py:117][0m Average action selection time: 0.3648
[32m[0907 16-39-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-39-14 @MBExp.py:227][0m Rewards obtained: [-4926.605585135461], Lows: [2437], Highs: [54], Total time: 86314.80277700002
[32m[0907 16-43-14 @MBExp.py:144][0m ####################################################################
[32m[0907 16-43-14 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 16-43-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34436, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-43-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34381, current rewards: -60.00000, mean: -1.00000
[32m[0907 16-43-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34407, current rewards: -110.00000, mean: -1.00000
[32m[0907 16-44-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34394, current rewards: -160.00000, mean: -1.00000
[32m[0907 16-44-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34367, current rewards: -210.00000, mean: -1.00000
[32m[0907 16-44-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34362, current rewards: -260.00000, mean: -1.00000
[32m[0907 16-45-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34338, current rewards: -310.00000, mean: -1.00000
[32m[0907 16-45-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34323, current rewards: -360.00000, mean: -1.00000
[32m[0907 16-45-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34315, current rewards: -410.00000, mean: -1.00000
[32m[0907 16-45-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34478, current rewards: -460.00000, mean: -1.00000
[32m[0907 16-46-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34736, current rewards: -510.00000, mean: -1.00000
[32m[0907 16-46-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34946, current rewards: -560.00000, mean: -1.00000
[32m[0907 16-46-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35125, current rewards: -610.00000, mean: -1.00000
[32m[0907 16-47-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35283, current rewards: -660.00000, mean: -1.00000
[32m[0907 16-47-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35413, current rewards: -710.00000, mean: -1.00000
[32m[0907 16-47-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35523, current rewards: -760.00000, mean: -1.00000
[32m[0907 16-48-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35611, current rewards: -810.00000, mean: -1.00000
[32m[0907 16-48-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35689, current rewards: -860.00000, mean: -1.00000
[32m[0907 16-48-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35764, current rewards: -910.00000, mean: -1.00000
[32m[0907 16-48-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35829, current rewards: -960.00000, mean: -1.00000
[32m[0907 16-49-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35884, current rewards: -1010.00000, mean: -1.00000
[32m[0907 16-49-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35935, current rewards: -1060.00000, mean: -1.00000
[32m[0907 16-49-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35982, current rewards: -1110.00000, mean: -1.00000
[32m[0907 16-50-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36028, current rewards: -1160.00000, mean: -1.00000
[32m[0907 16-50-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36076, current rewards: -1210.00000, mean: -1.00000
[32m[0907 16-50-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36110, current rewards: -1260.00000, mean: -1.00000
[32m[0907 16-51-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36142, current rewards: -1310.00000, mean: -1.00000
[32m[0907 16-51-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36172, current rewards: -1360.00000, mean: -1.00000
[32m[0907 16-51-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36205, current rewards: -1410.00000, mean: -1.00000
[32m[0907 16-52-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36236, current rewards: -1460.00000, mean: -1.00000
[32m[0907 16-52-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36260, current rewards: -1510.00000, mean: -1.00000
[32m[0907 16-52-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36257, current rewards: -1560.00000, mean: -1.00000
[32m[0907 16-52-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36255, current rewards: -1610.00000, mean: -1.00000
[32m[0907 16-53-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36251, current rewards: -1660.00000, mean: -1.00000
[32m[0907 16-53-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36248, current rewards: -1710.00000, mean: -1.00000
[32m[0907 16-53-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36247, current rewards: -1760.00000, mean: -1.00000
[32m[0907 16-54-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36244, current rewards: -1810.00000, mean: -1.00000
[32m[0907 16-54-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36241, current rewards: -1860.00000, mean: -1.00000
[32m[0907 16-54-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36239, current rewards: -1910.00000, mean: -1.00000
[32m[0907 16-55-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36235, current rewards: -1960.00000, mean: -1.00000
[32m[0907 16-55-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36233, current rewards: -2010.00000, mean: -1.00000
[32m[0907 16-55-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36233, current rewards: -2060.00000, mean: -1.00000
[32m[0907 16-55-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36232, current rewards: -2110.00000, mean: -1.00000
[32m[0907 16-56-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36232, current rewards: -2160.00000, mean: -1.00000
[32m[0907 16-56-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36243, current rewards: -2210.00000, mean: -1.00000
[32m[0907 16-56-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36263, current rewards: -2260.00000, mean: -1.00000
[32m[0907 16-57-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36281, current rewards: -2310.00000, mean: -1.00000
[32m[0907 16-57-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36300, current rewards: -2360.00000, mean: -1.00000
[32m[0907 16-57-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36316, current rewards: -2410.00000, mean: -1.00000
[32m[0907 16-58-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36330, current rewards: -2458.95199, mean: -0.99957
[32m[0907 16-58-23 @Agent.py:117][0m Average action selection time: 0.3634
[32m[0907 16-58-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-58-23 @MBExp.py:227][0m Rewards obtained: [-2457.0314462750716], Lows: [0], Highs: [2459], Total time: 87224.21632700002
[32m[0907 17-02-25 @MBExp.py:144][0m ####################################################################
[32m[0907 17-02-25 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 17-02-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34190, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-02-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34264, current rewards: -85.83208, mean: -1.43053
[32m[0907 17-03-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34291, current rewards: -185.83208, mean: -1.68938
[32m[0907 17-03-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34287, current rewards: -285.83208, mean: -1.78645
[32m[0907 17-03-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34291, current rewards: -385.83208, mean: -1.83730
[32m[0907 17-03-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34302, current rewards: -485.83208, mean: -1.86858
[32m[0907 17-04-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34304, current rewards: -585.83208, mean: -1.88978
[32m[0907 17-04-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34309, current rewards: -685.83208, mean: -1.90509
[32m[0907 17-04-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34304, current rewards: -785.83208, mean: -1.91666
[32m[0907 17-05-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34398, current rewards: -885.83208, mean: -1.92572
[32m[0907 17-05-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34681, current rewards: -985.83208, mean: -1.93300
[32m[0907 17-05-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34906, current rewards: -1085.83208, mean: -1.93899
[32m[0907 17-05-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35095, current rewards: -1185.83208, mean: -1.94399
[32m[0907 17-06-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35260, current rewards: -1285.83208, mean: -1.94823
[32m[0907 17-06-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35392, current rewards: -1377.83208, mean: -1.94061
[32m[0907 17-06-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35561, current rewards: -1448.87913, mean: -1.90642
[32m[0907 17-07-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35656, current rewards: -1522.69096, mean: -1.87987
[32m[0907 17-07-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35742, current rewards: -1615.64038, mean: -1.87865
[32m[0907 17-07-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35822, current rewards: -1715.64038, mean: -1.88532
[32m[0907 17-08-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35888, current rewards: -1815.64038, mean: -1.89129
[32m[0907 17-08-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35950, current rewards: -1915.64038, mean: -1.89667
[32m[0907 17-08-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36003, current rewards: -2015.64038, mean: -1.90155
[32m[0907 17-09-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36055, current rewards: -2115.64038, mean: -1.90598
[32m[0907 17-09-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36102, current rewards: -2215.64038, mean: -1.91003
[32m[0907 17-09-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36144, current rewards: -2315.64038, mean: -1.91375
[32m[0907 17-10-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36215, current rewards: -2384.10570, mean: -1.89215
[32m[0907 17-10-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36251, current rewards: -2484.10570, mean: -1.89626
[32m[0907 17-10-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36279, current rewards: -2584.10570, mean: -1.90008
[32m[0907 17-10-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36304, current rewards: -2684.10570, mean: -1.90362
[32m[0907 17-11-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36328, current rewards: -2784.10570, mean: -1.90692
[32m[0907 17-11-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36351, current rewards: -2884.10570, mean: -1.91000
[32m[0907 17-11-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36371, current rewards: -2984.10570, mean: -1.91289
[32m[0907 17-12-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36394, current rewards: -3084.10570, mean: -1.91559
[32m[0907 17-12-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36410, current rewards: -3184.10570, mean: -1.91814
[32m[0907 17-12-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36427, current rewards: -3284.10570, mean: -1.92053
[32m[0907 17-13-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36440, current rewards: -3384.10570, mean: -1.92279
[32m[0907 17-13-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36457, current rewards: -3484.10570, mean: -1.92492
[32m[0907 17-13-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36454, current rewards: -3584.10570, mean: -1.92694
[32m[0907 17-14-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36448, current rewards: -3684.10570, mean: -1.92885
[32m[0907 17-14-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36440, current rewards: -3784.10570, mean: -1.93067
[32m[0907 17-14-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36433, current rewards: -3884.10570, mean: -1.93239
[32m[0907 17-14-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36425, current rewards: -3984.10570, mean: -1.93403
[32m[0907 17-15-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36418, current rewards: -4084.10570, mean: -1.93560
[32m[0907 17-15-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36413, current rewards: -4184.10570, mean: -1.93709
[32m[0907 17-15-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36406, current rewards: -4284.10570, mean: -1.93851
[32m[0907 17-16-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36400, current rewards: -4384.10570, mean: -1.93987
[32m[0907 17-16-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36394, current rewards: -4484.10570, mean: -1.94117
[32m[0907 17-16-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36388, current rewards: -4584.10570, mean: -1.94242
[32m[0907 17-17-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36383, current rewards: -4684.10570, mean: -1.94361
[32m[0907 17-17-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36377, current rewards: -4784.10570, mean: -1.94476
[32m[0907 17-17-35 @Agent.py:117][0m Average action selection time: 0.3637
[32m[0907 17-17-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-17-35 @MBExp.py:227][0m Rewards obtained: [-4864.105700234286], Lows: [2379], Highs: [108], Total time: 88134.45302500001
[32m[0907 17-21-40 @MBExp.py:144][0m ####################################################################
[32m[0907 17-21-40 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 17-21-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.56750, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-22-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.56746, current rewards: -50.46575, mean: -0.84110
[32m[0907 17-22-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.50571, current rewards: -150.46575, mean: -1.36787
[32m[0907 17-22-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.45447, current rewards: -250.46575, mean: -1.56541
[32m[0907 17-23-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.42793, current rewards: -350.46575, mean: -1.66888
[32m[0907 17-23-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.41149, current rewards: -450.46575, mean: -1.73256
[32m[0907 17-23-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.40026, current rewards: -550.46575, mean: -1.77570
[32m[0907 17-24-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.39229, current rewards: -650.46575, mean: -1.80685
[32m[0907 17-24-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.38677, current rewards: -750.46575, mean: -1.83040
[32m[0907 17-24-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.38489, current rewards: -850.46575, mean: -1.84884
[32m[0907 17-24-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.38368, current rewards: -950.46575, mean: -1.86366
[32m[0907 17-25-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38265, current rewards: -1050.46575, mean: -1.87583
[32m[0907 17-25-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.38177, current rewards: -1150.46575, mean: -1.88601
[32m[0907 17-25-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.38094, current rewards: -1250.46575, mean: -1.89465
[32m[0907 17-26-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.38022, current rewards: -1350.46575, mean: -1.90206
[32m[0907 17-26-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37957, current rewards: -1450.46575, mean: -1.90851
[32m[0907 17-26-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37906, current rewards: -1550.46575, mean: -1.91416
[32m[0907 17-27-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37854, current rewards: -1650.46575, mean: -1.91915
[32m[0907 17-27-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37816, current rewards: -1750.46575, mean: -1.92359
[32m[0907 17-27-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37774, current rewards: -1850.46575, mean: -1.92757
[32m[0907 17-28-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37739, current rewards: -1950.46575, mean: -1.93115
[32m[0907 17-28-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37707, current rewards: -2050.46575, mean: -1.93440
[32m[0907 17-28-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37677, current rewards: -2150.46575, mean: -1.93736
[32m[0907 17-28-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37649, current rewards: -2250.46575, mean: -1.94006
[32m[0907 17-29-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37620, current rewards: -2350.46575, mean: -1.94253
[32m[0907 17-29-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37593, current rewards: -2450.46575, mean: -1.94481
[32m[0907 17-29-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37574, current rewards: -2550.46575, mean: -1.94692
[32m[0907 17-30-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37554, current rewards: -2650.46575, mean: -1.94887
[32m[0907 17-30-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37537, current rewards: -2750.46575, mean: -1.95068
[32m[0907 17-30-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37518, current rewards: -2850.46575, mean: -1.95237
[32m[0907 17-31-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37499, current rewards: -2950.46575, mean: -1.95395
[32m[0907 17-31-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37489, current rewards: -3050.46575, mean: -1.95543
[32m[0907 17-31-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37475, current rewards: -3150.46575, mean: -1.95681
[32m[0907 17-32-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37464, current rewards: -3250.46575, mean: -1.95811
[32m[0907 17-32-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37453, current rewards: -3350.46575, mean: -1.95934
[32m[0907 17-32-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37442, current rewards: -3450.46575, mean: -1.96049
[32m[0907 17-32-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37415, current rewards: -3550.46575, mean: -1.96158
[32m[0907 17-33-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37379, current rewards: -3650.46575, mean: -1.96262
[32m[0907 17-33-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37348, current rewards: -3750.46575, mean: -1.96359
[32m[0907 17-33-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37317, current rewards: -3850.46575, mean: -1.96452
[32m[0907 17-34-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37287, current rewards: -3950.46575, mean: -1.96541
[32m[0907 17-34-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37260, current rewards: -4050.46575, mean: -1.96625
[32m[0907 17-34-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37233, current rewards: -4150.46575, mean: -1.96705
[32m[0907 17-35-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37208, current rewards: -4250.46575, mean: -1.96781
[32m[0907 17-35-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37181, current rewards: -4350.46575, mean: -1.96854
[32m[0907 17-35-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37157, current rewards: -4450.46575, mean: -1.96923
[32m[0907 17-35-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37133, current rewards: -4550.46575, mean: -1.96990
[32m[0907 17-36-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37113, current rewards: -4650.46575, mean: -1.97054
[32m[0907 17-36-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37093, current rewards: -4750.46575, mean: -1.97115
[32m[0907 17-36-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37074, current rewards: -4850.46575, mean: -1.97173
[32m[0907 17-37-07 @Agent.py:117][0m Average action selection time: 0.3707
[32m[0907 17-37-07 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-37-07 @MBExp.py:227][0m Rewards obtained: [-4930.46574887708], Lows: [2454], Highs: [25], Total time: 89062.09565300001
[32m[0907 17-41-13 @MBExp.py:144][0m ####################################################################
[32m[0907 17-41-13 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 17-41-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34043, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-41-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34279, current rewards: -60.00000, mean: -1.00000
[32m[0907 17-41-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34350, current rewards: -110.00000, mean: -1.00000
[32m[0907 17-42-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34324, current rewards: -160.00000, mean: -1.00000
[32m[0907 17-42-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34311, current rewards: -210.00000, mean: -1.00000
[32m[0907 17-42-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34323, current rewards: -260.00000, mean: -1.00000
[32m[0907 17-43-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34320, current rewards: -310.00000, mean: -1.00000
[32m[0907 17-43-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34333, current rewards: -360.00000, mean: -1.00000
[32m[0907 17-43-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34355, current rewards: -410.00000, mean: -1.00000
[32m[0907 17-43-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34598, current rewards: -460.00000, mean: -1.00000
[32m[0907 17-44-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34840, current rewards: -510.00000, mean: -1.00000
[32m[0907 17-44-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35047, current rewards: -560.00000, mean: -1.00000
[32m[0907 17-44-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35224, current rewards: -610.00000, mean: -1.00000
[32m[0907 17-45-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35370, current rewards: -660.00000, mean: -1.00000
[32m[0907 17-45-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35495, current rewards: -710.00000, mean: -1.00000
[32m[0907 17-45-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35609, current rewards: -760.00000, mean: -1.00000
[32m[0907 17-46-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35701, current rewards: -810.00000, mean: -1.00000
[32m[0907 17-46-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35786, current rewards: -860.00000, mean: -1.00000
[32m[0907 17-46-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35865, current rewards: -910.00000, mean: -1.00000
[32m[0907 17-46-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35932, current rewards: -960.00000, mean: -1.00000
[32m[0907 17-47-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35992, current rewards: -1010.00000, mean: -1.00000
[32m[0907 17-47-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36040, current rewards: -1060.00000, mean: -1.00000
[32m[0907 17-47-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36084, current rewards: -1110.00000, mean: -1.00000
[32m[0907 17-48-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36130, current rewards: -1160.00000, mean: -1.00000
[32m[0907 17-48-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36169, current rewards: -1210.00000, mean: -1.00000
[32m[0907 17-48-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36200, current rewards: -1260.00000, mean: -1.00000
[32m[0907 17-49-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36233, current rewards: -1310.00000, mean: -1.00000
[32m[0907 17-49-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36261, current rewards: -1360.00000, mean: -1.00000
[32m[0907 17-49-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36286, current rewards: -1410.00000, mean: -1.00000
[32m[0907 17-50-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36313, current rewards: -1460.00000, mean: -1.00000
[32m[0907 17-50-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36337, current rewards: -1510.00000, mean: -1.00000
[32m[0907 17-50-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36361, current rewards: -1538.84271, mean: -0.98644
[32m[0907 17-51-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36387, current rewards: -1533.16565, mean: -0.95228
[32m[0907 17-51-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36407, current rewards: -1528.02958, mean: -0.92050
[32m[0907 17-51-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36429, current rewards: -1524.11239, mean: -0.89129
[32m[0907 17-51-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36446, current rewards: -1520.19521, mean: -0.86375
[32m[0907 17-52-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36451, current rewards: -1520.59140, mean: -0.84011
[32m[0907 17-52-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36446, current rewards: -1570.59140, mean: -0.84440
[32m[0907 17-52-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36441, current rewards: -1620.59140, mean: -0.84848
[32m[0907 17-53-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36437, current rewards: -1670.59140, mean: -0.85234
[32m[0907 17-53-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36432, current rewards: -1720.59140, mean: -0.85602
[32m[0907 17-53-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36427, current rewards: -1770.59140, mean: -0.85951
[32m[0907 17-54-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36422, current rewards: -1820.59140, mean: -0.86284
[32m[0907 17-54-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36416, current rewards: -1870.59140, mean: -0.86601
[32m[0907 17-54-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36411, current rewards: -1920.59140, mean: -0.86905
[32m[0907 17-54-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36408, current rewards: -1970.59140, mean: -0.87194
[32m[0907 17-55-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36403, current rewards: -2020.59140, mean: -0.87471
[32m[0907 17-55-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36400, current rewards: -2070.59140, mean: -0.87737
[32m[0907 17-55-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36397, current rewards: -2120.59140, mean: -0.87991
[32m[0907 17-56-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36396, current rewards: -2170.59140, mean: -0.88235
[32m[0907 17-56-24 @Agent.py:117][0m Average action selection time: 0.3640
[32m[0907 17-56-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-56-24 @MBExp.py:227][0m Rewards obtained: [-2210.591397203062], Lows: [0], Highs: [2235], Total time: 89973.04812200001
[32m[0907 18-00-34 @MBExp.py:144][0m ####################################################################
[32m[0907 18-00-34 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 18-00-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35077, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-00-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34451, current rewards: -58.63554, mean: -0.97726
[32m[0907 18-01-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34346, current rewards: -108.63554, mean: -0.98760
[32m[0907 18-01-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34341, current rewards: -158.63554, mean: -0.99147
[32m[0907 18-01-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34323, current rewards: -208.63554, mean: -0.99350
[32m[0907 18-02-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34329, current rewards: -258.63554, mean: -0.99475
[32m[0907 18-02-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34301, current rewards: -308.63554, mean: -0.99560
[32m[0907 18-02-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34311, current rewards: -358.63554, mean: -0.99621
[32m[0907 18-02-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34308, current rewards: -408.63554, mean: -0.99667
[32m[0907 18-03-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34397, current rewards: -458.63554, mean: -0.99703
[32m[0907 18-03-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34680, current rewards: -508.63554, mean: -0.99732
[32m[0907 18-03-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34898, current rewards: -558.63554, mean: -0.99756
[32m[0907 18-04-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35088, current rewards: -608.63554, mean: -0.99776
[32m[0907 18-04-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35246, current rewards: -658.63554, mean: -0.99793
[32m[0907 18-04-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35382, current rewards: -708.63554, mean: -0.99808
[32m[0907 18-05-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35498, current rewards: -758.63554, mean: -0.99820
[32m[0907 18-05-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35594, current rewards: -808.63554, mean: -0.99832
[32m[0907 18-05-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35688, current rewards: -858.63554, mean: -0.99841
[32m[0907 18-05-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35769, current rewards: -908.63554, mean: -0.99850
[32m[0907 18-06-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35839, current rewards: -958.63554, mean: -0.99858
[32m[0907 18-06-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35902, current rewards: -1008.63554, mean: -0.99865
[32m[0907 18-06-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35961, current rewards: -1058.63554, mean: -0.99871
[32m[0907 18-07-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36014, current rewards: -1108.63554, mean: -0.99877
[32m[0907 18-07-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36058, current rewards: -1158.63554, mean: -0.99882
[32m[0907 18-07-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36095, current rewards: -1203.37322, mean: -0.99452
[32m[0907 18-08-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36135, current rewards: -1247.01102, mean: -0.98969
[32m[0907 18-08-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36169, current rewards: -1297.01102, mean: -0.99008
[32m[0907 18-08-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36204, current rewards: -1347.01102, mean: -0.99045
[32m[0907 18-09-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36237, current rewards: -1397.01102, mean: -0.99079
[32m[0907 18-09-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36266, current rewards: -1447.01102, mean: -0.99110
[32m[0907 18-09-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36290, current rewards: -1497.01102, mean: -0.99140
[32m[0907 18-10-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36314, current rewards: -1547.01102, mean: -0.99167
[32m[0907 18-10-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36338, current rewards: -1597.01102, mean: -0.99193
[32m[0907 18-10-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36359, current rewards: -1647.01102, mean: -0.99218
[32m[0907 18-10-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36379, current rewards: -1697.01102, mean: -0.99240
[32m[0907 18-11-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36400, current rewards: -1747.01102, mean: -0.99262
[32m[0907 18-11-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36393, current rewards: -1797.01102, mean: -0.99282
[32m[0907 18-11-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36387, current rewards: -1847.01102, mean: -0.99302
[32m[0907 18-12-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36380, current rewards: -1897.01102, mean: -0.99320
[32m[0907 18-12-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36376, current rewards: -1947.01102, mean: -0.99337
[32m[0907 18-12-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36373, current rewards: -1997.01102, mean: -0.99354
[32m[0907 18-13-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36368, current rewards: -2047.01102, mean: -0.99369
[32m[0907 18-13-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36363, current rewards: -2097.01102, mean: -0.99384
[32m[0907 18-13-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36361, current rewards: -2147.01102, mean: -0.99399
[32m[0907 18-13-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36359, current rewards: -2197.01102, mean: -0.99412
[32m[0907 18-14-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36357, current rewards: -2247.01102, mean: -0.99425
[32m[0907 18-14-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36356, current rewards: -2297.01102, mean: -0.99438
[32m[0907 18-14-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36354, current rewards: -2347.01102, mean: -0.99450
[32m[0907 18-15-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36353, current rewards: -2397.01102, mean: -0.99461
[32m[0907 18-15-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36351, current rewards: -2447.01102, mean: -0.99472
[32m[0907 18-15-43 @Agent.py:117][0m Average action selection time: 0.3637
[32m[0907 18-15-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-15-44 @MBExp.py:227][0m Rewards obtained: [-2487.0110201406524], Lows: [1], Highs: [2486], Total time: 90883.05945
[32m[0907 18-19-55 @MBExp.py:144][0m ####################################################################
[32m[0907 18-19-55 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 18-19-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34191, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-20-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34254, current rewards: -43.81109, mean: -0.73018
[32m[0907 18-20-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34308, current rewards: -93.81109, mean: -0.85283
[32m[0907 18-20-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34343, current rewards: -143.81109, mean: -0.89882
[32m[0907 18-21-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34321, current rewards: -193.81109, mean: -0.92291
[32m[0907 18-21-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34325, current rewards: -243.81109, mean: -0.93773
[32m[0907 18-21-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34319, current rewards: -293.81109, mean: -0.94778
[32m[0907 18-21-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34316, current rewards: -343.81109, mean: -0.95503
[32m[0907 18-22-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34311, current rewards: -393.81109, mean: -0.96051
[32m[0907 18-22-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34328, current rewards: -443.81109, mean: -0.96481
[32m[0907 18-22-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34594, current rewards: -493.81109, mean: -0.96826
[32m[0907 18-23-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34813, current rewards: -543.81109, mean: -0.97109
[32m[0907 18-23-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35003, current rewards: -593.81109, mean: -0.97346
[32m[0907 18-23-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35170, current rewards: -643.81109, mean: -0.97547
[32m[0907 18-24-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35317, current rewards: -662.35158, mean: -0.93289
[32m[0907 18-24-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35442, current rewards: -656.39409, mean: -0.86368
[32m[0907 18-24-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35544, current rewards: -653.84426, mean: -0.80722
[32m[0907 18-25-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35636, current rewards: -651.45660, mean: -0.75751
[32m[0907 18-25-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35709, current rewards: -649.06894, mean: -0.71326
[32m[0907 18-25-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35778, current rewards: -692.78243, mean: -0.72165
[32m[0907 18-25-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35842, current rewards: -742.78243, mean: -0.73543
[32m[0907 18-26-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35900, current rewards: -792.78243, mean: -0.74791
[32m[0907 18-26-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35949, current rewards: -842.78243, mean: -0.75926
[32m[0907 18-26-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35998, current rewards: -892.78243, mean: -0.76964
[32m[0907 18-27-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36040, current rewards: -942.78243, mean: -0.77916
[32m[0907 18-27-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36079, current rewards: -992.78243, mean: -0.78792
[32m[0907 18-27-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36115, current rewards: -1042.78243, mean: -0.79602
[32m[0907 18-28-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36148, current rewards: -1092.78243, mean: -0.80352
[32m[0907 18-28-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36177, current rewards: -1142.78243, mean: -0.81048
[32m[0907 18-28-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36210, current rewards: -1192.78243, mean: -0.81697
[32m[0907 18-29-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36240, current rewards: -1242.78243, mean: -0.82303
[32m[0907 18-29-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36268, current rewards: -1292.78243, mean: -0.82871
[32m[0907 18-29-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36290, current rewards: -1342.78243, mean: -0.83403
[32m[0907 18-29-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36313, current rewards: -1392.78243, mean: -0.83903
[32m[0907 18-30-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36334, current rewards: -1442.78243, mean: -0.84373
[32m[0907 18-30-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36349, current rewards: -1492.78243, mean: -0.84817
[32m[0907 18-30-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36343, current rewards: -1542.78243, mean: -0.85237
[32m[0907 18-31-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36339, current rewards: -1592.78243, mean: -0.85633
[32m[0907 18-31-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36333, current rewards: -1642.78243, mean: -0.86010
[32m[0907 18-31-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36328, current rewards: -1692.78243, mean: -0.86366
[32m[0907 18-32-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36324, current rewards: -1742.78243, mean: -0.86706
[32m[0907 18-32-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36320, current rewards: -1792.78243, mean: -0.87028
[32m[0907 18-32-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36316, current rewards: -1842.78243, mean: -0.87336
[32m[0907 18-33-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36315, current rewards: -1892.78243, mean: -0.87629
[32m[0907 18-33-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36311, current rewards: -1942.78243, mean: -0.87909
[32m[0907 18-33-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36310, current rewards: -1992.78243, mean: -0.88176
[32m[0907 18-33-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36306, current rewards: -2042.78243, mean: -0.88432
[32m[0907 18-34-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36301, current rewards: -2092.78243, mean: -0.88677
[32m[0907 18-34-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36297, current rewards: -2142.78243, mean: -0.88912
[32m[0907 18-34-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36291, current rewards: -2192.78243, mean: -0.89137
[32m[0907 18-35-03 @Agent.py:117][0m Average action selection time: 0.3630
[32m[0907 18-35-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-35-04 @MBExp.py:227][0m Rewards obtained: [-2232.782425349803], Lows: [3], Highs: [2245], Total time: 91791.484977
[32m[0907 18-39-12 @MBExp.py:144][0m ####################################################################
[32m[0907 18-39-12 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 18-39-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37014, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-39-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34833, current rewards: -87.40971, mean: -1.45683
[32m[0907 18-39-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34326, current rewards: -187.40971, mean: -1.70372
[32m[0907 18-40-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34152, current rewards: -287.40971, mean: -1.79631
[32m[0907 18-40-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34036, current rewards: -387.40971, mean: -1.84481
[32m[0907 18-40-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33966, current rewards: -487.40971, mean: -1.87465
[32m[0907 18-40-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33915, current rewards: -587.40971, mean: -1.89487
[32m[0907 18-41-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33866, current rewards: -687.40971, mean: -1.90947
[32m[0907 18-41-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33834, current rewards: -787.40971, mean: -1.92051
[32m[0907 18-41-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33815, current rewards: -887.40971, mean: -1.92915
[32m[0907 18-42-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34005, current rewards: -987.40971, mean: -1.93610
[32m[0907 18-42-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34216, current rewards: -1087.40971, mean: -1.94180
[32m[0907 18-42-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34400, current rewards: -1187.40971, mean: -1.94657
[32m[0907 18-43-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34548, current rewards: -1287.40971, mean: -1.95062
[32m[0907 18-43-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34671, current rewards: -1387.40971, mean: -1.95410
[32m[0907 18-43-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34781, current rewards: -1487.40971, mean: -1.95712
[32m[0907 18-43-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34882, current rewards: -1587.40971, mean: -1.95977
[32m[0907 18-44-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34974, current rewards: -1687.40971, mean: -1.96210
[32m[0907 18-44-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35045, current rewards: -1787.40971, mean: -1.96419
[32m[0907 18-44-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35111, current rewards: -1887.40971, mean: -1.96605
[32m[0907 18-45-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35176, current rewards: -1987.40971, mean: -1.96773
[32m[0907 18-45-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35233, current rewards: -2087.40971, mean: -1.96925
[32m[0907 18-45-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35283, current rewards: -2187.40971, mean: -1.97064
[32m[0907 18-46-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35327, current rewards: -2287.40971, mean: -1.97190
[32m[0907 18-46-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35371, current rewards: -2387.40971, mean: -1.97307
[32m[0907 18-46-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35405, current rewards: -2487.40971, mean: -1.97413
[32m[0907 18-46-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35437, current rewards: -2587.40971, mean: -1.97512
[32m[0907 18-47-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35464, current rewards: -2687.40971, mean: -1.97604
[32m[0907 18-47-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35494, current rewards: -2787.40971, mean: -1.97689
[32m[0907 18-47-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35522, current rewards: -2887.40971, mean: -1.97768
[32m[0907 18-48-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35545, current rewards: -2987.40971, mean: -1.97842
[32m[0907 18-48-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35567, current rewards: -3087.40971, mean: -1.97911
[32m[0907 18-48-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35586, current rewards: -3187.40971, mean: -1.97976
[32m[0907 18-49-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35604, current rewards: -3287.40971, mean: -1.98037
[32m[0907 18-49-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35625, current rewards: -3387.40971, mean: -1.98094
[32m[0907 18-49-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35634, current rewards: -3487.40971, mean: -1.98148
[32m[0907 18-49-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35632, current rewards: -3587.40971, mean: -1.98199
[32m[0907 18-50-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35628, current rewards: -3687.40971, mean: -1.98248
[32m[0907 18-50-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35623, current rewards: -3787.40971, mean: -1.98294
[32m[0907 18-50-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35621, current rewards: -3887.40971, mean: -1.98337
[32m[0907 18-51-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35616, current rewards: -3987.40971, mean: -1.98379
[32m[0907 18-51-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35612, current rewards: -4087.40971, mean: -1.98418
[32m[0907 18-51-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35611, current rewards: -4187.40971, mean: -1.98455
[32m[0907 18-52-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35607, current rewards: -4287.40971, mean: -1.98491
[32m[0907 18-52-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35605, current rewards: -4387.40971, mean: -1.98525
[32m[0907 18-52-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35600, current rewards: -4487.40971, mean: -1.98558
[32m[0907 18-52-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35597, current rewards: -4587.40971, mean: -1.98589
[32m[0907 18-53-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35596, current rewards: -4687.40971, mean: -1.98619
[32m[0907 18-53-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35594, current rewards: -4787.40971, mean: -1.98648
[32m[0907 18-53-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35597, current rewards: -4887.40971, mean: -1.98675
[32m[0907 18-54-03 @Agent.py:117][0m Average action selection time: 0.3561
[32m[0907 18-54-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-54-03 @MBExp.py:227][0m Rewards obtained: [-4967.409714452912], Lows: [2474], Highs: [22], Total time: 92682.632843
[32m[0907 18-58-13 @MBExp.py:144][0m ####################################################################
[32m[0907 18-58-13 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 18-58-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33705, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-58-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34996, current rewards: -67.81410, mean: -1.13023
[32m[0907 18-58-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34640, current rewards: -120.45740, mean: -1.09507
[32m[0907 18-59-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34950, current rewards: -179.22970, mean: -1.12019
[32m[0907 18-59-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34968, current rewards: -226.62834, mean: -1.07918
[32m[0907 18-59-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35169, current rewards: -268.22112, mean: -1.03162
[32m[0907 19-00-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35844, current rewards: -341.22112, mean: -1.10071
[32m[0907 19-00-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37623, current rewards: -378.08889, mean: -1.05025
[32m[0907 19-00-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37962, current rewards: -442.16211, mean: -1.07844
[32m[0907 19-01-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37848, current rewards: -500.25361, mean: -1.08751
[32m[0907 19-01-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.38654, current rewards: -555.75777, mean: -1.08972
[32m[0907 19-01-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38806, current rewards: -600.09020, mean: -1.07159
[32m[0907 19-02-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.39558, current rewards: -659.07644, mean: -1.08045
[32m[0907 19-02-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39575, current rewards: -708.16541, mean: -1.07298
[32m[0907 19-02-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.39350, current rewards: -764.89622, mean: -1.07732
[32m[0907 19-03-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.39284, current rewards: -824.75469, mean: -1.08520
[32m[0907 19-03-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.39336, current rewards: -867.04989, mean: -1.07043
[32m[0907 19-03-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.39685, current rewards: -902.85790, mean: -1.04983
[32m[0907 19-04-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.39783, current rewards: -955.98667, mean: -1.05053
[32m[0907 19-04-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.40183, current rewards: -951.79637, mean: -0.99145
[32m[0907 19-05-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.40498, current rewards: -980.64167, mean: -0.97093
[32m[0907 19-05-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.40354, current rewards: -1029.26234, mean: -0.97100
[32m[0907 19-05-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.40212, current rewards: -1055.82762, mean: -0.95120
[32m[0907 19-06-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.40317, current rewards: -1089.40964, mean: -0.93915
[32m[0907 19-06-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.40166, current rewards: -1129.20624, mean: -0.93323
[32m[0907 19-06-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.40017, current rewards: -1165.77620, mean: -0.92522
[32m[0907 19-06-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.39894, current rewards: -1207.84097, mean: -0.92202
[32m[0907 19-07-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.39835, current rewards: -1254.30383, mean: -0.92228
[32m[0907 19-07-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.39763, current rewards: -1316.23430, mean: -0.93350
[32m[0907 19-07-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.39657, current rewards: -1366.05398, mean: -0.93565
[32m[0907 19-08-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.39603, current rewards: -1422.94209, mean: -0.94235
[32m[0907 19-08-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.39540, current rewards: -1476.58396, mean: -0.94653
[32m[0907 19-08-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.39490, current rewards: -1531.47859, mean: -0.95123
[32m[0907 19-09-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.39371, current rewards: -1586.07816, mean: -0.95547
[32m[0907 19-09-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.39355, current rewards: -1644.81270, mean: -0.96188
[32m[0907 19-09-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.39308, current rewards: -1694.82264, mean: -0.96297
[32m[0907 19-10-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.39218, current rewards: -1750.40334, mean: -0.96707
[32m[0907 19-10-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.39120, current rewards: -1800.40334, mean: -0.96796
[32m[0907 19-10-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.39027, current rewards: -1850.40334, mean: -0.96880
[32m[0907 19-10-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.38940, current rewards: -1900.40334, mean: -0.96959
[32m[0907 19-11-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.38856, current rewards: -1950.40334, mean: -0.97035
[32m[0907 19-11-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.38776, current rewards: -2000.40334, mean: -0.97107
[32m[0907 19-11-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.38700, current rewards: -2050.40334, mean: -0.97176
[32m[0907 19-12-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.38625, current rewards: -2100.40334, mean: -0.97241
[32m[0907 19-12-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.38556, current rewards: -2150.40334, mean: -0.97303
[32m[0907 19-12-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.38491, current rewards: -2200.40334, mean: -0.97363
[32m[0907 19-13-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.38450, current rewards: -2250.40334, mean: -0.97420
[32m[0907 19-13-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.38424, current rewards: -2308.29827, mean: -0.97809
[32m[0907 19-13-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.38360, current rewards: -2366.08411, mean: -0.98178
[32m[0907 19-13-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.38300, current rewards: -2400.70845, mean: -0.97590
[32m[0907 19-14-10 @Agent.py:117][0m Average action selection time: 0.3827
[32m[0907 19-14-10 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-14-10 @MBExp.py:227][0m Rewards obtained: [-2441.953638279082], Lows: [373], Highs: [1757], Total time: 93640.321647
[32m[0907 19-18-01 @MBExp.py:144][0m ####################################################################
[32m[0907 19-18-01 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 19-18-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34350, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-18-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32839, current rewards: -64.86036, mean: -1.08101
[32m[0907 19-18-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32557, current rewards: -138.95921, mean: -1.26327
[32m[0907 19-18-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32603, current rewards: -223.98538, mean: -1.39991
[32m[0907 19-19-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32558, current rewards: -298.91156, mean: -1.42339
[32m[0907 19-19-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32657, current rewards: -387.48106, mean: -1.49031
[32m[0907 19-19-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33630, current rewards: -450.87758, mean: -1.45444
[32m[0907 19-20-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34085, current rewards: -530.74335, mean: -1.47429
[32m[0907 19-20-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35156, current rewards: -589.69511, mean: -1.43828
[32m[0907 19-20-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35228, current rewards: -680.41662, mean: -1.47917
[32m[0907 19-21-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35248, current rewards: -780.41662, mean: -1.53023
[32m[0907 19-21-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35260, current rewards: -838.41662, mean: -1.49717
[32m[0907 19-21-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35248, current rewards: -888.41662, mean: -1.45642
[32m[0907 19-21-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35252, current rewards: -938.41662, mean: -1.42184
[32m[0907 19-22-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35264, current rewards: -988.41662, mean: -1.39214
[32m[0907 19-22-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35265, current rewards: -1060.41662, mean: -1.39529
[32m[0907 19-22-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35266, current rewards: -1160.41662, mean: -1.43261
[32m[0907 19-23-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35273, current rewards: -1217.41662, mean: -1.41560
[32m[0907 19-23-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35277, current rewards: -1315.41662, mean: -1.44551
[32m[0907 19-23-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35273, current rewards: -1415.41662, mean: -1.47439
[32m[0907 19-23-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35277, current rewards: -1515.41662, mean: -1.50041
[32m[0907 19-24-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35273, current rewards: -1615.41662, mean: -1.52398
[32m[0907 19-24-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35268, current rewards: -1715.41662, mean: -1.54542
[32m[0907 19-24-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35274, current rewards: -1815.41662, mean: -1.56501
[32m[0907 19-25-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35268, current rewards: -1915.41662, mean: -1.58299
[32m[0907 19-25-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35263, current rewards: -2015.41662, mean: -1.59954
[32m[0907 19-25-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35260, current rewards: -2115.41662, mean: -1.61482
[32m[0907 19-26-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35258, current rewards: -2215.41662, mean: -1.62898
[32m[0907 19-26-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35254, current rewards: -2315.41662, mean: -1.64214
[32m[0907 19-26-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35253, current rewards: -2415.41662, mean: -1.65439
[32m[0907 19-26-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35253, current rewards: -2515.41662, mean: -1.66584
[32m[0907 19-27-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35236, current rewards: -2615.41662, mean: -1.67655
[32m[0907 19-27-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35209, current rewards: -2715.41662, mean: -1.68659
[32m[0907 19-27-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35186, current rewards: -2815.41662, mean: -1.69603
[32m[0907 19-28-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35161, current rewards: -2915.41662, mean: -1.70492
[32m[0907 19-28-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35140, current rewards: -3015.41662, mean: -1.71330
[32m[0907 19-28-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35120, current rewards: -3115.41662, mean: -1.72122
[32m[0907 19-28-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35100, current rewards: -3215.41662, mean: -1.72872
[32m[0907 19-29-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35083, current rewards: -3315.41662, mean: -1.73582
[32m[0907 19-29-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35021, current rewards: -3415.41662, mean: -1.74256
[32m[0907 19-29-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34916, current rewards: -3515.41662, mean: -1.74896
[32m[0907 19-29-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34816, current rewards: -3615.41662, mean: -1.75506
[32m[0907 19-30-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34720, current rewards: -3715.41662, mean: -1.76086
[32m[0907 19-30-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34629, current rewards: -3815.41662, mean: -1.76640
[32m[0907 19-30-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34541, current rewards: -3915.41662, mean: -1.77168
[32m[0907 19-31-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34471, current rewards: -4015.41662, mean: -1.77673
[32m[0907 19-31-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34407, current rewards: -4115.41662, mean: -1.78157
[32m[0907 19-31-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34348, current rewards: -4215.41662, mean: -1.78619
[32m[0907 19-31-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34288, current rewards: -4315.41662, mean: -1.79063
[32m[0907 19-32-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34228, current rewards: -4415.41662, mean: -1.79488
[32m[0907 19-32-17 @Agent.py:117][0m Average action selection time: 0.3418
[32m[0907 19-32-17 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-32-17 @MBExp.py:227][0m Rewards obtained: [-4495.416622383314], Lows: [2080], Highs: [349], Total time: 94495.76075100001
[32m[0907 19-35-56 @MBExp.py:144][0m ####################################################################
[32m[0907 19-35-56 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 19-35-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32226, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-36-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32322, current rewards: -74.19132, mean: -1.23652
[32m[0907 19-36-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32667, current rewards: -138.53061, mean: -1.25937
[32m[0907 19-36-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32816, current rewards: -201.39718, mean: -1.25873
[32m[0907 19-37-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32813, current rewards: -266.54229, mean: -1.26925
[32m[0907 19-37-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32859, current rewards: -347.71382, mean: -1.33736
[32m[0907 19-37-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33109, current rewards: -392.15756, mean: -1.26502
[32m[0907 19-37-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33507, current rewards: -467.24419, mean: -1.29790
[32m[0907 19-38-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33849, current rewards: -515.63368, mean: -1.25764
[32m[0907 19-38-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34130, current rewards: -572.73733, mean: -1.24508
[32m[0907 19-38-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34301, current rewards: -638.02101, mean: -1.25102
[32m[0907 19-39-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34464, current rewards: -689.36918, mean: -1.23102
[32m[0907 19-39-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34570, current rewards: -750.64845, mean: -1.23057
[32m[0907 19-39-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34668, current rewards: -805.34525, mean: -1.22022
[32m[0907 19-40-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34750, current rewards: -869.10842, mean: -1.22410
[32m[0907 19-40-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34824, current rewards: -933.64225, mean: -1.22848
[32m[0907 19-40-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34886, current rewards: -1002.82808, mean: -1.23806
[32m[0907 19-40-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34948, current rewards: -1089.97373, mean: -1.26741
[32m[0907 19-41-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34998, current rewards: -1178.85319, mean: -1.29544
[32m[0907 19-41-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35045, current rewards: -1262.73263, mean: -1.31535
[32m[0907 19-41-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35081, current rewards: -1344.81006, mean: -1.33150
[32m[0907 19-42-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35107, current rewards: -1431.70121, mean: -1.35066
[32m[0907 19-42-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35161, current rewards: -1512.93769, mean: -1.36301
[32m[0907 19-42-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35241, current rewards: -1599.88473, mean: -1.37921
[32m[0907 19-43-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35305, current rewards: -1673.88473, mean: -1.38338
[32m[0907 19-43-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35367, current rewards: -1723.88473, mean: -1.36816
[32m[0907 19-43-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35394, current rewards: -1773.88473, mean: -1.35411
[32m[0907 19-43-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35405, current rewards: -1823.88473, mean: -1.34109
[32m[0907 19-44-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35417, current rewards: -1873.88473, mean: -1.32900
[32m[0907 19-44-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35430, current rewards: -1923.88473, mean: -1.31773
[32m[0907 19-44-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35433, current rewards: -1973.88473, mean: -1.30721
[32m[0907 19-45-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35419, current rewards: -2023.88473, mean: -1.29736
[32m[0907 19-45-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35406, current rewards: -2073.88473, mean: -1.28813
[32m[0907 19-45-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35391, current rewards: -2077.82305, mean: -1.25170
[32m[0907 19-46-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35377, current rewards: -2068.76961, mean: -1.20981
[32m[0907 19-46-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35363, current rewards: -2059.71618, mean: -1.17029
[32m[0907 19-46-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35350, current rewards: -2050.66275, mean: -1.13296
[32m[0907 19-46-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35337, current rewards: -2041.60932, mean: -1.09764
[32m[0907 19-47-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35325, current rewards: -2046.72871, mean: -1.07159
[32m[0907 19-47-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35317, current rewards: -2096.72871, mean: -1.06976
[32m[0907 19-47-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35307, current rewards: -2146.72871, mean: -1.06802
[32m[0907 19-48-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35297, current rewards: -2196.72871, mean: -1.06637
[32m[0907 19-48-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35286, current rewards: -2246.72871, mean: -1.06480
[32m[0907 19-48-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35276, current rewards: -2296.72871, mean: -1.06330
[32m[0907 19-48-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35266, current rewards: -2346.72871, mean: -1.06187
[32m[0907 19-49-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35277, current rewards: -2396.72871, mean: -1.06050
[32m[0907 19-49-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35287, current rewards: -2446.72871, mean: -1.05919
[32m[0907 19-49-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35301, current rewards: -2496.72871, mean: -1.05794
[32m[0907 19-50-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35312, current rewards: -2546.72871, mean: -1.05673
[32m[0907 19-50-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35322, current rewards: -2596.72871, mean: -1.05558
[32m[0907 19-50-40 @Agent.py:117][0m Average action selection time: 0.3533
[32m[0907 19-50-40 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-50-40 @MBExp.py:227][0m Rewards obtained: [-2636.728709061471], Lows: [725], Highs: [1281], Total time: 95379.83271100001
[32m[0907 19-54-45 @MBExp.py:144][0m ####################################################################
[32m[0907 19-54-45 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 19-54-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34631, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-55-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33100, current rewards: -58.95124, mean: -0.98252
[32m[0907 19-55-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32972, current rewards: -108.95124, mean: -0.99047
[32m[0907 19-55-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32909, current rewards: -158.95124, mean: -0.99345
[32m[0907 19-55-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32903, current rewards: -208.95124, mean: -0.99501
[32m[0907 19-56-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32835, current rewards: -258.95124, mean: -0.99597
[32m[0907 19-56-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32976, current rewards: -308.95124, mean: -0.99662
[32m[0907 19-56-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33368, current rewards: -358.95124, mean: -0.99709
[32m[0907 19-57-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33735, current rewards: -408.95124, mean: -0.99744
[32m[0907 19-57-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34021, current rewards: -458.95124, mean: -0.99772
[32m[0907 19-57-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34287, current rewards: -508.95124, mean: -0.99794
[32m[0907 19-57-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34484, current rewards: -558.95124, mean: -0.99813
[32m[0907 19-58-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34684, current rewards: -608.95124, mean: -0.99828
[32m[0907 19-58-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34846, current rewards: -658.95124, mean: -0.99841
[32m[0907 19-58-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34967, current rewards: -708.95124, mean: -0.99852
[32m[0907 19-59-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35092, current rewards: -758.95124, mean: -0.99862
[32m[0907 19-59-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35217, current rewards: -808.95124, mean: -0.99871
[32m[0907 19-59-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35321, current rewards: -858.95124, mean: -0.99878
[32m[0907 20-00-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35396, current rewards: -908.95124, mean: -0.99885
[32m[0907 20-00-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35454, current rewards: -958.95124, mean: -0.99891
[32m[0907 20-00-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35495, current rewards: -1008.95124, mean: -0.99896
[32m[0907 20-01-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35527, current rewards: -1018.59268, mean: -0.96094
[32m[0907 20-01-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35559, current rewards: -1010.93760, mean: -0.91075
[32m[0907 20-01-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35573, current rewards: -1003.28252, mean: -0.86490
[32m[0907 20-01-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35574, current rewards: -995.62744, mean: -0.82283
[32m[0907 20-02-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35578, current rewards: -987.97236, mean: -0.78411
[32m[0907 20-02-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35581, current rewards: -980.31728, mean: -0.74833
[32m[0907 20-02-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35583, current rewards: -972.66220, mean: -0.71519
[32m[0907 20-03-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35585, current rewards: -965.00712, mean: -0.68440
[32m[0907 20-03-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35593, current rewards: -957.35204, mean: -0.65572
[32m[0907 20-03-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35572, current rewards: -995.75219, mean: -0.65944
[32m[0907 20-04-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35551, current rewards: -1045.75219, mean: -0.67035
[32m[0907 20-04-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35541, current rewards: -1095.75219, mean: -0.68059
[32m[0907 20-04-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35530, current rewards: -1145.75219, mean: -0.69021
[32m[0907 20-04-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35520, current rewards: -1180.01788, mean: -0.69007
[32m[0907 20-05-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35503, current rewards: -1177.57018, mean: -0.66907
[32m[0907 20-05-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35482, current rewards: -1175.12247, mean: -0.64924
[32m[0907 20-05-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35460, current rewards: -1172.67477, mean: -0.63047
[32m[0907 20-06-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35441, current rewards: -1213.23419, mean: -0.63520
[32m[0907 20-06-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35422, current rewards: -1263.23419, mean: -0.64451
[32m[0907 20-06-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35404, current rewards: -1313.23419, mean: -0.65335
[32m[0907 20-06-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35385, current rewards: -1363.23419, mean: -0.66176
[32m[0907 20-07-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35370, current rewards: -1413.23419, mean: -0.66978
[32m[0907 20-07-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35353, current rewards: -1463.23419, mean: -0.67742
[32m[0907 20-07-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35345, current rewards: -1513.23419, mean: -0.68472
[32m[0907 20-08-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35355, current rewards: -1563.23419, mean: -0.69170
[32m[0907 20-08-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35361, current rewards: -1613.23419, mean: -0.69837
[32m[0907 20-08-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35367, current rewards: -1663.23419, mean: -0.70476
[32m[0907 20-08-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35374, current rewards: -1713.23419, mean: -0.71089
[32m[0907 20-09-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35380, current rewards: -1763.23419, mean: -0.71676
[32m[0907 20-09-30 @Agent.py:117][0m Average action selection time: 0.3538
[32m[0907 20-09-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-09-30 @MBExp.py:227][0m Rewards obtained: [-1803.234185519055], Lows: [0], Highs: [1880], Total time: 96265.301745
[32m[0907 20-13-37 @MBExp.py:144][0m ####################################################################
[32m[0907 20-13-37 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 20-13-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33271, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-13-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33352, current rewards: -94.94383, mean: -1.58240
[32m[0907 20-14-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33327, current rewards: -194.94383, mean: -1.77222
[32m[0907 20-14-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33312, current rewards: -294.94383, mean: -1.84340
[32m[0907 20-14-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33207, current rewards: -394.94383, mean: -1.88068
[32m[0907 20-15-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33111, current rewards: -494.94383, mean: -1.90363
[32m[0907 20-15-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33119, current rewards: -594.94383, mean: -1.91917
[32m[0907 20-15-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33369, current rewards: -694.94383, mean: -1.93040
[32m[0907 20-15-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33603, current rewards: -794.94383, mean: -1.93889
[32m[0907 20-16-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33798, current rewards: -894.94383, mean: -1.94553
[32m[0907 20-16-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33912, current rewards: -994.94383, mean: -1.95087
[32m[0907 20-16-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33696, current rewards: -1094.94383, mean: -1.95526
[32m[0907 20-17-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33545, current rewards: -1194.94383, mean: -1.95892
[32m[0907 20-17-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33390, current rewards: -1294.94383, mean: -1.96204
[32m[0907 20-17-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33271, current rewards: -1394.94383, mean: -1.96471
[32m[0907 20-17-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33162, current rewards: -1494.94383, mean: -1.96703
[32m[0907 20-18-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33061, current rewards: -1594.94383, mean: -1.96907
[32m[0907 20-18-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32976, current rewards: -1694.94383, mean: -1.97086
[32m[0907 20-18-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32901, current rewards: -1794.94383, mean: -1.97247
[32m[0907 20-18-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32828, current rewards: -1894.94383, mean: -1.97390
[32m[0907 20-19-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32768, current rewards: -1994.94383, mean: -1.97519
[32m[0907 20-19-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32714, current rewards: -2094.94383, mean: -1.97636
[32m[0907 20-19-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32661, current rewards: -2194.94383, mean: -1.97743
[32m[0907 20-19-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32617, current rewards: -2294.94383, mean: -1.97840
[32m[0907 20-20-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32571, current rewards: -2394.94383, mean: -1.97929
[32m[0907 20-20-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32531, current rewards: -2494.94383, mean: -1.98011
[32m[0907 20-20-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32492, current rewards: -2594.94383, mean: -1.98087
[32m[0907 20-20-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32456, current rewards: -2694.94383, mean: -1.98158
[32m[0907 20-21-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32423, current rewards: -2794.94383, mean: -1.98223
[32m[0907 20-21-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32384, current rewards: -2894.94383, mean: -1.98284
[32m[0907 20-21-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32329, current rewards: -2994.94383, mean: -1.98341
[32m[0907 20-22-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32278, current rewards: -3094.94383, mean: -1.98394
[32m[0907 20-22-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32243, current rewards: -3194.94383, mean: -1.98444
[32m[0907 20-22-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32306, current rewards: -3294.94383, mean: -1.98491
[32m[0907 20-22-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32369, current rewards: -3394.94383, mean: -1.98535
[32m[0907 20-23-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32427, current rewards: -3494.94383, mean: -1.98576
[32m[0907 20-23-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32482, current rewards: -3594.94383, mean: -1.98616
[32m[0907 20-23-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32522, current rewards: -3694.94383, mean: -1.98653
[32m[0907 20-23-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32476, current rewards: -3794.94383, mean: -1.98688
[32m[0907 20-24-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32433, current rewards: -3894.94383, mean: -1.98722
[32m[0907 20-24-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32396, current rewards: -3994.94383, mean: -1.98753
[32m[0907 20-24-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32357, current rewards: -4094.94383, mean: -1.98784
[32m[0907 20-24-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32319, current rewards: -4194.94383, mean: -1.98813
[32m[0907 20-25-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32284, current rewards: -4294.94383, mean: -1.98840
[32m[0907 20-25-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32269, current rewards: -4394.94383, mean: -1.98866
[32m[0907 20-25-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32254, current rewards: -4494.94383, mean: -1.98891
[32m[0907 20-26-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32238, current rewards: -4594.94383, mean: -1.98915
[32m[0907 20-26-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32222, current rewards: -4694.94383, mean: -1.98938
[32m[0907 20-26-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32208, current rewards: -4794.94383, mean: -1.98960
[32m[0907 20-26-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32196, current rewards: -4894.94383, mean: -1.98981
[32m[0907 20-27-02 @Agent.py:117][0m Average action selection time: 0.3219
[32m[0907 20-27-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-27-02 @MBExp.py:227][0m Rewards obtained: [-4974.943825938189], Lows: [2476], Highs: [23], Total time: 97070.76298300001
[32m[0907 20-30-41 @MBExp.py:144][0m ####################################################################
[32m[0907 20-30-41 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 20-30-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48105, current rewards: 0.66126, mean: 0.06613
[32m[0907 20-31-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35811, current rewards: -60.63702, mean: -1.01062
[32m[0907 20-31-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32744, current rewards: -110.63702, mean: -1.00579
[32m[0907 20-31-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31582, current rewards: -160.63702, mean: -1.00398
[32m[0907 20-31-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30974, current rewards: -210.63702, mean: -1.00303
[32m[0907 20-32-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30600, current rewards: -207.16870, mean: -0.79680
[32m[0907 20-32-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30386, current rewards: -203.53537, mean: -0.65657
[32m[0907 20-32-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30430, current rewards: -199.90204, mean: -0.55528
[32m[0907 20-32-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30601, current rewards: -205.92271, mean: -0.50225
[32m[0907 20-33-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30723, current rewards: -255.92271, mean: -0.55635
[32m[0907 20-33-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30809, current rewards: -305.92271, mean: -0.59985
[32m[0907 20-33-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30874, current rewards: -355.92271, mean: -0.63558
[32m[0907 20-33-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30935, current rewards: -405.92271, mean: -0.66545
[32m[0907 20-34-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30981, current rewards: -455.92271, mean: -0.69079
[32m[0907 20-34-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31023, current rewards: -505.92271, mean: -0.71257
[32m[0907 20-34-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31066, current rewards: -555.92271, mean: -0.73148
[32m[0907 20-34-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31098, current rewards: -605.92271, mean: -0.74805
[32m[0907 20-35-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31127, current rewards: -655.92271, mean: -0.76270
[32m[0907 20-35-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31147, current rewards: -705.92271, mean: -0.77574
[32m[0907 20-35-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31162, current rewards: -755.92271, mean: -0.78742
[32m[0907 20-35-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31178, current rewards: -805.92271, mean: -0.79794
[32m[0907 20-36-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31191, current rewards: -855.92271, mean: -0.80747
[32m[0907 20-36-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31202, current rewards: -905.92271, mean: -0.81615
[32m[0907 20-36-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31214, current rewards: -955.92271, mean: -0.82407
[32m[0907 20-36-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31227, current rewards: -1005.92271, mean: -0.83134
[32m[0907 20-37-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31239, current rewards: -1055.92271, mean: -0.83803
[32m[0907 20-37-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31249, current rewards: -1105.92271, mean: -0.84422
[32m[0907 20-37-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31258, current rewards: -1155.92271, mean: -0.84994
[32m[0907 20-38-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31288, current rewards: -1205.92271, mean: -0.85526
[32m[0907 20-38-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31287, current rewards: -1255.92271, mean: -0.86022
[32m[0907 20-38-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31286, current rewards: -1305.92271, mean: -0.86485
[32m[0907 20-38-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31288, current rewards: -1355.92271, mean: -0.86918
[32m[0907 20-39-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31289, current rewards: -1405.92271, mean: -0.87324
[32m[0907 20-39-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31291, current rewards: -1455.92271, mean: -0.87706
[32m[0907 20-39-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31291, current rewards: -1505.92271, mean: -0.88066
[32m[0907 20-39-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31292, current rewards: -1555.92271, mean: -0.88405
[32m[0907 20-40-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31291, current rewards: -1605.92271, mean: -0.88725
[32m[0907 20-40-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31289, current rewards: -1655.92271, mean: -0.89028
[32m[0907 20-40-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31307, current rewards: -1705.92271, mean: -0.89315
[32m[0907 20-40-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31384, current rewards: -1755.92271, mean: -0.89588
[32m[0907 20-41-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31459, current rewards: -1805.92271, mean: -0.89847
[32m[0907 20-41-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31530, current rewards: -1855.92271, mean: -0.90093
[32m[0907 20-41-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31596, current rewards: -1905.92271, mean: -0.90328
[32m[0907 20-42-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31670, current rewards: -1955.92271, mean: -0.90552
[32m[0907 20-42-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31753, current rewards: -2005.92271, mean: -0.90766
[32m[0907 20-42-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31831, current rewards: -2055.92271, mean: -0.90970
[32m[0907 20-42-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31908, current rewards: -2105.92271, mean: -0.91165
[32m[0907 20-43-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31983, current rewards: -2155.92271, mean: -0.91353
[32m[0907 20-43-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32053, current rewards: -2205.92271, mean: -0.91532
[32m[0907 20-43-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32119, current rewards: -2255.92271, mean: -0.91704
[32m[0907 20-44-06 @Agent.py:117][0m Average action selection time: 0.3217
[32m[0907 20-44-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-44-06 @MBExp.py:227][0m Rewards obtained: [-2295.922712548652], Lows: [25], Highs: [2262], Total time: 97875.82856800001
[32m[0907 20-48-10 @MBExp.py:144][0m ####################################################################
[32m[0907 20-48-10 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 20-48-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32131, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-48-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32663, current rewards: -96.00000, mean: -1.60000
[32m[0907 20-48-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33413, current rewards: -152.62237, mean: -1.38748
[32m[0907 20-49-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33635, current rewards: -201.26978, mean: -1.25794
[32m[0907 20-49-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33509, current rewards: -249.10997, mean: -1.18624
[32m[0907 20-49-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33837, current rewards: -296.63316, mean: -1.14090
[32m[0907 20-49-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33691, current rewards: -342.81394, mean: -1.10585
[32m[0907 20-50-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33932, current rewards: -391.54478, mean: -1.08762
[32m[0907 20-50-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34159, current rewards: -441.33575, mean: -1.07643
[32m[0907 20-50-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34536, current rewards: -491.45827, mean: -1.06839
[32m[0907 20-51-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34648, current rewards: -541.04136, mean: -1.06087
[32m[0907 20-51-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34847, current rewards: -586.35708, mean: -1.04707
[32m[0907 20-51-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34997, current rewards: -636.13385, mean: -1.04284
[32m[0907 20-52-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35113, current rewards: -677.56209, mean: -1.02661
[32m[0907 20-52-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35246, current rewards: -713.29284, mean: -1.00464
[32m[0907 20-52-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35263, current rewards: -765.29284, mean: -1.00696
[32m[0907 20-52-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35294, current rewards: -816.23631, mean: -1.00770
[32m[0907 20-53-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35405, current rewards: -864.51140, mean: -1.00525
[32m[0907 20-53-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35407, current rewards: -914.51140, mean: -1.00496
[32m[0907 20-53-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35420, current rewards: -964.51140, mean: -1.00470
[32m[0907 20-54-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35484, current rewards: -1017.51140, mean: -1.00744
[32m[0907 20-54-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35513, current rewards: -1088.51140, mean: -1.02690
[32m[0907 20-54-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35514, current rewards: -1138.51140, mean: -1.02569
[32m[0907 20-55-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35515, current rewards: -1179.99903, mean: -1.01724
[32m[0907 20-55-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35515, current rewards: -1176.79414, mean: -0.97256
[32m[0907 20-55-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35510, current rewards: -1173.59182, mean: -0.93142
[32m[0907 20-55-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35507, current rewards: -1170.38949, mean: -0.89343
[32m[0907 20-56-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35509, current rewards: -1167.18716, mean: -0.85823
[32m[0907 20-56-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35481, current rewards: -1185.34417, mean: -0.84067
[32m[0907 20-56-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35452, current rewards: -1235.34417, mean: -0.84613
[32m[0907 20-57-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35425, current rewards: -1285.34417, mean: -0.85122
[32m[0907 20-57-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35400, current rewards: -1335.34417, mean: -0.85599
[32m[0907 20-57-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35375, current rewards: -1385.34417, mean: -0.86046
[32m[0907 20-57-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35352, current rewards: -1435.34417, mean: -0.86467
[32m[0907 20-58-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35331, current rewards: -1485.34417, mean: -0.86862
[32m[0907 20-58-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35310, current rewards: -1535.34417, mean: -0.87235
[32m[0907 20-58-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35290, current rewards: -1585.34417, mean: -0.87588
[32m[0907 20-59-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35272, current rewards: -1635.34417, mean: -0.87922
[32m[0907 20-59-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35255, current rewards: -1685.34417, mean: -0.88238
[32m[0907 20-59-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35237, current rewards: -1735.34417, mean: -0.88538
[32m[0907 20-59-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35223, current rewards: -1785.34417, mean: -0.88823
[32m[0907 21-00-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35210, current rewards: -1835.34417, mean: -0.89094
[32m[0907 21-00-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35198, current rewards: -1885.34417, mean: -0.89353
[32m[0907 21-00-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35210, current rewards: -1935.34417, mean: -0.89599
[32m[0907 21-01-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35217, current rewards: -1985.34417, mean: -0.89835
[32m[0907 21-01-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35224, current rewards: -2035.34417, mean: -0.90059
[32m[0907 21-01-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35232, current rewards: -2085.34417, mean: -0.90275
[32m[0907 21-02-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35236, current rewards: -2135.34417, mean: -0.90481
[32m[0907 21-02-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35242, current rewards: -2185.34417, mean: -0.90678
[32m[0907 21-02-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35250, current rewards: -2235.34417, mean: -0.90868
[32m[0907 21-02-52 @Agent.py:117][0m Average action selection time: 0.3526
[32m[0907 21-02-52 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-02-52 @MBExp.py:227][0m Rewards obtained: [-2275.3441687438462], Lows: [99], Highs: [2101], Total time: 98758.07267500002
[32m[0907 21-07-03 @MBExp.py:144][0m ####################################################################
[32m[0907 21-07-03 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 21-07-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32417, current rewards: 0.54271, mean: 0.05427
[32m[0907 21-07-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32608, current rewards: -78.91458, mean: -1.31524
[32m[0907 21-07-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32601, current rewards: -178.91458, mean: -1.62650
[32m[0907 21-07-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32599, current rewards: -278.91458, mean: -1.74322
[32m[0907 21-08-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32600, current rewards: -378.91458, mean: -1.80436
[32m[0907 21-08-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32612, current rewards: -478.91458, mean: -1.84198
[32m[0907 21-08-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32620, current rewards: -578.91458, mean: -1.86747
[32m[0907 21-09-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32824, current rewards: -678.91458, mean: -1.88587
[32m[0907 21-09-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33115, current rewards: -733.71778, mean: -1.78956
[32m[0907 21-09-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33381, current rewards: -783.71778, mean: -1.70373
[32m[0907 21-09-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33594, current rewards: -833.71778, mean: -1.63474
[32m[0907 21-10-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33768, current rewards: -883.71778, mean: -1.57807
[32m[0907 21-10-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33913, current rewards: -960.71778, mean: -1.57495
[32m[0907 21-10-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34067, current rewards: -1051.84135, mean: -1.59370
[32m[0907 21-11-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34204, current rewards: -1111.70735, mean: -1.56579
[32m[0907 21-11-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34302, current rewards: -1200.31144, mean: -1.57936
[32m[0907 21-11-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34375, current rewards: -1280.14908, mean: -1.58043
[32m[0907 21-12-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34575, current rewards: -1358.73885, mean: -1.57993
[32m[0907 21-12-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34628, current rewards: -1438.37561, mean: -1.58063
[32m[0907 21-12-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34680, current rewards: -1538.37561, mean: -1.60247
[32m[0907 21-12-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34721, current rewards: -1600.06390, mean: -1.58422
[32m[0907 21-13-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34754, current rewards: -1662.06390, mean: -1.56798
[32m[0907 21-13-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34788, current rewards: -1762.06390, mean: -1.58744
[32m[0907 21-13-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34817, current rewards: -1862.06390, mean: -1.60523
[32m[0907 21-14-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34842, current rewards: -1962.06390, mean: -1.62154
[32m[0907 21-14-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34863, current rewards: -2062.06390, mean: -1.63656
[32m[0907 21-14-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34886, current rewards: -2162.06390, mean: -1.65043
[32m[0907 21-14-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34851, current rewards: -2262.06390, mean: -1.66328
[32m[0907 21-15-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34748, current rewards: -2362.06390, mean: -1.67522
[32m[0907 21-15-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34652, current rewards: -2462.06390, mean: -1.68635
[32m[0907 21-15-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34562, current rewards: -2562.06390, mean: -1.69673
[32m[0907 21-16-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34478, current rewards: -2662.06390, mean: -1.70645
[32m[0907 21-16-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34398, current rewards: -2762.06390, mean: -1.71557
[32m[0907 21-16-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34323, current rewards: -2862.06390, mean: -1.72413
[32m[0907 21-16-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34252, current rewards: -2962.06390, mean: -1.73220
[32m[0907 21-17-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34187, current rewards: -3062.06390, mean: -1.73981
[32m[0907 21-17-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34126, current rewards: -3162.06390, mean: -1.74700
[32m[0907 21-17-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34068, current rewards: -3262.06390, mean: -1.75380
[32m[0907 21-17-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34013, current rewards: -3362.06390, mean: -1.76024
[32m[0907 21-18-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33958, current rewards: -3462.06390, mean: -1.76636
[32m[0907 21-18-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33907, current rewards: -3562.06390, mean: -1.77217
[32m[0907 21-18-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33858, current rewards: -3662.06390, mean: -1.77770
[32m[0907 21-18-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33813, current rewards: -3762.06390, mean: -1.78297
[32m[0907 21-19-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33769, current rewards: -3862.06390, mean: -1.78799
[32m[0907 21-19-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33727, current rewards: -3962.06390, mean: -1.79279
[32m[0907 21-19-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33687, current rewards: -4062.06390, mean: -1.79737
[32m[0907 21-20-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33649, current rewards: -4162.06390, mean: -1.80176
[32m[0907 21-20-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33612, current rewards: -4262.06390, mean: -1.80596
[32m[0907 21-20-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33577, current rewards: -4362.06390, mean: -1.80999
[32m[0907 21-20-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33544, current rewards: -4462.06390, mean: -1.81385
[32m[0907 21-21-02 @Agent.py:117][0m Average action selection time: 0.3352
[32m[0907 21-21-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-21-02 @MBExp.py:227][0m Rewards obtained: [-4542.063895190995], Lows: [2091], Highs: [364], Total time: 99596.82938000002
